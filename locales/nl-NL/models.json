{
  "01-ai/yi-1.5-34b-chat.description": "Het nieuwste open-source model van 01.AI met 34 miljard parameters, geoptimaliseerd voor diverse dialoogscenario’s. Het is getraind op hoogwaardige data en afgestemd op menselijke voorkeuren.",
  "01-ai/yi-1.5-9b-chat.description": "Het nieuwste open-source model van 01.AI met 9 miljard parameters, geoptimaliseerd voor diverse dialoogscenario’s. Het is getraind op hoogwaardige data en afgestemd op menselijke voorkeuren.",
  "360/deepseek-r1.description": "DeepSeek-R1, ingezet door 360, gebruikt grootschalige reinforcement learning in de post-trainingfase om redeneervermogen sterk te verbeteren met minimale labeling. Het presteert vergelijkbaar met OpenAI o1 op wiskunde-, codeer- en taalredeneertaken.",
  "360gpt-pro-trans.description": "Een vertaalspecialistisch model, diepgaand getraind voor toonaangevende vertaalprestaties.",
  "360gpt-pro.description": "360GPT Pro is een belangrijk AI-model van 360 met efficiënte tekstverwerking voor uiteenlopende NLP-toepassingen. Het ondersteunt begrip van lange teksten en meerstapsdialogen.",
  "360gpt-turbo-responsibility-8k.description": "360GPT Turbo Responsibility 8K legt de nadruk op semantische veiligheid en verantwoord gebruik in contentgevoelige toepassingen, en garandeert nauwkeurige en robuuste gebruikerservaringen.",
  "360gpt-turbo.description": "360GPT Turbo biedt krachtige reken- en chatmogelijkheden met uitstekende semantische interpretatie en generatie-efficiëntie, ideaal voor bedrijven en ontwikkelaars.",
  "360gpt2-o1.description": "360gpt2-o1 bouwt een redeneerlijn op via boomzoektechnieken met een reflectiemechanisme en reinforcement learning, waardoor zelfreflectie en zelfcorrectie mogelijk zijn.",
  "360gpt2-pro.description": "360GPT2 Pro is een geavanceerd NLP-model van 360 met uitstekende tekstgeneratie en -begrip, vooral geschikt voor creatieve taken, complexe transformaties en rollenspel.",
  "360zhinao2-o1.description": "360zhinao2-o1 bouwt een redeneerlijn op via boomzoektechnieken met een reflectiemechanisme en reinforcement learning, waardoor zelfreflectie en zelfcorrectie mogelijk zijn.",
  "4.0Ultra.description": "Spark Ultra is het krachtigste model in de Spark-serie. Het verbetert tekstbegrip en samenvatting, en optimaliseert webzoekopdrachten. Het is een allesomvattende oplossing voor hogere productiviteit op de werkvloer en nauwkeurige antwoorden, en positioneert zich als een toonaangevend intelligent product.",
  "AnimeSharp.description": "AnimeSharp (ook bekend als \"4x-AnimeSharp\") is een open-source superresolutiemodel gebaseerd op ESRGAN van Kim2091, gericht op het opschalen en verscherpen van anime-afbeeldingen. In februari 2022 hernoemd van \"4x-TextSharpV1\", oorspronkelijk ook bedoeld voor tekstafbeeldingen, maar sterk geoptimaliseerd voor anime-inhoud.",
  "Baichuan2-Turbo.description": "Maakt gebruik van zoekverrijking om het model te verbinden met domein- en webkennis. Ondersteunt het uploaden van PDF/Word-bestanden en URL-invoer voor tijdige, uitgebreide informatieopvraging en professionele, nauwkeurige output.",
  "Baichuan3-Turbo-128k.description": "Met een ultralange context van 128K is dit model geoptimaliseerd voor veelgebruikte bedrijfsscenario’s met aanzienlijke prestatieverbeteringen. Vergeleken met Baichuan2 verbetert contentcreatie met 20%, kennis-QA met 17% en rollenspel met 40%. De algehele prestaties zijn beter dan GPT-3.5.",
  "Baichuan3-Turbo.description": "Geoptimaliseerd voor veelgebruikte bedrijfsscenario’s met aanzienlijke prestatieverbeteringen. Vergeleken met Baichuan2 verbetert contentcreatie met 20%, kennis-QA met 17% en rollenspel met 40%. De algehele prestaties zijn beter dan GPT-3.5.",
  "Baichuan4-Air.description": "Een topmodel in China dat toonaangevende buitenlandse modellen overtreft op Chinese taken zoals kennis, lange teksten en creatieve generatie. Beschikt ook over toonaangevende multimodale capaciteiten met sterke resultaten op gezaghebbende benchmarks.",
  "Baichuan4-Turbo.description": "Een topmodel in China dat toonaangevende buitenlandse modellen overtreft op Chinese taken zoals kennis, lange teksten en creatieve generatie. Beschikt ook over toonaangevende multimodale capaciteiten met sterke resultaten op gezaghebbende benchmarks.",
  "Baichuan4.description": "Topprestaties op nationaal niveau, overtreft toonaangevende buitenlandse modellen op Chinese taken zoals encyclopedische kennis, lange teksten en creatieve generatie. Biedt ook toonaangevende multimodale capaciteiten en sterke benchmarkresultaten.",
  "ByteDance-Seed/Seed-OSS-36B-Instruct.description": "Seed-OSS is een familie van open-source LLM’s van ByteDance Seed, ontworpen voor sterke prestaties op lange contexten, redeneren, agenttaken en algemene vaardigheden. Seed-OSS-36B-Instruct is een 36B instructiegericht model met native ultralange contextverwerking voor grote documenten of codebases. Geoptimaliseerd voor redeneren, codegeneratie en agenttaken (toolgebruik), met behoud van sterke algemene capaciteiten. Een belangrijk kenmerk is het \"Thinking Budget\", waarmee flexibele redeneerlengte mogelijk is voor hogere efficiëntie.",
  "DeepSeek-R1-Distill-Llama-70B.description": "DeepSeek R1, het grotere en slimmere model in de DeepSeek-reeks, is gedistilleerd in de Llama 70B-architectuur. Benchmarks en menselijke evaluaties tonen aan dat het slimmer is dan de basisversie van Llama 70B, vooral op wiskunde- en feitennauwkeurigheidstaken.",
  "DeepSeek-R1-Distill-Qwen-1.5B.description": "Een DeepSeek-R1 gedistilleerd model gebaseerd op Qwen2.5-Math-1.5B. Reinforcement learning en cold-start data optimaliseren het redeneervermogen en zetten nieuwe multitask-benchmarks voor open modellen.",
  "DeepSeek-R1-Distill-Qwen-14B.description": "DeepSeek-R1-Distill modellen zijn fijngestemd op basis van open-source modellen met behulp van voorbeelddata gegenereerd door DeepSeek-R1.",
  "DeepSeek-R1-Distill-Qwen-32B.description": "DeepSeek-R1-Distill modellen zijn fijngestemd op basis van open-source modellen met behulp van voorbeelddata gegenereerd door DeepSeek-R1.",
  "DeepSeek-R1-Distill-Qwen-7B.description": "Een DeepSeek-R1 gedistilleerd model gebaseerd op Qwen2.5-Math-7B. Reinforcement learning en cold-start data optimaliseren het redeneervermogen en zetten nieuwe multitask-benchmarks voor open modellen.",
  "DeepSeek-R1.description": "DeepSeek-R1 past grootschalige reinforcement learning toe tijdens de post-trainingfase, wat het redeneervermogen sterk verbetert met zeer weinig gelabelde data. Het presteert vergelijkbaar met het OpenAI o1-productiemodel op wiskunde-, codeer- en taalredeneertaken.",
  "DeepSeek-V3-1.description": "DeepSeek V3.1 is een next-gen redeneermodel met verbeterd complex redeneren en chain-of-thought, geschikt voor diepgaande analysetaken.",
  "DeepSeek-V3-Fast.description": "Aanbieder: sophnet. DeepSeek V3 Fast is de high-TPS-versie van DeepSeek V3 0324, full-precision (niet-gekwantiseerd) met sterkere code- en wiskundeprestaties en snellere reacties.",
  "DeepSeek-V3.1-Fast.description": "DeepSeek V3.1 Fast is de snelle high-TPS-variant van DeepSeek V3.1. Hybride denkmodus: via chattemplates ondersteunt één model zowel denken als niet-denken. Slimmer toolgebruik: post-training verbetert prestaties op tool- en agenttaken.",
  "DeepSeek-V3.1-Think.description": "DeepSeek-V3.1 denkmodus: een nieuw hybride redeneermodel met denk- en niet-denkmodi, efficiënter dan DeepSeek-R1-0528. Post-training optimalisaties verbeteren het gebruik van agenttools en prestaties op agenttaken aanzienlijk.",
  "DeepSeek-V3.description": "DeepSeek-V3 is een MoE-model ontwikkeld door DeepSeek. Het overtreft andere open modellen zoals Qwen2.5-72B en Llama-3.1-405B op veel benchmarks en is concurrerend met toonaangevende gesloten modellen zoals GPT-4o en Claude 3.5 Sonnet.",
  "Doubao-lite-128k.description": "Doubao-lite biedt ultrasnelle reacties en betere waarde, met flexibele opties voor verschillende scenario’s. Ondersteunt 128K context voor inferentie en fine-tuning.",
  "Doubao-lite-32k.description": "Doubao-lite biedt ultrasnelle reacties en betere waarde, met flexibele opties voor verschillende scenario’s. Ondersteunt 32K context voor inferentie en fine-tuning.",
  "Doubao-lite-4k.description": "Doubao-lite biedt ultrasnelle reacties en betere waarde, met flexibele opties voor verschillende scenario’s. Ondersteunt 4K context voor inferentie en fine-tuning.",
  "Doubao-pro-128k.description": "Toppresterend vlaggenschipmodel voor complexe taken, sterk in referentie-QA, samenvatting, creatie, classificatie en rollenspel. Ondersteunt 128K context voor inferentie en fine-tuning.",
  "Doubao-pro-32k.description": "Toppresterend vlaggenschipmodel voor complexe taken, sterk in referentie-QA, samenvatting, creatie, classificatie en rollenspel. Ondersteunt 32K context voor inferentie en fine-tuning.",
  "Doubao-pro-4k.description": "Toppresterend vlaggenschipmodel voor complexe taken, sterk in referentie-QA, samenvatting, creatie, classificatie en rollenspel. Ondersteunt 4K context voor inferentie en fine-tuning.",
  "DreamO.description": "DreamO is een open-source model voor beeldpersonalisatie, gezamenlijk ontwikkeld door ByteDance en de Universiteit van Peking. Het gebruikt een uniforme architectuur om multitask beeldgeneratie te ondersteunen. Dankzij efficiënte compositiemodellering genereert het zeer consistente, gepersonaliseerde beelden op basis van identiteit, onderwerp, stijl, achtergrond en andere gebruikersvoorwaarden.",
  "ERNIE-3.5-128K.description": "Baidu’s toonaangevende grootschalige LLM, getraind op enorme Chinese/Engelse corpora, met sterke algemene capaciteiten voor chat, creatie en plugingebruik; ondersteunt automatische integratie van de Baidu Search-plugin voor actuele antwoorden.",
  "ERNIE-3.5-8K-Preview.description": "Baidu’s toonaangevende grootschalige LLM, getraind op enorme Chinese/Engelse corpora, met sterke algemene capaciteiten voor chat, creatie en plugingebruik; ondersteunt automatische integratie van de Baidu Search-plugin voor actuele antwoorden.",
  "ERNIE-3.5-8K.description": "Baidu’s toonaangevende grootschalige LLM, getraind op enorme Chinese/Engelse corpora, met sterke algemene capaciteiten voor chat, creatie en plugingebruik; ondersteunt automatische integratie van de Baidu Search-plugin voor actuele antwoorden.",
  "ERNIE-4.0-8K-Latest.description": "Baidu’s toonaangevende ultra-grote LLM met uitgebreide verbeteringen ten opzichte van ERNIE 3.5, geschikt voor complexe taken in verschillende domeinen; ondersteunt integratie van de Baidu Search-plugin voor actuele antwoorden.",
  "ERNIE-4.0-8K-Preview.description": "Baidu’s toonaangevende ultra-grote LLM met uitgebreide verbeteringen ten opzichte van ERNIE 3.5, geschikt voor complexe taken in verschillende domeinen; ondersteunt integratie van de Baidu Search-plugin voor actuele antwoorden.",
  "ERNIE-4.0-Turbo-8K-Latest.description": "Baidu’s toonaangevende ultra-grote LLM met sterke algehele prestaties voor complexe taken, met integratie van de Baidu Search-plugin voor actuele antwoorden. Presteert beter dan ERNIE 4.0.",
  "ERNIE-4.0-Turbo-8K-Preview.description": "Baidu’s toonaangevende ultra-grote LLM met sterke algehele prestaties voor complexe taken, met integratie van de Baidu Search-plugin voor actuele antwoorden. Presteert beter dan ERNIE 4.0.",
  "ERNIE-Character-8K.description": "Baidu’s domeinspecifieke LLM voor game-NPC’s, klantenservice en rollenspel, met duidelijkere persona-consistentie, betere instructieopvolging en sterkere redeneercapaciteiten.",
  "ERNIE-Lite-Pro-128K.description": "Baidu’s lichtgewicht LLM die kwaliteit en inferentieprestaties in balans brengt, beter dan ERNIE Lite en geschikt voor omgevingen met beperkte rekenkracht.",
  "ERNIE-Speed-128K.description": "Baidu’s nieuwste high-performance LLM (2024) met sterke algemene capaciteiten, geschikt als basis voor fine-tuning in specifieke scenario’s, met uitstekende redeneercapaciteiten.",
  "ERNIE-Speed-Pro-128K.description": "Baidu’s nieuwste high-performance LLM (2024) met sterke algemene capaciteiten, beter dan ERNIE Speed, geschikt als basis voor fine-tuning met uitstekende redeneercapaciteiten.",
  "FLUX-1.1-pro.description": "FLUX.1.1 Pro",
  "FLUX.1-Kontext-dev.description": "FLUX.1-Kontext-dev is een multimodaal model voor beeldgeneratie en -bewerking van Black Forest Labs, gebaseerd op een Rectified Flow Transformer-architectuur met 12 miljard parameters. Het richt zich op het genereren, reconstrueren, verbeteren of bewerken van beelden op basis van contextuele voorwaarden. Het combineert de controleerbare generatiekracht van diffusie-modellen met contextmodellering via Transformers, en ondersteunt hoogwaardige output voor taken zoals inpainting, outpainting en visuele scenereconstructie.",
  "FLUX.1-Kontext-pro.description": "FLUX.1 Kontext [pro]",
  "FLUX.1-dev.description": "FLUX.1-dev is een open-source multimodaal taalmodel (MLLM) van Black Forest Labs, geoptimaliseerd voor beeld-teksttaken en combineert begrip en generatie van beeld/tekst. Gebouwd op geavanceerde LLM’s (zoals Mistral-7B), gebruikt het een zorgvuldig ontworpen vision encoder en meertraps instructie-tuning om multimodale coördinatie en complexe redeneertaken mogelijk te maken.",
  "Gryphe/MythoMax-L2-13b.description": "MythoMax-L2 (13B) is een innovatief model voor diverse domeinen en complexe taken.",
  "HelloMeme.description": "HelloMeme is een AI-tool die memes, GIF’s of korte video’s genereert op basis van de beelden of bewegingen die je aanlevert. Er zijn geen teken- of programmeervaardigheden nodig—alleen een referentiebeeld—om leuke, aantrekkelijke en stijlvaste content te maken.",
  "HiDream-I1-Full.description": "HiDream-E1-Full is een open-source multimodaal beeldbewerkingsmodel van HiDream.ai, gebaseerd op een geavanceerde Diffusion Transformer-architectuur en sterke taalbegrip (met ingebouwde LLaMA 3.1-8B-Instruct). Het ondersteunt beeldgeneratie op basis van natuurlijke taal, stijltransfers, lokale bewerkingen en herschildering, met uitstekend beeld-tekstbegrip en uitvoering.",
  "HunyuanDiT-v1.2-Diffusers-Distilled.description": "hunyuandit-v1.2-distilled is een lichtgewicht tekst-naar-beeldmodel dat via distillatie is geoptimaliseerd om snel beelden van hoge kwaliteit te genereren, vooral geschikt voor omgevingen met beperkte middelen en realtime generatie.",
  "InstantCharacter.description": "InstantCharacter is een tuning-vrij gepersonaliseerd karaktergeneratiemodel, uitgebracht door Tencent AI in 2025, gericht op getrouwe en consistente karaktergeneratie over verschillende scenario’s. Het kan een karakter modelleren op basis van één referentiebeeld en flexibel overdragen naar verschillende stijlen, acties en achtergronden.",
  "InternVL2-8B.description": "InternVL2-8B is een krachtig vision-language model dat multimodale beeld-tekstverwerking ondersteunt, beeldinhoud nauwkeurig herkent en relevante beschrijvingen of antwoorden genereert.",
  "InternVL2.5-26B.description": "InternVL2.5-26B is een krachtig vision-language model dat multimodale beeld-tekstverwerking ondersteunt, beeldinhoud nauwkeurig herkent en relevante beschrijvingen of antwoorden genereert.",
  "Kolors.description": "Kolors is een tekst-naar-beeldmodel ontwikkeld door het Kuaishou Kolors-team. Het is getraind met miljarden parameters en blinkt uit in visuele kwaliteit, Chinees semantisch begrip en tekstrendering.",
  "Kwai-Kolors/Kolors.description": "Kolors is een grootschalig latent-diffusie tekst-naar-beeldmodel van het Kuaishou Kolors-team. Getraind op miljarden tekst-beeldparen, blinkt het uit in visuele kwaliteit, complexe semantische nauwkeurigheid en Chinees/Engels tekstrendering, met sterk Chinees inhoudsbegrip en -generatie.",
  "Kwaipilot/KAT-Dev.description": "KAT-Dev (32B) is een open-source 32B-model voor software engineering-taken. Het behaalt een oplossingspercentage van 62,4% op SWE-Bench Verified en staat op de 5e plaats onder open modellen. Het is geoptimaliseerd via mid-training, SFT en RL voor codeaanvulling, bugfixing en codereview.",
  "Llama-3.2-11B-Vision-Instruct.description": "Sterk beeldredeneervermogen op hoge-resolutiebeelden, geschikt voor toepassingen in visueel begrip.",
  "Llama-3.2-90B-Vision-Instruct\t.description": "Geavanceerd beeldredeneren voor toepassingen met visueel begrip door agenten.",
  "Meta-Llama-3-3-70B-Instruct.description": "Llama 3.3 70B is een veelzijdig Transformer-model voor chat- en generatietaken.",
  "Meta-Llama-3.1-405B-Instruct.description": "Llama 3.1 is een instructie-afgestemd tekstmodel, geoptimaliseerd voor meertalige chat, en presteert sterk op gangbare industriële benchmarks onder open en gesloten chatmodellen.",
  "Meta-Llama-3.1-70B-Instruct.description": "Llama 3.1 is een instructie-afgestemd tekstmodel, geoptimaliseerd voor meertalige chat, en presteert sterk op gangbare industriële benchmarks onder open en gesloten chatmodellen.",
  "Meta-Llama-3.1-8B-Instruct.description": "Llama 3.1 is een instructie-afgestemd tekstmodel, geoptimaliseerd voor meertalige chat, en presteert sterk op gangbare industriële benchmarks onder open en gesloten chatmodellen.",
  "Meta-Llama-3.2-1B-Instruct.description": "Geavanceerd klein taalmodel met sterk taalbegrip, uitstekende redeneercapaciteiten en tekstgeneratie.",
  "Meta-Llama-3.2-3B-Instruct.description": "Geavanceerd klein taalmodel met sterk taalbegrip, uitstekende redeneercapaciteiten en tekstgeneratie.",
  "Meta-Llama-3.3-70B-Instruct.description": "Llama 3.3 is het meest geavanceerde meertalige open-source Llama-model, met prestaties vergelijkbaar met 405B tegen zeer lage kosten. Het is gebaseerd op een Transformer-architectuur en verbeterd met SFT en RLHF voor bruikbaarheid en veiligheid. De instructie-afgestemde versie is geoptimaliseerd voor meertalige chat en verslaat veel open en gesloten chatmodellen op industriële benchmarks. Kennisgrens: dec 2023.",
  "Meta-Llama-4-Maverick-17B-128E-Instruct-FP8.description": "Llama 4 Maverick is een groot MoE-model met efficiënte expertactivatie voor sterke redeneercapaciteiten.",
  "MiniMax-M1.description": "Een nieuw intern redeneermodel met 80K chain-of-thought en 1M input, met prestaties vergelijkbaar met toonaangevende wereldwijde modellen.",
  "MiniMax-M2-Stable.description": "Ontworpen voor efficiënte codeer- en agentworkflows, met hogere gelijktijdigheid voor commercieel gebruik.",
  "MiniMax-M2.1-Lightning.description": "Krachtige meertalige programmeermogelijkheden, een volledig vernieuwde programmeerervaring. Sneller en efficiënter.",
  "MiniMax-M2.1.description": "MiniMax-M2.1 is het vlaggenschip open-source grote model van MiniMax, gericht op het oplossen van complexe, realistische taken. De kernkwaliteiten zijn meertalige programmeermogelijkheden en het vermogen om complexe taken als een Agent op te lossen.",
  "MiniMax-M2.description": "Speciaal ontwikkeld voor efficiënt coderen en agent-workflows.",
  "MiniMax-Text-01.description": "MiniMax-01 introduceert grootschalige lineaire aandacht voorbij klassieke Transformers, met 456B parameters en 45,9B geactiveerd per pass. Het levert topprestaties en ondersteunt tot 4M tokens context (32× GPT-4o, 20× Claude-3.5-Sonnet).",
  "MiniMaxAI/MiniMax-M1-80k.description": "MiniMax-M1 is een open-gewichten grootschalig hybrid-attention redeneermodel met 456B totale parameters en ~45,9B actief per token. Het ondersteunt native 1M context en gebruikt Flash Attention om FLOPs met 75% te verminderen bij 100K-token generatie versus DeepSeek R1. Met een MoE-architectuur plus CISPO en hybrid-attention RL-training behaalt het toonaangevende prestaties op lang-input redeneren en echte software engineering-taken.",
  "MiniMaxAI/MiniMax-M2.description": "MiniMax-M2 herdefinieert agent-efficiëntie. Het is een compact, snel, kosteneffectief MoE-model met 230B totaal en 10B actieve parameters, gebouwd voor topniveau codeer- en agenttaken met behoud van sterke algemene intelligentie. Met slechts 10B actieve parameters evenaart het veel grotere modellen, ideaal voor toepassingen met hoge efficiëntie.",
  "Moonshot-Kimi-K2-Instruct.description": "1 biljoen totale parameters met 32 miljard actief. Onder de niet-denkende modellen behoort het tot de top op het gebied van geavanceerde kennis, wiskunde en programmeren, en is het sterker in algemene agenttaken. Geoptimaliseerd voor agentworkloads, kan het acties uitvoeren in plaats van alleen vragen beantwoorden. Ideaal voor improviserende, algemene gesprekken en agentervaringen als een reflexmatig model zonder langdurig denkproces.",
  "NousResearch/Nous-Hermes-2-Mixtral-8x7B-DPO.description": "Nous Hermes 2 - Mixtral 8x7B-DPO (46,7 miljard) is een zeer nauwkeurig instructiemodel voor complexe berekeningen.",
  "OmniConsistency.description": "OmniConsistency verbetert stijlconsistentie en generalisatie bij beeld-naar-beeld-taken door grootschalige Diffusion Transformers (DiTs) en gepaarde gestileerde data te introduceren, waardoor stijlvervaging wordt voorkomen.",
  "PaddlePaddle/PaddleOCR-VL-1.5.description": "PaddleOCR-VL-1.5 is een geüpgradede versie van de PaddleOCR-VL-serie en behaalt 94,5% nauwkeurigheid op de OmniDocBench v1.5 benchmark voor documentanalyse. Het overtreft toonaangevende algemene grote modellen en gespecialiseerde documentmodellen. Het ondersteunt innovatief de lokalisatie van onregelmatige begrenzingskaders voor documentelementen, en verwerkt effectief gescande, gekantelde en schermopnames.",
  "Phi-3-medium-128k-instruct.description": "Hetzelfde Phi-3-medium model met een groter contextvenster voor RAG of few-shot prompts.",
  "Phi-3-medium-4k-instruct.description": "Een model met 14 miljard parameters van hogere kwaliteit dan Phi-3-mini, gericht op hoogwaardige, redeneerintensieve data.",
  "Phi-3-mini-128k-instruct.description": "Hetzelfde Phi-3-mini model met een groter contextvenster voor RAG of few-shot prompts.",
  "Phi-3-mini-4k-instruct.description": "Het kleinste lid van de Phi-3-familie, geoptimaliseerd voor kwaliteit en lage latentie.",
  "Phi-3-small-128k-instruct.description": "Hetzelfde Phi-3-small model met een groter contextvenster voor RAG of few-shot prompts.",
  "Phi-3-small-8k-instruct.description": "Een model met 7 miljard parameters van hogere kwaliteit dan Phi-3-mini, gericht op hoogwaardige, redeneerintensieve data.",
  "Phi-3.5-mini-instruct.description": "Een bijgewerkte versie van het Phi-3-mini model.",
  "Phi-3.5-vision-instrust.description": "Een bijgewerkte versie van het Phi-3-vision model.",
  "Pro/MiniMaxAI/MiniMax-M2.1.description": "MiniMax-M2.1 is een open-source groot taalmodel geoptimaliseerd voor agent-capaciteiten, uitblinkend in programmeren, gebruik van tools, het volgen van instructies en langetermijnplanning. Het model ondersteunt meertalige softwareontwikkeling en de uitvoering van complexe workflows in meerdere stappen, behaalt een score van 74,0 op SWE-bench Verified en overtreft Claude Sonnet 4.5 in meertalige scenario’s.",
  "Pro/Qwen/Qwen2-7B-Instruct.description": "Qwen2-7B-Instruct is een 7 miljard parameter instructie-afgesteld LLM uit de Qwen2-serie. Het gebruikt een Transformer-architectuur met SwiGLU, attention QKV-bias en gegroepeerde query-attentie, en verwerkt grote invoer. Het presteert sterk op taalbegrip, generatie, meertalige taken, programmeren, wiskunde en redeneren, en overtreft de meeste open modellen en concurreert met gesloten modellen. Het presteert beter dan Qwen1.5-7B-Chat op meerdere benchmarks.",
  "Pro/Qwen/Qwen2.5-7B-Instruct.description": "Qwen2.5-7B-Instruct maakt deel uit van de nieuwste LLM-serie van Alibaba Cloud. Het 7 miljard model biedt aanzienlijke verbeteringen in programmeren en wiskunde, ondersteunt meer dan 29 talen en verbetert het volgen van instructies, begrip van gestructureerde data en gestructureerde output (vooral JSON).",
  "Pro/Qwen/Qwen2.5-Coder-7B-Instruct.description": "Qwen2.5-Coder-7B-Instruct is het nieuwste codegerichte LLM van Alibaba Cloud. Gebouwd op Qwen2.5 en getraind op 5,5 biljoen tokens, verbetert het aanzienlijk de codegeneratie, redenering en foutcorrectie, terwijl het sterke prestaties behoudt op het gebied van wiskunde en algemene taken. Het biedt een solide basis voor code-agents.",
  "Pro/Qwen/Qwen2.5-VL-7B-Instruct.description": "Qwen2.5-VL is een nieuw vision-language model uit de Qwen-serie met sterke visuele interpretatie. Het analyseert tekst, grafieken en lay-outs in afbeeldingen, begrijpt lange video's en gebeurtenissen, ondersteunt redenering en gereedschapsgebruik, objectverankering in meerdere formaten en gestructureerde output. Het verbetert dynamische resolutie en framerate-training voor video-inzicht en verhoogt de efficiëntie van de vision encoder.",
  "Pro/THUDM/GLM-4.1V-9B-Thinking.description": "GLM-4.1V-9B-Thinking is een open-source vision-language model van Zhipu AI en het KEG-lab van Tsinghua, ontworpen voor complexe multimodale cognitie. Gebaseerd op GLM-4-9B-0414, voegt het keten-van-gedachten-redenering en reinforcement learning toe om crossmodale redenering en stabiliteit aanzienlijk te verbeteren.",
  "Pro/THUDM/glm-4-9b-chat.description": "GLM-4-9B-Chat is het open-source GLM-4 model van Zhipu AI. Het presteert sterk op semantiek, wiskunde, redenering, programmeren en kennis. Naast meerstapsgesprekken ondersteunt het web browsing, code-uitvoering, aangepaste tool-aanroepen en redenering over lange teksten. Het ondersteunt 26 talen (waaronder Chinees, Engels, Japans, Koreaans en Duits). Het scoort goed op AlignBench-v2, MT-Bench, MMLU en C-Eval, en ondersteunt tot 128K context voor academisch en zakelijk gebruik.",
  "Pro/deepseek-ai/DeepSeek-R1-Distill-Qwen-7B.description": "DeepSeek-R1-Distill-Qwen-7B is gedistilleerd van Qwen2.5-Math-7B en verfijnd op 800.000 zorgvuldig geselecteerde DeepSeek-R1-samples. Het presteert sterk met 92,8% op MATH-500, 55,5% op AIME 2024 en een CodeForces-rating van 1189 voor een 7 miljard model.",
  "Pro/deepseek-ai/DeepSeek-R1.description": "DeepSeek-R1 is een redeneringsmodel aangedreven door reinforcement learning dat herhaling vermindert en de leesbaarheid verbetert. Het gebruikt cold-start data vóór RL om redenering verder te verbeteren, evenaart OpenAI-o1 op wiskunde-, code- en redeneertaken, en verbetert de algehele resultaten door zorgvuldige training.",
  "Pro/deepseek-ai/DeepSeek-V3.1-Terminus.description": "DeepSeek-V3.1-Terminus is een bijgewerkt V3.1-model gepositioneerd als een hybride agent-LLM. Het lost door gebruikers gemelde problemen op en verbetert de stabiliteit, taalconsistentie en vermindert gemengde Chinees/Engels en abnormale tekens. Het integreert denk- en niet-denkmodi met chatthema's voor flexibele omschakeling. Het verbetert ook de prestaties van Code Agent en Search Agent voor betrouwbaarder gereedschapsgebruik en meerstapstaken.",
  "Pro/deepseek-ai/DeepSeek-V3.2-Exp.description": "DeepSeek-V3.2-Exp is een experimentele V3.2-release die de brug slaat naar de volgende architectuur. Het voegt DeepSeek Sparse Attention (DSA) toe bovenop V3.1-Terminus om de efficiëntie van training en inferentie met lange context te verbeteren, met optimalisaties voor gereedschapsgebruik, begrip van lange documenten en meerstapsredenering. Ideaal voor het verkennen van hogere redeneerefficiëntie met grote contextbudgetten.",
  "Pro/deepseek-ai/DeepSeek-V3.description": "DeepSeek-V3 is een MoE-model met 671 miljard parameters dat gebruikmaakt van MLA en DeepSeekMoE met verliesvrije load balancing voor efficiënte inferentie en training. Voorgetraind op 14,8 biljoen hoogwaardige tokens en verder verfijnd met SFT en RL, overtreft het andere open modellen en benadert toonaangevende gesloten modellen.",
  "Pro/moonshotai/Kimi-K2-Instruct-0905.description": "Kimi K2-Instruct-0905 is de nieuwste en krachtigste Kimi K2. Het is een topklasse MoE-model met 1 biljoen totale en 32 miljard actieve parameters. Belangrijke kenmerken zijn sterkere agentgerichte programmeerintelligentie met aanzienlijke verbeteringen op benchmarks en echte agenttaken, plus verbeterde esthetiek en bruikbaarheid van frontend-code.",
  "Pro/moonshotai/Kimi-K2-Thinking.description": "Kimi K2 Thinking Turbo is de Turbo-variant geoptimaliseerd voor redeneersnelheid en verwerkingscapaciteit, terwijl het de meerstapsredenering en gereedschapsgebruik van K2 Thinking behoudt. Het is een MoE-model met ongeveer 1 biljoen totale parameters, native 256K context en stabiele grootschalige tool-aanroepen voor productieomgevingen met strengere eisen aan latentie en gelijktijdigheid.",
  "Pro/moonshotai/Kimi-K2.5.description": "Kimi K2.5 is een open-source native multimodaal agentmodel, gebaseerd op Kimi-K2-Base, getraind op ongeveer 1,5 biljoen gecombineerde visuele en tekstuele tokens. Het model gebruikt een MoE-architectuur met 1T totale parameters en 32B actieve parameters, ondersteunt een contextvenster van 256K en integreert naadloos visuele en taalbegripmogelijkheden.",
  "Pro/zai-org/glm-4.7.description": "GLM-4.7 is het nieuwste vlaggenschipmodel van Zhipu met 355 miljard totale parameters en 32 miljard actieve parameters. Het is volledig vernieuwd op het gebied van algemene dialoog, redeneren en agentfunctionaliteit. GLM-4.7 versterkt Interleaved Thinking en introduceert Preserved Thinking en Turn-level Thinking.",
  "QwQ-32B-Preview.description": "Qwen QwQ is een experimenteel onderzoeksmodel gericht op het verbeteren van redenering.",
  "Qwen/QVQ-72B-Preview.description": "QVQ-72B-Preview is een onderzoeksmodel van Qwen gericht op visuele redenering, met sterke prestaties in het begrijpen van complexe scènes en visuele wiskundeproblemen.",
  "Qwen/QwQ-32B-Preview.description": "Qwen QwQ is een experimenteel onderzoeksmodel gericht op verbeterde AI-redenering.",
  "Qwen/QwQ-32B.description": "QwQ is een redeneermodel binnen de Qwen-familie. In vergelijking met standaard instructie-afgestelde modellen voegt het denk- en redeneervermogen toe dat de prestaties op downstream-taken aanzienlijk verbetert, vooral bij moeilijke problemen. QwQ-32B is een model van gemiddelde grootte dat concurreert met top-redeneermodellen zoals DeepSeek-R1 en o1-mini. Het gebruikt RoPE, SwiGLU, RMSNorm en attention QKV-bias, met 64 lagen en 40 Q-attentiehoofden (8 KV in GQA).",
  "Qwen/Qwen-Image-Edit-2509.description": "Qwen-Image-Edit-2509 is de nieuwste bewerkingsversie van Qwen-Image van het Qwen-team. Gebouwd op het 20 miljard Qwen-Image model, breidt het sterke tekstrendering uit naar beeldbewerking voor nauwkeurige tekstaanpassingen. Het gebruikt een dual-control architectuur, waarbij invoer wordt gestuurd naar Qwen2.5-VL voor semantische controle en een VAE-encoder voor uiterlijkcontrole, wat bewerkingen op semantisch en uiterlijkniveau mogelijk maakt. Het ondersteunt lokale bewerkingen (toevoegen/verwijderen/wijzigen) en semantische bewerkingen op hoger niveau zoals IP-creatie en stijltransfer, terwijl de semantiek behouden blijft. Het behaalt SOTA-resultaten op meerdere benchmarks.",
  "Qwen/Qwen-Image.description": "Qwen-Image is een 20 miljard-parameter beeldgeneratiemodel van het Qwen-team. Het boekt grote vooruitgang in complexe tekstrendering en nauwkeurige beeldbewerking, vooral voor Chinese/Engelse tekst met hoge getrouwheid. Het ondersteunt meerregelige en paragraaflay-outs met consistente typografie. Naast tekstrendering ondersteunt het een breed scala aan stijlen van fotorealistisch tot anime, en geavanceerde bewerkingen zoals stijltransfer, object toevoegen/verwijderen, detailverbetering, tekstbewerking en posecontrole, met als doel een allesomvattend visueel creatief fundament te zijn.",
  "Qwen/Qwen2-72B-Instruct.description": "Qwen 2 Instruct (72B) biedt nauwkeurige instructieopvolging voor zakelijke toepassingen.",
  "Qwen/Qwen2-7B-Instruct.description": "Qwen2-7B-Instruct is een 7B model uit de Qwen2-serie, getraind op instructies en gebaseerd op Transformer, SwiGLU, QKV-bias en grouped-query attention. Het verwerkt grote invoer en presteert sterk op benchmarks voor begrip, generatie, meertaligheid, codering, wiskunde en redeneren. Het overtreft de meeste open modellen en presteert beter dan Qwen1.5-7B-Chat in meerdere evaluaties.",
  "Qwen/Qwen2-VL-72B-Instruct.description": "Qwen2-VL is het nieuwste Qwen-VL model en behaalt SOTA-resultaten op visuele benchmarks zoals MathVista, DocVQA, RealWorldQA en MTVQA. Het begrijpt video's van meer dan 20 minuten voor video-vragen, dialogen en contentcreatie. Het ondersteunt complexe redenering en besluitvorming, en kan worden geïntegreerd met apparaten/robots voor visueel gestuurde acties. Naast Engels en Chinees leest het ook tekst in veel andere talen, waaronder de meeste Europese talen, Japans, Koreaans, Arabisch en Vietnamees.",
  "Qwen/Qwen2.5-14B-Instruct.description": "Qwen2.5-14B-Instruct maakt deel uit van de nieuwste LLM-serie van Alibaba Cloud. Dit 14B-model biedt aanzienlijke verbeteringen in codering en wiskunde, ondersteunt meer dan 29 talen en verbetert instructieopvolging, begrip van gestructureerde data en gestructureerde output (vooral JSON).",
  "Qwen/Qwen2.5-32B-Instruct.description": "Qwen2.5-32B-Instruct maakt deel uit van de nieuwste LLM-serie van Alibaba Cloud. Dit 32B-model biedt aanzienlijke verbeteringen in codering en wiskunde, ondersteunt meer dan 29 talen en verbetert instructieopvolging, begrip van gestructureerde data en gestructureerde output (vooral JSON).",
  "Qwen/Qwen2.5-72B-Instruct-128K.description": "Qwen2.5-72B-Instruct maakt deel uit van de nieuwste LLM-serie van Alibaba Cloud. Dit 72B-model verbetert codering en wiskunde, ondersteunt tot 128K invoer en meer dan 8K uitvoer, biedt ondersteuning voor meer dan 29 talen en verbetert instructieopvolging en gestructureerde output (vooral JSON).",
  "Qwen/Qwen2.5-72B-Instruct-Turbo.description": "Qwen2.5 is een nieuwe LLM-familie geoptimaliseerd voor instructiegerichte taken.",
  "Qwen/Qwen2.5-72B-Instruct.description": "Qwen2.5-72B-Instruct maakt deel uit van de nieuwste LLM-serie van Alibaba Cloud. Dit 72B-model biedt aanzienlijke verbeteringen in codering en wiskunde, ondersteunt meer dan 29 talen en verbetert instructieopvolging, begrip van gestructureerde data en gestructureerde output (vooral JSON).",
  "Qwen/Qwen2.5-7B-Instruct-Turbo.description": "Qwen2.5 is een nieuwe LLM-familie geoptimaliseerd voor instructiegerichte taken.",
  "Qwen/Qwen2.5-7B-Instruct.description": "Qwen2.5-7B-Instruct maakt deel uit van de nieuwste LLM-serie van Alibaba Cloud. Dit 7B-model biedt aanzienlijke verbeteringen in codering en wiskunde, ondersteunt meer dan 29 talen en verbetert instructieopvolging, begrip van gestructureerde data en gestructureerde output (vooral JSON).",
  "Qwen/Qwen2.5-Coder-32B-Instruct.description": "Qwen2.5 Coder 32B Instruct is het nieuwste codegerichte LLM van Alibaba Cloud. Gebouwd op Qwen2.5 en getraind op 5,5T tokens, verbetert het aanzienlijk de codegeneratie, redenering en foutcorrectie, terwijl het sterke prestaties behoudt in wiskunde en algemene taken. Het biedt een solide basis voor code-agents.",
  "Qwen/Qwen2.5-Coder-7B-Instruct.description": "Qwen2.5-Coder-7B-Instruct is het nieuwste codegerichte LLM van Alibaba Cloud. Gebouwd op Qwen2.5 en getraind op 5,5T tokens, verbetert het aanzienlijk de codegeneratie, redenering en foutcorrectie, terwijl het sterke prestaties behoudt in wiskunde en algemene taken. Het biedt een solide basis voor code-agents.",
  "Qwen/Qwen2.5-VL-32B-Instruct.description": "Qwen2.5-VL-32B-Instruct is een multimodaal model van het Qwen-team. Het herkent veelvoorkomende objecten en analyseert tekst, grafieken, iconen, afbeeldingen en lay-outs. Als visuele agent kan het redeneren en dynamisch tools aansturen, inclusief computer- en telefoonbediening. Het lokaliseert objecten nauwkeurig en genereert gestructureerde output voor facturen en tabellen. Vergeleken met Qwen2-VL verbetert RL wiskunde en probleemoplossing, met antwoorden die beter aansluiten bij menselijke voorkeuren.",
  "Qwen/Qwen2.5-VL-72B-Instruct.description": "Qwen2.5-VL is het vision-language model in de Qwen2.5-serie met grote verbeteringen: sterkere visuele interpretatie van objecten, tekst, grafieken en lay-outs; redeneren als visuele agent met dynamisch gebruik van tools; begrip van video's van meer dan 1 uur en het vastleggen van belangrijke gebeurtenissen; nauwkeurige objectlokalisatie via vakken of punten; en gestructureerde output voor gescande gegevens zoals facturen en tabellen.",
  "Qwen/Qwen3-14B.description": "Qwen3 is een next-gen Tongyi Qwen-model met grote verbeteringen in redenering, algemene vaardigheden, agentcapaciteiten en meertalige prestaties, en ondersteunt het schakelen tussen denkmodi.",
  "Qwen/Qwen3-235B-A22B-Instruct-2507.description": "Qwen3-235B-A22B-Instruct-2507 is een vlaggenschip MoE-model uit de Qwen3-serie met 235B totale en 22B actieve parameters. Het is een bijgewerkte niet-denkende versie gericht op het verbeteren van instructieopvolging, logische redenering, tekstbegrip, wiskunde, wetenschap, codering en toolgebruik. Het breidt ook meertalige kennis uit en sluit beter aan bij gebruikersvoorkeuren voor open, subjectieve taken.",
  "Qwen/Qwen3-235B-A22B-Thinking-2507.description": "Qwen3-235B-A22B-Thinking-2507 is een Qwen3-model gericht op complexe redenering. Het gebruikt een MoE-architectuur met 235B totaal en ~22B actief per token voor meer efficiëntie. Als toegewijd denkmodel toont het grote verbeteringen in logica, wiskunde, wetenschap, codering en academische benchmarks, met topresultaten onder open denkmodellen. Het verbetert ook instructieopvolging, toolgebruik en tekstgeneratie, en ondersteunt standaard 256K context voor diepgaande redenering en lange documenten.",
  "Qwen/Qwen3-235B-A22B.description": "Qwen3 is een next-gen Tongyi Qwen-model met grote verbeteringen in redenering, algemene vaardigheden, agentcapaciteiten en meertalige prestaties, en ondersteunt het schakelen tussen denkmodi.",
  "Qwen/Qwen3-30B-A3B-Instruct-2507.description": "Qwen3-30B-A3B-Instruct-2507 is de bijgewerkte niet-denkende versie van Qwen3-30B-A3B. Het is een MoE-model met 30,5B totaal en 3,3B actieve parameters. Het verbetert aanzienlijk de instructieopvolging, logische redenering, tekstbegrip, wiskunde, wetenschap, codering en toolgebruik, breidt meertalige kennis uit en sluit beter aan bij gebruikersvoorkeuren voor subjectieve open taken. Het ondersteunt 256K context. Dit model is uitsluitend niet-denkend en genereert geen `<think></think>` tags.",
  "Qwen/Qwen3-30B-A3B-Thinking-2507.description": "Qwen3-30B-A3B-Thinking-2507 is het nieuwste denkmodel in de Qwen3-serie. Het is een MoE-model met 30,5B totaal en 3,3B actieve parameters, gericht op complexe taken. Het toont aanzienlijke verbeteringen in logica, wiskunde, wetenschap, codering en academische benchmarks, en verbetert instructieopvolging, toolgebruik, tekstgeneratie en voorkeurafstemming. Het ondersteunt standaard 256K context en kan worden uitgebreid tot 1M tokens. Deze versie is ontworpen voor denkmodus met gedetailleerde stapsgewijze redenering en sterke agentcapaciteiten.",
  "Qwen/Qwen3-30B-A3B.description": "Qwen3 is een next-gen Tongyi Qwen-model met grote verbeteringen in redenering, algemene vaardigheden, agentcapaciteiten en meertalige prestaties, en ondersteunt het schakelen tussen denkmodi.",
  "Qwen/Qwen3-32B.description": "Qwen3 is een next-gen Tongyi Qwen-model met grote verbeteringen in redenering, algemene vaardigheden, agentcapaciteiten en meertalige prestaties, en ondersteunt het schakelen tussen denkmodi.",
  "Qwen/Qwen3-8B.description": "Qwen3 is een next-gen Tongyi Qwen-model met grote verbeteringen in redenering, algemene vaardigheden, agentcapaciteiten en meertalige prestaties, en ondersteunt het schakelen tussen denkmodi.",
  "Qwen/Qwen3-Coder-30B-A3B-Instruct.description": "Qwen3-Coder-30B-A3B-Instruct is een Qwen3-codeermodel van het Qwen-team. Het is geoptimaliseerd voor hoge prestaties en efficiëntie, met verbeterde codecapaciteiten. Het presteert sterk op agentgebaseerde codering, geautomatiseerde browseracties en toolgebruik onder open modellen. Het ondersteunt standaard 256K context en kan worden uitgebreid tot 1M tokens voor begrip op codebase-niveau. Het ondersteunt agentgebaseerde codering op platforms zoals Qwen Code en CLINE met een speciaal functie-aanroepformaat.",
  "Qwen/Qwen3-Coder-480B-A35B-Instruct.description": "Qwen3-Coder-480B-A35B-Instruct is het meest geavanceerde codeermodel van Alibaba tot nu toe. Het is een MoE-model met 480B totaal en 35B actieve parameters, dat efficiëntie en prestaties in balans brengt. Het ondersteunt standaard 256K context en kan worden uitgebreid tot 1M tokens via YaRN, waardoor het geschikt is voor grote codebases. Ontworpen voor agentgebaseerde coderingsworkflows, kan het tools en omgevingen aansturen om complexe programmeertaken op te lossen. Het behaalt topresultaten op benchmarks voor codering en agenten, vergelijkbaar met toonaangevende modellen zoals Claude Sonnet 4.",
  "Qwen/Qwen3-Next-80B-A3B-Instruct.description": "Qwen3-Next-80B-A3B-Instruct is een geavanceerd basismodel dat gebruikmaakt van de Qwen3-Next-architectuur voor extreem efficiënte training en inferentie. Het combineert hybride aandacht (Gated DeltaNet + Gated Attention), sterk gespreide MoE en optimalisaties voor trainingsstabiliteit. Met 80 miljard totale parameters, maar slechts ~3 miljard actief tijdens inferentie, verlaagt het de rekencapaciteit en levert het meer dan 10x doorvoersnelheid ten opzichte van Qwen3-32B bij contexten >32K. Deze instructie-afgestemde versie is gericht op algemene taken (zonder Thinking-modus). Het presteert vergelijkbaar met Qwen3-235B op sommige benchmarks en toont sterke voordelen bij taken met ultralange context.",
  "Qwen/Qwen3-Next-80B-A3B-Thinking.description": "Qwen3-Next-80B-A3B-Thinking is een geavanceerd basismodel voor complexe redeneervaardigheden. Het maakt gebruik van de Qwen3-Next-architectuur met hybride aandacht (Gated DeltaNet + Gated Attention) en sterk gespreide MoE voor uiterst efficiënte training en inferentie. Met 80 miljard totale parameters, maar slechts ~3 miljard actief tijdens inferentie, verlaagt het de rekencapaciteit en levert het meer dan 10x doorvoersnelheid ten opzichte van Qwen3-32B bij contexten >32K. Deze Thinking-versie is gericht op meerstaps taken zoals bewijsvoering, codegeneratie, logische analyse en planning, en genereert gestructureerde redeneerstappen. Het overtreft Qwen3-32B-Thinking en verslaat Gemini-2.5-Flash-Thinking op meerdere benchmarks.",
  "Qwen/Qwen3-Omni-30B-A3B-Captioner.description": "Qwen3-Omni-30B-A3B-Captioner is een VLM uit de Qwen3-serie, ontworpen voor hoogwaardige, gedetailleerde en nauwkeurige beeldbeschrijvingen. Het gebruikt een MoE-architectuur met 30 miljard parameters om beelden diepgaand te begrijpen en vloeiende beschrijvingen te genereren. Het blinkt uit in detailherkenning, scènebegrip, objectherkenning en relationeel redeneren.",
  "Qwen/Qwen3-Omni-30B-A3B-Instruct.description": "Qwen3-Omni-30B-A3B-Instruct is een MoE-model uit de Qwen3-serie met 30 miljard totale en 3 miljard actieve parameters, dat sterke prestaties levert tegen lagere inferentiekosten. Het is getraind op hoogwaardige, meertalige data uit meerdere bronnen en ondersteunt volledige modale invoer (tekst, beeld, audio, video) en crossmodaal begrip en generatie.",
  "Qwen/Qwen3-Omni-30B-A3B-Thinking.description": "Qwen3-Omni-30B-A3B-Thinking is het centrale \"denkende\" component van Qwen3-Omni. Het verwerkt multimodale invoer (tekst, audio, beeld, video) en voert complexe redeneerstappen uit, waarbij het invoer verenigt in een gedeelde representatie voor diepgaand crossmodaal begrip. Het is een MoE-model met 30 miljard totale en 3 miljard actieve parameters, en biedt een balans tussen sterke redeneervaardigheden en rekenefficiëntie.",
  "Qwen/Qwen3-VL-235B-A22B-Instruct.description": "Qwen3-VL-235B-A22B-Instruct is een groot instructie-afgestemd Qwen3-VL-model gebaseerd op MoE, dat uitstekende multimodale interpretatie en generatie levert. Het ondersteunt standaard een context van 256K en is geschikt voor productieomgevingen met hoge gelijktijdigheid in multimodale toepassingen.",
  "Qwen/Qwen3-VL-235B-A22B-Thinking.description": "Qwen3-VL-235B-A22B-Thinking is de vlaggenschipversie van Qwen3-VL voor denken, geoptimaliseerd voor complexe multimodale redenatie, lange contexten en agentinteractie in zakelijke toepassingen.",
  "Qwen/Qwen3-VL-30B-A3B-Instruct.description": "Qwen3-VL-30B-A3B-Instruct is het instructie-afgestemde Qwen3-VL-model met sterke visuele-taalinterpretatie en generatie. Het ondersteunt standaard een context van 256K voor multimodale chat en beeldgestuurde generatie.",
  "Qwen/Qwen3-VL-30B-A3B-Thinking.description": "Qwen3-VL-30B-A3B-Thinking is de redeneerversterkte versie van Qwen3-VL, geoptimaliseerd voor multimodale redenatie, beeld-naar-code en complexe visuele interpretatie. Het ondersteunt een context van 256K met verbeterde redeneervaardigheden via keten-van-gedachten.",
  "Qwen/Qwen3-VL-32B-Instruct.description": "Qwen3-VL-32B-Instruct is een visuele-taalmodel van het Qwen-team met toonaangevende SOTA-resultaten op meerdere VL-benchmarks. Het ondersteunt beelden met megapixelresolutie en biedt sterke visuele interpretatie, meertalige OCR, fijnmazige visuele verankering en visuele dialoog. Het verwerkt complexe multimodale taken en ondersteunt toolgebruik en prefixaanvulling.",
  "Qwen/Qwen3-VL-32B-Thinking.description": "Qwen3-VL-32B-Thinking is geoptimaliseerd voor complexe visuele redenatie. Het bevat een ingebouwde Thinking-modus die tussenstappen in het redeneerproces genereert vóór het antwoord, wat meerstapslogica, planning en complexe redenatie versterkt. Het ondersteunt megapixelbeelden, sterke visuele interpretatie, meertalige OCR, fijnmazige verankering, visuele dialoog, toolgebruik en prefixaanvulling.",
  "Qwen/Qwen3-VL-8B-Instruct.description": "Qwen3-VL-8B-Instruct is een Qwen3 visuele-taalmodel gebaseerd op Qwen3-8B-Instruct en getraind op grote hoeveelheden beeld-tekstdata. Het blinkt uit in algemene visuele interpretatie, visiegerichte dialoog en meertalige tekstherkenning in beelden. Geschikt voor visuele QA, beeldbeschrijving, multimodale instructieopvolging en toolgebruik.",
  "Qwen/Qwen3-VL-8B-Thinking.description": "Qwen3-VL-8B-Thinking is de visuele Thinking-versie van Qwen3, geoptimaliseerd voor complexe meerstapsredenering. Het genereert een redeneerketen vóór het antwoord om de nauwkeurigheid te verbeteren, ideaal voor diepgaande visuele QA en gedetailleerde beeldanalyse.",
  "Qwen2-72B-Instruct.description": "Qwen2 is de nieuwste generatie in de Qwen-serie en ondersteunt een contextvenster van 128K. Vergeleken met de beste open modellen van dit moment, overtreft Qwen2-72B toonaangevende modellen aanzienlijk op het gebied van natuurlijke taalverwerking, kennis, code, wiskunde en meertalige capaciteiten.",
  "Qwen2-7B-Instruct.description": "Qwen2 is de nieuwste generatie in de Qwen-serie en overtreft de beste open modellen van vergelijkbare of zelfs grotere omvang. Qwen2 7B toont aanzienlijke voordelen op meerdere benchmarks, vooral in code en Chinees taalbegrip.",
  "Qwen2-VL-72B.description": "Qwen2-VL-72B is een krachtig visuele-taalmodel dat multimodale beeld-tekstverwerking ondersteunt, beeldinhoud nauwkeurig herkent en relevante beschrijvingen of antwoorden genereert.",
  "Qwen2.5-14B-Instruct.description": "Qwen2.5-14B-Instruct is een LLM met 14 miljard parameters en sterke prestaties, geoptimaliseerd voor Chinese en meertalige scenario's. Het ondersteunt intelligente vraag-antwoordinteractie en contentgeneratie.",
  "Qwen2.5-32B-Instruct.description": "Qwen2.5-32B-Instruct is een LLM met 32 miljard parameters en gebalanceerde prestaties, geoptimaliseerd voor Chinese en meertalige scenario's. Het ondersteunt intelligente vraag-antwoordinteractie en contentgeneratie.",
  "Qwen2.5-72B-Instruct.description": "LLM voor Chinees en Engels, afgestemd op taal, codering, wiskunde en redenatie.",
  "Qwen2.5-7B-Instruct.description": "Qwen2.5-7B-Instruct is een LLM met 7 miljard parameters die functieaanroepen en naadloze integratie met externe systemen ondersteunt, wat de flexibiliteit en uitbreidbaarheid aanzienlijk verbetert. Het is geoptimaliseerd voor Chinese en meertalige scenario's en ondersteunt intelligente vraag-antwoordinteractie en contentgeneratie.",
  "Qwen2.5-Coder-14B-Instruct.description": "Qwen2.5-Coder-14B-Instruct is een grootschalig voorgetraind model voor code-instructies met sterke codebegrip- en generatiecapaciteiten. Het verwerkt efficiënt een breed scala aan programmeertaken en is ideaal voor slim coderen, geautomatiseerde scriptgeneratie en programmeer-Q&A.",
  "Qwen2.5-Coder-32B-Instruct.description": "Geavanceerd LLM voor codegeneratie, redenatie en bugfixing in de belangrijkste programmeertalen.",
  "Qwen3-235B-A22B-Instruct-2507-FP8.description": "Qwen3 235B A22B Instruct 2507 is geoptimaliseerd voor geavanceerde redenatie en instructieopvolging, en gebruikt MoE om redenatie op schaal efficiënt te houden.",
  "Qwen3-235B.description": "Qwen3-235B-A22B is een MoE-model dat een hybride redeneermodus introduceert, waarmee gebruikers naadloos kunnen schakelen tussen denken en niet-denken. Het ondersteunt begrip en redenatie in 119 talen en dialecten en beschikt over sterke toolgebruikmogelijkheden. Het concurreert met toonaangevende modellen zoals DeepSeek R1, OpenAI o1, o3-mini, Grok 3 en Google Gemini 2.5 Pro op benchmarks voor algemene vaardigheden, code en wiskunde, meertalige capaciteiten en kennisredenering.",
  "Qwen3-32B.description": "Qwen3-32B is een dense model dat een hybride redeneermodus introduceert, waarmee gebruikers kunnen schakelen tussen denken en niet-denken. Dankzij architectuurverbeteringen, meer data en betere training presteert het op hetzelfde niveau als Qwen2.5-72B.",
  "SenseChat-128K.description": "Basis V4 met 128K context, sterk in het begrijpen en genereren van lange teksten.",
  "SenseChat-32K.description": "Basis V4 met 32K context, flexibel inzetbaar voor diverse scenario’s.",
  "SenseChat-5-1202.description": "Nieuwste versie gebaseerd op V5.5, met aanzienlijke verbeteringen in Chinese/Engelse basisvaardigheden, gesprekken, bètakennis, geesteswetenschappen, schrijven, wiskunde/logica en lengtebeheersing.",
  "SenseChat-5-Cantonese.description": "Ontworpen voor de dialooggewoonten, straattaal en lokale kennis van Hongkong; overtreft GPT-4 in Kantonees begrip en is vergelijkbaar met GPT-4 Turbo in kennis, redenering, wiskunde en programmeren.",
  "SenseChat-5-beta.description": "Presteert op sommige vlakken beter dan SenseChat-5-1202.",
  "SenseChat-5.description": "Nieuwste V5.5 met 128K context; grote vooruitgang in wiskundige redenering, Engelse gesprekken, instructieopvolging en begrip van lange teksten, vergelijkbaar met GPT-4o.",
  "SenseChat-Character-Pro.description": "Geavanceerd karaktergesprekmodel met 32K context, verbeterde capaciteiten en ondersteuning voor Chinees/Engels.",
  "SenseChat-Character.description": "Standaard karaktergesprekmodel met 8K context en hoge reactiesnelheid.",
  "SenseChat-Turbo-1202.description": "Nieuwste lichtgewicht model dat meer dan 90% van de volledige modelcapaciteit bereikt met aanzienlijk lagere inferentiekosten.",
  "SenseChat-Turbo.description": "Geschikt voor snelle vraag-en-antwoordscenario’s en modelafstemming.",
  "SenseChat-Vision.description": "Nieuwste V5.5 met invoer van meerdere afbeeldingen en brede kernverbeteringen in attributenherkenning, ruimtelijke relaties, actie-/gebeurtenisdetectie, scènebegrip, emotieherkenning, alledaagse redenering en tekstbegrip/-generatie.",
  "SenseChat.description": "Basis V4 met 4K context en sterke algemene capaciteiten.",
  "SenseNova-V6-5-Pro.description": "Met uitgebreide updates in multimodale, taal- en redeneergegevens en geoptimaliseerde trainingsstrategieën verbetert dit model aanzienlijk in multimodale redenering en algemene instructieopvolging. Ondersteunt tot 128K context en blinkt uit in OCR en culturele toerisme-IP-herkenning.",
  "SenseNova-V6-5-Turbo.description": "Met uitgebreide updates in multimodale, taal- en redeneergegevens en geoptimaliseerde trainingsstrategieën verbetert dit model aanzienlijk in multimodale redenering en algemene instructieopvolging. Ondersteunt tot 128K context en blinkt uit in OCR en culturele toerisme-IP-herkenning.",
  "SenseNova-V6-Pro.description": "Integreert beeld, tekst en video op natuurlijke wijze en doorbreekt traditionele multimodale silo’s; behaalt topposities op OpenCompass en SuperCLUE.",
  "SenseNova-V6-Reasoner.description": "Combineert visuele en taalkundige diepe redenering, ondersteunt langzaam denken en volledige gedachteketens.",
  "SenseNova-V6-Turbo.description": "Integreert beeld, tekst en video op natuurlijke wijze en doorbreekt traditionele multimodale silo’s. Leidt in kerncapaciteiten voor multimodale en taaltaken en scoort hoog in meerdere evaluaties.",
  "Skylark2-lite-8k.description": "Tweede generatie Skylark-model. Skylark2-lite biedt snelle reacties voor realtime, kostenbewuste scenario’s met lagere nauwkeurigheidseisen, met een contextvenster van 8K.",
  "Skylark2-pro-32k.description": "Tweede generatie Skylark-model. Skylark2-pro biedt hogere nauwkeurigheid voor complexe tekstgeneratie zoals professionele copywriting, roman schrijven en hoogwaardige vertaling, met een contextvenster van 32K.",
  "Skylark2-pro-4k.description": "Tweede generatie Skylark-model. Skylark2-pro biedt hogere nauwkeurigheid voor complexe tekstgeneratie zoals professionele copywriting, roman schrijven en hoogwaardige vertaling, met een contextvenster van 4K.",
  "Skylark2-pro-character-4k.description": "Tweede generatie Skylark-model. Skylark2-pro-character blinkt uit in rollenspel en gesprekken, met prompts die passen bij verschillende persona-stijlen en natuurlijke dialogen voor chatbots, virtuele assistenten en klantenservice, met snelle reacties.",
  "Skylark2-pro-turbo-8k.description": "Tweede generatie Skylark-model. Skylark2-pro-turbo-8k biedt snellere inferentie tegen lagere kosten met een contextvenster van 8K.",
  "THUDM/GLM-4-32B-0414.description": "GLM-4-32B-0414 is een next-gen open GLM-model met 32B parameters, vergelijkbaar in prestaties met OpenAI GPT en DeepSeek V3/R1-series.",
  "THUDM/GLM-4-9B-0414.description": "GLM-4-9B-0414 is een 9B GLM-model dat technieken van GLM-4-32B overneemt en lichtere implementatie biedt. Presteert goed in codegeneratie, webdesign, SVG-generatie en op zoek gebaseerde tekstproductie.",
  "THUDM/GLM-4.1V-9B-Thinking.description": "GLM-4.1V-9B-Thinking is een open-source VLM van Zhipu AI en Tsinghua KEG Lab, ontworpen voor complexe multimodale cognitie. Gebaseerd op GLM-4-9B-0414, voegt het gedachteketenredenering en RL toe om crossmodale redenering en stabiliteit aanzienlijk te verbeteren.",
  "THUDM/GLM-Z1-32B-0414.description": "GLM-Z1-32B-0414 is een diepdenkend redeneermodel gebaseerd op GLM-4-32B-0414 met cold-startgegevens en uitgebreide RL, verder getraind op wiskunde, code en logica. Verbetert wiskundige vaardigheden en complexe probleemoplossing aanzienlijk ten opzichte van het basismodel.",
  "THUDM/GLM-Z1-9B-0414.description": "GLM-Z1-9B-0414 is een klein GLM-model met 9B parameters dat open-source sterktes behoudt en indrukwekkende capaciteiten levert. Presteert sterk op wiskundige redenering en algemene taken, en is toonaangevend in zijn klasse onder open modellen.",
  "THUDM/GLM-Z1-Rumination-32B-0414.description": "GLM-Z1-Rumination-32B-0414 is een diep redeneermodel met reflectievermogen (getoetst aan OpenAI Deep Research). In tegenstelling tot typische diepdenkende modellen neemt het meer tijd voor overweging om open en complexe problemen op te lossen.",
  "THUDM/glm-4-9b-chat.description": "GLM-4-9B-Chat is het open-source GLM-4-model van Zhipu AI. Presteert sterk op semantiek, wiskunde, redenering, code en kennis. Naast meerstapsgesprekken ondersteunt het web browsing, code-uitvoering, aangepaste toolaanroepen en redenering over lange teksten. Ondersteunt 26 talen (waaronder Chinees, Engels, Japans, Koreaans, Duits). Presteert goed op AlignBench-v2, MT-Bench, MMLU en C-Eval, en ondersteunt tot 128K context voor academisch en zakelijk gebruik.",
  "Tongyi-Zhiwen/QwenLong-L1-32B.description": "QwenLong-L1-32B is het eerste redeneermodel met lange context (LRM) getraind met RL, geoptimaliseerd voor redenering over lange teksten. De progressieve contextuitbreiding via RL maakt stabiele overdracht van korte naar lange context mogelijk. Overtreft OpenAI-o3-mini en Qwen3-235B-A22B op zeven benchmarks voor document-QA met lange context, en is vergelijkbaar met Claude-3.7-Sonnet-Thinking. Vooral sterk in wiskunde, logica en multi-hop redenering.",
  "Yi-34B-Chat.description": "Yi-1.5-34B behoudt de sterke algemene taalvaardigheden van de serie en verbetert wiskundige logica en programmeren aanzienlijk door incrementele training op 500B hoogwaardige tokens.",
  "abab5.5-chat.description": "Ontworpen voor productiviteitsscenario’s met complexe taakverwerking en efficiënte tekstgeneratie voor professioneel gebruik.",
  "abab5.5s-chat.description": "Ontworpen voor Chinese persona-gesprekken, levert hoogwaardige Chinese dialogen voor diverse toepassingen.",
  "abab6.5g-chat.description": "Ontworpen voor meertalige persona-gesprekken, ondersteunt hoogwaardige dialooggeneratie in het Engels en andere talen.",
  "abab6.5s-chat.description": "Geschikt voor een breed scala aan NLP-taken, waaronder tekstgeneratie en dialoogsysteemontwikkeling.",
  "abab6.5t-chat.description": "Geoptimaliseerd voor Chinese persona-gesprekken, biedt vloeiende dialogen die passen bij Chinese uitdrukkingsgewoonten.",
  "accounts/fireworks/models/deepseek-r1.description": "DeepSeek-R1 is een geavanceerd LLM geoptimaliseerd met reinforcement learning en cold-startgegevens, met uitstekende prestaties in redenering, wiskunde en programmeren.",
  "accounts/fireworks/models/deepseek-v3.description": "Een krachtig Mixture-of-Experts (MoE) taalmodel van DeepSeek met 671B totale parameters en 37B actieve parameters per token.",
  "accounts/fireworks/models/llama-v3-70b-instruct.description": "Meta heeft de Meta Llama 3 LLM-serie ontwikkeld en uitgebracht, inclusief voorgetrainde en instructie-afgestemde tekstgeneratiemodellen van 8B en 70B. De Llama 3 instructie-afgestemde modellen zijn geoptimaliseerd voor conversatiegebruik en overtreffen veel bestaande open chatmodellen op gangbare industriële benchmarks.",
  "accounts/fireworks/models/llama-v3-8b-instruct-hf.description": "De Meta Llama 3 instructie-afgestemde modellen zijn geoptimaliseerd voor conversatiegebruik en overtreffen veel bestaande open chatmodellen op gangbare industriële benchmarks. Llama 3 8B Instruct (HF-versie) is de originele FP16-versie van Llama 3 8B Instruct, met resultaten die overeenkomen met de officiële Hugging Face-implementatie.",
  "accounts/fireworks/models/llama-v3-8b-instruct.description": "Meta heeft de Meta Llama 3 LLM-serie ontwikkeld en uitgebracht, een verzameling voorgetrainde en instructie-afgestemde tekstgeneratiemodellen van 8B en 70B. De Llama 3 instructie-afgestemde modellen zijn geoptimaliseerd voor conversatiegebruik en overtreffen veel bestaande open chatmodellen op gangbare industriële benchmarks.",
  "accounts/fireworks/models/llama-v3p1-405b-instruct.description": "Meta Llama 3.1 is een meertalig LLM-familie met voorgetrainde en instructie-afgestemde generatiemodellen van 8B, 70B en 405B. De instructie-afgestemde tekstmodellen zijn geoptimaliseerd voor meertalige dialogen en overtreffen veel bestaande open en gesloten chatmodellen op gangbare industriële benchmarks. 405B is het krachtigste model in de Llama 3.1-familie, met FP8-inferentie die nauw aansluit bij de referentie-implementatie.",
  "accounts/fireworks/models/llama-v3p1-70b-instruct.description": "Meta Llama 3.1 is een meertalig LLM-familie met voorgetrainde en instructie-afgestemde generatiemodellen van 8B, 70B en 405B. De instructie-afgestemde tekstmodellen zijn geoptimaliseerd voor meertalige dialogen en overtreffen veel bestaande open en gesloten chatmodellen op gangbare industriële benchmarks.",
  "accounts/fireworks/models/llama-v3p1-8b-instruct.description": "Meta Llama 3.1 is een meertalig LLM-familie met voorgetrainde en instructie-afgestemde generatiemodellen van 8B, 70B en 405B. De instructie-afgestemde tekstmodellen zijn geoptimaliseerd voor meertalige dialogen en overtreffen veel bestaande open en gesloten chatmodellen op gangbare industriële benchmarks.",
  "accounts/fireworks/models/llama-v3p2-11b-vision-instruct.description": "Een op instructies afgestemd visueel redeneermodel van Meta met 11 miljard parameters, geoptimaliseerd voor visuele herkenning, beeldredenering, ondertiteling en beeldgerelateerde vraag-en-antwoordtaken. Het begrijpt visuele gegevens zoals grafieken en diagrammen en slaat een brug tussen beeld en taal door tekstuele beschrijvingen van beeldinhoud te genereren.",
  "accounts/fireworks/models/llama-v3p2-3b-instruct.description": "Llama 3.2 3B Instruct is een lichtgewicht meertalig model van Meta, ontworpen voor efficiënte uitvoering met aanzienlijke voordelen in snelheid en kosten ten opzichte van grotere modellen. Typische toepassingen zijn het herschrijven van zoekopdrachten/prompts en hulp bij schrijven.",
  "accounts/fireworks/models/llama-v3p2-90b-vision-instruct.description": "Een op instructies afgestemd visueel redeneermodel van Meta met 90 miljard parameters, geoptimaliseerd voor visuele herkenning, beeldredenering, ondertiteling en beeldgerelateerde vraag-en-antwoordtaken. Het begrijpt visuele gegevens zoals grafieken en diagrammen en slaat een brug tussen beeld en taal door tekstuele beschrijvingen van beeldinhoud te genereren. Opmerking: dit model wordt momenteel experimenteel aangeboden als serverless model. Voor productiegebruik geldt dat Fireworks de implementatie mogelijk op korte termijn beëindigt.",
  "accounts/fireworks/models/llama-v3p3-70b-instruct.description": "Llama 3.3 70B Instruct is de decemberupdate van Llama 3.1 70B. Het verbetert het gebruik van tools, meertalige tekstondersteuning, wiskunde en programmeren ten opzichte van de release van juli 2024. Het behaalt toonaangevende prestaties op het gebied van redeneren, wiskunde en het volgen van instructies, en biedt prestaties vergelijkbaar met 3.1 405B met aanzienlijke voordelen in snelheid en kosten.",
  "accounts/fireworks/models/mistral-small-24b-instruct-2501.description": "Een model met 24 miljard parameters dat prestaties levert op topniveau, vergelijkbaar met grotere modellen.",
  "accounts/fireworks/models/mixtral-8x22b-instruct.description": "Mixtral MoE 8x22B Instruct v0.1 is de op instructies afgestemde versie van Mixtral MoE 8x22B v0.1, met ondersteuning voor de chat completion API.",
  "accounts/fireworks/models/mixtral-8x7b-instruct.description": "Mixtral MoE 8x7B Instruct is de op instructies afgestemde versie van Mixtral MoE 8x7B, met ondersteuning voor de chat completion API.",
  "accounts/fireworks/models/mythomax-l2-13b.description": "Een verbeterde variant van MythoMix, mogelijk een verfijndere vorm, die MythoLogic-L2 en Huginn samenvoegt met een experimentele tensor-merge techniek. Door zijn unieke karakter is het uitermate geschikt voor verhalen vertellen en rollenspel.",
  "accounts/fireworks/models/phi-3-vision-128k-instruct.description": "Phi-3-Vision-128K-Instruct is een lichtgewicht, geavanceerd open multimodaal model, getraind op synthetische data en zorgvuldig geselecteerde openbare webdatasets. Het richt zich op hoogwaardige, redeneerintensieve tekst- en visuele gegevens. Het behoort tot de Phi-3-familie en ondersteunt een contextlengte van 128K tokens. Het model is grondig verbeterd via gesuperviseerde fine-tuning en directe voorkeuroptimalisatie, wat zorgt voor nauwkeurige instructieopvolging en sterke veiligheidsmaatregelen.",
  "accounts/fireworks/models/qwen-qwq-32b-preview.description": "Het Qwen QwQ-model richt zich op het verbeteren van AI-redenering en toont aan dat open modellen kunnen concurreren met gesloten topmodellen op het gebied van redenering. QwQ-32B-Preview is een experimentele release die gelijkwaardig presteert aan o1 en beter scoort dan GPT-4o en Claude 3.5 Sonnet op redenering en analyse in GPQA, AIME, MATH-500 en LiveCodeBench. Opmerking: dit model wordt momenteel experimenteel aangeboden als serverless model. Voor productiegebruik geldt dat Fireworks de implementatie mogelijk op korte termijn beëindigt.",
  "accounts/fireworks/models/qwen2-vl-72b-instruct.description": "Het 72B Qwen-VL-model is de nieuwste iteratie van Alibaba, het resultaat van bijna een jaar innovatie.",
  "accounts/fireworks/models/qwen2p5-72b-instruct.description": "Qwen2.5 is een LLM-serie met alleen decoders, ontwikkeld door het Qwen-team en Alibaba Cloud. De serie biedt modellen van 0.5B, 1.5B, 3B, 7B, 14B, 32B en 72B, met zowel basis- als instructievarianten.",
  "accounts/fireworks/models/qwen2p5-coder-32b-instruct.description": "Qwen2.5-Coder is het nieuwste Qwen LLM-model gericht op programmeren (voorheen CodeQwen). Opmerking: dit model wordt momenteel experimenteel aangeboden als serverless model. Voor productiegebruik geldt dat Fireworks de implementatie mogelijk op korte termijn beëindigt.",
  "accounts/yi-01-ai/models/yi-large.description": "Yi-Large is een topklasse LLM die net onder GPT-4, Gemini 1.5 Pro en Claude 3 Opus staat op de LMSYS-ranglijst. Het blinkt uit in meertalige ondersteuning, met name in Spaans, Chinees, Japans, Duits en Frans. Yi-Large is ook ontwikkelaarsvriendelijk en gebruikt hetzelfde API-schema als OpenAI voor eenvoudige integratie.",
  "ai21-jamba-1.5-large.description": "Een meertalig model met 398 miljard parameters (waarvan 94 miljard actief), een contextvenster van 256K, ondersteuning voor functieaanroepen, gestructureerde output en onderbouwde generatie.",
  "ai21-jamba-1.5-mini.description": "Een meertalig model met 52 miljard parameters (waarvan 12 miljard actief), een contextvenster van 256K, ondersteuning voor functieaanroepen, gestructureerde output en onderbouwde generatie.",
  "ai21-labs/AI21-Jamba-1.5-Large.description": "Een meertalig model met 398 miljard parameters (waarvan 94 miljard actief), een contextvenster van 256K, ondersteuning voor functieaanroepen, gestructureerde output en onderbouwde generatie.",
  "ai21-labs/AI21-Jamba-1.5-Mini.description": "Een meertalig model met 52 miljard parameters (waarvan 12 miljard actief), een contextvenster van 256K, ondersteuning voor functieaanroepen, gestructureerde output en onderbouwde generatie.",
  "alibaba/qwen-3-14b.description": "Qwen3 is de nieuwste generatie in de Qwen-serie en biedt een uitgebreide reeks dichte en MoE-modellen. Gebaseerd op uitgebreide training levert het doorbraken op het gebied van redenering, instructieopvolging, agentcapaciteiten en meertalige ondersteuning.",
  "alibaba/qwen-3-235b.description": "Qwen3 is de nieuwste generatie in de Qwen-serie en biedt een uitgebreide reeks dichte en MoE-modellen. Gebaseerd op uitgebreide training levert het doorbraken op het gebied van redenering, instructieopvolging, agentcapaciteiten en meertalige ondersteuning.",
  "alibaba/qwen-3-30b.description": "Qwen3 is de nieuwste generatie in de Qwen-serie en biedt een uitgebreide reeks dichte en MoE-modellen. Gebaseerd op uitgebreide training levert het doorbraken op het gebied van redenering, instructieopvolging, agentcapaciteiten en meertalige ondersteuning.",
  "alibaba/qwen-3-32b.description": "Qwen3 is de nieuwste generatie in de Qwen-serie en biedt een uitgebreide reeks dichte en MoE-modellen. Gebaseerd op uitgebreide training levert het doorbraken op het gebied van redenering, instructieopvolging, agentcapaciteiten en meertalige ondersteuning.",
  "alibaba/qwen3-coder.description": "Qwen3-Coder-480B-A35B-Instruct is Qwen’s meest geavanceerde programmeermodel, met sterke prestaties op het gebied van agentisch programmeren, browsergebruik en andere kernprogrammeertaken, vergelijkbaar met Claude Sonnet-niveau.",
  "amazon/nova-lite.description": "Een zeer voordelig multimodaal model met extreem snelle verwerking van beeld-, video- en tekstinvoer.",
  "amazon/nova-micro.description": "Een tekstgericht model met ultralage latentie tegen zeer lage kosten.",
  "amazon/nova-pro.description": "Een krachtig multimodaal model met de beste balans tussen nauwkeurigheid, snelheid en kosten voor een breed scala aan taken.",
  "amazon/titan-embed-text-v2.description": "Amazon Titan Text Embeddings V2 is een lichtgewicht, efficiënt meertalig embeddingmodel dat ondersteuning biedt voor 1024, 512 en 256 dimensies.",
  "anthropic.claude-3-5-sonnet-20240620-v1:0.description": "Claude 3.5 Sonnet stelt een nieuwe industriestandaard en overtreft concurrenten en Claude 3 Opus in brede evaluaties, terwijl het snelheid en kosten op middelhoog niveau behoudt.",
  "anthropic.claude-3-5-sonnet-20241022-v2:0.description": "Claude 3.5 Sonnet stelt een nieuwe industriestandaard en overtreft concurrenten en Claude 3 Opus in brede evaluaties, terwijl het snelheid en kosten op middelhoog niveau behoudt.",
  "anthropic.claude-3-haiku-20240307-v1:0.description": "Claude 3 Haiku is het snelste en meest compacte model van Anthropic, dat vrijwel directe reacties levert op eenvoudige vragen. Het biedt een naadloze, mensachtige AI-ervaring en ondersteunt beeldinvoer met een contextvenster van 200K tokens.",
  "anthropic.claude-3-opus-20240229-v1:0.description": "Claude 3 Opus is het krachtigste AI-model van Anthropic met geavanceerde prestaties bij zeer complexe taken. Het verwerkt open vragen en nieuwe scenario’s met uitzonderlijke vloeiendheid en mensachtig begrip, en ondersteunt beeldinvoer met een contextvenster van 200K tokens.",
  "anthropic.claude-3-sonnet-20240229-v1:0.description": "Claude 3 Sonnet biedt een balans tussen intelligentie en snelheid voor zakelijke toepassingen, met sterke prestaties tegen lagere kosten. Het is ontworpen als een betrouwbare krachtpatser voor grootschalige AI-implementaties en ondersteunt beeldinvoer met een contextvenster van 200K tokens.",
  "anthropic.claude-instant-v1.description": "Een snel, voordelig en toch capabel model voor dagelijks chatten, tekstanalyse, samenvattingen en documentvragen.",
  "anthropic.claude-v2.description": "Een zeer capabel model voor uiteenlopende taken, van complexe dialogen en creatieve generatie tot gedetailleerde instructieopvolging.",
  "anthropic.claude-v2:1.description": "Een bijgewerkte versie van Claude 2 met een verdubbeld contextvenster en verbeterde betrouwbaarheid, lagere hallucinatiegraad en nauwkeurigheid op basis van bewijs voor lange documenten en RAG.",
  "anthropic/claude-3-haiku.description": "Claude 3 Haiku is het snelste model van Anthropic, ontworpen voor zakelijke toepassingen met langere prompts. Het kan snel grote documenten analyseren zoals kwartaalrapporten, contracten of juridische dossiers, tegen de helft van de kosten van vergelijkbare modellen.",
  "anthropic/claude-3-opus.description": "Claude 3 Opus is het meest intelligente model van Anthropic met toonaangevende prestaties bij zeer complexe taken. Het verwerkt open vragen en nieuwe scenario’s met uitzonderlijke vloeiendheid en mensachtig begrip.",
  "anthropic/claude-3.5-haiku.description": "Claude 3.5 Haiku biedt verbeterde snelheid, nauwkeurigheid bij programmeren en interactie met tools, geschikt voor scenario’s met hoge eisen aan snelheid en hulpmiddelengebruik.",
  "anthropic/claude-3.5-sonnet.description": "Claude 3.5 Sonnet is het snelle, efficiënte model binnen de Sonnet-familie, met betere prestaties op het gebied van programmeren en redeneren. Sommige versies worden geleidelijk vervangen door Sonnet 3.7 en latere modellen.",
  "anthropic/claude-3.7-sonnet.description": "Claude 3.7 Sonnet is een geüpgraded Sonnet-model met sterkere redeneervermogen en programmeercapaciteiten, geschikt voor complexe taken op ondernemingsniveau.",
  "anthropic/claude-haiku-4.5.description": "Claude Haiku 4.5 is het krachtige, snelle model van Anthropic, met zeer lage latentie en tegelijkertijd hoge nauwkeurigheid.",
  "anthropic/claude-opus-4.1.description": "Opus 4.1 is het high-end model van Anthropic, geoptimaliseerd voor programmeren, complexe redenering en langdurige taken.",
  "anthropic/claude-opus-4.5.description": "Claude Opus 4.5 is het vlaggenschipmodel van Anthropic, dat topintelligentie combineert met schaalbare prestaties voor complexe taken die hoogwaardige redenering vereisen.",
  "anthropic/claude-opus-4.description": "Opus 4 is het vlaggenschipmodel van Anthropic, ontworpen voor complexe taken en zakelijke toepassingen.",
  "anthropic/claude-sonnet-4.5.description": "Claude Sonnet 4.5 is het nieuwste hybride redeneermodel van Anthropic, geoptimaliseerd voor complexe redenering en programmeren.",
  "anthropic/claude-sonnet-4.description": "Claude Sonnet 4 is het hybride redeneermodel van Anthropic met een combinatie van denk- en niet-denkvermogen.",
  "ascend-tribe/pangu-pro-moe.description": "Pangu-Pro-MoE 72B-A16B is een gespreid LLM met 72 miljard totale en 16 miljard actieve parameters, gebaseerd op een gegroepeerde MoE (MoGE) architectuur. Het groepeert experts tijdens selectie en zorgt ervoor dat tokens een gelijk aantal experts per groep activeren, wat de belasting balanceert en de implementatie-efficiëntie op Ascend verbetert.",
  "aya.description": "Aya 23 is Cohere’s meertalige model dat 23 talen ondersteunt voor uiteenlopende toepassingen.",
  "aya:35b.description": "Aya 23 is Cohere’s meertalige model dat 23 talen ondersteunt voor uiteenlopende toepassingen.",
  "azure-DeepSeek-R1-0528.description": "Ingezet door Microsoft; DeepSeek R1 is geüpgraded naar DeepSeek-R1-0528. De update verhoogt de rekenkracht en optimaliseert de algoritmes na training, wat de diepgang van redeneren en inferentie aanzienlijk verbetert. Het presteert sterk op benchmarks voor wiskunde, programmeren en algemene logica, en benadert toonaangevende modellen zoals O3 en Gemini 2.5 Pro.",
  "baichuan-m2-32b.description": "Baichuan M2 32B is een MoE-model van Baichuan Intelligence met sterke redeneercapaciteiten.",
  "baichuan/baichuan2-13b-chat.description": "Baichuan-13B is een open-source, commercieel bruikbaar LLM met 13 miljard parameters van Baichuan, dat toonaangevende resultaten behaalt voor zijn grootte op gezaghebbende Chinese en Engelse benchmarks.",
  "baidu/ERNIE-4.5-300B-A47B.description": "ERNIE-4.5-300B-A47B is een MoE LLM van Baidu met 300 miljard totale parameters en 47 miljard actieve per token, wat sterke prestaties combineert met reken-efficiëntie. Als kernmodel van ERNIE 4.5 blinkt het uit in begrip, generatie, redeneren en programmeren. Het gebruikt een multimodale heterogene MoE pretraining met gecombineerde tekst-beeld training om de algehele capaciteit te versterken, vooral in instructievolging en wereldkennis.",
  "baidu/ernie-5.0-thinking-preview.description": "ERNIE 5.0 Thinking Preview is Baidu’s volgende generatie native multimodale ERNIE-model, sterk in multimodaal begrip, instructievolging, creatie, feitelijke Q&A en toolgebruik.",
  "black-forest-labs/flux-1.1-pro.description": "FLUX 1.1 Pro is een snellere, verbeterde versie van FLUX Pro met uitstekende beeldkwaliteit en nauwkeurige promptvolging.",
  "black-forest-labs/flux-dev.description": "FLUX Dev is de ontwikkelversie van FLUX voor niet-commercieel gebruik.",
  "black-forest-labs/flux-pro.description": "FLUX Pro is het professionele FLUX-model voor hoogwaardige beeldgeneratie.",
  "black-forest-labs/flux-schnell.description": "FLUX Schnell is een snel beeldgeneratiemodel geoptimaliseerd voor snelheid.",
  "c4ai-aya-expanse-32b.description": "Aya Expanse is een krachtig meertalig model met 32 miljard parameters dat gebruikmaakt van instructietuning, data-arbitrage, voorkeurstraining en modelfusie om te concurreren met eentalige modellen. Het ondersteunt 23 talen.",
  "c4ai-aya-expanse-8b.description": "Aya Expanse is een krachtig meertalig model met 8 miljard parameters dat gebruikmaakt van instructietuning, data-arbitrage, voorkeurstraining en modelfusie om te concurreren met eentalige modellen. Het ondersteunt 23 talen.",
  "c4ai-aya-vision-32b.description": "Aya Vision is een geavanceerd multimodaal model dat sterk presteert op belangrijke benchmarks voor taal, tekst en beeld. Het ondersteunt 23 talen. Deze 32B-versie richt zich op topprestaties in meertalige contexten.",
  "c4ai-aya-vision-8b.description": "Aya Vision is een geavanceerd multimodaal model dat sterk presteert op belangrijke benchmarks voor taal, tekst en beeld. Deze 8B-versie is geoptimaliseerd voor lage latentie en sterke prestaties.",
  "charglm-3.description": "CharGLM-3 is ontworpen voor rollenspel en emotionele interactie, met ondersteuning voor ultralange gesprekken en gepersonaliseerde dialogen.",
  "charglm-4.description": "CharGLM-4 is ontworpen voor rollenspel en emotionele interactie, met ondersteuning voor ultralange gesprekken en gepersonaliseerde dialogen.",
  "chatgpt-4o-latest.description": "ChatGPT-4o is een dynamisch model dat in realtime wordt bijgewerkt en sterke begrip- en generatiecapaciteiten combineert voor grootschalige toepassingen zoals klantenservice, onderwijs en technische ondersteuning.",
  "claude-2.0.description": "Claude 2 biedt belangrijke verbeteringen voor bedrijven, waaronder een toonaangevende context van 200.000 tokens, minder hallucinaties, systeemprompts en een nieuwe testfunctie: toolgebruik.",
  "claude-2.1.description": "Claude 2 biedt belangrijke verbeteringen voor bedrijven, waaronder een toonaangevende context van 200.000 tokens, minder hallucinaties, systeemprompts en een nieuwe testfunctie: toolgebruik.",
  "claude-3-5-haiku-20241022.description": "Claude 3.5 Haiku is het snelste model van de volgende generatie van Anthropic, met verbeterde vaardigheden en betere prestaties dan het vorige vlaggenschip Claude 3 Opus op veel benchmarks.",
  "claude-3-5-haiku-latest.description": "Claude 3.5 Haiku levert snelle reacties voor lichte taken.",
  "claude-3-7-sonnet-20250219.description": "Claude Sonnet 3.7 is het meest intelligente model van Anthropic en het eerste hybride redeneermodel op de markt. Het ondersteunt directe reacties of uitgebreide denkprocessen met fijnmazige controle.",
  "claude-3-7-sonnet-latest.description": "Claude 3.7 Sonnet is het nieuwste en meest capabele model van Anthropic voor zeer complexe taken, met uitmuntende prestaties, intelligentie, vloeiendheid en begrip.",
  "claude-3-haiku-20240307.description": "Claude 3 Haiku is het snelste en meest compacte model van Anthropic, ontworpen voor vrijwel directe reacties met snelle en nauwkeurige prestaties.",
  "claude-3-opus-20240229.description": "Claude 3 Opus is het krachtigste model van Anthropic voor zeer complexe taken, met uitmuntende prestaties, intelligentie, vloeiendheid en begrip.",
  "claude-3-sonnet-20240229.description": "Claude 3 Sonnet biedt een balans tussen intelligentie en snelheid voor zakelijke toepassingen, met hoge bruikbaarheid tegen lagere kosten en betrouwbare grootschalige inzet.",
  "claude-haiku-4-5-20251001.description": "Claude Haiku 4.5 is het snelste en meest intelligente Haiku-model van Anthropic, met bliksemsnelle reacties en diepgaand denkvermogen.",
  "claude-opus-4-1-20250805-thinking.description": "Claude Opus 4.1 Thinking is een geavanceerde variant die zijn redeneerproces kan onthullen.",
  "claude-opus-4-1-20250805.description": "Claude Opus 4.1 is het nieuwste en meest capabele model van Anthropic voor zeer complexe taken, uitblinkend in prestaties, intelligentie, vloeiendheid en begrip.",
  "claude-opus-4-20250514.description": "Claude Opus 4 is het krachtigste model van Anthropic voor zeer complexe taken, met uitmuntende prestaties, intelligentie, vloeiendheid en begrip.",
  "claude-opus-4-5-20251101.description": "Claude Opus 4.5 is het vlaggenschipmodel van Anthropic, dat uitzonderlijke intelligentie combineert met schaalbare prestaties. Ideaal voor complexe taken die hoogwaardige antwoorden en redenering vereisen.",
  "claude-opus-4-6.description": "Claude Opus 4.6 is het meest intelligente model van Anthropic voor het bouwen van agents en programmeren.",
  "claude-sonnet-4-20250514-thinking.description": "Claude Sonnet 4 Thinking kan vrijwel directe antwoorden geven of uitgebreide stapsgewijze redenering tonen met zichtbaar proces.",
  "claude-sonnet-4-20250514.description": "Claude Sonnet 4 is het meest intelligente model van Anthropic tot nu toe, met directe reacties of uitgebreide stapsgewijze denkprocessen en fijnmazige controle voor API-gebruikers.",
  "claude-sonnet-4-5-20250929.description": "Claude Sonnet 4.5 is het meest intelligente model van Anthropic tot nu toe.",
  "codegeex-4.description": "CodeGeeX-4 is een krachtige AI-codeassistent die meertalige Q&A en codeaanvulling ondersteunt om de productiviteit van ontwikkelaars te verhogen.",
  "codegeex4-all-9b.description": "CodeGeeX4-ALL-9B is een meertalig codegeneratiemodel dat codeaanvulling en -generatie, code-interpreter, webzoekopdrachten, functieaanroepen en Q&A op repo-niveau ondersteunt. Het dekt een breed scala aan softwareontwikkelingsscenario’s en is een topmodel onder de 10 miljard parameters.",
  "codegemma.description": "CodeGemma is een lichtgewicht model voor diverse programmeertaken, dat snelle iteratie en integratie mogelijk maakt.",
  "codegemma:2b.description": "CodeGemma is een lichtgewicht model voor diverse programmeertaken, dat snelle iteratie en integratie mogelijk maakt.",
  "codellama.description": "Code Llama is een LLM gericht op codegeneratie en -bespreking, met brede taalondersteuning voor ontwikkelworkflows.",
  "codellama/CodeLlama-34b-Instruct-hf.description": "Code Llama is een LLM gericht op codegeneratie en -bespreking, met brede taalondersteuning voor ontwikkelworkflows.",
  "codellama:13b.description": "Code Llama is een LLM gericht op codegeneratie en -bespreking, met brede taalondersteuning voor ontwikkelworkflows.",
  "codellama:34b.description": "Code Llama is een LLM gericht op codegeneratie en -bespreking, met brede taalondersteuning voor ontwikkelworkflows.",
  "codellama:70b.description": "Code Llama is een LLM gericht op codegeneratie en -bespreking, met brede taalondersteuning voor ontwikkelworkflows.",
  "codeqwen.description": "CodeQwen1.5 is een groot taalmodel getraind op uitgebreide codegegevens, ontworpen voor complexe programmeertaken.",
  "codestral-latest.description": "Codestral is ons meest geavanceerde codemodel; versie 2 (jan 2025) is gericht op taken met lage latentie en hoge frequentie zoals FIM, codecorrectie en testgeneratie.",
  "codestral.description": "Codestral is het eerste codemodel van Mistral AI, met sterke ondersteuning voor codegeneratie.",
  "codex-mini-latest.description": "codex-mini-latest is een verfijnd o4-mini-model voor de Codex CLI. Voor direct API-gebruik raden we aan te beginnen met gpt-4.1.",
  "cogito-2.1:671b.description": "Cogito v2.1 671B is een Amerikaans open-source LLM dat vrij is voor commercieel gebruik. Het biedt prestaties die vergelijkbaar zijn met topmodellen, hogere efficiëntie in tokenredenering, een contextlengte van 128k en sterke algemene capaciteiten.",
  "cogview-4.description": "CogView-4 is het eerste open-source tekst-naar-beeldmodel van Zhipu dat Chinese karakters kan genereren. Het verbetert semantisch begrip, beeldkwaliteit en weergave van Chinese/Engelse tekst, ondersteunt tweetalige prompts van willekeurige lengte en kan beelden genereren in elke resolutie binnen opgegeven bereiken.",
  "cohere-command-r-plus.description": "Command R+ is een geavanceerd model geoptimaliseerd voor RAG, ontworpen voor bedrijfsomgevingen.",
  "cohere-command-r.description": "Command R is een schaalbaar generatief model ontworpen voor RAG en toolgebruik, geschikt voor productieklare AI.",
  "cohere/Cohere-command-r-plus.description": "Command R+ is een geavanceerd model geoptimaliseerd voor RAG, ontworpen voor bedrijfsomgevingen.",
  "cohere/Cohere-command-r.description": "Command R is een schaalbaar generatief model ontworpen voor RAG en toolgebruik, geschikt voor productieklare AI.",
  "cohere/command-a.description": "Command A is het krachtigste model van Cohere tot nu toe, uitblinkend in toolgebruik, agents, RAG en meertalige toepassingen. Het ondersteunt een contextlengte van 256K, draait op slechts twee GPU's en levert 150% hogere doorvoer dan Command R+ 08-2024.",
  "cohere/command-r-plus.description": "Command R+ is het nieuwste LLM van Cohere, geoptimaliseerd voor chat en lange contexten, met als doel uitzonderlijke prestaties zodat bedrijven voorbij prototypes kunnen gaan naar productie.",
  "cohere/command-r.description": "Command R is geoptimaliseerd voor chat- en lange-contexttaken, gepositioneerd als een 'schaalbaar' model dat hoge prestaties en nauwkeurigheid in balans brengt, zodat bedrijven voorbij prototypes kunnen gaan naar productie.",
  "cohere/embed-v4.0.description": "Een model dat tekst, afbeeldingen of gemengde inhoud classificeert of omzet in embeddings.",
  "comfyui/flux-dev.description": "FLUX.1 Dev is een hoogwaardig tekst-naar-beeldmodel (10–50 stappen), ideaal voor creatieve en artistieke output van topkwaliteit.",
  "comfyui/flux-kontext-dev.description": "FLUX.1 Kontext-dev is een afbeeldingsbewerkingsmodel dat tekstgestuurde bewerkingen ondersteunt, waaronder lokale aanpassingen en stijltransfers.",
  "comfyui/flux-krea-dev.description": "FLUX.1 Krea-dev is een tekst-naar-beeldmodel met verbeterde veiligheid, mede ontwikkeld met Krea, en bevat ingebouwde veiligheidsfilters.",
  "comfyui/flux-schnell.description": "FLUX.1 Schnell is een ultrasnel tekst-naar-beeldmodel dat hoogwaardige beelden genereert in 1-4 stappen, ideaal voor realtime gebruik en snelle prototyping.",
  "comfyui/stable-diffusion-15.description": "Stable Diffusion 1.5 is een klassiek 512x512 tekst-naar-beeldmodel, ideaal voor snelle prototyping en creatieve experimenten.",
  "comfyui/stable-diffusion-35-inclclip.description": "Stable Diffusion 3.5 met ingebouwde CLIP/T5-encoders vereist geen externe encoderbestanden en is geschikt voor modellen zoals sd3.5_medium_incl_clips met lager middelenverbruik.",
  "comfyui/stable-diffusion-35.description": "Stable Diffusion 3.5 is een tekst-naar-beeldmodel van de volgende generatie met Large- en Medium-varianten. Het vereist externe CLIP-encoderbestanden en levert uitstekende beeldkwaliteit en promptnauwkeurigheid.",
  "comfyui/stable-diffusion-custom-refiner.description": "Aangepast SDXL beeld-naar-beeldmodel. Gebruik custom_sd_lobe.safetensors als bestandsnaam voor het model; als je een VAE hebt, gebruik dan custom_sd_vae_lobe.safetensors. Plaats modelbestanden in de vereiste Comfy-mappen.",
  "comfyui/stable-diffusion-custom.description": "Aangepast SD tekst-naar-beeldmodel. Gebruik custom_sd_lobe.safetensors als bestandsnaam voor het model; als je een VAE hebt, gebruik dan custom_sd_vae_lobe.safetensors. Plaats modelbestanden in de vereiste Comfy-mappen.",
  "comfyui/stable-diffusion-refiner.description": "SDXL beeld-naar-beeldmodel voert hoogwaardige transformaties uit op invoerbeelden, met ondersteuning voor stijltransfers, restauratie en creatieve variaties.",
  "comfyui/stable-diffusion-xl.description": "SDXL is een tekst-naar-beeldmodel dat 1024x1024 hoge resolutie ondersteunt met verbeterde beeldkwaliteit en detail.",
  "command-a-03-2025.description": "Command A is ons meest geavanceerde model tot nu toe, uitblinkend in het gebruik van tools, agents, RAG en meertalige scenario's. Het beschikt over een contextvenster van 256K, draait op slechts twee GPU's en levert 150% hogere verwerkingssnelheid dan Command R+ 08-2024.",
  "command-light-nightly.description": "Om de tijd tussen grote releases te verkorten, bieden we nachtelijke Command-builds aan. Voor de command-light-serie heet dit command-light-nightly. Dit is de nieuwste, meest experimentele (en mogelijk instabiele) versie, die regelmatig zonder aankondiging wordt bijgewerkt. Daarom wordt het niet aanbevolen voor productieomgevingen.",
  "command-light.description": "Een kleinere, snellere variant van Command die bijna even krachtig is, maar sneller werkt.",
  "command-nightly.description": "Om de tijd tussen grote releases te verkorten, bieden we nachtelijke Command-builds aan. Voor de Command-serie heet dit command-nightly. Dit is de nieuwste, meest experimentele (en mogelijk instabiele) versie, die regelmatig zonder aankondiging wordt bijgewerkt. Daarom wordt het niet aanbevolen voor productieomgevingen.",
  "command-r-03-2024.description": "Command R is een chatmodel dat instructies volgt met hogere kwaliteit, grotere betrouwbaarheid en een langer contextvenster dan eerdere modellen. Het ondersteunt complexe workflows zoals codegeneratie, RAG, toolgebruik en agents.",
  "command-r-08-2024.description": "command-r-08-2024 is een bijgewerkte versie van het Command R-model, uitgebracht in augustus 2024.",
  "command-r-plus-04-2024.description": "command-r-plus is een alias van command-r-plus-04-2024, dus het gebruik van command-r-plus in de API verwijst naar dat model.",
  "command-r-plus-08-2024.description": "Command R+ is een chatmodel dat instructies volgt met hogere kwaliteit, grotere betrouwbaarheid en een langer contextvenster dan eerdere modellen. Het is ideaal voor complexe RAG-workflows en meerstapsgebruik van tools.",
  "command-r-plus.description": "Command R+ is een krachtig LLM ontworpen voor echte zakelijke toepassingen en complexe apps.",
  "command-r.description": "Command R is een LLM geoptimaliseerd voor chat en taken met lange context, ideaal voor dynamische interactie en kennisbeheer.",
  "command-r7b-12-2024.description": "command-r7b-12-2024 is een kleine, efficiënte update uitgebracht in december 2024. Het blinkt uit in RAG, toolgebruik en agenttaken die complexe, meerstapsredenering vereisen.",
  "command.description": "Een chatmodel dat instructies volgt en betere kwaliteit en betrouwbaarheid levert bij taalopdrachten, met een langer contextvenster dan onze generatieve basismodellen.",
  "computer-use-preview.description": "computer-use-preview is een gespecialiseerd model voor de \"computer use tool\", getraind om computergerelateerde taken te begrijpen en uit te voeren.",
  "dall-e-2.description": "Tweede generatie DALL·E-model met realistischere, nauwkeurigere beeldgeneratie en 4× de resolutie van de eerste generatie.",
  "dall-e-3.description": "Het nieuwste DALL·E-model, uitgebracht in november 2023, ondersteunt realistischere, nauwkeurigere beeldgeneratie met sterkere details.",
  "databricks/dbrx-instruct.description": "DBRX Instruct biedt zeer betrouwbare instructieafhandeling in verschillende sectoren.",
  "deepseek-ai/DeepSeek-OCR.description": "DeepSeek-OCR is een vision-language model van DeepSeek AI, gericht op OCR en \"contextuele optische compressie\". Het onderzoekt het comprimeren van context uit afbeeldingen, verwerkt documenten efficiënt en zet ze om in gestructureerde tekst (zoals Markdown). Het herkent nauwkeurig tekst in afbeeldingen en is geschikt voor documentdigitalisering, tekstuittrekking en gestructureerde verwerking.",
  "deepseek-ai/DeepSeek-R1-0528-Qwen3-8B.description": "DeepSeek-R1-0528-Qwen3-8B distilleert chain-of-thought van DeepSeek-R1-0528 naar Qwen3 8B Base. Het bereikt SOTA onder open modellen, verslaat Qwen3 8B met 10% op AIME 2024 en evenaart de prestaties van Qwen3-235B-thinking. Het blinkt uit in wiskundige redenering, programmeren en algemene logica-benchmarks. Het deelt de Qwen3-8B-architectuur maar gebruikt de tokenizer van DeepSeek-R1-0528.",
  "deepseek-ai/DeepSeek-R1-0528.description": "DeepSeek R1 benut extra rekenkracht en post-trainingsoptimalisaties om redenering te verdiepen. Het presteert sterk op benchmarks in wiskunde, programmeren en algemene logica, en benadert leiders als o3 en Gemini 2.5 Pro.",
  "deepseek-ai/DeepSeek-R1-Distill-Llama-70B.description": "DeepSeek-R1 gedistilleerde modellen gebruiken RL en cold-start data om redenering te verbeteren en nieuwe open-model multi-task benchmarks te zetten.",
  "deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B.description": "DeepSeek-R1 gedistilleerde modellen gebruiken RL en cold-start data om redenering te verbeteren en nieuwe open-model multi-task benchmarks te zetten.",
  "deepseek-ai/DeepSeek-R1-Distill-Qwen-14B.description": "DeepSeek-R1 gedistilleerde modellen gebruiken RL en cold-start data om redenering te verbeteren en nieuwe open-model multi-task benchmarks te zetten.",
  "deepseek-ai/DeepSeek-R1-Distill-Qwen-32B.description": "DeepSeek-R1-Distill-Qwen-32B is gedistilleerd van Qwen2.5-32B en fijngestemd op 800K zorgvuldig geselecteerde DeepSeek-R1-samples. Het blinkt uit in wiskunde, programmeren en redenering, en behaalt sterke resultaten op AIME 2024, MATH-500 (94,3% nauwkeurigheid) en GPQA Diamond.",
  "deepseek-ai/DeepSeek-R1-Distill-Qwen-7B.description": "DeepSeek-R1-Distill-Qwen-7B is gedistilleerd van Qwen2.5-Math-7B en fijngestemd op 800K zorgvuldig geselecteerde DeepSeek-R1-samples. Het presteert sterk, met 92,8% op MATH-500, 55,5% op AIME 2024 en een CodeForces-rating van 1189 voor een 7B-model.",
  "deepseek-ai/DeepSeek-R1.description": "DeepSeek-R1 verbetert redenering met RL en cold-start data, zet nieuwe open-model multi-task benchmarks en overtreft OpenAI-o1-mini.",
  "deepseek-ai/DeepSeek-V2.5.description": "DeepSeek-V2.5 is een upgrade van DeepSeek-V2-Chat en DeepSeek-Coder-V2-Instruct, en combineert algemene en programmeervaardigheden. Het verbetert schrijven en instructievolging voor betere voorkeurafstemming, en toont aanzienlijke vooruitgang op AlpacaEval 2.0, ArenaHard, AlignBench en MT-Bench.",
  "deepseek-ai/DeepSeek-V3.1-Terminus.description": "DeepSeek-V3.1-Terminus is een bijgewerkt V3.1-model gepositioneerd als een hybride agent-LLM. Het lost door gebruikers gemelde problemen op en verbetert stabiliteit, taalconsistentie en vermindert gemengde Chinees/Engels en abnormale tekens. Het integreert Denk- en Niet-denkmodi met chattemplates voor flexibele omschakeling. Het verbetert ook de prestaties van Code Agent en Search Agent voor betrouwbaarder gebruik van tools en meerstapstaken.",
  "deepseek-ai/DeepSeek-V3.1.description": "DeepSeek V3.1 gebruikt een hybride redeneersarchitectuur en ondersteunt zowel denk- als niet-denkmodi.",
  "deepseek-ai/DeepSeek-V3.2-Exp.description": "DeepSeek-V3.2-Exp is een experimentele V3.2-release die de brug slaat naar de volgende architectuur. Het voegt DeepSeek Sparse Attention (DSA) toe bovenop V3.1-Terminus om de efficiëntie van training en inferentie met lange context te verbeteren, met optimalisaties voor toolgebruik, begrip van lange documenten en meerstapsredenering. Ideaal voor het verkennen van hogere redeneerefficiëntie met grote contextbudgetten.",
  "deepseek-ai/DeepSeek-V3.description": "DeepSeek-V3 is een MoE-model met 671 miljard parameters dat gebruikmaakt van MLA en DeepSeekMoE met verliesvrije load balancing voor efficiënte training en inferentie. Voorgetraind op 14,8T hoogwaardige tokens met SFT en RL, overtreft het andere open modellen en benadert het toonaangevende gesloten modellen.",
  "deepseek-ai/deepseek-llm-67b-chat.description": "DeepSeek LLM Chat (67B) is een innovatief model dat diep taalbegrip en interactie biedt.",
  "deepseek-ai/deepseek-v3.1-terminus.description": "DeepSeek V3.1 is een next-gen redeneermodel met sterkere complexe redenering en chain-of-thought voor diepgaande analysetaken.",
  "deepseek-ai/deepseek-v3.1.description": "DeepSeek V3.1 is een next-gen redeneermodel met sterkere complexe redenering en chain-of-thought voor diepgaande analysetaken.",
  "deepseek-ai/deepseek-vl2.description": "DeepSeek-VL2 is een MoE vision-language model gebaseerd op DeepSeekMoE-27B met sparse activatie, dat sterke prestaties levert met slechts 4,5B actieve parameters. Het blinkt uit in visuele QA, OCR, document-/tabel-/grafiekbegrip en visuele verankering.",
  "deepseek-chat.description": "DeepSeek V3.2 biedt een balans tussen redeneervermogen en outputlengte voor dagelijkse vraag-en-antwoordtaken en agenttoepassingen. Publieke benchmarks bereiken GPT-5-niveau, en het is het eerste model dat denken integreert in het gebruik van tools, leidend in open-source agentbeoordelingen.",
  "deepseek-coder-33B-instruct.description": "DeepSeek Coder 33B is een codeertaalmodel getraind op 2 biljoen tokens (87% code, 13% Chinees/Engels tekst). Het introduceert een contextvenster van 16K en 'fill-in-the-middle'-taken, wat projectniveau codeaanvulling en fragmentinvoeging mogelijk maakt.",
  "deepseek-coder-v2.description": "DeepSeek Coder V2 is een open-source MoE-codeermodel dat sterk presteert bij programmeertaken, vergelijkbaar met GPT-4 Turbo.",
  "deepseek-coder-v2:236b.description": "DeepSeek Coder V2 is een open-source MoE-codeermodel dat sterk presteert bij programmeertaken, vergelijkbaar met GPT-4 Turbo.",
  "deepseek-ocr.description": "DeepSeek-OCR is een visie-taalmodel van DeepSeek AI dat zich richt op OCR en \"contextuele optische compressie\". Het onderzoekt het comprimeren van contextuele informatie uit afbeeldingen, verwerkt documenten efficiënt en zet ze om in gestructureerde tekstformaten zoals Markdown. Het herkent nauwkeurig tekst in afbeeldingen, ideaal voor documentdigitalisatie, tekstuittrekking en gestructureerde verwerking.",
  "deepseek-r1-0528.description": "685B volledig model uitgebracht op 2025-05-28. DeepSeek-R1 gebruikt grootschalige versterkingsleren in de post-trainingfase, wat het redeneervermogen sterk verbetert met minimale gelabelde data, en presteert uitstekend op wiskunde, programmeren en natuurlijke taalredenering.",
  "deepseek-r1-250528.description": "DeepSeek R1 250528 is het volledige DeepSeek-R1 redeneermodel voor complexe wiskundige en logische taken.",
  "deepseek-r1-70b-fast-online.description": "DeepSeek R1 70B snelle editie met realtime webzoekfunctie, levert snellere reacties met behoud van prestaties.",
  "deepseek-r1-70b-online.description": "DeepSeek R1 70B standaardeditie met realtime webzoekfunctie, geschikt voor actuele chat- en teksttaken.",
  "deepseek-r1-distill-llama-70b.description": "DeepSeek R1 Distill Llama 70B combineert R1-redenering met het Llama-ecosysteem.",
  "deepseek-r1-distill-llama-8b.description": "DeepSeek-R1-Distill-Llama-8B is gedistilleerd uit Llama-3.1-8B met behulp van DeepSeek R1-uitvoer.",
  "deepseek-r1-distill-llama.description": "deepseek-r1-distill-llama is gedistilleerd uit DeepSeek-R1 op Llama.",
  "deepseek-r1-distill-qianfan-70b.description": "DeepSeek R1 Distill Qianfan 70B is een R1-distillatie gebaseerd op Qianfan-70B met hoge waarde.",
  "deepseek-r1-distill-qianfan-8b.description": "DeepSeek R1 Distill Qianfan 8B is een R1-distillatie gebaseerd op Qianfan-8B voor kleine en middelgrote toepassingen.",
  "deepseek-r1-distill-qianfan-llama-70b.description": "DeepSeek R1 Distill Qianfan Llama 70B is een R1-distillatie gebaseerd op Llama-70B.",
  "deepseek-r1-distill-qwen-1.5b.description": "DeepSeek R1 Distill Qwen 1.5B is een ultralicht distillatiemodel voor zeer beperkte omgevingen.",
  "deepseek-r1-distill-qwen-14b.description": "DeepSeek R1 Distill Qwen 14B is een middelgroot distillatiemodel voor inzet in meerdere scenario's.",
  "deepseek-r1-distill-qwen-32b.description": "DeepSeek R1 Distill Qwen 32B is een R1-distillatie gebaseerd op Qwen-32B, met een balans tussen prestaties en kosten.",
  "deepseek-r1-distill-qwen-7b.description": "DeepSeek R1 Distill Qwen 7B is een lichtgewicht distillatiemodel voor edge- en privébedrijfstoepassingen.",
  "deepseek-r1-distill-qwen.description": "deepseek-r1-distill-qwen is gedistilleerd uit DeepSeek-R1 op Qwen.",
  "deepseek-r1-fast-online.description": "DeepSeek R1 snelle volledige versie met realtime webzoekfunctie, combineert 671B-capaciteit met snellere reacties.",
  "deepseek-r1-online.description": "DeepSeek R1 volledige versie met 671B parameters en realtime webzoekfunctie, biedt sterkere begrip- en generatiecapaciteiten.",
  "deepseek-r1.description": "DeepSeek-R1 gebruikt cold-start data vóór versterkingsleren en presteert vergelijkbaar met OpenAI-o1 op wiskunde, programmeren en redenering.",
  "deepseek-reasoner.description": "DeepSeek V3.2 Thinking is een diep redeneermodel dat eerst een denkproces genereert voordat het output levert, voor hogere nauwkeurigheid. Het behaalt topprestaties in competities en redeneert op het niveau van Gemini-3.0-Pro.",
  "deepseek-v2.description": "DeepSeek V2 is een efficiënt MoE-model voor kosteneffectieve verwerking.",
  "deepseek-v2:236b.description": "DeepSeek V2 236B is DeepSeek’s codegerichte model met sterke codegeneratie.",
  "deepseek-v3-0324.description": "DeepSeek-V3-0324 is een MoE-model met 671B parameters en uitmuntende prestaties in programmeren, technische vaardigheden, contextbegrip en verwerking van lange teksten.",
  "deepseek-v3.1-terminus.description": "DeepSeek-V3.1-Terminus is een terminal-geoptimaliseerd LLM van DeepSeek, afgestemd op terminalapparaten.",
  "deepseek-v3.1-think-250821.description": "DeepSeek V3.1 Think 250821 is het diepdenkende model dat overeenkomt met de Terminus-versie, gebouwd voor hoogwaardig redeneervermogen.",
  "deepseek-v3.1.description": "DeepSeek-V3.1 is een nieuw hybride redeneermodel van DeepSeek, dat zowel denk- als niet-denkmodi ondersteunt en een hogere denkefficiëntie biedt dan DeepSeek-R1-0528. Optimalisaties na training verbeteren het gebruik van agenttools en de prestaties bij agenttaken aanzienlijk. Het ondersteunt een contextvenster van 128k en tot 64k outputtokens.",
  "deepseek-v3.1:671b.description": "DeepSeek V3.1 is een next-gen redeneermodel met verbeterde complexe redenering en gedachtegang, geschikt voor taken die diepgaande analyse vereisen.",
  "deepseek-v3.2-exp.description": "deepseek-v3.2-exp introduceert sparse attention om de efficiëntie van training en inferentie op lange teksten te verbeteren, tegen een lagere prijs dan deepseek-v3.1.",
  "deepseek-v3.2-think.description": "DeepSeek V3.2 Think is een volledig diepdenkend model met sterker langketen-redeneervermogen.",
  "deepseek-v3.2.description": "DeepSeek-V3.2 is het eerste hybride redeneermodel van DeepSeek dat denken integreert in het gebruik van tools. Het maakt gebruik van een efficiënte architectuur om rekenkracht te besparen, grootschalige reinforcement learning om capaciteiten te verbeteren, en synthetische taakdata op grote schaal om generalisatie te versterken. Deze combinatie levert prestaties vergelijkbaar met GPT-5-High, met aanzienlijk kortere outputlengte, wat de rekentijd en wachttijd voor gebruikers sterk vermindert.",
  "deepseek-v3.description": "DeepSeek-V3 is een krachtig MoE-model met in totaal 671B parameters en 37B actief per token.",
  "deepseek-vl2-small.description": "DeepSeek VL2 Small is een lichtgewicht multimodaal model voor omgevingen met beperkte middelen en hoge gelijktijdigheid.",
  "deepseek-vl2.description": "DeepSeek VL2 is een multimodaal model voor beeld-tekstbegrip en fijnmazige visuele vraagbeantwoording.",
  "deepseek/deepseek-chat-v3-0324.description": "DeepSeek V3 is een MoE-model met 685B parameters en de nieuwste iteratie van DeepSeek’s vlaggenschip-chatserie.\n\nHet bouwt voort op [DeepSeek V3](/deepseek/deepseek-chat-v3) en presteert sterk over verschillende taken.",
  "deepseek/deepseek-chat-v3-0324:free.description": "DeepSeek V3 is een MoE-model met 685B parameters en de nieuwste iteratie van DeepSeek’s vlaggenschip-chatserie.\n\nHet bouwt voort op [DeepSeek V3](/deepseek/deepseek-chat-v3) en presteert sterk over verschillende taken.",
  "deepseek/deepseek-chat-v3.1.description": "DeepSeek-V3.1 is DeepSeek’s hybride redeneermodel met lange context, dat gemengde denk-/niet-denkmodi en toolintegratie ondersteunt.",
  "deepseek/deepseek-chat.description": "DeepSeek-V3 is DeepSeek’s krachtige hybride redeneermodel voor complexe taken en toolintegratie.",
  "deepseek/deepseek-math-v2.description": "DeepSeek Math V2 is een model dat baanbrekende vooruitgang heeft geboekt in wiskundige redeneervermogen. De kerninnovatie is het \"zelfverificatie\"-trainingsmechanisme, en het heeft op topniveau gepresteerd in meerdere prestigieuze wiskundewedstrijden.",
  "deepseek/deepseek-r1-0528.description": "DeepSeek R1 0528 is een bijgewerkte variant gericht op open beschikbaarheid en diepere redenering.",
  "deepseek/deepseek-r1-0528:free.description": "DeepSeek-R1 verbetert het redeneervermogen aanzienlijk met minimale gelabelde data en genereert een gedachtegang vóór het eindantwoord om de nauwkeurigheid te verhogen.",
  "deepseek/deepseek-r1-distill-llama-70b.description": "DeepSeek R1 Distill Llama 70B is een gedistilleerd LLM gebaseerd op Llama 3.3 70B, fijngestemd met DeepSeek R1-uitvoer om concurrerende prestaties te leveren met grote frontiermodellen.",
  "deepseek/deepseek-r1-distill-llama-8b.description": "DeepSeek R1 Distill Llama 8B is een gedistilleerd LLM gebaseerd op Llama-3.1-8B-Instruct, getraind met DeepSeek R1-uitvoer.",
  "deepseek/deepseek-r1-distill-qwen-14b.description": "DeepSeek R1 Distill Qwen 14B is een gedistilleerd LLM gebaseerd op Qwen 2.5 14B, getraind met behulp van DeepSeek R1-uitvoer. Het presteert beter dan OpenAI o1-mini op meerdere benchmarks en behaalt toonaangevende resultaten onder dichte modellen. Benchmark hoogtepunten:\nAIME 2024 pass@1: 69,7\nMATH-500 pass@1: 93,9\nCodeForces Rating: 1481\nFijn-afstemming op DeepSeek R1-uitvoer levert concurrerende prestaties ten opzichte van grotere frontiermodellen.",
  "deepseek/deepseek-r1-distill-qwen-32b.description": "DeepSeek R1 Distill Qwen 32B is een gedistilleerd LLM gebaseerd op Qwen 2.5 32B, getraind met behulp van DeepSeek R1-uitvoer. Het presteert beter dan OpenAI o1-mini op meerdere benchmarks en behaalt toonaangevende resultaten onder dichte modellen. Benchmark hoogtepunten:\nAIME 2024 pass@1: 72,6\nMATH-500 pass@1: 94,3\nCodeForces Rating: 1691\nFijn-afstemming op DeepSeek R1-uitvoer levert concurrerende prestaties ten opzichte van grotere frontiermodellen.",
  "deepseek/deepseek-r1.description": "DeepSeek R1 is geüpdatet naar DeepSeek-R1-0528. Dankzij meer rekenkracht en algoritmische optimalisaties na de training is het redeneervermogen en de diepgang aanzienlijk verbeterd. Het presteert sterk op benchmarks voor wiskunde, programmeren en algemene logica, en benadert toonaangevende modellen zoals o3 en Gemini 2.5 Pro.",
  "deepseek/deepseek-r1/community.description": "DeepSeek R1 is het nieuwste open-source model van het DeepSeek-team, met zeer sterke redeneercapaciteiten, vooral op het gebied van wiskunde, codering en logische taken, vergelijkbaar met OpenAI o1.",
  "deepseek/deepseek-r1:free.description": "DeepSeek-R1 verbetert het redeneervermogen aanzienlijk met minimale gelabelde data en genereert een redeneerketen vóór het uiteindelijke antwoord om de nauwkeurigheid te verhogen.",
  "deepseek/deepseek-reasoner.description": "DeepSeek-V3 Thinking (reasoner) is het experimentele redeneermodel van DeepSeek, geschikt voor taken met hoge complexiteit.",
  "deepseek/deepseek-v3.1-base.description": "DeepSeek V3.1 Base is een verbeterde versie van het DeepSeek V3-model.",
  "deepseek/deepseek-v3.description": "Een snel, algemeen inzetbaar LLM met verbeterd redeneervermogen.",
  "deepseek/deepseek-v3/community.description": "DeepSeek-V3 betekent een grote doorbraak in redeneersnelheid ten opzichte van eerdere modellen. Het staat bovenaan onder open-source modellen en kan zich meten met de meest geavanceerde gesloten modellen. DeepSeek-V3 maakt gebruik van Multi-Head Latent Attention (MLA) en de DeepSeekMoE-architectuur, beide volledig gevalideerd in DeepSeek-V2. Het introduceert ook een verliesloze hulpsstrategie voor load balancing en een multi-token predictie trainingsdoel voor betere prestaties.",
  "deepseek_r1.description": "DeepSeek-R1 is een redeneermodel aangedreven door reinforcement learning dat herhaling en leesbaarheid aanpakt. Voorafgaand aan RL wordt cold-start data gebruikt om het redeneervermogen verder te verbeteren. Het evenaart OpenAI-o1 op het gebied van wiskunde, codering en redeneertaken, met zorgvuldig ontworpen training voor betere algehele resultaten.",
  "deepseek_r1_distill_llama_70b.description": "DeepSeek-R1-Distill-Llama-70B is gedistilleerd van Llama-3.3-70B-Instruct. Als onderdeel van de DeepSeek-R1-serie is het fijn-afgestemd op door DeepSeek-R1 gegenereerde voorbeelden en presteert het sterk in wiskunde, codering en redeneren.",
  "deepseek_r1_distill_qwen_14b.description": "DeepSeek-R1-Distill-Qwen-14B is gedistilleerd van Qwen2.5-14B en fijn-afgestemd op 800K zorgvuldig geselecteerde voorbeelden gegenereerd door DeepSeek-R1, met sterk redeneervermogen.",
  "deepseek_r1_distill_qwen_32b.description": "DeepSeek-R1-Distill-Qwen-32B is gedistilleerd van Qwen2.5-32B en fijn-afgestemd op 800K zorgvuldig geselecteerde voorbeelden gegenereerd door DeepSeek-R1, en blinkt uit in wiskunde, codering en redeneren.",
  "devstral-2:123b.description": "Devstral 2 123B blinkt uit in het gebruik van tools om codebases te verkennen, meerdere bestanden te bewerken en software engineering agents te ondersteunen.",
  "doubao-1.5-lite-32k.description": "Doubao-1.5-lite is een nieuw lichtgewicht model met ultrasnelle reacties en levert topkwaliteit met lage latentie.",
  "doubao-1.5-pro-256k.description": "Doubao-1.5-pro-256k is een uitgebreide upgrade van Doubao-1.5-Pro, met een prestatieverbetering van 10%. Het ondersteunt een contextvenster van 256k en tot 12k outputtokens, wat zorgt voor hogere prestaties, een groter bereik en sterke waarde voor bredere toepassingen.",
  "doubao-1.5-pro-32k.description": "Doubao-1.5-pro is een vlaggenschipmodel van de nieuwe generatie met algehele verbeteringen, uitblinkend in kennis, codering en redeneervermogen.",
  "doubao-1.5-thinking-pro-m.description": "Doubao-1.5 is een nieuw diep redeneermodel (de m-versie ondersteunt native multimodale diepe redenering) dat uitblinkt in wiskunde, codering, wetenschappelijke redenering en algemene taken zoals creatief schrijven. Het behaalt of benadert topprestaties op benchmarks zoals AIME 2024, Codeforces en GPQA. Het ondersteunt een contextvenster van 128k en 16k output.",
  "doubao-1.5-thinking-pro.description": "Doubao-1.5 is een nieuw diep redeneermodel dat uitblinkt in wiskunde, codering, wetenschappelijke redenering en algemene taken zoals creatief schrijven. Het behaalt of benadert topprestaties op benchmarks zoals AIME 2024, Codeforces en GPQA. Het ondersteunt een contextvenster van 128k en 16k output.",
  "doubao-1.5-thinking-vision-pro.description": "Een nieuw visueel diep redeneermodel met sterkere multimodale interpretatie en redenering, met SOTA-resultaten op 37 van de 59 openbare benchmarks.",
  "doubao-1.5-ui-tars.description": "Doubao-1.5-UI-TARS is een native GUI-georiënteerd agentmodel dat naadloos met interfaces communiceert via mensachtige waarneming, redenering en actie.",
  "doubao-1.5-vision-lite.description": "Doubao-1.5-vision-lite is een geüpgraded multimodaal model dat afbeeldingen ondersteunt in elke resolutie en extreme beeldverhoudingen. Het verbetert visuele redenering, documentherkenning, detailbegrip en instructieopvolging. Het ondersteunt een contextvenster van 128k en tot 16k outputtokens.",
  "doubao-1.5-vision-pro-32k.description": "Doubao-1.5-vision-pro is een geüpgraded multimodaal model dat afbeeldingen ondersteunt in elke resolutie en extreme beeldverhoudingen. Het verbetert visuele redenering, documentherkenning, detailbegrip en instructieopvolging.",
  "doubao-1.5-vision-pro.description": "Doubao-1.5-vision-pro is een geüpgraded multimodaal model dat afbeeldingen ondersteunt in elke resolutie en extreme beeldverhoudingen. Het verbetert visuele redenering, documentherkenning, detailbegrip en instructieopvolging.",
  "doubao-lite-128k.description": "Ultrasnelle reacties met betere waarde, biedt flexibelere keuzes voor verschillende scenario's. Ondersteunt redenering en fine-tuning met een contextvenster van 128k.",
  "doubao-lite-32k.description": "Ultrasnelle reacties met betere waarde, biedt flexibelere keuzes voor verschillende scenario's. Ondersteunt redenering en fine-tuning met een contextvenster van 32k.",
  "doubao-lite-4k.description": "Ultrasnelle reacties met betere waarde, biedt flexibelere keuzes voor verschillende scenario's. Ondersteunt redenering en fine-tuning met een contextvenster van 4k.",
  "doubao-pro-256k.description": "Het best presterende vlaggenschipmodel voor complexe taken, met sterke resultaten in referentievragen, samenvattingen, creatie, tekstclassificatie en rollenspel. Ondersteunt redenering en fine-tuning met een contextvenster van 256k.",
  "doubao-pro-32k.description": "Het best presterende vlaggenschipmodel voor complexe taken, met sterke resultaten in referentievragen, samenvattingen, creatie, tekstclassificatie en rollenspel. Ondersteunt redenering en fine-tuning met een contextvenster van 32k.",
  "doubao-seed-1.6-flash.description": "Doubao-Seed-1.6-flash is een ultrasnel multimodaal diep redeneermodel met een TPOT van slechts 10ms. Het ondersteunt zowel tekst als visuele input, overtreft het vorige lite-model in tekstbegrip en evenaart concurrerende pro-modellen in visuele prestaties. Het ondersteunt een contextvenster van 256k en tot 16k outputtokens.",
  "doubao-seed-1.6-lite.description": "Doubao-Seed-1.6-lite is een nieuw multimodaal diep redeneermodel met instelbare redeneerinspanning (Minimaal, Laag, Gemiddeld, Hoog), biedt betere waarde en is een sterke keuze voor algemene taken, met een contextvenster tot 256k.",
  "doubao-seed-1.6-thinking.description": "Doubao-Seed-1.6 versterkt het redeneervermogen aanzienlijk, verbetert de kernvaardigheden in codering, wiskunde en logica ten opzichte van Doubao-1.5-thinking-pro, en voegt visueel begrip toe. Het ondersteunt een contextvenster van 256k en tot 16k outputtokens.",
  "doubao-seed-1.6-vision.description": "Doubao-Seed-1.6-vision is een visueel diep redeneermodel dat sterkere multimodale interpretatie en redenering biedt voor onderwijs, beeldbeoordeling, inspectie/beveiliging en AI-zoekvragen. Het ondersteunt een contextvenster van 256k en tot 64k outputtokens.",
  "doubao-seed-1.6.description": "Doubao-Seed-1.6 is een nieuw multimodaal diep redeneermodel met automatische, denkende en niet-denkende modi. In de niet-denkende modus presteert het aanzienlijk beter dan Doubao-1.5-pro/250115. Het ondersteunt een contextvenster van 256k en tot 16k outputtokens.",
  "doubao-seed-1.8.description": "Doubao-Seed-1.8 beschikt over sterkere multimodale begrip- en agentcapaciteiten, ondersteunt tekst-/beeld-/video-invoer en contextcaching, en levert uitstekende prestaties bij complexe taken.",
  "doubao-seed-code.description": "Doubao-Seed-Code is geoptimaliseerd voor agentmatige codering, ondersteunt multimodale input (tekst/afbeelding/video) en een contextvenster van 256k, is compatibel met de Anthropic API en geschikt voor codering, visueel begrip en agentworkflows.",
  "doubao-seededit-3-0-i2i-250628.description": "Het Doubao-beeldmodel van ByteDance Seed ondersteunt tekst- en afbeeldingsinvoer met zeer controleerbare, hoogwaardige beeldgeneratie. Het ondersteunt tekstgestuurde beeldbewerking, met uitvoerformaten tussen 512 en 1536 aan de lange zijde.",
  "doubao-seedream-3-0-t2i-250415.description": "Seedream 3.0 is een beeldgeneratiemodel van ByteDance Seed dat tekst- en afbeeldingsinvoer ondersteunt voor zeer controleerbare, hoogwaardige beeldgeneratie. Het genereert beelden op basis van tekstprompts.",
  "doubao-seedream-4-0-250828.description": "Seedream 4.0 is een beeldgeneratiemodel van ByteDance Seed dat tekst- en afbeeldingsinvoer ondersteunt voor zeer controleerbare, hoogwaardige beeldgeneratie. Het genereert beelden op basis van tekstprompts.",
  "doubao-vision-lite-32k.description": "Doubao-vision is een multimodaal model van Doubao met sterk beeldbegrip en redenering, plus nauwkeurige instructieopvolging. Het presteert goed bij beeld-tekstextractie en op beeld gebaseerde redeneertaken, waardoor complexere en bredere visuele vraag-en-antwoordscenario's mogelijk zijn.",
  "doubao-vision-pro-32k.description": "Doubao-vision is een multimodaal model van Doubao met sterk beeldbegrip en redenering, plus nauwkeurige instructieopvolging. Het presteert goed bij beeld-tekstextractie en op beeld gebaseerde redeneertaken, waardoor complexere en bredere visuele vraag-en-antwoordscenario's mogelijk zijn.",
  "emohaa.description": "Emohaa is een mentaal gezondheidsmodel met professionele begeleidingsvaardigheden om gebruikers te helpen emotionele problemen te begrijpen.",
  "ernie-4.5-0.3b.description": "ERNIE 4.5 0.3B is een lichtgewicht open-source model voor lokale en aangepaste implementatie.",
  "ernie-4.5-21b-a3b.description": "ERNIE 4.5 21B A3B is een open-source model met veel parameters en verbeterde begrips- en generatiecapaciteiten.",
  "ernie-4.5-300b-a47b.description": "ERNIE 4.5 300B A47B is het ultra-grote MoE-model van Baidu ERNIE met uitstekende redeneercapaciteiten.",
  "ernie-4.5-8k-preview.description": "ERNIE 4.5 8K Preview is een previewmodel met 8K context voor het evalueren van ERNIE 4.5.",
  "ernie-4.5-turbo-128k-preview.description": "ERNIE 4.5 Turbo 128K Preview met capaciteiten op productieniveau, geschikt voor integratie en canary-tests.",
  "ernie-4.5-turbo-128k.description": "ERNIE 4.5 Turbo 128K is een krachtig algemeen model met zoekverrijking en toolgebruik voor vraag-en-antwoord, codering en agenttoepassingen.",
  "ernie-4.5-turbo-32k.description": "ERNIE 4.5 Turbo 32K is een versie met middellange context voor vraag-en-antwoord, kennisopvraging en meerstapsdialogen.",
  "ernie-4.5-turbo-latest.description": "De nieuwste ERNIE 4.5 Turbo met geoptimaliseerde algehele prestaties, ideaal als primair productiemodel.",
  "ernie-4.5-turbo-vl-32k-preview.description": "ERNIE 4.5 Turbo VL 32K Preview is een multimodale preview met 32K context voor het evalueren van visuele capaciteiten op lange termijn.",
  "ernie-4.5-turbo-vl-32k.description": "ERNIE 4.5 Turbo VL 32K is een multimodale versie met middellange context voor gecombineerd begrip van lange documenten en afbeeldingen.",
  "ernie-4.5-turbo-vl-latest.description": "ERNIE 4.5 Turbo VL Latest is de nieuwste multimodale versie met verbeterd beeld-tekstbegrip en redeneervermogen.",
  "ernie-4.5-turbo-vl-preview.description": "ERNIE 4.5 Turbo VL Preview is een multimodaal previewmodel voor beeld-tekstbegrip en -generatie, geschikt voor visuele vraag-en-antwoord en inhoudsbegrip.",
  "ernie-4.5-turbo-vl.description": "ERNIE 4.5 Turbo VL is een volwassen multimodaal model voor productiegericht beeld-tekstbegrip en herkenning.",
  "ernie-4.5-vl-28b-a3b.description": "ERNIE 4.5 VL 28B A3B is een open-source multimodaal model voor beeld-tekstbegrip en redenatie.",
  "ernie-5.0-thinking-latest.description": "Wenxin 5.0 Thinking is een native full-modale vlaggenschipmodel met geïntegreerde tekst-, beeld-, audio- en videomodellering. Het biedt brede capaciteitsverbeteringen voor complexe vraag-en-antwoord, creatie en agenttoepassingen.",
  "ernie-5.0-thinking-preview.description": "Wenxin 5.0 Thinking Preview is een native full-modale vlaggenschipmodel met geïntegreerde tekst-, beeld-, audio- en videomodellering. Het biedt brede capaciteitsverbeteringen voor complexe vraag-en-antwoord, creatie en agenttoepassingen.",
  "ernie-char-8k.description": "ERNIE Character 8K is een persoonlijk dialoogmodel voor het opbouwen van IP-personages en langdurige gezelschapschat.",
  "ernie-char-fiction-8k-preview.description": "ERNIE Character Fiction 8K Preview is een previewmodel voor personage- en plotcreatie, bedoeld voor functietests en evaluatie.",
  "ernie-char-fiction-8k.description": "ERNIE Character Fiction 8K is een personagegericht model voor romans en plotontwikkeling, geschikt voor het genereren van lange verhalen.",
  "ernie-irag-edit.description": "ERNIE iRAG Edit is een afbeeldingsbewerkingsmodel dat wissen, herschilderen en variantgeneratie ondersteunt.",
  "ernie-lite-pro-128k.description": "ERNIE Lite Pro 128K is een lichtgewicht model met hoge prestaties voor scenario's met lage latentie en kosten.",
  "ernie-novel-8k.description": "ERNIE Novel 8K is ontworpen voor lange romans en IP-verhalen met meerdere personages.",
  "ernie-speed-pro-128k.description": "ERNIE Speed Pro 128K is een model met hoge gelijktijdigheid en hoge waarde voor grootschalige online diensten en zakelijke toepassingen.",
  "ernie-x1-turbo-32k.description": "ERNIE X1 Turbo 32K is een snel denkend model met 32K context voor complexe redenatie en meerstapsgesprekken.",
  "ernie-x1.1-preview.description": "ERNIE X1.1 Preview is een preview van een denkmodel voor evaluatie en testen.",
  "fal-ai/bytedance/seedream/v4.5.description": "Seedream 4.5, ontwikkeld door het Seed-team van ByteDance, ondersteunt bewerking en compositie van meerdere afbeeldingen. Het biedt verbeterde onderwerpconsistentie, nauwkeurige instructieopvolging, ruimtelijk logisch begrip, esthetische expressie, posterlay-out en logodesign met zeer nauwkeurige tekst-beeldweergave.",
  "fal-ai/bytedance/seedream/v4.description": "Seedream 4.0, ontwikkeld door ByteDance Seed, ondersteunt tekst- en beeldinvoer voor zeer controleerbare, hoogwaardige beeldgeneratie op basis van prompts.",
  "fal-ai/flux-kontext/dev.description": "FLUX.1-model gericht op beeldbewerking, met ondersteuning voor tekst- en afbeeldingsinvoer.",
  "fal-ai/flux-pro/kontext.description": "FLUX.1 Kontext [pro] accepteert tekst en referentieafbeeldingen als invoer, waardoor gerichte lokale bewerkingen en complexe wereldwijde scèneaanpassingen mogelijk zijn.",
  "fal-ai/flux/krea.description": "Flux Krea [dev] is een afbeeldingsgeneratiemodel met een esthetische voorkeur voor realistische, natuurlijke beelden.",
  "fal-ai/flux/schnell.description": "FLUX.1 [schnell] is een afbeeldingsgeneratiemodel met 12 miljard parameters, ontworpen voor snelle en hoogwaardige output.",
  "fal-ai/hunyuan-image/v3.description": "Een krachtig, native multimodaal afbeeldingsgeneratiemodel.",
  "fal-ai/imagen4/preview.description": "Hoogwaardig afbeeldingsgeneratiemodel van Google.",
  "fal-ai/nano-banana.description": "Nano Banana is het nieuwste, snelste en meest efficiënte native multimodale model van Google, waarmee beeldgeneratie en -bewerking via conversatie mogelijk is.",
  "fal-ai/qwen-image-edit.description": "Een professioneel afbeeldingsbewerkingsmodel van het Qwen-team, met ondersteuning voor semantische en uiterlijke bewerkingen, nauwkeurige Chinese/Engelse tekstbewerking, stijltransformatie, rotatie en meer.",
  "fal-ai/qwen-image.description": "Een krachtig beeldgeneratiemodel van het Qwen-team met sterke Chinese tekstrendering en diverse visuele stijlen.",
  "flux-1-schnell.description": "Een tekst-naar-beeldmodel met 12 miljard parameters van Black Forest Labs, dat gebruikmaakt van latente adversariële diffusiedistillatie om hoogwaardige beelden te genereren in 1–4 stappen. Het evenaart gesloten alternatieven en is uitgebracht onder de Apache-2.0-licentie voor persoonlijk, onderzoeks- en commercieel gebruik.",
  "flux-dev.description": "FLUX.1 [dev] is een open-gewichten gedistilleerd model voor niet-commercieel gebruik. Het behoudt bijna professionele beeldkwaliteit en instructieopvolging, terwijl het efficiënter werkt en middelen beter benut dan standaardmodellen van vergelijkbare grootte.",
  "flux-kontext-max.description": "State-of-the-art contextuele beeldgeneratie en -bewerking, waarbij tekst en afbeeldingen worden gecombineerd voor nauwkeurige, samenhangende resultaten.",
  "flux-kontext-pro.description": "State-of-the-art contextuele beeldgeneratie en -bewerking, waarbij tekst en afbeeldingen worden gecombineerd voor nauwkeurige, samenhangende resultaten.",
  "flux-merged.description": "FLUX.1-merged combineert de diepe functies van \"DEV\" met de snelheid van \"Schnell\", waardoor de prestatiegrenzen worden verlegd en de toepassingsmogelijkheden worden uitgebreid.",
  "flux-pro-1.1-ultra.description": "Ultra-hoge resolutie beeldgeneratie met 4MP output, levert scherpe beelden in 10 seconden.",
  "flux-pro-1.1.description": "Geüpgraded professioneel afbeeldingsgeneratiemodel met uitstekende beeldkwaliteit en nauwkeurige promptnauwkeurigheid.",
  "flux-pro.description": "Topklasse commercieel afbeeldingsgeneratiemodel met ongeëvenaarde beeldkwaliteit en diverse outputmogelijkheden.",
  "flux-schnell.description": "FLUX.1 [schnell] is het meest geavanceerde open-source few-step model, dat vergelijkbare concurrenten en zelfs sterke niet-gedistilleerde modellen zoals Midjourney v6.0 en DALL-E 3 (HD) overtreft. Het is fijn afgestemd om de diversiteit van de pretraining te behouden, wat de visuele kwaliteit, instructieopvolging, formaatvariatie, lettertypeverwerking en outputdiversiteit aanzienlijk verbetert.",
  "flux.1-schnell.description": "FLUX.1-schnell is een hoogwaardig afbeeldingsgeneratiemodel voor snelle output in meerdere stijlen.",
  "gemini-1.0-pro-001.description": "Gemini 1.0 Pro 001 (Tuning) biedt stabiele, aanpasbare prestaties voor complexe taken.",
  "gemini-1.0-pro-002.description": "Gemini 1.0 Pro 002 (Tuning) biedt sterke multimodale ondersteuning voor complexe taken.",
  "gemini-1.0-pro-latest.description": "Gemini 1.0 Pro is het krachtige AI-model van Google, ontworpen voor grootschalige taakverwerking.",
  "gemini-1.5-flash-001.description": "Gemini 1.5 Flash 001 is een efficiënt multimodaal model voor brede toepassingsschaling.",
  "gemini-1.5-flash-002.description": "Gemini 1.5 Flash 002 is een efficiënt multimodaal model, gebouwd voor grootschalige inzet.",
  "gemini-1.5-flash-8b-exp-0924.description": "Gemini 1.5 Flash 8B 0924 is het nieuwste experimentele model met aanzienlijke verbeteringen voor tekst- en multimodale toepassingen.",
  "gemini-1.5-flash-8b-latest.description": "Gemini 1.5 Flash 8B is een efficiënt multimodaal model, gebouwd voor grootschalige inzet.",
  "gemini-1.5-flash-8b.description": "Gemini 1.5 Flash 8B is een efficiënt multimodaal model voor brede toepassingsschaling.",
  "gemini-1.5-flash-exp-0827.description": "Gemini 1.5 Flash 0827 levert geoptimaliseerde multimodale verwerking voor complexe taken.",
  "gemini-1.5-flash-latest.description": "Gemini 1.5 Flash is het nieuwste multimodale AI-model van Google met snelle verwerking, ondersteuning voor tekst-, beeld- en video-invoer, en efficiënte schaalbaarheid over taken heen.",
  "gemini-1.5-pro-001.description": "Gemini 1.5 Pro 001 is een schaalbare multimodale AI-oplossing voor complexe taken.",
  "gemini-1.5-pro-002.description": "Gemini 1.5 Pro 002 is het nieuwste productierijpe model met hogere outputkwaliteit, vooral voor wiskunde, lange context en visuele taken.",
  "gemini-1.5-pro-exp-0801.description": "Gemini 1.5 Pro 0801 biedt sterke multimodale verwerking met meer flexibiliteit voor app-ontwikkeling.",
  "gemini-1.5-pro-exp-0827.description": "Gemini 1.5 Pro 0827 past de nieuwste optimalisaties toe voor efficiëntere multimodale verwerking.",
  "gemini-1.5-pro-latest.description": "Gemini 1.5 Pro ondersteunt tot 2 miljoen tokens en is een ideaal middelgroot multimodaal model voor complexe taken.",
  "gemini-2.0-flash-001.description": "Gemini 2.0 Flash biedt functies van de volgende generatie, waaronder uitzonderlijke snelheid, native toolgebruik, multimodale generatie en een contextvenster van 1 miljoen tokens.",
  "gemini-2.0-flash-exp-image-generation.description": "Experimentele variant van Gemini 2.0 Flash met ondersteuning voor beeldgeneratie.",
  "gemini-2.0-flash-lite-001.description": "Een variant van Gemini 2.0 Flash geoptimaliseerd voor kostenefficiëntie en lage latentie.",
  "gemini-2.0-flash-lite.description": "Een variant van Gemini 2.0 Flash geoptimaliseerd voor kostenefficiëntie en lage latentie.",
  "gemini-2.0-flash.description": "Gemini 2.0 Flash biedt functies van de volgende generatie, waaronder uitzonderlijke snelheid, native toolgebruik, multimodale generatie en een contextvenster van 1 miljoen tokens.",
  "gemini-2.5-flash-image-preview.description": "Nano Banana is het nieuwste, snelste en meest efficiënte native multimodale model van Google, dat conversatiegestuurde beeldgeneratie en -bewerking mogelijk maakt.",
  "gemini-2.5-flash-image-preview:image.description": "Nano Banana is het nieuwste, snelste en meest efficiënte native multimodale model van Google, dat conversatiegestuurde beeldgeneratie en -bewerking mogelijk maakt.",
  "gemini-2.5-flash-image.description": "Nano Banana is het nieuwste, snelste en meest efficiënte native multimodale model van Google, waarmee conversatiegestuurde beeldgeneratie en -bewerking mogelijk is.",
  "gemini-2.5-flash-image:image.description": "Nano Banana is het nieuwste, snelste en meest efficiënte native multimodale model van Google, waarmee conversatiegestuurde beeldgeneratie en -bewerking mogelijk is.",
  "gemini-2.5-flash-lite-preview-06-17.description": "Gemini 2.5 Flash-Lite Preview is het kleinste en meest kostenefficiënte model van Google, ontworpen voor grootschalig gebruik.",
  "gemini-2.5-flash-lite-preview-09-2025.description": "Preview-release (25 september 2025) van Gemini 2.5 Flash-Lite.",
  "gemini-2.5-flash-lite.description": "Gemini 2.5 Flash-Lite is het kleinste en meest kostenefficiënte model van Google, ontworpen voor grootschalig gebruik.",
  "gemini-2.5-flash-preview-04-17.description": "Gemini 2.5 Flash Preview is het meest voordelige model van Google met volledige functionaliteit.",
  "gemini-2.5-flash-preview-09-2025.description": "Preview-release (25 september 2025) van Gemini 2.5 Flash.",
  "gemini-2.5-flash.description": "Gemini 2.5 Flash is het meest voordelige model van Google met volledige functionaliteit.",
  "gemini-2.5-pro-preview-03-25.description": "Gemini 2.5 Pro Preview is het meest geavanceerde redeneermodel van Google, in staat om te redeneren over code, wiskunde en STEM-vraagstukken en grote datasets, codebases en documenten met lange context te analyseren.",
  "gemini-2.5-pro-preview-05-06.description": "Gemini 2.5 Pro Preview is het meest geavanceerde redeneermodel van Google, in staat om te redeneren over code, wiskunde en STEM-vraagstukken en grote datasets, codebases en documenten met lange context te analyseren.",
  "gemini-2.5-pro-preview-06-05.description": "Gemini 2.5 Pro Preview is het meest geavanceerde redeneermodel van Google, in staat om te redeneren over code, wiskunde en STEM-vraagstukken en grote datasets, codebases en documenten met lange context te analyseren.",
  "gemini-2.5-pro.description": "Gemini 2.5 Pro is het meest geavanceerde redeneermodel van Google, in staat om te redeneren over code, wiskunde en STEM-vraagstukken en grote datasets, codebases en documenten met lange context te analyseren.",
  "gemini-3-flash-preview.description": "Gemini 3 Flash is het slimste model dat is gebouwd voor snelheid, met geavanceerde intelligentie en uitstekende zoekverankering.",
  "gemini-3-pro-image-preview.description": "Gemini 3 Pro Image (Nano Banana Pro) is het beeldgeneratiemodel van Google en ondersteunt ook multimodale gesprekken.",
  "gemini-3-pro-image-preview:image.description": "Gemini 3 Pro Image (Nano Banana Pro) is het beeldgeneratiemodel van Google en ondersteunt ook multimodale chat.",
  "gemini-3-pro-preview.description": "Gemini 3 Pro is het krachtigste agent- en vibe-codingmodel van Google, met rijkere visuele output en diepere interactie bovenop geavanceerde redeneercapaciteiten.",
  "gemini-flash-latest.description": "Nieuwste versie van Gemini Flash.",
  "gemini-flash-lite-latest.description": "Nieuwste versie van Gemini Flash-Lite.",
  "gemini-pro-latest.description": "Nieuwste versie van Gemini Pro.",
  "gemma-7b-it.description": "Gemma 7B is kostenefficiënt voor kleine tot middelgrote taken.",
  "gemma2-9b-it.description": "Gemma 2 9B is geoptimaliseerd voor specifieke taken en integratie met tools.",
  "gemma2.description": "Gemma 2 is het efficiënte model van Google, geschikt voor toepassingen van kleine apps tot complexe gegevensverwerking.",
  "gemma2:27b.description": "Gemma 2 is het efficiënte model van Google, geschikt voor toepassingen van kleine apps tot complexe gegevensverwerking.",
  "gemma2:2b.description": "Gemma 2 is het efficiënte model van Google, geschikt voor toepassingen van kleine apps tot complexe gegevensverwerking.",
  "generalv3.5.description": "Spark Max is de meest complete versie, met ondersteuning voor webzoekopdrachten en veel ingebouwde plug-ins. De volledig geoptimaliseerde kernfuncties, systeemrollen en functieaanroepen zorgen voor uitstekende prestaties in complexe toepassingsscenario's.",
  "generalv3.description": "Spark Pro is een krachtig LLM-model dat is geoptimaliseerd voor professionele domeinen, met focus op wiskunde, programmeren, gezondheidszorg en onderwijs. Het ondersteunt webzoekopdrachten en ingebouwde plug-ins zoals weer en datum. Het levert sterke prestaties en efficiëntie in complexe kennisvragen, taalbegrip en geavanceerde tekstcreatie, en is daarmee ideaal voor professioneel gebruik.",
  "glm-4-0520.description": "GLM-4-0520 is de nieuwste modelversie, ontworpen voor zeer complexe en diverse taken met uitstekende prestaties.",
  "glm-4-7.description": "GLM-4.7 is het nieuwste vlaggenschipmodel van Zhipu AI. Het verbetert programmeercapaciteiten, langetermijnplanning en samenwerking met tools voor Agentic Coding-scenario’s, en behaalt toonaangevende prestaties onder open-source modellen op meerdere benchmarks. Algemene capaciteiten zijn verbeterd, met natuurlijkere en beknoptere antwoorden en meeslepender schrijfvaardigheid. Bij complexe agenttaken is het volgen van instructies tijdens toolgebruik sterker, en de esthetiek van Artifacts en de Agentic Coding-frontend, evenals de efficiëntie van langetermijnuitvoering, zijn verder verbeterd. • Sterkere programmeercapaciteiten: aanzienlijk verbeterde meertalige codeerprestaties en terminalagentprestaties; GLM-4.7 kan nu \"eerst denken, dan handelen\" implementeren in programmeerframeworks zoals Claude Code, Kilo Code, TRAE, Cline en Roo Code, met stabielere prestaties bij complexe taken. • Verbetering van frontend-esthetiek: GLM-4.7 toont aanzienlijke vooruitgang in de kwaliteit van frontendgeneratie, en kan websites, presentaties en posters genereren met betere visuele aantrekkingskracht. • Sterkere toolintegratie: GLM-4.7 verbetert het gebruik van tools, scoort 67 in de BrowseComp-webtaakevaluatie en behaalt 84,7 in de τ²-Bench-evaluatie voor interactieve toolintegratie, waarmee het Claude Sonnet 4.5 overtreft als open-source SOTA. • Verbeterde redeneercapaciteit: aanzienlijk verbeterde wiskundige en logische vaardigheden, met een score van 42,8% op de HLE (\"Humanity's Last Exam\") benchmark, een verbetering van 41% ten opzichte van GLM-4.6, en beter dan GPT-5.1. • Algemene capaciteitsverbetering: GLM-4.7-gesprekken zijn beknopter, intelligenter en menselijker; schrijven en rollenspel zijn literairer en meeslepender.",
  "glm-4-9b-chat.description": "GLM-4-9B-Chat presteert sterk op semantiek, wiskunde, redeneren, code en kennis. Het ondersteunt ook webbrowseren, code-uitvoering, aangepaste toolaanroepen en redeneren over lange teksten, met ondersteuning voor 26 talen waaronder Japans, Koreaans en Duits.",
  "glm-4-air-250414.description": "GLM-4-Air is een voordelige optie met prestaties dicht bij GLM-4, hoge snelheid en lagere kosten.",
  "glm-4-air.description": "GLM-4-Air is een voordelige optie met prestaties dicht bij GLM-4, hoge snelheid en lagere kosten.",
  "glm-4-airx.description": "GLM-4-AirX is een efficiëntere variant van GLM-4-Air met tot 2,6x snellere redeneersnelheid.",
  "glm-4-alltools.description": "GLM-4-AllTools is een veelzijdig agentmodel dat is geoptimaliseerd voor complexe instructieplanning en toolgebruik zoals webbrowseren, codeuitleg en tekstgeneratie, geschikt voor multitask-uitvoering.",
  "glm-4-flash-250414.description": "GLM-4-Flash is ideaal voor eenvoudige taken: snelst en gratis.",
  "glm-4-flash.description": "GLM-4-Flash is ideaal voor eenvoudige taken: snelst en gratis.",
  "glm-4-flashx.description": "GLM-4-FlashX is een verbeterde Flash-versie met ultrasnelle redeneersnelheid.",
  "glm-4-long.description": "GLM-4-Long ondersteunt ultralange invoer voor geheugenachtige taken en grootschalige documentverwerking.",
  "glm-4-plus.description": "GLM-4-Plus is een vlaggenschipmodel met hoge intelligentie, sterke prestaties bij lange teksten en complexe taken, en verbeterde algehele prestaties.",
  "glm-4.1v-thinking-flash.description": "GLM-4.1V-Thinking is het krachtigste bekende ~10B VLM-model, geschikt voor SOTA-taken zoals videobegrip, beeldvragen, vakoplossingen, OCR, document- en grafieklezen, GUI-agents, frontend-codering en grounding. Het overtreft zelfs het 8x grotere Qwen2.5-VL-72B op veel taken. Met geavanceerde RL gebruikt het keten-van-gedachten-redenering om nauwkeurigheid en rijkdom te verbeteren, en presteert het beter dan traditionele niet-denkende modellen in zowel resultaten als uitlegbaarheid.",
  "glm-4.1v-thinking-flashx.description": "GLM-4.1V-Thinking is het krachtigste bekende ~10B VLM-model, geschikt voor SOTA-taken zoals videobegrip, beeldvragen, vakoplossingen, OCR, document- en grafieklezen, GUI-agents, frontend-codering en grounding. Het overtreft zelfs het 8x grotere Qwen2.5-VL-72B op veel taken. Met geavanceerde RL gebruikt het keten-van-gedachten-redenering om nauwkeurigheid en rijkdom te verbeteren, en presteert het beter dan traditionele niet-denkende modellen in zowel resultaten als uitlegbaarheid.",
  "glm-4.5-air.description": "GLM-4.5 lichte editie die prestaties en kosten in balans brengt, met flexibele hybride denkmodi.",
  "glm-4.5-airx.description": "GLM-4.5-Air snelle editie met snellere reacties voor grootschalig, snel gebruik.",
  "glm-4.5-x.description": "GLM-4.5 snelle editie, met sterke prestaties en generatiesnelheden tot 100 tokens/seconde.",
  "glm-4.5.description": "Zhipu vlaggenschipmodel met schakelbare denkmodus, levert open-source SOTA-prestaties en tot 128K context.",
  "glm-4.5v.description": "Zhipu’s volgende generatie MoE-visie-redeneermodel met 106B totale parameters en 12B actief, bereikt SOTA onder vergelijkbare open-source multimodale modellen voor beeld-, video-, documentbegrip en GUI-taken.",
  "glm-4.6.description": "GLM-4.6 (355B) is het nieuwste vlaggenschipmodel van Zhipu en overtreft zijn voorgangers volledig op het gebied van geavanceerde codering, verwerking van lange teksten, redeneren en agentfunctionaliteit. Het is bijzonder krachtig in programmeertaken en vergelijkbaar met Claude Sonnet 4, waarmee het het toonaangevende codeermodel van China is geworden.",
  "glm-4.7-flash.description": "GLM-4.7-Flash is een SOTA-model op 30B-niveau dat prestaties en efficiëntie in balans brengt. Het verbetert programmeercapaciteiten, langetermijnplanning en samenwerking met tools voor Agentic Coding-scenario’s, en behaalt toonaangevende prestaties onder open-source modellen van vergelijkbare grootte op meerdere benchmarks. Bij het uitvoeren van complexe agenttaken volgt het instructies beter tijdens toolgebruik, en verbetert het de esthetiek van de frontend en de efficiëntie van langetermijnuitvoering voor Artifacts en Agentic Coding.",
  "glm-4.7-flashx.description": "GLM-4.7-Flash is een SOTA-model op 30B-niveau dat prestaties en efficiëntie in balans brengt. Het verbetert programmeercapaciteiten, langetermijnplanning en samenwerking met tools voor Agentic Coding-scenario’s, en behaalt toonaangevende prestaties onder open-source modellen van vergelijkbare grootte op meerdere benchmarks. Bij het uitvoeren van complexe agenttaken volgt het instructies beter tijdens toolgebruik, en verbetert het de esthetiek van de frontend en de efficiëntie van langetermijnuitvoering voor Artifacts en Agentic Coding.",
  "glm-4.7.description": "GLM-4.7 is het nieuwste vlaggenschipmodel van Zhipu, geoptimaliseerd voor Agentic Coding-scenario’s met verbeterde codeercapaciteiten, langetermijnplanning en samenwerking met tools. Het levert toonaangevende prestaties onder open-source modellen op meerdere publieke benchmarks. De algemene capaciteiten zijn verbeterd met beknoptere en natuurlijkere antwoorden en meeslepender schrijfvaardigheid. Bij complexe agenttaken is het volgen van instructies tijdens toolgebruik sterker, en zijn de frontend-esthetiek en efficiëntie bij langetermijntaken in Artifacts en Agentic Coding verder verbeterd.",
  "glm-4.description": "GLM-4 is het oudere vlaggenschipmodel dat in januari 2024 werd uitgebracht en inmiddels is vervangen door het krachtigere GLM-4-0520.",
  "glm-4v-flash.description": "GLM-4V-Flash richt zich op efficiënte interpretatie van enkele afbeeldingen voor snelle analyses, zoals realtime- of batchverwerking van beelden.",
  "glm-4v-plus-0111.description": "GLM-4V-Plus begrijpt video’s en meerdere afbeeldingen en is geschikt voor multimodale taken.",
  "glm-4v-plus.description": "GLM-4V-Plus begrijpt video’s en meerdere afbeeldingen en is geschikt voor multimodale taken.",
  "glm-4v.description": "GLM-4V biedt krachtig beeldbegrip en redenering voor visuele taken.",
  "glm-z1-air.description": "Redeneermodel met sterke inferentiecapaciteiten voor taken die diepgaand redeneren vereisen.",
  "glm-z1-airx.description": "Ultrasnelle redenering met hoge kwaliteit van inferentie.",
  "glm-z1-flash.description": "De GLM-Z1-serie biedt krachtige complexe redenering en blinkt uit in logica, wiskunde en programmeren.",
  "glm-z1-flashx.description": "Snel en kostenefficiënt: Flash-verbeterd met ultrasnelle redenering en hogere gelijktijdigheid.",
  "glm-zero-preview.description": "GLM-Zero-Preview levert sterke complexe redenering en blinkt uit in logica, wiskunde en programmeren.",
  "global.anthropic.claude-opus-4-5-20251101-v1:0.description": "Claude Opus 4.5 is het vlaggenschipmodel van Anthropic, dat uitzonderlijke intelligentie en schaalbare prestaties combineert voor complexe taken die antwoorden van de hoogste kwaliteit en redeneervermogen vereisen.",
  "google/gemini-2.0-flash-001.description": "Gemini 2.0 Flash biedt mogelijkheden van de volgende generatie, waaronder uitstekende snelheid, native toolgebruik, multimodale generatie en een contextvenster van 1 miljoen tokens.",
  "google/gemini-2.0-flash-lite-001.description": "Gemini 2.0 Flash Lite is een lichte variant van Gemini met standaard uitgeschakeld denkvermogen om latentie en kosten te verlagen, maar dit kan worden ingeschakeld via parameters.",
  "google/gemini-2.0-flash-lite.description": "Gemini 2.0 Flash Lite biedt functies van de volgende generatie, waaronder uitzonderlijke snelheid, ingebouwd toolgebruik, multimodale generatie en een contextvenster van 1 miljoen tokens.",
  "google/gemini-2.0-flash.description": "Gemini 2.0 Flash is het krachtige redeneermodel van Google voor uitgebreide multimodale taken.",
  "google/gemini-2.5-flash-image-free.description": "Gratis versie van Gemini 2.5 Flash Image met beperkte multimodale generatiequota.",
  "google/gemini-2.5-flash-image-preview.description": "Experimenteel model van Gemini 2.5 Flash met ondersteuning voor beeldgeneratie.",
  "google/gemini-2.5-flash-image.description": "Gemini 2.5 Flash Image (Nano Banana) is het beeldgeneratiemodel van Google met ondersteuning voor multimodale conversaties.",
  "google/gemini-2.5-flash-lite.description": "Gemini 2.5 Flash Lite is de lichte variant van Gemini 2.5, geoptimaliseerd voor lage latentie en kosten, geschikt voor scenario’s met hoge doorvoer.",
  "google/gemini-2.5-flash-preview.description": "Gemini 2.5 Flash is het meest geavanceerde vlaggenschipmodel van Google, gebouwd voor geavanceerde redenering, codering, wiskunde en wetenschappelijke taken. Het bevat ingebouwd 'denken' om nauwkeurigere antwoorden te leveren met fijnere contextverwerking.\n\nOpmerking: dit model heeft twee varianten — met en zonder denken. De prijs van de output verschilt aanzienlijk afhankelijk van of denken is ingeschakeld. Als je de standaardvariant kiest (zonder de “:thinking”-suffix), zal het model expliciet vermijden om denkstappen te genereren.\n\nOm denken te gebruiken en denkstappen te ontvangen, moet je de “:thinking”-variant selecteren, wat hogere kosten voor denkoutput met zich meebrengt.\n\nGemini 2.5 Flash kan ook worden geconfigureerd via de parameter “max reasoning tokens” zoals gedocumenteerd (https://openrouter.ai/docs/use-cases/reasoning-tokens#max-tokens-for-reasoning).",
  "google/gemini-2.5-flash-preview:thinking.description": "Gemini 2.5 Flash is het meest geavanceerde vlaggenschipmodel van Google, gebouwd voor geavanceerde redenering, codering, wiskunde en wetenschappelijke taken. Het bevat ingebouwd 'denken' om nauwkeurigere antwoorden te leveren met fijnere contextverwerking.\n\nOpmerking: dit model heeft twee varianten — met en zonder denken. De prijs van de output verschilt aanzienlijk afhankelijk van of denken is ingeschakeld. Als je de standaardvariant kiest (zonder de “:thinking”-suffix), zal het model expliciet vermijden om denkstappen te genereren.\n\nOm denken te gebruiken en denkstappen te ontvangen, moet je de “:thinking”-variant selecteren, wat hogere kosten voor denkoutput met zich meebrengt.\n\nGemini 2.5 Flash kan ook worden geconfigureerd via de parameter “max reasoning tokens” zoals gedocumenteerd (https://openrouter.ai/docs/use-cases/reasoning-tokens#max-tokens-for-reasoning).",
  "google/gemini-2.5-flash.description": "Gemini 2.5 Flash (Lite/Pro/Flash) is de modelreeks van Google die varieert van lage latentie tot krachtige redenering.",
  "google/gemini-2.5-pro-free.description": "Gratis versie van Gemini 2.5 Pro met beperkte multimodale lange-contextcapaciteit, geschikt voor tests en lichte workflows.",
  "google/gemini-2.5-pro-preview.description": "Gemini 2.5 Pro Preview is het meest geavanceerde denkmodel van Google voor redenering over complexe problemen in code, wiskunde en STEM, en voor het analyseren van grote datasets, codebases en documenten met lange context.",
  "google/gemini-2.5-pro.description": "Gemini 2.5 Pro is het vlaggenschip redeneermodel van Google met ondersteuning voor lange contexten bij complexe taken.",
  "google/gemini-3-pro-image-preview-free.description": "Gratis versie van Gemini 3 Pro Image met beperkte multimodale generatiequota.",
  "google/gemini-3-pro-image-preview.description": "Gemini 3 Pro Image (Nano Banana Pro) is het beeldgeneratiemodel van Google met ondersteuning voor multimodale conversaties.",
  "google/gemini-3-pro-preview-free.description": "Gemini 3 Pro Preview Free biedt hetzelfde multimodale begrip en redenering als de standaardversie, maar met quota- en snelheidsbeperkingen, waardoor het beter geschikt is voor tests en laagfrequent gebruik.",
  "google/gemini-3-pro-preview.description": "Gemini 3 Pro is het multimodale redeneermodel van de volgende generatie binnen de Gemini-familie. Het begrijpt tekst, audio, afbeeldingen en video, en verwerkt complexe taken en grote codebases.",
  "google/gemini-embedding-001.description": "Een geavanceerd embeddingmodel met sterke prestaties in Engels, meertalige en codeertaken.",
  "google/gemini-flash-1.5.description": "Gemini 1.5 Flash biedt geoptimaliseerde multimodale verwerking voor een breed scala aan complexe taken.",
  "google/gemini-pro-1.5.description": "Gemini 1.5 Pro combineert de nieuwste optimalisaties voor efficiëntere verwerking van multimodale gegevens.",
  "google/gemma-2-27b-it.description": "Gemma 2 27B is een algemeen toepasbaar LLM met sterke prestaties in uiteenlopende scenario’s.",
  "google/gemma-2-27b.description": "Gemma 2 is Google's efficiënte modelfamilie voor toepassingen van kleine apps tot complexe gegevensverwerking.",
  "google/gemma-2-2b-it.description": "Een geavanceerd klein taalmodel ontworpen voor edge-toepassingen.",
  "google/gemma-2-9b-it.description": "Gemma 2 9B, ontwikkeld door Google, biedt efficiënte instructieopvolging en solide algemene capaciteiten.",
  "google/gemma-2-9b-it:free.description": "Gemma 2 is Google's lichtgewicht open-source tekstmodelfamilie.",
  "google/gemma-2-9b.description": "Gemma 2 is Google's efficiënte modelfamilie voor toepassingen van kleine apps tot complexe gegevensverwerking.",
  "google/gemma-2b-it.description": "Gemma Instruct (2B) biedt basisinstructieverwerking voor lichtgewicht toepassingen.",
  "google/gemma-3-12b-it.description": "Gemma 3 12B is een open-source taalmodel van Google dat nieuwe maatstaven zet op het gebied van efficiëntie en prestaties.",
  "google/gemma-3-27b-it.description": "Gemma 3 27B is een open-source taalmodel van Google dat nieuwe maatstaven zet op het gebied van efficiëntie en prestaties.",
  "google/text-embedding-005.description": "Een op het Engels gericht tekstembeddingmodel, geoptimaliseerd voor code- en taalverwerkingstaken.",
  "google/text-multilingual-embedding-002.description": "Een meertalig tekstembeddingmodel, geoptimaliseerd voor cross-linguale taken in vele talen.",
  "gpt-3.5-turbo-0125.description": "GPT 3.5 Turbo voor tekstgeneratie en -begrip; verwijst momenteel naar gpt-3.5-turbo-0125.",
  "gpt-3.5-turbo-1106.description": "GPT 3.5 Turbo voor tekstgeneratie en -begrip; verwijst momenteel naar gpt-3.5-turbo-0125.",
  "gpt-3.5-turbo-instruct.description": "GPT 3.5 Turbo voor tekstgeneratie- en begrijptaken, geoptimaliseerd voor instructieopvolging.",
  "gpt-3.5-turbo.description": "GPT 3.5 Turbo voor tekstgeneratie en -begrip; verwijst momenteel naar gpt-3.5-turbo-0125.",
  "gpt-35-turbo-16k.description": "GPT-3.5 Turbo 16k is een model met hoge capaciteit voor complexe tekstgeneratietaken.",
  "gpt-35-turbo.description": "GPT-3.5 Turbo is OpenAI’s efficiënte model voor chat en tekstgeneratie, met ondersteuning voor parallelle functieaanroepen.",
  "gpt-4-0125-preview.description": "De nieuwste GPT-4 Turbo voegt visuele mogelijkheden toe. Visuele verzoeken ondersteunen JSON-modus en functieaanroepen. Het is een kosteneffectief multimodaal model dat nauwkeurigheid en efficiëntie in realtime toepassingen in balans brengt.",
  "gpt-4-0613.description": "GPT-4 biedt een groter contextvenster om langere invoer te verwerken, geschikt voor brede informatie-integratie en data-analyse.",
  "gpt-4-1106-preview.description": "De nieuwste GPT-4 Turbo voegt visuele mogelijkheden toe. Visuele verzoeken ondersteunen JSON-modus en functieaanroepen. Het is een kosteneffectief multimodaal model dat nauwkeurigheid en efficiëntie in realtime toepassingen in balans brengt.",
  "gpt-4-32k-0613.description": "GPT-4 biedt een groter contextvenster om langere invoer te verwerken, geschikt voor brede informatie-integratie en data-analyse.",
  "gpt-4-32k.description": "GPT-4 biedt een groter contextvenster om langere invoer te verwerken, geschikt voor brede informatie-integratie en data-analyse.",
  "gpt-4-turbo-2024-04-09.description": "De nieuwste GPT-4 Turbo voegt visuele mogelijkheden toe. Visuele verzoeken ondersteunen JSON-modus en functieaanroepen. Het is een kosteneffectief multimodaal model dat nauwkeurigheid en efficiëntie in realtime toepassingen in balans brengt.",
  "gpt-4-turbo-preview.description": "De nieuwste GPT-4 Turbo voegt visuele mogelijkheden toe. Visuele verzoeken ondersteunen JSON-modus en functieaanroepen. Het is een kosteneffectief multimodaal model dat nauwkeurigheid en efficiëntie in realtime toepassingen in balans brengt.",
  "gpt-4-turbo.description": "De nieuwste GPT-4 Turbo voegt visuele mogelijkheden toe. Visuele verzoeken ondersteunen JSON-modus en functieaanroepen. Het is een kosteneffectief multimodaal model dat nauwkeurigheid en efficiëntie in realtime toepassingen in balans brengt.",
  "gpt-4-vision-preview.description": "GPT-4 Vision preview, ontworpen voor beeldanalyse- en verwerkingstaken.",
  "gpt-4.1-mini.description": "GPT-4.1 mini biedt een balans tussen intelligentie, snelheid en kosten, aantrekkelijk voor veel toepassingen.",
  "gpt-4.1-nano.description": "GPT-4.1 nano is het snelste en meest kosteneffectieve GPT-4.1 model.",
  "gpt-4.1.description": "GPT-4.1 is ons vlaggenschipmodel voor complexe taken en domeinoverstijgende probleemoplossing.",
  "gpt-4.5-preview.description": "GPT-4.5-preview is het nieuwste algemene model met diepgaande wereldkennis en beter intentiebegrip, sterk in creatieve taken en agentplanning. De kennisgrens is oktober 2023.",
  "gpt-4.description": "GPT-4 biedt een groter contextvenster om langere invoer te verwerken, geschikt voor brede informatie-integratie en data-analyse.",
  "gpt-4o-2024-05-13.description": "ChatGPT-4o is een dynamisch model dat realtime wordt bijgewerkt en sterke taalbegrip- en generatiecapaciteiten combineert voor grootschalige toepassingen zoals klantenservice, onderwijs en technische ondersteuning.",
  "gpt-4o-2024-08-06.description": "ChatGPT-4o is een dynamisch model dat realtime wordt bijgewerkt. Het combineert sterk taalbegrip en -generatie voor grootschalige toepassingen zoals klantenservice, onderwijs en technische ondersteuning.",
  "gpt-4o-2024-11-20.description": "ChatGPT-4o is een dynamisch model dat realtime wordt bijgewerkt en sterke taalbegrip- en generatiecapaciteiten combineert voor grootschalige toepassingen zoals klantenservice, onderwijs en technische ondersteuning.",
  "gpt-4o-audio-preview.description": "GPT-4o Audio Preview-model met audio-invoer en -uitvoer.",
  "gpt-4o-mini-audio-preview.description": "GPT-4o mini Audio-model met audio-invoer en -uitvoer.",
  "gpt-4o-mini-realtime-preview.description": "GPT-4o-mini realtime-variant met realtime audio- en tekstinvoer/-uitvoer.",
  "gpt-4o-mini-search-preview.description": "GPT-4o mini Search Preview is getraind om webzoekopdrachten te begrijpen en uit te voeren via de Chat Completions API. Webzoekopdrachten worden per toolaanroep gefactureerd, naast tokenkosten.",
  "gpt-4o-mini-transcribe.description": "GPT-4o Mini Transcribe is een spraak-naar-tekstmodel dat audio transcribeert met GPT-4o, met verbeterde woordherkenning, taalidentificatie en nauwkeurigheid ten opzichte van het oorspronkelijke Whisper-model.",
  "gpt-4o-mini-tts.description": "GPT-4o mini TTS is een tekst-naar-spraakmodel gebaseerd op GPT-4o mini, dat tekst omzet in natuurlijk klinkende spraak met een maximale invoer van 2000 tokens.",
  "gpt-4o-mini.description": "GPT-4o mini is OpenAI’s nieuwste model na GPT-4 Omni, met ondersteuning voor tekst+beeldinvoer en tekstuitvoer. Het is hun meest geavanceerde kleine model, veel goedkoper dan recente topmodellen en meer dan 60% goedkoper dan GPT-3.5 Turbo, met behoud van topintelligentie (82% MMLU).",
  "gpt-4o-realtime-preview-2024-10-01.description": "GPT-4o realtime-variant met realtime audio- en tekstinvoer/-uitvoer.",
  "gpt-4o-realtime-preview-2025-06-03.description": "GPT-4o realtime-variant met realtime audio- en tekstinvoer/-uitvoer.",
  "gpt-4o-realtime-preview.description": "GPT-4o realtime-variant met realtime audio- en tekstinvoer/-uitvoer.",
  "gpt-4o-search-preview.description": "GPT-4o Search Preview is getraind om webzoekopdrachten te begrijpen en uit te voeren via de Chat Completions API. Webzoekopdrachten worden per toolaanroep gefactureerd, naast tokenkosten.",
  "gpt-4o-transcribe.description": "GPT-4o Transcribe is een spraak-naar-tekstmodel dat audio transcribeert met GPT-4o, met verbeterde woordherkenning, taalidentificatie en nauwkeurigheid ten opzichte van het oorspronkelijke Whisper-model.",
  "gpt-4o.description": "ChatGPT-4o is een dynamisch model dat realtime wordt bijgewerkt en sterke taalbegrip- en generatiecapaciteiten combineert voor grootschalige toepassingen zoals klantenservice, onderwijs en technische ondersteuning.",
  "gpt-5-chat-latest.description": "Het GPT-5-model dat wordt gebruikt in ChatGPT, combineert sterk begrip en generatie voor conversatietoepassingen.",
  "gpt-5-chat.description": "GPT-5 Chat is een previewmodel geoptimaliseerd voor conversatiescenario's. Het ondersteunt tekst- en afbeeldingsinvoer, geeft alleen tekstuitvoer en is geschikt voor chatbots en conversatie-AI-toepassingen.",
  "gpt-5-codex.description": "GPT-5 Codex is een GPT-5-variant geoptimaliseerd voor agentmatige programmeertaken in Codex-achtige omgevingen.",
  "gpt-5-mini.description": "Een snellere, kostenefficiëntere GPT-5-variant voor goed gedefinieerde taken, met snelle reacties zonder kwaliteitsverlies.",
  "gpt-5-nano.description": "De snelste en meest kosteneffectieve GPT-5-variant, ideaal voor toepassingen met strikte eisen op het gebied van latentie en kosten.",
  "gpt-5-pro.description": "GPT-5 Pro gebruikt meer rekenkracht om dieper na te denken en consequent betere antwoorden te leveren.",
  "gpt-5.1-chat-latest.description": "GPT-5.1 Chat: de ChatGPT-variant van GPT-5.1, ontworpen voor chatscenario's.",
  "gpt-5.1-codex-mini.description": "GPT-5.1 Codex mini: een kleinere, goedkopere Codex-variant geoptimaliseerd voor agentmatige programmeertaken.",
  "gpt-5.1-codex.description": "GPT-5.1 Codex: een GPT-5.1-variant geoptimaliseerd voor agentmatige programmeertaken, geschikt voor complexe code-/agentworkflows in de Responses API.",
  "gpt-5.1.description": "GPT-5.1 — een toonaangevend model geoptimaliseerd voor programmeren en agenttaken met configureerbare redeneercapaciteit en langere context.",
  "gpt-5.2-chat-latest.description": "GPT-5.2 Chat is de ChatGPT-variant (chat-latest) met de nieuwste verbeteringen in conversatie.",
  "gpt-5.2-pro.description": "GPT-5.2 Pro: een slimmer, nauwkeuriger GPT-5.2-variant (alleen Responses API), geschikt voor moeilijke problemen en langere redeneringen over meerdere beurten.",
  "gpt-5.2.description": "GPT-5.2 is een toonaangevend model voor programmeren en agentworkflows met sterkere redeneercapaciteit en prestaties bij lange contexten.",
  "gpt-5.description": "Het beste model voor domeinoverstijgende programmeer- en agenttaken. GPT-5 biedt sprongen in nauwkeurigheid, snelheid, redeneervermogen, contextbewustzijn, gestructureerd denken en probleemoplossing.",
  "gpt-audio.description": "GPT Audio is een algemeen chatmodel voor audio-invoer/-uitvoer, ondersteund in de Chat Completions API.",
  "gpt-image-1-mini.description": "Een goedkopere GPT Image 1-variant met native tekst- en afbeeldingsinvoer en afbeeldingsuitvoer.",
  "gpt-image-1.5.description": "Een verbeterd GPT Image 1-model met 4× snellere generatie, nauwkeurigere bewerkingen en verbeterde tekstrendering.",
  "gpt-image-1.description": "ChatGPT's native multimodale afbeeldingsgeneratiemodel.",
  "gpt-oss-120b.description": "Toegang vereist een aanvraag. GPT-OSS-120B is een open-source groot taalmodel van OpenAI met sterke tekstgeneratiecapaciteit.",
  "gpt-oss-20b.description": "Toegang vereist een aanvraag. GPT-OSS-20B is een open-source middelgroot taalmodel van OpenAI met efficiënte tekstgeneratie.",
  "gpt-oss:120b.description": "GPT-OSS 120B is OpenAI’s grote open-source LLM met MXFP4-kwantisatie en gepositioneerd als vlaggenschipmodel. Het vereist multi-GPU- of high-end werkstationomgevingen en levert uitstekende prestaties in complexe redenering, codegeneratie en meertalige verwerking, met geavanceerde functieaanroepen en toolintegratie.",
  "gpt-oss:20b.description": "GPT-OSS 20B is een open-source LLM van OpenAI met MXFP4-kwantisatie, geschikt voor high-end consument-GPU’s of Apple Silicon Macs. Het presteert goed in dialooggeneratie, programmeren en redeneertaken, en ondersteunt functieaanroepen en toolgebruik.",
  "gpt-realtime.description": "Een algemeen realtime model dat realtime tekst- en audio-invoer/-uitvoer ondersteunt, plus afbeeldingsinvoer.",
  "grok-2-image-1212.description": "Ons nieuwste afbeeldingsgeneratiemodel creëert levendige, realistische beelden op basis van prompts en blinkt uit in marketing-, sociale media- en entertainmenttoepassingen.",
  "grok-2-vision-1212.description": "Verbeterde nauwkeurigheid, instructieopvolging en meertalige mogelijkheden.",
  "grok-3-mini.description": "Een lichtgewicht model dat eerst nadenkt voordat het antwoordt. Snel en slim voor logische taken die geen diepgaande domeinkennis vereisen, met toegang tot ruwe redeneertracering.",
  "grok-3.description": "Een vlaggenschipmodel dat uitblinkt in zakelijke toepassingen zoals gegevensextractie, programmeren en samenvatten, met diepgaande domeinkennis in financiën, gezondheidszorg, recht en wetenschap.",
  "grok-4-0709.description": "xAI’s Grok 4 met sterke redeneercapaciteit.",
  "grok-4-1-fast-non-reasoning.description": "Een grensverleggend multimodaal model geoptimaliseerd voor krachtige agenttoolgebruik.",
  "grok-4-1-fast-reasoning.description": "Een grensverleggend multimodaal model geoptimaliseerd voor krachtige agenttoolgebruik.",
  "grok-4-fast-non-reasoning.description": "We zijn verheugd Grok 4 Fast uit te brengen, onze nieuwste vooruitgang in kosteneffectieve redeneermodellen.",
  "grok-4-fast-reasoning.description": "We zijn verheugd Grok 4 Fast uit te brengen, onze nieuwste vooruitgang in kosteneffectieve redeneermodellen.",
  "grok-4.description": "Ons nieuwste en krachtigste vlaggenschipmodel, uitblinkend in NLP, wiskunde en redenering—een ideale allrounder.",
  "grok-code-fast-1.description": "We zijn verheugd om grok-code-fast-1 te lanceren, een snel en kosteneffectief redeneermodel dat uitblinkt in agentmatig programmeren.",
  "groq/compound-mini.description": "Compound-mini is een samengesteld AI-systeem dat gebruikmaakt van openbaar beschikbare modellen op GroqCloud en intelligent hulpmiddelen inzet om gebruikersvragen te beantwoorden.",
  "groq/compound.description": "Compound is een samengesteld AI-systeem dat gebruikmaakt van meerdere openbaar beschikbare modellen op GroqCloud en intelligent hulpmiddelen inzet om gebruikersvragen te beantwoorden.",
  "gryphe/mythomax-l2-13b.description": "MythoMax L2 13B is een creatief en intelligent taalmodel dat is samengesteld uit meerdere topmodellen.",
  "hunyuan-a13b.description": "Het eerste hybride redeneermodel van Hunyuan, een upgrade van hun hunyuan-standard-256K (80B totaal, 13B actief). Standaard ingesteld op langzaam denken, met ondersteuning voor snel/langzaam schakelen via parameters of prefix /no_think. De algehele capaciteit is verbeterd ten opzichte van de vorige generatie, vooral in wiskunde, wetenschap, langetekstbegrip en agenttaken.",
  "hunyuan-code.description": "Het nieuwste codegeneratiemodel, getraind met 200 miljard hoogwaardige codevoorbeelden en zes maanden SFT; context uitgebreid tot 8K. Het scoort hoog in geautomatiseerde benchmarks voor vijf programmeertalen en in menselijke evaluaties op tien criteria.",
  "hunyuan-functioncall.description": "Het nieuwste MoE FunctionCall-model, getraind met hoogwaardige functieaanroepdata, met een contextvenster van 32K en toonaangevende benchmarkresultaten op meerdere dimensies.",
  "hunyuan-large-longcontext.description": "Blinkt uit in taken met lange documenten zoals samenvattingen en vraag-antwoord, en is ook sterk in algemene tekstgeneratie. Uitstekend in analyse en generatie van complexe, gedetailleerde lange teksten.",
  "hunyuan-large-vision.description": "Een visueel-taalkundig model getraind vanuit Hunyuan Large voor beeld-tekstbegrip. Ondersteunt invoer van meerdere afbeeldingen + tekst in elke resolutie en verbetert meertalig visueel begrip.",
  "hunyuan-large.description": "Hunyuan-large heeft ~389 miljard totale parameters en ~52 miljard actieve, het grootste en krachtigste open MoE-model in een Transformer-architectuur.",
  "hunyuan-lite-vision.description": "Het nieuwste 7B multimodale model met een contextvenster van 32K, ondersteunt Chinees/Engels multimodaal chatten, objectherkenning, documenttabelbegrip en multimodale wiskunde, en presteert beter dan andere 7B-modellen op meerdere benchmarks.",
  "hunyuan-lite.description": "Geüpgraded naar een MoE-architectuur met een contextvenster van 256K, en overtreft veel open modellen op het gebied van NLP, code, wiskunde en industriële benchmarks.",
  "hunyuan-pro.description": "Een MoE-model met biljoenen parameters en een contextvenster van 32K, toonaangevend in benchmarks, sterk in complexe instructies en redenering, geavanceerde wiskunde, functieaanroepen, en geoptimaliseerd voor meertalige vertaling, financiën, recht en medische domeinen.",
  "hunyuan-role.description": "Het nieuwste rollenspelmodel, officieel getraind op rollenspeldata, met verbeterde prestaties voor rollenspeltoepassingen.",
  "hunyuan-standard-256K.description": "Maakt gebruik van verbeterde routering om load balancing en expertverval te voorkomen. Behaalt 99,9% 'needle-in-a-haystack'-score op lange context. MOE-256K breidt contextlengte en kwaliteit verder uit.",
  "hunyuan-standard-vision.description": "Het nieuwste multimodale model met meertalige antwoorden en gebalanceerde Chinese/Engelse vaardigheden.",
  "hunyuan-standard.description": "Maakt gebruik van verbeterde routering om load balancing en expertverval te voorkomen. Behaalt 99,9% 'needle-in-a-haystack'-score op lange context. MOE-32K biedt sterke prestaties bij lange invoer.",
  "hunyuan-t1-20250321.description": "Combineert evenwichtige artistieke en bètavaardigheden met sterk langetekstinformatiebegrip. Ondersteunt redenerende antwoorden voor wiskunde-, logica-, wetenschap- en programmeerproblemen op verschillende niveaus.",
  "hunyuan-t1-20250403.description": "Verbetert projectmatige codegeneratie en schrijfkwaliteit, versterkt begrip van meerstapsgesprekken en ToB-instructies, verbetert woordbegrip en vermindert problemen met gemengde vereenvoudigde/traditionele en Chinese/Engelse output.",
  "hunyuan-t1-20250529.description": "Verbetert creatief schrijven en compositie, versterkt frontend-programmeren, wiskunde en logische redenering, en verbetert het opvolgen van instructies.",
  "hunyuan-t1-20250711.description": "Verbetert aanzienlijk de prestaties bij moeilijke wiskunde, logica en programmeren, verhoogt de outputstabiliteit en versterkt langetekstcapaciteiten.",
  "hunyuan-t1-latest.description": "Verbetert het langzaam-denkende model aanzienlijk op het gebied van moeilijke wiskunde, complexe redenering, uitdagende codeertaken, instructieopvolging en creatieve schrijfkwaliteit.",
  "hunyuan-t1-vision-20250619.description": "Het nieuwste t1-vision multimodale diep-redeneermodel met native keten-van-gedachten, aanzienlijk verbeterd ten opzichte van de vorige standaardversie.",
  "hunyuan-t1-vision-20250916.description": "Het nieuwste t1-vision diep-redeneermodel met grote verbeteringen in VQA, visuele verankering, OCR, grafieken, het oplossen van gefotografeerde problemen en beeldgebaseerde creatie, plus sterkere prestaties in Engels en talen met weinig middelen.",
  "hunyuan-turbo-20241223.description": "Deze versie verbetert de schaalbaarheid van instructies voor betere generalisatie, verhoogt de prestaties in wiskunde/code/logica, verbetert woordbegrip en verhoogt de schrijfkwaliteit.",
  "hunyuan-turbo-latest.description": "Algemene verbeteringen in NLP-begrip, schrijven, chatten, vraag-antwoord, vertaling en domeinspecifieke toepassingen; menselijkere reacties, betere verduidelijking van onduidelijke intenties, verbeterde woordanalyse, hogere creatieve kwaliteit en interactiviteit, en sterkere meerstapsgesprekken.",
  "hunyuan-turbo-vision.description": "Volgende generatie visueel-taalkundig vlaggenschip met een nieuwe MoE-architectuur, met brede verbeteringen in herkenning, contentcreatie, kennisvraag-antwoord en analytisch redeneren.",
  "hunyuan-turbo.description": "Voorvertoning van Hunyuan’s volgende generatie LLM met een nieuwe MoE-architectuur, levert snellere redenering en sterkere resultaten dan hun hunyuan-pro.",
  "hunyuan-turbos-20250313.description": "Vereenvoudigt de stijl van wiskundige oplossingen en versterkt meerstaps wiskundige vraag-antwoord. De schrijfstijl is verfijnd om een minder AI-achtig karakter te hebben en meer gepolijst te zijn.",
  "hunyuan-turbos-20250416.description": "Geüpgradede pretrainingbasis voor beter begrip en opvolging van instructies; afstemming verbetert wiskunde, code, logica en wetenschap; verhoogt schrijfkwaliteit, begrip, vertaalnauwkeurigheid en kennisvraag-antwoord; versterkt agentvaardigheden, vooral bij meerstapsbegrip.",
  "hunyuan-turbos-20250604.description": "Geüpgradede pretrainingbasis met verbeterd schrijven en leesbegrip, aanzienlijke vooruitgang in code en STEM, en beter opvolgen van complexe instructies.",
  "hunyuan-turbos-20250926.description": "Verbeterde kwaliteit van pretrainingdata en post-trainingsstrategie, met verbeteringen in agenten, Engels/talen met weinig middelen, instructieopvolging, code en STEM-vaardigheden.",
  "hunyuan-turbos-latest.description": "Het nieuwste Hunyuan TurboS vlaggenschipmodel met sterkere redenering en een betere algehele ervaring.",
  "hunyuan-turbos-longtext-128k-20250325.description": "Blinkt uit in taken met lange documenten zoals samenvattingen en vraag-antwoord, en is ook sterk in algemene tekstgeneratie. Uitstekend in analyse en generatie van complexe, gedetailleerde lange teksten.",
  "hunyuan-turbos-role-plus.description": "Het nieuwste rollenspelmodel, officieel getraind op rollenspeldata, met verbeterde prestaties voor rollenspeltoepassingen.",
  "hunyuan-turbos-vision-20250619.description": "Het nieuwste TurboS visueel-taalkundig vlaggenschip met grote verbeteringen in beeld-teksttaken zoals entiteitsherkenning, kennisvraag-antwoord, copywriting en het oplossen van problemen op basis van foto's.",
  "hunyuan-turbos-vision.description": "Een visueel-taalkundig vlaggenschip van de volgende generatie gebaseerd op de nieuwste TurboS, gericht op beeld-tekstbegriptaken zoals entiteitsherkenning, kennisvraag-antwoord, copywriting en het oplossen van problemen op basis van foto's.",
  "hunyuan-vision-1.5-instruct.description": "Een snel denkend model dat tekst genereert op basis van afbeeldingen, gebouwd op het TurboS-platform. Vergeleken met de vorige versie zijn de prestaties op het gebied van beeldherkenning en visuele redenatie aanzienlijk verbeterd.",
  "hunyuan-vision.description": "Het nieuwste multimodale model dat tekst genereert op basis van gecombineerde beeld- en tekstinvoer.",
  "image-01-live.description": "Een beeldgeneratiemodel met fijne details, dat tekst-naar-beeld en aanpasbare stijlpresets ondersteunt.",
  "image-01.description": "Een nieuw beeldgeneratiemodel met fijne details, dat zowel tekst-naar-beeld als beeld-naar-beeld ondersteunt.",
  "imagen-4.0-fast-generate-001.description": "Snelle versie van de vierde generatie Imagen tekst-naar-beeld modelserie.",
  "imagen-4.0-generate-001.description": "Vierde generatie Imagen tekst-naar-beeld modelserie.",
  "imagen-4.0-generate-preview-06-06.description": "De vierde generatie tekst-naar-beeld modellen van Imagen.",
  "imagen-4.0-ultra-generate-001.description": "Ultra-versie van de vierde generatie Imagen tekst-naar-beeld modelserie.",
  "imagen-4.0-ultra-generate-preview-06-06.description": "Ultra-variant van de vierde generatie tekst-naar-beeld modellen van Imagen.",
  "inception/mercury-coder-small.description": "Mercury Coder Small is ideaal voor codegeneratie, foutopsporing en herstructurering met minimale vertraging.",
  "inclusionAI/Ling-flash-2.0.description": "Ling-flash-2.0 is het derde model in de Ling 2.0-architectuur van het Bailing-team van Ant Group. Het is een MoE-model met 100 miljard parameters, waarvan slechts 6,1 miljard actief per token (4,8 miljard exclusief embedding). Ondanks de lichte configuratie presteert het gelijk aan of beter dan dichte modellen van 40 miljard en grotere MoE-modellen op meerdere benchmarks, dankzij een efficiënte architectuur en trainingsstrategie.",
  "inclusionAI/Ling-mini-2.0.description": "Ling-mini-2.0 is een klein, krachtig MoE LLM met 16 miljard parameters en slechts 1,4 miljard actief per token (789 miljoen exclusief embedding), wat zorgt voor zeer snelle generatie. Dankzij een efficiënte MoE-architectuur en hoogwaardige trainingsdata levert het topprestaties die vergelijkbaar zijn met dichte modellen onder 10 miljard en grotere MoE-modellen.",
  "inclusionAI/Ring-flash-2.0.description": "Ring-flash-2.0 is een krachtig redeneermodel, geoptimaliseerd vanuit Ling-flash-2.0-base. Het gebruikt een MoE-architectuur met 100 miljard parameters en slechts 6,1 miljard actief per inferentie. Het icepop-algoritme stabiliseert RL-training voor MoE-modellen, wat leidt tot voortdurende verbeteringen in complexe redenatie. Het behaalt doorbraken op moeilijke benchmarks (wiskundewedstrijden, codegeneratie, logische redenatie), overtreft dichte modellen onder 40 miljard en evenaart grotere open en gesloten redenatiemodellen. Het presteert ook goed in creatief schrijven en biedt snelle inferentie tegen lage kosten voor toepassingen met hoge gelijktijdigheid.",
  "inclusionai/ling-1t.description": "Ling-1T is inclusionAI’s 1T MoE-model, geoptimaliseerd voor intensieve redeneertaken en werklasten met grote context.",
  "inclusionai/ling-flash-2.0.description": "Ling-flash-2.0 is inclusionAI’s MoE-model, geoptimaliseerd voor efficiëntie en redeneervermogen, geschikt voor middelgrote tot grote taken.",
  "inclusionai/ling-mini-2.0.description": "Ling-mini-2.0 is inclusionAI’s lichte MoE-model dat de kosten aanzienlijk verlaagt zonder in te boeten op redeneercapaciteit.",
  "inclusionai/ming-flash-omini-preview.description": "Ming-flash-omni Preview is inclusionAI’s multimodale model dat spraak-, beeld- en video-invoer ondersteunt, met verbeterde beeldweergave en spraakherkenning.",
  "inclusionai/ring-1t.description": "Ring-1T is inclusionAI’s triljoen-parameter MoE redeneermodel, geschikt voor grootschalige redeneer- en onderzoekstaken.",
  "inclusionai/ring-flash-2.0.description": "Ring-flash-2.0 is een variant van het Ring-model van inclusionAI voor scenario’s met hoge doorvoer, met nadruk op snelheid en kostenefficiëntie.",
  "inclusionai/ring-mini-2.0.description": "Ring-mini-2.0 is inclusionAI’s lichte MoE-model met hoge doorvoer, ontworpen voor gelijktijdige toepassingen.",
  "internlm/internlm2_5-7b-chat.description": "InternLM2.5-7B-Chat is een open-source chatmodel gebaseerd op de InternLM2-architectuur. Het 7B-model richt zich op dialooggeneratie met ondersteuning voor Chinees en Engels, en maakt gebruik van moderne trainingstechnieken voor vloeiende en intelligente gesprekken. Geschikt voor toepassingen zoals klantenservice en persoonlijke assistenten.",
  "internlm2.5-latest.description": "Legacy-modellen die nog steeds worden onderhouden met uitstekende, stabiele prestaties na vele iteraties. Beschikbaar in 7B- en 20B-varianten, met ondersteuning voor 1M context en verbeterde instructieopvolging en toolgebruik. Standaard ingesteld op de nieuwste InternLM2.5-serie (momenteel internlm2.5-20b-chat).",
  "internlm3-latest.description": "Onze nieuwste modelserie met uitstekende redeneercapaciteiten, toonaangevend onder open modellen in zijn klasse. Standaard ingesteld op de nieuwste InternLM3-serie (momenteel internlm3-8b-instruct).",
  "internvl2.5-38b-mpo.description": "InternVL2.5 38B MPO is een multimodaal voorgetraind model voor complexe beeld-tekst redenatie.",
  "internvl2.5-latest.description": "InternVL2.5 wordt nog steeds onderhouden met sterke, stabiele prestaties. Standaard ingesteld op de nieuwste InternVL2.5-serie (momenteel internvl2.5-78b).",
  "internvl3-14b.description": "InternVL3 14B is een middelgroot multimodaal model dat prestaties en kosten in balans houdt.",
  "internvl3-1b.description": "InternVL3 1B is een lichtgewicht multimodaal model voor implementatie in omgevingen met beperkte middelen.",
  "internvl3-38b.description": "InternVL3 38B is een groot open-source multimodaal model voor nauwkeurige beeld-tekst interpretatie.",
  "internvl3-latest.description": "Ons nieuwste multimodale model met verbeterd begrip van beeld-tekst en lange sequenties, vergelijkbaar met toonaangevende gesloten modellen. Standaard ingesteld op de nieuwste InternVL-serie (momenteel internvl3-78b).",
  "irag-1.0.description": "ERNIE iRAG is een model voor beeldopzoeking-ondersteunde generatie, geschikt voor beeldzoekopdrachten, beeld-tekstopzoeking en contentcreatie.",
  "jamba-large.description": "Ons krachtigste en meest geavanceerde model, ontworpen voor complexe zakelijke taken met uitstekende prestaties.",
  "jamba-mini.description": "Het meest efficiënte model in zijn klasse, met een optimale balans tussen snelheid en kwaliteit en een kleinere omvang.",
  "jina-deepsearch-v1.description": "DeepSearch combineert webzoekopdrachten, lezen en redeneren voor diepgaand onderzoek. Zie het als een agent die jouw onderzoekstaak uitvoert, brede zoekopdrachten doet in meerdere iteraties en pas daarna een antwoord formuleert. Het proces omvat voortdurend onderzoek, redenering en probleemoplossing vanuit meerdere invalshoeken, fundamenteel anders dan standaard LLM’s die antwoorden geven op basis van voorgetrainde data of traditionele RAG-systemen die vertrouwen op eenmalige oppervlakkige zoekopdrachten.",
  "kimi-k2-0711-preview.description": "kimi-k2 is een MoE-basismodel met sterke programmeer- en agentvaardigheden (1T totale parameters, 32B actief), dat beter presteert dan andere gangbare open modellen op het gebied van redeneren, programmeren, wiskunde en agentbenchmarks.",
  "kimi-k2-0905-preview.description": "kimi-k2-0905-preview biedt een contextvenster van 256k, sterkere agentmatige codeerprestaties, betere kwaliteit van front-end code en verbeterd contextbegrip.",
  "kimi-k2-instruct.description": "Kimi K2 Instruct is het officiële redeneermodel van Kimi met lange contextondersteuning voor code, vraag-en-antwoord en meer.",
  "kimi-k2-thinking-turbo.description": "Snelle K2-variant voor diepgaand denken met 256k context, sterke redenering en een uitvoersnelheid van 60–100 tokens/seconde.",
  "kimi-k2-thinking.description": "kimi-k2-thinking is een Moonshot AI-denkmodel met algemene agent- en redeneervaardigheden. Het blinkt uit in diepgaand redeneren en kan complexe problemen oplossen via meerstapsgebruik van tools.",
  "kimi-k2-turbo-preview.description": "kimi-k2 is een MoE-basismodel met sterke programmeer- en agentvaardigheden (1T totale parameters, 32B actief), dat beter presteert dan andere gangbare open modellen op het gebied van redeneren, programmeren, wiskunde en agentbenchmarks.",
  "kimi-k2.5.description": "Kimi K2.5 is het meest capabele Kimi-model, met open-source SOTA-prestaties in agenttaken, programmeren en visueel begrip. Het ondersteunt multimodale invoer en zowel denk- als niet-denkmodi.",
  "kimi-k2.description": "Kimi-K2 is een MoE-basismodel van Moonshot AI met sterke programmeer- en agentvaardigheden, met in totaal 1T parameters waarvan 32B actief. Het presteert beter dan andere gangbare open modellen op benchmarks voor algemeen redeneren, programmeren, wiskunde en agenttaken.",
  "kimi-k2:1t.description": "Kimi K2 is een groot MoE LLM van Moonshot AI met 1T totale parameters en 32B actief per voorwaartse stap. Het is geoptimaliseerd voor agentvaardigheden zoals geavanceerd toolgebruik, redeneren en codesynthese.",
  "kimi-latest.description": "Kimi Latest gebruikt het nieuwste Kimi-model en kan experimentele functies bevatten. Het ondersteunt beeldbegrip en kiest automatisch 8k/32k/128k factureringsmodellen op basis van contextlengte.",
  "kuaishou/kat-coder-pro-v1.description": "KAT-Coder-Pro-V1 (tijdelijk gratis) richt zich op codebegrip en automatisering voor efficiënte programmeeragents.",
  "learnlm-1.5-pro-experimental.description": "LearnLM is een experimenteel, taakspecifiek model dat is getraind op basis van leerwetenschappelijke principes om systeeminstructies te volgen in onderwijs-/leerscenario’s en fungeert als een deskundige tutor.",
  "learnlm-2.0-flash-experimental.description": "LearnLM is een experimenteel, taakspecifiek model dat is getraind op basis van leerwetenschappelijke principes om systeeminstructies te volgen in onderwijs-/leerscenario’s en fungeert als een deskundige tutor.",
  "lite.description": "Spark Lite is een lichtgewicht LLM met ultralage latentie en efficiënte verwerking. Het is volledig gratis en ondersteunt realtime webzoekopdrachten. Dankzij snelle reacties presteert het goed op apparaten met beperkte rekenkracht en voor modelafstemming, met sterke kostenefficiëntie en een slimme ervaring, vooral voor kennisvragen, contentgeneratie en zoekscenario’s.",
  "llama-3.1-70b-versatile.description": "Llama 3.1 70B biedt sterkere AI-redenering voor complexe toepassingen, met ondersteuning voor zware berekeningen met hoge efficiëntie en nauwkeurigheid.",
  "llama-3.1-8b-instant.description": "Llama 3.1 8B is een efficiënt model met snelle tekstgeneratie, ideaal voor grootschalige, kosteneffectieve toepassingen.",
  "llama-3.1-instruct.description": "Het op instructies afgestemde Llama 3.1-model is geoptimaliseerd voor chat en presteert beter dan veel open chatmodellen op gangbare industriële benchmarks.",
  "llama-3.2-11b-vision-instruct.description": "Sterke beeldredenering op hoge-resolutiebeelden, geschikt voor toepassingen met visueel begrip.",
  "llama-3.2-11b-vision-preview.description": "Llama 3.2 is ontworpen voor taken die visie en tekst combineren, en blinkt uit in beeldonderschriftgeneratie en visuele vraag-en-antwoord, waarmee het de kloof overbrugt tussen taalproductie en visuele redenering.",
  "llama-3.2-90b-vision-instruct.description": "Geavanceerde beeldredenering voor toepassingen met visueel begrip door agents.",
  "llama-3.2-90b-vision-preview.description": "Llama 3.2 is ontworpen voor taken die visie en tekst combineren, en blinkt uit in beeldonderschriftgeneratie en visuele vraag-en-antwoord, waarmee het de kloof overbrugt tussen taalproductie en visuele redenering.",
  "llama-3.2-vision-instruct.description": "Het op instructies afgestemde Llama 3.2-Vision-model is geoptimaliseerd voor visuele herkenning, beeldredenering, onderschriftgeneratie en algemene beeldvraag-en-antwoord.",
  "llama-3.3-70b-versatile.description": "Meta Llama 3.3 is een meertalig LLM met 70B parameters (tekst in/tekst uit), beschikbaar als voorgetrainde en op instructies afgestemde varianten. De tekst-only instructieversie is geoptimaliseerd voor meertalige dialoogtoepassingen en presteert beter dan veel open en gesloten chatmodellen op gangbare industriële benchmarks.",
  "llama-3.3-70b.description": "Llama 3.3 70B: een middelgroot tot groot Llama-model dat redenering en verwerkingssnelheid in balans houdt.",
  "llama-3.3-instruct.description": "Het op instructies afgestemde Llama 3.3-model is geoptimaliseerd voor chat en presteert beter dan veel open chatmodellen op gangbare industriële benchmarks.",
  "llama3-70b-8192.description": "Meta Llama 3 70B biedt uitzonderlijke complexiteitsverwerking voor veeleisende projecten.",
  "llama3-8b-8192.description": "Meta Llama 3 8B levert sterke redeneercapaciteiten voor uiteenlopende scenario’s.",
  "llama3-groq-70b-8192-tool-use-preview.description": "Llama 3 Groq 70B Tool Use biedt sterke tool-aanroepmogelijkheden voor efficiënte verwerking van complexe taken.",
  "llama3-groq-8b-8192-tool-use-preview.description": "Llama 3 Groq 8B Tool Use is geoptimaliseerd voor efficiënt gebruik van tools met snelle parallelle verwerking.",
  "llama3.1-8b.description": "Llama 3.1 8B: een kleine, laag-latentievariant van Llama voor lichte online inferentie en chat.",
  "llama3.1.description": "Llama 3.1 is het toonaangevende model van Meta, schaalbaar tot 405B parameters voor complexe dialogen, meertalige vertaling en data-analyse.",
  "llama3.1:405b.description": "Llama 3.1 is het toonaangevende model van Meta, schaalbaar tot 405B parameters voor complexe dialogen, meertalige vertaling en data-analyse.",
  "llama3.1:70b.description": "Llama 3.1 is het toonaangevende model van Meta, schaalbaar tot 405B parameters voor complexe dialogen, meertalige vertaling en data-analyse.",
  "llava-v1.5-7b-4096-preview.description": "LLaVA 1.5 7B combineert visuele verwerking om complexe uitvoer te genereren op basis van visuele input.",
  "llava.description": "LLaVA is een multimodaal model dat een visie-encoder en Vicuna combineert voor sterk visueel-taalbegrip.",
  "llava:13b.description": "LLaVA is een multimodaal model dat een visie-encoder en Vicuna combineert voor sterk visueel-taalbegrip.",
  "llava:34b.description": "LLaVA is een multimodaal model dat een visie-encoder en Vicuna combineert voor sterk visueel-taalbegrip.",
  "magistral-medium-latest.description": "Magistral Medium 1.2 is een geavanceerd redeneermodel van Mistral AI (sep 2025) met visuele ondersteuning.",
  "magistral-small-2509.description": "Magistral Small 1.2 is een open-source klein redeneermodel van Mistral AI (sep 2025) met visuele ondersteuning.",
  "mathstral.description": "MathΣtral is ontwikkeld voor wetenschappelijk onderzoek en wiskundig redeneren, met sterke rekenkracht en uitlegmogelijkheden.",
  "max-32k.description": "Spark Max 32K biedt verwerking van grote contexten met beter contextbegrip en logisch redeneren, en ondersteunt 32K-tokeninvoer voor het lezen van lange documenten en privékennis-vraag-en-antwoord.",
  "megrez-3b-instruct.description": "Megrez 3B Instruct is een klein, efficiënt model van Wuwen Xinqiong.",
  "meituan/longcat-flash-chat.description": "Een open-source basismodel zonder denkvermogen van Meituan, geoptimaliseerd voor dialoog- en agenttaken, sterk in toolgebruik en complexe meerstapsinteracties.",
  "meta-llama-3-70b-instruct.description": "Een krachtig model met 70 miljard parameters dat uitblinkt in redeneren, coderen en brede taaltaken.",
  "meta-llama-3-8b-instruct.description": "Een veelzijdig model met 8 miljard parameters, geoptimaliseerd voor chat en tekstgeneratie.",
  "meta-llama-3.1-405b-instruct.description": "Llama 3.1 is een instructie-afgestemd tekstmodel, geoptimaliseerd voor meertalige chat, met sterke prestaties op gangbare industriële benchmarks onder open en gesloten chatmodellen.",
  "meta-llama-3.1-70b-instruct.description": "Llama 3.1 is een instructie-afgestemd tekstmodel, geoptimaliseerd voor meertalige chat, met sterke prestaties op gangbare industriële benchmarks onder open en gesloten chatmodellen.",
  "meta-llama-3.1-8b-instruct.description": "Llama 3.1 is een instructie-afgestemd tekstmodel, geoptimaliseerd voor meertalige chat, met sterke prestaties op gangbare industriële benchmarks onder open en gesloten chatmodellen.",
  "meta-llama/Llama-2-13b-chat-hf.description": "LLaMA-2 Chat (13B) biedt sterke taalverwerking en een solide chatervaring.",
  "meta-llama/Llama-2-70b-hf.description": "LLaMA-2 biedt sterke taalverwerking en een solide interactie-ervaring.",
  "meta-llama/Llama-3-70b-chat-hf.description": "Llama 3 70B Instruct Reference is een krachtig chatmodel voor complexe dialogen.",
  "meta-llama/Llama-3-8b-chat-hf.description": "Llama 3 8B Instruct Reference biedt meertalige ondersteuning en brede domeinkennis.",
  "meta-llama/Llama-3.2-11B-Vision-Instruct-Turbo.description": "LLaMA 3.2 is ontworpen voor taken die visie en tekst combineren. Het blinkt uit in beeldonderschrift en visuele vraag-en-antwoord, en overbrugt taalproductie en visueel redeneren.",
  "meta-llama/Llama-3.2-3B-Instruct-Turbo.description": "LLaMA 3.2 is ontworpen voor taken die visie en tekst combineren. Het blinkt uit in beeldonderschrift en visuele vraag-en-antwoord, en overbrugt taalproductie en visueel redeneren.",
  "meta-llama/Llama-3.2-90B-Vision-Instruct-Turbo.description": "LLaMA 3.2 is ontworpen voor taken die visie en tekst combineren. Het blinkt uit in beeldonderschrift en visuele vraag-en-antwoord, en overbrugt taalproductie en visueel redeneren.",
  "meta-llama/Llama-3.3-70B-Instruct-Turbo.description": "Meta Llama 3.3 is een meertalig LLM met 70 miljard parameters (tekst-in/tekst-uit), voorgetraind en afgestemd op instructies. De instructie-afgestemde tekstversie is geoptimaliseerd voor meertalige chat en presteert beter dan veel open en gesloten chatmodellen op gangbare benchmarks.",
  "meta-llama/Llama-Vision-Free.description": "LLaMA 3.2 is ontworpen voor taken die visie en tekst combineren. Het blinkt uit in beeldonderschrift en visuele vraag-en-antwoord, en overbrugt taalproductie en visueel redeneren.",
  "meta-llama/Meta-Llama-3-70B-Instruct-Lite.description": "Llama 3 70B Instruct Lite is gebouwd voor hoge prestaties met lagere latentie.",
  "meta-llama/Meta-Llama-3-70B-Instruct-Turbo.description": "Llama 3 70B Instruct Turbo levert sterk begrip en generatie voor de meest veeleisende werklasten.",
  "meta-llama/Meta-Llama-3-8B-Instruct-Lite.description": "Llama 3 8B Instruct Lite biedt een goede balans tussen prestaties en middelen voor omgevingen met beperkte capaciteit.",
  "meta-llama/Meta-Llama-3-8B-Instruct-Turbo.description": "Llama 3 8B Instruct Turbo is een krachtig LLM voor een breed scala aan toepassingen.",
  "meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo.description": "Het 405B Llama 3.1 Turbo-model biedt enorme contextcapaciteit voor big data-verwerking en blinkt uit in grootschalige AI-toepassingen.",
  "meta-llama/Meta-Llama-3.1-405B-Instruct.description": "Llama 3.1 is Meta’s toonaangevende modelfamilie, met opschaling tot 405 miljard parameters voor complexe dialogen, meertalige vertaling en data-analyse.",
  "meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo.description": "Llama 3.1 70B is fijn afgestemd voor toepassingen met hoge belasting; FP8-kwantisatie zorgt voor efficiënte berekening en nauwkeurigheid in complexe scenario’s.",
  "meta-llama/Meta-Llama-3.1-70B.description": "Llama 3.1 is Meta’s toonaangevende modelfamilie, met opschaling tot 405 miljard parameters voor complexe dialogen, meertalige vertaling en data-analyse.",
  "meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo.description": "Llama 3.1 8B gebruikt FP8-kwantisatie, ondersteunt tot 131.072 contexttokens en behoort tot de top van open modellen voor complexe taken op veel benchmarks.",
  "meta-llama/llama-3-70b-instruct.description": "Llama 3 70B Instruct is geoptimaliseerd voor hoogwaardige dialogen en presteert sterk in menselijke evaluaties.",
  "meta-llama/llama-3-8b-instruct.description": "Llama 3 8B Instruct is geoptimaliseerd voor hoogwaardige dialogen en presteert beter dan veel gesloten modellen.",
  "meta-llama/llama-3.1-70b-instruct.description": "De nieuwste Llama 3.1-serie van Meta, de 70B instructie-afgestemde variant, geoptimaliseerd voor hoogwaardige dialogen. In industriële evaluaties toont het sterke prestaties ten opzichte van toonaangevende gesloten modellen. (Alleen beschikbaar voor geverifieerde zakelijke gebruikers.)",
  "meta-llama/llama-3.1-8b-instruct.description": "De nieuwste Llama 3.1-serie van Meta, de 8B instructie-afgestemde variant, is bijzonder snel en efficiënt. In industriële evaluaties levert het sterke prestaties en overtreft het veel toonaangevende gesloten modellen. (Alleen beschikbaar voor geverifieerde zakelijke gebruikers.)",
  "meta-llama/llama-3.1-8b-instruct:free.description": "LLaMA 3.1 biedt meertalige ondersteuning en is een van de toonaangevende generatieve modellen.",
  "meta-llama/llama-3.2-11b-vision-instruct.description": "LLaMA 3.2 is ontworpen voor taken die visie en tekst combineren. Het blinkt uit in beeldonderschrijving en visuele vraagbeantwoording, en overbrugt taalproductie en visueel redeneren.",
  "meta-llama/llama-3.2-3b-instruct.description": "meta-llama/llama-3.2-3b-instruct",
  "meta-llama/llama-3.2-90b-vision-instruct.description": "LLaMA 3.2 is ontworpen voor taken die visie en tekst combineren. Het blinkt uit in beeldonderschrijving en visuele vraagbeantwoording, en overbrugt taalproductie en visueel redeneren.",
  "meta-llama/llama-3.3-70b-instruct.description": "Llama 3.3 is het meest geavanceerde meertalige open-source Llama-model, met prestaties vergelijkbaar met 405B tegen zeer lage kosten. Het is gebaseerd op een Transformer-architectuur en verbeterd met SFT en RLHF voor bruikbaarheid en veiligheid. De instructie-afgestemde versie is geoptimaliseerd voor meertalige gesprekken en overtreft veel open en gesloten chatmodellen op industriestandaarden. Kennisgrens: dec 2023.",
  "meta-llama/llama-3.3-70b-instruct:free.description": "Llama 3.3 is het meest geavanceerde meertalige open-source Llama-model, met prestaties vergelijkbaar met 405B tegen zeer lage kosten. Het is gebaseerd op een Transformer-architectuur en verbeterd met SFT en RLHF voor bruikbaarheid en veiligheid. De instructie-afgestemde versie is geoptimaliseerd voor meertalige gesprekken en overtreft veel open en gesloten chatmodellen op industriestandaarden. Kennisgrens: dec 2023.",
  "meta.llama3-1-405b-instruct-v1:0.description": "Meta Llama 3.1 405B Instruct is het grootste en krachtigste Llama 3.1 Instruct-model, een zeer geavanceerd model voor dialoogredenering en synthetische datageneratie, en een sterke basis voor domeinspecifieke voortgezette pretraining of fine-tuning. De meertalige Llama 3.1 LLMs zijn een reeks voorgetrainde en instructie-afgestemde generatiemodellen in 8B-, 70B- en 405B-varianten (tekst in/tekst uit). De instructie-afgestemde modellen zijn geoptimaliseerd voor meertalige dialogen en presteren beter dan veel beschikbare open chatmodellen op gangbare benchmarks. Llama 3.1 is ontworpen voor commercieel en onderzoeksgebruik in meerdere talen. Instructie-afgestemde modellen zijn geschikt voor assistentachtige gesprekken, terwijl voorgetrainde modellen breder inzetbaar zijn voor natuurlijke taalproductie. De output van Llama 3.1 kan ook worden gebruikt om andere modellen te verbeteren, waaronder synthetische datageneratie en verfijning. Llama 3.1 is een autoregressief Transformer-model met een geoptimaliseerde architectuur. De afgestemde versies gebruiken gesuperviseerde fine-tuning (SFT) en reinforcement learning op basis van menselijke feedback (RLHF) om af te stemmen op menselijke voorkeuren voor behulpzaamheid en veiligheid.",
  "meta.llama3-1-70b-instruct-v1:0.description": "Een bijgewerkte Meta Llama 3.1 70B Instruct met een uitgebreid contextvenster van 128K, meertalige ondersteuning en verbeterd redeneervermogen. De meertalige Llama 3.1 LLMs zijn een reeks voorgetrainde en instructie-afgestemde generatiemodellen in 8B-, 70B- en 405B-varianten (tekst in/tekst uit). De instructie-afgestemde modellen zijn geoptimaliseerd voor meertalige dialogen en presteren beter dan veel beschikbare open chatmodellen op gangbare benchmarks. Llama 3.1 is ontworpen voor commercieel en onderzoeksgebruik in meerdere talen. Instructie-afgestemde modellen zijn geschikt voor assistentachtige gesprekken, terwijl voorgetrainde modellen breder inzetbaar zijn voor natuurlijke taalproductie. De output van Llama 3.1 kan ook worden gebruikt om andere modellen te verbeteren, waaronder synthetische datageneratie en verfijning. Llama 3.1 is een autoregressief Transformer-model met een geoptimaliseerde architectuur. De afgestemde versies gebruiken gesuperviseerde fine-tuning (SFT) en reinforcement learning op basis van menselijke feedback (RLHF) om af te stemmen op menselijke voorkeuren voor behulpzaamheid en veiligheid.",
  "meta.llama3-1-8b-instruct-v1:0.description": "Een bijgewerkte Meta Llama 3.1 8B Instruct met een contextvenster van 128K, meertalige ondersteuning en verbeterd redeneervermogen. De Llama 3.1-familie omvat 8B-, 70B- en 405B-instructie-afgestemde tekstmodellen die geoptimaliseerd zijn voor meertalige gesprekken en sterke benchmarkprestaties leveren. Het is ontworpen voor commercieel en onderzoeksgebruik in meerdere talen; instructie-afgestemde modellen zijn geschikt voor assistentachtige gesprekken, terwijl voorgetrainde modellen breder inzetbaar zijn voor tekstgeneratie. De output van Llama 3.1 kan ook worden gebruikt om andere modellen te verbeteren (bijv. synthetische data en verfijning). Het is een autoregressief Transformer-model, met SFT en RLHF om af te stemmen op behulpzaamheid en veiligheid.",
  "meta.llama3-70b-instruct-v1:0.description": "Meta Llama 3 is een open LLM voor ontwikkelaars, onderzoekers en bedrijven, ontworpen om hen te helpen generatieve AI-ideeën te bouwen, te experimenteren en verantwoord op te schalen. Als onderdeel van de basis voor wereldwijde gemeenschapsinnovatie is het goed geschikt voor contentcreatie, conversatie-AI, taalbegrip, R&D en zakelijke toepassingen.",
  "meta.llama3-8b-instruct-v1:0.description": "Meta Llama 3 is een open LLM voor ontwikkelaars, onderzoekers en bedrijven, ontworpen om hen te helpen bij het bouwen, experimenteren en verantwoord opschalen van generatieve AI-ideeën. Als onderdeel van de basis voor wereldwijde gemeenschapsinnovatie is het goed geschikt voor beperkte rekenkracht en middelen, edge-apparaten en snellere trainingstijden.",
  "meta/Llama-3.2-11B-Vision-Instruct.description": "Sterke beeldredenering op afbeeldingen met hoge resolutie, geschikt voor toepassingen voor visueel begrip.",
  "meta/Llama-3.2-90B-Vision-Instruct.description": "Geavanceerde beeldredenering voor toepassingen met visueel begrip en agentfunctionaliteit.",
  "meta/Llama-3.3-70B-Instruct.description": "Llama 3.3 is het meest geavanceerde meertalige open-source Llama-model, met prestaties vergelijkbaar met 405B tegen zeer lage kosten. Het is gebaseerd op een Transformer-architectuur en verbeterd met SFT en RLHF voor bruikbaarheid en veiligheid. De instructie-afgestemde versie is geoptimaliseerd voor meertalige chat en overtreft veel open en gesloten chatmodellen op industriestandaarden. Kennisgrens: december 2023.",
  "meta/Meta-Llama-3-70B-Instruct.description": "Een krachtig model met 70 miljard parameters dat uitblinkt in redeneren, coderen en brede taaltaken.",
  "meta/Meta-Llama-3-8B-Instruct.description": "Een veelzijdig model met 8 miljard parameters, geoptimaliseerd voor chat en tekstgeneratie.",
  "meta/Meta-Llama-3.1-405B-Instruct.description": "Llama 3.1 instructie-afgestemd tekstmodel, geoptimaliseerd voor meertalige chat, met sterke prestaties op gangbare industriestandaarden onder open en gesloten chatmodellen.",
  "meta/Meta-Llama-3.1-70B-Instruct.description": "Llama 3.1 instructie-afgestemd tekstmodel, geoptimaliseerd voor meertalige chat, met sterke prestaties op gangbare industriestandaarden onder open en gesloten chatmodellen.",
  "meta/Meta-Llama-3.1-8B-Instruct.description": "Llama 3.1 instructie-afgestemd tekstmodel, geoptimaliseerd voor meertalige chat, met sterke prestaties op gangbare industriestandaarden onder open en gesloten chatmodellen.",
  "meta/llama-3-70b.description": "Een open-source model met 70 miljard parameters, door Meta fijngestemd voor het volgen van instructies, aangeboden door Groq op LPU-hardware voor snelle en efficiënte inferentie.",
  "meta/llama-3-8b.description": "Een open-source model met 8 miljard parameters, door Meta fijngestemd voor het volgen van instructies, aangeboden door Groq op LPU-hardware voor snelle en efficiënte inferentie.",
  "meta/llama-3.1-405b-instruct.description": "Een geavanceerd LLM dat synthetische datageneratie, kennisdistillatie en redenering ondersteunt voor chatbots, codering en domeinspecifieke taken.",
  "meta/llama-3.1-70b-instruct.description": "Ontworpen voor complexe dialogen met uitstekend contextbegrip, redenering en tekstgeneratie.",
  "meta/llama-3.1-70b.description": "Een bijgewerkte Meta Llama 3 70B Instruct met 128K context, meertalige ondersteuning en verbeterde redenering.",
  "meta/llama-3.1-8b-instruct.description": "Een geavanceerd model met sterke taalbegrip, redenering en tekstgeneratie.",
  "meta/llama-3.1-8b.description": "Llama 3.1 8B ondersteunt een contextvenster van 128K, ideaal voor realtime chat en data-analyse, en biedt aanzienlijke kostenbesparingen ten opzichte van grotere modellen. Aangeboden door Groq op LPU-hardware voor snelle, efficiënte inferentie.",
  "meta/llama-3.2-11b-vision-instruct.description": "Een toonaangevend vision-language model dat uitblinkt in hoogwaardige redenering op basis van afbeeldingen.",
  "meta/llama-3.2-11b.description": "Een instructie-afgestemd beeldredeneringsmodel (tekst+afbeelding input, tekst output), geoptimaliseerd voor visuele herkenning, beeldredenering, ondertiteling en algemene beeld-QA.",
  "meta/llama-3.2-1b-instruct.description": "Een geavanceerd klein taalmodel met sterk begrip, redenering en tekstgeneratie.",
  "meta/llama-3.2-1b.description": "Alleen-tekstmodel voor toepassingen op apparaten zoals meertalige lokale zoekopdrachten, samenvattingen en herschrijven.",
  "meta/llama-3.2-3b-instruct.description": "Een geavanceerd klein taalmodel met sterk begrip, redenering en tekstgeneratie.",
  "meta/llama-3.2-3b.description": "Alleen-tekstmodel, fijngestemd voor toepassingen op apparaten zoals meertalige lokale zoekopdrachten, samenvattingen en herschrijven.",
  "meta/llama-3.2-90b-vision-instruct.description": "Een toonaangevend vision-language model dat uitblinkt in hoogwaardige redenering op basis van afbeeldingen.",
  "meta/llama-3.2-90b.description": "Een instructie-afgestemd beeldredeneringsmodel (tekst+afbeelding input, tekst output), geoptimaliseerd voor visuele herkenning, beeldredenering, ondertiteling en algemene beeld-QA.",
  "meta/llama-3.3-70b-instruct.description": "Een geavanceerd LLM dat sterk is in redenering, wiskunde, gezond verstand en functieaanroepen.",
  "meta/llama-3.3-70b.description": "Een perfecte balans tussen prestaties en efficiëntie. Ontworpen voor hoogwaardige conversatie-AI in contentcreatie, zakelijke toepassingen en onderzoek, met sterk taalbegrip voor samenvattingen, classificatie, sentimentanalyse en codegeneratie.",
  "meta/llama-4-maverick.description": "De Llama 4-familie is een native multimodaal AI-model dat tekst- en multimodale ervaringen ondersteunt, met gebruik van MoE voor toonaangevend tekst- en beeldbegrip. Llama 4 Maverick is een 17B-model met 128 experts, aangeboden door DeepInfra.",
  "meta/llama-4-scout.description": "De Llama 4-familie is een native multimodaal AI-model dat tekst- en multimodale ervaringen ondersteunt, met gebruik van MoE voor toonaangevend tekst- en beeldbegrip. Llama 4 Scout is een 17B-model met 16 experts, aangeboden door DeepInfra.",
  "microsoft/Phi-3-medium-128k-instruct.description": "Hetzelfde Phi-3-medium model met een groter contextvenster voor RAG- of few-shot prompts.",
  "microsoft/Phi-3-medium-4k-instruct.description": "Een model met 14 miljard parameters van hogere kwaliteit dan Phi-3-mini, gericht op hoogwaardige, redeneerintensieve data.",
  "microsoft/Phi-3-mini-128k-instruct.description": "Hetzelfde Phi-3-mini model met een groter contextvenster voor RAG- of few-shot prompts.",
  "microsoft/Phi-3-mini-4k-instruct.description": "Het kleinste lid van de Phi-3-familie, geoptimaliseerd voor kwaliteit en lage latentie.",
  "microsoft/Phi-3-small-128k-instruct.description": "Hetzelfde Phi-3-small model met een groter contextvenster voor RAG- of few-shot prompts.",
  "microsoft/Phi-3-small-8k-instruct.description": "Een model met 7 miljard parameters van hogere kwaliteit dan Phi-3-mini, gericht op hoogwaardige, redeneerintensieve data.",
  "microsoft/Phi-3.5-mini-instruct.description": "Een bijgewerkte versie van het Phi-3-mini model.",
  "microsoft/Phi-3.5-vision-instruct.description": "Een bijgewerkte versie van het Phi-3-vision model.",
  "microsoft/WizardLM-2-8x22B.description": "WizardLM 2 is een taalmodel van Microsoft AI dat uitblinkt in complexe dialogen, meertalige taken, redeneren en assistenttoepassingen.",
  "microsoft/wizardlm-2-8x22b.description": "WizardLM-2 8x22B is Microsoft AI’s meest geavanceerde Wizard-model met zeer concurrerende prestaties.",
  "mimo-v2-flash.description": "MiMo-V2-Flash: Een efficiënt model voor redeneren, programmeren en agentfundamenten.",
  "minicpm-v.description": "MiniCPM-V is het volgende generatie multimodale model van OpenBMB met uitstekende OCR- en multimodale begripscapaciteiten voor uiteenlopende toepassingen.",
  "minimax-m2.1.description": "MiniMax-M2.1 is de nieuwste versie in de MiniMax-serie, geoptimaliseerd voor meertalige programmering en complexe real-world taken. Als AI-native model biedt MiniMax-M2.1 aanzienlijke verbeteringen in modelprestaties, ondersteuning voor agentframeworks en aanpassing aan meerdere scenario’s, met als doel bedrijven en individuen sneller te helpen bij het vinden van AI-native werk- en levensstijlen.",
  "minimax-m2.description": "MiniMax M2 is een efficiënt groot taalmodel dat speciaal is ontwikkeld voor programmeer- en agentworkflows.",
  "minimax/minimax-m2.1.description": "MiniMax-M2.1 is een lichtgewicht, geavanceerd groot taalmodel geoptimaliseerd voor programmeren, proxyworkflows en moderne applicatieontwikkeling, met schonere, beknoptere output en snellere reactietijden.",
  "minimax/minimax-m2.description": "MiniMax-M2 is een waardevol model dat uitblinkt in programmeer- en agenttaken voor veel technische scenario’s.",
  "minimaxai/minimax-m2.description": "MiniMax-M2 is een compact, snel en kosteneffectief MoE-model (230B totaal, 10B actief) gebouwd voor topprestaties in programmeren en agenttaken, met behoud van sterke algemene intelligentie. Het blinkt uit in bewerkingen over meerdere bestanden, code-uitvoerings- en correctielussen, testvalidatie en complexe toolchains.",
  "ministral-3b-latest.description": "Ministral 3B is het topmodel voor edge-toepassingen van Mistral.",
  "ministral-8b-latest.description": "Ministral 8B is een zeer kosteneffectief edge-model van Mistral.",
  "mistral-ai/Mistral-Large-2411.description": "Het vlaggenschipmodel van Mistral voor complexe taken die grootschalig redeneren of specialisatie vereisen (synthetische tekstgeneratie, codegeneratie, RAG of agents).",
  "mistral-ai/Mistral-Nemo.description": "Mistral Nemo is een geavanceerd LLM met toonaangevend redeneervermogen, wereldkennis en programmeercapaciteiten voor zijn formaat.",
  "mistral-ai/mistral-small-2503.description": "Mistral Small is geschikt voor elke taaltaak die hoge efficiëntie en lage latentie vereist.",
  "mistral-large-instruct.description": "Mistral-Large-Instruct-2407 is een geavanceerd dense LLM met 123 miljard parameters en toonaangevend redeneervermogen, kennis en programmeercapaciteiten.",
  "mistral-large-latest.description": "Mistral Large is het vlaggenschipmodel, sterk in meertalige taken, complexe redenering en codegeneratie—ideaal voor hoogwaardige toepassingen.",
  "mistral-large.description": "Mixtral Large is het vlaggenschipmodel van Mistral, dat codegeneratie, wiskunde en redenering combineert met een contextvenster van 128K.",
  "mistral-medium-latest.description": "Mistral Medium 3 levert toonaangevende prestaties tegen 8× lagere kosten en vereenvoudigt implementatie in ondernemingen.",
  "mistral-nemo-instruct.description": "Mistral-Nemo-Instruct-2407 is de instructie-afgestemde versie van Mistral-Nemo-Base-2407.",
  "mistral-nemo.description": "Mistral Nemo is een efficiënt 12B-model van Mistral AI en NVIDIA.",
  "mistral-small-latest.description": "Mistral Small is een kosteneffectieve, snelle en betrouwbare optie voor vertaling, samenvatting en sentimentanalyse.",
  "mistral-small.description": "Mistral Small is geschikt voor elke taaltaak die hoge efficiëntie en lage latentie vereist.",
  "mistral.description": "Mistral is het 7B-model van Mistral AI, geschikt voor uiteenlopende taaltaken.",
  "mistral/codestral-embed.description": "Een code-embeddingmodel voor het embedden van codebases en repositories ter ondersteuning van programmeerassistenten.",
  "mistral/codestral.description": "Mistral Codestral 25.01 is een geavanceerd programmeermodel geoptimaliseerd voor lage latentie en veelvuldig gebruik. Het ondersteunt meer dan 80 talen en blinkt uit in FIM, codecorrectie en testgeneratie.",
  "mistral/devstral-small.description": "Devstral is een agentisch LLM voor software-engineeringtaken, waardoor het een sterke keuze is voor softwareagents.",
  "mistral/magistral-medium.description": "Complex denken ondersteund door diep begrip met transparante redenering die je kunt volgen en verifiëren. Behoudt nauwkeurige redenering over talen heen, zelfs midden in een taak.",
  "mistral/magistral-small.description": "Complex denken ondersteund door diep begrip met transparante redenering die je kunt volgen en verifiëren. Behoudt nauwkeurige redenering over talen heen, zelfs midden in een taak.",
  "mistral/ministral-3b.description": "Een compact, efficiënt model voor on-device taken zoals assistenten en lokale analyses, met lage latentieprestaties.",
  "mistral/ministral-8b.description": "Een krachtiger model met snellere, geheugenefficiënte inferentie, ideaal voor complexe workflows en veeleisende edge-toepassingen.",
  "mistral/mistral-embed.description": "Een algemeen tekst-embeddingmodel voor semantisch zoeken, gelijkenis, clustering en RAG-workflows.",
  "mistral/mistral-large.description": "Mistral Large is ideaal voor complexe taken die sterk redeneervermogen of specialisatie vereisen—synthetische tekstgeneratie, codegeneratie, RAG of agents.",
  "mistral/mistral-small.description": "Mistral Small is ideaal voor eenvoudige, batchbare taken zoals classificatie, klantenservice of tekstgeneratie, met uitstekende prestaties tegen een betaalbare prijs.",
  "mistral/mixtral-8x22b-instruct.description": "8x22B Instruct model. 8x22B is een open MoE-model aangeboden door Mistral.",
  "mistral/pixtral-12b.description": "Een 12B-model met beeldbegrip en tekstverwerking.",
  "mistral/pixtral-large.description": "Pixtral Large is het tweede model in onze multimodale familie met geavanceerd beeldbegrip. Het verwerkt documenten, grafieken en natuurlijke beelden en behoudt het toonaangevende tekstbegrip van Mistral Large 2.",
  "mistralai/Mistral-7B-Instruct-v0.1.description": "Mistral (7B) Instruct staat bekend om sterke prestaties bij veel taaltaken.",
  "mistralai/Mistral-7B-Instruct-v0.2.description": "Mistral (7B) Instruct v0.2 verbetert instructieverwerking en nauwkeurigheid van resultaten.",
  "mistralai/Mistral-7B-Instruct-v0.3.description": "Mistral (7B) Instruct v0.3 biedt efficiënte verwerking en sterk taalbegrip voor uiteenlopende toepassingen.",
  "mistralai/Mistral-7B-v0.1.description": "Mistral 7B is compact maar krachtig, sterk in batchverwerking en eenvoudige taken zoals classificatie en tekstgeneratie, met solide redeneervermogen.",
  "mistralai/Mixtral-8x22B-Instruct-v0.1.description": "Mixtral-8x22B Instruct (141B) is een zeer groot LLM voor zware werklasten.",
  "mistralai/Mixtral-8x7B-Instruct-v0.1.description": "Mixtral-8x7B Instruct (46.7B) biedt hoge capaciteit voor grootschalige gegevensverwerking.",
  "mistralai/Mixtral-8x7B-v0.1.description": "Mixtral 8x7B is een spars MoE-model dat de inferentiesnelheid verhoogt, geschikt voor meertalige en codegeneratietaken.",
  "mistralai/mistral-nemo.description": "Mistral Nemo is een 7.3B-model met meertalige ondersteuning en sterke programmeerprestaties.",
  "mixtral-8x7b-32768.description": "Mixtral 8x7B biedt fouttolerante parallelle verwerking voor complexe taken.",
  "mixtral.description": "Mixtral is het MoE-model van Mistral AI met open gewichten, dat codegeneratie en taalbegrip ondersteunt.",
  "mixtral:8x22b.description": "Mixtral is het MoE-model van Mistral AI met open gewichten, dat codegeneratie en taalbegrip ondersteunt.",
  "moonshot-v1-128k-vision-preview.description": "Kimi vision-modellen (waaronder moonshot-v1-8k-vision-preview/moonshot-v1-32k-vision-preview/moonshot-v1-128k-vision-preview) begrijpen beeldinhoud zoals tekst, kleuren en objectvormen.",
  "moonshot-v1-128k.description": "Moonshot V1 128K biedt een ultralange context voor het genereren van zeer lange teksten, met ondersteuning tot 128.000 tokens voor onderzoeks-, academische en grootschalige documenttoepassingen.",
  "moonshot-v1-32k-vision-preview.description": "Kimi vision-modellen (waaronder moonshot-v1-8k-vision-preview/moonshot-v1-32k-vision-preview/moonshot-v1-128k-vision-preview) begrijpen beeldinhoud zoals tekst, kleuren en objectvormen.",
  "moonshot-v1-32k.description": "Moonshot V1 32K ondersteunt 32.768 tokens voor contexten van gemiddelde lengte, ideaal voor lange documenten en complexe dialogen in contentcreatie, rapporten en chatsystemen.",
  "moonshot-v1-8k-vision-preview.description": "Kimi vision-modellen (waaronder moonshot-v1-8k-vision-preview/moonshot-v1-32k-vision-preview/moonshot-v1-128k-vision-preview) begrijpen beeldinhoud zoals tekst, kleuren en objectvormen.",
  "moonshot-v1-8k.description": "Moonshot V1 8K is geoptimaliseerd voor het genereren van korte teksten met efficiënte prestaties, en verwerkt 8.192 tokens voor korte gesprekken, notities en snelle content.",
  "moonshot-v1-auto.description": "Moonshot V1 Auto kiest automatisch het juiste model op basis van het huidige gebruik van contexttokens.",
  "moonshotai/Kimi-Dev-72B.description": "Kimi-Dev-72B is een open-source code-LLM geoptimaliseerd met grootschalige reinforcement learning om robuuste, productieklare patches te genereren. Het behaalt 60,4% op SWE-bench Verified en vestigt een nieuw record voor open modellen bij geautomatiseerde software-engineeringtaken zoals bugfixes en codebeoordeling.",
  "moonshotai/Kimi-K2-Instruct-0905.description": "Kimi K2-Instruct-0905 is de nieuwste en krachtigste Kimi K2. Het is een topklasse MoE-model met 1T totale en 32B actieve parameters. Belangrijke kenmerken zijn sterkere agentmatige code-intelligentie met aanzienlijke verbeteringen op benchmarks en real-world agenttaken, plus verbeterde frontend-code esthetiek en bruikbaarheid.",
  "moonshotai/Kimi-K2-Thinking.description": "Kimi K2 Thinking is het nieuwste en krachtigste open-source denkmodel. Het vergroot de diepte van meerstapsredenering aanzienlijk en behoudt stabiel gebruik van tools over 200–300 opeenvolgende oproepen. Het vestigt nieuwe records op Humanity's Last Exam (HLE), BrowseComp en andere benchmarks. Het blinkt uit in codering, wiskunde, logica en agentscenario's. Gebouwd op een MoE-architectuur met ~1T totale parameters, ondersteunt het een contextvenster van 256K en toolgebruik.",
  "moonshotai/kimi-k2-0711.description": "Kimi K2 0711 is de instructievariant in de Kimi-serie, geschikt voor hoogwaardige code en toolgebruik.",
  "moonshotai/kimi-k2-0905.description": "Kimi K2 0905 is een update die context- en redeneervermogen uitbreidt met optimalisaties voor codering.",
  "moonshotai/kimi-k2-instruct-0905.description": "Het kimi-k2-0905-preview model ondersteunt een contextvenster van 256k, met sterkere agentmatige codering, meer verfijnde en praktische frontend-code en beter contextbegrip.",
  "moonshotai/kimi-k2-thinking-turbo.description": "Kimi K2 Thinking Turbo is een snelle versie van Kimi K2 Thinking, met aanzienlijk lagere latentie terwijl diepe redenering behouden blijft.",
  "moonshotai/kimi-k2-thinking.description": "Kimi K2 Thinking is Moonshot’s redeneermodel, geoptimaliseerd voor diepgaande redeneertaken, met algemene agentcapaciteiten.",
  "moonshotai/kimi-k2.description": "Kimi K2 is een groot MoE-model van Moonshot AI met 1T totale parameters en 32B actief per forward pass, geoptimaliseerd voor agentcapaciteiten zoals geavanceerd toolgebruik, redenering en codesynthese.",
  "morph/morph-v3-fast.description": "Morph biedt een gespecialiseerd model om codewijzigingen toe te passen die zijn voorgesteld door frontier-modellen (zoals Claude of GPT-4o) op je bestaande bestanden met een snelheid van 4500+ tokens/sec. Het is de laatste stap in een AI-coderingworkflow en ondersteunt 16k input/output tokens.",
  "morph/morph-v3-large.description": "Morph biedt een gespecialiseerd model om codewijzigingen toe te passen die zijn voorgesteld door frontier-modellen (zoals Claude of GPT-4o) op je bestaande bestanden met een snelheid van 2500+ tokens/sec. Het is de laatste stap in een AI-coderingworkflow en ondersteunt 16k input/output tokens.",
  "nousresearch/hermes-2-pro-llama-3-8b.description": "Hermes 2 Pro Llama 3 8B is een bijgewerkte versie van Nous Hermes 2 met de nieuwste intern ontwikkelde datasets.",
  "nvidia/Llama-3.1-Nemotron-70B-Instruct-HF.description": "Llama 3.1 Nemotron 70B is een door NVIDIA aangepast LLM om behulpzaamheid te verbeteren. Het presteert sterk op Arena Hard, AlpacaEval 2 LC en GPT-4-Turbo MT-Bench, en staat op 1 in alle drie auto-alignment benchmarks per 1 oktober 2024. Het is getraind vanuit Llama-3.1-70B-Instruct met behulp van RLHF (REINFORCE), Llama-3.1-Nemotron-70B-Reward en HelpSteer2-Preference prompts.",
  "nvidia/llama-3.1-nemotron-51b-instruct.description": "Een onderscheidend taalmodel dat uitzonderlijke nauwkeurigheid en efficiëntie levert.",
  "nvidia/llama-3.1-nemotron-70b-instruct.description": "Llama-3.1-Nemotron-70B-Instruct is een aangepast NVIDIA-model ontworpen om de behulpzaamheid van LLM-antwoorden te verbeteren.",
  "o1-mini.description": "Kleiner en sneller dan o1-preview, 80% lagere kosten, sterk in codegeneratie en taken met korte context.",
  "o1-preview.description": "Gefocust op geavanceerde redenering en complexe probleemoplossing, inclusief wiskunde en wetenschap. Ideaal voor toepassingen die diep contextbegrip en autonome workflows vereisen.",
  "o1-pro.description": "De o1-serie is getraind met reinforcement learning om eerst te denken en complexe redenering aan te kunnen. o1-pro gebruikt meer rekenkracht voor diepere denkwijzen en levert consistent antwoorden van hogere kwaliteit.",
  "o1.description": "o1 is OpenAI’s nieuwe redeneermodel met tekst+beeldinvoer en tekstuitvoer, geschikt voor complexe taken die brede kennis vereisen. Het heeft een contextvenster van 200K en een kennisgrens van oktober 2023.",
  "o3-2025-04-16.description": "o3 is OpenAI’s nieuwe redeneermodel met tekst+beeldinvoer en tekstuitvoer voor complexe taken die brede kennis vereisen.",
  "o3-deep-research.description": "o3-deep-research is ons meest geavanceerde model voor diepgaand onderzoek bij complexe meerstapstaken. Het kan het web doorzoeken en toegang krijgen tot je gegevens via MCP-connectors.",
  "o3-mini.description": "o3-mini is ons nieuwste kleine redeneermodel, dat hogere intelligentie levert tegen dezelfde kosten- en latentiedoelen als o1-mini.",
  "o3-pro-2025-06-10.description": "o3 Pro is OpenAI’s nieuwe redeneermodel met tekst+beeldinvoer en tekstuitvoer voor complexe taken die brede kennis vereisen.",
  "o3-pro.description": "o3-pro gebruikt meer rekenkracht om dieper te denken en levert consequent betere antwoorden; alleen beschikbaar via de Responses API.",
  "o3.description": "o3 is een krachtig allround model dat een nieuwe standaard zet voor wiskunde, wetenschap, programmeren en visuele redenering. Het blinkt uit in technisch schrijven en het volgen van instructies, en kan tekst, code en afbeeldingen analyseren voor meerstapsproblemen.",
  "o4-mini-2025-04-16.description": "o4-mini is een OpenAI redeneermodel met tekst+beeldinvoer en tekstuitvoer, geschikt voor complexe taken die brede kennis vereisen, met een contextvenster van 200K.",
  "o4-mini-deep-research.description": "o4-mini-deep-research is een sneller en betaalbaarder model voor diepgaand onderzoek bij complexe meerstapstaken. Het kan het web doorzoeken en ook toegang krijgen tot je gegevens via MCP-connectors.",
  "o4-mini.description": "o4-mini is het nieuwste kleine model in de o-serie, geoptimaliseerd voor snelle, effectieve redenering met hoge efficiëntie in codeer- en visietaken.",
  "open-codestral-mamba.description": "Codestral Mamba is een Mamba 2-taalmodel gericht op codegeneratie, geschikt voor geavanceerde programmeer- en redeneertaken.",
  "open-mistral-7b.description": "Mistral 7B is compact maar krachtig, sterk in batchverwerking en eenvoudige taken zoals classificatie en tekstgeneratie, met solide redeneervermogen.",
  "open-mistral-nemo.description": "Mistral Nemo is een 12B-model mede ontwikkeld met Nvidia, met sterke prestaties in redeneren en programmeren en eenvoudige integratie.",
  "open-mixtral-8x22b.description": "Mixtral 8x22B is een groter MoE-model voor complexe taken, met sterk redeneervermogen en hogere verwerkingssnelheid.",
  "open-mixtral-8x7b.description": "Mixtral 8x7B is een spars MoE-model dat de inferentiesnelheid verhoogt, geschikt voor meertalige en codegeneratietaken.",
  "openai/gpt-3.5-turbo-instruct.description": "Vergelijkbare capaciteiten als GPT-3-modellen, compatibel met oudere completion-eindpunten in plaats van chat.",
  "openai/gpt-3.5-turbo.description": "OpenAI’s meest capabele en kosteneffectieve GPT-3.5-model, geoptimaliseerd voor chat maar ook sterk in klassieke completions.",
  "openai/gpt-4-turbo.description": "OpenAI’s gpt-4-turbo beschikt over brede algemene kennis en domeinexpertise, volgt complexe natuurlijke taalopdrachten en lost moeilijke problemen nauwkeurig op. Kennisgrens is april 2023 met een contextvenster van 128k.",
  "openai/gpt-4.1-mini.description": "GPT-4.1 Mini biedt lagere latentie en betere waarde voor werklasten met gemiddelde context.",
  "openai/gpt-4.1-nano.description": "GPT-4.1 Nano is een ultragoedkope, laag-latentieoptie voor korte chats met hoge frequentie of classificatie.",
  "openai/gpt-4.1.description": "De GPT-4.1-serie biedt grotere contextvensters en sterkere technische en redeneercapaciteiten.",
  "openai/gpt-4o-mini.description": "GPT-4o-mini is een snelle, kleine GPT-4o-variant voor multimodale toepassingen met lage latentie.",
  "openai/gpt-4o.description": "De GPT-4o-familie is OpenAI’s Omni-model met tekst + beeldinvoer en tekstuitvoer.",
  "openai/gpt-5-chat.description": "GPT-5 Chat is een GPT-5-variant geoptimaliseerd voor gesprekken met lagere latentie voor betere interactiviteit.",
  "openai/gpt-5-codex.description": "GPT-5-Codex is een GPT-5-variant verder geoptimaliseerd voor programmeren en grootschalige codeworkflows.",
  "openai/gpt-5-mini.description": "GPT-5 Mini is een kleinere GPT-5-variant voor scenario’s met lage latentie en lage kosten.",
  "openai/gpt-5-nano.description": "GPT-5 Nano is de ultrakleine variant voor scenario’s met strikte kosten- en latentie-eisen.",
  "openai/gpt-5-pro.description": "GPT-5 Pro is OpenAI’s vlaggenschipmodel met sterker redeneervermogen, codegeneratie en functies op ondernemingsniveau, met test-time routing en strengere veiligheidsmaatregelen.",
  "openai/gpt-5.1-chat.description": "GPT-5.1 Chat is het lichtgewicht lid van de GPT-5.1-familie, geoptimaliseerd voor gesprekken met lage latentie en behoud van sterk redeneervermogen en instructie-uitvoering.",
  "openai/gpt-5.1-codex-mini.description": "GPT-5.1-Codex-Mini is een kleinere, snellere versie van GPT-5.1-Codex, beter voor latency- en kostenkritische programmeerscenario’s.",
  "openai/gpt-5.1-codex.description": "GPT-5.1-Codex is een GPT-5.1-variant geoptimaliseerd voor softwareontwikkeling en programmeerworkflows, geschikt voor grote refactors, complexe debugging en langdurige autonome coderingstaken.",
  "openai/gpt-5.1.description": "GPT-5.1 is het nieuwste vlaggenschip in de GPT-5-serie, met aanzienlijke verbeteringen ten opzichte van GPT-5 in algemeen redeneervermogen, instructievolging en natuurlijke conversatie, geschikt voor brede toepassingen.",
  "openai/gpt-5.2-chat.description": "GPT-5.2 Chat is de ChatGPT-variant om de nieuwste verbeteringen in conversatie te ervaren.",
  "openai/gpt-5.2-pro.description": "GPT-5.2 Pro: een slimmer, nauwkeuriger GPT-5.2-variant (alleen Responses API), geschikt voor moeilijkere problemen en langere redeneringen over meerdere beurten.",
  "openai/gpt-5.2.description": "GPT-5.2 is een vlaggenschipmodel voor programmeren en agent-workflows met sterker redeneervermogen en prestaties op lange contexten.",
  "openai/gpt-5.description": "GPT-5 is OpenAI’s krachtige model voor een breed scala aan productie- en onderzoekstaken.",
  "openai/gpt-oss-120b.description": "Een zeer capabel algemeen LLM met sterk, controleerbaar redeneervermogen.",
  "openai/gpt-oss-20b.description": "Een compact taalmodel met open gewichten, geoptimaliseerd voor lage latentie en omgevingen met beperkte middelen, inclusief lokale en edge-implementaties.",
  "openai/o1-mini.description": "o1-mini is een snel, kostenefficiënt redeneermodel ontworpen voor programmeren, wiskunde en wetenschap. Het ondersteunt 128K context en heeft een kennisgrens van oktober 2023.",
  "openai/o1-preview.description": "o1 is het nieuwe redeneermodel van OpenAI voor complexe taken die brede kennis vereisen. Het ondersteunt 128K context en heeft een kennisgrens van oktober 2023.",
  "openai/o1.description": "OpenAI o1 is een vlaggenschip redeneermodel gebouwd voor complexe problemen die diepgaand denken vereisen, met sterk redeneervermogen en hogere nauwkeurigheid bij meerstapstaken.",
  "openai/o3-mini-high.description": "o3-mini (hoog redeneervermogen) biedt hogere intelligentie tegen dezelfde kosten en latentie als o1-mini.",
  "openai/o3-mini.description": "o3-mini is het nieuwste kleine redeneermodel van OpenAI, met hogere intelligentie tegen dezelfde kosten en latentie als o1-mini.",
  "openai/o3.description": "OpenAI o3 is het krachtigste redeneermodel, dat nieuwe SOTA-prestaties levert in programmeren, wiskunde, wetenschap en visuele perceptie. Het blinkt uit in complexe, veelzijdige vragen en is bijzonder sterk in het analyseren van afbeeldingen, grafieken en diagrammen.",
  "openai/o4-mini-high.description": "o4-mini high reasoning tier is geoptimaliseerd voor snelle, efficiënte redenering met sterke prestaties in programmeren en visuele taken.",
  "openai/o4-mini.description": "OpenAI o4-mini is een klein, efficiënt redeneermodel voor scenario's met lage latentie.",
  "openai/text-embedding-3-large.description": "Het meest capabele embeddingmodel van OpenAI voor Engelse en niet-Engelse taken.",
  "openai/text-embedding-3-small.description": "De verbeterde, krachtige ada embedding-variant van OpenAI.",
  "openai/text-embedding-ada-002.description": "Het oudere tekstembeddingmodel van OpenAI.",
  "openrouter/auto.description": "Op basis van contextlengte, onderwerp en complexiteit wordt je verzoek doorgestuurd naar Llama 3 70B Instruct, Claude 3.5 Sonnet (zelf-gemodereerd) of GPT-4o.",
  "perplexity/sonar-pro.description": "Het vlaggenschipproduct van Perplexity met zoekverankering, ondersteuning voor geavanceerde vragen en vervolginteracties.",
  "perplexity/sonar-reasoning-pro.description": "Een geavanceerd redeneermodel dat keten-van-gedachten (CoT) genereert met verbeterde zoekfunctionaliteit, inclusief meerdere zoekopdrachten per verzoek.",
  "perplexity/sonar-reasoning.description": "Een redeneermodel dat keten-van-gedachten (CoT) genereert met gedetailleerde, op zoek gebaseerde uitleg.",
  "perplexity/sonar.description": "Het lichtgewicht product van Perplexity met zoekverankering, sneller en goedkoper dan Sonar Pro.",
  "phi3.description": "Phi-3 is het lichtgewicht open model van Microsoft voor efficiënte integratie en grootschalige redenering.",
  "phi3:14b.description": "Phi-3 is het lichtgewicht open model van Microsoft voor efficiënte integratie en grootschalige redenering.",
  "pixtral-12b-2409.description": "Pixtral blinkt uit in grafiek-/beeldbegrip, documentvraag-en-antwoord, multimodale redenering en instructieopvolging. Het verwerkt beelden in native resolutie/verhouding en ondersteunt een onbeperkt aantal beelden binnen een contextvenster van 128K.",
  "pixtral-large-latest.description": "Pixtral Large is een open multimodaal model met 124B parameters, gebaseerd op Mistral Large 2. Het is het tweede model in onze multimodale familie met geavanceerd beeldbegrip.",
  "pro-128k.description": "Spark Pro 128K biedt een zeer grote contextcapaciteit tot 128K, ideaal voor langvormige documenten die volledige tekstanalyse en langeafstandscoherentie vereisen, met vloeiende logica en diverse citatieondersteuning in complexe discussies.",
  "pro-deepseek-r1.description": "Toegewijd bedrijfsmodel met gebundelde gelijktijdigheid.",
  "pro-deepseek-v3.description": "Toegewijd bedrijfsmodel met gebundelde gelijktijdigheid.",
  "qianfan-70b.description": "Qianfan 70B is een groot Chinees model voor hoogwaardige generatie en complexe redenering.",
  "qianfan-8b.description": "Qianfan 8B is een middelgroot algemeen model dat kosten en kwaliteit in balans brengt voor tekstgeneratie en vraag-antwoordtoepassingen.",
  "qianfan-agent-intent-32k.description": "Qianfan Agent Intent 32K richt zich op intentieherkenning en agentcoördinatie met ondersteuning voor lange context.",
  "qianfan-agent-lite-8k.description": "Qianfan Agent Lite 8K is een lichtgewicht agentmodel voor kostenefficiënte meerstapsdialogen en workflows.",
  "qianfan-check-vl.description": "Qianfan Check VL is een multimodaal contentcontrolemodel voor naleving en herkenning van beeld-tekstinhoud.",
  "qianfan-composition.description": "Qianfan Composition is een multimodaal creatiemodel voor gemengde beeld-tekstbegrip en -generatie.",
  "qianfan-engcard-vl.description": "Qianfan EngCard VL is een multimodaal herkenningsmodel gericht op Engelstalige scenario's.",
  "qianfan-lightning-128b-a19b.description": "Qianfan Lightning 128B A19B is een krachtig Chinees algemeen model voor complexe vraag-antwoordtoepassingen en grootschalige redenering.",
  "qianfan-llama-vl-8b.description": "Qianfan Llama VL 8B is een multimodaal model gebaseerd op Llama voor algemene beeld-tekstbegrip.",
  "qianfan-multipicocr.description": "Qianfan MultiPicOCR is een OCR-model voor meerdere afbeeldingen dat tekst detecteert en herkent in verschillende beelden.",
  "qianfan-qi-vl.description": "Qianfan QI VL is een multimodaal vraag-en-antwoordmodel voor nauwkeurige informatieopvraging en beantwoording in complexe beeld-tekstscenario's.",
  "qianfan-singlepicocr.description": "Qianfan SinglePicOCR is een OCR-model voor één afbeelding met zeer nauwkeurige tekenherkenning.",
  "qianfan-vl-70b.description": "Qianfan VL 70B is een groot vision-language model voor complex beeld-tekstbegrip.",
  "qianfan-vl-8b.description": "Qianfan VL 8B is een lichtgewicht vision-language model voor dagelijkse beeld-tekstvragen en -analyses.",
  "qvq-72b-preview.description": "QVQ-72B-Preview is een experimenteel onderzoeksmodel van Qwen gericht op het verbeteren van visueel redeneren.",
  "qvq-max.description": "Het Qwen QVQ visueel redeneermodel ondersteunt visuele input en keten-van-gedachten output, met sterke prestaties in wiskunde, codering, visuele analyse, creativiteit en algemene taken.",
  "qvq-plus.description": "Visueel redeneermodel met visuele input en keten-van-gedachten output. De qvq-plus-serie volgt op qvq-max en biedt snellere redenering met een betere balans tussen kwaliteit en kosten.",
  "qwen-3-32b.description": "Qwen 3 32B: sterk in meertalige en programmeertaken, geschikt voor middelgrote productieomgevingen.",
  "qwen-coder-plus.description": "Qwen codeermodel.",
  "qwen-coder-turbo-latest.description": "Qwen codeermodel.",
  "qwen-coder-turbo.description": "Qwen codeermodel.",
  "qwen-flash.description": "Snelste en goedkoopste Qwen-model, ideaal voor eenvoudige taken.",
  "qwen-image-edit.description": "Qwen Image Edit is een beeld-naar-beeldmodel dat afbeeldingen bewerkt op basis van invoerafbeeldingen en tekstprompts, voor nauwkeurige aanpassingen en creatieve transformaties.",
  "qwen-image.description": "Qwen-Image is een algemeen beeldgeneratiemodel dat meerdere kunststijlen ondersteunt en complexe tekstweergave aankan, vooral in het Chinees en Engels. Het ondersteunt meerregelige lay-outs, tekst op alinea-niveau en fijne details voor complexe tekst-beeldcombinaties.",
  "qwen-long.description": "Ultragroot Qwen-model met lange context en chatmogelijkheden over lange en meerdere documenten.",
  "qwen-math-plus-latest.description": "Qwen Math is een taalmodel gespecialiseerd in het oplossen van wiskundige problemen.",
  "qwen-math-plus.description": "Qwen Math is een taalmodel gespecialiseerd in het oplossen van wiskundige problemen.",
  "qwen-math-turbo-latest.description": "Qwen Math is een taalmodel gespecialiseerd in het oplossen van wiskundige problemen.",
  "qwen-math-turbo.description": "Qwen Math is een taalmodel gespecialiseerd in het oplossen van wiskundige problemen.",
  "qwen-max.description": "Qwen-model op honderd miljard-schaal dat Chinees, Engels en andere talen ondersteunt; het API-model achter de huidige Qwen2.5-producten.",
  "qwen-omni-turbo.description": "Qwen-Omni-modellen ondersteunen multimodale input (video, audio, afbeeldingen, tekst) en output in audio en tekst.",
  "qwen-plus.description": "Verbeterd ultragroot Qwen-model dat Chinees, Engels en andere talen ondersteunt.",
  "qwen-turbo.description": "Qwen Turbo wordt niet langer bijgewerkt; vervang door Qwen Flash. Ultragroot Qwen-model dat Chinees, Engels en andere talen ondersteunt.",
  "qwen-vl-chat-v1.description": "Qwen VL ondersteunt flexibele interacties zoals invoer van meerdere afbeeldingen, meerstaps vraag-en-antwoord en creatieve taken.",
  "qwen-vl-max-latest.description": "Ultragroot Qwen vision-language model. Vergeleken met de verbeterde versie biedt het betere visuele redenering en instructieopvolging voor sterkere waarneming en cognitie.",
  "qwen-vl-max.description": "Ultragroot Qwen vision-language model. Vergeleken met de verbeterde versie biedt het betere visuele redenering en instructieopvolging voor sterkere visuele waarneming en cognitie.",
  "qwen-vl-ocr.description": "Qwen OCR is een model voor tekstuittrekking uit documenten, tabellen, examenafbeeldingen en handschrift. Het ondersteunt Chinees, Engels, Frans, Japans, Koreaans, Duits, Russisch, Italiaans, Vietnamees en Arabisch.",
  "qwen-vl-plus-latest.description": "Verbeterd grootschalig Qwen vision-language model met grote verbeteringen in detail- en tekstherkenning, ondersteunt resoluties boven één megapixel en willekeurige beeldverhoudingen.",
  "qwen-vl-plus.description": "Verbeterd grootschalig Qwen vision-language model met grote verbeteringen in detail- en tekstherkenning, ondersteunt resoluties boven één megapixel en willekeurige beeldverhoudingen.",
  "qwen-vl-v1.description": "Voorgetraind model gebaseerd op Qwen-7B met een toegevoegd visiemodule en 448 beeldresolutie-invoer.",
  "qwen/qwen-2-7b-instruct.description": "Qwen2 is de nieuwe Qwen LLM-serie. Qwen2 7B is een transformer-gebaseerd model dat uitblinkt in taalbegrip, meertaligheid, programmeren, wiskunde en redeneren.",
  "qwen/qwen-2-7b-instruct:free.description": "Qwen2 is een nieuwe familie van grote taalmodellen met sterker begrip en generatievermogen.",
  "qwen/qwen-2-vl-72b-instruct.description": "Qwen2-VL is de nieuwste iteratie van Qwen-VL en behaalt state-of-the-art prestaties op visuele benchmarks zoals MathVista, DocVQA, RealWorldQA en MTVQA. Het kan meer dan 20 minuten video begrijpen voor hoogwaardige video-vraag-en-antwoord, dialoog en contentcreatie. Het verwerkt ook complexe redenering en besluitvorming, en integreert met mobiele apparaten en robots om te handelen op basis van visuele context en tekstinstructies. Naast Engels en Chinees leest het ook tekst in afbeeldingen in vele talen, waaronder de meeste Europese talen, Japans, Koreaans, Arabisch en Vietnamees.",
  "qwen/qwen-2.5-72b-instruct.description": "Qwen2.5-72B-Instruct is een van de nieuwste LLM-releases van Alibaba Cloud. Het 72B-model biedt aanzienlijke verbeteringen in codering en wiskunde, ondersteunt meer dan 29 talen (waaronder Chinees en Engels), en verbetert instructieopvolging, begrip van gestructureerde data en gestructureerde output (vooral JSON).",
  "qwen/qwen2.5-32b-instruct.description": "Qwen2.5-32B-Instruct is een van de nieuwste LLM-releases van Alibaba Cloud. Het 32B-model biedt aanzienlijke verbeteringen in codering en wiskunde, ondersteunt meer dan 29 talen (waaronder Chinees en Engels), en verbetert instructieopvolging, begrip van gestructureerde data en gestructureerde output (vooral JSON).",
  "qwen/qwen2.5-7b-instruct.description": "Een tweetalig LLM voor Chinees en Engels op het gebied van taal, codering, wiskunde en redenering.",
  "qwen/qwen2.5-coder-32b-instruct.description": "Een geavanceerd LLM voor codegeneratie, redenering en reparatie in gangbare programmeertalen.",
  "qwen/qwen2.5-coder-7b-instruct.description": "Een krachtig middelgroot codeermodel met 32K context, uitblinkend in meertalig programmeren.",
  "qwen/qwen3-14b.description": "Qwen3-14B is de 14B-variant voor algemene redenering en chatscenario's.",
  "qwen/qwen3-14b:free.description": "Qwen3-14B is een dense 14,8B-parameter causaal LLM gebouwd voor complexe redenering en efficiënte chat. Het schakelt tussen een denkmodus voor wiskunde, codering en logica en een niet-denkmodus voor algemene chat. Fijn afgestemd op instructieopvolging, gebruik van agenttools en creatief schrijven in meer dan 100 talen en dialecten. Ondersteunt standaard 32K context en schaalt tot 131K met YaRN.",
  "qwen/qwen3-235b-a22b-2507.description": "Qwen3-235B-A22B-Instruct-2507 is de instructievariant in de Qwen3-serie, die meertalige instructietaken combineert met scenario's met lange context.",
  "qwen/qwen3-235b-a22b-thinking-2507.description": "Qwen3-235B-A22B-Thinking-2507 is de Thinking-variant van Qwen3, versterkt voor complexe wiskundige en redeneertaken.",
  "qwen/qwen3-235b-a22b.description": "Qwen3-235B-A22B is een 235B-parameter MoE-model van Qwen met 22B actief per forward pass. Het schakelt tussen een denkmodus voor complexe redenering, wiskunde en codering en een niet-denkmodus voor efficiënte chat. Het biedt sterke redenering, meertalige ondersteuning (100+ talen/dialecten), geavanceerde instructieopvolging en gebruik van agenttools. Ondersteunt standaard 32K context en schaalt tot 131K met YaRN.",
  "qwen/qwen3-235b-a22b:free.description": "Qwen3-235B-A22B is een 235B-parameter MoE-model van Qwen met 22B actief per forward pass. Het schakelt tussen een denkmodus voor complexe redenering, wiskunde en codering en een niet-denkmodus voor efficiënte chat. Het biedt sterke redenering, meertalige ondersteuning (100+ talen/dialecten), geavanceerde instructieopvolging en gebruik van agenttools. Ondersteunt standaard 32K context en schaalt tot 131K met YaRN.",
  "qwen/qwen3-30b-a3b.description": "Qwen3 is de nieuwste generatie Qwen LLM met dense en MoE-architecturen, uitblinkend in redenering, meertalige ondersteuning en geavanceerde agenttaken. De unieke mogelijkheid om te schakelen tussen een denkmodus voor complexe redenering en een niet-denkmodus voor efficiënte chat zorgt voor veelzijdige, hoogwaardige prestaties.\n\nQwen3 presteert aanzienlijk beter dan eerdere modellen zoals QwQ en Qwen2.5, met uitstekende resultaten in wiskunde, codering, alledaagse redenering, creatief schrijven en interactieve chat. De Qwen3-30B-A3B-variant heeft 30,5B parameters (3,3B actief), 48 lagen, 128 experts (8 actief per taak) en ondersteunt tot 131K context met YaRN, en zet een nieuwe standaard voor open modellen.",
  "qwen/qwen3-30b-a3b:free.description": "Qwen3 is de nieuwste generatie Qwen LLM met dichte en MoE-architecturen, uitblinkend in redenering, meertalige ondersteuning en geavanceerde agenttaken. De unieke mogelijkheid om te schakelen tussen een denkmodus voor complexe redenering en een niet-denkmodus voor efficiënte gesprekken zorgt voor veelzijdige, hoogwaardige prestaties.\n\nQwen3 presteert aanzienlijk beter dan eerdere modellen zoals QwQ en Qwen2.5, met uitstekende resultaten in wiskunde, codering, alledaagse redenering, creatief schrijven en interactieve gesprekken. De Qwen3-30B-A3B-variant heeft 30,5 miljard parameters (3,3 miljard actief), 48 lagen, 128 experts (8 actief per taak) en ondersteunt tot 131K context met YaRN, waarmee het een nieuwe standaard zet voor open modellen.",
  "qwen/qwen3-32b.description": "Qwen3-32B is een dicht 32,8 miljard-parameter causaal LLM geoptimaliseerd voor complexe redenering en efficiënte gesprekken. Het schakelt tussen een denkmodus voor wiskunde, codering en logica en een niet-denkmodus voor snellere algemene gesprekken. Het presteert sterk in instructieopvolging, gebruik van agenttools en creatief schrijven in meer dan 100 talen en dialecten. Ondersteunt standaard 32K context en schaalt tot 131K met YaRN.",
  "qwen/qwen3-32b:free.description": "Qwen3-32B is een dicht 32,8 miljard-parameter causaal LLM geoptimaliseerd voor complexe redenering en efficiënte gesprekken. Het schakelt tussen een denkmodus voor wiskunde, codering en logica en een niet-denkmodus voor snellere algemene gesprekken. Het presteert sterk in instructieopvolging, gebruik van agenttools en creatief schrijven in meer dan 100 talen en dialecten. Ondersteunt standaard 32K context en schaalt tot 131K met YaRN.",
  "qwen/qwen3-8b:free.description": "Qwen3-8B is een dicht 8,2 miljard-parameter causaal LLM gebouwd voor taken met veel redenering en efficiënte gesprekken. Het schakelt tussen een denkmodus voor wiskunde, codering en logica en een niet-denkmodus voor algemene gesprekken. Fijn afgestemd op instructieopvolging, agentintegratie en creatief schrijven in meer dan 100 talen en dialecten. Ondersteunt standaard 32K context en schaalt tot 131K met YaRN.",
  "qwen/qwen3-coder-plus.description": "Qwen3-Coder-Plus is een Qwen-serie codeeragentmodel geoptimaliseerd voor complexer gebruik van tools en langdurige sessies.",
  "qwen/qwen3-coder.description": "Qwen3-Coder is de Qwen3-codegeneratiefamilie, sterk in het begrijpen en genereren van code in lange documenten.",
  "qwen/qwen3-max-preview.description": "Qwen3 Max (preview) is de Max-variant voor geavanceerde redenering en toolintegratie.",
  "qwen/qwen3-max.description": "Qwen3 Max is het high-end redeneringsmodel in de Qwen3-serie voor meertalige redenering en toolintegratie.",
  "qwen/qwen3-vl-plus.description": "Qwen3 VL-Plus is de visueel verbeterde Qwen3-variant met verbeterde multimodale redenering en videoprocessing.",
  "qwen2.5-14b-instruct-1m.description": "Qwen2.5 open-source 72B model.",
  "qwen2.5-14b-instruct.description": "Qwen2.5 open-source 14B model.",
  "qwen2.5-32b-instruct.description": "Qwen2.5 open-source 32B model.",
  "qwen2.5-72b-instruct.description": "Qwen2.5 open-source 72B model.",
  "qwen2.5-7b-instruct.description": "Qwen2.5 7B Instruct is een volwassen open-source instructiemodel voor chats en generatie in meerdere scenario's.",
  "qwen2.5-coder-1.5b-instruct.description": "Open-source Qwen-codeermodel.",
  "qwen2.5-coder-14b-instruct.description": "Open-source Qwen-codeermodel.",
  "qwen2.5-coder-32b-instruct.description": "Open-source Qwen-codeermodel.",
  "qwen2.5-coder-7b-instruct.description": "Open-source Qwen-codeermodel.",
  "qwen2.5-coder-instruct.description": "Qwen2.5-Coder is het nieuwste codegerichte LLM in de Qwen-familie (voorheen CodeQwen).",
  "qwen2.5-instruct.description": "Qwen2.5 is de nieuwste Qwen LLM-serie, met basis- en instructieafgestemde modellen van 0,5B tot 72B parameters.",
  "qwen2.5-math-1.5b-instruct.description": "Qwen-Math levert sterke prestaties bij het oplossen van wiskundige problemen.",
  "qwen2.5-math-72b-instruct.description": "Qwen-Math levert sterke prestaties bij het oplossen van wiskundige problemen.",
  "qwen2.5-math-7b-instruct.description": "Qwen-Math levert sterke prestaties bij het oplossen van wiskundige problemen.",
  "qwen2.5-omni-7b.description": "Qwen-Omni-modellen ondersteunen multimodale invoer (video, audio, afbeeldingen, tekst) en geven audio en tekst als uitvoer.",
  "qwen2.5-vl-32b-instruct.description": "Qwen2.5 VL 32B Instruct is een open-source multimodaal model geschikt voor privé-implementatie en gebruik in meerdere scenario's.",
  "qwen2.5-vl-72b-instruct.description": "Verbeterde instructieopvolging, wiskunde, probleemoplossing en codering, met sterkere algemene objectherkenning. Ondersteunt nauwkeurige lokalisatie van visuele elementen in verschillende formaten, begrip van lange video's (tot 10 minuten) met timing op secondeniveau, temporele ordening en snelheidsbegrip, en agents die besturingssystemen of mobiele apparaten kunnen aansturen via parsing en lokalisatie. Sterke extractie van kerninformatie en JSON-uitvoer. Dit is de 72B, krachtigste versie in de serie.",
  "qwen2.5-vl-7b-instruct.description": "Qwen2.5 VL 7B Instruct is een lichtgewicht multimodaal model dat implementatiekosten en herkenningsvermogen in balans brengt.",
  "qwen2.5-vl-instruct.description": "Qwen2.5-VL is het nieuwste visie-taalmodel in de Qwen-familie.",
  "qwen2.5.description": "Qwen2.5 is Alibaba’s volgende generatie groot taalmodel met sterke prestaties in uiteenlopende toepassingen.",
  "qwen2.5:0.5b.description": "Qwen2.5 is Alibaba’s volgende generatie groot taalmodel met sterke prestaties in uiteenlopende toepassingen.",
  "qwen2.5:1.5b.description": "Qwen2.5 is Alibaba’s volgende generatie groot taalmodel met sterke prestaties in uiteenlopende toepassingen.",
  "qwen2.5:72b.description": "Qwen2.5 is Alibaba’s volgende generatie groot taalmodel met sterke prestaties in uiteenlopende toepassingen.",
  "qwen2.description": "Qwen2 is Alibaba’s volgende generatie groot taalmodel met sterke prestaties in uiteenlopende toepassingen.",
  "qwen2:0.5b.description": "Qwen2 is Alibaba’s volgende generatie groot taalmodel met sterke prestaties in uiteenlopende toepassingen.",
  "qwen2:1.5b.description": "Qwen2 is Alibaba’s volgende generatie groot taalmodel met sterke prestaties in uiteenlopende toepassingen.",
  "qwen2:72b.description": "Qwen2 is Alibaba’s volgende generatie groot taalmodel met sterke prestaties in uiteenlopende toepassingen.",
  "qwen3-0.6b.description": "Qwen3 0.6B is een instapmodel voor eenvoudige redenering en zeer beperkte omgevingen.",
  "qwen3-1.7b.description": "Qwen3 1.7B is een ultralicht model voor implementatie op edge- en apparaatniveau.",
  "qwen3-14b.description": "Qwen3 14B is een middelgroot model voor meertalige vraag-antwoordtoepassingen en tekstgeneratie.",
  "qwen3-235b-a22b-instruct-2507.description": "Qwen3 235B A22B Instruct 2507 is een vlaggenschip instructiemodel voor een breed scala aan generatie- en redeneertaken.",
  "qwen3-235b-a22b-thinking-2507.description": "Qwen3 235B A22B Thinking 2507 is een ultragroot denkmodel voor complexe redenering.",
  "qwen3-235b-a22b.description": "Qwen3 is een next-gen Tongyi Qwen-model met grote verbeteringen in redenering, algemene vaardigheden, agentcapaciteiten en meertalige prestaties, en ondersteunt het schakelen tussen denkmodi.",
  "qwen3-30b-a3b-instruct-2507.description": "Qwen3 30B A3B Instruct 2507 is een middelgroot instructiemodel voor hoogwaardige generatie en vraag-antwoordtoepassingen.",
  "qwen3-30b-a3b-thinking-2507.description": "Qwen3 30B A3B Thinking 2507 is een middelgroot denkmodel dat nauwkeurigheid en kosten in balans brengt.",
  "qwen3-30b-a3b.description": "Qwen3 30B A3B is een middelgroot algemeen model dat kosten en kwaliteit in balans brengt.",
  "qwen3-32b.description": "Qwen3 32B is geschikt voor algemene taken die sterk begrip vereisen.",
  "qwen3-4b.description": "Qwen3 4B is geschikt voor kleine tot middelgrote toepassingen en lokale inferentie.",
  "qwen3-8b.description": "Qwen3 8B is een lichtgewicht model met flexibele implementatie voor werklasten met hoge gelijktijdigheid.",
  "qwen3-coder-30b-a3b-instruct.description": "Open-source Qwen-codeermodel. De nieuwste qwen3-coder-30b-a3b-instruct is gebaseerd op Qwen3 en levert sterke codeeragentmogelijkheden, toolgebruik en omgevingsinteractie voor autonoom programmeren, met uitstekende codeprestaties en solide algemene capaciteiten.",
  "qwen3-coder-480b-a35b-instruct.description": "Qwen3 Coder 480B A35B Instruct is een toonaangevend codeermodel voor meertalige programmering en complexe codebegrip.",
  "qwen3-coder-flash.description": "Qwen-codeermodel. De nieuwste Qwen3-Coder-serie is gebaseerd op Qwen3 en biedt krachtige mogelijkheden voor programmeeragenten, gereedschapsgebruik en interactie met omgevingen voor autonoom programmeren, met uitstekende codeprestaties en solide algemene capaciteiten.",
  "qwen3-coder-plus.description": "Qwen-codeermodel. De nieuwste Qwen3-Coder-serie is gebaseerd op Qwen3 en biedt krachtige mogelijkheden voor programmeeragenten, gereedschapsgebruik en interactie met omgevingen voor autonoom programmeren, met uitstekende codeprestaties en solide algemene capaciteiten.",
  "qwen3-coder:480b.description": "Alibaba’s krachtige model met lange context voor agent- en programmeertaken.",
  "qwen3-max-2026-01-23.description": "Qwen3 Max-modellen leveren grote verbeteringen ten opzichte van de 2.5-serie in algemene vaardigheden, Chinees/Engels begrip, complexe instructieopvolging, subjectieve open taken, meertalige vaardigheden en toolgebruik, met minder hallucinaties. De nieuwste qwen3-max verbetert agentisch programmeren en toolgebruik ten opzichte van qwen3-max-preview. Deze release bereikt SOTA-niveau en richt zich op complexere agentbehoeften.",
  "qwen3-max-preview.description": "Best presterend Qwen-model voor complexe, meerstaps taken. De preview ondersteunt denkprocessen.",
  "qwen3-max.description": "Qwen3 Max-modellen bieden aanzienlijke verbeteringen ten opzichte van de 2.5-serie op het gebied van algemene capaciteiten, Chinees/Engels begrip, complexe instructieopvolging, subjectieve open taken, meertaligheid en gereedschapsgebruik, met minder hallucinaties. De nieuwste qwen3-max verbetert programmeeragenten en gereedschapsgebruik ten opzichte van qwen3-max-preview. Deze release bereikt SOTA in het veld en richt zich op complexere agentbehoeften.",
  "qwen3-next-80b-a3b-instruct.description": "Volgende generatie Qwen3 open-source model zonder denkmodus. Vergeleken met de vorige versie (Qwen3-235B-A22B-Instruct-2507) heeft het een beter Chinees begrip, sterkere logische redenering en verbeterde tekstgeneratie.",
  "qwen3-next-80b-a3b-thinking.description": "Qwen3 Next 80B A3B Thinking is een toonaangevende redeneerversie voor complexe taken.",
  "qwen3-omni-flash.description": "Qwen-Omni accepteert gecombineerde invoer van tekst, afbeeldingen, audio en video, en genereert tekst of spraak. Het biedt meerdere natuurlijke stemstijlen, ondersteunt meertalige en dialectspraak, en is geschikt voor toepassingen zoals schrijven, visuele herkenning en spraakassistenten.",
  "qwen3-vl-235b-a22b-instruct.description": "Qwen3 VL 235B A22B Instruct is een toonaangevend multimodaal model voor veeleisend begrip en creatie.",
  "qwen3-vl-235b-a22b-thinking.description": "Qwen3 VL 235B A22B Thinking is de toonaangevende redeneerversie voor complexe multimodale redenering en planning.",
  "qwen3-vl-30b-a3b-instruct.description": "Qwen3 VL 30B A3B Instruct is een groot multimodaal model dat nauwkeurigheid en redeneervermogen in balans brengt.",
  "qwen3-vl-30b-a3b-thinking.description": "Qwen3 VL 30B A3B Thinking is een diepdenkende versie voor complexe multimodale taken.",
  "qwen3-vl-32b-instruct.description": "Qwen3 VL 32B Instruct is een multimodaal model getraind op instructies voor hoogwaardige beeld-tekst vraag-antwoord en creatie.",
  "qwen3-vl-32b-thinking.description": "Qwen3 VL 32B Thinking is een diepdenkende multimodale versie voor complexe redenering en ketenanalyse.",
  "qwen3-vl-8b-instruct.description": "Qwen3 VL 8B Instruct is een lichtgewicht multimodaal model voor dagelijkse visuele vraag-antwoord en app-integratie.",
  "qwen3-vl-8b-thinking.description": "Qwen3 VL 8B Thinking is een multimodaal keten-van-gedachten model voor gedetailleerde visuele redenering.",
  "qwen3-vl-flash.description": "Qwen3 VL Flash: lichtgewicht, snelle redeneerversie voor latency-gevoelige of grootschalige verzoeken.",
  "qwen3-vl-plus.description": "Qwen VL is een tekstgeneratiemodel met visueel begrip. Het kan OCR uitvoeren en ook samenvatten en redeneren, zoals het extraheren van kenmerken uit productfoto’s of het oplossen van problemen op basis van afbeeldingen.",
  "qwen3.description": "Qwen3 is Alibaba’s volgende generatie groot taalmodel met sterke prestaties in diverse toepassingen.",
  "qwq-32b-preview.description": "QwQ is een experimenteel onderzoeksmodel van Qwen gericht op verbeterde redenering.",
  "qwq-32b.description": "QwQ is een redeneermodel binnen de Qwen-familie. In vergelijking met standaard instructie-getrainde modellen biedt het denk- en redeneervermogen dat de prestaties op complexe problemen aanzienlijk verbetert. QwQ-32B is een middelgroot redeneermodel dat zich kan meten met topmodellen zoals DeepSeek-R1 en o1-mini.",
  "qwq-plus.description": "QwQ redeneermodel getraind op Qwen2.5 gebruikt RL om redenering sterk te verbeteren. Kernmetingen in wiskunde/code (AIME 24/25, LiveCodeBench) en enkele algemene benchmarks (IFEval, LiveBench) bereiken het niveau van DeepSeek-R1.",
  "qwq.description": "QwQ is een redeneermodel binnen de Qwen-familie. In vergelijking met standaard instructie-getrainde modellen biedt het denk- en redeneervermogen dat de prestaties op complexe problemen aanzienlijk verbetert. QwQ-32B is een middelgroot redeneermodel dat zich kan meten met topmodellen zoals DeepSeek-R1 en o1-mini.",
  "qwq_32b.description": "Middelgroot redeneermodel binnen de Qwen-familie. In vergelijking met standaard instructie-getrainde modellen verbeteren QwQ’s denk- en redeneervermogen de prestaties op complexe problemen aanzienlijk.",
  "r1-1776.description": "R1-1776 is een na-getrainde variant van DeepSeek R1, ontworpen om ongecensureerde, onbevooroordeelde feitelijke informatie te bieden.",
  "solar-mini-ja.description": "Solar Mini (Ja) breidt Solar Mini uit met focus op Japans, terwijl het efficiënte, sterke prestaties in Engels en Koreaans behoudt.",
  "solar-mini.description": "Solar Mini is een compact LLM dat beter presteert dan GPT-3.5, met sterke meertalige ondersteuning voor Engels en Koreaans, en biedt een efficiënte oplossing met een kleine voetafdruk.",
  "solar-pro.description": "Solar Pro is een intelligent LLM van Upstage, gericht op instructieopvolging op een enkele GPU, met IFEval-scores boven de 80. Momenteel ondersteunt het Engels; de volledige release stond gepland voor november 2024 met uitgebreidere taalondersteuning en langere context.",
  "sonar-deep-research.description": "Deep Research voert diepgaand onderzoek op expertniveau uit en zet dit om in toegankelijke, bruikbare rapporten.",
  "sonar-pro.description": "Een geavanceerd zoekproduct met zoekverankering voor complexe vragen en vervolgvragen.",
  "sonar-reasoning-pro.description": "Een geavanceerd zoekproduct met zoekverankering voor complexe vragen en vervolgvragen.",
  "sonar-reasoning.description": "Een geavanceerd zoekproduct met zoekverankering voor complexe vragen en vervolgvragen.",
  "sonar.description": "Een lichtgewicht zoekproduct met verankering, sneller en goedkoper dan Sonar Pro.",
  "spark-x.description": "X1.5-updates: (1) voegt dynamische denkmodus toe via het veld `thinking`; (2) grotere contextlengte met 64K invoer en 64K uitvoer; (3) ondersteunt FunctionCall.",
  "stable-diffusion-3-medium.description": "Het nieuwste tekst-naar-beeldmodel van Stability AI. Deze versie verbetert de beeldkwaliteit, tekstbegrip en stijlvariatie aanzienlijk, interpreteert complexe natuurlijke taal nauwkeuriger en genereert preciezere, gevarieerdere beelden.",
  "stable-diffusion-3.5-large-turbo.description": "stable-diffusion-3.5-large-turbo past adversarial diffusion distillation (ADD) toe op stable-diffusion-3.5-large voor hogere snelheid.",
  "stable-diffusion-3.5-large.description": "stable-diffusion-3.5-large is een 800M-parameter MMDiT tekst-naar-beeldmodel met uitstekende kwaliteit en prompt-afstemming, ondersteunt 1-megapixel beelden en draait efficiënt op consumentenhardware.",
  "stable-diffusion-v1.5.description": "stable-diffusion-v1.5 is geïnitialiseerd vanuit het v1.2-checkpoint en fijngestemd voor 595k stappen op \"laion-aesthetics v2 5+\" bij 512x512 resolutie, met 10% minder tekstconditionering voor verbeterde classifier-free guidance sampling.",
  "stable-diffusion-xl-base-1.0.description": "Een open-source tekst-naar-beeldmodel van Stability AI met toonaangevende creatieve beeldgeneratie. Het heeft sterk instructiebegrip en ondersteunt omgekeerde promptdefinities voor nauwkeurige generatie.",
  "stable-diffusion-xl.description": "stable-diffusion-xl biedt grote verbeteringen ten opzichte van v1.5 en evenaart de beste open tekst-naar-beeldresultaten. Verbeteringen omvatten een 3x grotere UNet-backbone, een verfijningsmodule voor betere beeldkwaliteit en efficiëntere trainingstechnieken.",
  "step-1-128k.description": "Balanceert prestaties en kosten voor algemene scenario’s.",
  "step-1-256k.description": "Extra lange contextverwerking, ideaal voor analyse van lange documenten.",
  "step-1-32k.description": "Ondersteunt middellange gesprekken voor een breed scala aan scenario’s.",
  "step-1-8k.description": "Klein model geschikt voor lichte taken.",
  "step-1-flash.description": "Hogesnelheidsmodel geschikt voor realtime chat.",
  "step-1.5v-mini.description": "Sterke videobegripscapaciteiten.",
  "step-1o-turbo-vision.description": "Sterk beeldbegrip, beter dan 1o in wiskunde en codering. Kleiner dan 1o met snellere output.",
  "step-1o-vision-32k.description": "Sterk beeldbegrip met betere visuele prestaties dan de Step-1V-serie.",
  "step-1v-32k.description": "Ondersteunt visuele invoer voor rijkere multimodale interactie.",
  "step-1v-8k.description": "Klein visiemodel voor basis beeld-en-tekst taken.",
  "step-1x-edit.description": "Dit model richt zich op bewerken van afbeeldingen, aanpassen en verbeteren op basis van door de gebruiker aangeleverde afbeeldingen en tekst. Ondersteunt meerdere invoerformaten, waaronder tekstbeschrijvingen en voorbeeldafbeeldingen, en genereert bewerkingen die aansluiten bij de gebruikersintentie.",
  "step-1x-medium.description": "Dit model biedt sterke beeldgeneratie op basis van tekstprompts. Met native ondersteuning voor Chinees begrijpt het Chinese beschrijvingen beter, vangt hun semantiek en zet deze om in visuele kenmerken voor nauwkeurigere generatie. Het produceert beelden van hoge resolutie en kwaliteit en ondersteunt een zekere mate van stijltransformatie.",
  "step-2-16k-exp.description": "Experimentele Step-2-versie met de nieuwste functies en doorlopende updates. Niet aanbevolen voor productie.",
  "step-2-16k.description": "Ondersteunt interacties met grote context voor complexe dialogen.",
  "step-2-mini.description": "Gebouwd op de volgende generatie interne MFA-attentiearchitectuur, levert Step-1-achtige resultaten tegen veel lagere kosten met hogere doorvoer en snellere latency. Behandelt algemene taken met sterke codeercapaciteit.",
  "step-2x-large.description": "Een nieuwe generatie StepFun-beeldmodel gericht op beeldgeneratie, produceert beelden van hoge kwaliteit op basis van tekstprompts. Levert realistischere texturen en sterkere Chinese/Engelse tekstrendering.",
  "whisper-1.description": "Een algemeen spraakherkenningsmodel dat meertalige ASR, spraakvertaling en taalidentificatie ondersteunt.",
  "wizardlm2.description": "WizardLM 2 is een taalmodel van Microsoft AI dat uitblinkt in complexe dialogen, meertalige taken, redeneren en assistenttoepassingen.",
  "wizardlm2:8x22b.description": "WizardLM 2 is een taalmodel van Microsoft AI dat uitblinkt in complexe dialogen, meertalige taken, redeneren en assistenttoepassingen.",
  "x-ai/grok-4-fast-non-reasoning.description": "Grok 4 Fast (Zonder Redenering) is xAI’s multimodale model met hoge verwerkingssnelheid en lage kosten (ondersteunt een contextvenster van 2M), bedoeld voor scenario’s die gevoelig zijn voor latentie en kosten en geen redenering binnen het model vereisen. Het staat naast de versie met redenering van Grok 4 Fast, waarbij redenering via de API-parameter kan worden ingeschakeld indien nodig. Prompts en antwoorden kunnen door xAI of OpenRouter worden gebruikt om toekomstige modellen te verbeteren.",
  "x-ai/grok-4-fast.description": "Grok 4 Fast is xAI’s model met hoge verwerkingssnelheid en lage kosten (ondersteunt een contextvenster van 2M), ideaal voor toepassingen met hoge gelijktijdigheid en lange contexten.",
  "x-ai/grok-4.1-fast-non-reasoning.description": "Grok 4.1 Fast (Zonder Redenering) is xAI’s multimodale model met hoge verwerkingssnelheid en lage kosten (ondersteunt een contextvenster van 2M), bedoeld voor scenario’s die gevoelig zijn voor latentie en kosten en geen redenering binnen het model vereisen. Het staat naast de versie met redenering van Grok 4.1 Fast, waarbij redenering via de API-parameter kan worden ingeschakeld indien nodig. Prompts en antwoorden kunnen door xAI of OpenRouter worden gebruikt om toekomstige modellen te verbeteren.",
  "x-ai/grok-4.1-fast.description": "Grok 4.1 Fast is xAI’s model met hoge verwerkingssnelheid en lage kosten (ondersteunt een contextvenster van 2M), ideaal voor toepassingen met hoge gelijktijdigheid en lange contexten.",
  "x-ai/grok-4.description": "Grok 4 is xAI's toonaangevende model voor redenering met sterke multimodale capaciteiten.",
  "x-ai/grok-code-fast-1.description": "Grok Code Fast 1 is xAI's snelle codemodel met leesbare, gebruiksvriendelijke output voor engineers.",
  "xai/grok-2-vision.description": "Grok 2 Vision blinkt uit in visuele taken en levert SOTA-prestaties op visuele wiskundige redenering (MathVista) en documentvragen (DocVQA). Het verwerkt documenten, grafieken, diagrammen, schermafbeeldingen en foto's.",
  "xai/grok-2.description": "Grok 2 is een geavanceerd model met state-of-the-art redenering, sterke chat-, codeer- en redeneercapaciteiten, en scoort hoger dan Claude 3.5 Sonnet en GPT-4 Turbo op LMSYS.",
  "xai/grok-3-fast.description": "xAI’s vlaggenschipmodel blinkt uit in zakelijke toepassingen zoals data-extractie, codering en samenvatting, met diepgaande domeinkennis in financiën, gezondheidszorg, recht en wetenschap. De snelle variant draait op snellere infrastructuur voor veel snellere reacties tegen hogere kosten per token.",
  "xai/grok-3-mini-fast.description": "xAI’s lichtgewicht model dat eerst nadenkt voordat het antwoordt, ideaal voor eenvoudige of logische taken zonder diepgaande domeinkennis. Ruwe redeneertraceringen zijn beschikbaar. De snelle variant draait op snellere infrastructuur voor veel snellere reacties tegen hogere kosten per token.",
  "xai/grok-3-mini.description": "xAI’s lichtgewicht model dat eerst nadenkt voordat het antwoordt, ideaal voor eenvoudige of logische taken zonder diepgaande domeinkennis. Ruwe redeneertraceringen zijn beschikbaar.",
  "xai/grok-3.description": "xAI’s vlaggenschipmodel blinkt uit in zakelijke toepassingen zoals data-extractie, codering en samenvatting, met diepgaande domeinkennis in financiën, gezondheidszorg, recht en wetenschap.",
  "xai/grok-4.description": "xAI’s nieuwste vlaggenschipmodel met ongeëvenaarde prestaties in natuurlijke taal, wiskunde en redenering—een ideale alleskunner.",
  "yi-large-fc.description": "Gebouwd op yi-large met verbeterde tool-integratie, geschikt voor agent- en workflowscenario’s.",
  "yi-large-preview.description": "Een vroege versie; yi-large (nieuwer) wordt aanbevolen.",
  "yi-large-rag.description": "Een geavanceerde service gebaseerd op yi-large, die ophalen en genereren combineert voor nauwkeurige antwoorden met realtime webzoekopdrachten.",
  "yi-large-turbo.description": "Uitzonderlijke waarde en prestaties, afgestemd op een sterke balans tussen kwaliteit, snelheid en kosten.",
  "yi-large.description": "Een nieuw model met 100 miljard parameters met sterke Q&A- en tekstgeneratiecapaciteiten.",
  "yi-lightning-lite.description": "Een lichtgewicht versie; yi-lightning wordt aanbevolen.",
  "yi-lightning.description": "Een recent hoogwaardig model met snellere inferentie en output van hoge kwaliteit.",
  "yi-medium-200k.description": "Een 200K lang-contextmodel voor diepgaand begrip en generatie van lange teksten.",
  "yi-medium.description": "Een afgestemd model van gemiddelde grootte met gebalanceerde capaciteiten en waarde, geoptimaliseerd voor instructievolging.",
  "yi-spark.description": "Een compact, snel model met versterkte wiskundige en codeercapaciteiten.",
  "yi-vision-v2.description": "Een visiemodel voor complexe taken met sterke multi-image interpretatie en analyse.",
  "yi-vision.description": "Een visiemodel voor complexe taken met sterke beeldinterpretatie en analyse.",
  "z-ai/glm-4.5-air.description": "GLM 4.5 Air is een lichtgewicht variant van GLM 4.5 voor kostenbewuste scenario’s, met behoud van sterke redeneercapaciteiten.",
  "z-ai/glm-4.5.description": "GLM 4.5 is Z.AI’s vlaggenschipmodel met hybride redenering, geoptimaliseerd voor engineering- en lang-contexttaken.",
  "z-ai/glm-4.6.description": "GLM 4.6 is Z.AI's vlaggenschipmodel met uitgebreide contextlengte en codeercapaciteiten.",
  "zai-org/GLM-4.5-Air.description": "GLM-4.5-Air is een basismodel voor agenttoepassingen met een Mixture-of-Experts-architectuur. Het is geoptimaliseerd voor toolgebruik, webnavigatie, softwareontwikkeling en frontend-codering, en integreert met code-agents zoals Claude Code en Roo Code. Het gebruikt hybride redenering om zowel complexe als alledaagse scenario’s aan te kunnen.",
  "zai-org/GLM-4.5.description": "GLM-4.5 is een basismodel gebouwd voor agenttoepassingen met een Mixture-of-Experts-architectuur. Het is diepgaand geoptimaliseerd voor toolgebruik, webnavigatie, softwareontwikkeling en frontend-codering, en integreert met code-agents zoals Claude Code en Roo Code. Het gebruikt hybride redenering om zowel complexe als alledaagse scenario’s aan te kunnen.",
  "zai-org/GLM-4.5V.description": "GLM-4.5V is Zhipu AI’s nieuwste VLM, gebaseerd op het GLM-4.5-Air vlaggenschiptekstmodel (106B totaal, 12B actief) met een MoE-architectuur voor sterke prestaties tegen lagere kosten. Het volgt het GLM-4.1V-Thinking pad en voegt 3D-RoPE toe voor verbeterde 3D-ruimtelijke redenering. Geoptimaliseerd via pretraining, SFT en RL, verwerkt het beelden, video’s en lange documenten en scoort het hoog op 41 openbare multimodale benchmarks. Een Thinking-modus schakelaar laat gebruikers kiezen tussen snelheid en diepgang.",
  "zai-org/GLM-4.6.description": "In vergelijking met GLM-4.5 breidt GLM-4.6 de context uit van 128K naar 200K voor complexere agenttaken. Het scoort hoger op codebenchmarks en toont sterkere prestaties in toepassingen zoals Claude Code, Cline, Roo Code en Kilo Code, inclusief betere frontendpagina-generatie. Redenering is verbeterd en toolgebruik wordt ondersteund tijdens het redeneren, wat de algehele capaciteit versterkt. Het integreert beter in agentframeworks, verbetert tool-/zoekagents en heeft een natuurlijkere schrijfstijl en rolspelervaring.",
  "zai/glm-4.5-air.description": "GLM-4.5 en GLM-4.5-Air zijn onze nieuwste vlaggenschipmodellen voor agenttoepassingen, beide gebruikmakend van MoE. GLM-4.5 heeft 355B totaal en 32B actief per forward pass; GLM-4.5-Air is slanker met 106B totaal en 12B actief.",
  "zai/glm-4.5.description": "De GLM-4.5-serie is ontworpen voor agents. Het vlaggenschip GLM-4.5 combineert redenering, codering en agentvaardigheden met 355B totale parameters (32B actief) en biedt dubbele werkmodi als hybride redeneersysteem.",
  "zai/glm-4.5v.description": "GLM-4.5V is gebaseerd op GLM-4.5-Air, erft bewezen technieken van GLM-4.1V-Thinking en schaalt met een krachtige 106B-parameter MoE-architectuur.",
  "zenmux/auto.description": "ZenMux auto-routing selecteert het best presterende en meest kostenefficiënte model uit de ondersteunde opties op basis van je aanvraag."
}
