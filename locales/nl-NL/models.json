{
  "01-ai/yi-1.5-34b-chat.description": "Het nieuwste open-source model van 01.AI met 34 miljard parameters, geschikt voor diverse dialoogscenario's. Getraind op hoogwaardige data en afgestemd op menselijke voorkeuren.",
  "01-ai/yi-1.5-9b-chat.description": "Het nieuwste open-source model van 01.AI met 9 miljard parameters, geschikt voor diverse dialoogscenario's. Getraind op hoogwaardige data en afgestemd op menselijke voorkeuren.",
  "360/deepseek-r1.description": "DeepSeek-R1, ingezet door 360, gebruikt grootschalige reinforcement learning in de post-trainingfase om redeneervermogen sterk te verbeteren met minimale labels. Presteert vergelijkbaar met OpenAI o1 op wiskunde-, code- en taalredeneertaken.",
  "360gpt-pro-trans.description": "Een vertaalspecialistisch model, diepgaand getraind voor toonaangevende vertaalprestaties.",
  "360gpt-pro.description": "360GPT Pro is een belangrijk AI-model van 360 met efficiënte tekstverwerking voor uiteenlopende NLP-scenario's. Ondersteunt begrip van lange teksten en meerstapsdialogen.",
  "360gpt-turbo-responsibility-8k.description": "360GPT Turbo Responsibility 8K legt de nadruk op semantische veiligheid en verantwoordelijkheid in contentgevoelige toepassingen, en garandeert nauwkeurige en robuuste gebruikerservaringen.",
  "360gpt-turbo.description": "360GPT Turbo biedt krachtige reken- en chatmogelijkheden met uitstekende semantische interpretatie en generatie-efficiëntie, ideaal voor bedrijven en ontwikkelaars.",
  "360gpt2-o1.description": "360gpt2-o1 bouwt een redeneerlijn op via boomzoektechnieken met een reflectiemechanisme en reinforcement learning, waardoor zelfreflectie en zelfcorrectie mogelijk zijn.",
  "360gpt2-pro.description": "360GPT2 Pro is een geavanceerd NLP-model van 360 met uitstekende tekstgeneratie en -begrip, vooral geschikt voor creatieve taken, complexe transformaties en rollenspel.",
  "360zhinao2-o1.description": "360zhinao2-o1 bouwt een redeneerlijn op via boomzoektechnieken met een reflectiemechanisme en reinforcement learning, waardoor zelfreflectie en zelfcorrectie mogelijk zijn.",
  "4.0Ultra.description": "Spark Ultra is het krachtigste model in de Spark-serie, met verbeterd tekstbegrip en samenvatting, en geavanceerde webzoekmogelijkheden. Het is een allesomvattende oplossing voor hogere productiviteit op de werkvloer en nauwkeurige antwoorden, en positioneert zich als een toonaangevend intelligent product.",
  "AnimeSharp.description": "AnimeSharp (ook bekend als \"4x-AnimeSharp\") is een open-source superresolutiemodel gebaseerd op ESRGAN van Kim2091, gericht op het opschalen en verscherpen van anime-stijl afbeeldingen. In februari 2022 hernoemd van \"4x-TextSharpV1\", oorspronkelijk ook bedoeld voor tekstafbeeldingen maar sterk geoptimaliseerd voor anime-inhoud.",
  "Baichuan2-Turbo.description": "Maakt gebruik van zoekverrijking om het model te verbinden met domein- en webkennis. Ondersteunt het uploaden van PDF/Word-bestanden en URL-invoer voor tijdige, uitgebreide informatieopvraging en professionele, nauwkeurige output.",
  "Baichuan3-Turbo-128k.description": "Met een ultralange context van 128K tokens is dit model geoptimaliseerd voor veelgebruikte bedrijfsscenario's met aanzienlijke prestatieverbeteringen. Vergeleken met Baichuan2 verbetert contentcreatie met 20%, kennis-QA met 17% en rollenspel met 40%. De algehele prestaties zijn beter dan GPT-3.5.",
  "Baichuan3-Turbo.description": "Geoptimaliseerd voor veelgebruikte bedrijfsscenario's met aanzienlijke prestatieverbeteringen. Vergeleken met Baichuan2 verbetert contentcreatie met 20%, kennis-QA met 17% en rollenspel met 40%. De algehele prestaties zijn beter dan GPT-3.5.",
  "Baichuan4-Air.description": "Een topmodel in China dat toonaangevende buitenlandse modellen overtreft op Chinese taken zoals kennis, lange teksten en creatieve generatie. Beschikt ook over toonaangevende multimodale capaciteiten met sterke resultaten op gezaghebbende benchmarks.",
  "Baichuan4-Turbo.description": "Een topmodel in China dat toonaangevende buitenlandse modellen overtreft op Chinese taken zoals kennis, lange teksten en creatieve generatie. Beschikt ook over toonaangevende multimodale capaciteiten met sterke resultaten op gezaghebbende benchmarks.",
  "Baichuan4.description": "Topprestaties op nationaal niveau, overtreft toonaangevende buitenlandse modellen op Chinese taken zoals encyclopedische kennis, lange teksten en creatieve generatie. Biedt ook toonaangevende multimodale capaciteiten en sterke benchmarkresultaten.",
  "ByteDance-Seed/Seed-OSS-36B-Instruct.description": "Seed-OSS is een familie van open-source LLM's van ByteDance Seed, ontworpen voor sterke prestaties op lange contexten, redeneren, agenttaken en algemene vaardigheden. Seed-OSS-36B-Instruct is een 36B instructiegericht model met native ultralange contextverwerking voor grote documenten of codebases. Geoptimaliseerd voor redeneren, codegeneratie en agenttaken (toolgebruik), met behoud van sterke algemene capaciteiten. Een belangrijk kenmerk is het \"Thinking Budget\", waarmee flexibele redeneerlengte mogelijk is voor betere efficiëntie.",
  "DeepSeek-R1-Distill-Llama-70B.description": "DeepSeek R1, het grotere en slimmere model in de DeepSeek-suite, is gedistilleerd in de Llama 70B-architectuur. Benchmarks en menselijke evaluaties tonen aan dat het slimmer is dan de basisversie van Llama 70B, vooral op wiskunde- en feitennauwkeurigheidstaken.",
  "DeepSeek-R1-Distill-Qwen-1.5B.description": "Een DeepSeek-R1 gedistilleerd model gebaseerd op Qwen2.5-Math-1.5B. Reinforcement learning en cold-start data optimaliseren het redeneervermogen en zetten nieuwe multitask-benchmarks voor open modellen.",
  "DeepSeek-R1-Distill-Qwen-14B.description": "DeepSeek-R1-Distill modellen zijn fijngestemd op basis van open-source modellen met behulp van voorbeelddata gegenereerd door DeepSeek-R1.",
  "DeepSeek-R1-Distill-Qwen-32B.description": "DeepSeek-R1-Distill modellen zijn fijngestemd op basis van open-source modellen met behulp van voorbeelddata gegenereerd door DeepSeek-R1.",
  "DeepSeek-R1-Distill-Qwen-7B.description": "Een DeepSeek-R1 gedistilleerd model gebaseerd op Qwen2.5-Math-7B. Reinforcement learning en cold-start data optimaliseren het redeneervermogen en zetten nieuwe multitask-benchmarks voor open modellen.",
  "DeepSeek-R1.description": "DeepSeek-R1 past grootschalige reinforcement learning toe tijdens de post-trainingfase, wat het redeneervermogen sterk verbetert met zeer weinig gelabelde data. Presteert vergelijkbaar met het OpenAI o1-productiemodel op wiskunde-, code- en taalredeneertaken.",
  "DeepSeek-V3-1.description": "DeepSeek V3.1 is een model van de volgende generatie met verbeterd complex redeneren en redeneerlijnen, geschikt voor diepgaande analysetaken.",
  "DeepSeek-V3-Fast.description": "Aanbieder: sophnet. DeepSeek V3 Fast is de high-TPS versie van DeepSeek V3 0324, met volledige precisie (niet-gekwantiseerd), sterk in code en wiskunde en met snellere reacties.",
  "DeepSeek-V3.1-Fast.description": "DeepSeek V3.1 Fast is de snelle high-TPS variant van DeepSeek V3.1. Hybride denkmodus: via chattemplates ondersteunt één model zowel denken als niet-denken. Slimmer toolgebruik: post-training verbetert prestaties op tool- en agenttaken.",
  "DeepSeek-V3.1-Think.description": "DeepSeek-V3.1 denkmodus: een nieuw hybride redeneermodel met denk- en niet-denkmodi, efficiënter dan DeepSeek-R1-0528. Post-training optimalisaties verbeteren het gebruik van agenttools en prestaties op agenttaken aanzienlijk.",
  "DeepSeek-V3.description": "DeepSeek-V3 is een MoE-model ontwikkeld door DeepSeek. Het overtreft andere open modellen zoals Qwen2.5-72B en Llama-3.1-405B op veel benchmarks en is concurrerend met toonaangevende gesloten modellen zoals GPT-4o en Claude 3.5 Sonnet.",
  "Doubao-lite-128k.description": "Doubao-lite biedt ultrasnelle reacties en betere waarde, met flexibele opties voor verschillende scenario's. Ondersteunt 128K context voor inferentie en fine-tuning.",
  "Doubao-lite-32k.description": "Doubao-lite biedt ultrasnelle reacties en betere waarde, met flexibele opties voor verschillende scenario's. Ondersteunt 32K context voor inferentie en fine-tuning.",
  "Doubao-lite-4k.description": "Doubao-lite biedt ultrasnelle reacties en betere waarde, met flexibele opties voor verschillende scenario's. Ondersteunt 4K context voor inferentie en fine-tuning.",
  "Doubao-pro-128k.description": "Best presterend vlaggenschipmodel voor complexe taken, sterk in referentie-QA, samenvatting, creatie, classificatie en rollenspel. Ondersteunt 128K context voor inferentie en fine-tuning.",
  "Doubao-pro-32k.description": "Best presterend vlaggenschipmodel voor complexe taken, sterk in referentie-QA, samenvatting, creatie, classificatie en rollenspel. Ondersteunt 32K context voor inferentie en fine-tuning.",
  "Doubao-pro-4k.description": "Best presterend vlaggenschipmodel voor complexe taken, sterk in referentie-QA, samenvatting, creatie, classificatie en rollenspel. Ondersteunt 4K context voor inferentie en fine-tuning.",
  "DreamO.description": "DreamO is een open-source model voor beeldpersonalisatie, gezamenlijk ontwikkeld door ByteDance en de Universiteit van Peking. Het gebruikt een uniforme architectuur om meerdere beeldgeneratietaken te ondersteunen. Dankzij efficiënte compositiemodellering genereert het zeer consistente, gepersonaliseerde beelden op basis van door de gebruiker gespecificeerde identiteit, onderwerp, stijl, achtergrond en andere voorwaarden.",
  "amazon/titan-embed-text-v2.description": "Amazon Titan Text Embeddings V2 is een lichtgewicht, efficiënt meertalig embed-model dat 1024, 512 en 256 dimensies ondersteunt.",
  "gemini-flash-latest.description": "Laatste release van Gemini Flash",
  "gemini-flash-lite-latest.description": "Laatste release van Gemini Flash-Lite",
  "gemini-pro-latest.description": "Laatste release van Gemini Pro",
  "meta/Llama-3.2-90B-Vision-Instruct.description": "Geavanceerd beeldredeneren voor toepassingen met visueel begrip.",
  "meta/Llama-3.3-70B-Instruct.description": "Llama 3.3 is het meest geavanceerde meertalige open-source Llama-model, met prestaties vergelijkbaar met 405B tegen zeer lage kosten. Het is gebaseerd op een Transformer-architectuur en verbeterd met SFT en RLHF voor bruikbaarheid en veiligheid. De instructie-afgestemde versie is geoptimaliseerd voor meertalige gesprekken en overtreft veel open en gesloten chatmodellen op industriestandaarden. Kennisgrens: dec 2023.",
  "meta/Meta-Llama-3-70B-Instruct.description": "Een krachtig model met 70 miljard parameters dat uitblinkt in redeneren, coderen en brede taaltoepassingen.",
  "meta/Meta-Llama-3-8B-Instruct.description": "Een veelzijdig model met 8 miljard parameters, geoptimaliseerd voor chat en tekstgeneratie.",
  "meta/Meta-Llama-3.1-405B-Instruct.description": "Llama 3.1 instructie-afgestemd tekstmodel, geoptimaliseerd voor meertalige chat, met sterke prestaties op gangbare industriestandaarden onder open en gesloten chatmodellen.",
  "meta/Meta-Llama-3.1-70B-Instruct.description": "Llama 3.1 instructie-afgestemd tekstmodel, geoptimaliseerd voor meertalige chat, met sterke prestaties op gangbare industriestandaarden onder open en gesloten chatmodellen.",
  "meta/Meta-Llama-3.1-8B-Instruct.description": "Llama 3.1 instructie-afgestemd tekstmodel, geoptimaliseerd voor meertalige chat, met sterke prestaties op gangbare industriestandaarden onder open en gesloten chatmodellen.",
  "meta/llama-3-70b.description": "Een open-source model met 70 miljard parameters, door Meta fijngestemd voor instructievolging en geleverd door Groq op LPU-hardware voor snelle, efficiënte inferentie.",
  "meta/llama-3-8b.description": "Een open-source model met 8 miljard parameters, door Meta fijngestemd voor instructievolging en geleverd door Groq op LPU-hardware voor snelle, efficiënte inferentie.",
  "meta/llama-3.1-405b-instruct.description": "Een geavanceerd LLM dat synthetische datageneratie, kennisdistillatie en redeneren ondersteunt voor chatbots, codering en domeinspecifieke taken.",
  "meta/llama-3.1-70b-instruct.description": "Ontworpen voor complexe dialogen met uitstekend contextbegrip, redeneren en tekstgeneratie.",
  "meta/llama-3.1-70b.description": "Een bijgewerkte Meta Llama 3 70B Instruct met 128K context, meertalige ondersteuning en verbeterd redeneervermogen.",
  "meta/llama-3.1-8b-instruct.description": "Een geavanceerd model met sterke taalbegrip, redeneren en tekstgeneratie.",
  "meta/llama-3.1-8b.description": "Llama 3.1 8B ondersteunt een contextvenster van 128K, ideaal voor realtime chat en data-analyse, en biedt aanzienlijke kostenbesparingen ten opzichte van grotere modellen. Geleverd door Groq op LPU-hardware voor snelle, efficiënte inferentie.",
  "meta/llama-3.2-11b-vision-instruct.description": "Een toonaangevend visie-taalmodel dat uitblinkt in hoogwaardig redeneren op basis van beelden.",
  "meta/llama-3.2-11b.description": "Een instructie-afgestemd beeldredeneermodel (tekst+beeldinvoer, tekstuitvoer), geoptimaliseerd voor visuele herkenning, beeldredeneren, bijschriften en algemene beeld-QA.",
  "meta/llama-3.2-1b-instruct.description": "Een geavanceerd klein taalmodel met sterk begrip, redeneren en tekstgeneratie.",
  "meta/llama-3.2-1b.description": "Alleen-tekstmodel voor toepassingen op apparaten zoals meertalige lokale zoekopdrachten, samenvattingen en herschrijven.",
  "meta/llama-3.2-3b-instruct.description": "Een geavanceerd klein taalmodel met sterk begrip, redeneren en tekstgeneratie.",
  "meta/llama-3.2-3b.description": "Alleen-tekstmodel, fijngestemd voor toepassingen op apparaten zoals meertalige lokale zoekopdrachten, samenvattingen en herschrijven.",
  "meta/llama-3.2-90b-vision-instruct.description": "Een toonaangevend visie-taalmodel dat uitblinkt in hoogwaardig redeneren op basis van beelden.",
  "meta/llama-3.2-90b.description": "Een instructie-afgestemd beeldredeneermodel (tekst+beeldinvoer, tekstuitvoer), geoptimaliseerd voor visuele herkenning, beeldredeneren, bijschriften en algemene beeld-QA.",
  "meta/llama-3.3-70b-instruct.description": "Een geavanceerd LLM dat sterk is in redeneren, wiskunde, gezond verstand en functieaanroepen.",
  "meta/llama-3.3-70b.description": "Een perfecte balans tussen prestaties en efficiëntie. Ontworpen voor hoogwaardige conversatie-AI in contentcreatie, zakelijke toepassingen en onderzoek, met sterk taalbegrip voor samenvattingen, classificatie, sentimentanalyse en codegeneratie.",
  "meta/llama-4-maverick.description": "De Llama 4-familie is een native multimodaal AI-model dat tekst- en multimodale ervaringen ondersteunt, met MoE voor toonaangevend tekst- en beeldbegrip. Llama 4 Maverick is een 17B-model met 128 experts, geleverd door DeepInfra.",
  "meta/llama-4-scout.description": "De Llama 4-familie is een native multimodaal AI-model dat tekst- en multimodale ervaringen ondersteunt, met MoE voor toonaangevend tekst- en beeldbegrip. Llama 4 Scout is een 17B-model met 16 experts, geleverd door DeepInfra.",
  "microsoft/Phi-3-medium-128k-instruct.description": "Hetzelfde Phi-3-medium model met een groter contextvenster voor RAG of few-shot prompts.",
  "microsoft/Phi-3-medium-4k-instruct.description": "Een model met 14 miljard parameters van hogere kwaliteit dan Phi-3-mini, gericht op hoogwaardige, redeneerintensieve data.",
  "microsoft/Phi-3-mini-128k-instruct.description": "Hetzelfde Phi-3-mini model met een groter contextvenster voor RAG of few-shot prompts.",
  "microsoft/Phi-3-mini-4k-instruct.description": "Het kleinste lid van de Phi-3-familie, geoptimaliseerd voor kwaliteit en lage latentie.",
  "microsoft/Phi-3-small-128k-instruct.description": "Hetzelfde Phi-3-small model met een groter contextvenster voor RAG of few-shot prompts.",
  "microsoft/Phi-3-small-8k-instruct.description": "Een model met 7 miljard parameters van hogere kwaliteit dan Phi-3-mini, gericht op hoogwaardige, redeneerintensieve data.",
  "microsoft/Phi-3.5-mini-instruct.description": "Een bijgewerkte versie van het Phi-3-mini model.",
  "microsoft/Phi-3.5-vision-instruct.description": "Een bijgewerkte versie van het Phi-3-vision model.",
  "microsoft/WizardLM-2-8x22B.description": "WizardLM 2 is een taalmodel van Microsoft AI dat uitblinkt in complexe dialogen, meertalige taken, redeneren en assistenten.",
  "microsoft/wizardlm-2-8x22b.description": "WizardLM-2 8x22B is het meest geavanceerde Wizard-model van Microsoft AI met zeer competitieve prestaties.",
  "minicpm-v.description": "MiniCPM-V is het volgende generatie multimodale model van OpenBMB met uitstekende OCR- en multimodale begrip voor uiteenlopende toepassingen.",
  "minimax-m2.description": "MiniMax M2 is een efficiënt LLM gebouwd voor codering en agent-workflows.",
  "minimax/minimax-m2.description": "MiniMax-M2 is een waardevol model dat uitblinkt in codering en agenttaken voor veel technische scenario's.",
  "minimaxai/minimax-m2.description": "MiniMax-M2 is een compact, snel, kosteneffectief MoE-model (230B totaal, 10B actief) gebouwd voor topniveau codering en agentprestaties met behoud van sterke algemene intelligentie. Het blinkt uit in bewerkingen over meerdere bestanden, code-uitvoerings- en correctielussen, testvalidatie en complexe toolchains.",
  "ministral-3b-latest.description": "Ministral 3B is het topmodel van Mistral voor edge-toepassingen.",
  "ministral-8b-latest.description": "Ministral 8B is een zeer kosteneffectief edge-model van Mistral.",
  "mistral-ai/Mistral-Large-2411.description": "Het vlaggenschipmodel van Mistral voor complexe taken die grootschalig redeneren of specialisatie vereisen (synthetische tekstgeneratie, codegeneratie, RAG of agents).",
  "mistral-ai/Mistral-Nemo.description": "Mistral Nemo is een geavanceerd LLM met state-of-the-art redeneren, wereldkennis en codering voor zijn grootte.",
  "mistral-ai/mistral-small-2503.description": "Mistral Small is geschikt voor elke taaltaak die hoge efficiëntie en lage latentie vereist.",
  "mistral-large-instruct.description": "Mistral-Large-Instruct-2407 is een geavanceerd dense LLM met 123 miljard parameters en state-of-the-art redeneren, kennis en codering.",
  "mistral-large-latest.description": "Mistral Large is het vlaggenschipmodel, sterk in meertalige taken, complex redeneren en codegeneratie—ideaal voor hoogwaardige toepassingen.",
  "mistral-large.description": "Mixtral Large is het vlaggenschipmodel van Mistral, dat codegeneratie, wiskunde en redeneren combineert met een contextvenster van 128K."
}
