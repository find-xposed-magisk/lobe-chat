{
  "01-ai/yi-1.5-34b-chat.description": "Le dernier modèle open source affiné de 01.AI avec 34 milliards de paramètres, prenant en charge divers scénarios de dialogue, entraîné sur des données de haute qualité et aligné sur les préférences humaines.",
  "01-ai/yi-1.5-9b-chat.description": "Le dernier modèle open source affiné de 01.AI avec 9 milliards de paramètres, prenant en charge divers scénarios de dialogue, entraîné sur des données de haute qualité et aligné sur les préférences humaines.",
  "360/deepseek-r1.description": "DeepSeek-R1, déployé par 360, utilise un apprentissage par renforcement à grande échelle en post-entraînement pour améliorer considérablement le raisonnement avec un minimum d’étiquettes. Il rivalise avec OpenAI o1 sur les tâches de mathématiques, de code et de raisonnement en langage naturel.",
  "360gpt-pro-trans.description": "Un modèle spécialisé dans la traduction, affiné en profondeur pour offrir une qualité de traduction de premier plan.",
  "360gpt-pro.description": "360GPT Pro est un modèle clé de 360 AI, optimisé pour le traitement efficace du texte dans divers scénarios de traitement du langage naturel, avec prise en charge de la compréhension de longs textes et du dialogue multi-tours.",
  "360gpt-turbo-responsibility-8k.description": "360GPT Turbo Responsibility 8K met l’accent sur la sécurité sémantique et la responsabilité dans les applications sensibles au contenu, garantissant des expériences utilisateur précises et robustes.",
  "360gpt-turbo.description": "360GPT Turbo offre de solides capacités de calcul et de conversation avec une excellente compréhension sémantique et une génération efficace, idéal pour les entreprises et les développeurs.",
  "360gpt2-o1.description": "360gpt2-o1 construit une chaîne de raisonnement via une recherche arborescente avec un mécanisme de réflexion et un entraînement par renforcement, permettant l’auto-réflexion et l’auto-correction.",
  "360gpt2-pro.description": "360GPT2 Pro est un modèle NLP avancé de 360, excellent en génération et compréhension de texte, particulièrement adapté aux tâches créatives, aux transformations complexes et aux jeux de rôle.",
  "360zhinao2-o1.description": "360zhinao2-o1 construit une chaîne de raisonnement via une recherche arborescente avec un mécanisme de réflexion et un entraînement par renforcement, permettant l’auto-réflexion et l’auto-correction.",
  "4.0Ultra.description": "Spark Ultra est le modèle le plus puissant de la série Spark, améliorant la compréhension et le résumé de texte tout en optimisant la recherche web. Il constitue une solution complète pour accroître la productivité au travail et fournir des réponses précises, se positionnant comme un produit intelligent de premier plan.",
  "AnimeSharp.description": "AnimeSharp (également connu sous le nom de \"4x-AnimeSharp\") est un modèle open source de super-résolution basé sur ESRGAN par Kim2091, conçu pour l’agrandissement et l’affinage des images de style anime. Il a été renommé depuis \"4x-TextSharpV1\" en février 2022, initialement destiné aussi aux images de texte mais désormais fortement optimisé pour le contenu anime.",
  "Baichuan2-Turbo.description": "Utilise l’augmentation par recherche pour connecter le modèle aux connaissances du domaine et du web. Prend en charge les téléchargements de fichiers PDF/Word et les entrées d’URL pour une récupération rapide et complète, avec des résultats professionnels et précis.",
  "Baichuan3-Turbo-128k.description": "Avec une fenêtre de contexte ultra-longue de 128K, ce modèle est optimisé pour les scénarios d’entreprise à haute fréquence avec des gains majeurs et une forte valeur ajoutée. Par rapport à Baichuan2, la création de contenu s’améliore de 20 %, les questions-réponses de connaissances de 17 % et les jeux de rôle de 40 %. Ses performances globales surpassent celles de GPT-3.5.",
  "Baichuan3-Turbo.description": "Optimisé pour les scénarios d’entreprise à haute fréquence avec des gains majeurs et une forte valeur ajoutée. Par rapport à Baichuan2, la création de contenu s’améliore de 20 %, les questions-réponses de connaissances de 17 % et les jeux de rôle de 40 %. Ses performances globales surpassent celles de GPT-3.5.",
  "Baichuan4-Air.description": "Un modèle de pointe en Chine, surpassant les principaux modèles étrangers sur les tâches en chinois telles que les connaissances, les textes longs et la génération créative. Il offre également des capacités multimodales de premier plan avec d’excellents résultats sur des benchmarks reconnus.",
  "Baichuan4-Turbo.description": "Un modèle de pointe en Chine, surpassant les principaux modèles étrangers sur les tâches en chinois telles que les connaissances, les textes longs et la génération créative. Il offre également des capacités multimodales de premier plan avec d’excellents résultats sur des benchmarks reconnus.",
  "Baichuan4.description": "Performances nationales de premier plan, surpassant les modèles étrangers de référence sur les tâches en chinois telles que les connaissances encyclopédiques, les textes longs et la génération créative. Il propose également des capacités multimodales de pointe et d’excellents résultats aux benchmarks.",
  "ByteDance-Seed/Seed-OSS-36B-Instruct.description": "Seed-OSS est une famille de modèles LLM open source de ByteDance Seed, conçue pour une gestion efficace des contextes longs, le raisonnement, les agents et les capacités générales. Seed-OSS-36B-Instruct est un modèle de 36 milliards de paramètres affiné pour les instructions, avec un contexte ultra-long natif pour traiter de grands documents ou bases de code. Il est optimisé pour le raisonnement, la génération de code et les tâches d’agent (utilisation d’outils), tout en conservant de solides capacités générales. Une fonctionnalité clé est le \"budget de réflexion\", permettant une longueur de raisonnement flexible pour améliorer l’efficacité.",
  "DeepSeek-R1-Distill-Llama-70B.description": "DeepSeek R1, le modèle le plus grand et le plus intelligent de la suite DeepSeek, est distillé dans l’architecture Llama 70B. Les benchmarks et les évaluations humaines montrent qu’il est plus performant que le Llama 70B de base, notamment sur les tâches de mathématiques et de précision factuelle.",
  "DeepSeek-R1-Distill-Qwen-1.5B.description": "Un modèle distillé DeepSeek-R1 basé sur Qwen2.5-Math-1.5B. L’apprentissage par renforcement et les données de démarrage à froid optimisent les performances de raisonnement, établissant de nouveaux benchmarks multitâches pour les modèles open source.",
  "DeepSeek-R1-Distill-Qwen-14B.description": "Les modèles DeepSeek-R1-Distill sont affinés à partir de modèles open source à l’aide d’échantillons générés par DeepSeek-R1.",
  "DeepSeek-R1-Distill-Qwen-32B.description": "Les modèles DeepSeek-R1-Distill sont affinés à partir de modèles open source à l’aide d’échantillons générés par DeepSeek-R1.",
  "DeepSeek-R1-Distill-Qwen-7B.description": "Un modèle distillé DeepSeek-R1 basé sur Qwen2.5-Math-7B. L’apprentissage par renforcement et les données de démarrage à froid optimisent les performances de raisonnement, établissant de nouveaux benchmarks multitâches pour les modèles open source.",
  "DeepSeek-R1.description": "DeepSeek-R1 applique un apprentissage par renforcement à grande échelle en post-entraînement, améliorant considérablement le raisonnement avec très peu de données étiquetées. Il rivalise avec le modèle de production OpenAI o1 sur les tâches de mathématiques, de code et de raisonnement en langage naturel.",
  "DeepSeek-V3-1.description": "DeepSeek V3.1 est un modèle de raisonnement de nouvelle génération avec des capacités améliorées pour le raisonnement complexe et la chaîne de pensée, adapté aux tâches d’analyse approfondie.",
  "DeepSeek-V3-Fast.description": "Fournisseur : sophnet. DeepSeek V3 Fast est la version à haut débit de DeepSeek V3 0324, en précision complète (non quantifiée), avec de meilleures performances en code et mathématiques et des réponses plus rapides.",
  "DeepSeek-V3.1-Fast.description": "DeepSeek V3.1 Fast est la variante rapide à haut débit de DeepSeek V3.1. Mode de pensée hybride : via des modèles de conversation, un seul modèle prend en charge les modes avec ou sans raisonnement. Utilisation d’outils plus intelligente : le post-entraînement améliore les performances des tâches d’agent et d’outil.",
  "DeepSeek-V3.1-Think.description": "Mode de réflexion DeepSeek-V3.1 : un nouveau modèle de raisonnement hybride avec modes de pensée et non-pensée, plus efficace que DeepSeek-R1-0528. Les optimisations post-entraînement améliorent considérablement l’utilisation des outils d’agent et les performances des tâches d’agent.",
  "DeepSeek-V3.description": "DeepSeek-V3 est un modèle MoE développé par DeepSeek. Il surpasse d’autres modèles open source comme Qwen2.5-72B et Llama-3.1-405B sur de nombreux benchmarks et rivalise avec les modèles fermés de pointe tels que GPT-4o et Claude 3.5 Sonnet.",
  "Doubao-lite-128k.description": "Doubao-lite offre des réponses ultra-rapides et un excellent rapport qualité-prix, avec des options flexibles selon les cas d’usage. Prend en charge un contexte de 128K pour l’inférence et l’ajustement fin.",
  "Doubao-lite-32k.description": "Doubao-lite offre des réponses ultra-rapides et un excellent rapport qualité-prix, avec des options flexibles selon les cas d’usage. Prend en charge un contexte de 32K pour l’inférence et l’ajustement fin.",
  "Doubao-lite-4k.description": "Doubao-lite offre des réponses ultra-rapides et un excellent rapport qualité-prix, avec des options flexibles selon les cas d’usage. Prend en charge un contexte de 4K pour l’inférence et l’ajustement fin.",
  "Doubao-pro-128k.description": "Modèle phare le plus performant pour les tâches complexes, excellent en questions-réponses avec références, résumé, création, classification et jeu de rôle. Prend en charge un contexte de 128K pour l’inférence et l’ajustement fin.",
  "Doubao-pro-32k.description": "Modèle phare le plus performant pour les tâches complexes, excellent en questions-réponses avec références, résumé, création, classification et jeu de rôle. Prend en charge un contexte de 32K pour l’inférence et l’ajustement fin.",
  "Doubao-pro-4k.description": "Modèle phare le plus performant pour les tâches complexes, excellent en questions-réponses avec références, résumé, création, classification et jeu de rôle. Prend en charge un contexte de 4K pour l’inférence et l’ajustement fin.",
  "DreamO.description": "DreamO est un modèle open source de personnalisation d’images développé conjointement par ByteDance et l’Université de Pékin, utilisant une architecture unifiée pour prendre en charge la génération d’images multitâches. Il utilise une modélisation compositionnelle efficace pour générer des images personnalisées et cohérentes selon l’identité, le sujet, le style, l’arrière-plan et d’autres conditions spécifiées par l’utilisateur.",
  "ERNIE-3.5-128K.description": "Modèle LLM phare de Baidu, entraîné sur de vastes corpus chinois/anglais, avec de solides capacités générales pour la conversation, la création et l’utilisation de plugins ; prend en charge l’intégration automatique du plugin Baidu Search pour des réponses actualisées.",
  "ERNIE-3.5-8K-Preview.description": "Modèle LLM phare de Baidu, entraîné sur de vastes corpus chinois/anglais, avec de solides capacités générales pour la conversation, la création et l’utilisation de plugins ; prend en charge l’intégration automatique du plugin Baidu Search pour des réponses actualisées.",
  "ERNIE-3.5-8K.description": "Modèle LLM phare de Baidu, entraîné sur de vastes corpus chinois/anglais, avec de solides capacités générales pour la conversation, la création et l’utilisation de plugins ; prend en charge l’intégration automatique du plugin Baidu Search pour des réponses actualisées.",
  "ERNIE-4.0-8K-Latest.description": "Modèle LLM ultra-large phare de Baidu avec des améliorations complètes par rapport à ERNIE 3.5, adapté aux tâches complexes dans divers domaines ; prend en charge l’intégration du plugin Baidu Search pour des réponses actualisées.",
  "ERNIE-4.0-8K-Preview.description": "Modèle LLM ultra-large phare de Baidu avec des améliorations complètes par rapport à ERNIE 3.5, adapté aux tâches complexes dans divers domaines ; prend en charge l’intégration du plugin Baidu Search pour des réponses actualisées.",
  "ERNIE-4.0-Turbo-8K-Latest.description": "Modèle LLM ultra-large phare de Baidu avec d’excellentes performances globales pour les tâches complexes, intégrant le plugin Baidu Search pour des réponses actualisées. Surpasse ERNIE 4.0.",
  "ERNIE-4.0-Turbo-8K-Preview.description": "Modèle LLM ultra-large phare de Baidu avec d’excellentes performances globales pour les tâches complexes, intégrant le plugin Baidu Search pour des réponses actualisées. Surpasse ERNIE 4.0.",
  "ERNIE-Character-8K.description": "Modèle LLM de Baidu spécialisé dans les domaines verticaux pour les PNJ de jeux, le service client et le jeu de rôle, avec une meilleure cohérence de personnage, un meilleur suivi des instructions et un raisonnement renforcé.",
  "ERNIE-Lite-Pro-128K.description": "Modèle LLM léger de Baidu alliant qualité et performance d’inférence, supérieur à ERNIE Lite et adapté aux accélérateurs à faible puissance de calcul.",
  "ERNIE-Speed-128K.description": "Dernier modèle LLM haute performance de Baidu (2024) avec de solides capacités générales, idéal comme base pour l’ajustement fin dans des scénarios spécifiques, avec d’excellentes performances en raisonnement.",
  "ERNIE-Speed-Pro-128K.description": "Dernier modèle LLM haute performance de Baidu (2024) avec de solides capacités générales, supérieur à ERNIE Speed, idéal comme base pour l’ajustement fin avec d’excellentes performances en raisonnement.",
  "FLUX-1.1-pro.description": "FLUX.1.1 Pro",
  "FLUX.1-Kontext-dev.description": "FLUX.1-Kontext-dev est un modèle multimodal de génération et d’édition d’images développé par Black Forest Labs, basé sur une architecture Rectified Flow Transformer avec 12 milliards de paramètres. Il se concentre sur la génération, la reconstruction, l’amélioration ou l’édition d’images selon des conditions contextuelles données. Il combine les atouts de la génération contrôlable des modèles de diffusion avec la modélisation contextuelle des Transformers, produisant des résultats de haute qualité pour des tâches telles que l’inpainting, l’outpainting et la reconstruction de scènes visuelles.",
  "FLUX.1-Kontext-pro.description": "FLUX.1 Kontext [pro]",
  "FLUX.1-dev.description": "FLUX.1-dev est un modèle de langage multimodal open source (MLLM) de Black Forest Labs, optimisé pour les tâches image-texte, combinant compréhension et génération d’images et de textes. Construit sur des LLM avancés (comme Mistral-7B), il utilise un encodeur visuel soigneusement conçu et un ajustement par instructions en plusieurs étapes pour permettre la coordination multimodale et le raisonnement sur des tâches complexes.",
  "Gryphe/MythoMax-L2-13b.description": "MythoMax-L2 (13B) est un modèle innovant pour des domaines variés et des tâches complexes.",
  "HelloMeme.description": "HelloMeme est un outil d’IA qui génère des mèmes, GIFs ou courtes vidéos à partir des images ou mouvements que vous fournissez. Aucune compétence en dessin ou en codage n’est requise : une simple image de référence suffit pour créer un contenu amusant, attrayant et stylistiquement cohérent.",
  "HiDream-I1-Full.description": "HiDream-E1-Full est un modèle open source d’édition d’images multimodal de HiDream.ai, basé sur une architecture Diffusion Transformer avancée et une solide compréhension du langage (intégrant LLaMA 3.1-8B-Instruct). Il prend en charge la génération d’images guidée par le langage naturel, le transfert de style, les modifications locales et la repeinture, avec une excellente compréhension et exécution image-texte.",
  "HunyuanDiT-v1.2-Diffusers-Distilled.description": "hunyuandit-v1.2-distilled est un modèle léger de génération d’images à partir de texte, optimisé par distillation pour produire rapidement des images de haute qualité, particulièrement adapté aux environnements à faibles ressources et à la génération en temps réel.",
  "InstantCharacter.description": "InstantCharacter est un modèle de génération de personnages personnalisés sans ajustement, publié par Tencent AI en 2025, visant une génération fidèle et cohérente de personnages à travers différents scénarios. Il peut modéliser un personnage à partir d’une seule image de référence et le transférer de manière flexible entre styles, actions et arrière-plans.",
  "InternVL2-8B.description": "InternVL2-8B est un puissant modèle vision-langage prenant en charge le traitement multimodal image-texte, capable de reconnaître précisément le contenu des images et de générer des descriptions ou réponses pertinentes.",
  "InternVL2.5-26B.description": "InternVL2.5-26B est un puissant modèle vision-langage prenant en charge le traitement multimodal image-texte, capable de reconnaître précisément le contenu des images et de générer des descriptions ou réponses pertinentes.",
  "Kolors.description": "Kolors est un modèle de génération d’images à partir de texte développé par l’équipe Kolors de Kuaishou. Entraîné avec des milliards de paramètres, il se distingue par sa qualité visuelle, sa compréhension sémantique du chinois et son rendu textuel.",
  "Kwai-Kolors/Kolors.description": "Kolors est un modèle de génération d’images à partir de texte à grande échelle basé sur la diffusion latente, développé par l’équipe Kolors de Kuaishou. Entraîné sur des milliards de paires texte-image, il excelle en qualité visuelle, précision sémantique complexe et rendu de texte en chinois/anglais, avec une forte capacité de compréhension et de génération de contenu en chinois.",
  "Kwaipilot/KAT-Dev.description": "KAT-Dev (32B) est un modèle open source de 32 milliards de paramètres pour les tâches d’ingénierie logicielle. Il atteint un taux de résolution de 62,4 % sur SWE-Bench Verified, se classant 5e parmi les modèles open source. Il est optimisé par entraînement intermédiaire, SFT et RL pour la complétion de code, la correction de bugs et la relecture de code.",
  "Llama-3.2-11B-Vision-Instruct.description": "Raisonnement visuel puissant sur des images haute résolution, adapté aux applications de compréhension visuelle.",
  "Llama-3.2-90B-Vision-Instruct\t.description": "Raisonnement visuel avancé pour les applications d’agents de compréhension visuelle.",
  "Meta-Llama-3-3-70B-Instruct.description": "Llama 3.3 70B est un modèle Transformer polyvalent pour les tâches de conversation et de génération.",
  "Meta-Llama-3.1-405B-Instruct.description": "Modèle textuel Llama 3.1 ajusté par instructions, optimisé pour la conversation multilingue, avec d’excellentes performances sur les principaux benchmarks industriels, surpassant de nombreux modèles ouverts et fermés.",
  "Meta-Llama-3.1-70B-Instruct.description": "Modèle textuel Llama 3.1 ajusté par instructions, optimisé pour la conversation multilingue, avec d’excellentes performances sur les principaux benchmarks industriels, surpassant de nombreux modèles ouverts et fermés.",
  "Meta-Llama-3.1-8B-Instruct.description": "Modèle textuel Llama 3.1 ajusté par instructions, optimisé pour la conversation multilingue, avec d’excellentes performances sur les principaux benchmarks industriels, surpassant de nombreux modèles ouverts et fermés.",
  "Meta-Llama-3.2-1B-Instruct.description": "Modèle linguistique de pointe de petite taille avec une solide compréhension du langage, un excellent raisonnement et une génération de texte efficace.",
  "Meta-Llama-3.2-3B-Instruct.description": "Modèle linguistique de pointe de petite taille avec une solide compréhension du langage, un excellent raisonnement et une génération de texte efficace.",
  "Meta-Llama-3.3-70B-Instruct.description": "Llama 3.3 est le modèle Llama multilingue open source le plus avancé, offrant des performances proches de celles du modèle 405B à un coût très faible. Basé sur une architecture Transformer, il est amélioré par SFT et RLHF pour l’utilité et la sécurité. La version ajustée par instructions est optimisée pour la conversation multilingue et surpasse de nombreux modèles ouverts et fermés sur les benchmarks industriels. Date de coupure des connaissances : décembre 2023.",
  "Meta-Llama-4-Maverick-17B-128E-Instruct-FP8.description": "Llama 4 Maverick est un grand modèle MoE avec activation efficace des experts pour des performances de raisonnement élevées.",
  "MiniMax-M1.description": "Un nouveau modèle de raisonnement interne avec 80 000 chaînes de pensée et 1 million d’entrées, offrant des performances comparables aux meilleurs modèles mondiaux.",
  "MiniMax-M2-Stable.description": "Conçu pour un codage efficace et des flux de travail d’agents, avec une plus grande simultanéité pour un usage commercial.",
  "MiniMax-M2.1-Lightning.description": "Puissante capacité de programmation multilingue, une expérience de codage entièrement améliorée. Plus rapide, plus efficace.",
  "MiniMax-M2.1.description": "Puissante capacité de programmation multilingue, une expérience de codage entièrement améliorée",
  "MiniMax-M2.description": "Conçu pour un codage efficace et des flux de travail d'agents",
  "MiniMax-Text-01.description": "MiniMax-01 introduit une attention linéaire à grande échelle au-delà des Transformers classiques, avec 456 milliards de paramètres et 45,9 milliards activés par passage. Il atteint des performances de premier plan et prend en charge jusqu’à 4 millions de jetons de contexte (32× GPT-4o, 20× Claude-3.5-Sonnet).",
  "MiniMaxAI/MiniMax-M1-80k.description": "MiniMax-M1 est un modèle de raisonnement à attention hybride à grande échelle avec poids ouverts, totalisant 456 milliards de paramètres et environ 45,9 milliards actifs par jeton. Il prend en charge nativement un contexte de 1 million de jetons et utilise Flash Attention pour réduire les FLOPs de 75 % sur une génération de 100 000 jetons par rapport à DeepSeek R1. Grâce à une architecture MoE, CISPO et un entraînement RL à attention hybride, il atteint des performances de pointe sur les tâches de raisonnement à long contexte et d’ingénierie logicielle réelle.",
  "MiniMaxAI/MiniMax-M2.description": "MiniMax-M2 redéfinit l’efficacité des agents. C’est un modèle MoE compact, rapide et économique avec 230 milliards de paramètres totaux et 10 milliards actifs, conçu pour des tâches de codage et d’agents de haut niveau tout en conservant une intelligence générale solide. Avec seulement 10 milliards de paramètres actifs, il rivalise avec des modèles bien plus grands, ce qui en fait un choix idéal pour des applications à haute efficacité.",
  "Moonshot-Kimi-K2-Instruct.description": "1 000 milliards de paramètres totaux avec 32 milliards actifs. Parmi les modèles non pensants, il excelle dans les connaissances de pointe, les mathématiques et le codage, et se montre plus performant dans les tâches générales d’agent. Optimisé pour les charges de travail d’agents, il peut agir, et pas seulement répondre. Idéal pour les conversations générales, improvisées et les expériences d’agents, en tant que modèle réflexe sans réflexion prolongée.",
  "NousResearch/Nous-Hermes-2-Mixtral-8x7B-DPO.description": "Nous Hermes 2 - Mixtral 8x7B-DPO (46,7B) est un modèle d’instruction de haute précision pour les calculs complexes.",
  "OmniConsistency.description": "OmniConsistency améliore la cohérence stylistique et la généralisation dans les tâches image-à-image en introduisant des Diffusion Transformers (DiTs) à grande échelle et des données stylisées appariées, évitant ainsi la dégradation du style.",
  "Phi-3-medium-128k-instruct.description": "Le même modèle Phi-3-medium avec une fenêtre de contexte élargie pour les invites RAG ou few-shot.",
  "Phi-3-medium-4k-instruct.description": "Un modèle de 14 milliards de paramètres avec une qualité supérieure à Phi-3-mini, axé sur des données de haute qualité nécessitant un raisonnement poussé.",
  "Phi-3-mini-128k-instruct.description": "Le même modèle Phi-3-mini avec une fenêtre de contexte élargie pour les invites RAG ou few-shot.",
  "Phi-3-mini-4k-instruct.description": "Le plus petit membre de la famille Phi-3, optimisé pour la qualité et une faible latence.",
  "Phi-3-small-128k-instruct.description": "Le même modèle Phi-3-small avec une fenêtre de contexte élargie pour les invites RAG ou few-shot.",
  "Phi-3-small-8k-instruct.description": "Un modèle de 7 milliards de paramètres avec une qualité supérieure à Phi-3-mini, axé sur des données de haute qualité nécessitant un raisonnement poussé.",
  "Phi-3.5-mini-instruct.description": "Une version mise à jour du modèle Phi-3-mini.",
  "Phi-3.5-vision-instrust.description": "Une version mise à jour du modèle Phi-3-vision.",
  "Pro/Qwen/Qwen2-7B-Instruct.description": "Qwen2-7B-Instruct est un LLM de 7 milliards de paramètres ajusté pour les instructions, de la série Qwen2. Il utilise une architecture Transformer avec SwiGLU, un biais QKV pour l’attention et une attention à requêtes groupées, capable de gérer de grandes entrées. Il excelle en compréhension linguistique, génération, tâches multilingues, codage, mathématiques et raisonnement, surpassant la plupart des modèles open source et rivalisant avec les modèles propriétaires. Il dépasse Qwen1.5-7B-Chat sur plusieurs benchmarks.",
  "Pro/Qwen/Qwen2.5-7B-Instruct.description": "Qwen2.5-7B-Instruct fait partie de la dernière série de LLM d’Alibaba Cloud. Ce modèle de 7 milliards apporte des améliorations notables en codage et mathématiques, prend en charge plus de 29 langues et améliore le suivi des instructions, la compréhension des données structurées et la génération de sorties structurées (notamment en JSON).",
  "Pro/Qwen/Qwen2.5-Coder-7B-Instruct.description": "Qwen2.5-Coder-7B-Instruct est le dernier LLM d’Alibaba Cloud axé sur le code. Basé sur Qwen2.5 et entraîné sur 5,5T de jetons, il améliore considérablement la génération de code, le raisonnement et la correction, tout en conservant ses forces en mathématiques et en intelligence générale, constituant une base solide pour les agents de codage.",
  "Pro/Qwen/Qwen2.5-VL-7B-Instruct.description": "Qwen2.5-VL est un nouveau modèle vision-langage de la série Qwen, doté d’une forte compréhension visuelle. Il analyse le texte, les graphiques et les mises en page dans les images, comprend les vidéos longues et les événements, prend en charge le raisonnement et l’utilisation d’outils, l’ancrage d’objets multi-formats et les sorties structurées. Il améliore la résolution dynamique et l’entraînement à fréquence d’images pour la compréhension vidéo, tout en augmentant l’efficacité de l’encodeur visuel.",
  "Pro/THUDM/GLM-4.1V-9B-Thinking.description": "GLM-4.1V-9B-Thinking est un modèle VLM open source développé par Zhipu AI et le laboratoire KEG de l’université Tsinghua, conçu pour la cognition multimodale complexe. Basé sur GLM-4-9B-0414, il ajoute un raisonnement en chaîne de pensée et un apprentissage par renforcement pour améliorer considérablement le raisonnement intermodal et la stabilité.",
  "Pro/THUDM/glm-4-9b-chat.description": "GLM-4-9B-Chat est le modèle open source GLM-4 de Zhipu AI. Il offre de solides performances en sémantique, mathématiques, raisonnement, code et connaissances. Au-delà du chat multi-tours, il prend en charge la navigation web, l’exécution de code, les appels d’outils personnalisés et le raisonnement sur de longs textes. Il prend en charge 26 langues (dont le chinois, l’anglais, le japonais, le coréen et l’allemand). Il obtient de bons résultats sur AlignBench-v2, MT-Bench, MMLU et C-Eval, et prend en charge jusqu’à 128 000 jetons de contexte pour un usage académique et professionnel.",
  "Pro/deepseek-ai/DeepSeek-R1-Distill-Qwen-7B.description": "DeepSeek-R1-Distill-Qwen-7B est distillé à partir de Qwen2.5-Math-7B et affiné sur 800 000 échantillons DeepSeek-R1 sélectionnés. Il offre d’excellentes performances, avec 92,8 % sur MATH-500, 55,5 % sur AIME 2024 et une note CodeForces de 1189 pour un modèle de 7B.",
  "Pro/deepseek-ai/DeepSeek-R1.description": "DeepSeek-R1 est un modèle de raisonnement basé sur l’apprentissage par renforcement qui réduit la répétition et améliore la lisibilité. Il utilise des données de démarrage à froid avant l’entraînement RL pour renforcer encore le raisonnement, rivalise avec OpenAI-o1 sur les tâches de mathématiques, de code et de raisonnement, et améliore les résultats globaux grâce à un entraînement soigné.",
  "Pro/deepseek-ai/DeepSeek-V3.1-Terminus.description": "DeepSeek-V3.1-Terminus est une version mise à jour du modèle V3.1, positionnée comme un LLM hybride pour agents. Il corrige les problèmes signalés par les utilisateurs, améliore la stabilité, la cohérence linguistique et réduit les caractères anormaux ou mélangés chinois/anglais. Il intègre les modes Pensant et Non pensant avec des modèles de chat pour un basculement flexible. Il améliore également les performances des agents de code et de recherche pour une utilisation plus fiable des outils et des tâches multi-étapes.",
  "Pro/deepseek-ai/DeepSeek-V3.2-Exp.description": "DeepSeek-V3.2-Exp est une version expérimentale de V3.2 servant de pont vers la prochaine architecture. Il ajoute DeepSeek Sparse Attention (DSA) au-dessus de V3.1-Terminus pour améliorer l’efficacité de l’entraînement et de l’inférence sur de longs contextes, avec des optimisations pour l’utilisation d’outils, la compréhension de documents longs et le raisonnement multi-étapes. Il est idéal pour explorer une efficacité de raisonnement accrue avec de grands budgets de contexte.",
  "Pro/deepseek-ai/DeepSeek-V3.description": "DeepSeek-V3 est un modèle MoE de 671 milliards de paramètres utilisant MLA et DeepSeekMoE avec un équilibrage de charge sans perte pour une inférence et un entraînement efficaces. Préentraîné sur 14,8T de jetons de haute qualité et affiné avec SFT et RL, il surpasse les autres modèles open source et se rapproche des modèles fermés de pointe.",
  "Pro/moonshotai/Kimi-K2-Instruct-0905.description": "Kimi K2-Instruct-0905 est le tout dernier et le plus puissant modèle Kimi K2. Il s'agit d'un modèle MoE de premier plan avec 1T de paramètres totaux et 32B de paramètres actifs. Ses principales caractéristiques incluent une intelligence de codage agentique renforcée avec des gains significatifs sur les benchmarks et les tâches d'agents réels, ainsi qu'une esthétique et une convivialité améliorées pour le codage en interface utilisateur.",
  "Pro/moonshotai/Kimi-K2-Thinking.description": "Kimi K2 Thinking Turbo est la variante Turbo optimisée pour la vitesse de raisonnement et le débit, tout en conservant le raisonnement multi-étapes et l'utilisation d'outils de K2 Thinking. Il s'agit d'un modèle MoE avec environ 1T de paramètres totaux, un contexte natif de 256K, et un appel d'outils à grande échelle stable pour des scénarios de production nécessitant une faible latence et une forte concurrence.",
  "Pro/zai-org/glm-4.7.description": "GLM-4.7 est le nouveau modèle phare de Zhipu, avec 355 milliards de paramètres totaux et 32 milliards de paramètres actifs. Il offre des améliorations complètes en dialogue général, raisonnement et capacités d'agents. GLM-4.7 renforce la pensée entrelacée (Interleaved Thinking), et introduit la pensée préservée (Preserved Thinking) et la pensée par tour (Turn-level Thinking).",
  "QwQ-32B-Preview.description": "Qwen QwQ est un modèle de recherche expérimental axé sur l'amélioration du raisonnement.",
  "Qwen/QVQ-72B-Preview.description": "QVQ-72B-Preview est un modèle de recherche de Qwen axé sur le raisonnement visuel, avec des points forts en compréhension de scènes complexes et en résolution de problèmes visuels mathématiques.",
  "Qwen/QwQ-32B-Preview.description": "Qwen QwQ est un modèle de recherche expérimental axé sur l'amélioration du raisonnement de l'IA.",
  "Qwen/QwQ-32B.description": "QwQ est un modèle de raisonnement de la famille Qwen. Par rapport aux modèles classiques ajustés par instruction, il intègre des capacités de réflexion et de raisonnement qui améliorent considérablement les performances en aval, notamment sur les problèmes complexes. QwQ-32B est un modèle de taille moyenne compétitif avec les meilleurs modèles de raisonnement comme DeepSeek-R1 et o1-mini. Il utilise RoPE, SwiGLU, RMSNorm et un biais QKV dans l'attention, avec 64 couches et 40 têtes d'attention Q (8 KV en GQA).",
  "Qwen/Qwen-Image-Edit-2509.description": "Qwen-Image-Edit-2509 est la dernière version d'édition d'image de l'équipe Qwen. Basé sur le modèle Qwen-Image de 20B, il étend ses capacités de rendu de texte à l'édition d'image pour des modifications textuelles précises. Il utilise une architecture à double contrôle, envoyant les entrées à Qwen2.5-VL pour le contrôle sémantique et à un encodeur VAE pour le contrôle de l'apparence, permettant des modifications à la fois sémantiques et visuelles. Il prend en charge les modifications locales (ajout/suppression/modification) ainsi que les modifications sémantiques de haut niveau comme la création d'IP et le transfert de style tout en préservant le sens. Il atteint des résultats SOTA sur plusieurs benchmarks.",
  "Qwen/Qwen-Image.description": "Qwen-Image est un modèle fondamental de génération d'image de 20B paramètres développé par l'équipe Qwen. Il réalise des avancées majeures dans le rendu de texte complexe et l'édition d'image précise, notamment pour le texte chinois/anglais haute fidélité. Il prend en charge les mises en page multi-lignes et en paragraphes tout en maintenant une typographie cohérente. Au-delà du rendu de texte, il prend en charge une large gamme de styles allant du photoréalisme à l'anime, ainsi que des fonctions d'édition avancées comme le transfert de style, l'ajout/suppression d'objets, l'amélioration des détails, l'édition de texte et le contrôle de pose, visant à devenir une base complète pour la création visuelle.",
  "Qwen/Qwen2-72B-Instruct.description": "Qwen 2 Instruct (72B) offre un suivi précis des instructions pour les charges de travail en entreprise.",
  "Qwen/Qwen2-7B-Instruct.description": "Qwen2-7B-Instruct est un modèle de 7B ajusté par instruction de la série Qwen2 utilisant Transformer, SwiGLU, un biais QKV et une attention par requêtes groupées. Il gère de grandes entrées et affiche d'excellentes performances en compréhension, génération, multilingue, codage, mathématiques et raisonnement, surpassant la plupart des modèles open source et dépassant Qwen1.5-7B-Chat dans de nombreuses évaluations.",
  "Qwen/Qwen2-VL-72B-Instruct.description": "Qwen2-VL est le dernier modèle Qwen-VL, atteignant l'état de l'art sur des benchmarks visuels comme MathVista, DocVQA, RealWorldQA et MTVQA. Il peut comprendre des vidéos de plus de 20 minutes pour des tâches de questions-réponses vidéo, de dialogue et de création de contenu. Il prend également en charge un raisonnement complexe et la prise de décision, s'intégrant à des appareils/robots pour des actions guidées par la vision. En plus de l'anglais et du chinois, il peut lire du texte dans de nombreuses langues, y compris la plupart des langues européennes, le japonais, le coréen, l'arabe et le vietnamien.",
  "Qwen/Qwen2.5-14B-Instruct.description": "Qwen2.5-14B-Instruct fait partie de la dernière série de LLM d'Alibaba Cloud. Le modèle 14B apporte des améliorations notables en codage et en mathématiques, prend en charge plus de 29 langues et améliore le suivi des instructions, la compréhension des données structurées et la génération de sorties structurées (notamment en JSON).",
  "Qwen/Qwen2.5-32B-Instruct.description": "Qwen2.5-32B-Instruct fait partie de la dernière série de LLM d'Alibaba Cloud. Le modèle 32B apporte des améliorations notables en codage et en mathématiques, prend en charge plus de 29 langues et améliore le suivi des instructions, la compréhension des données structurées et la génération de sorties structurées (notamment en JSON).",
  "Qwen/Qwen2.5-72B-Instruct-128K.description": "Qwen2.5-72B-Instruct fait partie de la dernière série de LLM d'Alibaba Cloud. Le modèle 72B améliore le codage et les mathématiques, prend en charge jusqu'à 128K d'entrée et plus de 8K de sortie, offre 29+ langues, et améliore le suivi des instructions et la sortie structurée (notamment en JSON).",
  "Qwen/Qwen2.5-72B-Instruct-Turbo.description": "Qwen2.5 est une nouvelle famille de LLM optimisée pour les tâches de type instruction.",
  "Qwen/Qwen2.5-72B-Instruct.description": "Qwen2.5-72B-Instruct fait partie de la dernière série de LLM d'Alibaba Cloud. Le modèle 72B apporte des améliorations notables en codage et en mathématiques, prend en charge plus de 29 langues et améliore le suivi des instructions, la compréhension des données structurées et la génération de sorties structurées (notamment en JSON).",
  "Qwen/Qwen2.5-7B-Instruct-Turbo.description": "Qwen2.5 est une nouvelle famille de LLM optimisée pour les tâches de type instruction.",
  "Qwen/Qwen2.5-7B-Instruct.description": "Qwen2.5-7B-Instruct fait partie de la dernière série de LLM d'Alibaba Cloud. Le modèle 7B apporte des améliorations notables en codage et en mathématiques, prend en charge plus de 29 langues et améliore le suivi des instructions, la compréhension des données structurées et la génération de sorties structurées (notamment en JSON).",
  "Qwen/Qwen2.5-Coder-32B-Instruct.description": "Qwen2.5 Coder 32B Instruct est le dernier LLM d'Alibaba Cloud axé sur le code. Construit sur Qwen2.5 et entraîné sur 5,5T de tokens, il améliore considérablement la génération de code, le raisonnement et la correction tout en conservant ses forces en mathématiques et en général, fournissant une base solide pour les agents de codage.",
  "Qwen/Qwen2.5-Coder-7B-Instruct.description": "Qwen2.5-Coder-7B-Instruct est le dernier LLM d'Alibaba Cloud axé sur le code. Construit sur Qwen2.5 et entraîné sur 5,5T de tokens, il améliore considérablement la génération de code, le raisonnement et la correction tout en conservant ses forces en mathématiques et en général, fournissant une base solide pour les agents de codage.",
  "Qwen/Qwen2.5-VL-32B-Instruct.description": "Qwen2.5-VL-32B-Instruct est un modèle multimodal de l'équipe Qwen. Il reconnaît les objets courants et analyse le texte, les graphiques, les icônes, les illustrations et les mises en page. En tant qu'agent visuel, il peut raisonner et contrôler dynamiquement des outils, y compris l'utilisation d'ordinateurs et de téléphones. Il localise précisément les objets et génère des sorties structurées pour les factures et les tableaux. Par rapport à Qwen2-VL, RL améliore encore les mathématiques et la résolution de problèmes, avec des réponses préférées par les humains.",
  "Qwen/Qwen2.5-VL-72B-Instruct.description": "Qwen2.5-VL est le modèle vision-langage de la série Qwen2.5 avec des améliorations majeures : meilleure compréhension visuelle des objets, textes, graphiques et mises en page ; raisonnement en tant qu'agent visuel avec utilisation dynamique d'outils ; compréhension de vidéos de plus d'une heure et capture des événements clés ; ancrage précis des objets via des boîtes ou des points ; et sorties structurées pour les données scannées comme les factures et les tableaux.",
  "Qwen/Qwen3-14B.description": "Qwen3 est un modèle Tongyi Qwen de nouvelle génération, offrant des avancées majeures en raisonnement, capacités générales, fonctionnement en tant qu'agent et performance multilingue. Il prend en charge le changement de mode de pensée.",
  "Qwen/Qwen3-235B-A22B-Instruct-2507.description": "Qwen3-235B-A22B-Instruct-2507 est un modèle MoE phare de la série Qwen3, avec 235 milliards de paramètres au total et 22 milliards actifs. Il s'agit d'une version non-pensante mise à jour, axée sur l'amélioration du suivi des instructions, du raisonnement logique, de la compréhension de texte, des mathématiques, des sciences, du codage et de l'utilisation d'outils. Il étend également les connaissances multilingues de longue traîne et s'aligne mieux sur les préférences des utilisateurs pour les tâches subjectives ouvertes.",
  "Qwen/Qwen3-235B-A22B-Thinking-2507.description": "Qwen3-235B-A22B-Thinking-2507 est un modèle Qwen3 dédié au raisonnement complexe. Il utilise une architecture MoE avec 235 milliards de paramètres au total et environ 22 milliards actifs par jeton pour une efficacité accrue. En tant que modèle de réflexion, il affiche des progrès significatifs en logique, mathématiques, sciences, codage et performances académiques, atteignant un niveau de réflexion ouvert de premier plan. Il améliore également le suivi des instructions, l'utilisation d'outils et la génération de texte, et prend en charge nativement un contexte de 256K pour le raisonnement approfondi et les documents longs.",
  "Qwen/Qwen3-235B-A22B.description": "Qwen3 est un modèle Tongyi Qwen de nouvelle génération, offrant des avancées majeures en raisonnement, capacités générales, fonctionnement en tant qu'agent et performance multilingue. Il prend en charge le changement de mode de pensée.",
  "Qwen/Qwen3-30B-A3B-Instruct-2507.description": "Qwen3-30B-A3B-Instruct-2507 est la version non-pensante mise à jour de Qwen3-30B-A3B. Il s'agit d'un modèle MoE avec 30,5 milliards de paramètres au total et 3,3 milliards actifs. Il améliore considérablement le suivi des instructions, le raisonnement logique, la compréhension de texte, les mathématiques, les sciences, le codage et l'utilisation d'outils, étend les connaissances multilingues de longue traîne et s'aligne mieux sur les préférences des utilisateurs pour les tâches ouvertes subjectives. Il prend en charge un contexte de 256K. Ce modèle est uniquement non-pensant et ne génère pas de balises `<think></think>`.",
  "Qwen/Qwen3-30B-A3B-Thinking-2507.description": "Qwen3-30B-A3B-Thinking-2507 est le dernier modèle de réflexion de la série Qwen3. Il s'agit d'un modèle MoE avec 30,5 milliards de paramètres au total et 3,3 milliards actifs, conçu pour les tâches complexes. Il affiche des gains significatifs en logique, mathématiques, sciences, codage et performances académiques, et améliore le suivi des instructions, l'utilisation d'outils, la génération de texte et l'alignement sur les préférences. Il prend en charge nativement un contexte de 256K et peut s'étendre jusqu'à 1 million de jetons. Cette version est conçue pour le mode de réflexion avec un raisonnement détaillé étape par étape et de solides capacités d'agent.",
  "Qwen/Qwen3-30B-A3B.description": "Qwen3 est un modèle Tongyi Qwen de nouvelle génération, offrant des avancées majeures en raisonnement, capacités générales, fonctionnement en tant qu'agent et performance multilingue. Il prend en charge le changement de mode de pensée.",
  "Qwen/Qwen3-32B.description": "Qwen3 est un modèle Tongyi Qwen de nouvelle génération, offrant des avancées majeures en raisonnement, capacités générales, fonctionnement en tant qu'agent et performance multilingue. Il prend en charge le changement de mode de pensée.",
  "Qwen/Qwen3-8B.description": "Qwen3 est un modèle Tongyi Qwen de nouvelle génération, offrant des avancées majeures en raisonnement, capacités générales, fonctionnement en tant qu'agent et performance multilingue. Il prend en charge le changement de mode de pensée.",
  "Qwen/Qwen3-Coder-30B-A3B-Instruct.description": "Qwen3-Coder-30B-A3B-Instruct est un modèle de génération de code de la série Qwen3 développé par l'équipe Qwen. Il est optimisé pour des performances élevées et une grande efficacité tout en renforçant les capacités de codage. Il se distingue dans le codage agentique, les opérations automatisées de navigateur et l'utilisation d'outils parmi les modèles ouverts. Il prend en charge nativement un contexte de 256K et peut s'étendre jusqu'à 1 million de jetons pour une compréhension à l'échelle d'une base de code. Il alimente le codage agentique sur des plateformes comme Qwen Code et CLINE avec un format dédié d'appel de fonctions.",
  "Qwen/Qwen3-Coder-480B-A35B-Instruct.description": "Qwen3-Coder-480B-A35B-Instruct est le modèle de codage le plus agentique d'Alibaba à ce jour. Il s'agit d'un modèle MoE avec 480 milliards de paramètres au total et 35 milliards actifs, équilibrant efficacité et performance. Il prend en charge nativement un contexte de 256K et peut s'étendre jusqu'à 1 million de jetons via YaRN, permettant la gestion de grandes bases de code. Conçu pour les flux de travail de codage agentique, il peut interagir avec des outils et des environnements pour résoudre des tâches de programmation complexes. Il atteint des résultats de premier plan parmi les modèles ouverts sur les benchmarks de codage et d'agents, comparables à des modèles comme Claude Sonnet 4.",
  "Qwen/Qwen3-Next-80B-A3B-Instruct.description": "Qwen3-Next-80B-A3B-Instruct est un modèle de base de nouvelle génération utilisant l'architecture Qwen3-Next pour une efficacité extrême en entraînement et inférence. Il combine attention hybride (Gated DeltaNet + Gated Attention), MoE hautement clairsemé et optimisations de stabilité d'entraînement. Avec 80 milliards de paramètres au total mais environ 3 milliards actifs à l'inférence, il réduit les besoins en calcul et offre un débit plus de 10 fois supérieur à Qwen3-32B sur des contextes >32K. Cette version ajustée pour les instructions cible les tâches générales (sans mode de réflexion). Elle offre des performances comparables à Qwen3-235B sur certains benchmarks et présente de forts avantages pour les tâches à contexte ultra-long.",
  "Qwen/Qwen3-Next-80B-A3B-Thinking.description": "Qwen3-Next-80B-A3B-Thinking est un modèle de base de nouvelle génération dédié au raisonnement complexe. Il utilise l'architecture Qwen3-Next avec attention hybride (Gated DeltaNet + Gated Attention) et MoE hautement clairsemé pour une efficacité extrême en entraînement et inférence. Avec 80 milliards de paramètres au total mais environ 3 milliards actifs à l'inférence, il réduit les besoins en calcul et offre un débit plus de 10 fois supérieur à Qwen3-32B sur des contextes >32K. Cette version de réflexion cible les tâches multi-étapes comme les démonstrations, la synthèse de code, l'analyse logique et la planification, en produisant une chaîne de pensée structurée. Elle surpasse Qwen3-32B-Thinking et bat Gemini-2.5-Flash-Thinking sur plusieurs benchmarks.",
  "Qwen/Qwen3-Omni-30B-A3B-Captioner.description": "Qwen3-Omni-30B-A3B-Captioner est un modèle VLM de la série Qwen3 conçu pour générer des légendes d'images de haute qualité, détaillées et précises. Il utilise une architecture MoE de 30 milliards de paramètres pour comprendre en profondeur les images et produire des descriptions fluides, excellant dans la capture de détails, la compréhension de scènes, la reconnaissance d'objets et le raisonnement relationnel.",
  "Qwen/Qwen3-Omni-30B-A3B-Instruct.description": "Qwen3-Omni-30B-A3B-Instruct est un modèle MoE de la série Qwen3 avec 30 milliards de paramètres au total et 3 milliards actifs, offrant de solides performances à moindre coût d'inférence. Entraîné sur des données multilingues de haute qualité et multi-sources, il prend en charge les entrées multimodales complètes (texte, images, audio, vidéo) ainsi que la compréhension et la génération intermodales.",
  "Qwen/Qwen3-Omni-30B-A3B-Thinking.description": "Qwen3-Omni-30B-A3B-Thinking est le composant central \"Thinker\" de Qwen3-Omni. Il traite les entrées multimodales (texte, audio, images, vidéo) et effectue un raisonnement complexe en chaîne de pensée, unifiant les entrées dans une représentation partagée pour une compréhension intermodale approfondie. Il s'agit d'un modèle MoE avec 30 milliards de paramètres au total et 3 milliards actifs, équilibrant raisonnement puissant et efficacité de calcul.",
  "Qwen/Qwen3-VL-235B-A22B-Instruct.description": "Qwen3-VL-235B-A22B-Instruct est un grand modèle Qwen3-VL ajusté pour les instructions, basé sur MoE, offrant une excellente compréhension et génération multimodales. Il prend en charge nativement un contexte de 256K et convient aux services multimodaux de production à forte concurrence.",
  "Qwen/Qwen3-VL-235B-A22B-Thinking.description": "Qwen3-VL-235B-A22B-Thinking est la version de réflexion phare de Qwen3-VL, optimisée pour le raisonnement multimodal complexe, le raisonnement à long contexte et l'interaction avec des agents dans des scénarios d'entreprise.",
  "Qwen/Qwen3-VL-30B-A3B-Instruct.description": "Qwen3-VL-30B-A3B-Instruct est le modèle Qwen3-VL ajusté pour les instructions, avec une forte compréhension et génération vision-langage. Il prend en charge nativement un contexte de 256K pour le chat multimodal et la génération conditionnée par image.",
  "Qwen/Qwen3-VL-30B-A3B-Thinking.description": "Qwen3-VL-30B-A3B-Thinking est la version renforcée pour le raisonnement de Qwen3-VL, optimisée pour le raisonnement multimodal, la conversion image-vers-code et la compréhension visuelle complexe. Il prend en charge un contexte de 256K avec une capacité renforcée de chaîne de pensée.",
  "Qwen/Qwen3-VL-32B-Instruct.description": "Qwen3-VL-32B-Instruct est un modèle vision-langage de l'équipe Qwen avec des résultats SOTA sur plusieurs benchmarks VL. Il prend en charge les images en résolution mégapixel et offre une forte compréhension visuelle, OCR multilingue, ancrage visuel précis et dialogue visuel. Il gère des tâches multimodales complexes et prend en charge l'appel d'outils et la complétion de préfixes.",
  "Qwen/Qwen3-VL-32B-Thinking.description": "Qwen3-VL-32B-Thinking est optimisé pour le raisonnement visuel complexe. Il inclut un mode de réflexion intégré qui génère des étapes de raisonnement intermédiaires avant les réponses, renforçant la logique multi-étapes, la planification et le raisonnement complexe. Il prend en charge les images mégapixel, une forte compréhension visuelle, l'OCR multilingue, l'ancrage fin, le dialogue visuel, l'appel d'outils et la complétion de préfixes.",
  "Qwen/Qwen3-VL-8B-Instruct.description": "Qwen3-VL-8B-Instruct est un modèle vision-langage Qwen3 basé sur Qwen3-8B-Instruct et entraîné sur de grandes données image-texte. Il excelle dans la compréhension visuelle générale, le dialogue centré sur la vision et la reconnaissance de texte multilingue dans les images, adapté à la QA visuelle, la légendation, le suivi d'instructions multimodales et l'utilisation d'outils.",
  "Qwen/Qwen3-VL-8B-Thinking.description": "Qwen3-VL-8B-Thinking est la version de réflexion visuelle de Qwen3, optimisée pour le raisonnement complexe en plusieurs étapes. Il génère une chaîne de pensée avant les réponses pour améliorer la précision, idéal pour la QA visuelle approfondie et l'analyse d'image détaillée.",
  "Qwen2-72B-Instruct.description": "Qwen2 est la dernière série Qwen, prenant en charge une fenêtre de contexte de 128k. Comparé aux meilleurs modèles ouverts actuels, Qwen2-72B surpasse largement les modèles leaders en compréhension du langage naturel, connaissances, code, mathématiques et capacités multilingues.",
  "Qwen2-7B-Instruct.description": "Qwen2 est la dernière série Qwen, surpassant les meilleurs modèles ouverts de taille similaire et même des modèles plus grands. Qwen2 7B présente des avantages significatifs sur de nombreux benchmarks, notamment en codage et en compréhension du chinois.",
  "Qwen2-VL-72B.description": "Qwen2-VL-72B est un puissant modèle vision-langage prenant en charge le traitement multimodal image-texte, reconnaissant avec précision le contenu des images et générant des descriptions ou réponses pertinentes.",
  "Qwen2.5-14B-Instruct.description": "Qwen2.5-14B-Instruct est un LLM de 14 milliards de paramètres avec de solides performances, optimisé pour les scénarios en chinois et multilingues, prenant en charge la QA intelligente et la génération de contenu.",
  "Qwen2.5-32B-Instruct.description": "Qwen2.5-32B-Instruct est un LLM de 32 milliards de paramètres avec des performances équilibrées, optimisé pour les scénarios en chinois et multilingues, prenant en charge la QA intelligente et la génération de contenu.",
  "Qwen2.5-72B-Instruct.description": "LLM pour le chinois et l'anglais, ajusté pour le langage, le codage, les mathématiques et le raisonnement.",
  "Qwen2.5-7B-Instruct.description": "Qwen2.5-7B-Instruct est un LLM de 7 milliards de paramètres prenant en charge l'appel de fonctions et l'intégration fluide avec des systèmes externes, améliorant considérablement la flexibilité et l'extensibilité. Il est optimisé pour les scénarios en chinois et multilingues, prenant en charge la QA intelligente et la génération de contenu.",
  "Qwen2.5-Coder-14B-Instruct.description": "Qwen2.5-Coder-14B-Instruct est un grand modèle de codage pré-entraîné avec une forte compréhension et génération de code. Il gère efficacement un large éventail de tâches de programmation, idéal pour le codage intelligent, la génération de scripts automatisés et la QA en programmation.",
  "Qwen2.5-Coder-32B-Instruct.description": "LLM avancé pour la génération de code, le raisonnement et la correction de bugs dans les principaux langages de programmation.",
  "Qwen3-235B-A22B-Instruct-2507-FP8.description": "Qwen3 235B A22B Instruct 2507 est optimisé pour le raisonnement avancé et le suivi des instructions, utilisant MoE pour maintenir une efficacité de raisonnement à grande échelle.",
  "Qwen3-235B.description": "Qwen3-235B-A22B est un modèle MoE qui introduit un mode de raisonnement hybride, permettant aux utilisateurs de basculer facilement entre réflexion et non-réflexion. Il prend en charge la compréhension et le raisonnement dans 119 langues et dialectes, et dispose de solides capacités d'appel d'outils, rivalisant avec des modèles de référence comme DeepSeek R1, OpenAI o1, o3-mini, Grok 3 et Google Gemini 2.5 Pro sur les benchmarks de capacités générales, code et mathématiques, multilinguisme et raisonnement par connaissances.",
  "Qwen3-32B.description": "Qwen3-32B est un modèle dense qui introduit un mode de raisonnement hybride, permettant aux utilisateurs de basculer entre réflexion et non-réflexion. Grâce à des améliorations architecturales, davantage de données et un meilleur entraînement, il offre des performances comparables à Qwen2.5-72B.",
  "SenseChat-128K.description": "Base V4 avec un contexte de 128K, excellent pour la compréhension et la génération de textes longs.",
  "SenseChat-32K.description": "Base V4 avec un contexte de 32K, flexible pour de nombreux scénarios.",
  "SenseChat-5-1202.description": "Dernière version basée sur V5.5, avec des progrès significatifs en fondamentaux chinois/anglais, chat, connaissances STEM, sciences humaines, écriture, mathématiques/logique et contrôle de longueur.",
  "SenseChat-5-Cantonese.description": "Conçu pour les habitudes de dialogue, le langage familier et les connaissances locales de Hong Kong ; surpasse GPT-4 en compréhension du cantonais et rivalise avec GPT-4 Turbo en connaissances, raisonnement, mathématiques et codage.",
  "SenseChat-5-beta.description": "Certaines performances dépassent celles de SenseChat-5-1202.",
  "SenseChat-5.description": "Dernier V5.5 avec un contexte de 128K ; grands progrès en raisonnement mathématique, chat en anglais, suivi d'instructions et compréhension de textes longs, comparable à GPT-4o.",
  "SenseChat-Character-Pro.description": "Modèle de chat de personnage avancé avec un contexte de 32K, capacités améliorées et prise en charge du chinois/anglais.",
  "SenseChat-Character.description": "Modèle standard de chat de personnage avec un contexte de 8K et une vitesse de réponse élevée.",
  "SenseChat-Turbo-1202.description": "Dernier modèle léger atteignant plus de 90 % des capacités du modèle complet avec un coût d'inférence nettement inférieur.",
  "SenseChat-Turbo.description": "Convient pour les scénarios de QA rapide et d'ajustement de modèle.",
  "SenseChat-Vision.description": "Dernier V5.5 avec entrée multi-images et améliorations générales en reconnaissance d'attributs, relations spatiales, détection d'action/événement, compréhension de scène, reconnaissance des émotions, raisonnement de bon sens et compréhension/génération de texte.",
  "SenseChat.description": "Base V4 avec un contexte de 4K et de solides capacités générales.",
  "SenseNova-V6-5-Pro.description": "Grâce à des mises à jour complètes des données multimodales, linguistiques et de raisonnement, ainsi qu'à une optimisation de la stratégie d'entraînement, ce nouveau modèle améliore considérablement le raisonnement multimodal et le suivi d'instructions généralisé. Il prend en charge une fenêtre de contexte allant jusqu'à 128k et excelle dans les tâches de reconnaissance OCR et d'identification d'IP liées au tourisme culturel.",
  "SenseNova-V6-5-Turbo.description": "Grâce à des mises à jour complètes des données multimodales, linguistiques et de raisonnement, ainsi qu'à une optimisation de la stratégie d'entraînement, ce nouveau modèle améliore considérablement le raisonnement multimodal et le suivi d'instructions généralisé. Il prend en charge une fenêtre de contexte allant jusqu'à 128k et excelle dans les tâches de reconnaissance OCR et d'identification d'IP liées au tourisme culturel.",
  "SenseNova-V6-Pro.description": "Unifie nativement l'image, le texte et la vidéo, brisant les silos multimodaux traditionnels ; se classe parmi les meilleurs sur OpenCompass et SuperCLUE.",
  "SenseNova-V6-Reasoner.description": "Combine une compréhension approfondie de la vision et du langage, prenant en charge la réflexion lente et le raisonnement en chaîne.",
  "SenseNova-V6-Turbo.description": "Unifie nativement l'image, le texte et la vidéo, brisant les silos multimodaux traditionnels. Il excelle dans les capacités fondamentales multimodales et linguistiques, et se classe parmi les meilleurs dans de nombreuses évaluations.",
  "Skylark2-lite-8k.description": "Modèle Skylark de 2e génération. Skylark2-lite offre des réponses rapides pour des scénarios en temps réel et sensibles aux coûts, avec des exigences de précision moindres, et une fenêtre de contexte de 8K.",
  "Skylark2-pro-32k.description": "Modèle Skylark de 2e génération. Skylark2-pro offre une précision accrue pour la génération de texte complexe, comme la rédaction professionnelle, l'écriture de romans et la traduction de haute qualité, avec une fenêtre de contexte de 32K.",
  "Skylark2-pro-4k.description": "Modèle Skylark de 2e génération. Skylark2-pro offre une précision accrue pour la génération de texte complexe, comme la rédaction professionnelle, l'écriture de romans et la traduction de haute qualité, avec une fenêtre de contexte de 4K.",
  "Skylark2-pro-character-4k.description": "Modèle Skylark de 2e génération. Skylark2-pro-character excelle dans les jeux de rôle et les conversations, en adaptant les invites à des styles de personnages distincts et à un dialogue naturel pour les chatbots, assistants virtuels et services clients, avec des réponses rapides.",
  "Skylark2-pro-turbo-8k.description": "Modèle Skylark de 2e génération. Skylark2-pro-turbo-8k offre une inférence plus rapide à moindre coût avec une fenêtre de contexte de 8K.",
  "THUDM/GLM-4-32B-0414.description": "GLM-4-32B-0414 est un modèle GLM de nouvelle génération avec 32 milliards de paramètres, comparable aux performances des séries OpenAI GPT et DeepSeek V3/R1.",
  "THUDM/GLM-4-9B-0414.description": "GLM-4-9B-0414 est un modèle GLM de 9 milliards de paramètres qui hérite des techniques de GLM-4-32B tout en offrant un déploiement plus léger. Il est performant en génération de code, conception web, génération SVG et rédaction basée sur la recherche.",
  "THUDM/GLM-4.1V-9B-Thinking.description": "GLM-4.1V-9B-Thinking est un modèle VLM open source développé par Zhipu AI et le laboratoire KEG de Tsinghua, conçu pour la cognition multimodale complexe. Basé sur GLM-4-9B-0414, il intègre le raisonnement en chaîne et l'apprentissage par renforcement pour améliorer considérablement le raisonnement intermodal et la stabilité.",
  "THUDM/GLM-Z1-32B-0414.description": "GLM-Z1-32B-0414 est un modèle de raisonnement approfondi dérivé de GLM-4-32B-0414, enrichi de données de démarrage à froid et d'un apprentissage par renforcement étendu. Entraîné davantage sur les mathématiques, le code et la logique, il améliore significativement les capacités de résolution de tâches complexes par rapport au modèle de base.",
  "THUDM/GLM-Z1-9B-0414.description": "GLM-Z1-9B-0414 est un modèle GLM compact de 9 milliards de paramètres qui conserve les avantages de l'open source tout en offrant des performances impressionnantes. Il se distingue dans le raisonnement mathématique et les tâches générales, dominant sa catégorie de taille parmi les modèles ouverts.",
  "THUDM/GLM-Z1-Rumination-32B-0414.description": "GLM-Z1-Rumination-32B-0414 est un modèle de raisonnement profond doté de capacités de rumination (évalué par rapport à OpenAI Deep Research). Contrairement aux modèles de réflexion classiques, il consacre plus de temps à la délibération pour résoudre des problèmes ouverts et complexes.",
  "THUDM/glm-4-9b-chat.description": "GLM-4-9B-Chat est le modèle GLM-4 open source de Zhipu AI. Il est performant en sémantique, mathématiques, raisonnement, code et connaissances. En plus du chat multi-tours, il prend en charge la navigation web, l'exécution de code, les appels d'outils personnalisés et le raisonnement sur de longs textes. Il prend en charge 26 langues (dont le chinois, l'anglais, le japonais, le coréen et l'allemand). Il obtient de bons résultats sur AlignBench-v2, MT-Bench, MMLU et C-Eval, et prend en charge jusqu'à 128K de contexte pour les usages académiques et professionnels.",
  "Tongyi-Zhiwen/QwenLong-L1-32B.description": "QwenLong-L1-32B est le premier modèle de raisonnement à long contexte (LRM) entraîné avec apprentissage par renforcement, optimisé pour le raisonnement sur de longs textes. Son apprentissage progressif du contexte permet un transfert stable du court au long. Il surpasse OpenAI-o3-mini et Qwen3-235B-A22B sur sept benchmarks de questions-réponses sur documents à long contexte, rivalisant avec Claude-3.7-Sonnet-Thinking. Il est particulièrement performant en mathématiques, logique et raisonnement multi-sauts.",
  "Yi-34B-Chat.description": "Yi-1.5-34B conserve les solides capacités linguistiques générales de la série tout en utilisant un entraînement incrémental sur 500 milliards de tokens de haute qualité pour améliorer significativement la logique mathématique et la programmation.",
  "abab5.5-chat.description": "Conçu pour les scénarios de productivité, avec une gestion efficace des tâches complexes et une génération de texte professionnelle.",
  "abab5.5s-chat.description": "Conçu pour les conversations avec des personnages en chinois, offrant des dialogues de haute qualité pour diverses applications.",
  "abab6.5g-chat.description": "Conçu pour les conversations multilingues avec des personnages, prenant en charge la génération de dialogues de haute qualité en anglais et dans d'autres langues.",
  "abab6.5s-chat.description": "Convient à un large éventail de tâches NLP, y compris la génération de texte et les systèmes de dialogue.",
  "abab6.5t-chat.description": "Optimisé pour les conversations avec des personnages en chinois, offrant des dialogues fluides adaptés aux habitudes d'expression chinoises.",
  "accounts/fireworks/models/deepseek-r1.description": "DeepSeek-R1 est un modèle de langage de pointe optimisé avec apprentissage par renforcement et données de démarrage à froid, offrant d'excellentes performances en raisonnement, mathématiques et programmation.",
  "accounts/fireworks/models/deepseek-v3.description": "Modèle de langage Mixture-of-Experts (MoE) puissant de DeepSeek avec 671 milliards de paramètres totaux et 37 milliards actifs par token.",
  "accounts/fireworks/models/llama-v3-70b-instruct.description": "Meta a développé et publié la série de modèles Llama 3, comprenant des modèles de génération de texte pré-entraînés et ajustés pour les instructions, en versions 8B et 70B. Les modèles Llama 3 ajustés pour les instructions sont optimisés pour les conversations et surpassent de nombreux modèles de chat open source sur les benchmarks industriels courants.",
  "accounts/fireworks/models/llama-v3-8b-instruct-hf.description": "Les modèles Llama 3 ajustés pour les instructions sont optimisés pour les conversations et surpassent de nombreux modèles de chat open source sur les benchmarks industriels courants. Llama 3 8B Instruct (version HF) est la version FP16 originale de Llama 3 8B Instruct, avec des résultats attendus équivalents à l'implémentation officielle sur Hugging Face.",
  "accounts/fireworks/models/llama-v3-8b-instruct.description": "Meta a développé et publié la série de modèles Llama 3, une collection de modèles de génération de texte pré-entraînés et ajustés pour les instructions, en versions 8B et 70B. Les modèles Llama 3 ajustés pour les instructions sont optimisés pour les conversations et surpassent de nombreux modèles de chat open source sur les benchmarks industriels courants.",
  "accounts/fireworks/models/llama-v3p1-405b-instruct.description": "Meta Llama 3.1 est une famille de modèles multilingues avec des modèles de génération pré-entraînés et ajustés pour les instructions en tailles 8B, 70B et 405B. Les modèles ajustés pour les instructions sont optimisés pour le dialogue multilingue et surpassent de nombreux modèles de chat open source et propriétaires sur les benchmarks industriels courants. Le modèle 405B est le plus performant de la famille Llama 3.1, utilisant une inférence FP8 qui correspond étroitement à l'implémentation de référence.",
  "accounts/fireworks/models/llama-v3p1-70b-instruct.description": "Meta Llama 3.1 est une famille de modèles multilingues avec des modèles de génération pré-entraînés et ajustés pour les instructions en tailles 8B, 70B et 405B. Les modèles ajustés pour les instructions sont optimisés pour le dialogue multilingue et surpassent de nombreux modèles de chat open source et propriétaires sur les benchmarks industriels courants.",
  "accounts/fireworks/models/llama-v3p1-8b-instruct.description": "Meta Llama 3.1 est une famille de modèles multilingues avec des modèles de génération pré-entraînés et ajustés pour les instructions en tailles 8B, 70B et 405B. Les modèles ajustés pour les instructions sont optimisés pour le dialogue multilingue et surpassent de nombreux modèles de chat open source et propriétaires sur les benchmarks industriels courants.",
  "accounts/fireworks/models/llama-v3p2-11b-vision-instruct.description": "Modèle de raisonnement visuel ajusté pour les instructions de Meta avec 11 milliards de paramètres, optimisé pour la reconnaissance visuelle, le raisonnement sur images, la génération de légendes et les questions-réponses liées aux images. Il comprend les données visuelles telles que les graphiques et les diagrammes, et relie la vision au langage en générant des descriptions textuelles des détails d'image.",
  "accounts/fireworks/models/llama-v3p2-3b-instruct.description": "Llama 3.2 3B Instruct est un modèle multilingue léger développé par Meta, conçu pour une exécution efficace avec des avantages significatifs en termes de latence et de coût par rapport aux modèles plus volumineux. Les cas d'utilisation typiques incluent la réécriture de requêtes/prompts et l'assistance à la rédaction.",
  "accounts/fireworks/models/llama-v3p2-90b-vision-instruct.description": "Modèle de raisonnement visuel ajusté par instruction de Meta avec 90 milliards de paramètres, optimisé pour la reconnaissance visuelle, le raisonnement sur image, la génération de légendes et les questions-réponses liées aux images. Il comprend les données visuelles telles que les graphiques et les diagrammes, et relie la vision au langage en générant des descriptions textuelles des détails d'image. Remarque : ce modèle est actuellement proposé à titre expérimental en mode sans serveur. Pour un usage en production, notez que Fireworks peut interrompre son déploiement sans préavis.",
  "accounts/fireworks/models/llama-v3p3-70b-instruct.description": "Llama 3.3 70B Instruct est la mise à jour de décembre du modèle Llama 3.1 70B. Il améliore l'utilisation d'outils, le support multilingue, les capacités en mathématiques et en programmation par rapport à la version de juillet 2024. Il atteint des performances de pointe en raisonnement, mathématiques et suivi d'instructions, offrant des résultats comparables au modèle 3.1 405B avec des avantages notables en vitesse et en coût.",
  "accounts/fireworks/models/mistral-small-24b-instruct-2501.description": "Un modèle de 24 milliards de paramètres offrant des performances de pointe comparables à celles de modèles plus volumineux.",
  "accounts/fireworks/models/mixtral-8x22b-instruct.description": "Mixtral MoE 8x22B Instruct v0.1 est la version ajustée par instruction du modèle Mixtral MoE 8x22B v0.1, avec l'API de complétion de chat activée.",
  "accounts/fireworks/models/mixtral-8x7b-instruct.description": "Mixtral MoE 8x7B Instruct est la version ajustée par instruction du modèle Mixtral MoE 8x7B, avec l'API de complétion de chat activée.",
  "accounts/fireworks/models/mythomax-l2-13b.description": "Une variante améliorée de MythoMix, probablement sa forme la plus raffinée, fusionnant MythoLogic-L2 et Huginn à l'aide d'une technique de fusion de tenseurs hautement expérimentale. Sa nature unique en fait un excellent choix pour la narration et les jeux de rôle.",
  "accounts/fireworks/models/phi-3-vision-128k-instruct.description": "Phi-3-Vision-128K-Instruct est un modèle multimodal léger et de pointe, construit à partir de données synthétiques et de jeux de données publics sélectionnés, axé sur des données textuelles et visuelles de haute qualité nécessitant un raisonnement approfondi. Il fait partie de la famille Phi-3, avec une version multimodale prenant en charge une longueur de contexte de 128 000 tokens. Le modèle bénéficie d'améliorations rigoureuses, notamment un ajustement supervisé et une optimisation directe des préférences, garantissant un suivi précis des instructions et des mesures de sécurité robustes.",
  "accounts/fireworks/models/qwen-qwq-32b-preview.description": "Le modèle Qwen QwQ se concentre sur l'amélioration du raisonnement de l'IA, démontrant que les modèles ouverts peuvent rivaliser avec les modèles propriétaires de pointe. QwQ-32B-Preview est une version expérimentale qui égale o1 et surpasse GPT-4o et Claude 3.5 Sonnet en raisonnement et analyse sur les benchmarks GPQA, AIME, MATH-500 et LiveCodeBench. Remarque : ce modèle est actuellement proposé à titre expérimental en mode sans serveur. Pour un usage en production, notez que Fireworks peut interrompre son déploiement sans préavis.",
  "accounts/fireworks/models/qwen2-vl-72b-instruct.description": "Le modèle Qwen-VL 72B est la dernière itération d'Alibaba, fruit de près d'une année d'innovation.",
  "accounts/fireworks/models/qwen2p5-72b-instruct.description": "Qwen2.5 est une série de modèles LLM à décodeur uniquement développée par l'équipe Qwen et Alibaba Cloud, disponible en tailles 0.5B, 1.5B, 3B, 7B, 14B, 32B et 72B, avec des variantes de base et ajustées par instruction.",
  "accounts/fireworks/models/qwen2p5-coder-32b-instruct.description": "Qwen2.5-Coder est le dernier modèle LLM de Qwen conçu pour le code (anciennement CodeQwen). Remarque : ce modèle est actuellement proposé à titre expérimental en mode sans serveur. Pour un usage en production, notez que Fireworks peut interrompre son déploiement sans préavis.",
  "accounts/yi-01-ai/models/yi-large.description": "Yi-Large est un LLM de premier plan qui se classe juste en dessous de GPT-4, Gemini 1.5 Pro et Claude 3 Opus dans le classement LMSYS. Il excelle en multilingue, notamment en espagnol, chinois, japonais, allemand et français. Yi-Large est également adapté aux développeurs, utilisant le même schéma d'API qu'OpenAI pour une intégration facile.",
  "ai21-jamba-1.5-large.description": "Un modèle multilingue de 398 milliards de paramètres (94B actifs) avec une fenêtre de contexte de 256K, prise en charge des appels de fonction, sortie structurée et génération ancrée.",
  "ai21-jamba-1.5-mini.description": "Un modèle multilingue de 52 milliards de paramètres (12B actifs) avec une fenêtre de contexte de 256K, prise en charge des appels de fonction, sortie structurée et génération ancrée.",
  "ai21-labs/AI21-Jamba-1.5-Large.description": "Un modèle multilingue de 398 milliards de paramètres (94B actifs) avec une fenêtre de contexte de 256K, prise en charge des appels de fonction, sortie structurée et génération ancrée.",
  "ai21-labs/AI21-Jamba-1.5-Mini.description": "Un modèle multilingue de 52 milliards de paramètres (12B actifs) avec une fenêtre de contexte de 256K, prise en charge des appels de fonction, sortie structurée et génération ancrée.",
  "alibaba/qwen-3-14b.description": "Qwen3 est la dernière génération de la série Qwen, offrant un ensemble complet de modèles denses et MoE. Construit sur un entraînement approfondi, il apporte des avancées en raisonnement, suivi d'instructions, capacités d'agents et support multilingue.",
  "alibaba/qwen-3-235b.description": "Qwen3 est la dernière génération de la série Qwen, offrant un ensemble complet de modèles denses et MoE. Construit sur un entraînement approfondi, il apporte des avancées en raisonnement, suivi d'instructions, capacités d'agents et support multilingue.",
  "alibaba/qwen-3-30b.description": "Qwen3 est la dernière génération de la série Qwen, offrant un ensemble complet de modèles denses et MoE. Construit sur un entraînement approfondi, il apporte des avancées en raisonnement, suivi d'instructions, capacités d'agents et support multilingue.",
  "alibaba/qwen-3-32b.description": "Qwen3 est la dernière génération de la série Qwen, offrant un ensemble complet de modèles denses et MoE. Construit sur un entraînement approfondi, il apporte des avancées en raisonnement, suivi d'instructions, capacités d'agents et support multilingue.",
  "alibaba/qwen3-coder.description": "Qwen3-Coder-480B-A35B-Instruct est le modèle de code le plus agentique de Qwen, performant dans le codage agentique, l'utilisation de navigateurs par agents et d'autres tâches de programmation clés, atteignant des résultats comparables à Claude Sonnet.",
  "amazon/nova-lite.description": "Un modèle multimodal très économique avec un traitement ultra-rapide des entrées image, vidéo et texte.",
  "amazon/nova-micro.description": "Un modèle uniquement textuel offrant une latence ultra-faible à très faible coût.",
  "amazon/nova-pro.description": "Un modèle multimodal très performant offrant le meilleur équilibre entre précision, vitesse et coût pour une large gamme de tâches.",
  "amazon/titan-embed-text-v2.description": "Amazon Titan Text Embeddings V2 est un modèle d'embedding multilingue léger et efficace prenant en charge les dimensions 1024, 512 et 256.",
  "anthropic.claude-3-5-sonnet-20240620-v1:0.description": "Claude 3.5 Sonnet établit une nouvelle norme dans l'industrie, surpassant ses concurrents et Claude 3 Opus dans de nombreuses évaluations tout en conservant une vitesse et un coût intermédiaires.",
  "anthropic.claude-3-5-sonnet-20241022-v2:0.description": "Claude 3.5 Sonnet établit une nouvelle norme dans l'industrie, surpassant ses concurrents et Claude 3 Opus dans de nombreuses évaluations tout en conservant une vitesse et un coût intermédiaires.",
  "anthropic.claude-3-haiku-20240307-v1:0.description": "Claude 3 Haiku est le modèle le plus rapide et le plus compact d’Anthropic, offrant des réponses quasi instantanées aux requêtes simples. Il permet des interactions fluides et naturelles avec l’IA, et prend en charge l’entrée d’images avec une fenêtre de contexte de 200 000 tokens.",
  "anthropic.claude-3-opus-20240229-v1:0.description": "Claude 3 Opus est le modèle d’IA le plus puissant d’Anthropic, offrant des performances de pointe sur des tâches hautement complexes. Il gère les requêtes ouvertes et les scénarios inédits avec une grande fluidité et une compréhension proche de l’humain, et prend en charge l’entrée d’images avec une fenêtre de contexte de 200 000 tokens.",
  "anthropic.claude-3-sonnet-20240229-v1:0.description": "Claude 3 Sonnet allie intelligence et rapidité pour les charges de travail en entreprise, offrant un excellent rapport qualité-prix. Conçu comme un modèle fiable pour les déploiements IA à grande échelle, il prend en charge l’entrée d’images avec une fenêtre de contexte de 200 000 tokens.",
  "anthropic.claude-instant-v1.description": "Un modèle rapide, économique et performant pour les conversations quotidiennes, l’analyse de texte, les résumés et les questions-réponses sur documents.",
  "anthropic.claude-v2.description": "Un modèle très performant pour des tâches variées, allant du dialogue complexe à la génération créative, en passant par le suivi précis d’instructions.",
  "anthropic.claude-v2:1.description": "Une version mise à jour de Claude 2 avec une fenêtre de contexte doublée et une fiabilité améliorée, réduisant les hallucinations et augmentant la précision fondée sur des preuves pour les documents longs et le RAG.",
  "anthropic/claude-3-haiku.description": "Claude 3 Haiku est le modèle le plus rapide d’Anthropic, conçu pour les charges de travail en entreprise avec des invites longues. Il peut analyser rapidement de grands documents comme des rapports trimestriels, des contrats ou des dossiers juridiques, à un coût moitié moindre que ses concurrents.",
  "anthropic/claude-3-opus.description": "Claude 3 Opus est le modèle le plus intelligent d’Anthropic, offrant des performances de pointe sur des tâches complexes, avec une grande fluidité et une compréhension proche de l’humain pour les requêtes ouvertes et les scénarios inédits.",
  "anthropic/claude-3.5-haiku.description": "Claude 3.5 Haiku offre une vitesse accrue, une meilleure précision en programmation et une utilisation optimisée des outils, idéal pour les scénarios exigeant rapidité et interaction avec des outils.",
  "anthropic/claude-3.5-sonnet.description": "Claude 3.5 Sonnet est le modèle rapide et efficace de la famille Sonnet, offrant de meilleures performances en programmation et en raisonnement, certaines versions étant progressivement remplacées par Sonnet 3.7 et ultérieures.",
  "anthropic/claude-3.7-sonnet.description": "Claude 3.7 Sonnet est une version améliorée du modèle Sonnet, avec des capacités renforcées en raisonnement et en programmation, adapté aux tâches complexes de niveau entreprise.",
  "anthropic/claude-haiku-4.5.description": "Claude Haiku 4.5 est le modèle rapide haute performance d’Anthropic, offrant une latence très faible tout en maintenant une grande précision.",
  "anthropic/claude-opus-4.1.description": "Opus 4.1 est le modèle haut de gamme d’Anthropic, optimisé pour la programmation, le raisonnement complexe et les tâches longues.",
  "anthropic/claude-opus-4.5.description": "Claude Opus 4.5 est le modèle phare d’Anthropic, combinant intelligence de haut niveau et performance évolutive pour des tâches complexes nécessitant un raisonnement de qualité supérieure.",
  "anthropic/claude-opus-4.description": "Opus 4 est le modèle phare d’Anthropic, conçu pour les tâches complexes et les applications en entreprise.",
  "anthropic/claude-sonnet-4.5.description": "Claude Sonnet 4.5 est le dernier modèle hybride de raisonnement d’Anthropic, optimisé pour le raisonnement complexe et la programmation.",
  "anthropic/claude-sonnet-4.description": "Claude Sonnet 4 est un modèle hybride de raisonnement d’Anthropic, combinant des capacités de réflexion et d’exécution directe.",
  "ascend-tribe/pangu-pro-moe.description": "Pangu-Pro-MoE 72B-A16B est un modèle LLM parcimonieux avec 72 milliards de paramètres au total et 16 milliards actifs, basé sur une architecture MoE groupée (MoGE). Il regroupe les experts lors de la sélection et contraint les jetons à activer un nombre égal d'experts par groupe, équilibrant ainsi la charge et améliorant l'efficacité du déploiement sur Ascend.",
  "aya.description": "Aya 23 est le modèle multilingue de Cohere prenant en charge 23 langues pour une grande variété de cas d’usage.",
  "aya:35b.description": "Aya 23 est le modèle multilingue de Cohere prenant en charge 23 langues pour une grande variété de cas d’usage.",
  "azure-DeepSeek-R1-0528.description": "Déployé par Microsoft, DeepSeek R1 a été mis à jour vers DeepSeek-R1-0528. Cette mise à jour améliore la puissance de calcul et les algorithmes de post-entraînement, renforçant considérablement la profondeur de raisonnement et les capacités d’inférence. Il offre d’excellentes performances en mathématiques, en programmation et en logique générale, rivalisant avec les modèles de pointe comme O3 et Gemini 2.5 Pro.",
  "baichuan-m2-32b.description": "Baichuan M2 32B est un modèle MoE développé par Baichuan Intelligence, doté de solides capacités de raisonnement.",
  "baichuan/baichuan2-13b-chat.description": "Baichuan-13B est un LLM open source de 13 milliards de paramètres, utilisable commercialement, développé par Baichuan. Il atteint des performances de premier plan pour sa taille sur des benchmarks chinois et anglais reconnus.",
  "baidu/ERNIE-4.5-300B-A47B.description": "ERNIE-4.5-300B-A47B est un LLM MoE de Baidu avec 300 milliards de paramètres au total et 47 milliards actifs par jeton, alliant hautes performances et efficacité de calcul. En tant que modèle central d’ERNIE 4.5, il excelle en compréhension, génération, raisonnement et programmation. Il utilise une méthode de pré-entraînement multimodale hétérogène MoE avec un apprentissage conjoint texte-image pour renforcer ses capacités globales, notamment le suivi d’instructions et les connaissances générales.",
  "baidu/ernie-5.0-thinking-preview.description": "ERNIE 5.0 Thinking Preview est le modèle ERNIE multimodal de nouvelle génération de Baidu, performant en compréhension multimodale, suivi d’instructions, création, questions-réponses factuelles et utilisation d’outils.",
  "black-forest-labs/flux-1.1-pro.description": "FLUX 1.1 Pro est une version plus rapide et améliorée de FLUX Pro, offrant une excellente qualité d’image et un respect précis des instructions.",
  "black-forest-labs/flux-dev.description": "FLUX Dev est la version de développement de FLUX, destinée à un usage non commercial.",
  "black-forest-labs/flux-pro.description": "FLUX Pro est le modèle professionnel de FLUX, conçu pour une production d’images de haute qualité.",
  "black-forest-labs/flux-schnell.description": "FLUX Schnell est un modèle de génération d’images rapide, optimisé pour la vitesse.",
  "c4ai-aya-expanse-32b.description": "Aya Expanse est un modèle multilingue haute performance de 32 milliards de paramètres, utilisant l’ajustement par instruction, l’arbitrage de données, l’entraînement par préférence et la fusion de modèles pour rivaliser avec les modèles monolingues. Il prend en charge 23 langues.",
  "c4ai-aya-expanse-8b.description": "Aya Expanse est un modèle multilingue haute performance de 8 milliards de paramètres, utilisant l’ajustement par instruction, l’arbitrage de données, l’entraînement par préférence et la fusion de modèles pour rivaliser avec les modèles monolingues. Il prend en charge 23 langues.",
  "c4ai-aya-vision-32b.description": "Aya Vision est un modèle multimodal de pointe performant sur les principaux benchmarks de langue, texte et vision. Cette version 32B est axée sur des performances multilingues de haut niveau et prend en charge 23 langues.",
  "c4ai-aya-vision-8b.description": "Aya Vision est un modèle multimodal de pointe performant sur les principaux benchmarks de langue, texte et vision. Cette version 8B est optimisée pour une faible latence et de bonnes performances.",
  "charglm-3.description": "CharGLM-3 est conçu pour le jeu de rôle et la compagnie émotionnelle, avec une mémoire multi-tours ultra-longue et des dialogues personnalisés.",
  "charglm-4.description": "CharGLM-4 est conçu pour le jeu de rôle et la compagnie émotionnelle, avec une mémoire multi-tours ultra-longue et des dialogues personnalisés.",
  "chatgpt-4o-latest.description": "ChatGPT-4o est un modèle dynamique mis à jour en temps réel, combinant compréhension et génération avancées pour des cas d’usage à grande échelle comme le support client, l’éducation et l’assistance technique.",
  "claude-2.0.description": "Claude 2 apporte des améliorations clés pour les entreprises, notamment un contexte de 200 000 jetons, une réduction des hallucinations, des invites système et une nouvelle fonctionnalité de test : l’appel d’outils.",
  "claude-2.1.description": "Claude 2 apporte des améliorations clés pour les entreprises, notamment un contexte de 200 000 jetons, une réduction des hallucinations, des invites système et une nouvelle fonctionnalité de test : l’appel d’outils.",
  "claude-3-5-haiku-20241022.description": "Claude 3.5 Haiku est le modèle nouvelle génération le plus rapide d’Anthropic. Par rapport à Claude 3 Haiku, il améliore ses compétences globales et surpasse le précédent plus grand modèle, Claude 3 Opus, sur de nombreux tests d’intelligence.",
  "claude-3-5-haiku-latest.description": "Claude 3.5 Haiku fournit des réponses rapides pour les tâches légères.",
  "claude-3-7-sonnet-20250219.description": "Claude 3.7 Sonnet est le modèle le plus intelligent d’Anthropic et le premier modèle hybride de raisonnement sur le marché. Il peut fournir des réponses quasi instantanées ou un raisonnement détaillé étape par étape visible par l’utilisateur. Sonnet excelle particulièrement en programmation, science des données, vision et tâches d’agents.",
  "claude-3-7-sonnet-latest.description": "Claude 3.7 Sonnet est le modèle le plus récent et le plus performant d’Anthropic pour les tâches complexes, excellent en performance, intelligence, fluidité et compréhension.",
  "claude-3-haiku-20240307.description": "Claude 3 Haiku est le modèle le plus rapide et le plus compact d’Anthropic, conçu pour des réponses quasi instantanées avec des performances rapides et précises.",
  "claude-3-opus-20240229.description": "Claude 3 Opus est le modèle le plus puissant d’Anthropic pour les tâches complexes, excellent en performance, intelligence, fluidité et compréhension.",
  "claude-3-sonnet-20240229.description": "Claude 3 Sonnet équilibre intelligence et rapidité pour les charges de travail en entreprise, offrant une grande utilité à moindre coût et un déploiement fiable à grande échelle.",
  "claude-haiku-4-5-20251001.description": "Claude Haiku 4.5 est le modèle Haiku le plus rapide et le plus intelligent d’Anthropic, alliant vitesse fulgurante et raisonnement approfondi.",
  "claude-opus-4-1-20250805-thinking.description": "Claude Opus 4.1 Thinking est une variante avancée capable de révéler son processus de raisonnement.",
  "claude-opus-4-1-20250805.description": "Claude Opus 4.1 est le modèle le plus récent et le plus performant d’Anthropic pour les tâches complexes, excellent en performance, intelligence, fluidité et compréhension.",
  "claude-opus-4-20250514.description": "Claude Opus 4 est le modèle le plus puissant d’Anthropic pour les tâches hautement complexes, offrant des performances exceptionnelles en intelligence, fluidité et compréhension.",
  "claude-opus-4-5-20251101.description": "Claude Opus 4.5 est le modèle phare d’Anthropic, combinant intelligence exceptionnelle et performance évolutive, idéal pour les tâches complexes nécessitant des réponses et un raisonnement de très haute qualité.",
  "claude-sonnet-4-20250514-thinking.description": "Claude Sonnet 4 Thinking peut produire des réponses quasi instantanées ou une réflexion détaillée étape par étape avec un processus visible.",
  "claude-sonnet-4-20250514.description": "Claude Sonnet 4 peut générer des réponses quasi instantanées ou un raisonnement détaillé étape par étape avec un processus visible.",
  "claude-sonnet-4-5-20250929.description": "Claude Sonnet 4.5 est le modèle le plus intelligent d’Anthropic à ce jour.",
  "codegeex-4.description": "CodeGeeX-4 est un assistant de codage IA puissant prenant en charge les questions-réponses multilingues et la complétion de code pour améliorer la productivité des développeurs.",
  "codegeex4-all-9b.description": "CodeGeeX4-ALL-9B est un modèle multilingue de génération de code prenant en charge la complétion et la génération de code, l’interprétation de code, la recherche web, l’appel de fonctions et les questions-réponses au niveau des dépôts. Il couvre un large éventail de scénarios de développement logiciel et est l’un des meilleurs modèles de code sous 10 milliards de paramètres.",
  "codegemma.description": "CodeGemma est un modèle léger pour diverses tâches de programmation, permettant une itération rapide et une intégration facile.",
  "codegemma:2b.description": "CodeGemma est un modèle léger pour diverses tâches de programmation, permettant une itération rapide et une intégration facile.",
  "codellama.description": "Code Llama est un LLM spécialisé dans la génération et la discussion de code, avec une large prise en charge des langages pour les flux de travail des développeurs.",
  "codellama/CodeLlama-34b-Instruct-hf.description": "Code Llama est un LLM spécialisé dans la génération et la discussion de code, avec une large prise en charge des langages pour les flux de travail des développeurs.",
  "codellama:13b.description": "Code Llama est un LLM spécialisé dans la génération et la discussion de code, avec une large prise en charge des langages pour les flux de travail des développeurs.",
  "codellama:34b.description": "Code Llama est un LLM spécialisé dans la génération et la discussion de code, avec une large prise en charge des langages pour les flux de travail des développeurs.",
  "codellama:70b.description": "Code Llama est un LLM spécialisé dans la génération et la discussion de code, avec une large prise en charge des langages pour les flux de travail des développeurs.",
  "codeqwen.description": "CodeQwen1.5 est un grand modèle de langage entraîné sur de vastes données de code, conçu pour des tâches de programmation complexes.",
  "codestral-latest.description": "Codestral est notre modèle de codage le plus avancé ; la version v2 (janvier 2025) cible les tâches à faible latence et haute fréquence comme FIM, la correction de code et la génération de tests.",
  "codestral.description": "Codestral est le premier modèle de code de Mistral AI, offrant un excellent support pour la génération de code.",
  "codex-mini-latest.description": "codex-mini-latest est un modèle o4-mini affiné pour l'interface en ligne de commande Codex. Pour une utilisation directe via l'API, nous recommandons de commencer avec gpt-4.1.",
  "cogito-2.1:671b.description": "Cogito v2.1 671B est un modèle de langage open source américain, gratuit pour un usage commercial. Il rivalise avec les meilleurs modèles, offre une meilleure efficacité de raisonnement par jeton, un contexte long de 128k et de solides performances globales.",
  "cogview-4.description": "CogView-4 est le premier modèle open source de génération d'images à partir de texte de Zhipu capable de générer des caractères chinois. Il améliore la compréhension sémantique, la qualité d'image et le rendu du texte en chinois/anglais, prend en charge des invites bilingues de longueur arbitraire et peut générer des images à toute résolution dans des plages spécifiées.",
  "cohere-command-r-plus.description": "Command R+ est un modèle avancé optimisé pour le RAG, conçu pour les charges de travail en entreprise.",
  "cohere-command-r.description": "Command R est un modèle génératif évolutif conçu pour le RAG et l'utilisation d'outils, permettant une IA de niveau production.",
  "cohere/Cohere-command-r-plus.description": "Command R+ est un modèle avancé optimisé pour le RAG, conçu pour les charges de travail en entreprise.",
  "cohere/Cohere-command-r.description": "Command R est un modèle génératif évolutif conçu pour le RAG et l'utilisation d'outils, permettant une IA de niveau production.",
  "cohere/command-a.description": "Command A est le modèle le plus puissant de Cohere à ce jour, excellent dans l'utilisation d'outils, les agents, le RAG et les cas d'utilisation multilingues. Il dispose d'un contexte de 256K, fonctionne sur seulement deux GPU et offre un débit 150 % supérieur à Command R+ 08-2024.",
  "cohere/command-r-plus.description": "Command R+ est le dernier modèle LLM de Cohere, optimisé pour le chat et les contextes longs, visant des performances exceptionnelles pour permettre aux entreprises de passer des prototypes à la production.",
  "cohere/command-r.description": "Command R est optimisé pour les tâches de chat et de contexte long, positionné comme un modèle « évolutif » qui équilibre haute performance et précision pour permettre aux entreprises de dépasser les prototypes et passer à la production.",
  "cohere/embed-v4.0.description": "Un modèle qui classe ou convertit du texte, des images ou du contenu mixte en embeddings.",
  "comfyui/flux-dev.description": "FLUX.1 Dev est un modèle texte-vers-image de haute qualité (10 à 50 étapes), idéal pour des rendus créatifs et artistiques premium.",
  "comfyui/flux-kontext-dev.description": "FLUX.1 Kontext-dev est un modèle d'édition d'image qui prend en charge les modifications guidées par le texte, y compris les modifications locales et le transfert de style.",
  "comfyui/flux-krea-dev.description": "FLUX.1 Krea-dev est un modèle texte-vers-image renforcé en sécurité, co-développé avec Krea, avec des filtres de sécurité intégrés.",
  "comfyui/flux-schnell.description": "FLUX.1 Schnell est un modèle texte-vers-image ultra-rapide qui génère des images de haute qualité en 1 à 4 étapes, idéal pour une utilisation en temps réel et le prototypage rapide.",
  "comfyui/stable-diffusion-15.description": "Stable Diffusion 1.5 est un modèle texte-vers-image classique en 512x512, idéal pour le prototypage rapide et les expérimentations créatives.",
  "comfyui/stable-diffusion-35-inclclip.description": "Stable Diffusion 3.5 avec encodeurs CLIP/T5 intégrés ne nécessite aucun fichier d'encodeur externe, adapté aux modèles comme sd3.5_medium_incl_clips avec une utilisation réduite des ressources.",
  "comfyui/stable-diffusion-35.description": "Stable Diffusion 3.5 est un modèle texte-vers-image de nouvelle génération avec des variantes Large et Medium. Il nécessite des fichiers d'encodeur CLIP externes et offre une excellente qualité d'image et une bonne fidélité aux invites.",
  "comfyui/stable-diffusion-custom-refiner.description": "Modèle image-vers-image SDXL personnalisé. Utilisez custom_sd_lobe.safetensors comme nom de fichier du modèle ; si vous avez un VAE, utilisez custom_sd_vae_lobe.safetensors. Placez les fichiers du modèle dans les dossiers requis de Comfy.",
  "comfyui/stable-diffusion-custom.description": "Modèle texte-vers-image SD personnalisé. Utilisez custom_sd_lobe.safetensors comme nom de fichier du modèle ; si vous avez un VAE, utilisez custom_sd_vae_lobe.safetensors. Placez les fichiers du modèle dans les dossiers requis de Comfy.",
  "comfyui/stable-diffusion-refiner.description": "Modèle image-vers-image SDXL réalisant des transformations de haute qualité à partir d'images d'entrée, prenant en charge le transfert de style, la restauration et les variations créatives.",
  "comfyui/stable-diffusion-xl.description": "SDXL est un modèle texte-vers-image prenant en charge la génération haute résolution 1024x1024 avec une meilleure qualité d'image et plus de détails.",
  "command-a-03-2025.description": "Command A est notre modèle le plus performant à ce jour, excellent dans l'utilisation d'outils, les agents, le RAG et les scénarios multilingues. Il dispose d'une fenêtre de contexte de 256K, fonctionne sur seulement deux GPU et offre un débit 150 % supérieur à Command R+ 08-2024.",
  "command-light-nightly.description": "Pour réduire l'intervalle entre les versions majeures, nous proposons des versions Command nocturnes. Pour la série command-light, cela s'appelle command-light-nightly. C'est la version la plus récente, la plus expérimentale (et potentiellement instable), mise à jour régulièrement sans préavis, donc non recommandée pour la production.",
  "command-light.description": "Une variante Command plus petite et plus rapide, presque aussi performante mais plus rapide.",
  "command-nightly.description": "Pour réduire l'intervalle entre les versions majeures, nous proposons des versions Command nocturnes. Pour la série Command, cela s'appelle command-nightly. C'est la version la plus récente, la plus expérimentale (et potentiellement instable), mise à jour régulièrement sans préavis, donc non recommandée pour la production.",
  "command-r-03-2024.description": "Command R est un modèle de chat suivant les instructions avec une qualité supérieure, une fiabilité accrue et une fenêtre de contexte plus longue que les modèles précédents. Il prend en charge des flux de travail complexes tels que la génération de code, le RAG, l'utilisation d'outils et les agents.",
  "command-r-08-2024.description": "command-r-08-2024 est une version mise à jour du modèle Command R publiée en août 2024.",
  "command-r-plus-04-2024.description": "command-r-plus est un alias de command-r-plus-04-2024, donc utiliser command-r-plus dans l'API pointe vers ce modèle.",
  "command-r-plus-08-2024.description": "Command R+ est un modèle de chat suivant les instructions avec une qualité supérieure, une fiabilité accrue et une fenêtre de contexte plus longue que les modèles précédents. Il est idéal pour les flux de travail RAG complexes et l'utilisation d'outils en plusieurs étapes.",
  "command-r-plus.description": "Command R+ est un LLM haute performance conçu pour des scénarios d'entreprise réels et des applications complexes.",
  "command-r.description": "Command R est un LLM optimisé pour le chat et les tâches à long contexte, idéal pour l'interaction dynamique et la gestion des connaissances.",
  "command-r7b-12-2024.description": "command-r7b-12-2024 est une mise à jour légère et efficace publiée en décembre 2024. Il excelle dans le RAG, l'utilisation d'outils et les tâches d'agents nécessitant un raisonnement complexe en plusieurs étapes.",
  "command.description": "Un modèle de chat suivant les instructions qui offre une qualité et une fiabilité supérieures pour les tâches linguistiques, avec une fenêtre de contexte plus longue que nos modèles génératifs de base.",
  "computer-use-preview.description": "computer-use-preview est un modèle spécialisé pour l'outil \"utilisation de l'ordinateur\", entraîné pour comprendre et exécuter des tâches liées à l'informatique.",
  "dall-e-2.description": "Modèle DALL·E de deuxième génération avec une génération d'images plus réaliste et précise, et une résolution 4× supérieure à la première génération.",
  "dall-e-3.description": "Le dernier modèle DALL·E, publié en novembre 2023, prend en charge une génération d'images plus réaliste et précise avec un niveau de détail renforcé.",
  "databricks/dbrx-instruct.description": "DBRX Instruct offre une gestion des instructions hautement fiable, adaptée à divers secteurs d'activité.",
  "deepseek-ai/DeepSeek-OCR.description": "DeepSeek-OCR est un modèle vision-langage développé par DeepSeek AI, spécialisé dans la reconnaissance optique de caractères (OCR) et la « compression optique contextuelle ». Il explore la compression du contexte à partir d’images, traite efficacement les documents et les convertit en texte structuré (par exemple, Markdown). Il reconnaît avec précision le texte dans les images, ce qui le rend idéal pour la numérisation de documents, l’extraction de texte et le traitement structuré.",
  "deepseek-ai/DeepSeek-R1-0528-Qwen3-8B.description": "DeepSeek-R1-0528-Qwen3-8B distille la chaîne de raisonnement de DeepSeek-R1-0528 dans Qwen3 8B Base. Il atteint l’état de l’art parmi les modèles open source, surpassant Qwen3 8B de 10 % sur AIME 2024 et égalant les performances de raisonnement de Qwen3-235B. Il excelle en raisonnement mathématique, en programmation et sur les benchmarks de logique générale. Il partage l’architecture de Qwen3-8B mais utilise le tokenizer de DeepSeek-R1-0528.",
  "deepseek-ai/DeepSeek-R1-0528.description": "DeepSeek R1 exploite une puissance de calcul accrue et des optimisations algorithmiques post-entraînement pour approfondir le raisonnement. Il affiche d’excellentes performances sur les benchmarks en mathématiques, programmation et logique générale, rivalisant avec des leaders comme o3 et Gemini 2.5 Pro.",
  "deepseek-ai/DeepSeek-R1-Distill-Llama-70B.description": "Les modèles distillés DeepSeek-R1 utilisent l’apprentissage par renforcement (RL) et des données de démarrage à froid pour améliorer le raisonnement et établir de nouveaux standards sur les benchmarks multitâches open source.",
  "deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B.description": "Les modèles distillés DeepSeek-R1 utilisent l’apprentissage par renforcement (RL) et des données de démarrage à froid pour améliorer le raisonnement et établir de nouveaux standards sur les benchmarks multitâches open source.",
  "deepseek-ai/DeepSeek-R1-Distill-Qwen-14B.description": "Les modèles distillés DeepSeek-R1 utilisent l’apprentissage par renforcement (RL) et des données de démarrage à froid pour améliorer le raisonnement et établir de nouveaux standards sur les benchmarks multitâches open source.",
  "deepseek-ai/DeepSeek-R1-Distill-Qwen-32B.description": "DeepSeek-R1-Distill-Qwen-32B est distillé à partir de Qwen2.5-32B et affiné sur 800 000 échantillons sélectionnés de DeepSeek-R1. Il excelle en mathématiques, programmation et raisonnement, avec d’excellents résultats sur AIME 2024, MATH-500 (94,3 % de précision) et GPQA Diamond.",
  "deepseek-ai/DeepSeek-R1-Distill-Qwen-7B.description": "DeepSeek-R1-Distill-Qwen-7B est distillé à partir de Qwen2.5-Math-7B et affiné sur 800 000 échantillons sélectionnés de DeepSeek-R1. Il affiche de solides performances avec 92,8 % sur MATH-500, 55,5 % sur AIME 2024 et une note CodeForces de 1189 pour un modèle 7B.",
  "deepseek-ai/DeepSeek-R1.description": "DeepSeek-R1 améliore le raisonnement grâce à l’apprentissage par renforcement et à des données de démarrage à froid, établissant de nouveaux standards multitâches open source et surpassant OpenAI-o1-mini.",
  "deepseek-ai/DeepSeek-V2.5.description": "DeepSeek-V2.5 améliore DeepSeek-V2-Chat et DeepSeek-Coder-V2-Instruct, combinant capacités générales et de codage. Il améliore la rédaction et le suivi des instructions pour un meilleur alignement des préférences, avec des gains significatifs sur AlpacaEval 2.0, ArenaHard, AlignBench et MT-Bench.",
  "deepseek-ai/DeepSeek-V3.1-Terminus.description": "DeepSeek-V3.1-Terminus est une version mise à jour du modèle V3.1, positionnée comme un agent hybride LLM. Il corrige les problèmes signalés par les utilisateurs et améliore la stabilité, la cohérence linguistique, tout en réduisant les caractères anormaux et le mélange chinois/anglais. Il intègre les modes de pensée et non-pensée avec des modèles de chat pour un basculement flexible. Il améliore également les performances des agents de code et de recherche pour une utilisation plus fiable des outils et des tâches multi-étapes.",
  "deepseek-ai/DeepSeek-V3.1.description": "DeepSeek V3.1 utilise une architecture de raisonnement hybride et prend en charge les modes pensée et non-pensée.",
  "deepseek-ai/DeepSeek-V3.2-Exp.description": "DeepSeek-V3.2-Exp est une version expérimentale de V3.2 servant de pont vers la prochaine architecture. Il ajoute DeepSeek Sparse Attention (DSA) au-dessus de V3.1-Terminus pour améliorer l’efficacité de l’entraînement et de l’inférence sur les contextes longs, avec des optimisations pour l’utilisation d’outils, la compréhension de documents longs et le raisonnement multi-étapes. Idéal pour explorer une efficacité de raisonnement accrue avec de grands budgets de contexte.",
  "deepseek-ai/DeepSeek-V3.description": "DeepSeek-V3 est un modèle MoE de 671 milliards de paramètres utilisant MLA et DeepSeekMoE avec un équilibrage de charge sans perte pour un entraînement et une inférence efficaces. Préentraîné sur 14,8T de tokens de haute qualité avec SFT et RL, il surpasse les autres modèles open source et rivalise avec les modèles fermés de pointe.",
  "deepseek-ai/deepseek-llm-67b-chat.description": "DeepSeek LLM Chat (67B) est un modèle innovant offrant une compréhension linguistique approfondie et une interaction fluide.",
  "deepseek-ai/deepseek-r1.description": "Un modèle LLM efficace de pointe, performant en raisonnement, mathématiques et programmation.",
  "deepseek-ai/deepseek-v3.1-terminus.description": "DeepSeek V3.1 est un modèle de raisonnement nouvelle génération avec un raisonnement complexe renforcé et une chaîne de pensée pour les tâches d’analyse approfondie.",
  "deepseek-ai/deepseek-v3.1.description": "DeepSeek V3.1 est un modèle de raisonnement nouvelle génération avec un raisonnement complexe renforcé et une chaîne de pensée pour les tâches d’analyse approfondie.",
  "deepseek-ai/deepseek-vl2.description": "DeepSeek-VL2 est un modèle vision-langage MoE basé sur DeepSeekMoE-27B avec activation clairsemée, atteignant de hautes performances avec seulement 4,5B de paramètres actifs. Il excelle en QA visuelle, OCR, compréhension de documents/tableaux/graphes et ancrage visuel.",
  "deepseek-chat.description": "Un nouveau modèle open source combinant capacités générales et de codage. Il conserve le dialogue général du modèle de chat et la puissance de codage du modèle de programmeur, avec un meilleur alignement des préférences. DeepSeek-V2.5 améliore également la rédaction et le suivi des instructions.",
  "deepseek-coder-33B-instruct.description": "DeepSeek Coder 33B est un modèle de langage pour le code entraîné sur 2T de tokens (87 % de code, 13 % de texte en chinois/anglais). Il introduit une fenêtre de contexte de 16K et des tâches de remplissage au milieu, offrant une complétion de code à l’échelle du projet et un remplissage de fragments.",
  "deepseek-coder-v2.description": "DeepSeek Coder V2 est un modèle de code MoE open source performant sur les tâches de programmation, comparable à GPT-4 Turbo.",
  "deepseek-coder-v2:236b.description": "DeepSeek Coder V2 est un modèle de code MoE open source performant sur les tâches de programmation, comparable à GPT-4 Turbo.",
  "deepseek-ocr.description": "DeepSeek-OCR est un modèle vision-langage de DeepSeek AI axé sur l’OCR et la « compression optique contextuelle ». Il explore la compression des informations contextuelles à partir d’images, traite efficacement les documents et les convertit en formats de texte structuré tels que Markdown. Il reconnaît avec précision le texte dans les images, ce qui le rend idéal pour la numérisation de documents, l’extraction de texte et le traitement structuré.",
  "deepseek-r1-0528.description": "Modèle complet de 685B publié le 28/05/2025. DeepSeek-R1 utilise un apprentissage par renforcement à grande échelle en post-entraînement, améliorant considérablement le raisonnement avec peu de données annotées, et affiche de solides performances en mathématiques, codage et raisonnement en langage naturel.",
  "deepseek-r1-250528.description": "DeepSeek R1 250528 est le modèle complet de raisonnement DeepSeek-R1 pour les tâches complexes en mathématiques et logique.",
  "deepseek-r1-70b-fast-online.description": "DeepSeek R1 70B édition rapide avec recherche web en temps réel, offrant des réponses plus rapides tout en maintenant les performances.",
  "deepseek-r1-70b-online.description": "DeepSeek R1 70B édition standard avec recherche web en temps réel, adaptée aux tâches de chat et de texte à jour.",
  "deepseek-r1-distill-llama-70b.description": "DeepSeek R1 Distill Llama 70B combine le raisonnement R1 avec l’écosystème Llama.",
  "deepseek-r1-distill-llama-8b.description": "DeepSeek-R1-Distill-Llama-8B est distillé à partir de Llama-3.1-8B en utilisant les sorties de DeepSeek R1.",
  "deepseek-r1-distill-llama.description": "deepseek-r1-distill-llama est distillé à partir de DeepSeek-R1 sur Llama.",
  "deepseek-r1-distill-qianfan-70b.description": "DeepSeek R1 Distill Qianfan 70B est une distillation R1 basée sur Qianfan-70B avec une forte valeur ajoutée.",
  "deepseek-r1-distill-qianfan-8b.description": "DeepSeek R1 Distill Qianfan 8B est une distillation R1 basée sur Qianfan-8B pour les applications petites et moyennes.",
  "deepseek-r1-distill-qianfan-llama-70b.description": "DeepSeek R1 Distill Qianfan Llama 70B est une distillation R1 basée sur Llama-70B.",
  "deepseek-r1-distill-qwen-1.5b.description": "DeepSeek R1 Distill Qwen 1.5B est un modèle ultra-léger pour les environnements à très faibles ressources.",
  "deepseek-r1-distill-qwen-14b.description": "DeepSeek R1 Distill Qwen 14B est un modèle de taille moyenne pour un déploiement multi-scénarios.",
  "deepseek-r1-distill-qwen-32b.description": "DeepSeek R1 Distill Qwen 32B est une distillation R1 basée sur Qwen-32B, équilibrant performance et coût.",
  "deepseek-r1-distill-qwen-7b.description": "DeepSeek R1 Distill Qwen 7B est un modèle léger pour les environnements en périphérie et les entreprises privées.",
  "deepseek-r1-distill-qwen.description": "deepseek-r1-distill-qwen est distillé à partir de DeepSeek-R1 sur Qwen.",
  "deepseek-r1-fast-online.description": "Version complète rapide de DeepSeek R1 avec recherche web en temps réel, combinant des capacités à l’échelle de 671B et des réponses plus rapides.",
  "deepseek-r1-online.description": "Version complète de DeepSeek R1 avec 671B de paramètres et recherche web en temps réel, offrant une meilleure compréhension et génération.",
  "deepseek-r1.description": "DeepSeek-R1 utilise des données de démarrage à froid avant l’apprentissage par renforcement et affiche des performances comparables à OpenAI-o1 en mathématiques, codage et raisonnement.",
  "deepseek-reasoner.description": "Le mode de pensée DeepSeek V3.2 produit une chaîne de raisonnement avant la réponse finale pour améliorer la précision.",
  "deepseek-v2.description": "DeepSeek V2 est un modèle MoE efficace pour un traitement économique.",
  "deepseek-v2:236b.description": "DeepSeek V2 236B est le modèle axé sur le code de DeepSeek avec une forte génération de code.",
  "deepseek-v3-0324.description": "DeepSeek-V3-0324 est un modèle MoE de 671B paramètres avec des points forts en programmation, compréhension du contexte et traitement de longs textes.",
  "deepseek-v3.1-terminus.description": "DeepSeek-V3.1-Terminus est un modèle LLM optimisé pour les terminaux, développé par DeepSeek, spécialement conçu pour les appareils en ligne de commande.",
  "deepseek-v3.1-think-250821.description": "DeepSeek V3.1 Think 250821 est le modèle de réflexion approfondie correspondant à la version Terminus, conçu pour un raisonnement haute performance.",
  "deepseek-v3.1.description": "DeepSeek-V3.1 est un nouveau modèle de raisonnement hybride de DeepSeek, prenant en charge les modes avec ou sans réflexion, et offrant une efficacité de raisonnement supérieure à celle de DeepSeek-R1-0528. Les optimisations post-entraînement améliorent considérablement l'utilisation des outils par les agents et leurs performances sur les tâches. Il prend en charge une fenêtre de contexte de 128k et jusqu'à 64k jetons de sortie.",
  "deepseek-v3.1:671b.description": "DeepSeek V3.1 est un modèle de raisonnement de nouvelle génération, amélioré pour le raisonnement complexe et la chaîne de pensée, adapté aux tâches nécessitant une analyse approfondie.",
  "deepseek-v3.2-exp.description": "deepseek-v3.2-exp introduit l'attention clairsemée pour améliorer l'efficacité de l'entraînement et de l'inférence sur les textes longs, à un coût inférieur à celui de deepseek-v3.1.",
  "deepseek-v3.2-think.description": "DeepSeek V3.2 Think est un modèle de réflexion approfondie complet, doté d'un raisonnement en chaîne plus puissant.",
  "deepseek-v3.2.description": "DeepSeek-V3.2 est le premier modèle de raisonnement hybride de DeepSeek intégrant la réflexion à l'utilisation d'outils. Il combine une architecture efficace pour économiser les ressources, un apprentissage par renforcement à grande échelle pour améliorer les capacités, et des données synthétiques massives pour renforcer la généralisation. Ses performances rivalisent avec celles de GPT-5-High, tout en réduisant considérablement la longueur des sorties, les coûts de calcul et le temps d'attente des utilisateurs.",
  "deepseek-v3.description": "DeepSeek-V3 est un puissant modèle MoE avec 671 milliards de paramètres au total et 37 milliards actifs par jeton.",
  "deepseek-vl2-small.description": "DeepSeek VL2 Small est une version multimodale légère, conçue pour les environnements à ressources limitées et les cas d'utilisation à forte concurrence.",
  "deepseek-vl2.description": "DeepSeek VL2 est un modèle multimodal pour la compréhension image-texte et les questions-réponses visuelles de précision.",
  "deepseek/deepseek-chat-v3-0324.description": "DeepSeek V3 est un modèle MoE de 685 milliards de paramètres, dernière itération de la série de chat phare de DeepSeek.\n\nIl s'appuie sur [DeepSeek V3](/deepseek/deepseek-chat-v3) et offre d'excellentes performances sur diverses tâches.",
  "deepseek/deepseek-chat-v3-0324:free.description": "DeepSeek V3 est un modèle MoE de 685 milliards de paramètres, dernière itération de la série de chat phare de DeepSeek.\n\nIl s'appuie sur [DeepSeek V3](/deepseek/deepseek-chat-v3) et offre d'excellentes performances sur diverses tâches.",
  "deepseek/deepseek-chat-v3.1.description": "DeepSeek-V3.1 est le modèle de raisonnement hybride à long contexte de DeepSeek, prenant en charge les modes de réflexion mixtes et l'intégration d'outils.",
  "deepseek/deepseek-chat.description": "DeepSeek-V3 est le modèle de raisonnement hybride haute performance de DeepSeek, conçu pour les tâches complexes et l'intégration d'outils.",
  "deepseek/deepseek-r1-0528.description": "DeepSeek R1 0528 est une variante mise à jour axée sur l'ouverture et un raisonnement plus approfondi.",
  "deepseek/deepseek-r1-0528:free.description": "DeepSeek-R1 améliore considérablement le raisonnement avec un minimum de données annotées et génère une chaîne de pensée avant la réponse finale pour en accroître la précision.",
  "deepseek/deepseek-r1-distill-llama-70b.description": "DeepSeek R1 Distill Llama 70B est un LLM distillé basé sur Llama 3.3 70B, affiné à l'aide des sorties de DeepSeek R1 pour atteindre des performances comparables aux modèles de pointe.",
  "deepseek/deepseek-r1-distill-llama-8b.description": "DeepSeek R1 Distill Llama 8B est un LLM distillé basé sur Llama-3.1-8B-Instruct, entraîné à partir des sorties de DeepSeek R1.",
  "deepseek/deepseek-r1-distill-qwen-14b.description": "DeepSeek R1 Distill Qwen 14B est un LLM distillé basé sur Qwen 2.5 14B, entraîné à partir des sorties de DeepSeek R1. Il surpasse OpenAI o1-mini sur plusieurs benchmarks, atteignant des résultats de pointe parmi les modèles denses. Résultats clés :\nAIME 2024 pass@1 : 69,7\nMATH-500 pass@1 : 93,9\nCodeForces Rating : 1481\nL'affinage avec les sorties de DeepSeek R1 permet d'obtenir des performances compétitives face aux modèles de pointe plus volumineux.",
  "deepseek/deepseek-r1-distill-qwen-32b.description": "DeepSeek R1 Distill Qwen 32B est un LLM distillé basé sur Qwen 2.5 32B, entraîné à partir des sorties de DeepSeek R1. Il surpasse OpenAI o1-mini sur plusieurs benchmarks, atteignant des résultats de pointe parmi les modèles denses. Résultats clés :\nAIME 2024 pass@1 : 72,6\nMATH-500 pass@1 : 94,3\nCodeForces Rating : 1691\nL'affinage avec les sorties de DeepSeek R1 permet d'obtenir des performances compétitives face aux modèles de pointe plus volumineux.",
  "deepseek/deepseek-r1.description": "DeepSeek R1 a été mis à jour vers DeepSeek-R1-0528. Grâce à une puissance de calcul accrue et à des optimisations algorithmiques post-entraînement, il améliore considérablement la profondeur et la capacité de raisonnement. Il offre d'excellentes performances en mathématiques, programmation et logique générale, rivalisant avec des leaders comme o3 et Gemini 2.5 Pro.",
  "deepseek/deepseek-r1/community.description": "DeepSeek R1 est le dernier modèle open source publié par l'équipe DeepSeek, avec des performances de raisonnement très solides, notamment en mathématiques, en programmation et en logique, comparables à OpenAI o1.",
  "deepseek/deepseek-r1:free.description": "DeepSeek-R1 améliore considérablement le raisonnement avec un minimum de données annotées et génère une chaîne de pensée avant la réponse finale pour en accroître la précision.",
  "deepseek/deepseek-reasoner.description": "DeepSeek-V3 Thinking (reasoner) est le modèle expérimental de raisonnement de DeepSeek, adapté aux tâches de raisonnement à haute complexité.",
  "deepseek/deepseek-v3.1-base.description": "DeepSeek V3.1 Base est une version améliorée du modèle DeepSeek V3.",
  "deepseek/deepseek-v3.description": "Un LLM polyvalent rapide avec des capacités de raisonnement renforcées.",
  "deepseek/deepseek-v3/community.description": "DeepSeek-V3 marque une avancée majeure en vitesse de raisonnement par rapport aux modèles précédents. Il se classe premier parmi les modèles open source et rivalise avec les modèles propriétaires les plus avancés. DeepSeek-V3 adopte l'attention latente multi-tête (MLA) et l'architecture DeepSeekMoE, toutes deux validées dans DeepSeek-V2. Il introduit également une stratégie auxiliaire sans perte pour l'équilibrage de charge et un objectif d'entraînement à prédiction multi-jetons pour des performances accrues.",
  "deepseek_r1.description": "DeepSeek-R1 est un modèle de raisonnement basé sur l'apprentissage par renforcement, conçu pour résoudre les problèmes de répétition et de lisibilité. Avant l'étape RL, il utilise des données de démarrage à froid pour améliorer encore les performances de raisonnement. Il rivalise avec OpenAI-o1 en mathématiques, programmation et logique, grâce à un entraînement soigneusement conçu qui améliore les résultats globaux.",
  "deepseek_r1_distill_llama_70b.description": "DeepSeek-R1-Distill-Llama-70B est distillé à partir de Llama-3.3-70B-Instruct. Faisant partie de la série DeepSeek-R1, il est affiné sur des échantillons générés par DeepSeek-R1 et offre d'excellentes performances en mathématiques, programmation et raisonnement.",
  "deepseek_r1_distill_qwen_14b.description": "DeepSeek-R1-Distill-Qwen-14B est distillé à partir de Qwen2.5-14B et affiné sur 800 000 échantillons sélectionnés générés par DeepSeek-R1, offrant un raisonnement solide.",
  "deepseek_r1_distill_qwen_32b.description": "DeepSeek-R1-Distill-Qwen-32B est distillé à partir de Qwen2.5-32B et affiné sur 800 000 échantillons sélectionnés générés par DeepSeek-R1, excellant en mathématiques, programmation et raisonnement.",
  "meta.llama3-8b-instruct-v1:0.description": "Meta Llama 3 est un modèle LLM ouvert destiné aux développeurs, chercheurs et entreprises, conçu pour les aider à créer, expérimenter et faire évoluer de manière responsable des idées d'IA générative. Faisant partie de la base de l'innovation communautaire mondiale, il est particulièrement adapté aux environnements à ressources limitées, aux appareils en périphérie et aux temps d'entraînement réduits.",
  "meta/Llama-3.2-11B-Vision-Instruct.description": "Raisonnement visuel performant sur des images haute résolution, idéal pour les applications de compréhension visuelle.",
  "meta/Llama-3.2-90B-Vision-Instruct.description": "Raisonnement visuel avancé pour les agents d'applications de compréhension visuelle.",
  "meta/Llama-3.3-70B-Instruct.description": "Llama 3.3 est le modèle Llama multilingue open source le plus avancé, offrant des performances proches de celles d’un modèle 405B à un coût très réduit. Basé sur l’architecture Transformer, il est amélioré par SFT et RLHF pour une meilleure utilité et sécurité. La version optimisée pour les instructions est conçue pour le chat multilingue et surpasse de nombreux modèles ouverts et fermés dans les benchmarks industriels. Date de coupure des connaissances : décembre 2023.",
  "meta/Meta-Llama-3-70B-Instruct.description": "Un modèle puissant de 70 milliards de paramètres, excellent en raisonnement, programmation et traitement du langage.",
  "meta/Meta-Llama-3-8B-Instruct.description": "Un modèle polyvalent de 8 milliards de paramètres, optimisé pour le chat et la génération de texte.",
  "meta/Meta-Llama-3.1-405B-Instruct.description": "Modèle Llama 3.1 optimisé pour les instructions, conçu pour le chat multilingue, avec d'excellentes performances sur les benchmarks industriels, qu'ils soient ouverts ou fermés.",
  "meta/Meta-Llama-3.1-70B-Instruct.description": "Modèle Llama 3.1 optimisé pour les instructions, conçu pour le chat multilingue, avec d'excellentes performances sur les benchmarks industriels, qu'ils soient ouverts ou fermés.",
  "meta/Meta-Llama-3.1-8B-Instruct.description": "Modèle Llama 3.1 optimisé pour les instructions, conçu pour le chat multilingue, avec d'excellentes performances sur les benchmarks industriels, qu'ils soient ouverts ou fermés.",
  "meta/llama-3-70b.description": "Un modèle open source de 70 milliards de paramètres affiné par Meta pour le suivi d'instructions, déployé par Groq sur du matériel LPU pour une inférence rapide et efficace.",
  "meta/llama-3-8b.description": "Un modèle open source de 8 milliards de paramètres affiné par Meta pour le suivi d'instructions, déployé par Groq sur du matériel LPU pour une inférence rapide et efficace.",
  "meta/llama-3.1-405b-instruct.description": "Un LLM avancé prenant en charge la génération de données synthétiques, la distillation des connaissances et le raisonnement pour les chatbots, la programmation et les tâches spécialisées.",
  "meta/llama-3.1-70b-instruct.description": "Conçu pour les dialogues complexes avec une excellente compréhension du contexte, un raisonnement poussé et une génération de texte de qualité.",
  "meta/llama-3.1-70b.description": "Version mise à jour de Meta Llama 3 70B Instruct avec une fenêtre de contexte de 128K, un support multilingue et un raisonnement amélioré.",
  "meta/llama-3.1-8b-instruct.description": "Un modèle de pointe avec une solide compréhension du langage, un bon raisonnement et une génération de texte efficace.",
  "meta/llama-3.1-8b.description": "Llama 3.1 8B prend en charge une fenêtre de contexte de 128K, idéal pour le chat en temps réel et l’analyse de données, tout en offrant des économies significatives par rapport aux modèles plus grands. Déployé par Groq sur du matériel LPU pour une inférence rapide et efficace.",
  "meta/llama-3.2-11b-vision-instruct.description": "Un modèle vision-langage de pointe, excellent pour le raisonnement de haute qualité à partir d’images.",
  "meta/llama-3.2-11b.description": "Modèle de raisonnement visuel optimisé pour les instructions (entrée texte + image, sortie texte), adapté à la reconnaissance visuelle, au raisonnement sur image, à la légende d’image et aux questions-réponses générales sur image.",
  "meta/llama-3.2-1b-instruct.description": "Un petit modèle de langage de pointe avec une forte compréhension, un bon raisonnement et une génération de texte efficace.",
  "meta/llama-3.2-1b.description": "Modèle texte uniquement pour les cas d’usage embarqués comme la recherche locale multilingue, le résumé et la réécriture.",
  "meta/llama-3.2-3b-instruct.description": "Un petit modèle de langage de pointe avec une forte compréhension, un bon raisonnement et une génération de texte efficace.",
  "meta/llama-3.2-3b.description": "Modèle texte uniquement affiné pour les cas d’usage embarqués comme la recherche locale multilingue, le résumé et la réécriture.",
  "meta/llama-3.2-90b-vision-instruct.description": "Un modèle vision-langage de pointe, excellent pour le raisonnement de haute qualité à partir d’images.",
  "meta/llama-3.2-90b.description": "Modèle de raisonnement visuel optimisé pour les instructions (entrée texte + image, sortie texte), adapté à la reconnaissance visuelle, au raisonnement sur image, à la légende d’image et aux questions-réponses générales sur image.",
  "meta/llama-3.3-70b-instruct.description": "Un LLM avancé, performant en raisonnement, mathématiques, bon sens et appels de fonctions.",
  "meta/llama-3.3-70b.description": "Un équilibre parfait entre performance et efficacité. Conçu pour une IA conversationnelle hautes performances dans la création de contenu, les applications d’entreprise et la recherche, avec une solide compréhension du langage pour le résumé, la classification, l’analyse de sentiment et la génération de code.",
  "meta/llama-4-maverick.description": "La famille Llama 4 est une série de modèles IA multimodaux natifs prenant en charge le texte et les expériences multimodales, utilisant MoE pour une compréhension avancée du texte et de l’image. Llama 4 Maverick est un modèle de 17B avec 128 experts, déployé par DeepInfra.",
  "meta/llama-4-scout.description": "La famille Llama 4 est une série de modèles IA multimodaux natifs prenant en charge le texte et les expériences multimodales, utilisant MoE pour une compréhension avancée du texte et de l’image. Llama 4 Scout est un modèle de 17B avec 16 experts, déployé par DeepInfra.",
  "mistralai/Mistral-7B-v0.1.description": "Mistral 7B est un modèle compact mais performant, idéal pour le traitement par lots et les tâches simples comme la classification et la génération de texte, avec un raisonnement solide.",
  "mistralai/Mixtral-8x22B-Instruct-v0.1.description": "Mixtral-8x22B Instruct (141B) est un très grand modèle de langage conçu pour les charges de travail intensives.",
  "mistralai/Mixtral-8x7B-Instruct-v0.1.description": "Mixtral-8x7B Instruct (46,7B) offre une grande capacité pour le traitement de données à grande échelle.",
  "mistralai/Mixtral-8x7B-v0.1.description": "Mixtral 8x7B est un modèle MoE épars qui accélère l'inférence, adapté aux tâches multilingues et à la génération de code.",
  "mistralai/mistral-nemo.description": "Mistral Nemo est un modèle de 7,3B avec prise en charge multilingue et de solides performances en programmation.",
  "mixtral-8x7b-32768.description": "Mixtral 8x7B offre un calcul parallèle tolérant aux pannes pour les tâches complexes.",
  "mixtral.description": "Mixtral est le modèle MoE de Mistral AI avec poids ouverts, prenant en charge la génération de code et la compréhension du langage.",
  "mixtral:8x22b.description": "Mixtral est le modèle MoE de Mistral AI avec poids ouverts, prenant en charge la génération de code et la compréhension du langage.",
  "moonshot-v1-128k-vision-preview.description": "Les modèles de vision Kimi (y compris moonshot-v1-8k-vision-preview/moonshot-v1-32k-vision-preview/moonshot-v1-128k-vision-preview) peuvent comprendre le contenu d’images comme le texte, les couleurs et les formes d’objets.",
  "moonshot-v1-128k.description": "Moonshot V1 128K offre un contexte ultra-long pour la génération de textes très étendus, jusqu’à 128 000 jetons, idéal pour la recherche, les travaux académiques et les documents volumineux.",
  "moonshot-v1-32k-vision-preview.description": "Les modèles de vision Kimi (y compris moonshot-v1-8k-vision-preview/moonshot-v1-32k-vision-preview/moonshot-v1-128k-vision-preview) peuvent comprendre le contenu d’images comme le texte, les couleurs et les formes d’objets.",
  "moonshot-v1-32k.description": "Moonshot V1 32K prend en charge 32 768 jetons pour un contexte de longueur moyenne, idéal pour les documents longs et les dialogues complexes dans la création de contenu, les rapports et les systèmes de chat.",
  "moonshot-v1-8k-vision-preview.description": "Les modèles de vision Kimi (y compris moonshot-v1-8k-vision-preview/moonshot-v1-32k-vision-preview/moonshot-v1-128k-vision-preview) peuvent comprendre le contenu d’images comme le texte, les couleurs et les formes d’objets.",
  "moonshot-v1-8k.description": "Moonshot V1 8K est optimisé pour la génération de textes courts avec des performances efficaces, prenant en charge 8 192 jetons pour les discussions brèves, les notes et le contenu rapide.",
  "moonshot-v1-auto.description": "Moonshot V1 Auto sélectionne le modèle approprié en fonction de l’utilisation actuelle des jetons de contexte.",
  "moonshotai/Kimi-Dev-72B.description": "Kimi-Dev-72B est un modèle de code open source optimisé avec un apprentissage par renforcement à grande échelle pour produire des correctifs robustes et prêts pour la production. Il atteint 60,4 % sur SWE-bench Verified, établissant un nouveau record pour les modèles ouverts dans les tâches d’ingénierie logicielle automatisée comme la correction de bugs et la revue de code.",
  "moonshotai/Kimi-K2-Instruct-0905.description": "Kimi K2-Instruct-0905 est la version la plus récente et la plus puissante de Kimi K2. C’est un modèle MoE de premier plan avec 1T de paramètres totaux et 32B actifs. Ses points forts incluent une intelligence de codage agentique renforcée avec des gains significatifs sur les benchmarks et les tâches réelles, ainsi qu’un code frontend plus esthétique et plus utilisable.",
  "moonshotai/Kimi-K2-Thinking.description": "Kimi K2 Thinking est le modèle de réflexion open source le plus avancé. Il étend considérablement la profondeur du raisonnement multi-étapes et maintient une utilisation stable des outils sur 200 à 300 appels consécutifs, établissant de nouveaux records sur Humanity's Last Exam (HLE), BrowseComp et d'autres benchmarks. Il excelle en codage, mathématiques, logique et scénarios d’agents. Construit sur une architecture MoE avec ~1T de paramètres totaux, il prend en charge une fenêtre de contexte de 256K et l’appel d’outils.",
  "moonshotai/kimi-k2-0711.description": "Kimi K2 0711 est la variante instructive de la série Kimi, adaptée au code de haute qualité et à l’utilisation d’outils.",
  "moonshotai/kimi-k2-0905.description": "Kimi K2 0905 est une mise à jour qui améliore les performances de contexte et de raisonnement avec des optimisations de codage.",
  "moonshotai/kimi-k2-instruct-0905.description": "Le modèle kimi-k2-0905-preview prend en charge une fenêtre de contexte de 256K, avec un codage agentique renforcé, un code frontend plus soigné et pratique, et une meilleure compréhension du contexte.",
  "moonshotai/kimi-k2-thinking-turbo.description": "Kimi K2 Thinking Turbo est une version rapide de Kimi K2 Thinking, réduisant considérablement la latence tout en conservant un raisonnement profond.",
  "moonshotai/kimi-k2-thinking.description": "Kimi K2 Thinking est le modèle de raisonnement de Moonshot optimisé pour les tâches de réflexion approfondie, avec des capacités générales d’agent.",
  "moonshotai/kimi-k2.description": "Kimi K2 est un grand modèle MoE de Moonshot AI avec 1T de paramètres totaux et 32B actifs par passage, optimisé pour les capacités d’agent, y compris l’utilisation avancée d’outils, le raisonnement et la synthèse de code.",
  "morph/morph-v3-fast.description": "Morph propose un modèle spécialisé pour appliquer les modifications de code suggérées par des modèles avancés (par ex. Claude ou GPT-4o) à vos fichiers existants à une vitesse de plus de 4500 jetons/sec. C’est l’étape finale d’un flux de travail de codage IA et il prend en charge 16k jetons en entrée/sortie.",
  "morph/morph-v3-large.description": "Morph propose un modèle spécialisé pour appliquer les modifications de code suggérées par des modèles avancés (par ex. Claude ou GPT-4o) à vos fichiers existants à une vitesse de plus de 2500 jetons/sec. C’est l’étape finale d’un flux de travail de codage IA et il prend en charge 16k jetons en entrée/sortie.",
  "nousresearch/hermes-2-pro-llama-3-8b.description": "Hermes 2 Pro Llama 3 8B est une version mise à jour de Nous Hermes 2 avec les derniers jeux de données développés en interne.",
  "nvidia/Llama-3.1-Nemotron-70B-Instruct-HF.description": "Llama 3.1 Nemotron 70B est un LLM personnalisé par NVIDIA pour améliorer l’utilité. Il obtient d’excellents résultats sur Arena Hard, AlpacaEval 2 LC et GPT-4-Turbo MT-Bench, se classant n°1 sur les trois benchmarks d’alignement automatique au 1er octobre 2024. Il est entraîné à partir de Llama-3.1-70B-Instruct avec RLHF (REINFORCE), Llama-3.1-Nemotron-70B-Reward et des invites HelpSteer2-Preference.",
  "nvidia/llama-3.1-nemotron-51b-instruct.description": "Un modèle de langage distinctif offrant une précision et une efficacité exceptionnelles.",
  "nvidia/llama-3.1-nemotron-70b-instruct.description": "Llama-3.1-Nemotron-70B-Instruct est un modèle personnalisé par NVIDIA conçu pour améliorer l’utilité des réponses des LLM.",
  "pixtral-12b-2409.description": "Pixtral excelle dans la compréhension de graphiques/images, les questions-réponses sur documents, le raisonnement multimodal et le suivi d'instructions. Il traite les images à leur résolution et ratio d'origine, et gère un nombre illimité d'images dans une fenêtre de contexte de 128K.",
  "pixtral-large-latest.description": "Pixtral Large est un modèle multimodal ouvert de 124 milliards de paramètres basé sur Mistral Large 2, le deuxième de notre famille multimodale, avec une compréhension d'image de pointe.",
  "pro-128k.description": "Spark Pro 128K offre une très grande capacité de contexte, jusqu'à 128K, idéale pour les documents longs nécessitant une analyse complète du texte et une cohérence à long terme, avec une logique fluide et un support de citations variées dans des discussions complexes.",
  "pro-deepseek-r1.description": "Modèle de service dédié aux entreprises avec une concurrence groupée.",
  "pro-deepseek-v3.description": "Modèle de service dédié aux entreprises avec une concurrence groupée.",
  "qianfan-70b.description": "Qianfan 70B est un grand modèle chinois conçu pour une génération de haute qualité et un raisonnement complexe.",
  "qianfan-8b.description": "Qianfan 8B est un modèle général de taille moyenne équilibrant coût et qualité pour la génération de texte et les questions-réponses.",
  "qianfan-agent-intent-32k.description": "Qianfan Agent Intent 32K est conçu pour la reconnaissance d'intention et l'orchestration d'agents avec un support de contexte étendu.",
  "qianfan-agent-lite-8k.description": "Qianfan Agent Lite 8K est un modèle d'agent léger pour des dialogues multi-tours à faible coût et des flux de travail simples.",
  "qianfan-agent-speed-32k.description": "Qianfan Agent Speed 32K est un modèle d'agent à haut débit pour des applications d'agents multitâches à grande échelle.",
  "qianfan-agent-speed-8k.description": "Qianfan Agent Speed 8K est un modèle d'agent à haute concurrence pour des conversations courtes à moyennes avec des réponses rapides.",
  "qianfan-check-vl.description": "Qianfan Check VL est un modèle de révision de contenu multimodal pour les tâches de conformité et de reconnaissance image-texte.",
  "qianfan-composition.description": "Qianfan Composition est un modèle de création multimodale pour la compréhension et la génération combinées d'image et de texte.",
  "qianfan-engcard-vl.description": "Qianfan EngCard VL est un modèle de reconnaissance multimodale axé sur les scénarios en anglais.",
  "qianfan-lightning-128b-a19b.description": "Qianfan Lightning 128B A19B est un modèle général chinois haute performance pour les questions-réponses complexes et le raisonnement à grande échelle.",
  "qianfan-llama-vl-8b.description": "Qianfan Llama VL 8B est un modèle multimodal basé sur Llama pour la compréhension générale image-texte.",
  "qianfan-multipicocr.description": "Qianfan MultiPicOCR est un modèle OCR multi-images pour la détection et la reconnaissance de texte à travers plusieurs images.",
  "qianfan-qi-vl.description": "Qianfan QI VL est un modèle de questions-réponses multimodal pour une récupération précise et des réponses dans des scénarios image-texte complexes.",
  "qianfan-singlepicocr.description": "Qianfan SinglePicOCR est un modèle OCR pour image unique avec une reconnaissance de caractères très précise.",
  "qianfan-vl-70b.description": "Qianfan VL 70B est un grand modèle vision-langage pour la compréhension complexe image-texte.",
  "qianfan-vl-8b.description": "Qianfan VL 8B est un modèle vision-langage léger pour les questions-réponses image-texte quotidiennes et l'analyse visuelle.",
  "qvq-72b-preview.description": "QVQ-72B-Preview est un modèle de recherche expérimental de Qwen axé sur l'amélioration du raisonnement visuel.",
  "qvq-max.description": "Le modèle de raisonnement visuel Qwen QVQ prend en charge les entrées visuelles et les sorties en chaîne de pensée, avec de meilleures performances en mathématiques, codage, analyse visuelle, créativité et tâches générales.",
  "qvq-plus.description": "Modèle de raisonnement visuel avec entrée visuelle et sortie en chaîne de pensée. La série qvq-plus succède à qvq-max et offre un raisonnement plus rapide avec un meilleur équilibre qualité-coût.",
  "qwen-3-32b.description": "Qwen 3 32B : performant en tâches multilingues et de programmation, adapté à une utilisation en production à moyenne échelle.",
  "qwen-coder-plus.description": "Modèle de code Qwen.",
  "qwen-coder-turbo-latest.description": "Modèle de code Qwen.",
  "qwen-coder-turbo.description": "Modèle de code Qwen.",
  "qwen-flash.description": "Modèle Qwen le plus rapide et le plus économique, idéal pour les tâches simples.",
  "qwen-image-edit.description": "Qwen Image Edit est un modèle image-à-image qui modifie les images en fonction d'images d'entrée et d'invites textuelles, permettant des ajustements précis et des transformations créatives.",
  "qwen-image.description": "Qwen-Image est un modèle général de génération d'images prenant en charge plusieurs styles artistiques et une forte capacité de rendu de texte complexe, notamment en chinois et en anglais. Il prend en charge les mises en page multi-lignes, les textes au niveau paragraphe et les détails fins pour des compositions texte-image complexes.",
  "qwen-long.description": "Modèle Qwen ultra-large avec support de long contexte et de chat sur plusieurs documents.",
  "qwen-math-plus-latest.description": "Qwen Math est un modèle linguistique spécialisé dans la résolution de problèmes mathématiques.",
  "qwen-math-plus.description": "Qwen Math est un modèle linguistique spécialisé dans la résolution de problèmes mathématiques.",
  "qwen-math-turbo-latest.description": "Qwen Math est un modèle linguistique spécialisé dans la résolution de problèmes mathématiques.",
  "qwen-math-turbo.description": "Qwen Math est un modèle linguistique spécialisé dans la résolution de problèmes mathématiques.",
  "qwen-max.description": "Modèle Qwen ultra-large à l'échelle de cent milliards de paramètres, prenant en charge le chinois, l'anglais et d'autres langues ; modèle API derrière les produits Qwen2.5 actuels.",
  "qwen-omni-turbo.description": "Les modèles Qwen-Omni prennent en charge les entrées multimodales (vidéo, audio, images, texte) et produisent de l'audio et du texte.",
  "qwen-plus.description": "Modèle Qwen ultra-large amélioré prenant en charge le chinois, l'anglais et d'autres langues.",
  "qwen-turbo.description": "Qwen Turbo ne sera plus mis à jour ; remplacez-le par Qwen Flash. Modèle Qwen ultra-large prenant en charge le chinois, l'anglais et d'autres langues.",
  "qwen-vl-chat-v1.description": "Qwen VL prend en charge des interactions flexibles incluant l'entrée multi-images, les questions-réponses multi-tours et les tâches créatives.",
  "qwen-vl-max-latest.description": "Modèle vision-langage Qwen ultra-large. Par rapport à la version améliorée, il améliore encore le raisonnement visuel et le suivi d'instructions pour une perception et une cognition renforcées.",
  "qwen-vl-max.description": "Modèle vision-langage Qwen ultra-large. Par rapport à la version améliorée, il améliore encore le raisonnement visuel et le suivi d'instructions pour une perception visuelle et une cognition renforcées.",
  "qwen-vl-ocr.description": "Qwen OCR est un modèle d'extraction de texte pour les documents, tableaux, images d'examen et écritures manuscrites. Il prend en charge le chinois, l'anglais, le français, le japonais, le coréen, l'allemand, le russe, l'italien, le vietnamien et l'arabe.",
  "qwen-vl-plus-latest.description": "Modèle vision-langage Qwen de grande échelle amélioré avec des gains majeurs en reconnaissance de détails et de texte, prenant en charge une résolution supérieure à un mégapixel et des ratios d'aspect arbitraires.",
  "qwen-vl-plus.description": "Modèle vision-langage Qwen de grande échelle amélioré avec des gains majeurs en reconnaissance de détails et de texte, prenant en charge une résolution supérieure à un mégapixel et des ratios d'aspect arbitraires.",
  "qwen-vl-v1.description": "Modèle préentraîné initialisé à partir de Qwen-7B avec un module de vision ajouté et une entrée image en résolution 448.",
  "qwen2.5-14b-instruct.description": "Modèle open source Qwen2.5 de 14 milliards de paramètres.",
  "qwen2.5-32b-instruct.description": "Modèle open source Qwen2.5 de 32 milliards de paramètres.",
  "qwen2.5-72b-instruct.description": "Modèle open source Qwen2.5 de 72 milliards de paramètres.",
  "qwen2.5-7b-instruct.description": "Qwen2.5 7B Instruct est un modèle open source mature, conçu pour le dialogue et la génération dans divers scénarios.",
  "qwen2.5-coder-1.5b-instruct.description": "Modèle de code open source Qwen.",
  "qwen2.5-coder-14b-instruct.description": "Modèle de code open source Qwen.",
  "qwen2.5-coder-32b-instruct.description": "Modèle de code open source Qwen.",
  "qwen2.5-coder-7b-instruct.description": "Modèle de code open source Qwen.",
  "qwen2.5-coder-instruct.description": "Qwen2.5-Coder est le dernier modèle LLM axé sur le code de la famille Qwen (anciennement CodeQwen).",
  "qwen2.5-instruct.description": "Qwen2.5 est la dernière série de LLM Qwen, avec des modèles de base et ajustés pour les instructions, allant de 0,5B à 72B de paramètres.",
  "qwen2.5-math-1.5b-instruct.description": "Qwen-Math offre de solides capacités de résolution de problèmes mathématiques.",
  "qwen2.5-math-72b-instruct.description": "Qwen-Math offre de solides capacités de résolution de problèmes mathématiques.",
  "qwen2.5-math-7b-instruct.description": "Qwen-Math offre de solides capacités de résolution de problèmes mathématiques.",
  "qwen2.5-omni-7b.description": "Les modèles Qwen-Omni prennent en charge les entrées multimodales (vidéo, audio, images, texte) et produisent de l'audio ou du texte.",
  "qwen2.5-vl-32b-instruct.description": "Qwen2.5 VL 32B Instruct est un modèle multimodal open source adapté au déploiement privé et à des usages variés.",
  "qwen2.5-vl-72b-instruct.description": "Amélioration du suivi des instructions, des mathématiques, de la résolution de problèmes et du codage, avec une reconnaissance d’objets plus robuste. Prise en charge de la localisation précise des éléments visuels, compréhension de vidéos longues (jusqu’à 10 minutes), chronologie d’événements, compréhension de la vitesse, et agents capables de contrôler un OS ou un mobile via analyse et localisation. Extraction d’informations clés et sortie JSON performantes. Version 72B, la plus puissante de la série.",
  "qwen2.5-vl-7b-instruct.description": "Qwen2.5 VL 7B Instruct est un modèle multimodal léger, équilibrant coût de déploiement et capacité de reconnaissance.",
  "qwen2.5-vl-instruct.description": "Qwen2.5-VL est le dernier modèle vision-langage de la famille Qwen.",
  "qwen2.5.description": "Qwen2.5 est le modèle de langage de nouvelle génération d'Alibaba, performant dans de nombreux cas d’usage.",
  "qwen2.5:0.5b.description": "Qwen2.5 est le modèle de langage de nouvelle génération d'Alibaba, performant dans de nombreux cas d’usage.",
  "qwen2.5:1.5b.description": "Qwen2.5 est le modèle de langage de nouvelle génération d'Alibaba, performant dans de nombreux cas d’usage.",
  "qwen2.5:72b.description": "Qwen2.5 est le modèle de langage de nouvelle génération d'Alibaba, performant dans de nombreux cas d’usage.",
  "qwen2.description": "Qwen2 est le modèle de langage de nouvelle génération d'Alibaba, performant dans de nombreux cas d’usage.",
  "qwen2:0.5b.description": "Qwen2 est le modèle de langage de nouvelle génération d'Alibaba, performant dans de nombreux cas d’usage.",
  "qwen2:1.5b.description": "Qwen2 est le modèle de langage de nouvelle génération d'Alibaba, performant dans de nombreux cas d’usage.",
  "qwen2:72b.description": "Qwen2 est le modèle de langage de nouvelle génération d'Alibaba, performant dans de nombreux cas d’usage.",
  "qwen3-0.6b.description": "Qwen3 0.6B est un modèle d’entrée de gamme pour le raisonnement simple et les environnements très contraints.",
  "qwen3-1.7b.description": "Qwen3 1.7B est un modèle ultra-léger pour le déploiement sur périphériques et en périphérie.",
  "qwen3-14b.description": "Qwen3 14B est un modèle de taille moyenne pour les questions-réponses multilingues et la génération de texte.",
  "qwen3-235b-a22b-instruct-2507.description": "Qwen3 235B A22B Instruct 2507 est un modèle instruct phare pour une large gamme de tâches de génération et de raisonnement.",
  "qwen3-235b-a22b-thinking-2507.description": "Qwen3 235B A22B Thinking 2507 est un modèle de raisonnement ultra-large pour les tâches complexes.",
  "qwen3-235b-a22b.description": "Qwen3 235B A22B est un modèle général de grande taille pour les tâches complexes.",
  "qwen3-30b-a3b-instruct-2507.description": "Qwen3 30B A3B Instruct 2507 est un modèle instruct de taille moyenne à grande pour une génération et des réponses de haute qualité.",
  "qwen3-30b-a3b-thinking-2507.description": "Qwen3 30B A3B Thinking 2507 est un modèle de raisonnement équilibrant précision et coût.",
  "qwen3-30b-a3b.description": "Qwen3 30B A3B est un modèle général de taille moyenne à grande, équilibrant coût et qualité.",
  "qwen3-32b.description": "Qwen3 32B est adapté aux tâches générales nécessitant une compréhension approfondie.",
  "qwen3-4b.description": "Qwen3 4B convient aux applications petites à moyennes et à l’inférence locale.",
  "qwen3-8b.description": "Qwen3 8B est un modèle léger avec un déploiement flexible pour des charges de travail à forte concurrence.",
  "qwen3-coder-30b-a3b-instruct.description": "Modèle de code open source Qwen. Le dernier qwen3-coder-30b-a3b-instruct est basé sur Qwen3 et offre de solides capacités d’agent de codage, d’utilisation d’outils et d’interaction avec l’environnement pour la programmation autonome, avec d’excellentes performances en code et de bonnes capacités générales.",
  "qwen3-coder-480b-a35b-instruct.description": "Qwen3 Coder 480B A35B Instruct est un modèle de code phare pour la programmation multilingue et la compréhension de code complexe.",
  "qwen3-coder-flash.description": "Modèle de code Qwen. La dernière série Qwen3-Coder est basée sur Qwen3 et offre de solides capacités d’agent de codage, d’utilisation d’outils et d’interaction avec l’environnement pour la programmation autonome, avec d’excellentes performances en code et de bonnes capacités générales.",
  "qwen3-coder-plus.description": "Modèle de code Qwen. La dernière série Qwen3-Coder est basée sur Qwen3 et offre de solides capacités d’agent de codage, d’utilisation d’outils et d’interaction avec l’environnement pour la programmation autonome, avec d’excellentes performances en code et de bonnes capacités générales.",
  "qwen3-coder:480b.description": "Modèle haute performance d’Alibaba pour les tâches d’agent et de codage avec contexte long.",
  "qwen3-max-preview.description": "Modèle Qwen le plus performant pour les tâches complexes à étapes multiples. La version preview prend en charge le raisonnement.",
  "qwen3-max.description": "Les modèles Qwen3 Max offrent des gains importants par rapport à la série 2.5 en capacité générale, compréhension du chinois/anglais, suivi d’instructions complexes, tâches ouvertes subjectives, multilinguisme et utilisation d’outils, avec moins d’hallucinations. La dernière version améliore la programmation agentique et l’utilisation d’outils par rapport à qwen3-max-preview. Cette version atteint le SOTA dans son domaine et vise des besoins agents plus complexes.",
  "qwen3-next-80b-a3b-instruct.description": "Modèle open source Qwen3 de nouvelle génération sans raisonnement. Par rapport à la version précédente (Qwen3-235B-A22B-Instruct-2507), il offre une meilleure compréhension du chinois, un raisonnement logique renforcé et une génération de texte améliorée.",
  "qwen3-next-80b-a3b-thinking.description": "Qwen3 Next 80B A3B Thinking est une version phare de raisonnement pour les tâches complexes.",
  "qwen3-omni-flash.description": "Qwen-Omni accepte des entrées combinées (texte, images, audio, vidéo) et produit du texte ou de la parole. Il propose plusieurs styles vocaux naturels, prend en charge les langues et dialectes, et convient à des cas comme la rédaction, la reconnaissance visuelle et les assistants vocaux.",
  "qwen3-vl-235b-a22b-instruct.description": "Qwen3 VL 235B A22B Instruct est un modèle multimodal phare pour la compréhension et la création exigeantes.",
  "qwen3-vl-235b-a22b-thinking.description": "Qwen3 VL 235B A22B Thinking est la version de raisonnement phare pour les tâches multimodales complexes et la planification.",
  "qwen3-vl-30b-a3b-instruct.description": "Qwen3 VL 30B A3B Instruct est un grand modèle multimodal équilibrant précision et performance de raisonnement.",
  "qwen3-vl-30b-a3b-thinking.description": "Qwen3 VL 30B A3B Thinking est une version de raisonnement approfondi pour les tâches multimodales complexes.",
  "qwen3-vl-32b-instruct.description": "Qwen3 VL 32B Instruct est un modèle multimodal ajusté pour les instructions, destiné aux questions-réponses image-texte de haute qualité et à la création.",
  "qwen3-vl-32b-thinking.description": "Qwen3 VL 32B Thinking est une version multimodale de raisonnement approfondi pour l’analyse complexe et en chaîne.",
  "qwen3-vl-8b-instruct.description": "Qwen3 VL 8B Instruct est un modèle multimodal léger pour les questions-réponses visuelles quotidiennes et l’intégration dans les applications.",
  "qwen3-vl-8b-thinking.description": "Qwen3 VL 8B Thinking est un modèle multimodal de raisonnement en chaîne pour une analyse visuelle détaillée.",
  "qwen3-vl-flash.description": "Qwen3 VL Flash : version légère et rapide de raisonnement pour les requêtes sensibles à la latence ou à fort volume.",
  "qwen3-vl-plus.description": "Qwen VL est un modèle de génération de texte avec compréhension visuelle. Il peut effectuer de l’OCR, résumer, raisonner, extraire des attributs de photos de produits ou résoudre des problèmes à partir d’images.",
  "qwen3.description": "Qwen3 est le modèle de langage de nouvelle génération d'Alibaba, performant dans de nombreux cas d’usage.",
  "taichu_o1.description": "taichu_o1 est un modèle de raisonnement de nouvelle génération qui utilise l’interaction multimodale et l’apprentissage par renforcement pour reproduire une chaîne de pensée humaine. Il prend en charge la simulation de décisions complexes, expose les chemins de raisonnement tout en maintenant une grande précision, et convient parfaitement à l’analyse stratégique et à la réflexion approfondie.",
  "taichu_vl.description": "Combine la compréhension d’images, le transfert de connaissances et l’attribution logique, excellant dans les questions-réponses image-texte.",
  "tencent/Hunyuan-A13B-Instruct.description": "Hunyuan-A13B-Instruct utilise un total de 80 milliards de paramètres, dont 13 milliards actifs, pour rivaliser avec des modèles plus grands. Il prend en charge un raisonnement hybride rapide/lent, une compréhension stable de longs textes, et se distingue dans les capacités d’agent sur BFCL-v3 et τ-Bench. Les formats GQA et multi-quant permettent une inférence efficace.",
  "tencent/Hunyuan-MT-7B.description": "Le modèle de traduction Hunyuan comprend Hunyuan-MT-7B et l’ensemble Hunyuan-MT-Chimera. Hunyuan-MT-7B est un modèle de traduction léger de 7 milliards de paramètres prenant en charge 33 langues ainsi que 5 langues minoritaires chinoises. Il a obtenu 30 premières places sur 31 paires de langues lors du WMT25. Tencent Hunyuan utilise une chaîne d’entraînement complète, du pré-entraînement à l’ajustement fin (SFT), en passant par l’apprentissage par renforcement pour la traduction et les ensembles, atteignant des performances de pointe avec un déploiement efficace et simple.",
  "text-embedding-3-large.description": "Le modèle d’intégration le plus performant pour les tâches en anglais et en langues étrangères.",
  "text-embedding-3-small.description": "Un modèle d’intégration de nouvelle génération, efficace et économique, pour les scénarios de recherche et de génération augmentée par récupération (RAG).",
  "thudm/glm-4-32b.description": "GLM-4-32B-0414 est un modèle bilingue (chinois/anglais) de 32 milliards de paramètres à poids ouverts, optimisé pour la génération de code, les appels de fonctions et les tâches d’agent. Il est préentraîné sur 15 To de données de haute qualité axées sur le raisonnement, puis affiné avec un alignement sur les préférences humaines, un échantillonnage par rejet et l’apprentissage par renforcement. Il excelle dans le raisonnement complexe, la génération d’artefacts et les sorties structurées, atteignant des performances comparables à GPT-4o et DeepSeek-V3-0324 sur de nombreux benchmarks.",
  "thudm/glm-4-32b:free.description": "GLM-4-32B-0414 est un modèle bilingue (chinois/anglais) de 32 milliards de paramètres à poids ouverts, optimisé pour la génération de code, les appels de fonctions et les tâches d’agent. Il est préentraîné sur 15 To de données de haute qualité axées sur le raisonnement, puis affiné avec un alignement sur les préférences humaines, un échantillonnage par rejet et l’apprentissage par renforcement. Il excelle dans le raisonnement complexe, la génération d’artefacts et les sorties structurées, atteignant des performances comparables à GPT-4o et DeepSeek-V3-0324 sur de nombreux benchmarks.",
  "thudm/glm-4-9b-chat.description": "La version open source du dernier modèle préentraîné GLM-4 de Zhipu AI.",
  "thudm/glm-z1-32b.description": "GLM-Z1-32B-0414 est une variante de raisonnement avancée de GLM-4-32B, conçue pour la résolution de problèmes complexes en mathématiques, logique et code. Il utilise un apprentissage par renforcement étendu (préférences spécifiques aux tâches et générales) pour améliorer les tâches complexes en plusieurs étapes. Par rapport à GLM-4-32B, Z1 améliore considérablement le raisonnement structuré et les capacités dans les domaines formels.\n\nIl prend en charge l’imposition d’étapes de « réflexion » via l’ingénierie de prompt, améliore la cohérence des longues sorties, et est optimisé pour les flux de travail d’agent avec contexte long (via YaRN), appels d’outils JSON, et échantillonnage fin pour un raisonnement stable. Idéal pour les cas d’usage nécessitant des déductions formelles ou multi-étapes rigoureuses.",
  "thudm/glm-z1-rumination-32b.description": "GLM Z1 Rumination 32B est un modèle de raisonnement profond de 32 milliards de paramètres de la série GLM-4-Z1, optimisé pour les tâches ouvertes complexes nécessitant une réflexion prolongée. Basé sur glm-4-32b-0414, il ajoute des étapes supplémentaires d’apprentissage par renforcement et un alignement multi-étapes, introduisant une capacité de « rumination » qui simule un traitement cognitif étendu. Cela inclut le raisonnement itératif, l’analyse multi-sauts et les flux de travail augmentés par outils tels que la recherche, la récupération et la synthèse avec prise en compte des citations.\n\nIl excelle dans la rédaction de recherches, l’analyse comparative et les questions-réponses complexes. Il prend en charge les appels de fonctions pour les primitives de recherche/navigation (`search`, `click`, `open`, `finish`) dans les pipelines d’agent. Le comportement de rumination est contrôlé par des boucles multi-tours avec façonnage de récompense basé sur des règles et des mécanismes de décision différée, évalué selon des cadres de recherche approfondie comme la pile d’alignement interne d’OpenAI. Cette variante privilégie la profondeur à la vitesse.",
  "tngtech/deepseek-r1t-chimera:free.description": "DeepSeek-R1T-Chimera est issu de la fusion de DeepSeek-R1 et DeepSeek-V3 (0324), combinant le raisonnement de R1 avec l’efficacité des tokens de V3. Il repose sur le transformeur DeepSeek-MoE et est optimisé pour la génération de texte généraliste.\n\nIl fusionne les poids préentraînés pour équilibrer raisonnement, efficacité et suivi d’instructions. Publié sous licence MIT pour un usage de recherche et commercial.",
  "togethercomputer/StripedHyena-Nous-7B.description": "StripedHyena Nous (7B) offre une efficacité de calcul améliorée grâce à son architecture et sa stratégie.",
  "tts-1-hd.description": "Le dernier modèle de synthèse vocale optimisé pour la qualité.",
  "tts-1.description": "Le dernier modèle de synthèse vocale optimisé pour la vitesse en temps réel.",
  "upstage/SOLAR-10.7B-Instruct-v1.0.description": "Upstage SOLAR Instruct v1 (11B) est ajusté pour les tâches d’instruction précises avec de solides performances linguistiques.",
  "us.anthropic.claude-3-5-sonnet-20241022-v2:0.description": "Claude 3.5 Sonnet redéfinit les standards de l’industrie, surpassant ses concurrents et Claude 3 Opus dans de nombreuses évaluations tout en conservant une vitesse et un coût intermédiaires.",
  "us.anthropic.claude-3-7-sonnet-20250219-v1:0.description": "Claude 3.7 Sonnet est le modèle nouvelle génération le plus rapide d’Anthropic. Par rapport à Claude 3 Haiku, il améliore toutes les compétences et dépasse l’ancien modèle phare Claude 3 Opus sur de nombreux benchmarks d’intelligence.",
  "us.anthropic.claude-haiku-4-5-20251001-v1:0.description": "Claude Haiku 4.5 est le modèle Haiku le plus rapide et le plus intelligent d’Anthropic, avec une vitesse fulgurante et une capacité de réflexion étendue.",
  "us.anthropic.claude-sonnet-4-5-20250929-v1:0.description": "Claude Sonnet 4.5 est à ce jour le modèle le plus intelligent d’Anthropic.",
  "v0-1.0-md.description": "v0-1.0-md est un modèle hérité accessible via l’API v0.",
  "v0-1.5-lg.description": "v0-1.5-lg est adapté aux tâches avancées de réflexion ou de raisonnement.",
  "v0-1.5-md.description": "v0-1.5-md est adapté aux tâches quotidiennes et à la génération d’interfaces utilisateur.",
  "vercel/v0-1.0-md.description": "Accédez aux modèles derrière v0 pour générer, corriger et optimiser des applications web modernes avec un raisonnement spécifique aux frameworks et des connaissances à jour.",
  "vercel/v0-1.5-md.description": "Accédez aux modèles derrière v0 pour générer, corriger et optimiser des applications web modernes avec un raisonnement spécifique aux frameworks et des connaissances à jour.",
  "volcengine/doubao-seed-code.description": "Doubao-Seed-Code est le modèle LLM de ByteDance Volcano Engine optimisé pour la programmation agentique, performant sur les benchmarks de programmation et d’agent avec un support de contexte de 256K.",
  "wan2.2-t2i-flash.description": "Wanxiang 2.2 Speed est le dernier modèle avec des améliorations en créativité, stabilité et réalisme, offrant une génération rapide et une grande valeur.",
  "wan2.2-t2i-plus.description": "Wanxiang 2.2 Pro est le dernier modèle avec des améliorations en créativité, stabilité et réalisme, produisant des détails plus riches.",
  "wanx-v1.description": "Modèle de base texte-vers-image. Correspond à Tongyi Wanxiang 1.0 General.",
  "wanx2.0-t2i-turbo.description": "Excelle dans les portraits texturés avec une vitesse modérée et un coût réduit. Correspond à Tongyi Wanxiang 2.0 Speed.",
  "wanx2.1-t2i-plus.description": "Version entièrement mise à jour avec des détails d’image plus riches et une vitesse légèrement réduite. Correspond à Tongyi Wanxiang 2.1 Pro.",
  "wanx2.1-t2i-turbo.description": "Version entièrement mise à jour avec une génération rapide, une qualité globale élevée et une grande valeur. Correspond à Tongyi Wanxiang 2.1 Speed.",
  "whisper-1.description": "Modèle général de reconnaissance vocale prenant en charge la transcription multilingue, la traduction vocale et l’identification de la langue.",
  "wizardlm2.description": "WizardLM 2 est un modèle linguistique de Microsoft AI qui excelle dans les dialogues complexes, les tâches multilingues, le raisonnement et les assistants.",
  "wizardlm2:8x22b.description": "WizardLM 2 est un modèle linguistique de Microsoft AI qui excelle dans les dialogues complexes, les tâches multilingues, le raisonnement et les assistants.",
  "x-ai/grok-4-fast-non-reasoning.description": "Grok 4 Fast (Non-Reasoning) est le modèle multimodal à haut débit et faible coût de xAI (avec une fenêtre de contexte de 2M), conçu pour les scénarios sensibles à la latence et au coût ne nécessitant pas de raisonnement intégré. Il est proposé aux côtés de la version avec raisonnement de Grok 4 Fast, et le raisonnement peut être activé via le paramètre API. Les prompts et complétions peuvent être utilisés par xAI ou OpenRouter pour améliorer les modèles futurs.",
  "x-ai/grok-4-fast.description": "Grok 4 Fast est le modèle à haut débit et faible coût de xAI (avec une fenêtre de contexte de 2M), idéal pour les cas d’usage à forte concurrence et à long contexte."
}
