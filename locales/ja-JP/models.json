{
  "01-ai/yi-1.5-34b-chat.description": "01.AIの最新のオープンソース微調整モデル。34Bパラメータを持ち、複数の対話シナリオに対応。高品質なデータで学習され、人間の好みに合わせて調整されています。",
  "01-ai/yi-1.5-9b-chat.description": "01.AIの最新のオープンソース微調整モデル。9Bパラメータを持ち、複数の対話シナリオに対応。高品質なデータで学習され、人間の好みに合わせて調整されています。",
  "360/deepseek-r1.description": "360が展開するDeepSeek-R1は、ポストトレーニングで大規模な強化学習を活用し、最小限のラベルで推論能力を大幅に向上させます。数学、コード、自然言語推論タスクにおいてOpenAI o1と同等の性能を発揮します。",
  "360gpt-pro-trans.description": "高品質な翻訳性能を実現するために深く微調整された、翻訳特化型モデルです。",
  "360gpt-pro.description": "360GPT Proは、さまざまなNLPシナリオに対応する効率的なテキスト処理を備えた360の主要AIモデルで、長文理解やマルチターン対話をサポートします。",
  "360gpt-turbo-responsibility-8k.description": "360GPT Turbo Responsibility 8Kは、意味的な安全性と責任ある出力を重視し、コンテンツに敏感なアプリケーションにおいて正確で堅牢なユーザー体験を提供します。",
  "360gpt-turbo.description": "360GPT Turboは、優れた意味理解と生成効率を備えた高性能な計算・対話能力を提供し、企業や開発者に最適です。",
  "360gpt2-o1.description": "360gpt2-o1は、ツリー探索と内省メカニズム、強化学習を組み合わせて思考の連鎖を構築し、自己内省と自己修正を可能にします。",
  "360gpt2-pro.description": "360GPT2 Proは、360が開発した高度なNLPモデルで、創造的なタスクにおいて優れたテキスト生成と理解を実現し、複雑な変換やロールプレイにも対応します。",
  "360zhinao2-o1.description": "360zhinao2-o1は、ツリー探索と内省メカニズム、強化学習を通じて思考の連鎖を構築し、自己内省と自己修正を可能にします。",
  "4.0Ultra.description": "Spark UltraはSparkシリーズで最も強力なモデルであり、テキスト理解と要約を強化し、ウェブ検索機能も向上。職場の生産性と正確な応答を高める包括的なソリューションとして、インテリジェント製品のリーダー的存在です。",
  "AnimeSharp.description": "AnimeSharp（別名「4x-AnimeSharp」）は、Kim2091によるESRGANをベースにしたオープンソースの超解像モデルで、アニメスタイルの画像の拡大とシャープ化に特化しています。2022年2月に「4x-TextSharpV1」から改名され、当初はテキスト画像にも対応していましたが、アニメコンテンツ向けに最適化されています。",
  "Baichuan2-Turbo.description": "検索拡張を活用して、モデルをドメイン知識やウェブ知識と接続。PDF/WordのアップロードやURL入力に対応し、タイムリーで包括的な情報取得と専門的で正確な出力を実現します。",
  "Baichuan3-Turbo-128k.description": "128Kの超長文コンテキストウィンドウを備え、頻度の高い企業シナリオに最適化され、大幅な性能向上と高い価値を提供します。Baichuan2と比較して、コンテンツ生成は20%、知識QAは17%、ロールプレイは40%向上。全体的な性能はGPT-3.5を上回ります。",
  "Baichuan3-Turbo.description": "頻度の高い企業シナリオに最適化され、大幅な性能向上と高い価値を提供します。Baichuan2と比較して、コンテンツ生成は20%、知識QAは17%、ロールプレイは40%向上。全体的な性能はGPT-3.5を上回ります。",
  "Baichuan4-Air.description": "中国国内でトップクラスの性能を誇り、知識、長文生成、創造的生成などの中国語タスクで海外の主要モデルを上回ります。業界最先端のマルチモーダル機能も備え、権威あるベンチマークで高評価を獲得しています。",
  "Baichuan4-Turbo.description": "中国国内でトップクラスの性能を誇り、知識、長文生成、創造的生成などの中国語タスクで海外の主要モデルを上回ります。業界最先端のマルチモーダル機能も備え、権威あるベンチマークで高評価を獲得しています。",
  "Baichuan4.description": "中国国内で最高レベルの性能を持ち、百科事典的知識、長文生成、創造的生成などの中国語タスクで海外の主要モデルを上回ります。業界最先端のマルチモーダル機能と優れたベンチマーク結果も提供します。",
  "ByteDance-Seed/Seed-OSS-36B-Instruct.description": "Seed-OSSは、ByteDance Seedが開発したオープンソースのLLMファミリーで、長文処理、推論、エージェント、汎用能力に優れています。Seed-OSS-36B-Instructは、36Bの命令調整済みモデルで、超長文コンテキストにネイティブ対応し、大規模な文書やコードベースの処理に最適です。推論、コード生成、エージェントタスク（ツール使用）に最適化され、汎用能力も維持しています。特徴的な「Thinking Budget」機能により、柔軟な推論長を実現し、効率を向上させます。",
  "DeepSeek-R1-Distill-Llama-70B.description": "DeepSeek R1は、DeepSeekスイートの中でより大規模かつ高性能なモデルであり、Llama 70Bアーキテクチャに蒸留されています。ベンチマークと人間による評価により、特に数学や事実精度のタスクで、ベースのLlama 70Bよりも優れていることが示されています。",
  "DeepSeek-R1-Distill-Qwen-1.5B.description": "Qwen2.5-Math-1.5BをベースにしたDeepSeek-R1蒸留モデル。強化学習とコールドスタートデータにより推論性能を最適化し、オープンモデルのマルチタスクベンチマークで新たな基準を打ち立てています。",
  "DeepSeek-R1-Distill-Qwen-14B.description": "DeepSeek-R1-Distillモデルは、DeepSeek-R1によって生成されたサンプルデータを用いて、オープンソースモデルから微調整されています。",
  "DeepSeek-R1-Distill-Qwen-32B.description": "DeepSeek-R1-Distillモデルは、DeepSeek-R1によって生成されたサンプルデータを用いて、オープンソースモデルから微調整されています。",
  "DeepSeek-R1-Distill-Qwen-7B.description": "Qwen2.5-Math-7BをベースにしたDeepSeek-R1蒸留モデル。強化学習とコールドスタートデータにより推論性能を最適化し、オープンモデルのマルチタスクベンチマークで新たな基準を打ち立てています。",
  "DeepSeek-R1.description": "DeepSeek-R1は、ポストトレーニングで大規模な強化学習を適用し、最小限のラベル付きデータで推論能力を大幅に向上させます。数学、コード、自然言語推論タスクにおいてOpenAI o1のプロダクションモデルと同等の性能を発揮します。",
  "DeepSeek-V3-1.description": "DeepSeek V3.1は、複雑な推論と思考の連鎖を強化した次世代推論モデルで、深い分析タスクに適しています。",
  "DeepSeek-V3-Fast.description": "提供元：sophnet。DeepSeek V3 Fastは、DeepSeek V3 0324の高TPSバージョンで、フル精度（非量子化）により、コードと数学に強く、応答も高速です。",
  "DeepSeek-V3.1-Fast.description": "DeepSeek V3.1 Fastは、DeepSeek V3.1の高TPS高速バリアントです。ハイブリッド思考モードにより、1つのモデルで思考と非思考の両方をサポート。ポストトレーニングにより、ツールとエージェントタスクの性能が向上しています。",
  "DeepSeek-V3.1-Think.description": "DeepSeek-V3.1の思考モード：思考と非思考の両モードを備えた新しいハイブリッド推論モデルで、DeepSeek-R1-0528よりも効率的です。ポストトレーニングの最適化により、エージェントのツール使用とタスク性能が大幅に向上しています。",
  "DeepSeek-V3.description": "DeepSeek-V3は、DeepSeekが開発したMoEモデルで、Qwen2.5-72BやLlama-3.1-405Bなどの他のオープンモデルを多くのベンチマークで上回り、GPT-4oやClaude 3.5 Sonnetなどの主要なクローズドモデルと競合します。",
  "amazon/titan-embed-text-v2.description": "Amazon Titan Text Embeddings V2 は軽量で効率的な多言語埋め込みモデルで、1024、512、256次元をサポートします。",
  "gemini-flash-latest.description": "Gemini Flash の最新リリース",
  "gemini-flash-lite-latest.description": "Gemini Flash-Lite の最新リリース",
  "gemini-pro-latest.description": "Gemini Pro の最新リリース",
  "meta/Llama-3.2-90B-Vision-Instruct.description": "視覚理解エージェント向けの高度な画像推論機能。",
  "meta/Llama-3.3-70B-Instruct.description": "Llama 3.3 は、最先端の多言語対応オープンソース Llama モデルであり、非常に低コストで 405B に近い性能を実現します。Transformer ベースで、SFT および RLHF により有用性と安全性が向上しています。命令調整版は多言語チャットに最適化されており、業界ベンチマークで多くのオープン・クローズドチャットモデルを上回ります。知識カットオフ：2023年12月。",
  "meta/Meta-Llama-3-70B-Instruct.description": "推論、コーディング、幅広い言語タスクに優れた 70B パラメータの強力なモデル。",
  "meta/Meta-Llama-3-8B-Instruct.description": "チャットとテキスト生成に最適化された多用途な 8B パラメータモデル。",
  "meta/Meta-Llama-3.1-405B-Instruct.description": "多言語チャットに最適化された Llama 3.1 命令調整テキストモデルで、オープン・クローズドチャットモデルの中でも業界標準ベンチマークで高い性能を発揮します。",
  "meta/Meta-Llama-3.1-70B-Instruct.description": "多言語チャットに最適化された Llama 3.1 命令調整テキストモデルで、オープン・クローズドチャットモデルの中でも業界標準ベンチマークで高い性能を発揮します。",
  "meta/Meta-Llama-3.1-8B-Instruct.description": "多言語チャットに最適化された Llama 3.1 命令調整テキストモデルで、オープン・クローズドチャットモデルの中でも業界標準ベンチマークで高い性能を発揮します。",
  "meta/llama-3-70b.description": "Meta によって命令追従に最適化された 70B のオープンソースモデル。Groq の LPU ハードウェア上で提供され、高速かつ効率的な推論を実現。",
  "meta/llama-3-8b.description": "Meta によって命令追従に最適化された 8B のオープンソースモデル。Groq の LPU ハードウェア上で提供され、高速かつ効率的な推論を実現。",
  "meta/llama-3.1-405b-instruct.description": "チャットボット、コーディング、ドメインタスク向けに、合成データ生成、知識蒸留、推論をサポートする高度な LLM。",
  "meta/llama-3.1-70b-instruct.description": "優れた文脈理解、推論、テキスト生成能力を備えた複雑な対話向けに構築されたモデル。",
  "meta/llama-3.1-70b.description": "128K コンテキスト、多言語対応、推論能力の向上を備えた最新の Meta Llama 3 70B Instruct。",
  "meta/llama-3.1-8b-instruct.description": "高度な言語理解、推論、テキスト生成能力を備えた最先端モデル。",
  "meta/llama-3.1-8b.description": "Llama 3.1 8B は 128K のコンテキストウィンドウをサポートし、リアルタイムチャットやデータ分析に最適。大規模モデルと比較して大幅なコスト削減を実現。Groq の LPU ハードウェア上で提供され、高速かつ効率的な推論を実現。",
  "meta/llama-3.2-11b-vision-instruct.description": "画像からの高品質な推論に優れた最先端の視覚言語モデル。",
  "meta/llama-3.2-11b.description": "視覚認識、画像推論、キャプション生成、一般的な画像 QA に最適化された命令調整型の画像推論モデル（テキスト＋画像入力、テキスト出力）。",
  "meta/llama-3.2-1b-instruct.description": "高度な理解力、推論力、テキスト生成能力を備えた最先端の小型言語モデル。",
  "meta/llama-3.2-1b.description": "多言語ローカル検索、要約、リライトなどのオンデバイス用途向けのテキスト専用モデル。",
  "meta/llama-3.2-3b-instruct.description": "高度な理解力、推論力、テキスト生成能力を備えた最先端の小型言語モデル。",
  "meta/llama-3.2-3b.description": "多言語ローカル検索、要約、リライトなどのオンデバイス用途向けにファインチューニングされたテキスト専用モデル。",
  "meta/llama-3.2-90b-vision-instruct.description": "画像からの高品質な推論に優れた最先端の視覚言語モデル。",
  "meta/llama-3.2-90b.description": "視覚認識、画像推論、キャプション生成、一般的な画像 QA に最適化された命令調整型の画像推論モデル（テキスト＋画像入力、テキスト出力）。",
  "meta/llama-3.3-70b-instruct.description": "推論、数学、常識、関数呼び出しに強い高度な LLM。",
  "meta/llama-3.3-70b.description": "性能と効率の完璧なバランス。コンテンツ制作、企業アプリ、研究における高性能な会話型 AI 向けに構築され、要約、分類、感情分析、コード生成において優れた言語理解を発揮。",
  "meta/llama-4-maverick.description": "Llama 4 ファミリーは、MoE を活用してテキストと画像の理解をリードする、テキストおよびマルチモーダル体験をサポートするネイティブマルチモーダル AI モデル群です。Llama 4 Maverick は 128 のエキスパートを持つ 17B モデルで、DeepInfra により提供されます。",
  "meta/llama-4-scout.description": "Llama 4 ファミリーは、MoE を活用してテキストと画像の理解をリードする、テキストおよびマルチモーダル体験をサポートするネイティブマルチモーダル AI モデル群です。Llama 4 Scout は 16 のエキスパートを持つ 17B モデルで、DeepInfra により提供されます。",
  "microsoft/Phi-3-medium-128k-instruct.description": "RAG や few-shot プロンプト向けにコンテキストウィンドウを拡張した Phi-3-medium モデル。",
  "microsoft/Phi-3-medium-4k-instruct.description": "Phi-3-mini よりも高品質で、推論重視のデータに特化した 14B パラメータモデル。",
  "microsoft/Phi-3-mini-128k-instruct.description": "RAG や few-shot プロンプト向けにコンテキストウィンドウを拡張した Phi-3-mini モデル。",
  "microsoft/Phi-3-mini-4k-instruct.description": "Phi-3 ファミリーで最小のモデル。品質と低レイテンシに最適化。",
  "microsoft/Phi-3-small-128k-instruct.description": "RAG や few-shot プロンプト向けにコンテキストウィンドウを拡張した Phi-3-small モデル。",
  "microsoft/Phi-3-small-8k-instruct.description": "Phi-3-mini よりも高品質で、推論重視のデータに特化した 7B パラメータモデル。",
  "microsoft/Phi-3.5-mini-instruct.description": "Phi-3-mini モデルの更新版。",
  "microsoft/Phi-3.5-vision-instruct.description": "Phi-3-vision モデルの更新版。",
  "microsoft/WizardLM-2-8x22B.description": "WizardLM 2 は Microsoft AI による言語モデルで、複雑な対話、多言語タスク、推論、アシスタントに優れています。",
  "microsoft/wizardlm-2-8x22b.description": "WizardLM-2 8x22B は Microsoft AI による最先端の Wizard モデルで、非常に競争力のある性能を発揮します。",
  "minicpm-v.description": "MiniCPM-V は OpenBMB の次世代マルチモーダルモデルで、OCR とマルチモーダル理解に優れ、幅広い用途に対応します。",
  "minimax-m2.description": "MiniMax M2 は、コーディングとエージェントワークフロー向けに構築された効率的な LLM です。",
  "minimax/minimax-m2.description": "MiniMax-M2 は、エンジニアリングシナリオにおけるコーディングとエージェントタスクに優れた高価値モデルです。",
  "minimaxai/minimax-m2.description": "MiniMax-M2 は、230B 総パラメータ中 10B アクティブのコンパクトで高速、コスト効率の高い MoE モデルで、マルチファイル編集、コード実行・修正ループ、テスト検証、複雑なツールチェーンに優れた性能を発揮します。"
}
