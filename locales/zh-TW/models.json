{
  "01-ai/yi-1.5-34b-chat.description": "01.AI 最新開源微調模型，擁有 340 億參數，支援多種對話場景，訓練於高品質資料，並對齊人類偏好。",
  "01-ai/yi-1.5-9b-chat.description": "01.AI 最新開源微調模型，擁有 90 億參數，支援多種對話場景，訓練於高品質資料，並對齊人類偏好。",
  "360/deepseek-r1.description": "360 部署的 DeepSeek-R1 在後訓練階段應用大規模強化學習，僅需極少標註資料即可大幅提升推理能力，在數學、程式碼與自然語言推理任務上與 OpenAI o1 表現相當。",
  "360gpt-pro-trans.description": "專為翻譯任務設計的模型，經深度微調以實現領先的翻譯品質。",
  "360gpt-pro.description": "360GPT Pro 是 360 AI 的核心模型，具備高效文本處理能力，適用於多樣化 NLP 應用場景，支援長文本理解與多輪對話。",
  "360gpt-turbo-responsibility-8k.description": "360GPT Turbo Responsibility 8K 著重語義安全與內容責任，適用於敏感應用場景，確保準確且穩健的使用者體驗。",
  "360gpt-turbo.description": "360GPT Turbo 具備強大運算與對話能力，語義理解與生成效率優異，適合企業與開發者使用。",
  "360gpt2-o1.description": "360gpt2-o1 結合樹狀搜尋與反思機制，透過強化學習訓練建立思維鏈，實現自我反思與修正能力。",
  "360gpt2-pro.description": "360GPT2 Pro 是 360 推出的進階 NLP 模型，擅長創意生成與文本理解，能處理複雜轉換與角色扮演任務。",
  "360zhinao2-o1.description": "360zhinao2-o1 結合樹狀搜尋與反思機制，透過強化學習訓練建立思維鏈，實現自我反思與修正能力。",
  "4.0Ultra.description": "Spark Ultra 為 Spark 系列中最強大的模型，提升文本理解與摘要能力，並升級網頁搜尋功能。為提升職場效率與準確回應的全方位解決方案，定位為領先的智慧產品。",
  "AnimeSharp.description": "AnimeSharp（又名「4x-AnimeSharp」）是由 Kim2091 基於 ESRGAN 開發的開源超解析度模型，專注於動畫風格圖像的放大與銳化。原名為「4x-TextSharpV1」，於 2022 年 2 月更名，雖最初也支援文字圖像，但已針對動畫內容進行深度優化。",
  "Baichuan2-Turbo.description": "透過搜尋增強技術，將模型與領域知識與網路資訊連結。支援 PDF/Word 上傳與網址輸入，實現即時、全面的檢索與專業、準確的輸出。",
  "Baichuan3-Turbo-128k.description": "具備 128K 超長上下文視窗，針對高頻企業場景進行優化，帶來顯著效能提升。相較於 Baichuan2，內容創作提升 20%，知識問答提升 17%，角色扮演提升 40%。整體表現優於 GPT-3.5。",
  "Baichuan3-Turbo.description": "針對高頻企業場景進行優化，帶來顯著效能提升。相較於 Baichuan2，內容創作提升 20%，知識問答提升 17%，角色扮演提升 40%。整體表現優於 GPT-3.5。",
  "Baichuan4-Air.description": "中國表現最強的模型之一，在知識問答、長文本處理與創意生成等中文任務上超越多個海外主流模型。具備業界領先的多模態能力，在權威基準測試中表現優異。",
  "Baichuan4-Turbo.description": "中國表現最強的模型之一，在知識問答、長文本處理與創意生成等中文任務上超越多個海外主流模型。具備業界領先的多模態能力，在權威基準測試中表現優異。",
  "Baichuan4.description": "國內頂尖表現，在百科知識、長文本處理與創意生成等中文任務上超越主流海外模型。亦具備業界領先的多模態能力與強勁的基準測試成績。",
  "ByteDance-Seed/Seed-OSS-36B-Instruct.description": "Seed-OSS 是字節跳動 Seed 團隊推出的開源 LLM 系列，具備強大的長上下文處理、推理、代理與通用能力。Seed-OSS-36B-Instruct 是一款 360 億參數的指令微調模型，原生支援超長上下文，適用於處理大型文件或程式碼庫。針對推理、程式碼生成與代理任務（工具使用）進行優化，同時保有強大的通用能力。其關鍵特性為「思考預算」，可靈活調整推理長度以提升效率。",
  "DeepSeek-R1-Distill-Llama-70B.description": "DeepSeek R1 是 DeepSeek 系列中更大更智慧的模型，已蒸餾至 Llama 70B 架構。基準測試與人工評估顯示其在數學與事實精確任務上優於原始 Llama 70B。",
  "DeepSeek-R1-Distill-Qwen-1.5B.description": "基於 Qwen2.5-Math-1.5B 的 DeepSeek-R1 蒸餾模型。透過強化學習與冷啟動資料優化推理表現，為開源模型樹立多任務新基準。",
  "DeepSeek-R1-Distill-Qwen-14B.description": "DeepSeek-R1-Distill 模型是從開源模型出發，使用 DeepSeek-R1 生成的樣本資料進行微調。",
  "DeepSeek-R1-Distill-Qwen-32B.description": "DeepSeek-R1-Distill 模型是從開源模型出發，使用 DeepSeek-R1 生成的樣本資料進行微調。",
  "DeepSeek-R1-Distill-Qwen-7B.description": "基於 Qwen2.5-Math-7B 的 DeepSeek-R1 蒸餾模型。透過強化學習與冷啟動資料優化推理表現，為開源模型樹立多任務新基準。",
  "DeepSeek-R1.description": "DeepSeek-R1 在後訓練階段應用大規模強化學習，僅需極少標註資料即可大幅提升推理能力，在數學、程式碼與自然語言推理任務上與 OpenAI o1 生產模型表現相當。",
  "DeepSeek-V3-1.description": "DeepSeek V3.1 是新一代推理模型，強化複雜推理與思維鏈能力，適用於深度分析任務。",
  "DeepSeek-V3-Fast.description": "提供者：sophnet。DeepSeek V3 Fast 是 DeepSeek V3 0324 的高 TPS 版本，為全精度（非量化）模型，具備更強的程式碼與數學能力，回應速度更快。",
  "DeepSeek-V3.1-Fast.description": "DeepSeek V3.1 Fast 是 DeepSeek V3.1 的高 TPS 快速版本。混合思維模式：透過對話模板，一個模型支援思考與非思考模式。工具使用更智慧：後訓練提升工具與代理任務表現。",
  "DeepSeek-V3.1-Think.description": "DeepSeek-V3.1 思考模式：新型混合推理模型，具備思考與非思考模式，效率優於 DeepSeek-R1-0528。後訓練優化顯著提升代理工具使用與任務表現。",
  "DeepSeek-V3.description": "DeepSeek-V3 是 DeepSeek 開發的 MoE 模型，在多項基準測試中超越 Qwen2.5-72B 與 Llama-3.1-405B 等開源模型，並與 GPT-4o、Claude 3.5 Sonnet 等主流封閉模型競爭。",
  "Doubao-lite-128k.description": "Doubao-lite 提供超快速回應與更高性價比，適用於多種場景，支援 128K 上下文推理與微調。",
  "Doubao-lite-32k.description": "Doubao-lite 提供超快速回應與更高性價比，適用於多種場景，支援 32K 上下文推理與微調。",
  "Doubao-lite-4k.description": "Doubao-lite 提供超快速回應與更高性價比，適用於多種場景，支援 4K 上下文推理與微調。",
  "Doubao-pro-128k.description": "旗艦級最佳表現模型，擅長參考問答、摘要、創作、分類與角色扮演。支援 128K 上下文推理與微調。",
  "Doubao-pro-32k.description": "旗艦級最佳表現模型，擅長參考問答、摘要、創作、分類與角色扮演。支援 32K 上下文推理與微調。",
  "Doubao-pro-4k.description": "旗艦級最佳表現模型，擅長參考問答、摘要、創作、分類與角色扮演。支援 4K 上下文推理與微調。",
  "DreamO.description": "DreamO 是由字節跳動與北京大學聯合開發的開源圖像定制模型，採用統一架構支援多任務圖像生成。透過高效組合建模，根據使用者指定的身份、主題、風格、背景等條件生成高度一致的定制圖像。",
  "ERNIE-3.5-128K.description": "百度旗艦級大模型，訓練於大規模中英文語料，具備強大通用能力，支援對話、創作與插件使用；可自動整合百度搜尋插件以提供即時答案。",
  "ERNIE-3.5-8K-Preview.description": "百度旗艦級大模型，訓練於大規模中英文語料，具備強大通用能力，支援對話、創作與插件使用；可自動整合百度搜尋插件以提供即時答案。",
  "ERNIE-3.5-8K.description": "百度旗艦級大模型，訓練於大規模中英文語料，具備強大通用能力，支援對話、創作與插件使用；可自動整合百度搜尋插件以提供即時答案。",
  "ERNIE-4.0-8K-Latest.description": "百度旗艦級超大模型，全面升級自 ERNIE 3.5，適用於跨領域複雜任務；支援百度搜尋插件整合以提供即時答案。",
  "ERNIE-4.0-8K-Preview.description": "百度旗艦級超大模型，全面升級自 ERNIE 3.5，適用於跨領域複雜任務；支援百度搜尋插件整合以提供即時答案。",
  "ERNIE-4.0-Turbo-8K-Latest.description": "百度旗艦級超大模型，整體表現強勁，適用於複雜任務，支援百度搜尋插件整合以提供即時答案。表現優於 ERNIE 4.0。",
  "ERNIE-4.0-Turbo-8K-Preview.description": "百度旗艦級超大模型，整體表現強勁，適用於複雜任務，支援百度搜尋插件整合以提供即時答案。表現優於 ERNIE 4.0。",
  "ERNIE-Character-8K.description": "百度面向遊戲 NPC、客服與角色扮演的垂直領域大模型，具備更清晰的人設一致性、更強的指令遵循能力與推理能力。",
  "ERNIE-Lite-Pro-128K.description": "百度輕量級大模型，在品質與推理效能間取得平衡，優於 ERNIE Lite，適用於低算力加速器。",
  "ERNIE-Speed-128K.description": "百度最新高效能大模型（2024），具備強大通用能力，適合作為微調基礎模型，推理表現優異。",
  "ERNIE-Speed-Pro-128K.description": "百度最新高效能大模型（2024），具備強大通用能力，優於 ERNIE Speed，適合作為微調基礎模型，推理表現優異。",
  "FLUX-1.1-pro.description": "FLUX.1.1 Pro",
  "FLUX.1-Kontext-dev.description": "FLUX.1-Kontext-dev 是來自 Black Forest Labs 的多模態圖像生成與編輯模型，基於 Rectified Flow Transformer 架構，擁有 120 億參數。該模型專注於在特定語境條件下生成、重建、增強或編輯圖像。它結合了擴散模型的可控生成能力與 Transformer 的語境建模能力，支援高品質的圖像修補、擴圖與視覺場景重建等任務。",
  "FLUX.1-Kontext-pro.description": "FLUX.1 Kontext [專業版]",
  "FLUX.1-dev.description": "FLUX.1-dev 是來自 Black Forest Labs 的開源多模態語言模型（MLLM），針對圖文任務進行優化，結合圖像與文字的理解與生成能力。該模型基於先進的大型語言模型（如 Mistral-7B），搭配精心設計的視覺編碼器與多階段指令微調，實現多模態協同與複雜任務推理。",
  "Gryphe/MythoMax-L2-13b.description": "MythoMax-L2（13B）是一款創新模型，適用於多領域與複雜任務。",
  "HelloMeme.description": "HelloMeme 是一款 AI 工具，可根據您提供的圖像或動作生成迷因、GIF 或短影片。無需繪圖或程式設計技能，只需一張參考圖像，即可創作出有趣、吸睛且風格一致的內容。",
  "HiDream-I1-Full.description": "HiDream-E1-Full 是來自 HiDream.ai 的開源多模態圖像編輯模型，基於先進的 Diffusion Transformer 架構與強大的語言理解能力（內建 LLaMA 3.1-8B-Instruct）。支援自然語言驅動的圖像生成、風格轉換、局部編輯與重繪，具備優異的圖文理解與執行能力。",
  "HunyuanDiT-v1.2-Diffusers-Distilled.description": "hunyuandit-v1.2-distilled 是一款經過蒸餾優化的輕量級文字轉圖像模型，可快速生成高品質圖像，特別適合資源有限的環境與即時生成場景。",
  "InstantCharacter.description": "InstantCharacter 是騰訊 AI 於 2025 年推出的免微調個人化角色生成模型，致力於高保真、跨場景一致的角色建模。它可從單張參考圖像建構角色，並靈活轉換風格、動作與背景。",
  "InternVL2-8B.description": "InternVL2-8B 是一款強大的視覺語言模型，支援多模態圖文處理，能準確識別圖像內容並生成相關描述或回答。",
  "InternVL2.5-26B.description": "InternVL2.5-26B 是一款強大的視覺語言模型，支援多模態圖文處理，能準確識別圖像內容並生成相關描述或回答。",
  "Kolors.description": "Kolors 是由快手 Kolors 團隊開發的文字轉圖像模型。該模型擁有數十億參數，在視覺品質、中文語義理解與文字渲染方面具有顯著優勢。",
  "Kwai-Kolors/Kolors.description": "Kolors 是快手 Kolors 團隊推出的大型潛變分布式文字轉圖像模型。訓練資料涵蓋數十億組圖文對，在視覺品質、複雜語義準確性與中英文文字渲染方面表現出色，具備強大的中文內容理解與生成能力。",
  "Kwaipilot/KAT-Dev.description": "KAT-Dev（32B）是開源的 32B 軟體工程任務模型，在 SWE-Bench Verified 測試中達到 62.4% 解題率，於開源模型中排名第五。透過中期訓練、SFT 與強化學習優化，支援程式補全、錯誤修復與程式碼審查。",
  "Llama-3.2-11B-Vision-Instruct.description": "具備高解析度圖像的強大圖像推理能力，適用於視覺理解應用。",
  "Llama-3.2-90B-Vision-Instruct\t.description": "先進的圖像推理能力，適用於視覺理解代理應用。",
  "Meta-Llama-3-3-70B-Instruct.description": "Llama 3.3 70B 是一款多功能 Transformer 模型，適用於對話與生成任務。",
  "Meta-Llama-3.1-405B-Instruct.description": "Llama 3.1 是針對多語言對話優化的指令微調文字模型，在開源與封閉聊天模型中於多項業界基準測試中表現優異。",
  "Meta-Llama-3.1-70B-Instruct.description": "Llama 3.1 是針對多語言對話優化的指令微調文字模型，在開源與封閉聊天模型中於多項業界基準測試中表現優異。",
  "Meta-Llama-3.1-8B-Instruct.description": "Llama 3.1 是針對多語言對話優化的指令微調文字模型，在開源與封閉聊天模型中於多項業界基準測試中表現優異。",
  "Meta-Llama-3.2-1B-Instruct.description": "前沿的小型語言模型，具備強大的語言理解、優異的推理與文字生成能力。",
  "Meta-Llama-3.2-3B-Instruct.description": "前沿的小型語言模型，具備強大的語言理解、優異的推理與文字生成能力。",
  "Meta-Llama-3.3-70B-Instruct.description": "Llama 3.3 是最先進的多語言開源 Llama 模型，以極低成本實現接近 405B 的效能。基於 Transformer 架構，並透過 SFT 與 RLHF 提升實用性與安全性。指令微調版本針對多語言對話進行優化，在多項業界基準測試中超越許多開源與封閉聊天模型。知識截止時間：2023 年 12 月。",
  "Meta-Llama-4-Maverick-17B-128E-Instruct-FP8.description": "Llama 4 Maverick 是一款大型 MoE 模型，具備高效專家啟用機制，展現強大的推理效能。",
  "MiniMax-M1.description": "一款內部開發的推理模型，具備 80K 思路鏈與 100 萬輸入，效能媲美全球頂尖模型。",
  "MiniMax-M2-Stable.description": "專為高效編碼與代理流程設計，具備更高併發能力，適用於商業應用。",
  "MiniMax-M2.1-Lightning.description": "強大的多語言編程能力，全面升級的編程體驗。更快速、更高效。",
  "MiniMax-M2.1.description": "MiniMax-M2.1 是 MiniMax 推出的旗艦開源大型模型，專注於解決複雜的真實世界任務。其核心優勢在於多語言程式設計能力與作為智能代理執行複雜任務的能力。",
  "MiniMax-M2.description": "專為高效編碼與智能體工作流程打造",
  "MiniMax-Text-01.description": "MiniMax-01 採用超越傳統 Transformer 的大規模線性注意力機制，擁有 4560 億參數，每次啟用 459 億，支援最多 400 萬字元上下文（為 GPT-4o 的 32 倍，Claude-3.5-Sonnet 的 20 倍），效能頂尖。",
  "MiniMaxAI/MiniMax-M1-80k.description": "MiniMax-M1 是一款開源權重的大型混合注意力推理模型，總參數 4560 億，每個 token 啟用約 459 億。原生支援 100 萬上下文，使用 Flash Attention 技術，在 10 萬 token 生成任務中比 DeepSeek R1 減少 75% FLOPs。採用 MoE 架構、CISPO 與混合注意力強化學習訓練，在長輸入推理與真實軟體工程任務中表現領先。",
  "MiniMaxAI/MiniMax-M2.description": "MiniMax-M2 重新定義代理效率。這是一款緊湊、快速、具成本效益的 MoE 模型，總參數 2300 億，啟用參數僅 100 億，專為頂級編碼與代理任務設計，同時保有強大的通用智能。即使僅啟用 100 億參數，其效能仍可媲美更大型模型，適合高效率應用場景。",
  "Moonshot-Kimi-K2-Instruct.description": "總參數 1 兆，啟用 320 億。在非思考模型中於前沿知識、數學與編碼方面表現頂尖，並在通用代理任務中更為強大。針對代理工作負載進行優化，具備行動能力而非僅能回答問題。作為一款反射級模型，特別適合即興對話、通用聊天與代理體驗。",
  "NousResearch/Nous-Hermes-2-Mixtral-8x7B-DPO.description": "Nous Hermes 2 - Mixtral 8x7B-DPO（46.7B）是一款高精度指令模型，適用於複雜計算任務。",
  "OmniConsistency.description": "OmniConsistency 透過引入大規模的擴散式 Transformer（DiTs）與配對風格化資料，提升圖像轉圖像任務中的風格一致性與泛化能力，避免風格退化問題。",
  "PaddlePaddle/PaddleOCR-VL-1.5.description": "PaddleOCR-VL-1.5 是 PaddleOCR-VL 系列的升級版本，在 OmniDocBench v1.5 文件解析基準測試中達到 94.5% 的準確率，超越主流通用大型模型與專業文件解析模型。創新地支援文件元素的不規則邊界框定位，能有效處理掃描、傾斜與螢幕截圖等圖像。",
  "Phi-3-medium-128k-instruct.description": "與 Phi-3-medium 相同的模型，具備更大的上下文視窗，適用於 RAG 或少量示例提示。",
  "Phi-3-medium-4k-instruct.description": "一個擁有 140 億參數的模型，品質優於 Phi-3-mini，專注於高品質、需推理的資料。",
  "Phi-3-mini-128k-instruct.description": "與 Phi-3-mini 相同的模型，具備更大的上下文視窗，適用於 RAG 或少量示例提示。",
  "Phi-3-mini-4k-instruct.description": "Phi-3 系列中最小的成員，針對品質與低延遲進行最佳化。",
  "Phi-3-small-128k-instruct.description": "與 Phi-3-small 相同的模型，具備更大的上下文視窗，適用於 RAG 或少量示例提示。",
  "Phi-3-small-8k-instruct.description": "一個擁有 70 億參數的模型，品質優於 Phi-3-mini，專注於高品質、需推理的資料。",
  "Phi-3.5-mini-instruct.description": "Phi-3-mini 模型的更新版本。",
  "Phi-3.5-vision-instrust.description": "Phi-3-vision 模型的更新版本。",
  "Pro/MiniMaxAI/MiniMax-M2.1.description": "MiniMax-M2.1 是一款開源的大型語言模型，專為代理能力進行優化，擅長程式設計、工具使用、指令遵循與長期規劃。該模型支援多語言軟體開發與複雜的多步驟工作流程執行，在 SWE-bench Verified 測試中獲得 74.0 分，並在多語言場景中超越 Claude Sonnet 4.5。",
  "Pro/Qwen/Qwen2-7B-Instruct.description": "Qwen2-7B-Instruct 是 Qwen2 系列中的一款 70 億參數指令微調大型語言模型。它採用 Transformer 架構，結合 SwiGLU、注意力 QKV 偏置與分組查詢注意力機制，能處理大規模輸入內容。該模型在語言理解、生成、多語言任務、程式碼、數學與推理等方面表現優異，超越多數開源模型，並可與商業模型競爭。在多項基準測試中表現優於 Qwen1.5-7B-Chat。",
  "Pro/Qwen/Qwen2.5-7B-Instruct.description": "Qwen2.5-7B-Instruct 是阿里雲最新大型語言模型系列的一部分。此 70 億參數模型在程式碼與數學方面有顯著提升，支援超過 29 種語言，並加強了指令遵循、結構化資料理解與結構化輸出（特別是 JSON）能力。",
  "Pro/Qwen/Qwen2.5-Coder-7B-Instruct.description": "Qwen2.5-Coder-7B-Instruct 是阿里雲最新專注於程式碼的語言模型。基於 Qwen2.5 架構並訓練於 5.5 兆詞元上，顯著提升了程式碼生成、推理與修復能力，同時保有數學與通用能力，為開發智能程式代理提供堅實基礎。",
  "Pro/Qwen/Qwen2.5-VL-7B-Instruct.description": "Qwen2.5-VL 是 Qwen 團隊推出的新一代視覺語言模型，具備強大的視覺理解能力。它能分析圖像中的文字、圖表與版面配置，理解長影片與事件，支援推理與工具使用、多格式物件定位與結構化輸出。透過動態解析度與影格率訓練，提升了影片理解能力，並強化視覺編碼器效率。",
  "Pro/THUDM/GLM-4.1V-9B-Thinking.description": "GLM-4.1V-9B-Thinking 是由智譜 AI 與清華大學知識工程實驗室共同開源的視覺語言模型，專為複雜多模態認知設計。基於 GLM-4-9B-0414 架構，加入了思維鏈推理與強化學習，顯著提升跨模態推理能力與穩定性。",
  "Pro/THUDM/glm-4-9b-chat.description": "GLM-4-9B-Chat 是智譜 AI 開源的 GLM-4 模型，於語意、數學、推理、程式碼與知識等方面表現出色。除多輪對話外，還支援網頁瀏覽、程式執行、自定義工具調用與長文本推理。支援 26 種語言（包括中文、英文、日文、韓文、德文），在 AlignBench-v2、MT-Bench、MMLU 與 C-Eval 等基準測試中表現優異，並支援最多 128K 上下文，適用於學術與商業場景。",
  "Pro/deepseek-ai/DeepSeek-R1-Distill-Qwen-7B.description": "DeepSeek-R1-Distill-Qwen-7B 是從 Qwen2.5-Math-7B 蒸餾而來，並在 80 萬條精選 DeepSeek-R1 數據上微調。其表現優異，在 MATH-500 上達到 92.8%、AIME 2024 為 55.5%，CodeForces 評分為 1189，為 7B 模型中的佼佼者。",
  "Pro/deepseek-ai/DeepSeek-R1.description": "DeepSeek-R1 是一款以強化學習驅動的推理模型，能減少重複並提升可讀性。透過在強化學習前使用冷啟動資料，進一步增強推理能力，在數學、程式與推理任務上與 OpenAI-o1 表現相當，並透過精心訓練提升整體表現。",
  "Pro/deepseek-ai/DeepSeek-V3.1-Terminus.description": "DeepSeek-V3.1-Terminus 是 V3.1 版本的更新模型，定位為混合代理型大型語言模型。修復了用戶回報的問題，提升穩定性與語言一致性，減少中英混雜與異常字符。整合思考與非思考模式，並提供聊天模板以靈活切換。強化了程式代理與搜尋代理的表現，提升工具使用與多步任務的可靠性。",
  "Pro/deepseek-ai/DeepSeek-V3.2-Exp.description": "DeepSeek-V3.2-Exp 是 V3.2 的實驗版本，為下一代架構鋪路。在 V3.1-Terminus 基礎上加入 DeepSeek 稀疏注意力（DSA），提升長上下文訓練與推理效率，並針對工具使用、長文檔理解與多步推理進行優化。非常適合探索在大上下文預算下的高效推理能力。",
  "Pro/deepseek-ai/DeepSeek-V3.description": "DeepSeek-V3 是一款擁有 6710 億參數的 MoE 模型，採用 MLA 與 DeepSeekMoE 架構，並透過無損負載平衡實現高效推理與訓練。預訓練於 14.8 兆高品質詞元上，並經過 SFT 與強化學習微調，表現超越其他開源模型，接近領先的封閉模型。",
  "Pro/moonshotai/Kimi-K2-Instruct-0905.description": "Kimi K2-Instruct-0905 是最新且最強大的 Kimi K2 模型。這是一款頂級的 MoE 模型，總參數達 1 兆，啟用參數為 320 億。其主要特點包括更強的代理式程式設計智能，在基準測試與真實世界代理任務中表現大幅提升，並且前端程式碼的美學與可用性也獲得顯著改善。",
  "Pro/moonshotai/Kimi-K2-Thinking.description": "Kimi K2 Thinking Turbo 是 K2 Thinking 的 Turbo 變體，針對推理速度與吞吐量進行優化，同時保留多步推理與工具使用能力。這是一款 MoE 模型，總參數約為 1 兆，原生支援 256K 上下文，並具備穩定的大規模工具調用能力，適用於對延遲與併發有嚴格要求的生產場景。",
  "Pro/moonshotai/Kimi-K2.5.description": "Kimi K2.5 是一款原生開源多模態代理模型，基於 Kimi-K2-Base 架構，訓練資料包含約 1.5 兆視覺與文字混合標記。模型採用 MoE 架構，總參數量達 1 兆，啟用參數為 320 億，支援 256K 上下文視窗，實現視覺與語言理解的無縫整合。",
  "Pro/zai-org/glm-4.7.description": "GLM-4.7 是智譜推出的新一代旗艦模型，擁有 3550 億總參數與 320 億活躍參數，在通用對話、推理與智能體能力方面全面升級。GLM-4.7 強化了交錯思維，並引入了保留思維與輪次級思維。",
  "QwQ-32B-Preview.description": "Qwen QwQ 是一個實驗性研究模型，專注於提升推理能力。",
  "Qwen/QVQ-72B-Preview.description": "QVQ-72B-Preview 是來自 Qwen 的研究模型，專注於視覺推理，擅長複雜場景理解與視覺數學問題。",
  "Qwen/QwQ-32B-Preview.description": "Qwen QwQ 是一個實驗性研究模型，致力於提升 AI 推理能力。",
  "Qwen/QwQ-32B.description": "QwQ 是 Qwen 系列中的推理模型。與標準的指令微調模型相比，它加入了思考與推理機制，顯著提升下游任務表現，特別是在困難問題上。QwQ-32B 是一款中型推理模型，具備與 DeepSeek-R1 和 o1-mini 等頂尖推理模型競爭的能力。其架構採用 RoPE、SwiGLU、RMSNorm 和注意力 QKV 偏置，擁有 64 層與 40 個 Q 注意力頭（GQA 中為 8 個 KV）。",
  "Qwen/Qwen-Image-Edit-2509.description": "Qwen-Image-Edit-2509 是 Qwen 團隊推出的最新圖像編輯版本。基於 20B 參數的 Qwen-Image 模型，該版本將強大的文字渲染能力擴展至圖像編輯，實現精準的文字修改。其採用雙重控制架構，將輸入分別送至 Qwen2.5-VL 進行語義控制，以及 VAE 編碼器進行外觀控制，實現語義與外觀層級的編輯。支援局部編輯（新增/刪除/修改）與高階語義編輯，如 IP 創作與風格轉換，同時保留語義一致性。該模型在多項基準測試中達到 SOTA 表現。",
  "Qwen/Qwen-Image.description": "Qwen-Image 是 Qwen 團隊推出的 20B 參數圖像生成基礎模型，在複雜文字渲染與精準圖像編輯方面取得重大突破，特別擅長中英文高保真文字處理。支援多行與段落排版，保持排版一致性。除文字渲染外，還支援從寫實風格到動漫風格的多樣圖像風格，以及進階編輯功能，如風格轉換、物件新增/刪除、細節增強、文字編輯與姿勢控制，致力於成為全面的視覺創作基礎模型。",
  "Qwen/Qwen2-72B-Instruct.description": "Qwen 2 Instruct（72B）針對企業級工作負載提供精準的指令遵循能力。",
  "Qwen/Qwen2-7B-Instruct.description": "Qwen2-7B-Instruct 是 Qwen2 系列中的 7B 指令微調模型，採用 Transformer、SwiGLU、QKV 偏置與分組查詢注意力架構。能處理大規模輸入，在理解、生成、多語言、程式碼、數學與推理基準測試中表現優異，超越多數開源模型，並在多項評估中勝過 Qwen1.5-7B-Chat。",
  "Qwen/Qwen2-VL-72B-Instruct.description": "Qwen2-VL 是最新的 Qwen-VL 模型，在 MathVista、DocVQA、RealWorldQA 與 MTVQA 等視覺基準測試中達到 SOTA 表現。可理解超過 20 分鐘的影片，支援影片問答、對話與內容創作。具備複雜推理與決策能力，能與裝置/機器人整合進行視覺驅動操作。除中英文外，還能辨識多種語言文字，包括大多數歐洲語言、日語、韓語、阿拉伯語與越南語。",
  "Qwen/Qwen2.5-14B-Instruct.description": "Qwen2.5-14B-Instruct 是阿里雲最新 LLM 系列的一部分。此 14B 模型在程式碼與數學方面有顯著提升，支援超過 29 種語言，並強化指令遵循、結構化資料理解與結構化輸出（特別是 JSON）。",
  "Qwen/Qwen2.5-32B-Instruct.description": "Qwen2.5-32B-Instruct 是阿里雲最新 LLM 系列的一部分。此 32B 模型在程式碼與數學方面有顯著提升，支援超過 29 種語言，並強化指令遵循、結構化資料理解與結構化輸出（特別是 JSON）。",
  "Qwen/Qwen2.5-72B-Instruct-128K.description": "Qwen2.5-72B-Instruct 是阿里雲最新 LLM 系列的一部分。此 72B 模型提升了程式碼與數學能力，支援最多 128K 輸入與超過 8K 輸出，涵蓋 29+ 種語言，並強化指令遵循與結構化輸出（特別是 JSON）。",
  "Qwen/Qwen2.5-72B-Instruct-Turbo.description": "Qwen2.5 是一個針對指令型任務優化的新 LLM 系列。",
  "Qwen/Qwen2.5-72B-Instruct.description": "Qwen2.5-72B-Instruct 是阿里雲最新 LLM 系列的一部分。此 72B 模型在程式碼與數學方面有顯著提升，支援超過 29 種語言，並強化指令遵循、結構化資料理解與結構化輸出（特別是 JSON）。",
  "Qwen/Qwen2.5-7B-Instruct-Turbo.description": "Qwen2.5 是一個針對指令型任務優化的新 LLM 系列。",
  "Qwen/Qwen2.5-7B-Instruct.description": "Qwen2.5-7B-Instruct 是阿里雲最新 LLM 系列的一部分。此 7B 模型在程式碼與數學方面有顯著提升，支援超過 29 種語言，並強化指令遵循、結構化資料理解與結構化輸出（特別是 JSON）。",
  "Qwen/Qwen2.5-Coder-32B-Instruct.description": "Qwen2.5 Coder 32B Instruct 是阿里雲最新專注於程式碼的 LLM。基於 Qwen2.5 並使用 5.5T token 訓練，顯著提升程式碼生成、推理與修復能力，同時保有數學與通用能力，為程式代理提供強大基礎。",
  "Qwen/Qwen2.5-Coder-7B-Instruct.description": "Qwen2.5-Coder-7B-Instruct 是阿里雲最新專注於程式碼的 LLM。基於 Qwen2.5 並使用 5.5T token 訓練，顯著提升程式碼生成、推理與修復能力，同時保有數學與通用能力，為程式代理提供穩固基礎。",
  "Qwen/Qwen2.5-VL-32B-Instruct.description": "Qwen2.5-VL-32B-Instruct 是 Qwen 團隊推出的多模態模型。能辨識常見物體並分析文字、圖表、圖示、圖形與版面配置。作為視覺代理，可進行推理並動態控制工具，包括電腦與手機操作。能精準定位物體並為發票與表格生成結構化輸出。相較於 Qwen2-VL，強化了數學與問題解決能力，回應更符合人類偏好。",
  "Qwen/Qwen2.5-VL-72B-Instruct.description": "Qwen2.5-VL 是 Qwen2.5 系列中的視覺語言模型，進行重大升級：加強物體、文字、圖表與版面配置的視覺理解；作為視覺代理進行動態工具使用；理解超過 1 小時的影片並捕捉關鍵事件；透過框選或點選精準定位物體；為掃描資料如發票與表格生成結構化輸出。",
  "Qwen/Qwen3-14B.description": "Qwen3 是新一代通義千問模型，在推理、通用能力、代理能力與多語言表現方面取得重大突破，並支援思維模式切換。",
  "Qwen/Qwen3-235B-A22B-Instruct-2507.description": "Qwen3-235B-A22B-Instruct-2507 是 Qwen3 MoE 系列的旗艦模型，總參數量為 235B，啟用參數為 22B。此版本為更新後的非思考模式，專注於提升指令遵循、邏輯推理、文本理解、數學、科學、程式編寫與工具使用能力。它亦擴展了多語言長尾知識，並更好地對齊使用者在主觀開放任務上的偏好。",
  "Qwen/Qwen3-235B-A22B-Thinking-2507.description": "Qwen3-235B-A22B-Thinking-2507 是 Qwen3 系列中專注於高難度複雜推理的模型。採用 MoE 架構，總參數為 235B，每個 token 啟用約 22B 參數以提升效率。作為專用思考模型，在邏輯、數學、科學、程式編寫與學術基準測試中表現卓越，達到頂尖開放式思考水準。它同時提升了指令遵循、工具使用與文本生成能力，並原生支援 256K 上下文長度，適用於深度推理與長文處理。",
  "Qwen/Qwen3-235B-A22B.description": "Qwen3 是新一代通義千問模型，在推理能力、通用能力、智能體能力與多語言表現方面有重大突破，並支援思考模式切換。",
  "Qwen/Qwen3-30B-A3B-Instruct-2507.description": "Qwen3-30B-A3B-Instruct-2507 是 Qwen3-30B-A3B 的更新版非思考模型。採用 MoE 架構，總參數為 30.5B，啟用參數為 3.3B。顯著提升了指令遵循、邏輯推理、文本理解、數學、科學、程式編寫與工具使用能力，擴展多語言長尾知識，並更好地對齊使用者在主觀開放任務上的偏好。支援 256K 上下文長度。此模型僅支援非思考模式，不會輸出 `<think></think>` 標籤。",
  "Qwen/Qwen3-30B-A3B-Thinking-2507.description": "Qwen3-30B-A3B-Thinking-2507 是 Qwen3 系列中最新的思考模型。採用 MoE 架構，總參數為 30.5B，啟用參數為 3.3B，專注於處理複雜任務。在邏輯、數學、科學、程式編寫與學術基準測試中表現顯著提升，並改善了指令遵循、工具使用、文本生成與偏好對齊能力。原生支援 256K 上下文，並可擴展至 1M token。此版本設計為思考模式，具備詳細的逐步推理與強大的智能體能力。",
  "Qwen/Qwen3-30B-A3B.description": "Qwen3 是新一代通義千問模型，在推理能力、通用能力、智能體能力與多語言表現方面有重大突破，並支援思考模式切換。",
  "Qwen/Qwen3-32B.description": "Qwen3 是新一代通義千問模型，在推理能力、通用能力、智能體能力與多語言表現方面有重大突破，並支援思考模式切換。",
  "Qwen/Qwen3-8B.description": "Qwen3 是新一代通義千問模型，在推理能力、通用能力、智能體能力與多語言表現方面有重大突破，並支援思考模式切換。",
  "Qwen/Qwen3-Coder-30B-A3B-Instruct.description": "Qwen3-Coder-30B-A3B-Instruct 是 Qwen 團隊推出的 Qwen3 程式模型。此模型在提升程式能力的同時，兼顧高效能與運行效率。其在智能體程式編寫、自動化瀏覽器操作與工具使用方面，在開源模型中表現出色。原生支援 256K 上下文，並可擴展至 1M token，適用於程式庫層級理解。支援 Qwen Code 與 CLINE 等平台上的智能體程式編寫，並採用專用函式呼叫格式。",
  "Qwen/Qwen3-Coder-480B-A35B-Instruct.description": "Qwen3-Coder-480B-A35B-Instruct 是阿里巴巴目前最具智能體能力的程式模型。採用 MoE 架構，總參數為 480B，啟用參數為 35B，兼顧效能與效率。原生支援 256K 上下文，並可透過 YaRN 擴展至 1M token，能處理大型程式碼庫。專為智能體程式編寫流程設計，能與工具與環境互動以解決複雜程式任務。在程式與智能體基準測試中達到開源模型頂尖水準，媲美 Claude Sonnet 4。",
  "Qwen/Qwen3-Next-80B-A3B-Instruct.description": "Qwen3-Next-80B-A3B-Instruct 是採用 Qwen3-Next 架構的新一代基礎模型，具備極致的訓練與推理效率。結合混合注意力機制（Gated DeltaNet + Gated Attention）、高度稀疏的 MoE 架構與訓練穩定性優化。雖總參數為 80B，但推理時僅啟用約 3B 參數，計算成本大幅降低，並在超過 32K 上下文下達到 Qwen3-32B 的 10 倍以上吞吐量。此指令微調版本針對通用任務（不支援思考模式），在部分基準測試中表現可與 Qwen3-235B 相媲美，並在超長上下文任務中展現強大優勢。",
  "Qwen/Qwen3-Next-80B-A3B-Thinking.description": "Qwen3-Next-80B-A3B-Thinking 是專為複雜推理設計的新一代基礎模型。採用 Qwen3-Next 架構，結合混合注意力（Gated DeltaNet + Gated Attention）與高度稀疏的 MoE 架構，實現極致的訓練與推理效率。雖總參數為 80B，但推理時僅啟用約 3B 參數，計算成本大幅降低，並在超過 32K 上下文下達到 Qwen3-32B 的 10 倍以上吞吐量。此思考版本針對多步驟任務，如證明、程式合成、邏輯分析與規劃，輸出結構化的思考鏈。其表現超越 Qwen3-32B-Thinking，並在多項基準測試中勝過 Gemini-2.5-Flash-Thinking。",
  "Qwen/Qwen3-Omni-30B-A3B-Captioner.description": "Qwen3-Omni-30B-A3B-Captioner 是 Qwen3 系列的視覺語言模型（VLM），專為高品質、細緻且準確的圖像描述而設計。採用 30B 參數的 MoE 架構，能深入理解圖像並生成流暢描述，擅長細節捕捉、場景理解、物體辨識與關係推理。",
  "Qwen/Qwen3-Omni-30B-A3B-Instruct.description": "Qwen3-Omni-30B-A3B-Instruct 是 Qwen3 系列的 MoE 模型，總參數為 30B，啟用參數為 3B，具備高效能與低推理成本。訓練於高品質多來源多語言資料，支援全模態輸入（文字、圖像、音訊、影片）與跨模態理解與生成。",
  "Qwen/Qwen3-Omni-30B-A3B-Thinking.description": "Qwen3-Omni-30B-A3B-Thinking 是 Qwen3-Omni 的核心「思考者」組件。可處理多模態輸入（文字、音訊、圖像、影片），並執行複雜的思考鏈推理，將輸入統一為共享表示以實現深度跨模態理解。採用 MoE 架構，總參數為 30B，啟用參數為 3B，兼顧強大推理能力與運算效率。",
  "Qwen/Qwen3-VL-235B-A22B-Instruct.description": "Qwen3-VL-235B-A22B-Instruct 是基於 MoE 架構的大型指令微調視覺語言模型，具備卓越的多模態理解與生成能力。原生支援 256K 上下文，適用於高併發生產級多模態服務。",
  "Qwen/Qwen3-VL-235B-A22B-Thinking.description": "Qwen3-VL-235B-A22B-Thinking 是 Qwen3-VL 的旗艦思考版本，針對複雜多模態推理、長上下文推理與企業場景中的智能體互動進行優化。",
  "Qwen/Qwen3-VL-30B-A3B-Instruct.description": "Qwen3-VL-30B-A3B-Instruct 是指令微調的 Qwen3-VL 模型，具備強大的視覺語言理解與生成能力。原生支援 256K 上下文，適用於多模態對話與圖像條件生成。",
  "Qwen/Qwen3-VL-30B-A3B-Thinking.description": "Qwen3-VL-30B-A3B-Thinking 是 Qwen3-VL 的推理增強版本，針對多模態推理、圖像轉程式碼與複雜視覺理解進行優化。支援 256K 上下文，具備更強的思考鏈能力。",
  "Qwen/Qwen3-VL-32B-Instruct.description": "Qwen3-VL-32B-Instruct 是 Qwen 團隊推出的視覺語言模型，在多項 VL 基準測試中取得領先成績。支援百萬像素解析度圖像，具備強大的視覺理解、多語言 OCR、細粒度視覺定位與視覺對話能力。可處理複雜多模態任務，並支援工具呼叫與前綴補全。",
  "Qwen/Qwen3-VL-32B-Thinking.description": "Qwen3-VL-32B-Thinking 專為複雜視覺推理優化。內建思考模式，在回答前生成中間推理步驟，提升多步邏輯、規劃與複雜推理能力。支援百萬像素圖像、強視覺理解、多語言 OCR、細粒度定位、視覺對話、工具呼叫與前綴補全。",
  "Qwen/Qwen3-VL-8B-Instruct.description": "Qwen3-VL-8B-Instruct 是基於 Qwen3-8B-Instruct 的視覺語言模型，訓練於大量圖文資料。擅長通用視覺理解、以視覺為中心的對話與圖像中的多語言文字辨識，適用於視覺問答、圖說、多模態指令遵循與工具使用。",
  "Qwen/Qwen3-VL-8B-Thinking.description": "Qwen3-VL-8B-Thinking 是 Qwen3 的視覺思考版本，針對複雜多步推理進行優化。在回答前生成思考鏈以提升準確性，適用於深度視覺問答與細緻圖像分析。",
  "Qwen2-72B-Instruct.description": "Qwen2 是最新的 Qwen 系列，支援 128K 上下文視窗。與當前最佳開源模型相比，Qwen2-72B 在自然語言理解、知識、程式碼、數學與多語言能力方面顯著超越主流模型。",
  "Qwen2-7B-Instruct.description": "Qwen2 是最新的 Qwen 系列，在同級與更大模型中表現優異。Qwen2 7B 在多項基準測試中展現顯著優勢，特別是在程式碼與中文理解方面。",
  "Qwen2-VL-72B.description": "Qwen2-VL-72B 是一款強大的視覺語言模型，支援多模態圖文處理，能準確識別圖像內容並生成相關描述或答案。",
  "Qwen2.5-14B-Instruct.description": "Qwen2.5-14B-Instruct 是一款擁有 14B 參數的大型語言模型，針對中文與多語言場景進行優化，支援智慧問答與內容生成。",
  "Qwen2.5-32B-Instruct.description": "Qwen2.5-32B-Instruct 是一款擁有 32B 參數的語言模型，具備平衡的效能，針對中文與多語言場景進行優化，支援智慧問答與內容生成。",
  "Qwen2.5-72B-Instruct.description": "支援中英文的語言模型，針對語言、程式碼、數學與推理進行微調。",
  "Qwen2.5-7B-Instruct.description": "Qwen2.5-7B-Instruct 是一款擁有 7B 參數的語言模型，支援函式呼叫與無縫整合外部系統，大幅提升靈活性與擴展性。針對中文與多語言場景進行優化，支援智慧問答與內容生成。",
  "Qwen2.5-Coder-14B-Instruct.description": "Qwen2.5-Coder-14B-Instruct 是一款大型預訓練程式指令模型，具備強大的程式理解與生成能力。能高效處理各類程式任務，適用於智慧編碼、自動腳本生成與程式問答。",
  "Qwen2.5-Coder-32B-Instruct.description": "進階語言模型，支援多種程式語言的程式碼生成、推理與錯誤修復。",
  "Qwen3-235B-A22B-Instruct-2507-FP8.description": "Qwen3 235B A22B Instruct 2507 針對高階推理與指令遵循進行最佳化，採用 MoE 架構以在大規模下保持推理效率。",
  "Qwen3-235B.description": "Qwen3-235B-A22B 是一款 MoE 模型，導入混合推理模式，讓使用者能在思考與非思考之間無縫切換。它支援 119 種語言與方言的理解與推理，具備強大的工具調用能力，在通用能力、程式碼與數學、多語言能力與知識推理等基準測試中，與 DeepSeek R1、OpenAI o1、o3-mini、Grok 3 和 Google Gemini 2.5 Pro 等主流模型競爭。",
  "Qwen3-32B.description": "Qwen3-32B 是一款密集模型，導入混合推理模式，讓使用者能在思考與非思考之間切換。透過架構改進、更多資料與更佳訓練，其表現與 Qwen2.5-72B 相當。",
  "SenseChat-128K.description": "Base V4，支援 128K 上下文，擅長長文本理解與生成。",
  "SenseChat-32K.description": "Base V4，支援 32K 上下文，靈活應用於多種場景。",
  "SenseChat-5-1202.description": "基於 V5.5 的最新版本，在中英文基礎能力、對話、STEM 知識、人文知識、寫作、數學/邏輯與長度控制方面有顯著提升。",
  "SenseChat-5-Cantonese.description": "專為香港對話習慣、俚語與在地知識設計；在粵語理解上超越 GPT-4，並在知識、推理、數學與程式碼方面可與 GPT-4 Turbo 匹敵。",
  "SenseChat-5-beta.description": "部分性能超越 SenseChat-5-1202。",
  "SenseChat-5.description": "最新 V5.5 版本，支援 128K 上下文；在數學推理、英文對話、指令遵循與長文本理解方面有重大提升，表現可比擬 GPT-4o。",
  "SenseChat-Character-Pro.description": "進階角色對話模型，支援 32K 上下文，能力提升，支援中英文。",
  "SenseChat-Character.description": "標準角色對話模型，支援 8K 上下文，回應速度快。",
  "SenseChat-Turbo-1202.description": "最新輕量模型，在大幅降低推理成本的同時達到 90% 以上的完整模型能力。",
  "SenseChat-Turbo.description": "適用於快速問答與模型微調場景。",
  "SenseChat-Vision.description": "最新 V5.5 版本，支援多圖輸入，在屬性辨識、空間關係、動作/事件偵測、場景理解、情緒辨識、常識推理與文字理解/生成等核心能力上全面提升。",
  "SenseChat.description": "Base V4，支援 4K 上下文，具備強大通用能力。",
  "SenseNova-V6-5-Pro.description": "透過多模態、語言與推理資料的全面升級及訓練策略優化，該模型大幅提升多模態推理與通用指令遵循能力，支援最高 128K 上下文，並在 OCR 與文化旅遊 IP 辨識任務中表現優異。",
  "SenseNova-V6-5-Turbo.description": "透過多模態、語言與推理資料的全面升級及訓練策略優化，該模型大幅提升多模態推理與通用指令遵循能力，支援最高 128K 上下文，並在 OCR 與文化旅遊 IP 辨識任務中表現優異。",
  "SenseNova-V6-Pro.description": "原生整合圖像、文字與影片，打破傳統多模態隔閡；在 OpenCompass 與 SuperCLUE 中名列前茅。",
  "SenseNova-V6-Reasoner.description": "結合視覺與語言的深度推理，支援慢思考與完整思路鏈。",
  "SenseNova-V6-Turbo.description": "原生整合圖像、文字與影片，打破傳統多模態隔閡。在多模態與語言核心能力上領先，於多項評測中名列前茅。",
  "Skylark2-lite-8k.description": "Skylark 第二代模型。Skylark2-lite 回應快速，適用於即時、成本敏感但精度要求較低的場景，支援 8K 上下文。",
  "Skylark2-pro-32k.description": "Skylark 第二代模型。Skylark2-pro 精度更高，適用於專業文案、小說創作與高品質翻譯等複雜文本生成任務，支援 32K 上下文。",
  "Skylark2-pro-4k.description": "Skylark 第二代模型。Skylark2-pro 精度更高，適用於專業文案、小說創作與高品質翻譯等複雜文本生成任務，支援 4K 上下文。",
  "Skylark2-pro-character-4k.description": "Skylark 第二代模型。Skylark2-pro-character 擅長角色扮演與對話，能根據提示展現鮮明人設風格與自然對話，適用於聊天機器人、虛擬助理與客服場景，回應快速。",
  "Skylark2-pro-turbo-8k.description": "Skylark 第二代模型。Skylark2-pro-turbo-8k 在 8K 上下文下提供更快推理與更低成本。",
  "THUDM/GLM-4-32B-0414.description": "GLM-4-32B-0414 是新一代開源 GLM 模型，擁有 32B 參數，性能可與 OpenAI GPT 與 DeepSeek V3/R1 系列媲美。",
  "THUDM/GLM-4-9B-0414.description": "GLM-4-9B-0414 是一款 9B 參數的 GLM 模型，繼承 GLM-4-32B 技術，部署更輕量。其在程式碼生成、網頁設計、SVG 生成與搜尋式寫作方面表現優異。",
  "THUDM/GLM-4.1V-9B-Thinking.description": "GLM-4.1V-9B-Thinking 是由智譜 AI 與清華 KEG 實驗室推出的開源視覺語言模型，專為複雜多模態認知設計。基於 GLM-4-9B-0414，加入思路鏈推理與強化學習，顯著提升跨模態推理與穩定性。",
  "THUDM/GLM-Z1-32B-0414.description": "GLM-Z1-32B-0414 是一款深度推理模型，基於 GLM-4-32B-0414，加入冷啟動資料與擴展強化學習，並在數學、程式碼與邏輯上進行進一步訓練，數學能力與複雜任務解決能力大幅提升。",
  "THUDM/GLM-Z1-9B-0414.description": "GLM-Z1-9B-0414 是一款小型 9B 參數的 GLM 模型，保留開源優勢並展現出色能力。在數學推理與通用任務上表現強勁，於同級開源模型中領先。",
  "THUDM/GLM-Z1-Rumination-32B-0414.description": "GLM-Z1-Rumination-32B-0414 是一款具備深度反思能力的推理模型（對標 OpenAI Deep Research）。與一般深思模型不同，它會花更多時間思考，以解決更開放與複雜的問題。",
  "THUDM/glm-4-9b-chat.description": "GLM-4-9B-Chat 是智譜 AI 推出的開源 GLM-4 模型，在語義、數學、推理、程式碼與知識方面表現強勁。除多輪對話外，還支援網頁瀏覽、程式碼執行、自定義工具調用與長文本推理。支援 26 種語言（含中、英、日、韓、德），在 AlignBench-v2、MT-Bench、MMLU 與 C-Eval 等評測中表現優異，並支援最高 128K 上下文，適用於學術與商業場景。",
  "Tongyi-Zhiwen/QwenLong-L1-32B.description": "QwenLong-L1-32B 是首款以強化學習訓練的長上下文推理模型（LRM），針對長文本推理進行最佳化。其漸進式上下文擴展強化學習策略，實現從短上下文到長上下文的穩定遷移。在七項長文檔問答基準上超越 OpenAI-o3-mini 與 Qwen3-235B-A22B，表現可與 Claude-3.7-Sonnet-Thinking 匹敵，特別擅長數學、邏輯與多跳推理。",
  "Yi-34B-Chat.description": "Yi-1.5-34B 延續該系列強大的通用語言能力，並透過對 5000 億高品質語料的增量訓練，顯著提升數學邏輯與程式碼能力。",
  "abab5.5-chat.description": "專為生產力場景打造，能處理複雜任務並高效生成專業文本。",
  "abab5.5s-chat.description": "專為中文人設對話設計，提供高品質中文對話體驗，適用於多種應用場景。",
  "abab6.5g-chat.description": "專為多語言人設對話設計，支援英文及其他語言的高品質對話生成。",
  "abab6.5s-chat.description": "適用於多種自然語言處理任務，包括文本生成與對話系統。",
  "abab6.5t-chat.description": "針對中文人設對話進行最佳化，提供符合中文表達習慣的流暢對話體驗。",
  "accounts/fireworks/models/deepseek-r1.description": "DeepSeek-R1 是一款先進的大型語言模型，透過強化學習與冷啟動資料進行最佳化，在推理、數學與程式碼方面表現卓越。",
  "accounts/fireworks/models/deepseek-v3.description": "DeepSeek 推出的強大 MoE 語言模型，總參數達 671B，每個 token 啟用 37B 參數。",
  "accounts/fireworks/models/llama-v3-70b-instruct.description": "Meta 開發並發布了 Meta Llama 3 大型語言模型系列，涵蓋 8B 和 70B 參數的預訓練與指令微調文字生成模型。Llama 3 的指令微調模型專為對話應用優化，在多項業界常用基準測試中表現優於許多現有的開源聊天模型。",
  "accounts/fireworks/models/llama-v3-8b-instruct-hf.description": "Meta Llama 3 的指令微調模型專為對話應用優化，在多項業界常用基準測試中表現優異。Llama 3 8B Instruct（HF 版本）是 Llama 3 8B Instruct 的原始 FP16 版本，預期結果與 Hugging Face 官方實作一致。",
  "accounts/fireworks/models/llama-v3-8b-instruct.description": "Meta 開發並發布了 Meta Llama 3 大型語言模型系列，涵蓋 8B 和 70B 參數的預訓練與指令微調文字生成模型。Llama 3 的指令微調模型專為對話應用優化，在多項業界常用基準測試中表現優於許多現有的開源聊天模型。",
  "accounts/fireworks/models/llama-v3p1-405b-instruct.description": "Meta Llama 3.1 是一個多語言大型語言模型系列，提供 8B、70B 和 405B 參數的預訓練與指令微調生成模型。這些指令微調模型針對多語言對話進行優化，在多項業界常用基準測試中表現優於許多開源與封閉聊天模型。405B 是 Llama 3.1 系列中最強大的模型，採用 FP8 推論，與參考實作高度一致。",
  "accounts/fireworks/models/llama-v3p1-70b-instruct.description": "Meta Llama 3.1 是一個多語言大型語言模型系列，提供 8B、70B 和 405B 參數的預訓練與指令微調生成模型。這些指令微調模型針對多語言對話進行優化，在多項業界常用基準測試中表現優於許多開源與封閉聊天模型。",
  "accounts/fireworks/models/llama-v3p1-8b-instruct.description": "Meta Llama 3.1 是一個多語言大型語言模型系列，提供 8B、70B 和 405B 參數的預訓練與指令微調生成模型。這些指令微調模型針對多語言對話進行優化，在多項業界常用基準測試中表現優於許多開源與封閉聊天模型。",
  "accounts/fireworks/models/llama-v3p2-11b-vision-instruct.description": "Meta 推出的 11B 參數視覺推理模型，經指令微調，專為視覺辨識、圖像推理、圖說生成與圖像相關問答優化。能理解圖表等視覺資料，並透過文字描述圖像細節，實現視覺與語言的橋接。",
  "accounts/fireworks/models/llama-v3p2-3b-instruct.description": "Llama 3.2 3B Instruct 是 Meta 推出的輕量級多語言模型，具備高效執行效能，延遲與成本明顯優於大型模型。典型應用包括查詢/提示重寫與寫作輔助。",
  "accounts/fireworks/models/llama-v3p2-90b-vision-instruct.description": "Meta 推出的 90B 參數視覺推理模型，經指令微調，專為視覺辨識、圖像推理、圖說生成與圖像相關問答優化。能理解圖表等視覺資料，並透過文字描述圖像細節，實現視覺與語言的橋接。注意：此模型目前以無伺服器方式實驗性提供，Fireworks 可能會在短時間內終止部署，請注意生產環境使用風險。",
  "accounts/fireworks/models/llama-v3p3-70b-instruct.description": "Llama 3.3 70B Instruct 是 Llama 3.1 70B 的 12 月更新版本，提升了工具使用、多語言文字支援、數學與程式能力，優於 2024 年 7 月版本。在推理、數學與指令遵循方面達到業界領先表現，效能接近 3.1 405B，但具備顯著的速度與成本優勢。",
  "accounts/fireworks/models/mistral-small-24b-instruct-2501.description": "一個具備 24B 參數的模型，擁有與更大型模型相當的先進能力。",
  "accounts/fireworks/models/mixtral-8x22b-instruct.description": "Mixtral MoE 8x22B Instruct v0.1 是 Mixtral MoE 8x22B v0.1 的指令微調版本，已啟用聊天補全 API。",
  "accounts/fireworks/models/mixtral-8x7b-instruct.description": "Mixtral MoE 8x7B Instruct 是 Mixtral MoE 8x7B 的指令微調版本，已啟用聊天補全 API。",
  "accounts/fireworks/models/mythomax-l2-13b.description": "MythoMix 的改良版本，可能是其更精緻的形式，融合 MythoLogic-L2 與 Huginn，採用高度實驗性的張量合併技術。其獨特特性使其非常適合用於故事創作與角色扮演。",
  "accounts/fireworks/models/phi-3-vision-128k-instruct.description": "Phi-3-Vision-128K-Instruct 是一款輕量級、先進的開源多模態模型，基於合成資料與精選公開網路資料集訓練，專注於高品質、推理密集的文字與視覺資料。屬於 Phi-3 系列，支援 128K 的上下文長度（以 token 計）。模型經過嚴格優化，包括監督式微調與偏好調整，確保精確的指令遵循與強化的安全性。",
  "accounts/fireworks/models/qwen-qwq-32b-preview.description": "Qwen QwQ 模型專注於推進 AI 推理能力，證明開源模型在推理方面可媲美封閉前沿模型。QwQ-32B-Preview 是一個實驗性版本，在 GPQA、AIME、MATH-500 與 LiveCodeBench 等推理與分析基準上，表現與 o1 相當，並超越 GPT-4o 與 Claude 3.5 Sonnet。注意：此模型目前以無伺服器方式實驗性提供，Fireworks 可能會在短時間內終止部署，請注意生產環境使用風險。",
  "accounts/fireworks/models/qwen2-vl-72b-instruct.description": "72B Qwen-VL 模型是阿里巴巴最新版本，展現近一年來的創新成果。",
  "accounts/fireworks/models/qwen2p5-72b-instruct.description": "Qwen2.5 是由 Qwen 團隊與阿里雲開發的僅解碼式大型語言模型系列，提供 0.5B、1.5B、3B、7B、14B、32B 與 72B 等多種規模，涵蓋基礎與指令微調版本。",
  "accounts/fireworks/models/qwen2p5-coder-32b-instruct.description": "Qwen2.5-Coder 是最新的 Qwen 程式語言模型（前身為 CodeQwen）。注意：此模型目前以無伺服器方式實驗性提供，Fireworks 可能會在短時間內終止部署，請注意生產環境使用風險。",
  "accounts/yi-01-ai/models/yi-large.description": "Yi-Large 是一款頂尖的大型語言模型，在 LMSYS 排行榜上僅次於 GPT-4、Gemini 1.5 Pro 與 Claude 3 Opus。其多語言能力出色，特別擅長西班牙語、中文、日語、德語與法語。Yi-Large 也對開發者友好，採用與 OpenAI 相同的 API 架構，便於整合。",
  "ai21-jamba-1.5-large.description": "一款具備 398B 參數（94B 啟用）的多語言模型，支援 256K 上下文視窗、函式呼叫、結構化輸出與基於事實的生成。",
  "ai21-jamba-1.5-mini.description": "一款具備 52B 參數（12B 啟用）的多語言模型，支援 256K 上下文視窗、函式呼叫、結構化輸出與基於事實的生成。",
  "ai21-labs/AI21-Jamba-1.5-Large.description": "一款具備 398B 參數（94B 啟用）的多語言模型，支援 256K 上下文視窗、函式呼叫、結構化輸出與基於事實的生成。",
  "ai21-labs/AI21-Jamba-1.5-Mini.description": "一款具備 52B 參數（12B 啟用）的多語言模型，支援 256K 上下文視窗、函式呼叫、結構化輸出與基於事實的生成。",
  "alibaba/qwen-3-14b.description": "Qwen3 是 Qwen 系列的最新一代，提供完整的密集與 MoE 模型組合。透過大規模訓練，在推理、指令遵循、代理能力與多語言支援方面實現突破。",
  "alibaba/qwen-3-235b.description": "Qwen3 是 Qwen 系列的最新一代，提供完整的密集與 MoE 模型組合。透過大規模訓練，在推理、指令遵循、代理能力與多語言支援方面實現突破。",
  "alibaba/qwen-3-30b.description": "Qwen3 是 Qwen 系列的最新一代，提供完整的密集與 MoE 模型組合。透過大規模訓練，在推理、指令遵循、代理能力與多語言支援方面實現突破。",
  "alibaba/qwen-3-32b.description": "Qwen3 是 Qwen 系列的最新一代，提供完整的密集與 MoE 模型組合。透過大規模訓練，在推理、指令遵循、代理能力與多語言支援方面實現突破。",
  "alibaba/qwen3-coder.description": "Qwen3-Coder-480B-A35B-Instruct 是 Qwen 最具代理能力的程式模型，在代理式編碼、瀏覽器操作及其他核心編碼任務上表現優異，達到與 Claude Sonnet 同級的成果。",
  "amazon/nova-lite.description": "一款極低成本的多模態模型，能以極快速度處理圖像、影片與文字輸入。",
  "amazon/nova-micro.description": "一款僅支援文字的模型，提供超低延遲與極低成本的運算效能。",
  "amazon/nova-pro.description": "一款功能強大的多模態模型，在準確性、速度與成本之間達到最佳平衡，適用於各類任務。",
  "amazon/titan-embed-text-v2.description": "Amazon Titan Text Embeddings V2 是一個輕量級、高效的多語言嵌入模型，支援 1024、512 和 256 維度。",
  "anthropic.claude-3-5-sonnet-20240620-v1:0.description": "Claude 3.5 Sonnet 提升了業界標準，在多項評估中超越競爭對手與 Claude 3 Opus，同時維持中階速度與成本。",
  "anthropic.claude-3-5-sonnet-20241022-v2:0.description": "Claude 3.5 Sonnet 提升了業界標準，在多項評估中超越競爭對手與 Claude 3 Opus，同時維持中階速度與成本。",
  "anthropic.claude-3-haiku-20240307-v1:0.description": "Claude 3 Haiku 是 Anthropic 速度最快、體積最小的模型，能即時回應簡單查詢，提供流暢自然的 AI 體驗，並支援圖像輸入與 200K 的上下文視窗。",
  "anthropic.claude-3-opus-20240229-v1:0.description": "Claude 3 Opus 是 Anthropic 最強大的 AI 模型，在處理高度複雜任務時展現最先進的效能，具備開放式提示與新穎情境的流暢應對能力，並支援圖像輸入與 200K 的上下文視窗。",
  "anthropic.claude-3-sonnet-20240229-v1:0.description": "Claude 3 Sonnet 在智慧與速度之間取得平衡，適用於企業級工作負載，提供高性價比與可靠的大規模部署能力，並支援圖像輸入與 200K 的上下文視窗。",
  "anthropic.claude-instant-v1.description": "一款快速、經濟且功能強大的模型，適用於日常對話、文字分析、摘要與文件問答。",
  "anthropic.claude-v2.description": "一款功能全面的模型，涵蓋複雜對話、創意生成與精確指令執行等任務。",
  "anthropic.claude-v2:1.description": "Claude 2 的升級版，具備雙倍上下文視窗，並在長文件與檢索增強生成（RAG）任務中提升可靠性、降低幻覺率與提升基於證據的準確性。",
  "anthropic/claude-3-haiku.description": "Claude 3 Haiku 是 Anthropic 速度最快的模型，專為處理長提示的企業級工作負載設計，能快速分析大型文件如季報、合約或法律案件，成本僅為同類模型的一半。",
  "anthropic/claude-3-opus.description": "Claude 3 Opus 是 Anthropic 最智慧的模型，在處理高度複雜任務時展現市場領先的效能，能流暢應對開放式提示與新穎情境，具備類人理解能力。",
  "anthropic/claude-3.5-haiku.description": "Claude 3.5 Haiku 提升了速度、程式碼準確性與工具使用能力，適用於對速度與工具互動有高要求的場景。",
  "anthropic/claude-3.5-sonnet.description": "Claude 3.5 Sonnet 是 Sonnet 系列中快速且高效的模型，具備更佳的程式與推理能力，部分版本已逐步由 Sonnet 3.7 或更新版本取代。",
  "anthropic/claude-3.7-sonnet.description": "Claude 3.7 Sonnet 是升級版的 Sonnet 模型，具備更強的推理與程式能力，適用於企業級複雜任務。",
  "anthropic/claude-haiku-4.5.description": "Claude Haiku 4.5 是 Anthropic 的高效能快速模型，在保持高準確度的同時提供極低延遲。",
  "anthropic/claude-opus-4.1.description": "Opus 4.1 是 Anthropic 的高階模型，針對程式設計、複雜推理與長時間任務進行最佳化。",
  "anthropic/claude-opus-4.5.description": "Claude Opus 4.5 是 Anthropic 的旗艦模型，結合頂尖智慧與可擴展效能，適用於複雜且高品質的推理任務。",
  "anthropic/claude-opus-4.description": "Opus 4 是 Anthropic 為複雜任務與企業應用設計的旗艦模型。",
  "anthropic/claude-sonnet-4.5.description": "Claude Sonnet 4.5 是 Anthropic 最新的混合推理模型，針對複雜推理與程式設計進行最佳化。",
  "anthropic/claude-sonnet-4.description": "Claude Sonnet 4 是 Anthropic 的混合推理模型，具備思考與非思考能力的結合。",
  "ascend-tribe/pangu-pro-moe.description": "Pangu-Pro-MoE 72B-A16B 是一個稀疏大型語言模型，總參數為 720 億，活躍參數為 160 億，採用分組專家模型（MoGE）架構。透過分組選擇專家並限制每組啟用相同數量的專家，以平衡負載並提升在昇騰平台上的部署效率。",
  "aya.description": "Aya 23 是 Cohere 推出的多語言模型，支援 23 種語言，適用於多元應用場景。",
  "aya:35b.description": "Aya 23 是 Cohere 推出的多語言模型，支援 23 種語言，適用於多元應用場景。",
  "azure-DeepSeek-R1-0528.description": "由微軟部署的 DeepSeek R1 已升級為 DeepSeek-R1-0528。此次更新提升了運算能力與後訓練演算法優化，顯著增強推理深度與推論表現，在數學、程式碼與邏輯基準測試中表現優異，接近 O3 與 Gemini 2.5 Pro 等領先模型。",
  "baichuan-m2-32b.description": "Baichuan M2 32B 是百川智能推出的 MoE 模型，具備強大的推理能力。",
  "baichuan/baichuan2-13b-chat.description": "Baichuan-13B 是百川推出的開源、可商用的 130 億參數大型語言模型，在中文與英文權威基準測試中表現同級最佳。",
  "baidu/ERNIE-4.5-300B-A47B.description": "ERNIE-4.5-300B-A47B 是百度推出的 MoE 架構大型語言模型，總參數為 3000 億，每個 token 啟用 470 億參數，兼顧效能與運算效率。作為 ERNIE 4.5 核心模型之一，擅長理解、生成、推理與程式設計。採用多模態異構 MoE 預訓練方法，結合文字與視覺訓練，全面提升能力，特別是在指令遵循與世界知識方面。",
  "baidu/ernie-5.0-thinking-preview.description": "ERNIE 5.0 Thinking Preview 是百度新一代原生多模態 ERNIE 模型，擅長多模態理解、指令遵循、創作、事實問答與工具調用。",
  "black-forest-labs/flux-1.1-pro.description": "FLUX 1.1 Pro 是升級版的 FLUX Pro，具備更快速度、優異的圖像品質與提示遵循能力。",
  "black-forest-labs/flux-dev.description": "FLUX Dev 是 FLUX 的開發版本，僅供非商業用途。",
  "black-forest-labs/flux-pro.description": "FLUX Pro 是專業級 FLUX 模型，專為高品質圖像輸出設計。",
  "black-forest-labs/flux-schnell.description": "FLUX Schnell 是一款針對速度優化的快速圖像生成模型。",
  "c4ai-aya-expanse-32b.description": "Aya Expanse 是一款高效能的 320 億參數多語言模型，透過指令微調、資料仲裁、偏好訓練與模型融合，達到媲美單語模型的表現。支援 23 種語言。",
  "c4ai-aya-expanse-8b.description": "Aya Expanse 是一款高效能的 80 億參數多語言模型，透過指令微調、資料仲裁、偏好訓練與模型融合，達到媲美單語模型的表現。支援 23 種語言。",
  "c4ai-aya-vision-32b.description": "Aya Vision 是一款先進的多模態模型，在語言、文字與視覺基準測試中表現優異。此 320 億參數版本專注於頂級多語言效能，支援 23 種語言。",
  "c4ai-aya-vision-8b.description": "Aya Vision 是一款先進的多模態模型，在語言、文字與視覺基準測試中表現優異。此 80 億參數版本著重於低延遲與穩定效能。",
  "charglm-3.description": "CharGLM-3 專為角色扮演與情感陪伴設計，支援超長多輪記憶與個性化對話。",
  "charglm-4.description": "CharGLM-4 專為角色扮演與情感陪伴設計，支援超長多輪記憶與個性化對話。",
  "chatgpt-4o-latest.description": "ChatGPT-4o 是一款即時更新的動態模型，結合強大的理解與生成能力，適用於客服、教育與技術支援等大規模應用場景。",
  "claude-2.0.description": "Claude 2 提供企業級關鍵改進，包括領先的 20 萬 token 上下文、降低幻覺、系統提示與新測試功能：工具調用。",
  "claude-2.1.description": "Claude 2 提供企業級關鍵改進，包括領先的 20 萬 token 上下文、降低幻覺、系統提示與新測試功能：工具調用。",
  "claude-3-5-haiku-20241022.description": "Claude 3.5 Haiku 是 Anthropic 推出的最新一代最快速模型。相較於 Claude 3 Haiku，其在多項技能上皆有提升，並在多項智能基準測試中超越先前最大模型 Claude 3 Opus。",
  "claude-3-5-haiku-latest.description": "Claude 3.5 Haiku 提供快速回應，適用於輕量任務。",
  "claude-3-7-sonnet-20250219.description": "Claude 3.7 Sonnet 是 Anthropic 最具智慧的模型，也是市場上首個混合推理模型。它能夠即時回應，或進行可視化的逐步推理。Sonnet 尤其擅長程式設計、資料科學、視覺處理與智能代理任務。",
  "claude-3-7-sonnet-latest.description": "Claude 3.7 Sonnet 是 Anthropic 最新且最強大的模型，適用於高度複雜任務，具備卓越的效能、智慧、流暢度與理解力。",
  "claude-3-haiku-20240307.description": "Claude 3 Haiku 是 Anthropic 推出的最快速且最精簡的模型，設計用於即時回應，具備快速且準確的表現。",
  "claude-3-opus-20240229.description": "Claude 3 Opus 是 Anthropic 最強大的模型，適用於高度複雜任務，具備卓越的效能、智慧、流暢度與理解力。",
  "claude-3-sonnet-20240229.description": "Claude 3 Sonnet 在智慧與速度之間取得平衡，適合企業工作負載，提供高效能與低成本的大規模部署。",
  "claude-haiku-4-5-20251001.description": "Claude Haiku 4.5 是 Anthropic 推出的最快速且最智慧的 Haiku 模型，具備閃電般的速度與延伸推理能力。",
  "claude-opus-4-1-20250805-thinking.description": "Claude Opus 4.1 Thinking 是一個進階版本，能夠揭示其推理過程。",
  "claude-opus-4-1-20250805.description": "Claude Opus 4.1 是 Anthropic 最新且最強大的模型，專為處理高度複雜任務而設，於效能、智慧、流暢度與理解力方面皆表現卓越。",
  "claude-opus-4-20250514.description": "Claude Opus 4 是 Anthropic 最強大的模型，專為處理高度複雜任務而設，於效能、智慧、流暢度與理解力方面皆表現出色。",
  "claude-opus-4-5-20251101.description": "Claude Opus 4.5 是 Anthropic 的旗艦模型，結合卓越智慧與可擴展效能，適合需要最高品質回應與推理的複雜任務。",
  "claude-opus-4-6.description": "Claude Opus 4.6 是 Anthropic 最智慧的模型，專為建構智能代理與程式開發而設計。",
  "claude-sonnet-4-20250514-thinking.description": "Claude Sonnet 4 Thinking 可產生即時回應或延伸的逐步思考，並顯示其推理過程。",
  "claude-sonnet-4-20250514.description": "Claude Sonnet 4 能夠即時回應，或進行可視化的逐步思考過程。",
  "claude-sonnet-4-5-20250929.description": "Claude Sonnet 4.5 是 Anthropic 迄今最具智慧的模型。",
  "codegeex-4.description": "CodeGeeX-4 是一款強大的 AI 程式輔助工具，支援多語言問答與程式碼補全，能有效提升開發者的生產力。",
  "codegeex4-all-9b.description": "CodeGeeX4-ALL-9B 是一個多語言程式碼生成模型，支援程式碼補全與生成、程式碼解釋器、網頁搜尋、函式呼叫與倉庫層級的程式碼問答，涵蓋多種軟體開發場景。它是參數數量低於 100 億的頂尖程式碼模型之一。",
  "codegemma.description": "CodeGemma 是一款輕量級模型，適用於多樣化的程式任務，能快速迭代與整合。",
  "codegemma:2b.description": "CodeGemma 是一款輕量級模型，適用於多樣化的程式任務，能快速迭代與整合。",
  "codellama.description": "Code Llama 是一款專注於程式碼生成與討論的大型語言模型，支援多種語言，優化開發者的工作流程。",
  "codellama/CodeLlama-34b-Instruct-hf.description": "Code Llama 是一款專注於程式碼生成與討論的大型語言模型，支援多種語言，優化開發者的工作流程。",
  "codellama:13b.description": "Code Llama 是一款專注於程式碼生成與討論的大型語言模型，支援多種語言，優化開發者的工作流程。",
  "codellama:34b.description": "Code Llama 是一款專注於程式碼生成與討論的大型語言模型，支援多種語言，優化開發者的工作流程。",
  "codellama:70b.description": "Code Llama 是一款專注於程式碼生成與討論的大型語言模型，支援多種語言，優化開發者的工作流程。",
  "codeqwen.description": "CodeQwen1.5 是一款以大量程式碼資料訓練的大型語言模型，專為處理複雜的程式任務而設計。",
  "codestral-latest.description": "Codestral 是我們最先進的程式模型；v2（2025 年 1 月）針對低延遲、高頻率任務如 FIM、程式碼修正與測試生成進行優化。",
  "codestral.description": "Codestral 是 Mistral AI 推出的首款程式模型，具備強大的程式碼生成能力。",
  "codex-mini-latest.description": "codex-mini-latest 是針對 Codex CLI 微調的 o4-mini 模型。如需直接使用 API，建議從 gpt-4.1 開始。",
  "cogito-2.1:671b.description": "Cogito v2.1 671B 是一款美國開源的大型語言模型，可商業使用，效能媲美頂尖模型，具備更高的 Token 推理效率、128k 長上下文能力與整體強大表現。",
  "cogview-4.description": "CogView-4 是智譜推出的首款開源文字轉圖像模型，支援中文字符生成。它提升了語意理解、圖像品質與中英文文字渲染能力，支援任意長度的雙語提示詞，並可在指定範圍內生成任意解析度的圖像。",
  "cohere-command-r-plus.description": "Command R+ 是一款針對企業工作負載優化的先進 RAG 模型。",
  "cohere-command-r.description": "Command R 是一款可擴展的生成模型，設計用於 RAG 與工具使用，支援生產級 AI 應用。",
  "cohere/Cohere-command-r-plus.description": "Command R+ 是一款針對企業工作負載優化的先進 RAG 模型。",
  "cohere/Cohere-command-r.description": "Command R 是一款可擴展的生成模型，設計用於 RAG 與工具使用，支援生產級 AI 應用。",
  "cohere/command-a.description": "Command A 是 Cohere 目前最強大的模型，擅長工具使用、代理任務、RAG 與多語言應用。具備 256K 上下文長度，僅需兩張 GPU 即可運行，吞吐量比 Command R+ 08-2024 高出 150%。",
  "cohere/command-r-plus.description": "Command R+ 是 Cohere 最新的大型語言模型，針對聊天與長上下文任務進行優化，幫助企業從原型邁向生產階段。",
  "cohere/command-r.description": "Command R 針對聊天與長上下文任務進行優化，定位為「可擴展」模型，在高效能與準確性之間取得平衡，協助企業從原型邁向生產階段。",
  "cohere/embed-v4.0.description": "一款可將文字、圖像或混合內容分類或轉換為嵌入向量的模型。",
  "comfyui/flux-dev.description": "FLUX.1 Dev 是一款高品質的文字轉圖像模型（10–50 步），非常適合創意與藝術性輸出。",
  "comfyui/flux-kontext-dev.description": "FLUX.1 Kontext-dev 是一款支援文字引導編輯的圖像編輯模型，包含局部編輯與風格轉換功能。",
  "comfyui/flux-krea-dev.description": "FLUX.1 Krea-dev 是與 Krea 共同開發的安全增強型文字轉圖像模型，內建安全過濾機制。",
  "comfyui/flux-schnell.description": "FLUX.1 Schnell 是一款超高速文字轉圖像模型，可在 1–4 步內生成高品質圖像，適合即時應用與快速原型設計。",
  "comfyui/stable-diffusion-15.description": "Stable Diffusion 1.5 是經典的 512x512 文字轉圖像模型，適合快速原型設計與創意實驗。",
  "comfyui/stable-diffusion-35-inclclip.description": "Stable Diffusion 3.5 內建 CLIP/T5 編碼器，無需外部編碼器檔案，適用於如 sd3.5_medium_incl_clips 等資源使用較低的模型。",
  "comfyui/stable-diffusion-35.description": "Stable Diffusion 3.5 是新一代文字轉圖像模型，提供 Large 與 Medium 版本。需搭配外部 CLIP 編碼器檔案，具備優異的圖像品質與提示詞遵循度。",
  "comfyui/stable-diffusion-custom-refiner.description": "自訂 SDXL 圖像轉圖像模型。請使用 custom_sd_lobe.safetensors 作為模型檔名；若有 VAE，請使用 custom_sd_vae_lobe.safetensors。將模型檔案放入 Comfy 指定資料夾中。",
  "comfyui/stable-diffusion-custom.description": "自訂 SD 文字轉圖像模型。請使用 custom_sd_lobe.safetensors 作為模型檔名；若有 VAE，請使用 custom_sd_vae_lobe.safetensors。將模型檔案放入 Comfy 指定資料夾中。",
  "comfyui/stable-diffusion-refiner.description": "SDXL 圖像轉圖像模型，能從輸入圖像進行高品質轉換，支援風格轉換、修復與創意變化。",
  "comfyui/stable-diffusion-xl.description": "SDXL 是一款支援 1024x1024 高解析度生成的文字轉圖像模型，具備更佳的圖像品質與細節表現。",
  "command-a-03-2025.description": "Command A 是我們目前最強大的模型，擅長工具使用、代理任務、RAG 與多語言場景。具備 256K 上下文視窗，僅需兩張 GPU 即可運行，吞吐量比 Command R+ 08-2024 高出 150%。",
  "command-light-nightly.description": "為縮短主要版本之間的間隔，我們提供 Command 系列的夜間版本。command-light-nightly 是 command-light 系列中最新、最具實驗性（可能不穩定）的版本，會定期更新，建議僅用於測試環境。",
  "command-light.description": "Command 的輕量快速版本，功能接近但速度更快。",
  "command-nightly.description": "為縮短主要版本之間的間隔，我們提供 Command 系列的夜間版本。command-nightly 是 Command 系列中最新、最具實驗性（可能不穩定）的版本，會定期更新，建議僅用於測試環境。",
  "command-r-03-2024.description": "Command R 是一款遵循指令的聊天模型，品質更高、穩定性更強，並具備比早期模型更長的上下文視窗。支援程式碼生成、RAG、工具使用與代理等複雜工作流程。",
  "command-r-08-2024.description": "command-r-08-2024 是 2024 年 8 月發布的 Command R 模型更新版本。",
  "command-r-plus-04-2024.description": "command-r-plus 是 command-r-plus-04-2024 的別名，因此在 API 中使用 command-r-plus 即指向該模型。",
  "command-r-plus-08-2024.description": "Command R+ 是一款遵循指令的聊天模型，品質更高、穩定性更強，並具備比前代模型更長的上下文視窗。最適合用於複雜的 RAG 工作流程與多步驟工具使用。",
  "command-r-plus.description": "Command R+ 是一款高效能的大型語言模型，專為真實企業場景與複雜應用而設計。",
  "command-r.description": "Command R 是一款針對聊天與長上下文任務優化的大型語言模型，適合動態互動與知識管理。",
  "command-r7b-12-2024.description": "command-r7b-12-2024 是 2024 年 12 月發布的小型高效更新版本，擅長需要複雜多步推理的 RAG、工具使用與代理任務。",
  "command.description": "一款遵循指令的聊天模型，在語言任務中提供更高品質與可靠性，具備比基礎生成模型更長的上下文視窗。",
  "computer-use-preview.description": "computer-use-preview 是一款專為「電腦使用工具」訓練的模型，能理解並執行與電腦相關的任務。",
  "dall-e-2.description": "第二代 DALL·E 模型，具備更真實、準確的圖像生成能力，解析度為第一代的四倍。",
  "dall-e-3.description": "最新的 DALL·E 模型於 2023 年 11 月發布，支援更真實、準確的圖像生成，細節表現更強。",
  "databricks/dbrx-instruct.description": "DBRX Instruct 提供跨產業高度可靠的指令處理能力。",
  "deepseek-ai/DeepSeek-OCR.description": "DeepSeek-OCR 是 DeepSeek AI 推出的視覺語言模型，專注於光學字元辨識（OCR）與「上下文光學壓縮」。該模型探索從影像中壓縮上下文資訊，能高效處理文件並轉換為結構化文字（如 Markdown），準確辨識影像中的文字，適用於文件數位化、文字擷取與結構化處理。",
  "deepseek-ai/DeepSeek-R1-0528-Qwen3-8B.description": "DeepSeek-R1-0528-Qwen3-8B 將 DeepSeek-R1-0528 的思維鏈（Chain-of-Thought）蒸餾至 Qwen3 8B Base。在開源模型中達到 SOTA 表現，於 AIME 2024 超越 Qwen3 8B 10%，並匹敵 Qwen3-235B-thinking 的表現。擅長數學推理、程式設計與邏輯基準測試。架構與 Qwen3-8B 相同，但使用 DeepSeek-R1-0528 的分詞器。",
  "deepseek-ai/DeepSeek-R1-0528.description": "DeepSeek R1 利用額外算力與後訓練演算法優化，深化推理能力。在數學、程式設計與邏輯基準測試中表現優異，接近 o3 與 Gemini 2.5 Pro 等領先模型。",
  "deepseek-ai/DeepSeek-R1-Distill-Llama-70B.description": "DeepSeek-R1 蒸餾模型使用強化學習（RL）與冷啟動資料來提升推理能力，並創下開源多任務基準新紀錄。",
  "deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B.description": "DeepSeek-R1 蒸餾模型使用強化學習（RL）與冷啟動資料來提升推理能力，並創下開源多任務基準新紀錄。",
  "deepseek-ai/DeepSeek-R1-Distill-Qwen-14B.description": "DeepSeek-R1 蒸餾模型使用強化學習（RL）與冷啟動資料來提升推理能力，並創下開源多任務基準新紀錄。",
  "deepseek-ai/DeepSeek-R1-Distill-Qwen-32B.description": "DeepSeek-R1-Distill-Qwen-32B 是從 Qwen2.5-32B 蒸餾而來，並在 80 萬筆精選 DeepSeek-R1 樣本上微調。擅長數學、程式設計與推理，在 AIME 2024、MATH-500（94.3% 準確率）與 GPQA Diamond 上表現出色。",
  "deepseek-ai/DeepSeek-R1-Distill-Qwen-7B.description": "DeepSeek-R1-Distill-Qwen-7B 是從 Qwen2.5-Math-7B 蒸餾而來，並在 80 萬筆精選 DeepSeek-R1 樣本上微調。表現優異，在 MATH-500 達 92.8%、AIME 2024 達 55.5%、CodeForces 評分為 1189（7B 模型）。",
  "deepseek-ai/DeepSeek-R1.description": "DeepSeek-R1 結合強化學習與冷啟動資料，提升推理能力，創下開源多任務基準新高，超越 OpenAI-o1-mini。",
  "deepseek-ai/DeepSeek-V2.5.description": "DeepSeek-V2.5 升級了 DeepSeek-V2-Chat 與 DeepSeek-Coder-V2-Instruct，融合通用與程式能力。提升寫作與指令遵循能力，偏好對齊更佳，在 AlpacaEval 2.0、ArenaHard、AlignBench 與 MT-Bench 上有顯著進步。",
  "deepseek-ai/DeepSeek-V3.1-Terminus.description": "DeepSeek-V3.1-Terminus 是 V3.1 的更新版本，定位為混合智能體大模型。修復用戶回報問題，提升穩定性與語言一致性，減少中英混雜與異常字元。整合思考與非思考模式，支援聊天模板靈活切換。Code Agent 與 Search Agent 表現也獲得提升，工具使用與多步任務更可靠。",
  "deepseek-ai/DeepSeek-V3.1.description": "DeepSeek V3.1 採用混合推理架構，支援思考與非思考模式。",
  "deepseek-ai/DeepSeek-V3.2-Exp.description": "DeepSeek-V3.2-Exp 是 V3.2 的實驗版本，銜接下一代架構。在 V3.1-Terminus 基礎上加入 DeepSeek Sparse Attention（DSA），提升長上下文訓練與推理效率，並針對工具使用、長文理解與多步推理進行優化，適合探索高效推理與大上下文應用。",
  "deepseek-ai/DeepSeek-V3.description": "DeepSeek-V3 是一款擁有 671B 參數的 MoE 模型，採用 MLA 與 DeepSeekMoE 架構，具備無損負載平衡，訓練與推理效率高。預訓練資料達 14.8T 高品質 token，並經過 SFT 與 RL 微調，表現超越其他開源模型，接近封閉模型領先水準。",
  "deepseek-ai/deepseek-llm-67b-chat.description": "DeepSeek LLM Chat（67B）是一款創新模型，具備深層語言理解與互動能力。",
  "deepseek-ai/deepseek-v3.1-terminus.description": "DeepSeek V3.1 是新一代推理模型，具備更強的複雜推理與思維鏈能力，適用於深度分析任務。",
  "deepseek-ai/deepseek-v3.1.description": "DeepSeek V3.1 是新一代推理模型，具備更強的複雜推理與思維鏈能力，適用於深度分析任務。",
  "deepseek-ai/deepseek-vl2.description": "DeepSeek-VL2 是一款基於 DeepSeekMoE-27B 的 MoE 視覺語言模型，採用稀疏激活，僅使用 4.5B 活躍參數即可達到強大表現。擅長視覺問答、OCR、文件/表格/圖表理解與視覺對齊。",
  "deepseek-chat.description": "一款結合通用對話與程式能力的新開源模型。它保留了聊天模型的對話能力與程式模型的強大編碼能力，並在偏好對齊方面有所提升。DeepSeek-V2.5 也在寫作與指令遵循方面表現更佳。",
  "deepseek-coder-33B-instruct.description": "DeepSeek Coder 33B 是一款程式語言模型，訓練於 2T token（87% 程式碼，13% 中英文文本），支援 16K 上下文視窗與中間填充任務，提供專案級程式補全與片段填充功能。",
  "deepseek-coder-v2.description": "DeepSeek Coder V2 是一款開源 MoE 程式模型，在程式任務中表現強勁，媲美 GPT-4 Turbo。",
  "deepseek-coder-v2:236b.description": "DeepSeek Coder V2 是一款開源 MoE 程式模型，在程式任務中表現強勁，媲美 GPT-4 Turbo。",
  "deepseek-ocr.description": "DeepSeek-OCR 是 DeepSeek AI 推出的視覺語言模型，專注於 OCR 與「上下文光學壓縮」。探索從影像中壓縮上下文資訊，能高效處理文件並轉換為結構化文字格式（如 Markdown），準確辨識影像中的文字，適用於文件數位化、文字擷取與結構化處理。",
  "deepseek-r1-0528.description": "685B 全量模型於 2025-05-28 發布。DeepSeek-R1 在後訓練階段引入大規模強化學習（RL），即使標註資料極少，也能大幅提升推理能力，並在數學、程式碼與自然語言推理方面表現優異。",
  "deepseek-r1-250528.description": "DeepSeek R1 250528 是專為高難度數學與邏輯任務設計的 DeepSeek-R1 全量推理模型。",
  "deepseek-r1-70b-fast-online.description": "DeepSeek R1 70B 快速版，支援即時網頁搜尋，回應更迅速且維持高效能。",
  "deepseek-r1-70b-online.description": "DeepSeek R1 70B 標準版，支援即時網頁搜尋，適合處理最新聊天與文字任務。",
  "deepseek-r1-distill-llama-70b.description": "DeepSeek R1 Distill Llama 70B 結合 R1 推理能力與 Llama 生態系統。",
  "deepseek-r1-distill-llama-8b.description": "DeepSeek-R1-Distill-Llama-8B 是以 DeepSeek R1 輸出資料蒸餾自 Llama-3.1-8B。",
  "deepseek-r1-distill-llama.description": "deepseek-r1-distill-llama 是以 DeepSeek-R1 在 Llama 上進行蒸餾訓練的模型。",
  "deepseek-r1-distill-qianfan-70b.description": "DeepSeek R1 Distill Qianfan 70B 是基於 Qianfan-70B 的 R1 蒸餾模型，具備高價值表現。",
  "deepseek-r1-distill-qianfan-8b.description": "DeepSeek R1 Distill Qianfan 8B 是基於 Qianfan-8B 的 R1 蒸餾模型，適用於中小型應用場景。",
  "deepseek-r1-distill-qianfan-llama-70b.description": "DeepSeek R1 Distill Qianfan Llama 70B 是基於 Llama-70B 的 R1 蒸餾模型。",
  "deepseek-r1-distill-qwen-1.5b.description": "DeepSeek R1 Distill Qwen 1.5B 是超輕量蒸餾模型，適用於極低資源環境。",
  "deepseek-r1-distill-qwen-14b.description": "DeepSeek R1 Distill Qwen 14B 是中型蒸餾模型，適合多場景部署。",
  "deepseek-r1-distill-qwen-32b.description": "DeepSeek R1 Distill Qwen 32B 是基於 Qwen-32B 的 R1 蒸餾模型，兼顧效能與成本。",
  "deepseek-r1-distill-qwen-7b.description": "DeepSeek R1 Distill Qwen 7B 是輕量級蒸餾模型，適合邊緣端與企業私有部署環境。",
  "deepseek-r1-distill-qwen.description": "deepseek-r1-distill-qwen 是以 DeepSeek-R1 在 Qwen 上進行蒸餾訓練的模型。",
  "deepseek-r1-fast-online.description": "DeepSeek R1 快速全量版，支援即時網頁搜尋，結合 671B 規模能力與快速回應。",
  "deepseek-r1-online.description": "DeepSeek R1 全量版擁有 671B 參數與即時網頁搜尋功能，提供更強的理解與生成能力。",
  "deepseek-r1.description": "DeepSeek-R1 在強化學習前使用冷啟動資料，於數學、程式碼與推理任務中表現可媲美 OpenAI-o1。",
  "deepseek-reasoner.description": "DeepSeek V3.2 推理模式會在最終答案前輸出思考鏈，以提升準確性。",
  "deepseek-v2.description": "DeepSeek V2 是一款高效的 MoE 模型，適用於具成本效益的處理任務。",
  "deepseek-v2:236b.description": "DeepSeek V2 236B 是 DeepSeek 專注於程式碼生成的模型，具備強大能力。",
  "deepseek-v3-0324.description": "DeepSeek-V3-0324 是一款擁有 671B 參數的 MoE 模型，在程式設計、技術能力、語境理解與長文本處理方面表現出色。",
  "deepseek-v3.1-terminus.description": "DeepSeek-V3.1-Terminus 是 DeepSeek 為終端設備優化的 LLM 模型。",
  "deepseek-v3.1-think-250821.description": "DeepSeek V3.1 Think 250821 是對應 Terminus 版本的深度思考模型，專為高效推理而設計。",
  "deepseek-v3.1.description": "DeepSeek-V3.1 是 DeepSeek 推出的新一代混合推理模型，支援思考與非思考模式，思考效率高於 DeepSeek-R1-0528。後訓練優化大幅提升代理工具使用與任務執行能力，支援 128k 上下文視窗與最多 64k 輸出字元。",
  "deepseek-v3.1:671b.description": "DeepSeek V3.1 是新一代推理模型，強化複雜推理與思路鏈能力，適合需要深入分析的任務。",
  "deepseek-v3.2-exp.description": "deepseek-v3.2-exp 引入稀疏注意力機制，在處理長文本時提升訓練與推理效率，價格低於 deepseek-v3.1。",
  "deepseek-v3.2-think.description": "DeepSeek V3.2 Think 是完整的深度思考模型，具備更強的長鏈推理能力。",
  "deepseek-v3.2.description": "DeepSeek-V3.2 是 DeepSeek 首個融合推理能力的混合模型，將思考能力整合至工具使用中。透過高效架構節省運算資源，結合大規模強化學習提升能力，並利用大量合成任務數據強化泛化能力。三者結合使其表現可媲美 GPT-5-High，且大幅縮短輸出長度，顯著降低計算負擔與用戶等待時間。",
  "deepseek-v3.description": "DeepSeek-V3 是一款強大的 MoE 模型，總參數達 671B，每個 token 啟用 37B 參數。",
  "deepseek-vl2-small.description": "DeepSeek VL2 Small 是輕量級多模態模型，適用於資源受限與高併發場景。",
  "deepseek-vl2.description": "DeepSeek VL2 是一款多模態模型，支援圖文理解與細緻的視覺問答任務。",
  "deepseek/deepseek-chat-v3-0324.description": "DeepSeek V3 是一款擁有 685B 參數的 MoE 模型，是 DeepSeek 旗艦聊天系列的最新版本。\n\n它基於 [DeepSeek V3](/deepseek/deepseek-chat-v3) 打造，在多項任務中表現出色。",
  "deepseek/deepseek-chat-v3-0324:free.description": "DeepSeek V3 是一款擁有 685B 參數的 MoE 模型，是 DeepSeek 旗艦聊天系列的最新版本。\n\n它基於 [DeepSeek V3](/deepseek/deepseek-chat-v3) 打造，在多項任務中表現出色。",
  "deepseek/deepseek-chat-v3.1.description": "DeepSeek-V3.1 是 DeepSeek 的長上下文混合推理模型，支援思考與非思考模式切換，並整合工具使用。",
  "deepseek/deepseek-chat.description": "DeepSeek-V3 是 DeepSeek 的高效能混合推理模型，適用於複雜任務與工具整合。",
  "deepseek/deepseek-math-v2.description": "DeepSeek Math V2 是一款在數學推理能力上取得重大突破的模型。其核心創新在於「自我驗證」訓練機制，並在多項頂級數學競賽中達到金牌水準。",
  "deepseek/deepseek-r1-0528.description": "DeepSeek R1 0528 是一個專注於開放可用性與深度推理的更新版本。",
  "deepseek/deepseek-r1-0528:free.description": "DeepSeek-R1 在僅需少量標註資料的情況下大幅提升推理能力，並在最終答案前輸出思考鏈以提高準確性。",
  "deepseek/deepseek-r1-distill-llama-70b.description": "DeepSeek R1 Distill Llama 70B 是基於 Llama 3.3 70B 精煉而成的大型語言模型，透過 DeepSeek R1 輸出進行微調，達到與大型前沿模型相當的效能。",
  "deepseek/deepseek-r1-distill-llama-8b.description": "DeepSeek R1 Distill Llama 8B 是基於 Llama-3.1-8B-Instruct 精煉而成的語言模型，使用 DeepSeek R1 輸出進行訓練。",
  "deepseek/deepseek-r1-distill-qwen-14b.description": "DeepSeek R1 Distill Qwen 14B 是基於 Qwen 2.5 14B 精煉而成的語言模型，使用 DeepSeek R1 輸出進行訓練。其在多項基準測試中超越 OpenAI o1-mini，於密集模型中達到 SOTA 水準。基準亮點：\nAIME 2024 pass@1：69.7\nMATH-500 pass@1：93.9\nCodeForces 評分：1481\n透過 DeepSeek R1 輸出微調，效能媲美更大型的前沿模型。",
  "deepseek/deepseek-r1-distill-qwen-32b.description": "DeepSeek R1 Distill Qwen 32B 是基於 Qwen 2.5 32B 精煉而成的語言模型，使用 DeepSeek R1 輸出進行訓練。其在多項基準測試中超越 OpenAI o1-mini，於密集模型中達到 SOTA 水準。基準亮點：\nAIME 2024 pass@1：72.6\nMATH-500 pass@1：94.3\nCodeForces 評分：1691\n透過 DeepSeek R1 輸出微調，效能媲美更大型的前沿模型。",
  "deepseek/deepseek-r1.description": "DeepSeek R1 已更新為 DeepSeek-R1-0528。透過更強的運算資源與後訓練演算法優化，其推理深度與能力大幅提升。在數學、程式設計與邏輯基準測試中表現優異，接近 o3 與 Gemini 2.5 Pro 等領先模型。",
  "deepseek/deepseek-r1/community.description": "DeepSeek R1 是 DeepSeek 團隊最新釋出的開源模型，在數學、程式設計與推理任務中展現強大推理能力，表現可媲美 OpenAI o1。",
  "deepseek/deepseek-r1:free.description": "DeepSeek-R1 在僅需少量標註資料的情況下大幅提升推理能力，並在最終答案前輸出思考鏈以提高準確性。",
  "deepseek/deepseek-reasoner.description": "DeepSeek-V3 Thinking（reasoner）是 DeepSeek 的實驗性推理模型，適用於高複雜度推理任務。",
  "deepseek/deepseek-v3.1-base.description": "DeepSeek V3.1 Base 是 DeepSeek V3 模型的改進版本。",
  "deepseek/deepseek-v3.description": "一款快速的通用大型語言模型，具備增強的推理能力。",
  "deepseek/deepseek-v3/community.description": "DeepSeek-V3 在推理速度上相較前代實現重大突破。其在開源模型中排名第一，並可媲美最先進的封閉模型。DeepSeek-V3 採用 Multi-Head Latent Attention（MLA）與 DeepSeekMoE 架構，兩者皆已在 DeepSeek-V2 中驗證。另引入無損輔助策略以實現負載平衡，並採用多標記預測訓練目標以提升效能。",
  "deepseek_r1.description": "DeepSeek-R1 是一款以強化學習驅動的推理模型，針對重複與可讀性問題進行優化。在進行強化學習前，使用冷啟動資料進一步提升推理表現。其在數學、程式設計與推理任務中表現與 OpenAI-o1 相當，透過精心設計的訓練流程提升整體效能。",
  "deepseek_r1_distill_llama_70b.description": "DeepSeek-R1-Distill-Llama-70B 是從 Llama-3.3-70B-Instruct 精煉而來。作為 DeepSeek-R1 系列的一部分，該模型以 DeepSeek-R1 生成樣本進行微調，在數學、程式設計與推理方面表現出色。",
  "deepseek_r1_distill_qwen_14b.description": "DeepSeek-R1-Distill-Qwen-14B 是從 Qwen2.5-14B 精煉而來，並以 DeepSeek-R1 生成的 80 萬條精選樣本進行微調，展現強大推理能力。",
  "deepseek_r1_distill_qwen_32b.description": "DeepSeek-R1-Distill-Qwen-32B 是從 Qwen2.5-32B 精煉而來，並以 DeepSeek-R1 生成的 80 萬條精選樣本進行微調，在數學、程式設計與推理方面表現卓越。",
  "devstral-2:123b.description": "Devstral 2 123B 擅長使用工具探索程式碼庫、編輯多個檔案，並支援軟體工程代理人。",
  "doubao-1.5-lite-32k.description": "Doubao-1.5-lite 是一款全新輕量級模型，具備極速回應能力，提供頂級品質與低延遲表現。",
  "doubao-1.5-pro-256k.description": "Doubao-1.5-pro-256k 是 Doubao-1.5-Pro 的全面升級版，整體效能提升 10%。支援 256k 上下文視窗與最多 12k 輸出字元，提供更高效能、更大視窗與更廣泛應用價值。",
  "doubao-1.5-pro-32k.description": "Doubao-1.5-pro 是新一代旗艦模型，全面升級，在知識、程式設計與推理方面表現出色。",
  "doubao-1.5-thinking-pro-m.description": "Doubao-1.5 是一款全新深度推理模型（m 版本支援原生多模態深度推理），在數學、程式設計、科學推理及創意寫作等通用任務中表現優異。於 AIME 2024、Codeforces 與 GPQA 等基準測試中達到或接近頂尖水準。支援 128k 上下文視窗與 16k 輸出。",
  "doubao-1.5-thinking-pro.description": "Doubao-1.5 是一款全新深度推理模型，在數學、程式設計、科學推理及創意寫作等通用任務中表現優異。於 AIME 2024、Codeforces 與 GPQA 等基準測試中達到或接近頂尖水準。支援 128k 上下文視窗與 16k 輸出。",
  "doubao-1.5-thinking-vision-pro.description": "全新視覺深度推理模型，具備更強的多模態理解與推理能力，在 59 個公開基準中有 37 項達到 SOTA 表現。",
  "doubao-1.5-ui-tars.description": "Doubao-1.5-UI-TARS 是一款原生圖形介面導向代理模型，透過類人感知、推理與行動，與介面無縫互動。",
  "doubao-1.5-vision-lite.description": "Doubao-1.5-vision-lite 是升級版多模態模型，支援任意解析度與極端長寬比的圖像，強化視覺推理、文件識別、細節理解與指令遵循。支援 128k 上下文視窗與最多 16k 輸出字元。",
  "doubao-1.5-vision-pro-32k.description": "Doubao-1.5-vision-pro 是升級版多模態模型，支援任意解析度與極端長寬比的圖像，強化視覺推理、文件識別、細節理解與指令遵循。",
  "doubao-1.5-vision-pro.description": "Doubao-1.5-vision-pro 是升級版多模態模型，支援任意解析度與極端長寬比的圖像，強化視覺推理、文件識別、細節理解與指令遵循。",
  "doubao-lite-128k.description": "極速回應與高性價比，提供多場景靈活選擇。支援推理與微調，具備 128k 上下文視窗。",
  "doubao-lite-32k.description": "極速回應與高性價比，提供多場景靈活選擇。支援推理與微調，具備 32k 上下文視窗。",
  "doubao-lite-4k.description": "極速回應與高性價比，提供多場景靈活選擇。支援推理與微調，具備 4k 上下文視窗。",
  "doubao-pro-256k.description": "最強旗艦模型，適用於複雜任務，在參考問答、摘要、創作、文本分類與角色扮演等方面表現卓越。支援推理與微調，具備 256k 上下文視窗。",
  "doubao-pro-32k.description": "最強旗艦模型，適用於複雜任務，在參考問答、摘要、創作、文本分類與角色扮演等方面表現卓越。支援推理與微調，具備 32k 上下文視窗。",
  "doubao-seed-1.6-flash.description": "Doubao-Seed-1.6-flash 是一款極速多模態深度推理模型，TPOT 低至 10ms。支援文字與圖像，文字理解超越前代 lite 模型，視覺能力媲美競品 pro 模型。支援 256k 上下文視窗與最多 16k 輸出字元。",
  "doubao-seed-1.6-lite.description": "Doubao-Seed-1.6-lite 是一款全新多模態深度推理模型，支援可調推理強度（最低、低、中、高），在常見任務中提供更高性價比與穩定選擇，支援最高 256k 上下文視窗。",
  "doubao-seed-1.6-thinking.description": "Doubao-Seed-1.6-thinking 大幅強化推理能力，進一步提升程式設計、數學與邏輯推理核心能力，並新增視覺理解。支援 256k 上下文視窗與最多 16k 輸出字元。",
  "doubao-seed-1.6-vision.description": "Doubao-Seed-1.6-vision 是一款視覺深度推理模型，針對教育、圖像審查、檢測/安防與 AI 搜尋問答等場景提供更強的多模態理解與推理能力。支援 256k 上下文視窗與最多 64k 輸出字元。",
  "doubao-seed-1.6.description": "Doubao-Seed-1.6 是一款全新多模態深度推理模型，具備自動、思考與非思考模式。在非思考模式下，效能顯著超越 Doubao-1.5-pro/250115。支援 256k 上下文視窗與最多 16k 輸出字元。",
  "doubao-seed-1.8.description": "豆包 Seed-1.8 擁有更強的多模態理解與智能體能力，支援文字／圖片／影片輸入與上下文快取，在複雜任務中展現優異表現。",
  "doubao-seed-code.description": "Doubao-Seed-Code 專為代理式程式設計深度優化，支援多模態輸入（文字/圖片/影片）與 256k 上下文視窗，兼容 Anthropic API，適用於程式設計、視覺理解與代理工作流程。",
  "doubao-seededit-3-0-i2i-250628.description": "Doubao 影像模型（來自字節跳動 Seed）支援文字與圖像輸入，實現高度可控、高品質的圖像生成。支援文字引導的圖像編輯，輸出尺寸長邊介於 512 至 1536。",
  "doubao-seedream-3-0-t2i-250415.description": "Seedream 3.0 是字節跳動 Seed 團隊推出的圖像生成模型，支援文字與圖像輸入，實現高度可控、高品質的圖像生成。可根據文字提示生成圖像。",
  "doubao-seedream-4-0-250828.description": "Seedream 4.0 是字節跳動 Seed 團隊推出的圖像生成模型，支援文字與圖像輸入，實現高度可控、高品質的圖像生成。可根據文字提示生成圖像。",
  "doubao-vision-lite-32k.description": "Doubao-vision 是 Doubao 推出的多模態模型，具備強大的圖像理解與推理能力，並能精準執行指令。擅長圖文抽取與基於圖像的推理任務，支援更複雜與廣泛的視覺問答場景。",
  "doubao-vision-pro-32k.description": "Doubao-vision 是 Doubao 推出的多模態模型，具備強大的圖像理解與推理能力，並能精準執行指令。擅長圖文抽取與基於圖像的推理任務，支援更複雜與廣泛的視覺問答場景。",
  "emohaa.description": "Emohaa 是一款心理健康模型，具備專業諮詢能力，協助使用者理解情緒問題。",
  "ernie-4.5-0.3b.description": "ERNIE 4.5 0.3B 是一款開源輕量級模型，適合本地與客製化部署。",
  "ernie-4.5-21b-a3b.description": "ERNIE 4.5 21B A3B 是一款開源大參數模型，具備更強的理解與生成能力。",
  "ernie-4.5-300b-a47b.description": "ERNIE 4.5 300B A47B 是百度 ERNIE 的超大規模 MoE 模型，推理能力卓越。",
  "ernie-4.5-8k-preview.description": "ERNIE 4.5 8K Preview 是一款 8K 上下文預覽模型，用於評估 ERNIE 4.5。",
  "ernie-4.5-turbo-128k-preview.description": "ERNIE 4.5 Turbo 128K 預覽版具備正式版本能力，適合整合與金絲雀測試。",
  "ernie-4.5-turbo-128k.description": "ERNIE 4.5 Turbo 128K 是一款高效能通用模型，支援搜尋增強與工具調用，適用於問答、程式設計與代理場景。",
  "ernie-4.5-turbo-32k.description": "ERNIE 4.5 Turbo 32K 是中長上下文版本，適用於問答、知識庫檢索與多輪對話。",
  "ernie-4.5-turbo-latest.description": "最新 ERNIE 4.5 Turbo，整體效能優化，適合作為主要生產模型。",
  "ernie-4.5-turbo-vl-32k-preview.description": "ERNIE 4.5 Turbo VL 32K 預覽版是一款 32K 多模態模型，用於評估長上下文視覺能力。",
  "ernie-4.5-turbo-vl-32k.description": "ERNIE 4.5 Turbo VL 32K 是中長上下文多模態版本，適用於長文檔與圖像理解。",
  "ernie-4.5-turbo-vl-latest.description": "ERNIE 4.5 Turbo VL 最新版，圖文理解與推理能力提升。",
  "ernie-4.5-turbo-vl-preview.description": "ERNIE 4.5 Turbo VL 預覽版是一款多模態模型，適用於圖文理解與生成，支援視覺問答與內容理解。",
  "ernie-4.5-turbo-vl.description": "ERNIE 4.5 Turbo VL 是一款成熟的多模態模型，適用於生產級圖文理解與識別。",
  "ernie-4.5-vl-28b-a3b.description": "ERNIE 4.5 VL 28B A3B 是一款開源多模態模型，支援圖文理解與推理。",
  "ernie-5.0-thinking-latest.description": "文心 5.0 思考版是一款原生全模態旗艦模型，整合文字、圖像、音訊與影片建模，全面升級複雜問答、創作與智能體場景的能力。",
  "ernie-5.0-thinking-preview.description": "文心 5.0 思考預覽版是一款原生全模態旗艦模型，整合文字、圖像、音訊與影片建模，全面升級複雜問答、創作與智能體場景的能力。",
  "ernie-char-8k.description": "ERNIE 角色 8K 是一款面向 IP 角色塑造與長期陪伴對話的角色對話模型。",
  "ernie-char-fiction-8k-preview.description": "ERNIE 角色小說 8K 預覽版是一款面向角色與情節創作的模型預覽，用於功能評估與測試。",
  "ernie-char-fiction-8k.description": "ERNIE 角色小說 8K 是一款面向小說與情節創作的角色模型，適合長篇故事生成。",
  "ernie-irag-edit.description": "ERNIE iRAG Edit 是一款支援擦除、重繪與變體生成的圖像編輯模型。",
  "ernie-lite-pro-128k.description": "ERNIE Lite Pro 128K 是一款輕量高效能模型，適用於延遲與成本敏感場景。",
  "ernie-novel-8k.description": "ERNIE 小說 8K 專為長篇小說與 IP 情節創作打造，支援多角色敘事。",
  "ernie-speed-pro-128k.description": "ERNIE Speed Pro 128K 是一款高併發、高價值模型，適用於大規模線上服務與企業應用。",
  "ernie-x1-turbo-32k.description": "ERNIE X1 Turbo 32K 是一款快速思考模型，具備 32K 上下文，適合複雜推理與多輪對話。",
  "ernie-x1.1-preview.description": "ERNIE X1.1 預覽版是一款思考模型預覽，用於評估與測試。",
  "fal-ai/bytedance/seedream/v4.description": "Seedream 4.0 是來自字節跳動 Seed 團隊的圖像生成模型，支援文字與圖像輸入，具備高度可控性與高品質圖像生成能力，能根據文字提示生成圖像。",
  "fal-ai/flux-kontext/dev.description": "FLUX.1 模型專注於圖像編輯，支援文字與圖像輸入。",
  "fal-ai/flux-pro/kontext.description": "FLUX.1 Kontext [pro] 接受文字與參考圖像輸入，實現目標區域編輯與複雜場景轉換。",
  "fal-ai/flux/krea.description": "Flux Krea [dev] 是一款圖像生成模型，偏好更真實自然的美學風格。",
  "fal-ai/flux/schnell.description": "FLUX.1 [schnell] 是一款具備 120 億參數的圖像生成模型，專為快速高品質輸出打造。",
  "fal-ai/hunyuan-image/v3.description": "一款強大的原生多模態圖像生成模型。",
  "fal-ai/imagen4/preview.description": "來自 Google 的高品質圖像生成模型。",
  "fal-ai/nano-banana.description": "Nano Banana 是 Google 最新、最快且最高效的原生多模態模型，支援透過對話進行圖像生成與編輯。",
  "fal-ai/qwen-image-edit.description": "來自 Qwen 團隊的專業圖像編輯模型，支援語意與外觀編輯，能精確處理中英文文字，並實現風格轉換、物體旋轉等高品質編輯效果。",
  "fal-ai/qwen-image.description": "來自 Qwen 團隊的強大圖像生成模型，具備優異的中文文字呈現能力與多樣化的視覺風格。",
  "flux-1-schnell.description": "來自黑森林實驗室的 12B 參數文字轉圖像模型，透過潛在對抗擴散蒸餾技術，在 1 至 4 步內生成高品質圖像。其表現媲美封閉式替代方案，並以 Apache-2.0 授權釋出，供個人、研究與商業用途。",
  "flux-dev.description": "FLUX.1 [dev] 是一款開放權重的蒸餾模型，僅限非商業用途。它保有接近專業水準的圖像品質與指令遵循能力，同時運行更高效，資源使用優於同等大小的標準模型。",
  "flux-kontext-max.description": "最先進的語境圖像生成與編輯技術，結合文字與圖像輸入，實現精準且一致的結果。",
  "flux-kontext-pro.description": "最先進的語境圖像生成與編輯技術，結合文字與圖像輸入，實現精準且一致的結果。",
  "flux-merged.description": "FLUX.1-merged 結合了「DEV」版本的深層特徵與「Schnell」版本的高速優勢，拓展性能極限並擴大應用範圍。",
  "flux-pro-1.1-ultra.description": "支援 4MP 輸出的超高解析度圖像生成，10 秒內產出清晰圖像。",
  "flux-pro-1.1.description": "升級版專業級圖像生成模型，具備卓越圖像品質與精準提示遵循能力。",
  "flux-pro.description": "頂級商業圖像生成模型，擁有無與倫比的圖像品質與多樣化輸出能力。",
  "flux-schnell.description": "FLUX.1 [schnell] 是最先進的開源少步驟模型，超越同類競品，甚至優於如 Midjourney v6.0 與 DALL-E 3（HD）等強大非蒸餾模型。其精細調校保留預訓練多樣性，顯著提升視覺品質、指令遵循、尺寸與比例變化、字體處理與輸出多樣性。",
  "flux.1-schnell.description": "FLUX.1-schnell 是一款高效能圖像生成模型，支援快速多風格輸出。",
  "gemini-1.0-pro-001.description": "Gemini 1.0 Pro 001（調校版）在處理複雜任務時提供穩定且可調整的效能。",
  "gemini-1.0-pro-002.description": "Gemini 1.0 Pro 002（調校版）在處理複雜任務時提供強大的多模態支援。",
  "gemini-1.0-pro-latest.description": "Gemini 1.0 Pro 是 Google 所推出的高效能 AI 模型，專為大規模任務擴展而設計。",
  "gemini-1.5-flash-001.description": "Gemini 1.5 Flash 001 是一款高效率的多模態模型，適用於廣泛應用的擴展場景。",
  "gemini-1.5-flash-002.description": "Gemini 1.5 Flash 002 是一款高效率的多模態模型，專為大規模部署而打造。",
  "gemini-1.5-flash-8b-exp-0924.description": "Gemini 1.5 Flash 8B 0924 是最新的實驗性模型，在文字與多模態應用上有顯著提升。",
  "gemini-1.5-flash-8b-latest.description": "Gemini 1.5 Flash 8B 是一款高效率的多模態模型，專為大規模部署而設計。",
  "gemini-1.5-flash-8b.description": "Gemini 1.5 Flash 8B 是一款高效率的多模態模型，適用於廣泛應用的擴展場景。",
  "gemini-1.5-flash-exp-0827.description": "Gemini 1.5 Flash 0827 提供針對複雜任務的最佳化多模態處理能力。",
  "gemini-1.5-flash-latest.description": "Gemini 1.5 Flash 是 Google 最新的多模態 AI 模型，具備快速處理能力，支援文字、圖像與影片輸入，能高效擴展至各類任務。",
  "gemini-1.5-pro-001.description": "Gemini 1.5 Pro 001 是一款可擴展的多模態 AI 解決方案，適用於處理複雜任務。",
  "gemini-1.5-pro-002.description": "Gemini 1.5 Pro 002 是最新的生產就緒模型，輸出品質更高，特別適用於數學、長上下文與視覺任務。",
  "gemini-1.5-pro-exp-0801.description": "Gemini 1.5 Pro 0801 提供強大的多模態處理能力，並具備更高的應用開發彈性。",
  "gemini-1.5-pro-exp-0827.description": "Gemini 1.5 Pro 0827 採用最新優化技術，提升多模態處理效率。",
  "gemini-1.5-pro-latest.description": "Gemini 1.5 Pro 支援最多 200 萬個 token，是一款中型多模態模型，適合處理複雜任務。",
  "gemini-2.0-flash-001.description": "Gemini 2.0 Flash 提供次世代功能，包括極速處理、原生工具使用、多模態生成，以及 100 萬 token 的上下文視窗。",
  "gemini-2.0-flash-exp-image-generation.description": "Gemini 2.0 Flash 實驗性模型，支援圖像生成功能。",
  "gemini-2.0-flash-lite-001.description": "Gemini 2.0 Flash 的一個變體，針對成本效益與低延遲進行最佳化。",
  "gemini-2.0-flash-lite.description": "Gemini 2.0 Flash 的一個變體，針對成本效益與低延遲進行最佳化。",
  "gemini-2.0-flash.description": "Gemini 2.0 Flash 提供次世代功能，包括極速處理、原生工具使用、多模態生成，以及 100 萬 token 的上下文視窗。",
  "gemini-2.5-flash-image.description": "Nano Banana 是 Google 最新、最快且最有效率的原生多模態模型，支援對話式圖像生成與編輯。",
  "gemini-2.5-flash-image:image.description": "Nano Banana 是 Google 最新、最快且最有效率的原生多模態模型，支援對話式圖像生成與編輯。",
  "gemini-2.5-flash-lite-preview-06-17.description": "Gemini 2.5 Flash-Lite Preview 是 Google 體積最小、性價比最高的模型，專為大規模應用而設計。",
  "gemini-2.5-flash-lite-preview-09-2025.description": "Gemini 2.5 Flash-Lite 的預覽版本（2025 年 9 月 25 日）。",
  "gemini-2.5-flash-lite.description": "Gemini 2.5 Flash-Lite 是 Google 體積最小、性價比最高的模型，專為大規模應用而設計。",
  "gemini-2.5-flash-preview-04-17.description": "Gemini 2.5 Flash Preview 是 Google 功能最完整、性價比最高的模型。",
  "gemini-2.5-flash-preview-09-2025.description": "Gemini 2.5 Flash 的預覽版本（2025 年 9 月 25 日）。",
  "gemini-2.5-flash.description": "Gemini 2.5 Flash 是 Google 功能最完整、性價比最高的模型。",
  "gemini-2.5-pro-preview-03-25.description": "Gemini 2.5 Pro Preview 是 Google 最先進的推理模型，能處理程式碼、數學與 STEM 問題，並分析大型資料集、程式碼庫與長篇文件。",
  "gemini-2.5-pro-preview-05-06.description": "Gemini 2.5 Pro Preview 是 Google 最先進的推理模型，能處理程式碼、數學與 STEM 問題，並分析大型資料集、程式碼庫與長篇文件。",
  "gemini-2.5-pro-preview-06-05.description": "Gemini 2.5 Pro Preview 是 Google 最先進的推理模型，能處理程式碼、數學與 STEM 問題，並分析大型資料集、程式碼庫與長篇文件。",
  "gemini-2.5-pro.description": "Gemini 2.5 Pro 是 Google 的旗艦推理模型，支援長上下文，適用於處理複雜任務。",
  "gemini-3-flash-preview.description": "Gemini 3 Flash 是一款以速度為核心的智慧模型，結合尖端智能與卓越的搜尋基礎能力。",
  "gemini-3-pro-image-preview.description": "Gemini 3 Pro Image（Nano Banana Pro）是 Google 的圖像生成模型，支援多模態對話。",
  "gemini-3-pro-image-preview:image.description": "Gemini 3 Pro Image（Nano Banana Pro）是 Google 的圖像生成模型，同時支援多模態對話功能。",
  "gemini-3-pro-preview.description": "Gemini 3 Pro 是 Google 最強大的智能代理與情境編碼模型，具備頂尖推理能力、豐富視覺表現與深度互動。",
  "gemini-flash-latest.description": "Gemini Flash 最新版本",
  "gemini-flash-lite-latest.description": "Gemini Flash-Lite 最新版本",
  "gemini-pro-latest.description": "Gemini Pro 最新版本",
  "gemma-7b-it.description": "Gemma 7B 是一款適合中小型任務的高性價比模型。",
  "gemma2-9b-it.description": "Gemma 2 9B 專為特定任務與工具整合進行優化。",
  "gemma2.description": "Gemma 2 是 Google 的高效模型，涵蓋從小型應用到複雜資料處理的多種場景。",
  "gemma2:27b.description": "Gemma 2 是 Google 的高效模型，涵蓋從小型應用到複雜資料處理的多種場景。",
  "gemma2:2b.description": "Gemma 2 是 Google 的高效模型，涵蓋從小型應用到複雜資料處理的多種場景。",
  "generalv3.5.description": "Spark Max 是功能最完整的版本，支援網頁搜尋與多種內建插件。其核心能力、系統角色與函數調用皆經過全面優化，能在複雜應用場景中展現卓越表現。",
  "generalv3.description": "Spark Pro 是一款針對專業領域優化的高效能大型語言模型，專注於數學、程式設計、醫療與教育，支援網頁搜尋與天氣、日期等內建插件。其在複雜知識問答、語言理解與高階文本創作方面表現出色，是專業應用的理想選擇。",
  "glm-4-0520.description": "GLM-4-0520 是最新版本模型，專為高度複雜與多樣化任務設計，具備卓越效能。",
  "glm-4-7.description": "GLM-4.7 是智譜 AI 最新的旗艦模型。GLM-4.7 強化了程式能力、長期任務規劃與工具協作，適用於 Agentic Coding 場景，在多項公開基準測試中於開源模型中表現領先。其通用能力亦有所提升，回應更簡潔自然，寫作更具沉浸感。在複雜代理任務中，工具調用時的指令遵循能力更強，並進一步提升 Artifacts 與 Agentic Coding 前端的美學與長期任務完成效率。• 更強的程式能力：多語言編碼與終端代理表現顯著提升；GLM-4.7 現可在 Claude Code、Kilo Code、TRAE、Cline、Roo Code 等框架中實現「先思考，後行動」機制，處理複雜任務更穩定。• 前端美學提升：GLM-4.7 在前端生成品質上有顯著進展，能生成更具視覺吸引力的網站、簡報與海報。• 更強的工具調用能力：GLM-4.7 在 BrowseComp 網頁任務評估中得分 67，在 τ²-Bench 互動工具調用評估中得分 84.7，超越 Claude Sonnet 4.5，成為開源 SOTA。• 推理能力提升：數學與推理能力大幅增強，在 HLE（「人類最後考試」）基準測試中得分 42.8%，較 GLM-4.6 提升 41%，超越 GPT-5.1。• 通用能力增強：GLM-4.7 對話更簡潔、智慧且具人性；寫作與角色扮演更具文學性與沉浸感。",
  "glm-4-9b-chat.description": "GLM-4-9B-Chat 在語義、數學、推理、程式與知識方面表現優異，並支援網頁瀏覽、程式執行、自訂工具調用與長文本推理，支援包括日語、韓語、德語在內的 26 種語言。",
  "glm-4-air-250414.description": "GLM-4-Air 是一款高性價比選擇，效能接近 GLM-4，速度快且成本低。",
  "glm-4-air.description": "GLM-4-Air 是一款高性價比選擇，效能接近 GLM-4，速度快且成本低。",
  "glm-4-airx.description": "GLM-4-AirX 是 GLM-4-Air 的高效版本，推理速度提升至 2.6 倍。",
  "glm-4-alltools.description": "GLM-4-AllTools 是一款多功能智能體模型，針對複雜指令規劃與工具使用（如網頁瀏覽、程式解釋、文本生成）進行優化，適合多任務執行。",
  "glm-4-flash-250414.description": "GLM-4-Flash 適合簡單任務：速度最快且免費。",
  "glm-4-flash.description": "GLM-4-Flash 適合簡單任務：速度最快且免費。",
  "glm-4-flashx.description": "GLM-4-FlashX 是 Flash 的增強版，具備超快推理能力。",
  "glm-4-long.description": "GLM-4-Long 支援超長輸入，適用於記憶型任務與大規模文件處理。",
  "glm-4-plus.description": "GLM-4-Plus 是高智能旗艦模型，擅長處理長文本與複雜任務，整體效能全面升級。",
  "glm-4.1v-thinking-flash.description": "GLM-4.1V-Thinking 是目前已知最強的約 10B 視覺語言模型，涵蓋影片理解、圖像問答、學科解題、OCR、文件與圖表閱讀、GUI 智能體、前端編碼與語義對齊等 SOTA 任務。透過先進強化學習與思考鏈推理，提升準確性與豐富度，超越傳統非思考模型的結果與可解釋性。",
  "glm-4.1v-thinking-flashx.description": "GLM-4.1V-Thinking 是目前已知最強的約 10B 視覺語言模型，涵蓋影片理解、圖像問答、學科解題、OCR、文件與圖表閱讀、GUI 智能體、前端編碼與語義對齊等 SOTA 任務。透過先進強化學習與思考鏈推理，提升準確性與豐富度，超越傳統非思考模型的結果與可解釋性。",
  "glm-4.5-air.description": "GLM-4.5 輕量版，兼顧效能與成本，支援靈活的混合思考模式。",
  "glm-4.5-airx.description": "GLM-4.5-Air 快速版，回應更迅速，適用於大規模高速應用。",
  "glm-4.5-x.description": "GLM-4.5 快速版，生成速度高達每秒 100 個 token，效能出色。",
  "glm-4.5.description": "智譜旗艦模型，支援可切換思考模式，整體表現達開源 SOTA，支援最多 128K 上下文。",
  "glm-4.5v.description": "智譜新一代 MoE 視覺推理模型，總參數 106B，啟用 12B，於圖像、影片、文件理解與 GUI 任務中，在同級開源多模態模型中達到 SOTA 水準。",
  "glm-4.6.description": "智譜最新旗艦模型 GLM-4.6（3550 億參數）在高階編碼、長文本處理、推理與智能體能力上全面超越前代，程式能力與 Claude Sonnet 4 相當，成為中國頂尖的編碼模型。",
  "glm-4.7-flash.description": "GLM-4.7-Flash 作為 30B 級別的 SOTA 模型，提供在效能與效率間取得平衡的新選擇。它強化了程式能力、長期任務規劃與工具協作，適用於 Agentic Coding 場景，在多項當前基準排行榜中於同級開源模型中表現領先。在執行複雜智慧代理任務時，其工具調用的指令遵循能力更強，並進一步提升 Artifacts 與 Agentic Coding 前端的美學與長期任務完成效率。",
  "glm-4.7-flashx.description": "GLM-4.7-Flash 作為 30B 級別的 SOTA 模型，提供在效能與效率間取得平衡的新選擇。它強化了程式能力、長期任務規劃與工具協作，適用於 Agentic Coding 場景，在多項當前基準排行榜中於同級開源模型中表現領先。在執行複雜智慧代理任務時，其工具調用的指令遵循能力更強，並進一步提升 Artifacts 與 Agentic Coding 前端的美學與長期任務完成效率。",
  "glm-4.7.description": "GLM-4.7 是智譜最新旗艦模型，針對智能體編碼場景進行強化，提升了編碼能力、長期任務規劃與工具協作能力。在多個公開基準測試中於開源模型中表現領先。通用能力方面，回應更簡潔自然，寫作更具沉浸感。對於複雜智能體任務，工具調用時的指令遵循能力更強，並進一步提升了 Artifacts 與智能體編碼的前端美學與長期任務完成效率。",
  "glm-4.description": "GLM-4 是 2024 年 1 月推出的舊版旗艦模型，現已由更強的 GLM-4-0520 取代。",
  "glm-4v-flash.description": "GLM-4V-Flash 專注於單張圖像的高效理解，適用於即時或批次圖像處理等快速分析場景。",
  "glm-4v-plus-0111.description": "GLM-4V-Plus 能理解影片與多張圖像，適合多模態任務。",
  "glm-4v-plus.description": "GLM-4V-Plus 能理解影片與多張圖像，適合多模態任務。",
  "glm-4v.description": "GLM-4V 在各類視覺任務中展現強大的圖像理解與推理能力。",
  "glm-z1-air.description": "具備強大推理能力的模型，適用於需要深度推理的任務。",
  "glm-z1-airx.description": "超高速推理，兼具高品質推理表現。",
  "glm-z1-flash.description": "GLM-Z1 系列具備強大的複雜推理能力，擅長邏輯、數學與程式任務。",
  "glm-z1-flashx.description": "快速且低成本：Flash 增強版，具備超快推理與高併發能力。",
  "glm-zero-preview.description": "GLM-Zero-Preview 具備強大的複雜推理能力，擅長邏輯、數學與程式任務。",
  "global.anthropic.claude-opus-4-5-20251101-v1:0.description": "Claude Opus 4.5 是 Anthropic 的旗艦模型，結合卓越智慧與可擴展效能，專為需要高品質回應與推理的複雜任務而設計。",
  "google/gemini-2.0-flash-001.description": "Gemini 2.0 Flash 提供新一代能力，包括極速處理、原生工具使用、多模態生成，以及 100 萬 token 的上下文視窗。",
  "google/gemini-2.0-flash-lite-001.description": "Gemini 2.0 Flash Lite 是輕量版 Gemini，預設關閉思考功能以降低延遲與成本，但可透過參數啟用。",
  "google/gemini-2.0-flash-lite.description": "Gemini 2.0 Flash Lite 提供新一代功能，包括極速處理、內建工具使用、多模態生成，以及 100 萬 token 的上下文視窗。",
  "google/gemini-2.0-flash.description": "Gemini 2.0 Flash 是 Google 的高效能推理模型，適用於延伸多模態任務。",
  "google/gemini-2.5-flash-image-free.description": "Gemini 2.5 Flash Image 免費層，支援有限配額的多模態生成。",
  "google/gemini-2.5-flash-image-preview.description": "Gemini 2.5 Flash 實驗模型，支援圖像生成。",
  "google/gemini-2.5-flash-image.description": "Gemini 2.5 Flash Image（Nano Banana）是 Google 的圖像生成模型，支援多模態對話。",
  "google/gemini-2.5-flash-lite.description": "Gemini 2.5 Flash Lite 是 Gemini 2.5 的輕量版本，針對延遲與成本進行優化，適合高吞吐量場景。",
  "google/gemini-2.5-flash-preview.description": "Gemini 2.5 Flash 是 Google 最先進的旗艦模型，專為高階推理、程式設計、數學與科學任務打造。內建「思考」功能，能提供更高準確度與更細緻的上下文處理。\n\n注意：此模型有兩種變體——思考與非思考。啟用思考功能會產生額外費用。若選擇標準版本（無「:thinking」後綴），模型將避免生成思考 token。\n\n若需使用思考功能並接收思考 token，請選擇「:thinking」變體，將產生較高的輸出費用。\n\nGemini 2.5 Flash 亦可透過「max reasoning tokens」參數進行配置，詳見文件：https://openrouter.ai/docs/use-cases/reasoning-tokens#max-tokens-for-reasoning。",
  "google/gemini-2.5-flash-preview:thinking.description": "Gemini 2.5 Flash 是 Google 最先進的旗艦模型，專為高階推理、程式設計、數學與科學任務打造。內建「思考」功能，能提供更高準確度與更細緻的上下文處理。\n\n注意：此模型有兩種變體——思考與非思考。啟用思考功能會產生額外費用。若選擇標準版本（無「:thinking」後綴），模型將避免生成思考 token。\n\n若需使用思考功能並接收思考 token，請選擇「:thinking」變體，將產生較高的輸出費用。\n\nGemini 2.5 Flash 亦可透過「max reasoning tokens」參數進行配置，詳見文件：https://openrouter.ai/docs/use-cases/reasoning-tokens#max-tokens-for-reasoning。",
  "google/gemini-2.5-flash.description": "Gemini 2.5 Flash（Lite/Pro/Flash）是 Google 的模型家族，涵蓋低延遲至高效能推理應用。",
  "google/gemini-2.5-pro-free.description": "Gemini 2.5 Pro 免費層提供有限配額的多模態長上下文支援，適合試用與輕量工作流程。",
  "google/gemini-2.5-pro-preview.description": "Gemini 2.5 Pro Preview 是 Google 最先進的思考模型，適用於程式碼、數學與 STEM 領域的複雜推理，並能分析大型資料集、程式碼庫與長文件。",
  "google/gemini-2.5-pro.description": "Gemini 2.5 Pro 是 Google 的旗艦推理模型，支援長上下文處理，適用於複雜任務。",
  "google/gemini-3-pro-image-preview-free.description": "Gemini 3 Pro Image 免費層，支援有限配額的多模態生成。",
  "google/gemini-3-pro-image-preview.description": "Gemini 3 Pro Image（Nano Banana Pro）是 Google 的圖像生成模型，支援多模態對話。",
  "google/gemini-3-pro-preview-free.description": "Gemini 3 Pro Preview 免費版具備與標準版相同的多模態理解與推理能力，但有配額與速率限制，適合試用與低頻使用。",
  "google/gemini-3-pro-preview.description": "Gemini 3 Pro 是 Gemini 家族的次世代多模態推理模型，能理解文字、音訊、圖像與影片，處理複雜任務與大型程式碼庫。",
  "google/gemini-embedding-001.description": "一款最先進的嵌入模型，在英文、多語言與程式任務中表現優異。",
  "google/gemini-flash-1.5.description": "Gemini 1.5 Flash 提供針對複雜任務的多模態處理最佳化。",
  "google/gemini-pro-1.5.description": "Gemini 1.5 Pro 結合最新優化技術，提升多模態資料處理效率。",
  "google/gemma-2-27b-it.description": "Gemma 2 27B 是一款通用大型語言模型，在多種場景中表現出色。",
  "google/gemma-2-27b.description": "Gemma 2 是 Google 推出的高效模型家族，適用於從小型應用到複雜資料處理的各種場景。",
  "google/gemma-2-2b-it.description": "一款專為邊緣應用設計的先進小型語言模型。",
  "google/gemma-2-9b-it.description": "由 Google 開發的 Gemma 2 9B，具備高效的指令遵循能力與穩健的整體表現。",
  "google/gemma-2-9b-it:free.description": "Gemma 2 是 Google 推出的輕量級開源文字模型家族。",
  "google/gemma-2-9b.description": "Gemma 2 是 Google 推出的高效模型家族，適用於從小型應用到複雜資料處理的各種場景。",
  "google/gemma-2b-it.description": "Gemma Instruct (2B) 提供基礎指令處理能力，適用於輕量應用。",
  "google/gemma-3-12b-it.description": "Gemma 3 12B 是 Google 推出的開源語言模型，在效率與效能上樹立新標竿。",
  "google/gemma-3-27b-it.description": "Gemma 3 27B 是 Google 推出的開源語言模型，在效率與效能上樹立新標竿。",
  "google/text-embedding-005.description": "一款專注於英文的文字嵌入模型，針對程式與英文任務進行最佳化。",
  "google/text-multilingual-embedding-002.description": "一款多語言文字嵌入模型，針對跨語言任務進行最佳化，支援多種語言。",
  "gpt-3.5-turbo-0125.description": "GPT 3.5 Turbo 用於文字生成與理解，目前指向 gpt-3.5-turbo-0125。",
  "gpt-3.5-turbo-1106.description": "GPT 3.5 Turbo 用於文字生成與理解，目前指向 gpt-3.5-turbo-0125。",
  "gpt-3.5-turbo-instruct.description": "GPT 3.5 Turbo 用於文字生成與理解任務，針對指令遵循進行最佳化。",
  "gpt-3.5-turbo.description": "GPT 3.5 Turbo 用於文字生成與理解，目前指向 gpt-3.5-turbo-0125。",
  "gpt-35-turbo-16k.description": "GPT-3.5 Turbo 16k 是一款高容量文字生成模型，適用於複雜任務。",
  "gpt-35-turbo.description": "GPT-3.5 Turbo 是 OpenAI 推出的高效模型，支援聊天與文字生成，具備平行函數呼叫能力。",
  "gpt-4-0125-preview.description": "最新 GPT-4 Turbo 加入視覺功能。視覺請求支援 JSON 模式與函數呼叫。這是一款具成本效益的多模態模型，兼顧準確性與效率，適用於即時應用。",
  "gpt-4-0613.description": "GPT-4 提供更大的上下文視窗，能處理更長的輸入，適合廣泛資訊整合與資料分析。",
  "gpt-4-1106-preview.description": "最新 GPT-4 Turbo 加入視覺功能。視覺請求支援 JSON 模式與函數呼叫。這是一款具成本效益的多模態模型，兼顧準確性與效率，適用於即時應用。",
  "gpt-4-32k-0613.description": "GPT-4 提供更大的上下文視窗，能處理更長的輸入，適合需要廣泛資訊整合與資料分析的場景。",
  "gpt-4-32k.description": "GPT-4 提供更大的上下文視窗，能處理更長的輸入，適合需要廣泛資訊整合與資料分析的場景。",
  "gpt-4-turbo-2024-04-09.description": "最新 GPT-4 Turbo 加入視覺功能。視覺請求支援 JSON 模式與函數呼叫。這是一款具成本效益的多模態模型，兼顧準確性與效率，適用於即時應用。",
  "gpt-4-turbo-preview.description": "最新 GPT-4 Turbo 加入視覺功能。視覺請求支援 JSON 模式與函數呼叫。這是一款具成本效益的多模態模型，兼顧準確性與效率，適用於即時應用。",
  "gpt-4-turbo.description": "最新 GPT-4 Turbo 加入視覺功能。視覺請求支援 JSON 模式與函數呼叫。這是一款具成本效益的多模態模型，兼顧準確性與效率，適用於即時應用。",
  "gpt-4-vision-preview.description": "GPT-4 Vision 預覽版，專為圖像分析與處理任務設計。",
  "gpt-4.1-mini.description": "GPT-4.1 mini 在智慧、速度與成本之間取得平衡，適用於多種應用場景。",
  "gpt-4.1-nano.description": "GPT-4.1 nano 是 GPT-4.1 系列中最快且最具成本效益的模型。",
  "gpt-4.1.description": "GPT-4.1 是我們的旗艦模型，適用於複雜任務與跨領域問題解決。",
  "gpt-4.5-preview.description": "GPT-4.5-preview 是最新的通用模型，具備深厚的世界知識與更佳的意圖理解能力，擅長創意任務與智能代理規劃。知識截止時間為 2023 年 10 月。",
  "gpt-4.description": "GPT-4 提供更大的上下文視窗，能處理更長的輸入，適合廣泛資訊整合與資料分析。",
  "gpt-4o-2024-05-13.description": "ChatGPT-4o 是一款即時更新的動態模型，結合強大的理解與生成能力，適用於客服、教育與技術支援等大規模應用場景。",
  "gpt-4o-2024-08-06.description": "ChatGPT-4o 是一款即時更新的動態模型，結合強大的語言理解與生成能力，適用於客服、教育與技術支援等大規模應用場景。",
  "gpt-4o-2024-11-20.description": "ChatGPT-4o 是一款即時更新的動態模型，結合強大的理解與生成能力，適用於客服、教育與技術支援等大規模應用場景。",
  "gpt-4o-audio-preview.description": "GPT-4o 音訊預覽模型，支援音訊輸入與輸出。",
  "gpt-4o-mini-audio-preview.description": "GPT-4o mini 音訊模型，支援音訊輸入與輸出。",
  "gpt-4o-mini-realtime-preview.description": "GPT-4o-mini 即時變體，支援音訊與文字的即時輸入/輸出。",
  "gpt-4o-mini-search-preview.description": "GPT-4o mini 搜尋預覽模型，透過 Chat Completions API 訓練以理解並執行網頁搜尋查詢。網頁搜尋按工具呼叫次數額外計費。",
  "gpt-4o-mini-transcribe.description": "GPT-4o Mini Transcribe 是一款語音轉文字模型，使用 GPT-4o 進行音訊轉錄，提升詞錯率、語言識別與準確性，優於原始 Whisper 模型。",
  "gpt-4o-mini-tts.description": "GPT-4o mini TTS 是一款基於 GPT-4o mini 的文字轉語音模型，將文字轉換為自然語音，最多支援 2000 個 token 輸入。",
  "gpt-4o-mini.description": "GPT-4o mini 是 OpenAI 在 GPT-4 Omni 之後推出的最新模型，支援文字+圖片輸入與文字輸出。作為最先進的小型模型，其價格遠低於最新前沿模型，比 GPT-3.5 Turbo 便宜超過 60%，同時保有頂尖智慧（82% MMLU）。",
  "gpt-4o-realtime-preview-2024-10-01.description": "GPT-4o 即時變體，支援音訊與文字的即時輸入/輸出。",
  "gpt-4o-realtime-preview-2025-06-03.description": "GPT-4o 即時變體，支援音訊與文字的即時輸入/輸出。",
  "gpt-4o-realtime-preview.description": "GPT-4o 即時變體，支援音訊與文字的即時輸入/輸出。",
  "gpt-4o-search-preview.description": "GPT-4o 搜尋預覽模型，透過 Chat Completions API 訓練以理解並執行網頁搜尋查詢。網頁搜尋按工具呼叫次數額外計費。",
  "gpt-4o-transcribe.description": "GPT-4o Transcribe 是一款語音轉文字模型，使用 GPT-4o 進行音訊轉錄，提升詞錯率、語言識別與準確性，優於原始 Whisper 模型。",
  "gpt-4o.description": "ChatGPT-4o 是一款即時更新的動態模型，結合強大的理解與生成能力，適用於客服、教育與技術支援等大規模應用場景。",
  "gpt-5-chat-latest.description": "GPT-5 模型應用於 ChatGPT，結合強大的理解與生成能力，適用於對話應用。",
  "gpt-5-chat.description": "GPT-5 Chat 是一款預覽模型，針對對話場景進行最佳化。支援文字與圖片輸入，僅輸出文字，適用於聊天機器人與對話式 AI 應用。",
  "gpt-5-codex.description": "GPT-5 Codex 是 GPT-5 的變體，針對類似 Codex 環境中的智能編碼任務進行最佳化。",
  "gpt-5-mini.description": "GPT-5 的快速且具成本效益的變體，適用於明確任務，回應更快且維持品質。",
  "gpt-5-nano.description": "GPT-5 中最快且最具成本效益的變體，適用於對延遲與成本敏感的應用場景。",
  "gpt-5-pro.description": "GPT-5 Pro 使用更多運算資源以進行更深入思考，穩定提供更優質的答案。",
  "gpt-5.1-chat-latest.description": "GPT-5.1 Chat：GPT-5.1 的 ChatGPT 變體，專為對話場景打造。",
  "gpt-5.1-codex-mini.description": "GPT-5.1 Codex mini：較小且成本更低的 Codex 變體，針對智能編碼任務進行最佳化。",
  "gpt-5.1-codex.description": "GPT-5.1 Codex：GPT-5.1 的變體，針對複雜程式碼與智能體工作流程進行最佳化，適用於 Responses API。",
  "gpt-5.1.description": "GPT-5.1 — 旗艦模型，針對編碼與智能體任務進行最佳化，具備可調整的推理深度與更長的上下文支援。",
  "gpt-5.2-chat-latest.description": "GPT-5.2 Chat 是 ChatGPT 的最新對話版本，帶來最新的對話體驗改進。",
  "gpt-5.2-pro.description": "GPT-5.2 Pro：更智慧、更精確的 GPT-5.2 變體（僅限 Responses API），適用於高難度問題與多輪長推理。",
  "gpt-5.2.description": "GPT-5.2 是針對編碼與智能體工作流程的旗艦模型，具備更強推理能力與長上下文表現。",
  "gpt-5.description": "跨領域編碼與智能體任務的最佳模型。GPT-5 在準確性、速度、推理、上下文理解、結構化思維與問題解決方面實現飛躍。",
  "gpt-audio.description": "GPT Audio 是一款通用聊天模型，支援音訊輸入/輸出，並整合於 Chat Completions API 中。",
  "gpt-image-1-mini.description": "GPT Image 1 的低成本變體，原生支援文字與圖片輸入，並輸出圖片。",
  "gpt-image-1.5.description": "GPT Image 1 的增強版，生成速度提升 4 倍，編輯更精準，文字渲染效果更佳。",
  "gpt-image-1.description": "ChatGPT 原生多模態圖像生成模型。",
  "gpt-oss-120b.description": "需申請使用。GPT-OSS-120B 是 OpenAI 推出的開源大型語言模型，具備強大的文字生成能力。",
  "gpt-oss-20b.description": "需申請使用。GPT-OSS-20B 是 OpenAI 推出的中型開源語言模型，具備高效的文字生成能力。",
  "gpt-oss:120b.description": "GPT-OSS 120B 是 OpenAI 的大型開源 LLM，採用 MXFP4 量化，定位為旗艦模型。需多 GPU 或高階工作站環境，於複雜推理、程式碼生成與多語言處理方面表現優異，支援進階函式呼叫與工具整合。",
  "gpt-oss:20b.description": "GPT-OSS 20B 是 OpenAI 的開源 LLM，採用 MXFP4 量化，適用於高階消費級 GPU 或 Apple Silicon Mac。於對話生成、編碼與推理任務中表現良好，支援函式呼叫與工具使用。",
  "gpt-realtime.description": "通用即時模型，支援即時文字與音訊輸入/輸出，並支援圖片輸入。",
  "grok-2-image-1212.description": "我們最新的圖像生成模型可根據提示生成生動、寫實的圖像，特別適用於行銷、社群媒體與娛樂場景。",
  "grok-2-vision-1212.description": "提升了準確性、指令遵循能力與多語言支持。",
  "grok-3-mini.description": "一款在回應前先思考的輕量模型。適合不需深度領域知識的邏輯任務，具備快速反應與原始推理軌跡存取能力。",
  "grok-3.description": "旗艦模型，擅長企業應用如資料擷取、程式編寫與摘要，具備金融、醫療、法律與科學等領域的深度知識。",
  "grok-4-0709.description": "xAI 的 Grok 4，具備強大的推理能力。",
  "grok-4-1-fast-non-reasoning.description": "前沿多模態模型，針對高效能智能體工具使用進行優化。",
  "grok-4-1-fast-reasoning.description": "前沿多模態模型，針對高效能智能體工具使用進行優化。",
  "grok-4-fast-non-reasoning.description": "我們很高興推出 Grok 4 Fast，這是我們在高性價比推理模型上的最新進展。",
  "grok-4-fast-reasoning.description": "我們很高興推出 Grok 4 Fast，這是我們在高性價比推理模型上的最新進展。",
  "grok-4.description": "我們最新且最強大的旗艦模型，在自然語言處理、數學與推理方面表現卓越，是理想的全能型模型。",
  "grok-code-fast-1.description": "我們很高興推出 grok-code-fast-1，一款快速且高性價比的推理模型，特別擅長智能體編碼。",
  "groq/compound-mini.description": "Compound-mini 是一個由 GroqCloud 支援的複合式 AI 系統，整合多個公開模型，能智慧選擇工具來回應用戶查詢。",
  "groq/compound.description": "Compound 是一個由 GroqCloud 支援的複合式 AI 系統，整合多個公開模型，能智慧選擇工具來回應用戶查詢。",
  "gryphe/mythomax-l2-13b.description": "MythoMax L2 13B 是一款融合多個頂尖模型的創意型智慧語言模型。",
  "hunyuan-a13b.description": "混合推理模型 Hunyuan-A13B，從 hunyuan-standard-256K（總參數 800 億，活躍參數 130 億）升級而來。預設為慢思考模式，並可透過參數或前綴 /no_think 切換快／慢思考。整體能力較前代大幅提升，特別是在數學、科學、長文本理解與智能體任務方面。",
  "hunyuan-code.description": "最新程式碼生成模型，使用 2000 億高品質程式碼與六個月 SFT 訓練，支援 8K 上下文。在五種語言的自動化基準測試中名列前茅，並在十項人工評估指標中表現優異。",
  "hunyuan-functioncall.description": "最新 MoE FunctionCall 模型，使用高品質函數調用數據訓練，具備 32K 上下文視窗，在多項基準測試中表現領先。",
  "hunyuan-large-longcontext.description": "擅長長文檔任務如摘要與問答，同時具備通用生成能力。對於複雜、細節豐富內容的長文本分析與生成表現出色。",
  "hunyuan-large-vision.description": "由 Hunyuan Large 訓練的視覺語言模型，支援多圖＋文字輸入，解析度不限，並提升多語言視覺理解能力。",
  "hunyuan-large.description": "Hunyuan-large 擁有約 3890 億總參數與約 520 億活躍參數，是目前最大且最強的開源 MoE Transformer 架構模型。",
  "hunyuan-lite-vision.description": "最新 70 億參數多模態模型，具備 32K 上下文視窗，支援中英文多模態對話、物體識別、文檔表格理解與多模態數學，在多項基準測試中超越同級模型。",
  "hunyuan-lite.description": "升級為 MoE 架構，支援 256K 上下文視窗，在 NLP、程式碼、數學與產業基準測試中領先多數開源模型。",
  "hunyuan-pro.description": "兆級參數 MOE-32K 長上下文模型，在複雜指令與推理、高階數學、函數調用方面表現優異，並針對多語翻譯、金融、法律與醫療領域進行優化。",
  "hunyuan-role.description": "最新角色扮演模型，經過角色扮演數據集精調，為角色扮演場景提供更強的基礎表現。",
  "hunyuan-standard-256K.description": "透過改進路由機制減少負載不均與專家崩潰問題。在長上下文中達成 99.9% 的 needle-in-a-haystack 成就。MOE-256K 進一步擴展上下文長度與品質。",
  "hunyuan-standard-vision.description": "最新多模態模型，具備多語言回應能力，中英文表現均衡。",
  "hunyuan-standard.description": "透過改進路由機制減少負載不均與專家崩潰問題。在長上下文中達成 99.9% 的 needle-in-a-haystack 成就。MOE-32K 提供強大價值並能處理長輸入。",
  "hunyuan-t1-20250321.description": "在文藝與 STEM 能力間取得平衡，具備強大的長文本資訊捕捉能力。支援數學、邏輯、科學與程式問題的推理解答，涵蓋各種難度。",
  "hunyuan-t1-20250403.description": "提升專案級程式碼生成與寫作品質，加強多輪主題理解與 ToB 指令遵循，改善詞彙層級理解，減少簡繁混用與中英混雜輸出問題。",
  "hunyuan-t1-20250529.description": "提升創意寫作與作文能力，加強前端編碼、數學與邏輯推理，並增強指令遵循能力。",
  "hunyuan-t1-20250711.description": "大幅提升高難度數學、邏輯與程式能力，增強輸出穩定性與長文本處理能力。",
  "hunyuan-t1-latest.description": "顯著提升慢思考模型在高難度數學、複雜推理、困難編碼、指令遵循與創意寫作品質方面的表現。",
  "hunyuan-t1-vision-20250619.description": "最新 t1-vision 多模態深度推理模型，具備原生長鏈思維，較前代預設版本有顯著提升。",
  "hunyuan-t1-vision-20250916.description": "最新 t1-vision 深度推理模型，在 VQA、視覺對齊、OCR、圖表、拍照題解與圖像創作方面有重大突破，並強化英文與低資源語言能力。",
  "hunyuan-turbo-20241223.description": "本版本提升指令擴展能力以增強泛化性，顯著改善數學／程式／邏輯推理，增強詞彙層級理解與寫作品質。",
  "hunyuan-turbo-latest.description": "在 NLP 理解、寫作、對話、問答、翻譯與專業領域方面全面提升體驗；回應更具人性化，對模糊意圖澄清更佳，詞彙解析更準確，創意與互動性更高，多輪對話能力更強。",
  "hunyuan-turbo-vision.description": "下一代視覺語言旗艦模型，採用全新 MoE 架構，在識別、內容創作、知識問答與分析推理方面全面升級。",
  "hunyuan-turbo.description": "混元下一代大型語言模型預覽版，採用全新 MoE 架構，推理速度更快，整體表現超越 hunyuan-pro。",
  "hunyuan-turbos-20250313.description": "統一數學解題風格，加強多輪數學問答。寫作風格更自然，減少 AI 感，提升語言潤色。",
  "hunyuan-turbos-20250416.description": "升級預訓練基座以提升指令理解與遵循能力；對齊強化數學、程式、邏輯與科學能力；改善寫作品質、閱讀理解、翻譯準確性與知識問答；加強智能體能力，特別是多輪理解。",
  "hunyuan-turbos-20250604.description": "升級預訓練基座，提升寫作與閱讀理解能力，在程式與 STEM 領域取得重大進展，並改善複雜指令遵循能力。",
  "hunyuan-turbos-20250926.description": "升級預訓練數據品質與後訓練策略，提升智能體能力、英文與低資源語言表現、指令遵循、程式與 STEM 能力。",
  "hunyuan-turbos-latest.description": "最新混元 TurboS 旗艦模型，推理能力更強，整體體驗更佳。",
  "hunyuan-turbos-longtext-128k-20250325.description": "擅長長文檔任務如摘要與問答，同時具備通用生成能力。對於複雜、細節豐富內容的長文本分析與生成表現出色。",
  "hunyuan-turbos-role-plus.description": "最新角色扮演模型，經過角色扮演數據集精調，為角色扮演場景提供更強的基礎表現。",
  "hunyuan-turbos-vision-20250619.description": "最新 TurboS 視覺語言旗艦模型，在圖文任務如實體識別、知識問答、文案撰寫與拍照題解方面取得重大進展。",
  "hunyuan-turbos-vision.description": "基於最新 TurboS 的下一代視覺語言旗艦模型，專注於圖文理解任務，如實體識別、知識問答、文案撰寫與拍照題解。",
  "hunyuan-vision-1.5-instruct.description": "基於文本 TurboS 基座打造的圖生文快思考模型，較前代在圖像基礎識別、圖像分析推理等方面有明顯提升。",
  "hunyuan-vision.description": "最新多模態模型，支援圖像＋文字輸入以生成文字。",
  "image-01-live.description": "一款具備精細細節的圖像生成模型，支援文字轉圖像與可控風格預設。",
  "image-01.description": "一款全新圖像生成模型，具備精細細節，支援文字轉圖像與圖像轉圖像功能。",
  "imagen-4.0-fast-generate-001.description": "Imagen 第四代文字轉圖像模型系列的快速版本",
  "imagen-4.0-generate-001.description": "Imagen 第四代文字轉圖像模型系列",
  "imagen-4.0-generate-preview-06-06.description": "Imagen 第四代文字轉圖像模型家族。",
  "imagen-4.0-ultra-generate-001.description": "Imagen 第四代文字轉圖像模型系列的超高版本",
  "imagen-4.0-ultra-generate-preview-06-06.description": "Imagen 第四代文字轉圖像模型的 Ultra 變體。",
  "inception/mercury-coder-small.description": "Mercury Coder Small 是一款適用於程式碼生成、除錯與重構的低延遲模型。",
  "inclusionAI/Ling-flash-2.0.description": "Ling-flash-2.0 是螞蟻集團百靈團隊推出的第三款 Ling 2.0 架構模型。該模型為 MoE 架構，總參數量為 1000 億，但每個 token 僅啟用 61 億參數（不含嵌入為 48 億）。儘管配置輕量，卻在多項基準測試中與 400 億密集模型甚至更大型 MoE 模型相媲美甚至超越，展現出透過架構與訓練策略實現高效能的潛力。",
  "inclusionAI/Ling-mini-2.0.description": "Ling-mini-2.0 是一款小型高效能 MoE 大語言模型，總參數為 160 億，每個 token 僅啟用 14 億參數（不含嵌入為 7.89 億），具備極快的生成速度。透過高效的 MoE 設計與大量高品質訓練資料，其效能可媲美 100 億以下的密集模型與更大型的 MoE 模型。",
  "inclusionAI/Ring-flash-2.0.description": "Ring-flash-2.0 是從 Ling-flash-2.0-base 優化而來的高效能推理模型。採用 MoE 架構，總參數為 1000 億，每次推理僅啟用 61 億參數。其 icepop 演算法穩定了 MoE 模型的強化學習訓練，使其在複雜推理任務中持續進步。該模型在數學競賽、程式碼生成與邏輯推理等嚴苛基準測試中取得重大突破，超越 400 億以下的密集模型，並可與更大型的開源或封閉推理模型匹敵。它在創意寫作方面也表現出色，且其高效架構可在高併發場景下以較低部署成本實現快速推理。",
  "inclusionai/ling-1t.description": "Ling-1T 是 inclusionAI 推出的 1 兆參數 MoE 模型，專為高強度推理任務與大上下文工作負載而優化。",
  "inclusionai/ling-flash-2.0.description": "Ling-flash-2.0 是 inclusionAI 推出的 MoE 模型，針對效率與推理效能進行優化，適用於中大型任務。",
  "inclusionai/ling-mini-2.0.description": "Ling-mini-2.0 是 inclusionAI 推出的輕量級 MoE 模型，在大幅降低成本的同時保有推理能力。",
  "inclusionai/ming-flash-omini-preview.description": "Ming-flash-omni 預覽版是 inclusionAI 的多模態模型，支援語音、圖像與影片輸入，並提升了圖像渲染與語音辨識能力。",
  "inclusionai/ring-1t.description": "Ring-1T 是 inclusionAI 推出的兆級參數 MoE 推理模型，適用於大規模推理與研究任務。",
  "inclusionai/ring-flash-2.0.description": "Ring-flash-2.0 是 inclusionAI 推出的 Ring 模型變體，專為高吞吐量場景設計，強調速度與成本效益。",
  "inclusionai/ring-mini-2.0.description": "Ring-mini-2.0 是 inclusionAI 推出的高吞吐量輕量級 MoE 模型，專為高併發場景打造。",
  "internlm/internlm2_5-7b-chat.description": "InternLM2.5-7B-Chat 是基於 InternLM2 架構的開源聊天模型。該 70 億參數模型專注於中英文對話生成，採用現代化訓練方法，實現流暢且智慧的對話體驗，適用於客服、個人助理等多種聊天場景。",
  "internlm2.5-latest.description": "歷經多次迭代後仍維持優異穩定表現的舊版模型。提供 70 億與 200 億版本，支援 100 萬上下文長度，具備更強的指令遵循與工具使用能力。預設為最新 InternLM2.5 系列（目前為 internlm2.5-20b-chat）。",
  "internlm3-latest.description": "我們最新的模型系列，具備卓越的推理能力，在同級開源模型中表現領先。預設為最新 InternLM3 系列（目前為 internlm3-8b-instruct）。",
  "internvl2.5-38b-mpo.description": "InternVL2.5 38B MPO 是一款多模態預訓練模型，專為複雜圖文推理任務設計。",
  "internvl2.5-latest.description": "InternVL2.5 維持穩定且強大的表現。預設為最新 InternVL2.5 系列（目前為 internvl2.5-78b）。",
  "internvl3-14b.description": "InternVL3 14B 是一款中型多模態模型，在效能與成本之間取得平衡。",
  "internvl3-1b.description": "InternVL3 1B 是一款輕量級多模態模型，適合資源受限的部署場景。",
  "internvl3-38b.description": "InternVL3 38B 是一款大型開源多模態模型，專為高準確度圖文理解任務設計。",
  "internvl3-latest.description": "我們最新的多模態模型，具備更強的圖文理解與長序列圖像理解能力，表現可媲美頂級封閉模型。預設為最新 InternVL 系列（目前為 internvl3-78b）。",
  "irag-1.0.description": "ERNIE iRAG 是一款圖像檢索增強生成模型，支援圖像搜尋、圖文檢索與內容生成任務。",
  "jamba-large.description": "我們最強大、最先進的模型，專為複雜企業任務設計，具備卓越效能。",
  "jamba-mini.description": "同級中最具效率的模型，在速度與品質之間取得平衡，佔用資源更少。",
  "jina-deepsearch-v1.description": "DeepSearch 結合網頁搜尋、閱讀與推理，進行深入調查。它如同一位代理人，接收你的研究任務後，進行多輪廣泛搜尋，最終才產出答案。整個過程包含持續研究、推理與多角度問題解決，與僅依賴預訓練資料的標準 LLM 或一次性檢索的傳統 RAG 系統截然不同。",
  "kimi-k2-0711-preview.description": "kimi-k2 是一款具備強大程式編寫與智能代理能力的 MoE 基礎模型（總參數量達 1 兆，啟用參數為 320 億），在推理、程式設計、數學與代理任務的基準測試中表現優於其他主流開源模型。",
  "kimi-k2-0905-preview.description": "kimi-k2-0905-preview 提供 256k 上下文視窗，具備更強的代理程式能力、更優質的前端程式碼品質，以及更佳的上下文理解能力。",
  "kimi-k2-instruct.description": "Kimi K2 Instruct 是 Kimi 官方推出的推理模型，支援長上下文，適用於程式碼、問答等多種任務。",
  "kimi-k2-thinking-turbo.description": "高速版 K2 長思考模型，支援 256k 上下文，具備強大的深度推理能力，輸出速度達 60–100 tokens/秒。",
  "kimi-k2-thinking.description": "kimi-k2-thinking 是 Moonshot AI 推出的思考模型，具備通用代理與推理能力，擅長深度推理，能透過多步驟工具使用解決複雜問題。",
  "kimi-k2-turbo-preview.description": "kimi-k2 是一款具備強大程式編寫與智能代理能力的 MoE 基礎模型（總參數量達 1 兆，啟用參數為 320 億），在推理、程式設計、數學與代理任務的基準測試中表現優於其他主流開源模型。",
  "kimi-k2.5.description": "Kimi K2.5 是最強大的 Kimi 模型，在代理任務、程式設計與視覺理解方面達到開源 SOTA 水準。支援多模態輸入與思考/非思考模式切換。",
  "kimi-k2.description": "Kimi-K2 是 Moonshot AI 推出的 MoE 基礎模型，具備強大的程式編寫與代理能力，總參數達 1 兆，啟用參數為 320 億。在通用推理、程式設計、數學與代理任務的基準測試中，表現優於其他主流開源模型。",
  "kimi-k2:1t.description": "Kimi K2 是 Moonshot AI 推出的大型 MoE 語言模型，總參數達 1 兆，每次前向傳遞啟用 320 億參數。針對代理能力進行最佳化，包括進階工具使用、推理與程式碼生成。",
  "kimi-latest.description": "Kimi Latest 採用最新版本的 Kimi 模型，可能包含實驗性功能。支援圖像理解，並根據上下文長度自動選擇 8k/32k/128k 計費模型。",
  "kuaishou/kat-coder-pro-v1.description": "KAT-Coder-Pro-V1（限時免費）專注於程式碼理解與自動化，提升程式代理效率。",
  "learnlm-1.5-pro-experimental.description": "LearnLM 是一款實驗性任務導向模型，基於學習科學原則訓練，能在教學/學習場景中遵循系統指令，扮演專業導師角色。",
  "learnlm-2.0-flash-experimental.description": "LearnLM 是一款實驗性任務導向模型，基於學習科學原則訓練，能在教學/學習場景中遵循系統指令，扮演專業導師角色。",
  "lite.description": "Spark Lite 是一款輕量級語言模型，具備超低延遲與高效處理能力，完全免費，支援即時網頁搜尋。其快速回應在低算力設備與模型微調場景中表現優異，特別適用於知識問答、內容生成與搜尋應用。",
  "llama-3.1-70b-versatile.description": "Llama 3.1 70B 提供更強的 AI 推理能力，適用於複雜應用，支援高效能運算與高準確度。",
  "llama-3.1-8b-instant.description": "Llama 3.1 8B 是一款高效率模型，具備快速文字生成能力，適合大規模、具成本效益的應用場景。",
  "llama-3.1-instruct.description": "Llama 3.1 指令微調模型針對對話進行最佳化，在多項業界基準測試中超越多數開源對話模型。",
  "llama-3.2-11b-vision-instruct.description": "具備高解析度圖像推理能力，適用於視覺理解應用。",
  "llama-3.2-11b-vision-preview.description": "Llama 3.2 專為結合視覺與文字任務設計，擅長圖像描述與視覺問答，實現語言生成與視覺推理的橋接。",
  "llama-3.2-90b-vision-instruct.description": "進階圖像推理能力，適用於視覺理解型代理應用。",
  "llama-3.2-90b-vision-preview.description": "Llama 3.2 專為結合視覺與文字任務設計，擅長圖像描述與視覺問答，實現語言生成與視覺推理的橋接。",
  "llama-3.2-vision-instruct.description": "Llama 3.2-Vision 指令微調模型針對視覺辨識、圖像推理、圖像描述與一般圖像問答進行最佳化。",
  "llama-3.3-70b-versatile.description": "Meta Llama 3.3 是一款多語言大型語言模型，擁有 700 億參數（文字輸入/輸出），提供預訓練與指令微調版本。文字專用指令微調模型針對多語言對話進行最佳化，在多項業界基準測試中超越多數開放與封閉對話模型。",
  "llama-3.3-70b.description": "Llama 3.3 70B：中大型 Llama 模型，在推理能力與處理效率間取得平衡。",
  "llama-3.3-instruct.description": "Llama 3.3 指令微調模型針對對話進行最佳化，在多項業界基準測試中超越多數開源對話模型。",
  "llama3-70b-8192.description": "Meta Llama 3 70B 具備卓越的複雜任務處理能力，適用於高需求專案。",
  "llama3-8b-8192.description": "Meta Llama 3 8B 在多樣化場景中展現強大的推理能力。",
  "llama3-groq-70b-8192-tool-use-preview.description": "Llama 3 Groq 70B Tool Use 提供強大的工具調用能力，能高效處理複雜任務。",
  "llama3-groq-8b-8192-tool-use-preview.description": "Llama 3 Groq 8B Tool Use 針對高效工具使用進行最佳化，支援快速並行運算。",
  "llama3.1-8b.description": "Llama 3.1 8B：小型、低延遲的 Llama 變體，適用於輕量級線上推理與對話。",
  "llama3.1.description": "Llama 3.1 是 Meta 的旗艦模型，規模可達 4050 億參數，適用於複雜對話、多語言翻譯與資料分析。",
  "llama3.1:405b.description": "Llama 3.1 是 Meta 的旗艦模型，規模可達 4050 億參數，適用於複雜對話、多語言翻譯與資料分析。",
  "llama3.1:70b.description": "Llama 3.1 是 Meta 的旗艦模型，規模可達 4050 億參數，適用於複雜對話、多語言翻譯與資料分析。",
  "llava-v1.5-7b-4096-preview.description": "LLaVA 1.5 7B 結合視覺處理能力，能從視覺輸入中生成複雜輸出。",
  "llava.description": "LLaVA 是一款多模態模型，結合視覺編碼器與 Vicuna，具備強大的視覺-語言理解能力。",
  "llava:13b.description": "LLaVA 是一款多模態模型，結合視覺編碼器與 Vicuna，具備強大的視覺-語言理解能力。",
  "llava:34b.description": "LLaVA 是一款多模態模型，結合視覺編碼器與 Vicuna，具備強大的視覺-語言理解能力。",
  "magistral-medium-latest.description": "Magistral Medium 1.2 是 Mistral AI 推出的前沿推理模型（2025 年 9 月），支援視覺任務。",
  "magistral-small-2509.description": "Magistral Small 1.2 是 Mistral AI 推出的開源小型推理模型（2025 年 9 月），支援視覺任務。",
  "mathstral.description": "MathΣtral 專為科學研究與數學推理設計，具備強大的計算與解釋能力。",
  "max-32k.description": "Spark Max 32K 提供大上下文處理能力，具備更強的上下文理解與邏輯推理能力，支援 32K token 輸入，適用於長文閱讀與私有知識問答。",
  "megrez-3b-instruct.description": "Megrez 3B Instruct 是來自無問星穹的小型高效模型。",
  "meituan/longcat-flash-chat.description": "來自美團的開源非思考型基礎模型，針對對話與代理任務進行最佳化，擅長工具使用與複雜多輪互動。",
  "meta-llama-3-70b-instruct.description": "一款擁有 700 億參數的強大模型，擅長推理、程式設計與多語言任務。",
  "meta-llama-3-8b-instruct.description": "一款多功能的 80 億參數模型，針對對話與文字生成進行優化。",
  "meta-llama-3.1-405b-instruct.description": "Llama 3.1 指令微調文字模型，針對多語言對話進行優化，在開源與封閉模型中於業界基準測試表現優異。",
  "meta-llama-3.1-70b-instruct.description": "Llama 3.1 指令微調文字模型，針對多語言對話進行優化，在開源與封閉模型中於業界基準測試表現優異。",
  "meta-llama-3.1-8b-instruct.description": "Llama 3.1 指令微調文字模型，針對多語言對話進行優化，在開源與封閉模型中於業界基準測試表現優異。",
  "meta-llama/Llama-2-13b-chat-hf.description": "LLaMA-2 Chat（13B）具備強大的語言處理能力與穩定的對話體驗。",
  "meta-llama/Llama-2-70b-hf.description": "LLaMA-2 提供強大的語言處理能力與穩定的互動體驗。",
  "meta-llama/Llama-3-70b-chat-hf.description": "Llama 3 70B Instruct Reference 是一款適用於複雜對話的強大聊天模型。",
  "meta-llama/Llama-3-8b-chat-hf.description": "Llama 3 8B Instruct Reference 提供多語言支援與廣泛的領域知識。",
  "meta-llama/Llama-3.2-11B-Vision-Instruct-Turbo.description": "LLaMA 3.2 專為結合視覺與文字的任務設計，擅長圖像描述與視覺問答，連結語言生成與視覺推理。",
  "meta-llama/Llama-3.2-3B-Instruct-Turbo.description": "LLaMA 3.2 專為結合視覺與文字的任務設計，擅長圖像描述與視覺問答，連結語言生成與視覺推理。",
  "meta-llama/Llama-3.2-90B-Vision-Instruct-Turbo.description": "LLaMA 3.2 專為結合視覺與文字的任務設計，擅長圖像描述與視覺問答，連結語言生成與視覺推理。",
  "meta-llama/Llama-3.3-70B-Instruct-Turbo.description": "Meta Llama 3.3 多語言大型語言模型，為 70B（文字輸入/輸出）預訓練並指令微調版本。此文字指令微調版本針對多語言對話進行優化，在開源與封閉模型中於業界基準測試表現優異。",
  "meta-llama/Llama-Vision-Free.description": "LLaMA 3.2 專為結合視覺與文字的任務設計，擅長圖像描述與視覺問答，連結語言生成與視覺推理。",
  "meta-llama/Meta-Llama-3-70B-Instruct-Lite.description": "Llama 3 70B Instruct Lite 針對高效能與低延遲進行設計。",
  "meta-llama/Meta-Llama-3-70B-Instruct-Turbo.description": "Llama 3 70B Instruct Turbo 提供強大的理解與生成能力，適用於最嚴苛的工作負載。",
  "meta-llama/Meta-Llama-3-8B-Instruct-Lite.description": "Llama 3 8B Instruct Lite 在資源受限環境中平衡效能與效率。",
  "meta-llama/Meta-Llama-3-8B-Instruct-Turbo.description": "Llama 3 8B Instruct Turbo 是一款高效能大型語言模型，適用於多種應用場景。",
  "meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo.description": "405B Llama 3.1 Turbo 模型具備超大上下文容量，適用於大數據處理與超大規模 AI 應用。",
  "meta-llama/Meta-Llama-3.1-405B-Instruct.description": "Llama 3.1 是 Meta 領先的模型系列，參數規模高達 405B，適用於複雜對話、多語言翻譯與資料分析。",
  "meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo.description": "Llama 3.1 70B 為高負載應用精細調整；FP8 量化實現高效運算與複雜場景下的準確性。",
  "meta-llama/Meta-Llama-3.1-70B.description": "Llama 3.1 是 Meta 領先的模型系列，參數規模高達 405B，適用於複雜對話、多語言翻譯與資料分析。",
  "meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo.description": "Llama 3.1 8B 採用 FP8 量化，支援最多 131,072 個上下文 token，在多項基準測試中名列前茅，適合處理複雜任務。",
  "meta-llama/llama-3-70b-instruct.description": "Llama 3 70B Instruct 針對高品質對話進行優化，在人類評估中表現優異。",
  "meta-llama/llama-3-8b-instruct.description": "Llama 3 8B Instruct 針對高品質對話進行優化，表現超越多數封閉模型。",
  "meta-llama/llama-3.1-70b-instruct.description": "Meta 最新的 Llama 3.1 系列，70B 指令微調版本，針對高品質對話進行優化。在業界評估中，表現優於多數封閉模型。（僅限企業驗證用戶使用）",
  "meta-llama/llama-3.1-8b-instruct.description": "Meta 最新的 Llama 3.1 系列，8B 指令微調版本，速度快且效率高。在業界評估中表現優異，超越多數封閉模型。（僅限企業驗證用戶使用）",
  "meta-llama/llama-3.1-8b-instruct:free.description": "LLaMA 3.1 提供多語言支援，是領先的生成式模型之一。",
  "meta-llama/llama-3.2-11b-vision-instruct.description": "LLaMA 3.2 專為結合視覺與文字的任務設計，擅長圖像描述與視覺問答，連結語言生成與視覺推理。",
  "meta-llama/llama-3.2-3b-instruct.description": "meta-llama/llama-3.2-3b-instruct",
  "meta-llama/llama-3.2-90b-vision-instruct.description": "LLaMA 3.2 專為結合視覺與文字的任務設計，擅長圖像描述與視覺問答，連結語言生成與視覺推理。",
  "meta-llama/llama-3.3-70b-instruct.description": "Llama 3.3 是最先進的多語言開源 Llama 模型，以極低成本提供接近 405B 的效能。基於 Transformer 架構，並透過 SFT 與 RLHF 提升實用性與安全性。指令微調版本針對多語言對話進行優化，在業界基準測試中超越多數開源與封閉模型。知識截止時間：2023 年 12 月。",
  "meta-llama/llama-3.3-70b-instruct:free.description": "Llama 3.3 是最先進的多語言開源 Llama 模型，以極低成本提供接近 405B 的效能。基於 Transformer 架構，並透過 SFT 與 RLHF 提升實用性與安全性。指令微調版本針對多語言對話進行優化，在業界基準測試中超越多數開源與封閉模型。知識截止時間：2023 年 12 月。",
  "meta.llama3-1-405b-instruct-v1:0.description": "Meta Llama 3.1 405B Instruct 是 Llama 3.1 Instruct 系列中最大且最強的模型，專為對話推理與合成資料生成設計，亦是領域特定持續預訓練或微調的強大基礎。Llama 3.1 多語言 LLM 系列包含 8B、70B 與 405B 模型，經過預訓練與指令微調，優化多語言對話，並在多項業界基準中超越其他開源聊天模型。Llama 3.1 適用於商業與研究用途，指令微調模型適合助理型對話，預訓練模型則適用於更廣泛的自然語言生成任務。其輸出亦可用於改進其他模型，包括合成資料生成與優化。Llama 3.1 採用自回歸 Transformer 架構，經由監督式微調（SFT）與人類回饋強化學習（RLHF）對齊人類偏好，提升有用性與安全性。",
  "meta.llama3-1-70b-instruct-v1:0.description": "更新版 Meta Llama 3.1 70B Instruct，具備 128K 擴展上下文視窗、多語言支援與更強推理能力。Llama 3.1 多語言 LLM 系列包含 8B、70B 與 405B 模型，經過預訓練與指令微調，優化多語言對話，並在多項業界基準中超越其他開源聊天模型。Llama 3.1 適用於商業與研究用途，指令微調模型適合助理型對話，預訓練模型則適用於更廣泛的自然語言生成任務。其輸出亦可用於改進其他模型，包括合成資料生成與優化。Llama 3.1 採用自回歸 Transformer 架構，經由監督式微調（SFT）與人類回饋強化學習（RLHF）對齊人類偏好，提升有用性與安全性。",
  "meta.llama3-1-8b-instruct-v1:0.description": "更新版 Meta Llama 3.1 8B Instruct，具備 128K 上下文視窗、多語言支援與更強推理能力。Llama 3.1 系列包含 8B、70B 與 405B 指令微調模型，優化多語言對話並在基準測試中表現優異。適用於跨語言的商業與研究用途；指令微調模型適合助理型對話，預訓練模型則適用於更廣泛的生成任務。其輸出亦可用於改進其他模型（如合成資料與優化）。此為自回歸 Transformer 模型，透過 SFT 與 RLHF 對齊人類偏好，提升有用性與安全性。",
  "meta.llama3-70b-instruct-v1:0.description": "Meta Llama 3 是一款開放式 LLM，專為開發者、研究人員與企業設計，協助他們構建、實驗並負責任地擴展生成式 AI 應用。作為全球社群創新的基礎，適用於內容創作、對話式 AI、語言理解、研發與企業應用。",
  "meta.llama3-8b-instruct-v1:0.description": "Meta Llama 3 是一款開放式 LLM，專為開發者、研究人員與企業設計，協助他們構建、實驗並負責任地擴展生成式 AI 應用。適合運算資源有限的場景、邊緣設備與快速訓練需求。",
  "meta/Llama-3.2-11B-Vision-Instruct.description": "具備高解析度圖像推理能力，適用於視覺理解應用。",
  "meta/Llama-3.2-90B-Vision-Instruct.description": "先進的圖像推理能力，適用於視覺理解代理應用。",
  "meta/Llama-3.3-70B-Instruct.description": "Llama 3.3 是最先進的多語言開源 Llama 模型，以極低成本提供接近 405B 的效能。該模型基於 Transformer 架構，並透過 SFT 與 RLHF 提升實用性與安全性。經指令微調版本針對多語言對話進行最佳化，在業界基準測試中超越多數開放與封閉模型。知識截止時間：2023 年 12 月。",
  "meta/Meta-Llama-3-70B-Instruct.description": "一款功能強大的 70B 參數模型，擅長推理、程式編寫與廣泛語言任務。",
  "meta/Meta-Llama-3-8B-Instruct.description": "一款多功能的 8B 參數模型，針對對話與文字生成進行最佳化。",
  "meta/Meta-Llama-3.1-405B-Instruct.description": "Llama 3.1 經指令微調的文字模型，針對多語言對話進行最佳化，在開放與封閉對話模型中於業界基準測試表現優異。",
  "meta/Meta-Llama-3.1-70B-Instruct.description": "Llama 3.1 經指令微調的文字模型，針對多語言對話進行最佳化，在開放與封閉對話模型中於業界基準測試表現優異。",
  "meta/Meta-Llama-3.1-8B-Instruct.description": "Llama 3.1 經指令微調的文字模型，針對多語言對話進行最佳化，在開放與封閉對話模型中於業界基準測試表現優異。",
  "meta/llama-3-70b.description": "一款由 Meta 微調的 70B 開源模型，專為指令遵循設計，透過 Groq 的 LPU 硬體提供快速且高效的推論服務。",
  "meta/llama-3-8b.description": "一款由 Meta 微調的 8B 開源模型，專為指令遵循設計，透過 Groq 的 LPU 硬體提供快速且高效的推論服務。",
  "meta/llama-3.1-405b-instruct.description": "一款先進的大型語言模型，支援合成資料生成、知識蒸餾與對話機器人、程式編寫及領域任務的推理。",
  "meta/llama-3.1-70b-instruct.description": "專為複雜對話設計，具備卓越的語境理解、推理與文字生成能力。",
  "meta/llama-3.1-70b.description": "更新版 Meta Llama 3 70B Instruct，支援 128K 語境、多語言能力與強化推理表現。",
  "meta/llama-3.1-8b-instruct.description": "一款尖端模型，具備強大的語言理解、推理與文字生成能力。",
  "meta/llama-3.1-8b.description": "Llama 3.1 8B 支援 128K 語境視窗，適合即時對話與資料分析，與大型模型相比具備顯著成本優勢。透過 Groq 的 LPU 硬體提供快速且高效的推論服務。",
  "meta/llama-3.2-11b-vision-instruct.description": "前沿的視覺語言模型，擅長從圖像中進行高品質推理。",
  "meta/llama-3.2-11b.description": "一款經指令微調的圖像推理模型（文字+圖像輸入，文字輸出），針對視覺辨識、圖像推理、圖說生成與一般圖像問答進行最佳化。",
  "meta/llama-3.2-1b-instruct.description": "一款尖端的小型語言模型，具備強大的理解、推理與文字生成能力。",
  "meta/llama-3.2-1b.description": "純文字模型，適用於裝置端應用，如多語言本地檢索、摘要與重寫。",
  "meta/llama-3.2-3b-instruct.description": "一款尖端的小型語言模型，具備強大的理解、推理與文字生成能力。",
  "meta/llama-3.2-3b.description": "純文字模型，經微調以支援裝置端應用，如多語言本地檢索、摘要與重寫。",
  "meta/llama-3.2-90b-vision-instruct.description": "前沿的視覺語言模型，擅長從圖像中進行高品質推理。",
  "meta/llama-3.2-90b.description": "一款經指令微調的圖像推理模型（文字+圖像輸入，文字輸出），針對視覺辨識、圖像推理、圖說生成與一般圖像問答進行最佳化。",
  "meta/llama-3.3-70b-instruct.description": "一款先進的大型語言模型，擅長推理、數學、常識與函式呼叫。",
  "meta/llama-3.3-70b.description": "效能與效率的完美平衡。專為高效能對話式 AI 應用於內容創作、企業應用與研究而設計，具備強大的語言理解能力，適用於摘要、分類、情感分析與程式碼生成。",
  "meta/llama-4-maverick.description": "Llama 4 系列為原生多模態 AI 模型，支援文字與多模態體驗，採用 MoE 架構以實現領先的文字與圖像理解。Llama 4 Maverick 為一款擁有 128 位專家的 17B 模型，由 DeepInfra 提供服務。",
  "meta/llama-4-scout.description": "Llama 4 系列為原生多模態 AI 模型，支援文字與多模態體驗，採用 MoE 架構以實現領先的文字與圖像理解。Llama 4 Scout 為一款擁有 16 位專家的 17B 模型，由 DeepInfra 提供服務。",
  "microsoft/Phi-3-medium-128k-instruct.description": "與 Phi-3-medium 相同，但具備更大的上下文視窗，適用於 RAG 或少樣本提示。",
  "microsoft/Phi-3-medium-4k-instruct.description": "一款擁有 140 億參數的模型，品質優於 Phi-3-mini，專注於高品質、推理密集型資料。",
  "microsoft/Phi-3-mini-128k-instruct.description": "與 Phi-3-mini 相同，但具備更大的上下文視窗，適用於 RAG 或少樣本提示。",
  "microsoft/Phi-3-mini-4k-instruct.description": "Phi-3 系列中最小的成員，針對品質與低延遲進行優化。",
  "microsoft/Phi-3-small-128k-instruct.description": "與 Phi-3-small 相同，但具備更大的上下文視窗，適用於 RAG 或少樣本提示。",
  "microsoft/Phi-3-small-8k-instruct.description": "一款擁有 70 億參數的模型，品質優於 Phi-3-mini，專注於高品質、推理密集型資料。",
  "microsoft/Phi-3.5-mini-instruct.description": "Phi-3-mini 模型的更新版本。",
  "microsoft/Phi-3.5-vision-instruct.description": "Phi-3-vision 模型的更新版本。",
  "microsoft/WizardLM-2-8x22B.description": "WizardLM 2 是 Microsoft AI 推出的語言模型，擅長處理複雜對話、多語言任務、推理與助理應用。",
  "microsoft/wizardlm-2-8x22b.description": "WizardLM-2 8x22B 是 Microsoft AI 最先進的 Wizard 模型，具備極高的競爭力。",
  "mimo-v2-flash.description": "MiMo-V2-Flash：一款高效模型，專注於推理、編碼與智能代理基礎。",
  "minicpm-v.description": "MiniCPM-V 是 OpenBMB 的次世代多模態模型，具備卓越的光學字符識別（OCR）與多模態理解能力，適用於多種應用場景。",
  "minimax-m2.1.description": "MiniMax-M2.1 是 MiniMax 系列的最新版本，針對多語言編程與真實世界的複雜任務進行優化。作為原生 AI 模型，MiniMax-M2.1 在模型效能、代理框架支援與多場景適應性方面均有顯著提升，旨在協助企業與個人更快速地實現 AI 原生的工作與生活方式。",
  "minimax-m2.description": "MiniMax M2 是一款專為編碼與代理工作流程打造的高效大型語言模型。",
  "minimax/minimax-m2.1.description": "MiniMax-M2.1 是一款輕量且先進的大型語言模型，針對編碼、代理工作流程與現代應用開發進行優化，提供更簡潔的輸出與更快速的感知反應。",
  "minimax/minimax-m2.description": "MiniMax-M2 是一款高性價比模型，擅長處理多種工程場景中的編碼與代理任務。",
  "minimaxai/minimax-m2.description": "MiniMax-M2 是一款緊湊、快速且具成本效益的 MoE 模型（總參數 230B，啟用參數 10B），專為頂級編碼與代理效能打造，同時保有強大的通用智能。擅長多檔案編輯、代碼執行修復循環、測試驗證與複雜工具鏈。",
  "ministral-3b-latest.description": "Ministral 3B 是 Mistral 的頂級邊緣模型。",
  "ministral-8b-latest.description": "Ministral 8B 是 Mistral 推出的高性價比邊緣模型。",
  "mistral-ai/Mistral-Large-2411.description": "Mistral 的旗艦模型，適用於需要大規模推理或專業化的複雜任務（如合成文本生成、代碼生成、RAG 或智能代理）。",
  "mistral-ai/Mistral-Nemo.description": "Mistral Nemo 是一款先進的大型語言模型，具備同級最佳的推理能力、世界知識與編碼能力。",
  "mistral-ai/mistral-small-2503.description": "Mistral Small 適用於任何需要高效率與低延遲的語言任務。",
  "mistral-large-instruct.description": "Mistral-Large-Instruct-2407 是一款擁有 123B 參數的先進密集型大型語言模型，具備頂尖的推理、知識與編碼能力。",
  "mistral-large-latest.description": "Mistral Large 是旗艦模型，擅長多語言任務、複雜推理與代碼生成，適用於高端應用場景。",
  "mistral-large.description": "Mixtral Large 是 Mistral 的旗艦模型，結合代碼生成、數學與推理能力，支援 128K 上下文視窗。",
  "mistral-medium-latest.description": "Mistral Medium 3 以 8 倍成本效益提供同級最佳效能，簡化企業部署流程。",
  "mistral-nemo-instruct.description": "Mistral-Nemo-Instruct-2407 是 Mistral-Nemo-Base-2407 的指令微調版本。",
  "mistral-nemo.description": "Mistral Nemo 是 Mistral AI 與 NVIDIA 推出的高效能 12B 模型。",
  "mistral-small-latest.description": "Mistral Small 是翻譯、摘要與情感分析等任務的高效、快速且可靠選擇。",
  "mistral-small.description": "Mistral Small 適用於任何需要高效率與低延遲的語言任務。",
  "mistral.description": "Mistral 是 Mistral AI 推出的 7B 模型，適用於多樣化語言任務。",
  "mistral/codestral-embed.description": "一款用於嵌入代碼庫與儲存庫的代碼嵌入模型，支援編碼助手應用。",
  "mistral/codestral.description": "Mistral Codestral 25.01 是一款先進的編碼模型，針對低延遲與高頻使用進行優化。支援 80 多種語言，擅長 FIM、代碼修正與測試生成。",
  "mistral/devstral-small.description": "Devstral 是一款專為軟體工程任務設計的代理型大型語言模型，是軟體工程代理的強力選擇。",
  "mistral/magistral-medium.description": "透過深層理解支援複雜思維，並提供可追溯與可驗證的透明推理。即使在任務中途，也能維持跨語言的高保真推理能力。",
  "mistral/magistral-small.description": "透過深層理解支援複雜思維，並提供可追溯與可驗證的透明推理。即使在任務中途，也能維持跨語言的高保真推理能力。",
  "mistral/ministral-3b.description": "一款緊湊高效的模型，適用於裝置端任務，如助手與本地分析，提供低延遲效能。",
  "mistral/ministral-8b.description": "一款更強大的模型，具備更快且記憶體效率更高的推理能力，適合複雜工作流程與高需求邊緣應用。",
  "mistral/mistral-embed.description": "一款通用文本嵌入模型，適用於語意搜尋、相似度分析、聚類與 RAG 工作流程。",
  "mistral/mistral-large.description": "Mistral Large 適用於需要強大推理或專業化的複雜任務，如合成文本生成、代碼生成、RAG 或智能代理。",
  "mistral/mistral-small.description": "Mistral Small 適合處理分類、客服或文本生成等簡單、可批次處理的任務，提供高效能與實惠價格。",
  "mistral/mixtral-8x22b-instruct.description": "8x22B 指令模型。8x22B 是由 Mistral 提供服務的開源 MoE 模型。",
  "mistral/pixtral-12b.description": "一款具備圖像理解與文本處理能力的 12B 模型。",
  "mistral/pixtral-large.description": "Pixtral Large 是我們多模態系列的第二款模型，具備前沿級圖像理解能力。可處理文件、圖表與自然圖像，同時保有 Mistral Large 2 的頂尖文本理解能力。",
  "mistralai/Mistral-7B-Instruct-v0.1.description": "Mistral（7B）Instruct 以其在多種語言任務中的強大表現而聞名。",
  "mistralai/Mistral-7B-Instruct-v0.2.description": "Mistral（7B）Instruct v0.2 改進了指令處理與結果準確性。",
  "mistralai/Mistral-7B-Instruct-v0.3.description": "Mistral（7B）Instruct v0.3 提供高效運算與強大的語言理解能力，適用於多種應用場景。",
  "mistralai/Mistral-7B-v0.1.description": "Mistral 7B 體積小但效能強，適合批次處理與分類、文本生成等簡單任務，具備穩定的推理能力。",
  "mistralai/Mixtral-8x22B-Instruct-v0.1.description": "Mixtral-8x22B Instruct（141B）是一款適用於重負載任務的超大型語言模型。",
  "mistralai/Mixtral-8x7B-Instruct-v0.1.description": "Mixtral-8x7B Instruct（46.7B）具備高容量，適合大規模資料處理。",
  "mistralai/Mixtral-8x7B-v0.1.description": "Mixtral 8x7B 是一款稀疏 MoE 模型，提升推理速度，適用於多語言與代碼生成任務。",
  "mistralai/mistral-nemo.description": "Mistral Nemo 是一款 7.3B 模型，支援多語言並具備強大的編碼能力。",
  "mixtral-8x7b-32768.description": "Mixtral 8x7B 提供容錯的平行運算能力，適用於複雜任務。",
  "mixtral.description": "Mixtral 是 Mistral AI 推出的 MoE 模型，具備開源權重，支援代碼生成與語言理解。",
  "mixtral:8x22b.description": "Mixtral 是 Mistral AI 推出的 MoE 模型，具備開源權重，支援代碼生成與語言理解。",
  "moonshot-v1-128k-vision-preview.description": "Kimi 視覺模型（包括 moonshot-v1-8k-vision-preview/moonshot-v1-32k-vision-preview/moonshot-v1-128k-vision-preview）能理解圖像內容，如文字、顏色與物體形狀。",
  "moonshot-v1-128k.description": "Moonshot V1 128K 提供超長上下文能力，支援最多 128,000 個 token，適用於研究、學術與長文檔場景。",
  "moonshot-v1-32k-vision-preview.description": "Kimi 視覺模型（包括 moonshot-v1-8k-vision-preview/moonshot-v1-32k-vision-preview/moonshot-v1-128k-vision-preview）能理解圖像內容，如文字、顏色與物體形狀。",
  "moonshot-v1-32k.description": "Moonshot V1 32K 支援 32,768 個 token 的中長上下文，適合內容創作、報告與聊天系統中的長文檔與複雜對話。",
  "moonshot-v1-8k-vision-preview.description": "Kimi 視覺模型（包括 moonshot-v1-8k-vision-preview/moonshot-v1-32k-vision-preview/moonshot-v1-128k-vision-preview）能理解圖像內容，如文字、顏色與物體形狀。",
  "moonshot-v1-8k.description": "Moonshot V1 8K 針對短文本生成進行優化，支援 8,192 個 token，適用於短對話、筆記與快速內容生成。",
  "moonshot-v1-auto.description": "Moonshot V1 Auto 會根據當前上下文 token 使用情況自動選擇合適模型。",
  "moonshotai/Kimi-Dev-72B.description": "Kimi-Dev-72B 是一款開源程式語言模型，透過大規模強化學習優化，可產出穩健、可用於生產環境的修補程式。其在 SWE-bench Verified 測試中取得 60.4% 的成績，創下自動化軟體工程任務（如除錯與程式碼審查）的開源模型新紀錄。",
  "moonshotai/Kimi-K2-Instruct-0905.description": "Kimi K2-Instruct-0905 是最新且最強大的 Kimi K2 模型。這是一款頂級 MoE 模型，總參數達 1 兆，啟用參數為 320 億。其特色包括更強的代理式程式智能，在基準測試與真實任務中表現卓越，並提升前端程式美學與可用性。",
  "moonshotai/Kimi-K2-Thinking.description": "Kimi K2 Thinking 是最新且最強大的開源推理模型。它大幅提升多步推理的深度，並能在 200–300 次連續調用中穩定使用工具，在 Humanity's Last Exam (HLE)、BrowseComp 等基準測試中創下新紀錄。擅長程式設計、數學、邏輯與智能代理場景。採用 MoE 架構，總參數約為 1 兆，支援 256K 上下文視窗與工具調用。",
  "moonshotai/kimi-k2-0711.description": "Kimi K2 0711 是 Kimi 系列中的指令變體，適用於高品質程式碼生成與工具使用。",
  "moonshotai/kimi-k2-0905.description": "Kimi K2 0905 是一項更新，提升了上下文擴展與推理效能，並優化了程式碼能力。",
  "moonshotai/kimi-k2-instruct-0905.description": "kimi-k2-0905-preview 模型支援 256K 上下文視窗，具備更強的智能代理程式設計能力、更精緻實用的前端程式碼，以及更佳的上下文理解。",
  "moonshotai/kimi-k2-thinking-turbo.description": "Kimi K2 Thinking Turbo 是 Kimi K2 Thinking 的高速版本，在保留深度推理能力的同時大幅降低延遲。",
  "moonshotai/kimi-k2-thinking.description": "Kimi K2 Thinking 是 Moonshot 專為深度推理任務優化的推理模型，具備通用智能代理能力。",
  "moonshotai/kimi-k2.description": "Kimi K2 是 Moonshot AI 推出的大型 MoE 模型，總參數達 1 兆，每次前向傳遞啟用 32B，針對智能代理能力（如進階工具使用、推理與程式碼合成）進行優化。",
  "morph/morph-v3-fast.description": "Morph 提供專門模型，能以超過 4500 個 token/秒的速度，將前沿模型（如 Claude 或 GPT-4o）建議的程式碼變更應用至現有檔案。作為 AI 程式開發流程的最後一步，支援 16K 輸入/輸出 token。",
  "morph/morph-v3-large.description": "Morph 提供專門模型，能以超過 2500 個 token/秒的速度，將前沿模型（如 Claude 或 GPT-4o）建議的程式碼變更應用至現有檔案。作為 AI 程式開發流程的最後一步，支援 16K 輸入/輸出 token。",
  "nousresearch/hermes-2-pro-llama-3-8b.description": "Hermes 2 Pro Llama 3 8B 是 Nous Hermes 2 的更新版本，採用最新內部開發的資料集。",
  "nvidia/Llama-3.1-Nemotron-70B-Instruct-HF.description": "Llama 3.1 Nemotron 70B 是 NVIDIA 客製化的大型語言模型，旨在提升回應的有用性。於 2024 年 10 月 1 日，在 Arena Hard、AlpacaEval 2 LC 和 GPT-4-Turbo MT-Bench 三項自動對齊基準測試中皆排名第一。該模型基於 Llama-3.1-70B-Instruct，並透過 RLHF（REINFORCE）、Llama-3.1-Nemotron-70B-Reward 與 HelpSteer2-Preference 提示進行訓練。",
  "nvidia/llama-3.1-nemotron-51b-instruct.description": "一款具備卓越準確性與效率的獨特語言模型。",
  "nvidia/llama-3.1-nemotron-70b-instruct.description": "Llama-3.1-Nemotron-70B-Instruct 是 NVIDIA 客製化模型，旨在提升大型語言模型回應的有用性。",
  "o1-mini.description": "比 o1-preview 更小更快，成本降低 80%，擅長程式碼生成與短上下文任務。",
  "o1-preview.description": "專注於進階推理與複雜問題解決，包括數學與科學。適用於需要深度上下文理解與自主工作流程的應用場景。",
  "o1-pro.description": "o1 系列透過強化學習訓練，具備先思考再作答的能力，能處理複雜推理任務。o1-pro 使用更多運算資源以進行更深入思考，並穩定提供更高品質的回答。",
  "o1.description": "o1 是 OpenAI 的新一代推理模型，支援文字與圖像輸入、文字輸出，適用於需要廣泛知識的複雜任務。具備 200K 上下文視窗，知識截止於 2023 年 10 月。",
  "o3-2025-04-16.description": "o3 是 OpenAI 的新一代推理模型，支援文字與圖像輸入、文字輸出，適用於需要廣泛知識的複雜任務。",
  "o3-deep-research.description": "o3-deep-research 是我們最先進的深度研究模型，適用於複雜的多步任務。可透過 MCP 連接器搜尋網路並存取您的資料。",
  "o3-mini.description": "o3-mini 是我們最新的小型推理模型，在維持與 o1-mini 相同成本與延遲的前提下，提供更高智慧表現。",
  "o3-pro-2025-06-10.description": "o3 Pro 是 OpenAI 的新一代推理模型，支援文字與圖像輸入、文字輸出，適用於需要廣泛知識的複雜任務。",
  "o3-pro.description": "o3-pro 使用更多運算資源以進行更深入思考，穩定提供更佳回答；僅透過 Responses API 提供。",
  "o3.description": "o3 是一款全方位強大的模型，在數學、科學、程式設計與視覺推理方面樹立新標竿。擅長技術寫作與指令執行，能分析文字、程式碼與圖像以解決多步問題。",
  "o4-mini-2025-04-16.description": "o4-mini 是 OpenAI 的推理模型，支援文字與圖像輸入、文字輸出，適用於需要廣泛知識的複雜任務，具備 200K 上下文視窗。",
  "o4-mini-deep-research.description": "o4-mini-deep-research 是一款更快速、更經濟的深度研究模型，適用於複雜的多步研究任務。可搜尋網路並透過 MCP 連接器存取您的資料。",
  "o4-mini.description": "o4-mini 是最新的小型 o 系列模型，針對快速、有效推理進行優化，在程式設計與視覺任務中具備高效率。",
  "open-codestral-mamba.description": "Codestral Mamba 是一款專注於程式碼生成的 Mamba 2 語言模型，支援進階程式設計與推理任務。",
  "open-mistral-7b.description": "Mistral 7B 體積小但效能強，適合批次處理與分類、文字生成等簡單任務，具備穩定推理能力。",
  "open-mistral-nemo.description": "Mistral Nemo 是與 Nvidia 共同開發的 12B 模型，具備強大的推理與程式設計能力，易於整合。",
  "open-mixtral-8x22b.description": "Mixtral 8x22B 是一款大型 MoE 模型，適用於複雜任務，具備強大推理能力與高吞吐量。",
  "open-mixtral-8x7b.description": "Mixtral 8x7B 是一款稀疏 MoE 模型，提升推理速度，適合多語言與程式碼生成任務。",
  "openai/gpt-3.5-turbo-instruct.description": "具備與 GPT-3 時代模型相似的能力，與舊版 completion 端點相容，而非 chat 模式。",
  "openai/gpt-3.5-turbo.description": "OpenAI 最具性價比的 GPT-3.5 模型，針對聊天優化，同時在傳統 completion 任務中表現穩定。",
  "openai/gpt-4-turbo.description": "OpenAI 的 gpt-4-turbo 擁有廣泛的通識知識與領域專業，能理解複雜自然語言指令並準確解決困難問題。知識截止於 2023 年 4 月，支援 128K 上下文視窗。",
  "openai/gpt-4.1-mini.description": "GPT-4.1 Mini 提供較低延遲與更高性價比，適用於中等上下文工作負載。",
  "openai/gpt-4.1-nano.description": "GPT-4.1 Nano 是超低成本、低延遲的選擇，適合高頻率短對話或分類任務。",
  "openai/gpt-4.1.description": "GPT-4.1 系列提供更大的上下文視窗與更強的工程與推理能力。",
  "openai/gpt-4o-mini.description": "GPT-4o-mini 是 GPT-4o 的快速小型變體，適用於低延遲多模態應用。",
  "openai/gpt-4o.description": "GPT-4o 系列是 OpenAI 的 Omni 模型，支援文字 + 圖像輸入與文字輸出。",
  "openai/gpt-5-chat.description": "GPT-5 Chat 是針對對話優化的 GPT-5 變體，具備更低延遲與更佳互動性。",
  "openai/gpt-5-codex.description": "GPT-5-Codex 是進一步針對程式設計與大規模程式工作流程優化的 GPT-5 變體。",
  "openai/gpt-5-mini.description": "GPT-5 Mini 是一款較小的 GPT-5 變體，適用於低延遲、低成本場景。",
  "openai/gpt-5-nano.description": "GPT-5 Nano 是超小型變體，適用於對成本與延遲有嚴格限制的場景。",
  "openai/gpt-5-pro.description": "GPT-5 Pro 是 OpenAI 的旗艦模型，具備更強的推理、程式生成與企業級功能，支援測試時路由與更嚴格的安全政策。",
  "openai/gpt-5.1-chat.description": "GPT-5.1 Chat 是 GPT-5.1 系列中輕量級成員，針對低延遲對話優化，同時保有強大的推理與指令執行能力。",
  "openai/gpt-5.1-codex-mini.description": "GPT-5.1-Codex-Mini 是 GPT-5.1-Codex 的小型快速版本，適合對延遲與成本敏感的程式設計場景。",
  "openai/gpt-5.1-codex.description": "GPT-5.1-Codex 是針對軟體工程與程式工作流程優化的 GPT-5.1 變體，適用於大型重構、複雜除錯與長時間自動程式任務。",
  "openai/gpt-5.1.description": "GPT-5.1 是 GPT-5 系列的最新旗艦版本，在通用推理、指令遵循與對話自然度方面相較 GPT-5 有顯著提升，適用於廣泛任務。",
  "openai/gpt-5.2-chat.description": "GPT-5.2 Chat 是 ChatGPT 的變體，用於體驗最新的對話改進。",
  "openai/gpt-5.2-pro.description": "GPT-5.2 Pro：更智慧、更精確的 GPT-5.2 變體（僅限 Responses API），適用於更困難的問題與更長的多輪推理。",
  "openai/gpt-5.2.description": "GPT-5.2 是一款旗艦模型，專為程式設計與代理工作流程打造，具備更強的推理與長上下文處理能力。",
  "openai/gpt-5.description": "GPT-5 是 OpenAI 的高效能模型，適用於各類生產與研究任務。",
  "openai/gpt-oss-120b.description": "一款具備強大可控推理能力的通用大型語言模型。",
  "openai/gpt-oss-20b.description": "一款緊湊型開源權重語言模型，針對低延遲與資源受限環境（如本地與邊緣部署）進行優化。",
  "openai/o1-mini.description": "o1-mini 是一款快速、具成本效益的推理模型，適用於程式設計、數學與科學任務。具備 128K 上下文與 2023 年 10 月知識截止。",
  "openai/o1-preview.description": "o1 是 OpenAI 的新型推理模型，適用於需要廣泛知識的複雜任務。具備 128K 上下文與 2023 年 10 月知識截止。",
  "openai/o1.description": "OpenAI o1 是一款旗艦推理模型，專為需要深入思考的複雜問題設計，具備強大推理能力與多步驟任務的高準確性。",
  "openai/o3-mini-high.description": "o3-mini（高推理）在維持與 o1-mini 相同成本與延遲的前提下，提供更高智慧表現。",
  "openai/o3-mini.description": "o3-mini 是 OpenAI 最新的小型推理模型，在相同成本與延遲下提供更高智慧表現。",
  "openai/o3.description": "OpenAI o3 是最強大的推理模型，在程式設計、數學、科學與視覺感知領域創下新標竿。擅長處理複雜、多面向查詢，特別擅長分析圖像、圖表與示意圖。",
  "openai/o4-mini-high.description": "o4-mini 高推理等級，針對快速、高效推理進行優化，具備強大程式與視覺表現。",
  "openai/o4-mini.description": "OpenAI o4-mini 是一款小型高效推理模型，適用於低延遲場景。",
  "openai/text-embedding-3-large.description": "OpenAI 最強大的嵌入模型，適用於英文與非英文任務。",
  "openai/text-embedding-3-small.description": "OpenAI 改良版、高效能的 ada 嵌入模型變體。",
  "openai/text-embedding-ada-002.description": "OpenAI 的舊版文字嵌入模型。",
  "openrouter/auto.description": "根據上下文長度、主題與複雜度，自動將請求路由至 Llama 3 70B Instruct、Claude 3.5 Sonnet（自我審核）或 GPT-4o。",
  "perplexity/sonar-pro.description": "Perplexity 的旗艦產品，具備搜尋依據，支援進階查詢與後續提問。",
  "perplexity/sonar-reasoning-pro.description": "一款專注推理的進階模型，輸出包含增強搜尋的思考鏈（CoT），每次請求可包含多個搜尋查詢。",
  "perplexity/sonar-reasoning.description": "一款專注推理的模型，輸出具詳細搜尋依據的思考鏈（CoT）解釋。",
  "perplexity/sonar.description": "Perplexity 的輕量產品，具備搜尋依據，速度更快、成本更低於 Sonar Pro。",
  "phi3.description": "Phi-3 是 Microsoft 的輕量開源模型，適用於高效整合與大規模推理。",
  "phi3:14b.description": "Phi-3 是 Microsoft 的輕量開源模型，適用於高效整合與大規模推理。",
  "pixtral-12b-2409.description": "Pixtral 擅長圖表/圖像理解、文件問答、多模態推理與指令遵循。可原生解析圖像解析度與比例，並在 128K 上下文中處理任意數量圖像。",
  "pixtral-large-latest.description": "Pixtral Large 是一款擁有 124B 參數的開源多模態模型，基於 Mistral Large 2 架構，是我們多模態系列中的第二代，具備前沿級圖像理解能力。",
  "pro-128k.description": "Spark Pro 128K 提供超大上下文容量，最多支援 128K 上下文，適合需要全文分析與長距離邏輯連貫性的長篇文件，並在複雜討論中支援流暢邏輯與多樣引用。",
  "pro-deepseek-r1.description": "企業專用服務模型，內含綁定併發能力。",
  "pro-deepseek-v3.description": "企業專用服務模型，內含綁定併發能力。",
  "qianfan-70b.description": "千帆 70B 是一款大型中文模型，具備高品質生成與複雜推理能力。",
  "qianfan-8b.description": "千帆 8B 是一款中型通用模型，在生成文本與問答任務中兼顧成本與品質。",
  "qianfan-agent-intent-32k.description": "千帆 Agent Intent 32K 專注於意圖識別與智能代理協作，支援長上下文處理。",
  "qianfan-agent-lite-8k.description": "千帆 Agent Lite 8K 是一款輕量級代理模型，適用於低成本的多輪對話與工作流程。",
  "qianfan-check-vl.description": "千帆 Check VL 是一款多模態內容審核模型，支援圖文合規與識別任務。",
  "qianfan-composition.description": "千帆 Composition 是一款多模態創作模型，支援圖文混合理解與生成。",
  "qianfan-engcard-vl.description": "千帆 EngCard VL 是一款聚焦英語場景的多模態識別模型。",
  "qianfan-lightning-128b-a19b.description": "千帆 Lightning 128B A19B 是一款高效能中文通用模型，適用於複雜問答與大規模推理任務。",
  "qianfan-llama-vl-8b.description": "千帆 Llama VL 8B 是基於 Llama 的多模態模型，支援通用圖文理解。",
  "qianfan-multipicocr.description": "千帆 MultiPicOCR 是一款多圖像 OCR 模型，支援跨圖像的文字檢測與識別。",
  "qianfan-qi-vl.description": "千帆 QI VL 是一款多模態問答模型，適用於複雜圖文場景中的精準檢索與問答。",
  "qianfan-singlepicocr.description": "千帆 SinglePicOCR 是一款單張圖片的光學字元辨識（OCR）模型，具備高精度的文字識別能力。",
  "qianfan-vl-70b.description": "千帆 VL 70B 是一款大型視覺語言模型（VLM），專為複雜的圖文理解任務設計。",
  "qianfan-vl-8b.description": "千帆 VL 8B 是一款輕量級視覺語言模型，適用於日常圖文問答與分析。",
  "qvq-72b-preview.description": "QVQ-72B-Preview 是 Qwen 推出的實驗性研究模型，專注於提升視覺推理能力。",
  "qvq-max.description": "Qwen QVQ 視覺推理模型支援視覺輸入與思維鏈式輸出，在數學、程式碼、視覺分析、創意與通用任務中表現更強。",
  "qvq-plus.description": "具備視覺輸入與思維鏈式輸出的視覺推理模型。qvq-plus 系列延續 qvq-max，提供更快速的推理能力與更佳的品質成本平衡。",
  "qwen-3-32b.description": "Qwen 3 32B：擅長多語言與程式碼任務，適合中型規模的生產應用。",
  "qwen-coder-plus.description": "Qwen 程式碼模型。",
  "qwen-coder-turbo-latest.description": "Qwen 程式碼模型。",
  "qwen-coder-turbo.description": "Qwen 程式碼模型。",
  "qwen-flash.description": "Qwen 最快且成本最低的模型，適用於簡單任務。",
  "qwen-image-edit.description": "Qwen Image Edit 是一款圖像轉圖像模型，根據輸入圖片與文字提示進行圖像編輯，實現精準調整與創意轉換。",
  "qwen-image.description": "Qwen-Image 是一款通用圖像生成模型，支援多種藝術風格與強大的中英文複雜文字渲染能力。支援多行排版、段落級文字與複雜圖文細節。",
  "qwen-long.description": "超大型 Qwen 模型，具備長上下文處理能力，適用於長篇與多文件對話場景。",
  "qwen-math-plus-latest.description": "Qwen Math 是一款專門用於解決數學問題的語言模型。",
  "qwen-math-plus.description": "Qwen Math 是一款專門用於解決數學問題的語言模型。",
  "qwen-math-turbo-latest.description": "Qwen Math 是一款專門用於解決數學問題的語言模型。",
  "qwen-math-turbo.description": "Qwen Math 是一款專門用於解決數學問題的語言模型。",
  "qwen-max.description": "千億級超大型 Qwen 模型，支援中文、英文及其他語言；為目前 Qwen2.5 系列產品背後的 API 模型。",
  "qwen-omni-turbo.description": "Qwen-Omni 模型支援多模態輸入（影片、音訊、圖片、文字）並輸出語音與文字。",
  "qwen-plus.description": "增強版超大型 Qwen 模型，支援中文、英文及其他語言。",
  "qwen-turbo.description": "Qwen Turbo 將不再更新，請改用 Qwen Flash。超大型 Qwen 模型，支援中文、英文及其他語言。",
  "qwen-vl-chat-v1.description": "Qwen VL 支援靈活互動，包括多圖輸入、多輪問答與創意任務。",
  "qwen-vl-max-latest.description": "超大型 Qwen 視覺語言模型。相較於增強版，進一步提升視覺推理與指令遵循能力，具備更強的感知與認知能力。",
  "qwen-vl-max.description": "超大型 Qwen 視覺語言模型。相較於增強版，進一步提升視覺推理與指令遵循能力，具備更強的視覺感知與認知能力。",
  "qwen-vl-ocr.description": "Qwen OCR 是一款文字擷取模型，適用於文件、表格、考卷圖片與手寫文字。支援中文、英文、法文、日文、韓文、德文、俄文、義大利文、越南文與阿拉伯文。",
  "qwen-vl-plus-latest.description": "增強版大型 Qwen 視覺語言模型，在細節與文字識別方面有重大提升，支援超過百萬像素解析度與任意長寬比。",
  "qwen-vl-plus.description": "增強版大型 Qwen 視覺語言模型，在細節與文字識別方面有重大提升，支援超過百萬像素解析度與任意長寬比。",
  "qwen-vl-v1.description": "從 Qwen-7B 預訓練模型初始化，加入視覺模組並支援 448 圖像解析度輸入。",
  "qwen/qwen-2-7b-instruct.description": "Qwen2 是全新 Qwen LLM 系列。Qwen2 7B 是一款基於 Transformer 的模型，擅長語言理解、多語言處理、程式設計、數學與推理。",
  "qwen/qwen-2-7b-instruct:free.description": "Qwen2 是一個全新的大型語言模型系列，具備更強的理解與生成能力。",
  "qwen/qwen-2-vl-72b-instruct.description": "Qwen2-VL 是 Qwen-VL 的最新版本，在 MathVista、DocVQA、RealWorldQA、MTVQA 等視覺基準上達到 SOTA 表現。可理解超過 20 分鐘影片，進行高品質問答、對話與內容創作。支援複雜推理與決策，能與行動裝置與機器人整合，根據視覺上下文與文字指令執行操作。除中英文外，也能辨識多種語言的圖像文字，包括多數歐洲語言、日文、韓文、阿拉伯文與越南文。",
  "qwen/qwen-2.5-72b-instruct.description": "Qwen2.5-72B-Instruct 是阿里雲最新發布的 LLM 之一。72B 模型在程式設計與數學方面有顯著提升，支援超過 29 種語言（含中英文），並大幅提升指令遵循、結構化資料理解與結構化輸出（特別是 JSON）。",
  "qwen/qwen2.5-32b-instruct.description": "Qwen2.5-32B-Instruct 是阿里雲最新發布的 LLM 之一。32B 模型在程式設計與數學方面有顯著提升，支援超過 29 種語言（含中英文），並大幅提升指令遵循、結構化資料理解與結構化輸出（特別是 JSON）。",
  "qwen/qwen2.5-7b-instruct.description": "一款中英文雙語 LLM，涵蓋語言、程式設計、數學與推理任務。",
  "qwen/qwen2.5-coder-32b-instruct.description": "一款進階 LLM，支援主流程式語言的程式碼生成、推理與修復。",
  "qwen/qwen2.5-coder-7b-instruct.description": "一款中型強大程式碼模型，具備 32K 上下文，擅長多語言程式設計。",
  "qwen/qwen3-14b.description": "Qwen3-14B 是一款 14B 參數模型，適用於通用推理與對話場景。",
  "qwen/qwen3-14b:free.description": "Qwen3-14B 是一款密集型 14.8B 參數因果 LLM，專為複雜推理與高效對話設計。可在數學、程式設計與邏輯的思考模式與一般對話的非思考模式間切換。針對指令遵循、工具使用與創意寫作進行微調，支援 100 多種語言與方言。原生支援 32K 上下文，並可透過 YaRN 擴展至 131K。",
  "qwen/qwen3-235b-a22b-2507.description": "Qwen3-235B-A22B-Instruct-2507 是 Qwen3 系列中的 Instruct 變體，兼顧多語指令使用與長上下文場景。",
  "qwen/qwen3-235b-a22b-thinking-2507.description": "Qwen3-235B-A22B-Thinking-2507 是 Qwen3 的 Thinking 變體，強化數學與複雜推理能力。",
  "qwen/qwen3-235b-a22b.description": "Qwen3-235B-A22B 是 Qwen 推出的 235B 參數 MoE 模型，每次前向傳遞啟用 22B 參數。可在複雜推理、數學與程式碼的思考模式與高效聊天的非思考模式間切換。具備強大推理、多語言支援（超過 100 種語言/方言）、高階指令遵循與代理工具使用能力。原生支援 32K 上下文，並可透過 YaRN 擴展至 131K。",
  "qwen/qwen3-235b-a22b:free.description": "Qwen3-235B-A22B 是 Qwen 推出的 235B 參數 MoE 模型，每次前向傳遞啟用 22B 參數。可在複雜推理、數學與程式碼的思考模式與高效聊天的非思考模式間切換。具備強大推理、多語言支援（超過 100 種語言/方言）、高階指令遵循與代理工具使用能力。原生支援 32K 上下文，並可透過 YaRN 擴展至 131K。",
  "qwen/qwen3-30b-a3b.description": "Qwen3 是最新一代的 Qwen 大型語言模型，採用密集與 MoE 架構，擅長推理、多語言支援與進階代理任務。其獨特的能力可在複雜推理的「思考模式」與高效對話的「非思考模式」間切換，確保多元且高品質的表現。\n\nQwen3 在數學、程式碼、常識推理、創意寫作與互動對話方面，表現遠超前代模型如 QwQ 與 Qwen2.5。Qwen3-30B-A3B 版本擁有 305 億參數（其中 3.3 億為活躍參數）、48 層、128 位專家（每次任務啟用 8 位），並透過 YaRN 支援最高 131K 的上下文長度，為開源模型樹立新標竿。",
  "qwen/qwen3-30b-a3b:free.description": "Qwen3 是最新一代的 Qwen 大型語言模型，採用密集與 MoE 架構，擅長推理、多語言支援與進階代理任務。其獨特的能力可在複雜推理的「思考模式」與高效對話的「非思考模式」間切換，確保多元且高品質的表現。\n\nQwen3 在數學、程式碼、常識推理、創意寫作與互動對話方面，表現遠超前代模型如 QwQ 與 Qwen2.5。Qwen3-30B-A3B 版本擁有 305 億參數（其中 3.3 億為活躍參數）、48 層、128 位專家（每次任務啟用 8 位），並透過 YaRN 支援最高 131K 的上下文長度，為開源模型樹立新標竿。",
  "qwen/qwen3-32b.description": "Qwen3-32B 是一款密集型、擁有 328 億參數的因果語言模型，針對複雜推理與高效對話進行最佳化。它可在數學、程式設計與邏輯的「思考模式」與快速對話的「非思考模式」間切換。該模型在指令遵循、代理工具使用與創意寫作方面表現優異，支援超過 100 種語言與方言。原生支援 32K 上下文，並可透過 YaRN 擴展至 131K。",
  "qwen/qwen3-32b:free.description": "Qwen3-32B 是一款密集型、擁有 328 億參數的因果語言模型，針對複雜推理與高效對話進行最佳化。它可在數學、程式設計與邏輯的「思考模式」與快速對話的「非思考模式」間切換。該模型在指令遵循、代理工具使用與創意寫作方面表現優異，支援超過 100 種語言與方言。原生支援 32K 上下文，並可透過 YaRN 擴展至 131K。",
  "qwen/qwen3-8b:free.description": "Qwen3-8B 是一款密集型、擁有 8.2 億參數的因果語言模型，專為重推理任務與高效對話設計。它可在數學、程式設計與邏輯的「思考模式」與一般對話的「非思考模式」間切換。經過微調以強化指令遵循、代理整合與創意寫作，支援超過 100 種語言與方言。原生支援 32K 上下文，並可透過 YaRN 擴展至 131K。",
  "qwen/qwen3-coder-plus.description": "Qwen3-Coder-Plus 是 Qwen 系列中的程式代理模型，針對更複雜的工具使用與長時間工作流程進行最佳化。",
  "qwen/qwen3-coder.description": "Qwen3-Coder 是 Qwen3 的程式碼生成系列，擅長長文件的程式理解與生成。",
  "qwen/qwen3-max-preview.description": "Qwen3 Max（預覽版）是 Max 變體，專為進階推理與工具整合設計。",
  "qwen/qwen3-max.description": "Qwen3 Max 是 Qwen3 系列中高階推理模型，支援多語言推理與工具整合。",
  "qwen/qwen3-vl-plus.description": "Qwen3 VL-Plus 是強化視覺能力的 Qwen3 變體，具備更佳的多模態推理與影片處理能力。",
  "qwen2.5-14b-instruct-1m.description": "Qwen2.5 開源 72B 模型。",
  "qwen2.5-14b-instruct.description": "Qwen2.5 開源 14B 模型。",
  "qwen2.5-32b-instruct.description": "Qwen2.5 開源 32B 模型。",
  "qwen2.5-72b-instruct.description": "Qwen2.5 開源 72B 模型。",
  "qwen2.5-7b-instruct.description": "Qwen2.5 7B Instruct 是一款成熟的開源指令模型，適用於多場景對話與生成。",
  "qwen2.5-coder-1.5b-instruct.description": "開源 Qwen 程式碼模型。",
  "qwen2.5-coder-14b-instruct.description": "開源 Qwen 程式碼模型。",
  "qwen2.5-coder-32b-instruct.description": "開源 Qwen 程式碼模型。",
  "qwen2.5-coder-7b-instruct.description": "開源 Qwen 程式碼模型。",
  "qwen2.5-coder-instruct.description": "Qwen2.5-Coder 是 Qwen 家族中最新的程式碼導向大型語言模型（前身為 CodeQwen）。",
  "qwen2.5-instruct.description": "Qwen2.5 是 Qwen 最新一代語言模型系列，包含基礎與指令微調模型，參數範圍從 0.5B 到 72B。",
  "qwen2.5-math-1.5b-instruct.description": "Qwen-Math 擅長數學問題解決。",
  "qwen2.5-math-72b-instruct.description": "Qwen-Math 擅長數學問題解決。",
  "qwen2.5-math-7b-instruct.description": "Qwen-Math 擅長數學問題解決。",
  "qwen2.5-omni-7b.description": "Qwen-Omni 模型支援多模態輸入（影片、音訊、圖片、文字）並可輸出語音與文字。",
  "qwen2.5-vl-32b-instruct.description": "Qwen2.5 VL 32B Instruct 是一款開源多模態模型，適合私有部署與多場景應用。",
  "qwen2.5-vl-72b-instruct.description": "強化指令遵循、數學、問題解決與程式能力，具備更強的物體辨識能力。支援跨格式精準視覺元素定位、長影片理解（最長 10 分鐘）、事件時間點與順序理解、速度感知，以及可控制作業系統或行動裝置的代理。具備強大的關鍵資訊擷取與 JSON 輸出能力。此為系列中最強的 72B 版本。",
  "qwen2.5-vl-7b-instruct.description": "Qwen2.5 VL 7B Instruct 是一款輕量級多模態模型，兼顧部署成本與辨識能力。",
  "qwen2.5-vl-instruct.description": "Qwen2.5-VL 是 Qwen 家族中最新的視覺語言模型。",
  "qwen2.5.description": "Qwen2.5 是阿里巴巴新一代大型語言模型，在多種應用場景中表現優異。",
  "qwen2.5:0.5b.description": "Qwen2.5 是阿里巴巴新一代大型語言模型，在多種應用場景中表現優異。",
  "qwen2.5:1.5b.description": "Qwen2.5 是阿里巴巴新一代大型語言模型，在多種應用場景中表現優異。",
  "qwen2.5:72b.description": "Qwen2.5 是阿里巴巴新一代大型語言模型，在多種應用場景中表現優異。",
  "qwen2.description": "Qwen2 是阿里巴巴新一代大型語言模型，在多種應用場景中表現優異。",
  "qwen2:0.5b.description": "Qwen2 是阿里巴巴新一代大型語言模型，在多種應用場景中表現優異。",
  "qwen2:1.5b.description": "Qwen2 是阿里巴巴新一代大型語言模型，在多種應用場景中表現優異。",
  "qwen2:72b.description": "Qwen2 是阿里巴巴新一代大型語言模型，在多種應用場景中表現優異。",
  "qwen3-0.6b.description": "Qwen3 0.6B 是一款入門級模型，適用於簡單推理與資源受限環境。",
  "qwen3-1.7b.description": "Qwen3 1.7B 是一款超輕量模型，適合邊緣設備與裝置部署。",
  "qwen3-14b.description": "Qwen3 14B 是一款中型模型，適用於多語言問答與文本生成任務。",
  "qwen3-235b-a22b-instruct-2507.description": "Qwen3 235B A22B Instruct 2507 是一款旗艦級指令模型，支援多樣生成與推理任務。",
  "qwen3-235b-a22b-thinking-2507.description": "Qwen3 235B A22B Thinking 2507 是一款超大型思考模型，專為高難度推理任務設計。",
  "qwen3-235b-a22b.description": "Qwen3 是新一代通義千問模型，在推理能力、通用能力、代理能力與多語言表現方面有重大提升，並支援思考模式切換。",
  "qwen3-30b-a3b-instruct-2507.description": "Qwen3 30B A3B Instruct 2507 是一款中大型指令模型，適用於高品質生成與問答任務。",
  "qwen3-30b-a3b-thinking-2507.description": "Qwen3 30B A3B Thinking 2507 是一款中大型思考模型，在準確性與成本間取得平衡。",
  "qwen3-30b-a3b.description": "Qwen3 30B A3B 是一款中大型通用模型，兼顧成本與品質。",
  "qwen3-32b.description": "Qwen3 32B 適用於需要更強理解能力的通用任務。",
  "qwen3-4b.description": "Qwen3 4B 適合小型至中型應用與本地推理場景。",
  "qwen3-8b.description": "Qwen3 8B 是一款輕量模型，具備靈活部署能力，適合高併發工作負載。",
  "qwen3-coder-30b-a3b-instruct.description": "開源 Qwen 程式碼模型。最新的 qwen3-coder-30b-a3b-instruct 基於 Qwen3，具備強大的程式代理能力、工具使用與環境互動能力，支援自主編程，程式碼表現優異，通用能力穩健。",
  "qwen3-coder-480b-a35b-instruct.description": "Qwen3 Coder 480B A35B Instruct 是一款旗艦級程式碼模型，支援多語言編程與複雜程式理解。",
  "qwen3-coder-flash.description": "Qwen 程式碼模型。最新的 Qwen3-Coder 系列基於 Qwen3，具備強大的程式代理能力、工具使用與環境互動能力，支援自主編程，程式碼表現優異，通用能力穩健。",
  "qwen3-coder-plus.description": "Qwen 程式碼模型。最新的 Qwen3-Coder 系列基於 Qwen3，具備強大的程式代理能力、工具使用與環境互動能力，支援自主編程，程式碼表現優異，通用能力穩健。",
  "qwen3-coder:480b.description": "阿里巴巴推出的高效能長上下文模型，適用於代理與程式任務。",
  "qwen3-max-2026-01-23.description": "Qwen3 Max 系列在通用能力、中英文理解、複雜指令執行、主觀開放任務、多語言能力與工具使用方面相較 2.5 系列有大幅提升，幻覺更少。最新版本在代理程式設計與工具使用方面優於 qwen3-max-preview，達到領域 SOTA，針對更複雜的代理需求而設計。",
  "qwen3-max-preview.description": "Qwen 最佳效能模型，適用於複雜多步驟任務。預覽版本支援思考能力。",
  "qwen3-max.description": "Qwen3 Max 模型在通用能力、中文/英文理解、複雜指令遵循、主觀開放任務、多語言能力與工具使用方面，相較 2.5 系列有大幅提升，且幻覺更少。最新版本在代理編程與工具使用方面優於 qwen3-max-preview。此版本達到領先水準，針對更複雜的代理需求設計。",
  "qwen3-next-80b-a3b-instruct.description": "下一代 Qwen3 非思考開源模型。相較前代（Qwen3-235B-A22B-Instruct-2507），具備更佳中文理解、更強邏輯推理與更優文本生成能力。",
  "qwen3-next-80b-a3b-thinking.description": "Qwen3 Next 80B A3B Thinking 是一款旗艦級推理模型，適用於複雜任務。",
  "qwen3-omni-flash.description": "Qwen-Omni 支援文字、圖像、音訊與影片的混合輸入，並可輸出文字或語音。提供多種自然語音風格，支援多語言與方言語音，適用於寫作、視覺識別與語音助理等場景。",
  "qwen3-vl-235b-a22b-instruct.description": "Qwen3 VL 235B A22B Instruct 是一款旗艦級多模態模型，適用於高要求的理解與創作任務。",
  "qwen3-vl-235b-a22b-thinking.description": "Qwen3 VL 235B A22B Thinking 是旗艦級的深度思考版本，專為複雜的多模態推理與規劃任務設計。",
  "qwen3-vl-30b-a3b-instruct.description": "Qwen3 VL 30B A3B Instruct 是一款大型多模態模型，在準確性與推理效能之間取得良好平衡。",
  "qwen3-vl-30b-a3b-thinking.description": "Qwen3 VL 30B A3B Thinking 是深度思考版本，適用於處理複雜的多模態任務。",
  "qwen3-vl-32b-instruct.description": "Qwen3 VL 32B Instruct 是一款經指令微調的多模態模型，適用於高品質的圖文問答與創作。",
  "qwen3-vl-32b-thinking.description": "Qwen3 VL 32B Thinking 是深度思考多模態版本，擅長處理複雜推理與長鏈分析任務。",
  "qwen3-vl-8b-instruct.description": "Qwen3 VL 8B Instruct 是輕量級多模態模型，適合日常視覺問答與應用整合。",
  "qwen3-vl-8b-thinking.description": "Qwen3 VL 8B Thinking 是一款具備思維鏈能力的多模態模型，適用於細緻的視覺推理。",
  "qwen3-vl-flash.description": "Qwen3 VL Flash：輕量高速推理版本，適用於對延遲敏感或高頻請求場景。",
  "qwen3-vl-plus.description": "Qwen VL 是一款具備視覺理解能力的文字生成模型，能進行文字辨識（OCR）、摘要與推理，例如從商品圖片中提取屬性或解決圖像問題。",
  "qwen3.description": "Qwen3 是阿里巴巴新一代大型語言模型，在多種應用場景中展現出強大效能。",
  "qwq-32b-preview.description": "QwQ 是 Qwen 的實驗性研究模型，專注於推理能力的提升。",
  "qwq-32b.description": "QwQ 是 Qwen 系列中的推理模型。相較於標準指令微調模型，它具備更強的思考與推理能力，顯著提升下游任務表現，特別是在處理複雜問題時。QwQ-32B 是中型推理模型，表現可媲美 DeepSeek-R1 與 o1-mini 等頂尖模型。",
  "qwq-plus.description": "QwQ 推理模型基於 Qwen2.5 訓練，透過強化學習大幅提升推理能力。在數學/程式碼（AIME 24/25、LiveCodeBench）與部分通用基準（IFEval、LiveBench）上達到 DeepSeek-R1 的水準。",
  "qwq.description": "QwQ 是 Qwen 系列中的推理模型。相較於標準指令微調模型，它具備更強的思考與推理能力，顯著提升下游任務表現，特別是在處理困難問題時。QwQ-32B 是中型推理模型，表現可媲美 DeepSeek-R1 與 o1-mini 等頂尖模型。",
  "qwq_32b.description": "Qwen 系列中的中型推理模型。相較於標準指令微調模型，QwQ 的思考與推理能力顯著提升下游任務表現，特別是在處理困難問題時。",
  "r1-1776.description": "R1-1776 是 DeepSeek R1 的後訓練版本，旨在提供未經審查、無偏見的事實資訊。",
  "solar-mini-ja.description": "Solar Mini (Ja) 是 Solar Mini 的日文強化版本，同時維持在英文與韓文上的高效能表現。",
  "solar-mini.description": "Solar Mini 是一款緊湊型大型語言模型，效能超越 GPT-3.5，具備強大的多語言能力，支援英文與韓文，提供高效能且佔用資源小的解決方案。",
  "solar-pro.description": "Solar Pro 是 Upstage 推出的高智慧大型語言模型，專注於單 GPU 上的指令遵循任務，IFEval 分數超過 80。目前支援英文，完整版本預計於 2024 年 11 月推出，將擴展語言支援與上下文長度。",
  "sonar-deep-research.description": "Deep Research 提供專業級的深入研究，並將其整合為易於理解與採取行動的報告。",
  "sonar-pro.description": "進階搜尋產品，具備搜尋基礎能力，適用於處理複雜查詢與後續追問。",
  "sonar-reasoning-pro.description": "進階搜尋產品，具備搜尋基礎能力，適用於處理複雜查詢與後續追問。",
  "sonar-reasoning.description": "進階搜尋產品，具備搜尋基礎能力，適用於處理複雜查詢與後續追問。",
  "sonar.description": "輕量級搜尋基礎產品，速度更快、成本更低，適合替代 Sonar Pro。",
  "spark-x.description": "X1.5 更新內容：(1) 新增由 `thinking` 欄位控制的動態思考模式；(2) 支援 64K 輸入與 64K 輸出的大型上下文；(3) 支援 FunctionCall 功能。",
  "stable-diffusion-3-medium.description": "Stability AI 最新的文字轉圖像模型。本版本大幅提升圖像品質、文字理解與風格多樣性，能更準確地解析複雜自然語言提示並生成精緻多樣的圖像。",
  "stable-diffusion-3.5-large-turbo.description": "stable-diffusion-3.5-large-turbo 將對抗擴散蒸餾（ADD）應用於 stable-diffusion-3.5-large，以提升生成速度。",
  "stable-diffusion-3.5-large.description": "stable-diffusion-3.5-large 是一款擁有 8 億參數的 MMDiT 文字轉圖像模型，具備優異的圖像品質與提示對齊能力，支援 1 百萬像素圖像，並可高效運行於消費級硬體。",
  "stable-diffusion-v1.5.description": "stable-diffusion-v1.5 基於 v1.2 檢查點初始化，並在 \"laion-aesthetics v2 5+\" 數據集上以 512x512 解析度進行 595k 步微調，將文字條件影響降低 10%，以提升無分類器引導取樣效果。",
  "stable-diffusion-xl-base-1.0.description": "Stability AI 推出的開源文字轉圖像模型，具備業界領先的創意圖像生成能力。其指令理解能力強，並支援反向提示定義以實現精準生成。",
  "stable-diffusion-xl.description": "stable-diffusion-xl 相較於 v1.5 有重大改進，並達到開源文字轉圖像模型的頂尖水準。改進包括 3 倍大的 UNet 主幹網路、提升圖像品質的精煉模組，以及更高效的訓練技術。",
  "step-1-128k.description": "在效能與成本之間取得平衡，適用於一般場景。",
  "step-1-256k.description": "支援超長上下文，適合長文檔分析。",
  "step-1-32k.description": "支援中等長度對話，適用於多種場景。",
  "step-1-8k.description": "小型模型，適合輕量任務。",
  "step-1-flash.description": "高速模型，適合即時聊天應用。",
  "step-1.5v-mini.description": "具備強大影片理解能力。",
  "step-1o-turbo-vision.description": "具備強大圖像理解能力，在數學與程式碼任務上超越 1o。體積更小，輸出更快。",
  "step-1o-vision-32k.description": "具備強大圖像理解能力，視覺表現優於 Step-1V 系列。",
  "step-1v-32k.description": "支援視覺輸入，實現更豐富的多模態互動。",
  "step-1v-8k.description": "小型視覺模型，適用於基本圖文任務。",
  "step-1x-edit.description": "此模型專注於圖像編輯，可根據使用者提供的圖像與文字進行修改與增強。支援多種輸入格式，包括文字描述與範例圖像，並生成符合使用者意圖的編輯結果。",
  "step-1x-medium.description": "此模型具備強大的文字提示圖像生成能力。原生支援中文，能更好理解中文描述並轉化為視覺特徵，實現更準確的生成。可產出高解析度、高品質圖像，並支援一定程度的風格轉換。",
  "step-2-16k-exp.description": "Step-2 實驗版本，具備最新功能與持續更新。不建議用於生產環境。",
  "step-2-16k.description": "支援大上下文互動，適合複雜對話場景。",
  "step-2-mini.description": "基於新一代自研 MFA 注意力架構，提供類似 Step-1 的效能，成本更低、吞吐更高、延遲更低。具備強大程式能力，適用於通用任務。",
  "step-2x-large.description": "新一代 StepFun 圖像模型，專注於文字提示圖像生成，能產出高品質圖像，具備更真實的質感與更強的中英文文字渲染能力。",
  "step-3.description": "此模型具備強大的視覺感知與複雜推理能力，能準確處理跨領域知識理解、數學與視覺交叉分析，以及多種日常視覺分析任務。",
  "step-r1-v-mini.description": "具備強大圖像理解能力的推理模型，能處理圖像與文字，並在深度推理後生成文字。擅長視覺推理，在數學、程式碼與文字推理方面表現頂尖，支援 100K 上下文。",
  "stepfun-ai/step3.description": "Step3 是 StepFun 推出的尖端多模態推理模型，採用 MoE 架構，總參數 321B，啟用參數 38B。其端到端設計降低解碼成本，實現頂級視覺語言推理能力。透過 MFA 與 AFD 設計，在旗艦與低階加速器上皆具高效能。預訓練涵蓋超過 20 兆文字與 4 兆圖文資料，支援多語言，於數學、程式與多模態基準測試中表現領先。",
  "taichu_llm.description": "基於海量高品質資料訓練，具備更強的文本理解、內容創作與對話問答能力。",
  "taichu_o1.description": "taichu_o1 是新一代推理模型，透過多模態互動與強化學習實現類人思維鏈，支援複雜決策模擬，並在保持高準確輸出的同時揭示推理路徑，適用於策略分析與深度思考。",
  "taichu_vl.description": "結合圖像理解、知識遷移與邏輯歸因，在圖文問答方面表現卓越。",
  "tencent/Hunyuan-A13B-Instruct.description": "Hunyuan-A13B-Instruct 採用總參數量 80B、啟用參數 13B 的架構，媲美更大型模型。支援快慢混合推理、穩定的長文本理解，並在 BFCL-v3 與 τ-Bench 上展現領先代理能力。GQA 與多量化格式實現高效推理。",
  "tencent/Hunyuan-MT-7B.description": "混元翻譯模型包含 Hunyuan-MT-7B 與集成模型 Hunyuan-MT-Chimera。Hunyuan-MT-7B 是一款輕量級 7B 翻譯模型，支援 33 種語言及 5 種中國少數民族語言。在 WMT25 中於 31 組語言對中獲得 30 項第一名。騰訊混元採用完整訓練流程，從預訓練到 SFT、翻譯強化學習與集成強化學習，在同級模型中表現領先，部署高效便捷。",
  "text-embedding-3-large.description": "目前最強大的英文與非英文任務嵌入模型。",
  "text-embedding-3-small.description": "適用於檢索與 RAG 場景的高效、具成本效益的新一代嵌入模型。",
  "thudm/glm-4-32b.description": "GLM-4-32B-0414 是一款 32B 中英雙語開源模型，針對程式碼生成、函數調用與代理任務進行優化。預訓練資料達 15T，涵蓋高品質與高推理需求內容，並透過人類偏好對齊、拒絕採樣與強化學習進一步優化。擅長複雜推理、內容生成與結構化輸出，在多項基準測試中達到 GPT-4o 與 DeepSeek-V3-0324 的水準。",
  "thudm/glm-4-32b:free.description": "GLM-4-32B-0414 是一款 32B 中英雙語開源模型，針對程式碼生成、函數調用與代理任務進行優化。預訓練資料達 15T，涵蓋高品質與高推理需求內容，並透過人類偏好對齊、拒絕採樣與強化學習進一步優化。擅長複雜推理、內容生成與結構化輸出，在多項基準測試中達到 GPT-4o 與 DeepSeek-V3-0324 的水準。",
  "thudm/glm-4-9b-chat.description": "智譜 AI 最新 GLM-4 預訓練模型的開源版本。",
  "thudm/glm-z1-32b.description": "GLM-Z1-32B-0414 是 GLM-4-32B 的增強推理版本，專為數學、邏輯與程式碼密集型問題解決而設計。透過擴展的強化學習（任務特定與通用偏好對齊）提升多步驟任務表現。相較於 GLM-4-32B，Z1 在結構化推理與正式領域能力上有顯著提升。\n\n支援透過提示工程強化「思考」步驟，提升長輸出的一致性，並針對代理流程進行優化，支援長上下文（透過 YaRN）、JSON 工具調用與細緻採樣以穩定推理。非常適合需要謹慎多步推理或形式推導的應用場景。",
  "thudm/glm-z1-rumination-32b.description": "GLM Z1 Rumination 32B 是 GLM-4-Z1 系列中的深度推理模型，針對需長時間思考的開放式複雜任務進行優化。基於 glm-4-32b-0414，加入額外的強化學習階段與多階段對齊，引入「反思」能力，模擬延伸的認知處理過程，包括迭代推理、多跳分析與工具輔助流程（如搜尋、檢索與具引用意識的綜合）。\n\n擅長研究寫作、比較分析與複雜問答。支援搜尋/導航原語（`search`、`click`、`open`、`finish`）的函數調用，適用於代理流程。反思行為透過多輪迴圈、基於規則的獎勵塑形與延遲決策機制控制，並以 OpenAI 內部對齊架構等深度研究框架為基準。此版本重深度而非速度。",
  "tngtech/deepseek-r1t-chimera:free.description": "DeepSeek-R1T-Chimera 是由 DeepSeek-R1 與 DeepSeek-V3（0324）合併而成，結合 R1 的推理能力與 V3 的代幣效率。基於 DeepSeek-MoE Transformer，針對通用文本生成進行優化。\n\n透過合併預訓練權重，在推理、效率與指令遵循間取得平衡。以 MIT 授權釋出，供研究與商業使用。",
  "togethercomputer/StripedHyena-Nous-7B.description": "StripedHyena Nous（7B）透過其架構與策略實現更高的運算效率。",
  "tts-1-hd.description": "最新的文字轉語音模型，優化音質表現。",
  "tts-1.description": "最新的文字轉語音模型，優化即時速度。",
  "upstage/SOLAR-10.7B-Instruct-v1.0.description": "Upstage SOLAR Instruct v1（11B）針對精準指令任務進行調校，語言表現強勁。",
  "us.anthropic.claude-3-5-sonnet-20241022-v2:0.description": "Claude 3.5 Sonnet 提升業界標準，在多項評估中超越競爭對手與 Claude 3 Opus，同時保持中階速度與成本。",
  "us.anthropic.claude-3-7-sonnet-20250219-v1:0.description": "Claude 3.7 Sonnet 是 Anthropic 最新一代最快速模型。相較於 Claude 3 Haiku，在多項技能上有所提升，並在多個智慧基準測試中超越前一代旗艦 Claude 3 Opus。",
  "us.anthropic.claude-haiku-4-5-20251001-v1:0.description": "Claude Haiku 4.5 是 Anthropic 目前最快速且最智慧的 Haiku 模型，具備閃電般的速度與延伸思考能力。",
  "us.anthropic.claude-opus-4-6-v1.description": "Claude Opus 4.6 是 Anthropic 最智慧的模型，專為建構智能代理與程式設計而打造。",
  "us.anthropic.claude-sonnet-4-5-20250929-v1:0.description": "Claude Sonnet 4.5 是 Anthropic 目前最智慧的模型。",
  "v0-1.0-md.description": "v0-1.0-md 是透過 v0 API 提供的舊版模型。",
  "v0-1.5-lg.description": "v0-1.5-lg 適用於進階思考或推理任務。",
  "v0-1.5-md.description": "v0-1.5-md 適合日常任務與 UI 生成。",
  "vercel/v0-1.0-md.description": "存取 v0 背後的模型，以生成、修復與優化現代 Web 應用，具備框架特定推理與最新知識。",
  "vercel/v0-1.5-md.description": "存取 v0 背後的模型，以生成、修復與優化現代 Web 應用，具備框架特定推理與最新知識。",
  "volcengine/doubao-seed-code.description": "豆包 Seed Code 是字節跳動火山引擎推出的 LLM，針對代理式程式設計進行優化，在程式與代理基準上表現優異，支援 256K 上下文。",
  "wan2.2-t2i-flash.description": "萬象 2.2 Speed 是最新模型，在創意、穩定性與寫實度方面全面升級，實現快速生成與高性價比。",
  "wan2.2-t2i-plus.description": "萬象 2.2 Pro 是最新模型，在創意、穩定性與寫實度方面全面升級，生成細節更豐富。",
  "wanx-v1.description": "基礎文字轉圖像模型。對應通義萬象 1.0 通用版。",
  "wanx2.0-t2i-turbo.description": "擅長紋理人像，速度適中、成本較低。對應通義萬象 2.0 Speed。",
  "wanx2.1-t2i-plus.description": "全面升級版本，圖像細節更豐富，速度略慢。對應通義萬象 2.1 Pro。",
  "wanx2.1-t2i-turbo.description": "全面升級版本，生成快速、整體品質強、性價比高。對應通義萬象 2.1 Speed。",
  "whisper-1.description": "通用語音識別模型，支援多語言 ASR、語音翻譯與語言識別。",
  "wizardlm2.description": "WizardLM 2 是微軟 AI 推出的語言模型，擅長複雜對話、多語言任務、推理與助手應用。",
  "wizardlm2:8x22b.description": "WizardLM 2 是微軟 AI 推出的語言模型，擅長複雜對話、多語言任務、推理與助手應用。",
  "x-ai/grok-4-fast-non-reasoning.description": "Grok 4 Fast（非推理版）是 xAI 推出的高吞吐、低成本多模態模型（支援 2M 上下文），適用於對延遲與成本敏感但不需模型內推理的場景。可透過 API 的 reasoning 參數啟用推理功能。提示與完成可能被 xAI 或 OpenRouter 用於改進未來模型。",
  "x-ai/grok-4-fast.description": "Grok 4 Fast 是 xAI 推出的高吞吐、低成本模型（支援 2M 上下文），適用於高併發與長上下文應用場景。",
  "x-ai/grok-4.1-fast-non-reasoning.description": "Grok 4.1 Fast（非推理版）是 xAI 推出的高吞吐、低成本多模態模型（支援 2M 上下文），適用於對延遲與成本敏感但不需模型內推理的場景。可透過 API 的 reasoning 參數啟用推理功能。提示與完成可能被 xAI 或 OpenRouter 用於改進未來模型。",
  "x-ai/grok-4.1-fast.description": "Grok 4.1 Fast 是 xAI 推出的高吞吐、低成本模型（支援 2M 上下文），適用於高併發與長上下文應用場景。",
  "x-ai/grok-4.description": "Grok 4 是 xAI 的旗艦推理模型，具備強大的推理與多模態能力。",
  "x-ai/grok-code-fast-1.description": "Grok Code Fast 1 是 xAI 推出的快速程式碼模型，輸出可讀性高，適合工程應用。",
  "xai/grok-2-vision.description": "Grok 2 Vision 擅長視覺任務，在視覺數學推理（MathVista）與文件問答（DocVQA）上表現領先。可處理文件、圖表、截圖與照片。",
  "xai/grok-2.description": "Grok 2 是前沿模型，具備最先進的推理能力，擅長聊天、編碼與推理，在 LMSYS 排名中超越 Claude 3.5 Sonnet 與 GPT-4 Turbo。",
  "xai/grok-3-fast.description": "xAI 的旗艦模型，擅長企業應用如資料擷取、編碼與摘要，具備金融、醫療、法律與科學等領域的深度知識。快速版本運行於更快基礎設施，回應速度更快但每字成本較高。",
  "xai/grok-3-mini-fast.description": "xAI 的輕量模型，在回應前會進行思考，適合簡單或邏輯型任務，不需深度領域知識。提供原始推理軌跡。快速版本運行於更快基礎設施，回應速度更快但每字成本較高。",
  "xai/grok-3-mini.description": "xAI 的輕量模型，在回應前會進行思考，適合簡單或邏輯型任務，不需深度領域知識。提供原始推理軌跡。",
  "xai/grok-3.description": "xAI 的旗艦模型，擅長企業應用如資料擷取、編碼與摘要，具備金融、醫療、法律與科學等領域的深度知識。",
  "xai/grok-4.description": "xAI 最新旗艦模型，在自然語言、數學與推理方面表現卓越，是理想的全能型選擇。",
  "yi-large-fc.description": "基於 yi-large，增強工具調用能力，適用於代理與工作流程場景。",
  "yi-large-preview.description": "早期版本；建議使用更新的 yi-large。",
  "yi-large-rag.description": "基於 yi-large 的進階服務，結合檢索與生成，透過即時網頁搜尋提供精準答案。",
  "yi-large-turbo.description": "具備卓越性價比與效能，兼顧品質、速度與成本。",
  "yi-large.description": "全新 100B 參數模型，擅長問答與文本生成。",
  "yi-lightning-lite.description": "輕量版本；建議使用 yi-lightning。",
  "yi-lightning.description": "最新高效能模型，推理速度更快，輸出品質更高。",
  "yi-medium-200k.description": "支援 200K 長上下文的模型，適用於深度長文理解與生成。",
  "yi-medium.description": "調校後的中型模型，能力與性價比平衡，優化指令遵循表現。",
  "yi-spark.description": "緊湊快速的模型，強化數學與編碼能力。",
  "yi-vision-v2.description": "適用於複雜任務的視覺模型，具備強大的多圖理解與分析能力。",
  "yi-vision.description": "適用於複雜任務的視覺模型，具備強大的圖像理解與分析能力。",
  "z-ai/glm-4.5-air.description": "GLM 4.5 Air 是 GLM 4.5 的輕量版本，適用於成本敏感場景，同時保有強大推理能力。",
  "z-ai/glm-4.5.description": "GLM 4.5 是 Z.AI 的旗艦模型，採用混合推理設計，針對工程與長上下文任務進行優化。",
  "z-ai/glm-4.6.description": "GLM 4.6 是 Z.AI 的旗艦模型，擴展上下文長度並增強編碼能力。",
  "z-ai/glm-4.7.description": "GLM-4.7 是智譜最新旗艦模型，具備更強通用能力、回應更自然簡潔，並提供更具沉浸感的寫作體驗。",
  "zai-org/GLM-4.5-Air.description": "GLM-4.5-Air 是一款基於專家混合架構的代理應用基礎模型，針對工具使用、網頁瀏覽、軟體工程與前端編碼進行優化，並可與 Claude Code、Roo Code 等程式代理整合。採用混合推理處理複雜與日常任務。",
  "zai-org/GLM-4.5.description": "GLM-4.5 是一款基於專家混合架構的代理應用基礎模型，深度優化工具使用、網頁瀏覽、軟體工程與前端編碼，並可與 Claude Code、Roo Code 等程式代理整合。採用混合推理處理複雜與日常任務。",
  "zai-org/GLM-4.5V.description": "GLM-4.5V 是智譜 AI 最新 VLM，基於 GLM-4.5-Air 旗艦文本模型（總參數 106B，啟用 12B），採用 MoE 架構，在成本較低的情況下提供強大效能。延續 GLM-4.1V-Thinking 路線，加入 3D-RoPE 提升三維空間推理能力。透過預訓練、SFT 與強化學習優化，支援圖像、影片與長文檔，在 41 項公開多模態基準中名列前茅。提供「思考模式」切換，讓用戶在速度與深度間取得平衡。",
  "zai-org/GLM-4.6.description": "相較於 GLM-4.5，GLM-4.6 將上下文從 128K 擴展至 200K，適用於更複雜的代理任務。在程式碼基準上得分更高，並在 Claude Code、Cline、Roo Code、Kilo Code 等應用中展現更強的實際效能，包括更佳的前端頁面生成。推理能力提升，推理過程中支援工具使用，整體能力更強。更好地整合至代理框架，強化工具/搜尋代理，並具備更符合人類偏好的寫作風格與角色扮演自然度。",
  "zai/glm-4.5-air.description": "GLM-4.5 與 GLM-4.5-Air 是我們針對代理應用推出的最新旗艦模型，皆採用 MoE 架構。GLM-4.5 總參數 355B，啟用 32B；GLM-4.5-Air 較輕量，總參數 106B，啟用 12B。",
  "zai/glm-4.5.description": "GLM-4.5 系列專為代理設計。旗艦版 GLM-4.5 結合推理、編碼與代理能力，總參數 355B（啟用 32B），提供混合推理系統的雙模式運行。",
  "zai/glm-4.5v.description": "GLM-4.5V 建構於 GLM-4.5-Air 基礎上，延續 GLM-4.1V-Thinking 技術，並以強大的 106B MoE 架構擴展能力。",
  "zenmux/auto.description": "ZenMux 自動路由會根據您的請求，從支援的選項中選擇性價比最高、效能最佳的模型。"
}
