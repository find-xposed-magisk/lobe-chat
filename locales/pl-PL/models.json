{
  "01-ai/yi-1.5-34b-chat.description": "Najnowszy otwartoźródłowy model 01.AI z 34 miliardami parametrów, dostrojony do różnych scenariuszy dialogowych, trenowany na wysokiej jakości danych i dostosowany do preferencji użytkowników.",
  "01-ai/yi-1.5-9b-chat.description": "Najnowszy otwartoźródłowy model 01.AI z 9 miliardami parametrów, dostrojony do różnych scenariuszy dialogowych, trenowany na wysokiej jakości danych i dostosowany do preferencji użytkowników.",
  "360/deepseek-r1.description": "DeepSeek-R1 wdrożony przez 360 wykorzystuje skalowane uczenie przez wzmocnienie (RL) w fazie post-treningowej, znacząco poprawiając zdolności rozumowania przy minimalnym oznakowaniu danych. Dorównuje modelowi OpenAI o1 w zadaniach z matematyki, programowania i rozumowania językowego.",
  "360gpt-pro-trans.description": "Model wyspecjalizowany w tłumaczeniach, głęboko dostrojony w celu zapewnienia najwyższej jakości przekładów.",
  "360gpt-pro.description": "360GPT Pro to kluczowy model AI od 360, oferujący wydajne przetwarzanie tekstu w różnorodnych scenariuszach NLP, z obsługą długich tekstów i dialogów wieloetapowych.",
  "360gpt-turbo-responsibility-8k.description": "360GPT Turbo Responsibility 8K kładzie nacisk na bezpieczeństwo semantyczne i odpowiedzialność w aplikacjach wrażliwych na treść, zapewniając precyzyjne i niezawodne doświadczenia użytkownika.",
  "360gpt-turbo.description": "360GPT Turbo oferuje wysoką wydajność obliczeniową i zdolności konwersacyjne, z doskonałym rozumieniem semantycznym i efektywnością generowania — idealny dla firm i deweloperów.",
  "360gpt2-o1.description": "360gpt2-o1 buduje łańcuch rozumowania poprzez przeszukiwanie drzewa z mechanizmem refleksji i treningiem RL, umożliwiając samorefleksję i autokorektę.",
  "360gpt2-pro.description": "360GPT2 Pro to zaawansowany model NLP od 360, wyróżniający się w generowaniu i rozumieniu tekstu, szczególnie w zadaniach kreatywnych, transformacjach i odgrywaniu ról.",
  "360zhinao2-o1.description": "360zhinao2-o1 buduje łańcuch rozumowania poprzez przeszukiwanie drzewa z mechanizmem refleksji i treningiem RL, umożliwiając samorefleksję i autokorektę.",
  "4.0Ultra.description": "Spark Ultra to najpotężniejszy model z serii Spark, ulepszający rozumienie tekstu i podsumowywanie oraz wzbogacający wyszukiwanie internetowe. Stanowi kompleksowe rozwiązanie zwiększające produktywność w pracy i precyzję odpowiedzi, pozycjonując się jako wiodący produkt inteligentny.",
  "AnimeSharp.description": "AnimeSharp (znany również jako „4x-AnimeSharp”) to otwartoźródłowy model super-rozdzielczości oparty na ESRGAN autorstwa Kim2091, skoncentrowany na skalowaniu i wyostrzaniu obrazów w stylu anime. W lutym 2022 roku zmieniono jego nazwę z „4x-TextSharpV1”; pierwotnie służył również do obrazów tekstowych, ale został silnie zoptymalizowany pod kątem treści anime.",
  "Baichuan2-Turbo.description": "Wykorzystuje rozszerzenie wyszukiwania do połączenia modelu z wiedzą dziedzinową i internetową. Obsługuje przesyłanie plików PDF/Word oraz wprowadzanie adresów URL w celu szybkiego i kompleksowego pozyskiwania informacji oraz generowania profesjonalnych i precyzyjnych odpowiedzi.",
  "Baichuan3-Turbo-128k.description": "Dzięki ultradługiemu kontekstowi 128K, zoptymalizowany do intensywnych zastosowań biznesowych, oferuje znaczne korzyści i wysoką wartość. W porównaniu z Baichuan2, tworzenie treści wzrasta o 20%, pytania i odpowiedzi oparte na wiedzy o 17%, a odgrywanie ról o 40%. Ogólna wydajność przewyższa GPT-3.5.",
  "Baichuan3-Turbo.description": "Zoptymalizowany do intensywnych zastosowań biznesowych, oferuje znaczne korzyści i wysoką wartość. W porównaniu z Baichuan2, tworzenie treści wzrasta o 20%, pytania i odpowiedzi oparte na wiedzy o 17%, a odgrywanie ról o 40%. Ogólna wydajność przewyższa GPT-3.5.",
  "Baichuan4-Air.description": "Model o najwyższej wydajności w Chinach, przewyższający czołowe modele zagraniczne w zadaniach w języku chińskim, takich jak wiedza, długie teksty i generowanie kreatywne. Oferuje również wiodące w branży możliwości multimodalne z silnymi wynikami w autorytatywnych testach porównawczych.",
  "Baichuan4-Turbo.description": "Model o najwyższej wydajności w Chinach, przewyższający czołowe modele zagraniczne w zadaniach w języku chińskim, takich jak wiedza, długie teksty i generowanie kreatywne. Oferuje również wiodące w branży możliwości multimodalne z silnymi wynikami w autorytatywnych testach porównawczych.",
  "Baichuan4.description": "Najlepsza krajowa wydajność, przewyższająca czołowe modele zagraniczne w zadaniach w języku chińskim, takich jak wiedza encyklopedyczna, długie teksty i generowanie kreatywne. Oferuje również wiodące w branży możliwości multimodalne i silne wyniki w testach porównawczych.",
  "ByteDance-Seed/Seed-OSS-36B-Instruct.description": "Seed-OSS to rodzina otwartoźródłowych modeli LLM od ByteDance Seed, zaprojektowana z myślą o obsłudze długiego kontekstu, rozumowaniu, zadaniach agentowych i ogólnych możliwościach. Seed-OSS-36B-Instruct to model z 36 miliardami parametrów dostrojony do instrukcji, z natywnym ultradługim kontekstem do przetwarzania dużych dokumentów lub baz kodu. Zoptymalizowany pod kątem rozumowania, generowania kodu i zadań agentowych (użycie narzędzi), zachowując przy tym silne ogólne zdolności. Kluczową cechą jest „Budżet Myślenia”, umożliwiający elastyczną długość rozumowania w celu zwiększenia efektywności.",
  "DeepSeek-R1-Distill-Llama-70B.description": "DeepSeek R1, większy i inteligentniejszy model z rodziny DeepSeek, został zdestylowany do architektury Llama 70B. Testy porównawcze i oceny ludzkie pokazują, że przewyższa bazowy Llama 70B, szczególnie w zadaniach matematycznych i wymagających precyzji faktów.",
  "DeepSeek-R1-Distill-Qwen-1.5B.description": "Model zdestylowany z DeepSeek-R1 na bazie Qwen2.5-Math-1.5B. Uczenie przez wzmocnienie i dane cold-start optymalizują wydajność rozumowania, ustanawiając nowe standardy dla otwartych modeli wielozadaniowych.",
  "DeepSeek-R1-Distill-Qwen-14B.description": "Modele DeepSeek-R1-Distill są dostrajane z otwartoźródłowych modeli przy użyciu próbek danych generowanych przez DeepSeek-R1.",
  "DeepSeek-R1-Distill-Qwen-32B.description": "Modele DeepSeek-R1-Distill są dostrajane z otwartoźródłowych modeli przy użyciu próbek danych generowanych przez DeepSeek-R1.",
  "DeepSeek-R1-Distill-Qwen-7B.description": "Model zdestylowany z DeepSeek-R1 na bazie Qwen2.5-Math-7B. Uczenie przez wzmocnienie i dane cold-start optymalizują wydajność rozumowania, ustanawiając nowe standardy dla otwartych modeli wielozadaniowych.",
  "DeepSeek-R1.description": "DeepSeek-R1 stosuje skalowane uczenie przez wzmocnienie w fazie post-treningowej, znacząco poprawiając zdolności rozumowania przy bardzo małej liczbie oznakowanych danych. Dorównuje produkcyjnemu modelowi OpenAI o1 w zadaniach z matematyki, programowania i rozumowania językowego.",
  "DeepSeek-V3-1.description": "DeepSeek V3.1 to model nowej generacji do rozumowania, z ulepszonym rozumowaniem złożonym i łańcuchowym, odpowiedni do zadań wymagających głębokiej analizy.",
  "DeepSeek-V3-Fast.description": "Dostawca: sophnet. DeepSeek V3 Fast to wersja o wysokim TPS modelu DeepSeek V3 0324, w pełnej precyzji (bez kwantyzacji), z lepszymi wynikami w kodzie i matematyce oraz szybszymi odpowiedziami.",
  "DeepSeek-V3.1-Fast.description": "DeepSeek V3.1 Fast to szybka wersja modelu DeepSeek V3.1 o wysokim TPS. Tryb hybrydowego myślenia: dzięki szablonom czatu jeden model obsługuje zarówno tryb myślący, jak i niemyslący. Inteligentniejsze użycie narzędzi: optymalizacje po treningu poprawiają wydajność zadań agentowych i użycia narzędzi.",
  "DeepSeek-V3.1-Think.description": "Tryb myślenia DeepSeek-V3.1: nowy hybrydowy model rozumowania z trybami myślącym i niemyslącym, bardziej wydajny niż DeepSeek-R1-0528. Optymalizacje po treningu znacząco poprawiają użycie narzędzi agentowych i wydajność zadań agentowych.",
  "DeepSeek-V3.description": "DeepSeek-V3 to model MoE opracowany przez DeepSeek. Przewyższa inne otwarte modele, takie jak Qwen2.5-72B i Llama-3.1-405B w wielu testach porównawczych i konkuruje z czołowymi zamkniętymi modelami, takimi jak GPT-4o i Claude 3.5 Sonnet.",
  "Doubao-lite-128k.description": "Doubao-lite oferuje ultraszybkie odpowiedzi i lepszy stosunek jakości do ceny, z elastycznymi opcjami dla różnych scenariuszy. Obsługuje kontekst 128K do wnioskowania i dostrajania.",
  "Doubao-lite-32k.description": "Doubao-lite oferuje ultraszybkie odpowiedzi i lepszy stosunek jakości do ceny, z elastycznymi opcjami dla różnych scenariuszy. Obsługuje kontekst 32K do wnioskowania i dostrajania.",
  "Doubao-lite-4k.description": "Doubao-lite oferuje ultraszybkie odpowiedzi i lepszy stosunek jakości do ceny, z elastycznymi opcjami dla różnych scenariuszy. Obsługuje kontekst 4K do wnioskowania i dostrajania.",
  "Doubao-pro-128k.description": "Najlepszy model flagowy do złożonych zadań, doskonały w zadaniach typu QA z odniesieniami, streszczaniu, tworzeniu treści, klasyfikacji i odgrywaniu ról. Obsługuje kontekst 128K do wnioskowania i dostrajania.",
  "Doubao-pro-32k.description": "Najlepszy model flagowy do złożonych zadań, doskonały w zadaniach typu QA z odniesieniami, streszczaniu, tworzeniu treści, klasyfikacji i odgrywaniu ról. Obsługuje kontekst 32K do wnioskowania i dostrajania.",
  "Doubao-pro-4k.description": "Najlepszy model flagowy do złożonych zadań, doskonały w zadaniach typu QA z odniesieniami, streszczaniu, tworzeniu treści, klasyfikacji i odgrywaniu ról. Obsługuje kontekst 4K do wnioskowania i dostrajania.",
  "DreamO.description": "DreamO to otwartoźródłowy model personalizacji obrazów opracowany wspólnie przez ByteDance i Uniwersytet Pekiński, wykorzystujący zunifikowaną architekturę do obsługi wielozadaniowego generowania obrazów. Wykorzystuje wydajne modelowanie kompozycyjne do generowania spójnych, dostosowanych obrazów na podstawie tożsamości, tematu, stylu, tła i innych warunków określonych przez użytkownika.",
  "ERNIE-3.5-128K.description": "Flagowy model LLM Baidu, wytrenowany na ogromnych korpusach chińsko-angielskich, o silnych ogólnych możliwościach w zakresie czatu, tworzenia treści i korzystania z wtyczek; obsługuje automatyczną integrację z wtyczką Baidu Search dla aktualnych odpowiedzi.",
  "ERNIE-3.5-8K-Preview.description": "Flagowy model LLM Baidu, wytrenowany na ogromnych korpusach chińsko-angielskich, o silnych ogólnych możliwościach w zakresie czatu, tworzenia treści i korzystania z wtyczek; obsługuje automatyczną integrację z wtyczką Baidu Search dla aktualnych odpowiedzi.",
  "ERNIE-3.5-8K.description": "Flagowy model LLM Baidu, wytrenowany na ogromnych korpusach chińsko-angielskich, o silnych ogólnych możliwościach w zakresie czatu, tworzenia treści i korzystania z wtyczek; obsługuje automatyczną integrację z wtyczką Baidu Search dla aktualnych odpowiedzi.",
  "ERNIE-4.0-8K-Latest.description": "Flagowy ultraduży model LLM Baidu z kompleksowymi ulepszeniami względem ERNIE 3.5, odpowiedni do złożonych zadań w różnych dziedzinach; obsługuje integrację z wtyczką Baidu Search dla aktualnych odpowiedzi.",
  "ERNIE-4.0-8K-Preview.description": "Flagowy ultraduży model LLM Baidu z kompleksowymi ulepszeniami względem ERNIE 3.5, odpowiedni do złożonych zadań w różnych dziedzinach; obsługuje integrację z wtyczką Baidu Search dla aktualnych odpowiedzi.",
  "ERNIE-4.0-Turbo-8K-Latest.description": "Flagowy ultraduży model LLM Baidu o wysokiej wydajności ogólnej do złożonych zadań, z integracją wtyczki Baidu Search dla aktualnych odpowiedzi. Przewyższa ERNIE 4.0.",
  "ERNIE-4.0-Turbo-8K-Preview.description": "Flagowy ultraduży model LLM Baidu o wysokiej wydajności ogólnej do złożonych zadań, z integracją wtyczki Baidu Search dla aktualnych odpowiedzi. Przewyższa ERNIE 4.0.",
  "ERNIE-Character-8K.description": "Model LLM Baidu dla domen wertykalnych, takich jak NPC w grach, obsługa klienta i odgrywanie ról, z lepszą spójnością postaci, silniejszym podążaniem za instrukcjami i lepszym rozumowaniem.",
  "ERNIE-Lite-Pro-128K.description": "Lekki model LLM Baidu, łączący jakość i wydajność wnioskowania, lepszy niż ERNIE Lite i odpowiedni dla akceleratorów o niskiej mocy obliczeniowej.",
  "ERNIE-Speed-128K.description": "Najnowszy model LLM Baidu o wysokiej wydajności (2024), o silnych ogólnych możliwościach, odpowiedni jako baza do dostrajania w celu obsługi konkretnych scenariuszy, z doskonałą wydajnością rozumowania.",
  "ERNIE-Speed-Pro-128K.description": "Najnowszy model LLM Baidu o wysokiej wydajności (2024), o silnych ogólnych możliwościach, lepszy niż ERNIE Speed, odpowiedni jako baza do dostrajania z doskonałą wydajnością rozumowania.",
  "FLUX-1.1-pro.description": "FLUX.1.1 Pro",
  "FLUX.1-Kontext-dev.description": "FLUX.1-Kontext-dev to multimodalny model generowania i edycji obrazów od Black Forest Labs, oparty na architekturze Rectified Flow Transformer z 12 miliardami parametrów. Skupia się na generowaniu, rekonstrukcji, ulepszaniu lub edytowaniu obrazów w określonym kontekście. Łączy kontrolowaną generację modeli dyfuzyjnych z modelowaniem kontekstu przez Transformery, wspierając wysokiej jakości wyniki w zadaniach takich jak inpainting, outpainting i rekonstrukcja scen wizualnych.",
  "FLUX.1-Kontext-pro.description": "FLUX.1 Kontext [pro]",
  "FLUX.1-dev.description": "FLUX.1-dev to otwartoźródłowy multimodalny model językowy (MLLM) od Black Forest Labs, zoptymalizowany do zadań obraz-tekst, łączący rozumienie i generowanie obrazów/tekstu. Zbudowany na zaawansowanych LLM (np. Mistral-7B), wykorzystuje starannie zaprojektowany enkoder wizji i wieloetapowe dostrajanie instrukcji, umożliwiając multimodalną koordynację i złożone rozumowanie.",
  "Gryphe/MythoMax-L2-13b.description": "MythoMax-L2 (13B) to innowacyjny model do różnorodnych dziedzin i złożonych zadań.",
  "HelloMeme.description": "HelloMeme to narzędzie AI do generowania memów, GIF-ów lub krótkich filmów z dostarczonych obrazów lub ruchów. Nie wymaga umiejętności rysowania ani kodowania — wystarczy obraz referencyjny, aby stworzyć zabawne, atrakcyjne i stylistycznie spójne treści.",
  "HiDream-I1-Full.description": "HiDream-E1-Full to otwartoźródłowy multimodalny model edycji obrazów od HiDream.ai, oparty na zaawansowanej architekturze Diffusion Transformer i silnym rozumieniu języka (wbudowany LLaMA 3.1-8B-Instruct). Obsługuje generowanie obrazów sterowane językiem naturalnym, transfer stylu, lokalne edycje i przemalowywanie, z doskonałym rozumieniem i wykonaniem obraz-tekst.",
  "HunyuanDiT-v1.2-Diffusers-Distilled.description": "hunyuandit-v1.2-distilled to lekki model tekst-na-obraz zoptymalizowany przez destylację do szybkiego generowania wysokiej jakości obrazów, szczególnie odpowiedni dla środowisk o ograniczonych zasobach i generowania w czasie rzeczywistym.",
  "InstantCharacter.description": "InstantCharacter to model generowania spersonalizowanych postaci bez potrzeby dostrajania, wydany przez Tencent AI w 2025 roku, mający na celu wierne i spójne generowanie postaci w różnych scenariuszach. Może modelować postać na podstawie jednego obrazu referencyjnego i elastycznie przenosić ją między stylami, działaniami i tłami.",
  "InternVL2-8B.description": "InternVL2-8B to potężny model wizja-język obsługujący multimodalne przetwarzanie obraz-tekst, dokładnie rozpoznający zawartość obrazu i generujący odpowiednie opisy lub odpowiedzi.",
  "InternVL2.5-26B.description": "InternVL2.5-26B to potężny model wizja-język obsługujący multimodalne przetwarzanie obraz-tekst, dokładnie rozpoznający zawartość obrazu i generujący odpowiednie opisy lub odpowiedzi.",
  "Kolors.description": "Kolors to model tekst-na-obraz opracowany przez zespół Kuaishou Kolors. Wytrenowany na miliardach parametrów, wyróżnia się jakością wizualną, rozumieniem semantyki chińskiej i renderowaniem tekstu.",
  "Kwai-Kolors/Kolors.description": "Kolors to wielkoskalowy model latent-diffusion tekst-na-obraz od zespołu Kuaishou Kolors. Wytrenowany na miliardach par tekst-obraz, wyróżnia się jakością wizualną, dokładnością semantyczną i renderowaniem tekstu w języku chińskim/angielskim, z silnym rozumieniem i generowaniem treści w języku chińskim.",
  "Kwaipilot/KAT-Dev.description": "KAT-Dev (32B) to otwartoźródłowy model 32B do zadań inżynierii oprogramowania. Osiąga 62,4% skuteczności na SWE-Bench Verified, zajmując 5. miejsce wśród otwartych modeli. Zoptymalizowany przez mid-training, SFT i RL do uzupełniania kodu, naprawy błędów i przeglądu kodu.",
  "Llama-3.2-11B-Vision-Instruct.description": "Silne rozumowanie obrazowe na obrazach wysokiej rozdzielczości, odpowiednie do zastosowań wymagających rozumienia wizualnego.",
  "Llama-3.2-90B-Vision-Instruct\t.description": "Zaawansowane rozumowanie obrazowe dla aplikacji agentów rozumiejących wizję.",
  "Meta-Llama-3-3-70B-Instruct.description": "Llama 3.3 70B to wszechstronny model Transformer do zadań czatu i generowania treści.",
  "Meta-Llama-3.1-405B-Instruct.description": "Model tekstowy Llama 3.1 dostrojony do instrukcji, zoptymalizowany do czatu wielojęzycznego, osiągający wysokie wyniki w branżowych benchmarkach wśród modeli otwartych i zamkniętych.",
  "Meta-Llama-3.1-70B-Instruct.description": "Model tekstowy Llama 3.1 dostrojony do instrukcji, zoptymalizowany do czatu wielojęzycznego, osiągający wysokie wyniki w branżowych benchmarkach wśród modeli otwartych i zamkniętych.",
  "Meta-Llama-3.1-8B-Instruct.description": "Model tekstowy Llama 3.1 dostrojony do instrukcji, zoptymalizowany do czatu wielojęzycznego, osiągający wysokie wyniki w branżowych benchmarkach wśród modeli otwartych i zamkniętych.",
  "Meta-Llama-3.2-1B-Instruct.description": "Nowoczesny mały model językowy o silnym rozumieniu języka, doskonałym rozumowaniu i generowaniu tekstu.",
  "Meta-Llama-3.2-3B-Instruct.description": "Nowoczesny mały model językowy o silnym rozumieniu języka, doskonałym rozumowaniu i generowaniu tekstu.",
  "Meta-Llama-3.3-70B-Instruct.description": "Llama 3.3 to najbardziej zaawansowany wielojęzyczny otwartoźródłowy model Llama, oferujący wydajność zbliżoną do 405B przy bardzo niskim koszcie. Opiera się na architekturze Transformer i został ulepszony za pomocą SFT i RLHF dla użyteczności i bezpieczeństwa. Wersja dostrojona do instrukcji jest zoptymalizowana do czatu wielojęzycznego i przewyższa wiele modeli otwartych i zamkniętych w branżowych benchmarkach. Data odcięcia wiedzy: grudzień 2023.",
  "Meta-Llama-4-Maverick-17B-128E-Instruct-FP8.description": "Llama 4 Maverick to duży model MoE z efektywną aktywacją ekspertów, zapewniający wysoką wydajność rozumowania.",
  "MiniMax-M1.description": "Nowy wewnętrzny model rozumowania z 80 tys. łańcuchów myślowych i 1 mln tokenów wejściowych, oferujący wydajność porównywalną z czołowymi modelami światowymi.",
  "MiniMax-M2-Stable.description": "Zaprojektowany z myślą o wydajnym kodowaniu i przepływach pracy agentów, z większą równoległością dla zastosowań komercyjnych.",
  "MiniMax-M2.1-Lightning.description": "Potężne możliwości programowania w wielu językach – kompleksowe ulepszenie doświadczenia kodowania. Szybciej i wydajniej.",
  "MiniMax-M2.1.description": "Potężne możliwości programowania w wielu językach – kompleksowe ulepszenie doświadczenia kodowania",
  "MiniMax-M2.description": "Stworzony z myślą o wydajnym kodowaniu i przepływach pracy agentów",
  "MiniMax-Text-01.description": "MiniMax-01 wprowadza dużą skalę uwagi liniowej wykraczającą poza klasyczne Transformatory, z 456 mld parametrów i 45,9 mld aktywowanych na przebieg. Osiąga najwyższą wydajność i obsługuje do 4 mln tokenów kontekstu (32× GPT-4o, 20× Claude-3.5-Sonnet).",
  "MiniMaxAI/MiniMax-M1-80k.description": "MiniMax-M1 to model rozumowania o otwartych wagach, oparty na hybrydowej uwadze, z 456 mld parametrów ogółem i ~45,9 mld aktywnych na token. Natywnie obsługuje kontekst 1 mln tokenów i wykorzystuje Flash Attention, redukując FLOPs o 75% przy generowaniu 100 tys. tokenów w porównaniu do DeepSeek R1. Dzięki architekturze MoE, CISPO i treningowi RL z hybrydową uwagą, osiąga czołowe wyniki w zadaniach rozumowania z długim wejściem i rzeczywistym inżynierii oprogramowania.",
  "MiniMaxAI/MiniMax-M2.description": "MiniMax-M2 redefiniuje efektywność agentów. To kompaktowy, szybki i opłacalny model MoE z 230 mld parametrów ogółem i 10 mld aktywnych, zaprojektowany do zadań kodowania i agentowych najwyższej klasy, przy zachowaniu silnej inteligencji ogólnej. Dzięki tylko 10 mld aktywnych parametrów dorównuje znacznie większym modelom, co czyni go idealnym do zastosowań wymagających wysokiej wydajności.",
  "Moonshot-Kimi-K2-Instruct.description": "1 bln parametrów ogółem, z 32 mld aktywnych. Wśród modeli bez trybu myślenia, wyróżnia się w wiedzy czołowej, matematyce i kodowaniu, a także w zadaniach ogólnych agentów. Optymalizowany pod kątem obciążeń agentowych – potrafi podejmować działania, a nie tylko odpowiadać. Najlepszy do improwizowanych rozmów, ogólnego czatu i doświadczeń agentowych jako model reagujący bez długiego namysłu.",
  "NousResearch/Nous-Hermes-2-Mixtral-8x7B-DPO.description": "Nous Hermes 2 - Mixtral 8x7B-DPO (46,7 mld) to model instrukcyjny o wysokiej precyzji do złożonych obliczeń.",
  "OmniConsistency.description": "OmniConsistency poprawia spójność stylu i uogólnianie w zadaniach obraz-do-obrazu, wprowadzając duże Transformatory Dyfuzyjne (DiTs) i sparowane dane stylizowane, unikając degradacji stylu.",
  "Phi-3-medium-128k-instruct.description": "Ten sam model Phi-3-medium z większym oknem kontekstu do zadań RAG lub few-shot.",
  "Phi-3-medium-4k-instruct.description": "Model z 14 mld parametrów, o wyższej jakości niż Phi-3-mini, skoncentrowany na danych wymagających intensywnego rozumowania.",
  "Phi-3-mini-128k-instruct.description": "Ten sam model Phi-3-mini z większym oknem kontekstu do zadań RAG lub few-shot.",
  "Phi-3-mini-4k-instruct.description": "Najmniejszy członek rodziny Phi-3, zoptymalizowany pod kątem jakości i niskich opóźnień.",
  "Phi-3-small-128k-instruct.description": "Ten sam model Phi-3-small z większym oknem kontekstu do zadań RAG lub few-shot.",
  "Phi-3-small-8k-instruct.description": "Model z 7 mld parametrów, o wyższej jakości niż Phi-3-mini, skoncentrowany na danych wymagających intensywnego rozumowania.",
  "Phi-3.5-mini-instruct.description": "Zaktualizowana wersja modelu Phi-3-mini.",
  "Phi-3.5-vision-instrust.description": "Zaktualizowana wersja modelu Phi-3-vision.",
  "Pro/Qwen/Qwen2-7B-Instruct.description": "Qwen2-7B-Instruct to 7-miliardowy model LLM z serii Qwen2, dostrojony do instrukcji. Wykorzystuje architekturę Transformera z SwiGLU, biasem QKV i grupowaną uwagę zapytań, obsługuje duże wejścia. Wyróżnia się w rozumieniu języka, generowaniu, zadaniach wielojęzycznych, kodowaniu, matematyce i rozumowaniu, przewyższając większość modeli otwartych i konkurując z zamkniętymi. Przewyższa Qwen1.5-7B-Chat w wielu testach.",
  "Pro/Qwen/Qwen2.5-7B-Instruct.description": "Qwen2.5-7B-Instruct to część najnowszej serii LLM Alibaba Cloud. Model 7B przynosi znaczące ulepszenia w kodowaniu i matematyce, obsługuje ponad 29 języków i poprawia wykonywanie instrukcji, rozumienie danych strukturalnych i generowanie strukturalnych wyników (szczególnie JSON).",
  "Pro/Qwen/Qwen2.5-Coder-7B-Instruct.description": "Qwen2.5-Coder-7B-Instruct to najnowszy model LLM Alibaba Cloud skoncentrowany na kodzie. Zbudowany na bazie Qwen2.5 i wytrenowany na 5,5 bln tokenów, znacząco poprawia generowanie kodu, rozumowanie i naprawę, zachowując mocne strony w matematyce i ogólnych zadaniach, stanowiąc solidną bazę dla agentów kodujących.",
  "Pro/Qwen/Qwen2.5-VL-7B-Instruct.description": "Qwen2.5-VL to nowy model językowo-wizualny Qwen z silnym rozumieniem wizualnym. Analizuje tekst, wykresy i układy na obrazach, rozumie długie filmy i zdarzenia, wspiera rozumowanie i użycie narzędzi, uziemienie obiektów w wielu formatach i strukturalne wyniki. Poprawia rozdzielczość dynamiczną i trening z różnymi klatkami dla lepszego rozumienia wideo oraz zwiększa efektywność enkodera wizji.",
  "Pro/THUDM/GLM-4.1V-9B-Thinking.description": "GLM-4.1V-9B-Thinking to otwartoźródłowy model VLM od Zhipu AI i laboratorium KEG Uniwersytetu Tsinghua, zaprojektowany do złożonego poznania multimodalnego. Zbudowany na bazie GLM-4-9B-0414, dodaje rozumowanie łańcuchowe i RL, znacząco poprawiając rozumowanie między modalnościami i stabilność.",
  "Pro/THUDM/glm-4-9b-chat.description": "GLM-4-9B-Chat to otwartoźródłowy model GLM-4 od Zhipu AI. Wyróżnia się w semantyce, matematyce, rozumowaniu, kodzie i wiedzy. Poza wieloetapowym czatem obsługuje przeglądanie sieci, wykonywanie kodu, niestandardowe wywołania narzędzi i rozumowanie długich tekstów. Obsługuje 26 języków (w tym chiński, angielski, japoński, koreański, niemiecki). Osiąga dobre wyniki w AlignBench-v2, MT-Bench, MMLU i C-Eval, obsługuje do 128 tys. tokenów kontekstu do zastosowań akademickich i biznesowych.",
  "Pro/deepseek-ai/DeepSeek-R1-Distill-Qwen-7B.description": "DeepSeek-R1-Distill-Qwen-7B to model zdestylowany z Qwen2.5-Math-7B i dostrojony na 800 tys. starannie dobranych próbkach DeepSeek-R1. Osiąga wysokie wyniki: 92,8% na MATH-500, 55,5% na AIME 2024 i ocenę 1189 na CodeForces dla modelu 7B.",
  "Pro/deepseek-ai/DeepSeek-R1.description": "DeepSeek-R1 to model rozumowania oparty na RL, który redukuje powtórzenia i poprawia czytelność. Wykorzystuje dane cold-start przed RL, by dodatkowo zwiększyć zdolności rozumowania, dorównuje OpenAI-o1 w zadaniach matematycznych, kodowych i rozumowania, a dzięki starannemu treningowi poprawia ogólne wyniki.",
  "Pro/deepseek-ai/DeepSeek-V3.1-Terminus.description": "DeepSeek-V3.1-Terminus to zaktualizowany model V3.1, pozycjonowany jako hybrydowy agent LLM. Naprawia zgłoszone przez użytkowników problemy, poprawia stabilność, spójność językową i redukuje mieszane znaki chińskie/angielskie oraz nieprawidłowe znaki. Integruje tryby myślenia i nie-myślenia z szablonami czatu dla elastycznego przełączania. Poprawia również wydajność agentów kodu i wyszukiwania dla bardziej niezawodnego użycia narzędzi i zadań wieloetapowych.",
  "Pro/deepseek-ai/DeepSeek-V3.2-Exp.description": "DeepSeek-V3.2-Exp to eksperymentalne wydanie V3.2, łączące się z nową architekturą. Dodaje DeepSeek Sparse Attention (DSA) do V3.1-Terminus, poprawiając efektywność treningu i wnioskowania w długim kontekście, z optymalizacjami dla użycia narzędzi, rozumienia długich dokumentów i rozumowania wieloetapowego. Idealny do eksploracji wyższej efektywności rozumowania przy dużych budżetach kontekstu.",
  "Pro/deepseek-ai/DeepSeek-V3.description": "DeepSeek-V3 to model MoE z 671 mld parametrów, wykorzystujący MLA i DeepSeekMoE z równoważeniem obciążenia bez strat, zapewniający efektywne wnioskowanie i trening. Wstępnie wytrenowany na 14,8 bln wysokiej jakości tokenów i dalej dostrojony za pomocą SFT i RL, przewyższa inne modele otwarte i zbliża się do czołowych modeli zamkniętych.",
  "Pro/moonshotai/Kimi-K2-Instruct-0905.description": "Kimi K2-Instruct-0905 to najnowsza i najpotężniejsza wersja Kimi K2. Jest to model MoE najwyższej klasy z 1T łącznych i 32B aktywnych parametrów. Kluczowe cechy to silniejsza inteligencja kodowania agentowego z istotnymi poprawami w testach porównawczych i zadaniach agentowych w rzeczywistych warunkach, a także ulepszona estetyka i użyteczność kodowania frontendowego.",
  "Pro/moonshotai/Kimi-K2-Thinking.description": "Kimi K2 Thinking Turbo to wariant Turbo zoptymalizowany pod kątem szybkości rozumowania i przepustowości, zachowując jednocześnie wieloetapowe rozumowanie i obsługę narzędzi znane z K2 Thinking. Jest to model MoE z około 1T łącznych parametrów, natywnym kontekstem 256K i stabilnym wywoływaniem narzędzi na dużą skalę, przeznaczony do zastosowań produkcyjnych z rygorystycznymi wymaganiami dotyczącymi opóźnień i współbieżności.",
  "Pro/zai-org/glm-4.7.description": "GLM-4.7 to najnowszy flagowy model Zhipu, zaprojektowany z myślą o scenariuszach Agentic Coding. Wzmacnia zdolności kodowania, planowania długoterminowego oraz współpracy z narzędziami, osiągając czołowe wyniki wśród modeli open-source na wielu publicznych benchmarkach. Ulepszono ogólne możliwości modelu — odpowiedzi są bardziej zwięzłe i naturalne, a teksty pisane bardziej immersyjne. W realizacji złożonych zadań agentowych i przy wywoływaniu narzędzi model wykazuje lepsze przestrzeganie instrukcji, a estetyka interfejsu Artifacts i efektywność realizacji długich zadań w Agentic Coding zostały znacznie poprawione.",
  "QwQ-32B-Preview.description": "Qwen QwQ to eksperymentalny model badawczy skoncentrowany na ulepszaniu zdolności rozumowania.",
  "Qwen/QVQ-72B-Preview.description": "QVQ-72B-Preview to model badawczy od Qwen, skoncentrowany na rozumowaniu wizualnym, wyróżniający się w złożonym rozumieniu scen i problemach matematycznych opartych na obrazie.",
  "Qwen/QwQ-32B-Preview.description": "Qwen QwQ to eksperymentalny model badawczy skoncentrowany na ulepszonym rozumowaniu sztucznej inteligencji.",
  "Qwen/QwQ-32B.description": "QwQ to model rozumowania z rodziny Qwen. W porównaniu do standardowych modeli dostrojonych do instrukcji, dodaje warstwę myślenia i rozumowania, co znacząco poprawia wydajność w zadaniach końcowych, szczególnie w trudnych problemach. QwQ-32B to model średniej wielkości konkurujący z czołowymi modelami rozumowania, takimi jak DeepSeek-R1 i o1-mini. Wykorzystuje RoPE, SwiGLU, RMSNorm i bias QKV w mechanizmie uwagi, z 64 warstwami i 40 głowicami uwagi Q (8 KV w GQA).",
  "Qwen/Qwen-Image-Edit-2509.description": "Qwen-Image-Edit-2509 to najnowsza wersja edycyjna Qwen-Image od zespołu Qwen. Bazując na modelu Qwen-Image 20B, rozszerza możliwości renderowania tekstu na edycję obrazów, umożliwiając precyzyjne modyfikacje tekstowe. Wykorzystuje architekturę podwójnej kontroli, przesyłając dane wejściowe do Qwen2.5-VL w celu kontroli semantycznej oraz do kodera VAE w celu kontroli wyglądu, co umożliwia edycję zarówno na poziomie semantycznym, jak i wizualnym. Obsługuje lokalne zmiany (dodawanie/usuwanie/modyfikacja) oraz edycje semantyczne wyższego poziomu, takie jak tworzenie IP i transfer stylu, zachowując przy tym znaczenie. Osiąga najlepsze wyniki w wielu testach porównawczych.",
  "Qwen/Qwen-Image.description": "Qwen-Image to bazowy model generowania obrazów o 20 miliardach parametrów od zespołu Qwen. Oferuje znaczące postępy w renderowaniu złożonego tekstu i precyzyjnej edycji obrazów, szczególnie w przypadku tekstu chińskiego i angielskiego o wysokiej wierności. Obsługuje układy wieloliniowe i akapity, zachowując spójność typograficzną. Poza renderowaniem tekstu, wspiera szeroki zakres stylów – od fotorealistycznych po anime – oraz zaawansowane techniki edycji, takie jak transfer stylu, dodawanie/usuwanie obiektów, poprawa szczegółów, edycja tekstu i kontrola pozycji, dążąc do bycia kompleksową bazą do tworzenia wizualnego.",
  "Qwen/Qwen2-72B-Instruct.description": "Qwen 2 Instruct (72B) zapewnia precyzyjne wykonywanie instrukcji dla zastosowań korporacyjnych.",
  "Qwen/Qwen2-7B-Instruct.description": "Qwen2-7B-Instruct to model o 7 miliardach parametrów z serii Qwen2, dostrojony do instrukcji, wykorzystujący architekturę Transformer, SwiGLU, bias QKV i grupowaną uwagę zapytań. Obsługuje duże dane wejściowe i osiąga wysokie wyniki w testach rozumienia, generowania, wielojęzyczności, kodowania, matematyki i rozumowania, przewyższając większość otwartych modeli i wyprzedzając Qwen1.5-7B-Chat w wielu ocenach.",
  "Qwen/Qwen2-VL-72B-Instruct.description": "Qwen2-VL to najnowszy model Qwen-VL, osiągający najlepsze wyniki w testach wizualnych, takich jak MathVista, DocVQA, RealWorldQA i MTVQA. Potrafi rozumieć filmy trwające ponad 20 minut w kontekście pytań wideo, dialogów i tworzenia treści. Obsługuje również złożone rozumowanie i podejmowanie decyzji, integrując się z urządzeniami/robotami do działań opartych na wizji. Poza językiem angielskim i chińskim, potrafi czytać tekst w wielu językach, w tym większości języków europejskich, japońskim, koreańskim, arabskim i wietnamskim.",
  "Qwen/Qwen2.5-14B-Instruct.description": "Qwen2.5-14B-Instruct to część najnowszej serii LLM Alibaba Cloud. Model 14B przynosi znaczące postępy w kodowaniu i matematyce, obsługuje ponad 29 języków i poprawia wykonywanie instrukcji, rozumienie danych strukturalnych oraz generowanie danych strukturalnych (szczególnie JSON).",
  "Qwen/Qwen2.5-32B-Instruct.description": "Qwen2.5-32B-Instruct to część najnowszej serii LLM Alibaba Cloud. Model 32B przynosi znaczące postępy w kodowaniu i matematyce, obsługuje ponad 29 języków i poprawia wykonywanie instrukcji, rozumienie danych strukturalnych oraz generowanie danych strukturalnych (szczególnie JSON).",
  "Qwen/Qwen2.5-72B-Instruct-128K.description": "Qwen2.5-72B-Instruct to część najnowszej serii LLM Alibaba Cloud. Model 72B poprawia kodowanie i matematykę, obsługuje do 128K danych wejściowych i ponad 8K danych wyjściowych, oferuje wsparcie dla ponad 29 języków oraz ulepsza wykonywanie instrukcji i generowanie danych strukturalnych (szczególnie JSON).",
  "Qwen/Qwen2.5-72B-Instruct-Turbo.description": "Qwen2.5 to nowa rodzina LLM zoptymalizowana pod kątem zadań w stylu instrukcji.",
  "Qwen/Qwen2.5-72B-Instruct.description": "Qwen2.5-72B-Instruct to część najnowszej serii LLM Alibaba Cloud. Model 72B przynosi znaczące postępy w kodowaniu i matematyce, obsługuje ponad 29 języków i poprawia wykonywanie instrukcji, rozumienie danych strukturalnych oraz generowanie danych strukturalnych (szczególnie JSON).",
  "Qwen/Qwen2.5-7B-Instruct-Turbo.description": "Qwen2.5 to nowa rodzina LLM zoptymalizowana pod kątem zadań w stylu instrukcji.",
  "Qwen/Qwen2.5-7B-Instruct.description": "Qwen2.5-7B-Instruct to część najnowszej serii LLM Alibaba Cloud. Model 7B przynosi znaczące postępy w kodowaniu i matematyce, obsługuje ponad 29 języków i poprawia wykonywanie instrukcji, rozumienie danych strukturalnych oraz generowanie danych strukturalnych (szczególnie JSON).",
  "Qwen/Qwen2.5-Coder-32B-Instruct.description": "Qwen2.5 Coder 32B Instruct to najnowszy model LLM Alibaba Cloud skoncentrowany na kodzie. Zbudowany na bazie Qwen2.5 i wytrenowany na 5,5T tokenów, znacząco poprawia generowanie kodu, rozumowanie i naprawę błędów, zachowując przy tym mocne strony w matematyce i ogólnych zadaniach, stanowiąc solidną bazę dla agentów kodujących.",
  "Qwen/Qwen2.5-Coder-7B-Instruct.description": "Qwen2.5-Coder-7B-Instruct to najnowszy model LLM Alibaba Cloud skoncentrowany na kodzie. Zbudowany na bazie Qwen2.5 i wytrenowany na 5,5T tokenów, znacząco poprawia generowanie kodu, rozumowanie i naprawę błędów, zachowując przy tym mocne strony w matematyce i ogólnych zadaniach, stanowiąc solidną bazę dla agentów kodujących.",
  "Qwen/Qwen2.5-VL-32B-Instruct.description": "Qwen2.5-VL-32B-Instruct to model multimodalny od zespołu Qwen. Rozpoznaje powszechne obiekty i analizuje tekst, wykresy, ikony, grafiki i układy. Jako agent wizualny potrafi rozumować i dynamicznie kontrolować narzędzia, w tym korzystanie z komputera i telefonu. Precyzyjnie lokalizuje obiekty i generuje dane strukturalne dla faktur i tabel. W porównaniu do Qwen2-VL, RL dodatkowo poprawia matematykę i rozwiązywanie problemów, oferując bardziej preferowane przez ludzi odpowiedzi.",
  "Qwen/Qwen2.5-VL-72B-Instruct.description": "Qwen2.5-VL to model językowo-wizualny z serii Qwen2.5 z dużymi ulepszeniami: silniejsze rozumienie wizualne obiektów, tekstu, wykresów i układów; rozumowanie jako agent wizualny z dynamicznym użyciem narzędzi; rozumienie filmów trwających ponad godzinę i wychwytywanie kluczowych wydarzeń; precyzyjne lokalizowanie obiektów za pomocą ramek lub punktów; oraz generowanie danych strukturalnych dla zeskanowanych danych, takich jak faktury i tabele.",
  "Qwen/Qwen3-14B.description": "Qwen3 to nowej generacji model Tongyi Qwen, oferujący znaczne ulepszenia w zakresie rozumowania, ogólnych zdolności, możliwości działania jako agent oraz wydajności wielojęzycznej. Obsługuje przełączanie trybów myślenia.",
  "Qwen/Qwen3-235B-A22B-Instruct-2507.description": "Qwen3-235B-A22B-Instruct-2507 to flagowy model Qwen3 MoE z 235 miliardami parametrów ogólnych i 22 miliardami aktywnych. Jest to zaktualizowana wersja bez trybu myślenia, skoncentrowana na poprawie wykonywania instrukcji, rozumowania logicznego, rozumienia tekstu, matematyki, nauk ścisłych, programowania i obsługi narzędzi. Rozszerza również wiedzę długiego ogona w wielu językach i lepiej dopasowuje się do preferencji użytkowników w zadaniach subiektywnych i otwartych.",
  "Qwen/Qwen3-235B-A22B-Thinking-2507.description": "Qwen3-235B-A22B-Thinking-2507 to model Qwen3 skoncentrowany na złożonym rozumowaniu. Wykorzystuje architekturę MoE z 235 miliardami parametrów ogólnych i około 22 miliardami aktywnych na token, co zwiększa efektywność. Jako dedykowany model myślący, osiąga znaczne postępy w logice, matematyce, naukach ścisłych, programowaniu i testach akademickich, osiągając najwyższy poziom otwartego rozumowania. Poprawia również wykonywanie instrukcji, obsługę narzędzi i generowanie tekstu, a także natywnie obsługuje kontekst 256K dla głębokiego rozumowania i długich dokumentów.",
  "Qwen/Qwen3-235B-A22B.description": "Qwen3 to nowej generacji model Tongyi Qwen, oferujący znaczne ulepszenia w zakresie rozumowania, ogólnych zdolności, możliwości działania jako agent oraz wydajności wielojęzycznej. Obsługuje przełączanie trybów myślenia.",
  "Qwen/Qwen3-30B-A3B-Instruct-2507.description": "Qwen3-30B-A3B-Instruct-2507 to zaktualizowana wersja modelu Qwen3-30B-A3B bez trybu myślenia. Jest to model MoE z 30,5 miliardami parametrów ogólnych i 3,3 miliardami aktywnych. Znacząco poprawia wykonywanie instrukcji, rozumowanie logiczne, rozumienie tekstu, matematykę, nauki ścisłe, programowanie i obsługę narzędzi, rozszerza wiedzę długiego ogona w wielu językach i lepiej dopasowuje się do preferencji użytkowników w zadaniach subiektywnych. Obsługuje kontekst 256K. Ten model działa wyłącznie w trybie bez myślenia i nie generuje znaczników `<think></think>`.",
  "Qwen/Qwen3-30B-A3B-Thinking-2507.description": "Qwen3-30B-A3B-Thinking-2507 to najnowszy model myślący z serii Qwen3. Jest to model MoE z 30,5 miliardami parametrów ogólnych i 3,3 miliardami aktywnych, skoncentrowany na złożonych zadaniach. Osiąga znaczące postępy w logice, matematyce, naukach ścisłych, programowaniu i testach akademickich, a także poprawia wykonywanie instrukcji, obsługę narzędzi, generowanie tekstu i dopasowanie do preferencji. Natywnie obsługuje kontekst 256K i może zostać rozszerzony do 1 miliona tokenów. Ta wersja została zaprojektowana do trybu myślenia z dokładnym rozumowaniem krok po kroku i silnymi możliwościami agenta.",
  "Qwen/Qwen3-30B-A3B.description": "Qwen3 to nowej generacji model Tongyi Qwen, oferujący znaczne ulepszenia w zakresie rozumowania, ogólnych zdolności, możliwości działania jako agent oraz wydajności wielojęzycznej. Obsługuje przełączanie trybów myślenia.",
  "Qwen/Qwen3-32B.description": "Qwen3 to nowej generacji model Tongyi Qwen, oferujący znaczne ulepszenia w zakresie rozumowania, ogólnych zdolności, możliwości działania jako agent oraz wydajności wielojęzycznej. Obsługuje przełączanie trybów myślenia.",
  "Qwen/Qwen3-8B.description": "Qwen3 to nowej generacji model Tongyi Qwen, oferujący znaczne ulepszenia w zakresie rozumowania, ogólnych zdolności, możliwości działania jako agent oraz wydajności wielojęzycznej. Obsługuje przełączanie trybów myślenia.",
  "Qwen/Qwen3-Coder-30B-A3B-Instruct.description": "Qwen3-Coder-30B-A3B-Instruct to model kodowania z serii Qwen3 opracowany przez zespół Qwen. Został zoptymalizowany pod kątem wysokiej wydajności i efektywności, jednocześnie zwiększając możliwości kodowania. Wyróżnia się w kodowaniu agentowym, automatyzacji przeglądarki i obsłudze narzędzi wśród modeli otwartych. Natywnie obsługuje kontekst 256K i może zostać rozszerzony do 1 miliona tokenów dla zrozumienia na poziomie całej bazy kodu. Obsługuje kodowanie agentowe na platformach takich jak Qwen Code i CLINE z dedykowanym formatem wywoływania funkcji.",
  "Qwen/Qwen3-Coder-480B-A35B-Instruct.description": "Qwen3-Coder-480B-A35B-Instruct to najbardziej zaawansowany model kodowania agentowego firmy Alibaba. Jest to model MoE z 480 miliardami parametrów ogólnych i 35 miliardami aktywnych, łączący efektywność z wydajnością. Natywnie obsługuje kontekst 256K i może zostać rozszerzony do 1 miliona tokenów za pomocą YaRN, umożliwiając obsługę dużych baz kodu. Zaprojektowany do przepływów pracy kodowania agentowego, potrafi współdziałać z narzędziami i środowiskami w celu rozwiązywania złożonych zadań programistycznych. Osiąga najlepsze wyniki wśród modeli otwartych w testach kodowania i agentów, porównywalne z wiodącymi modelami, takimi jak Claude Sonnet 4.",
  "Qwen/Qwen3-Next-80B-A3B-Instruct.description": "Qwen3-Next-80B-A3B-Instruct to nowej generacji model bazowy oparty na architekturze Qwen3-Next, zaprojektowany z myślą o ekstremalnej wydajności trenowania i wnioskowania. Łączy hybrydową uwagę (Gated DeltaNet + Gated Attention), silnie rozrzedzoną architekturę MoE oraz optymalizacje stabilności treningu. Choć posiada 80 miliardów parametrów, podczas wnioskowania aktywnych jest jedynie około 3 miliardów, co znacząco redukuje zapotrzebowanie na zasoby obliczeniowe i zapewnia ponad 10-krotnie większą przepustowość niż Qwen3-32B przy kontekstach >32K. Wersja dostrojona do instrukcji jest przeznaczona do ogólnych zadań (bez trybu myślenia). Osiąga porównywalne wyniki z Qwen3-235B w niektórych testach i wykazuje wyraźną przewagę w zadaniach z ultradługim kontekstem.",
  "Qwen/Qwen3-Next-80B-A3B-Thinking.description": "Qwen3-Next-80B-A3B-Thinking to nowej generacji model bazowy przeznaczony do złożonego rozumowania. Wykorzystuje architekturę Qwen3-Next z hybrydową uwagą (Gated DeltaNet + Gated Attention) oraz silnie rozrzedzoną architekturę MoE, zapewniając ekstremalną wydajność trenowania i wnioskowania. Choć posiada 80 miliardów parametrów, podczas wnioskowania aktywnych jest jedynie około 3 miliardów, co znacząco redukuje zapotrzebowanie na zasoby obliczeniowe i zapewnia ponad 10-krotnie większą przepustowość niż Qwen3-32B przy kontekstach >32K. Wersja Thinking jest zoptymalizowana pod kątem zadań wieloetapowych, takich jak dowodzenie, synteza kodu, analiza logiczna i planowanie, generując uporządkowany łańcuch myślowy. Przewyższa Qwen3-32B-Thinking i pokonuje Gemini-2.5-Flash-Thinking w wielu testach porównawczych.",
  "Qwen/Qwen3-Omni-30B-A3B-Captioner.description": "Qwen3-Omni-30B-A3B-Captioner to model VLM z serii Qwen3, stworzony do generowania wysokiej jakości, szczegółowych i precyzyjnych opisów obrazów. Wykorzystuje architekturę MoE z 30 miliardami parametrów, aby dogłębnie analizować obrazy i tworzyć płynne opisy, wyróżniając się w uchwyceniu detali, rozumieniu scen, rozpoznawaniu obiektów i relacyjnym rozumowaniu.",
  "Qwen/Qwen3-Omni-30B-A3B-Instruct.description": "Qwen3-Omni-30B-A3B-Instruct to model MoE z serii Qwen3, posiadający 30 miliardów parametrów ogółem i 3 miliardy aktywnych, oferujący wysoką wydajność przy niskim koszcie wnioskowania. Trenowany na wysokiej jakości danych wielojęzycznych z wielu źródeł, obsługuje pełne wejścia modalne (tekst, obrazy, dźwięk, wideo) oraz rozumienie i generowanie między modalnościami.",
  "Qwen/Qwen3-Omni-30B-A3B-Thinking.description": "Qwen3-Omni-30B-A3B-Thinking to kluczowy komponent „Myślący” w Qwen3-Omni. Przetwarza dane multimodalne (tekst, dźwięk, obrazy, wideo) i wykonuje złożone rozumowanie łańcuchowe, łącząc dane wejściowe w jedną reprezentację dla głębokiego rozumienia między modalnościami. Jest to model MoE z 30 miliardami parametrów ogółem i 3 miliardami aktywnych, łączący silne zdolności rozumowania z efektywnością obliczeniową.",
  "Qwen/Qwen3-VL-235B-A22B-Instruct.description": "Qwen3-VL-235B-A22B-Instruct to duży model Qwen3-VL dostrojony do instrukcji, oparty na architekturze MoE, zapewniający doskonałe rozumienie i generowanie multimodalne. Obsługuje natywnie kontekst 256K i nadaje się do produkcyjnych usług multimodalnych o wysokiej współbieżności.",
  "Qwen/Qwen3-VL-235B-A22B-Thinking.description": "Qwen3-VL-235B-A22B-Thinking to flagowa wersja myśląca modelu Qwen3-VL, zoptymalizowana pod kątem złożonego rozumowania multimodalnego, rozumowania w długim kontekście oraz interakcji agentów w zastosowaniach korporacyjnych.",
  "Qwen/Qwen3-VL-30B-A3B-Instruct.description": "Qwen3-VL-30B-A3B-Instruct to model Qwen3-VL dostrojony do instrukcji, oferujący silne rozumienie i generowanie wizualno-językowe. Obsługuje natywnie kontekst 256K dla czatu multimodalnego i generowania warunkowanego obrazem.",
  "Qwen/Qwen3-VL-30B-A3B-Thinking.description": "Qwen3-VL-30B-A3B-Thinking to wersja modelu Qwen3-VL wzbogacona o zdolności rozumowania, zoptymalizowana pod kątem rozumowania multimodalnego, konwersji obrazu na kod oraz złożonego rozumienia wizualnego. Obsługuje kontekst 256K z silniejszymi zdolnościami łańcucha myślowego.",
  "Qwen/Qwen3-VL-32B-Instruct.description": "Qwen3-VL-32B-Instruct to model wizualno-językowy zespołu Qwen, osiągający czołowe wyniki SOTA w wielu testach VL. Obsługuje obrazy w rozdzielczości megapikselowej i oferuje silne rozumienie wizualne, wielojęzyczne OCR, precyzyjne osadzanie wizualne oraz dialog wizualny. Radzi sobie ze złożonymi zadaniami multimodalnymi i obsługuje wywoływanie narzędzi oraz uzupełnianie prefiksów.",
  "Qwen/Qwen3-VL-32B-Thinking.description": "Qwen3-VL-32B-Thinking jest zoptymalizowany do złożonego rozumowania wizualnego. Zawiera wbudowany tryb myślenia, który generuje pośrednie kroki rozumowania przed odpowiedziami, zwiększając logikę wieloetapową, planowanie i złożone rozumowanie. Obsługuje obrazy megapikselowe, silne rozumienie wizualne, wielojęzyczne OCR, precyzyjne osadzanie, dialog wizualny, wywoływanie narzędzi i uzupełnianie prefiksów.",
  "Qwen/Qwen3-VL-8B-Instruct.description": "Qwen3-VL-8B-Instruct to model wizualno-językowy Qwen3 oparty na Qwen3-8B-Instruct, trenowany na dużych zbiorach danych obraz-tekst. Wyróżnia się w ogólnym rozumieniu wizualnym, dialogu skoncentrowanym na obrazie oraz wielojęzycznym rozpoznawaniu tekstu w obrazach, odpowiedni do wizualnego QA, opisywania, multimodalnego podążania za instrukcjami i użycia narzędzi.",
  "Qwen/Qwen3-VL-8B-Thinking.description": "Qwen3-VL-8B-Thinking to wizualna wersja myśląca Qwen3, zoptymalizowana do złożonego rozumowania wieloetapowego. Generuje łańcuch myślowy przed odpowiedziami, aby poprawić dokładność, idealna do głębokiego wizualnego QA i szczegółowej analizy obrazów.",
  "Qwen2-72B-Instruct.description": "Qwen2 to najnowsza seria Qwen, obsługująca okno kontekstu 128k. W porównaniu z najlepszymi obecnie otwartymi modelami, Qwen2-72B znacznie przewyższa czołowe modele w zakresie rozumienia języka naturalnego, wiedzy, kodu, matematyki i możliwości wielojęzycznych.",
  "Qwen2-7B-Instruct.description": "Qwen2 to najnowsza seria Qwen, przewyższająca najlepsze otwarte modele o podobnej wielkości, a nawet większe. Qwen2 7B wykazuje znaczną przewagę w wielu testach, szczególnie w zakresie kodu i rozumienia języka chińskiego.",
  "Qwen2-VL-72B.description": "Qwen2-VL-72B to potężny model wizualno-językowy obsługujący przetwarzanie multimodalne obraz-tekst, dokładnie rozpoznający zawartość obrazów i generujący odpowiednie opisy lub odpowiedzi.",
  "Qwen2.5-14B-Instruct.description": "Qwen2.5-14B-Instruct to model językowy LLM z 14 miliardami parametrów, oferujący wysoką wydajność, zoptymalizowany pod kątem scenariuszy chińskich i wielojęzycznych, wspierający inteligentne pytania i odpowiedzi oraz generowanie treści.",
  "Qwen2.5-32B-Instruct.description": "Qwen2.5-32B-Instruct to model językowy LLM z 32 miliardami parametrów, oferujący zrównoważoną wydajność, zoptymalizowany pod kątem scenariuszy chińskich i wielojęzycznych, wspierający inteligentne pytania i odpowiedzi oraz generowanie treści.",
  "Qwen2.5-72B-Instruct.description": "Model LLM dla języka chińskiego i angielskiego, dostrojony do języka, kodowania, matematyki i rozumowania.",
  "Qwen2.5-7B-Instruct.description": "Qwen2.5-7B-Instruct to model językowy LLM z 7 miliardami parametrów, obsługujący wywoływanie funkcji i płynną integrację z systemami zewnętrznymi, znacznie zwiększając elastyczność i rozszerzalność. Zoptymalizowany pod kątem scenariuszy chińskich i wielojęzycznych, wspierający inteligentne pytania i odpowiedzi oraz generowanie treści.",
  "Qwen2.5-Coder-14B-Instruct.description": "Qwen2.5-Coder-14B-Instruct to duży model kodowania dostrojony do instrukcji, oferujący silne rozumienie i generowanie kodu. Skutecznie obsługuje szeroki zakres zadań programistycznych, idealny do inteligentnego kodowania, automatycznego generowania skryptów i pytań i odpowiedzi związanych z programowaniem.",
  "Qwen2.5-Coder-32B-Instruct.description": "Zaawansowany model LLM do generowania kodu, rozumowania i naprawy błędów w głównych językach programowania.",
  "Qwen3-235B-A22B-Instruct-2507-FP8.description": "Qwen3 235B A22B Instruct 2507 jest zoptymalizowany pod kątem zaawansowanego rozumowania i podążania za instrukcjami, wykorzystując architekturę MoE, aby zapewnić efektywność rozumowania w dużej skali.",
  "Qwen3-235B.description": "Qwen3-235B-A22B to model MoE, który wprowadza hybrydowy tryb rozumowania, umożliwiając użytkownikom płynne przełączanie się między trybem myślenia i niemyslenia. Obsługuje rozumienie i rozumowanie w 119 językach i dialektach oraz posiada silne możliwości wywoływania narzędzi, konkurując z głównymi modelami, takimi jak DeepSeek R1, OpenAI o1, o3-mini, Grok 3 i Google Gemini 2.5 Pro w testach ogólnych, kodowania i matematyki, możliwości wielojęzycznych oraz rozumowania wiedzy.",
  "Qwen3-32B.description": "Qwen3-32B to gęsty model, który wprowadza hybrydowy tryb rozumowania, umożliwiając użytkownikom przełączanie się między trybem myślenia i niemyslenia. Dzięki ulepszeniom architektury, większej ilości danych i lepszemu treningowi, osiąga wydajność porównywalną z Qwen2.5-72B.",
  "SenseChat-128K.description": "Wersja bazowa V4 z kontekstem 128K, doskonała w rozumieniu i generowaniu długich tekstów.",
  "SenseChat-32K.description": "Wersja bazowa V4 z kontekstem 32K, elastyczna w wielu zastosowaniach.",
  "SenseChat-5-1202.description": "Najnowsza wersja oparta na V5.5, z istotnymi ulepszeniami w zakresie podstaw języka chińskiego/angielskiego, rozmów, wiedzy STEM, nauk humanistycznych, pisania, matematyki/logiki oraz kontroli długości.",
  "SenseChat-5-Cantonese.description": "Dostosowana do zwyczajów językowych Hongkongu, slangu i wiedzy lokalnej; przewyższa GPT-4 w rozumieniu kantońskiego i dorównuje GPT-4 Turbo w wiedzy, rozumowaniu, matematyce i programowaniu.",
  "SenseChat-5-beta.description": "W niektórych aspektach przewyższa SenseChat-5-1202.",
  "SenseChat-5.description": "Najnowsza wersja V5.5 z kontekstem 128K; znaczne postępy w rozumowaniu matematycznym, rozmowach po angielsku, wykonywaniu poleceń i rozumieniu długich tekstów, porównywalna z GPT-4o.",
  "SenseChat-Character-Pro.description": "Zaawansowany model rozmów z postaciami z kontekstem 32K, ulepszoną funkcjonalnością i wsparciem dla języka chińskiego/angielskiego.",
  "SenseChat-Character.description": "Standardowy model rozmów z postaciami z kontekstem 8K i wysoką szybkością odpowiedzi.",
  "SenseChat-Turbo-1202.description": "Najnowszy lekki model osiągający ponad 90% możliwości pełnego modelu przy znacznie niższych kosztach wnioskowania.",
  "SenseChat-Turbo.description": "Odpowiedni do szybkich pytań i odpowiedzi oraz scenariuszy dostrajania modeli.",
  "SenseChat-Vision.description": "Najnowsza wersja V5.5 z obsługą wielu obrazów i szerokimi ulepszeniami w rozpoznawaniu atrybutów, relacjach przestrzennych, wykrywaniu działań/zdarzeń, rozumieniu scen, rozpoznawaniu emocji, rozumowaniu zdroworozsądkowemu oraz rozumieniu/generowaniu tekstu.",
  "SenseChat.description": "Wersja bazowa V4 z kontekstem 4K i silnymi ogólnymi możliwościami.",
  "SenseNova-V6-5-Pro.description": "Dzięki kompleksowym aktualizacjom danych multimodalnych, językowych i logicznych oraz optymalizacji strategii treningowej, nowy model znacząco poprawia rozumowanie multimodalne i ogólne podążanie za instrukcjami, obsługuje kontekst do 128 tys. tokenów i wyróżnia się w zadaniach OCR oraz rozpoznawania IP w turystyce kulturowej.",
  "SenseNova-V6-5-Turbo.description": "Dzięki kompleksowym aktualizacjom danych multimodalnych, językowych i logicznych oraz optymalizacji strategii treningowej, nowy model znacząco poprawia rozumowanie multimodalne i ogólne podążanie za instrukcjami, obsługuje kontekst do 128 tys. tokenów i wyróżnia się w zadaniach OCR oraz rozpoznawania IP w turystyce kulturowej.",
  "SenseNova-V6-Pro.description": "Model natywnie integruje obraz, tekst i wideo, przełamując tradycyjne bariery multimodalne; zdobywa czołowe miejsca w rankingach OpenCompass i SuperCLUE.",
  "SenseNova-V6-Reasoner.description": "Łączy głębokie rozumowanie wizualne i językowe, wspierając powolne myślenie i pełny łańcuch rozumowania.",
  "SenseNova-V6-Turbo.description": "Model natywnie integruje obraz, tekst i wideo, przełamując tradycyjne bariery multimodalne. Przoduje w kluczowych możliwościach multimodalnych i językowych, zajmując czołowe miejsca w wielu ocenach.",
  "Skylark2-lite-8k.description": "Model drugiej generacji Skylark. Skylark2-lite zapewnia szybkie odpowiedzi w scenariuszach czasu rzeczywistego i wrażliwych na koszty, gdzie wymagana jest mniejsza dokładność, z kontekstem do 8 tys. tokenów.",
  "Skylark2-pro-32k.description": "Model drugiej generacji Skylark. Skylark2-pro oferuje wyższą dokładność w złożonym generowaniu tekstu, takim jak profesjonalne copywriting, pisanie powieści i wysokiej jakości tłumaczenia, z kontekstem do 32 tys. tokenów.",
  "Skylark2-pro-4k.description": "Model drugiej generacji Skylark. Skylark2-pro oferuje wyższą dokładność w złożonym generowaniu tekstu, takim jak profesjonalne copywriting, pisanie powieści i wysokiej jakości tłumaczenia, z kontekstem do 4 tys. tokenów.",
  "Skylark2-pro-character-4k.description": "Model drugiej generacji Skylark. Skylark2-pro-character doskonale sprawdza się w odgrywaniu ról i rozmowach, dopasowując odpowiedzi do unikalnych stylów osobowości i naturalnego dialogu — idealny dla chatbotów, wirtualnych asystentów i obsługi klienta, z szybkimi odpowiedziami.",
  "Skylark2-pro-turbo-8k.description": "Model drugiej generacji Skylark. Skylark2-pro-turbo-8k oferuje szybsze wnioskowanie przy niższych kosztach, z kontekstem do 8 tys. tokenów.",
  "THUDM/GLM-4-32B-0414.description": "GLM-4-32B-0414 to nowej generacji otwarty model GLM z 32 miliardami parametrów, porównywalny pod względem wydajności z OpenAI GPT i serią DeepSeek V3/R1.",
  "THUDM/GLM-4-9B-0414.description": "GLM-4-9B-0414 to model GLM z 9 miliardami parametrów, który dziedziczy techniki GLM-4-32B, oferując jednocześnie lżejsze wdrożenie. Sprawdza się w generowaniu kodu, projektowaniu stron internetowych, tworzeniu grafiki SVG i pisaniu opartym na wyszukiwaniu.",
  "THUDM/GLM-4.1V-9B-Thinking.description": "GLM-4.1V-9B-Thinking to otwartoźródłowy model VLM od Zhipu AI i laboratorium KEG Uniwersytetu Tsinghua, zaprojektowany do złożonego poznania multimodalnego. Bazując na GLM-4-9B-0414, dodaje rozumowanie łańcuchowe i uczenie przez wzmocnienie (RL), znacząco poprawiając rozumowanie między modalnościami i stabilność.",
  "THUDM/GLM-Z1-32B-0414.description": "GLM-Z1-32B-0414 to model głębokiego rozumowania oparty na GLM-4-32B-0414, wzbogacony o dane cold-start i rozszerzone RL, dodatkowo trenowany na matematyce, kodzie i logice. Znacząco poprawia zdolności matematyczne i rozwiązywanie złożonych zadań w porównaniu z modelem bazowym.",
  "THUDM/GLM-Z1-9B-0414.description": "GLM-Z1-9B-0414 to kompaktowy model GLM z 9 miliardami parametrów, który zachowuje zalety otwartego źródła, oferując jednocześnie imponujące możliwości. Wyróżnia się w rozumowaniu matematycznym i zadaniach ogólnych, przewodząc w swojej klasie rozmiarowej wśród modeli otwartych.",
  "THUDM/GLM-Z1-Rumination-32B-0414.description": "GLM-Z1-Rumination-32B-0414 to model głębokiego rozumowania z funkcją refleksji (porównywany z OpenAI Deep Research). W przeciwieństwie do typowych modeli głębokiego myślenia, poświęca więcej czasu na rozważania, aby rozwiązywać bardziej otwarte i złożone problemy.",
  "THUDM/glm-4-9b-chat.description": "GLM-4-9B-Chat to otwartoźródłowy model GLM-4 od Zhipu AI. Wyróżnia się w semantyce, matematyce, rozumowaniu, kodzie i wiedzy. Poza wieloetapową rozmową obsługuje przeglądanie stron internetowych, wykonywanie kodu, wywoływanie niestandardowych narzędzi i rozumowanie długich tekstów. Obsługuje 26 języków (w tym chiński, angielski, japoński, koreański, niemiecki). Osiąga dobre wyniki w AlignBench-v2, MT-Bench, MMLU i C-Eval oraz obsługuje kontekst do 128 tys. tokenów do zastosowań akademickich i biznesowych.",
  "Tongyi-Zhiwen/QwenLong-L1-32B.description": "QwenLong-L1-32B to pierwszy model rozumowania z długim kontekstem (LRM) trenowany z użyciem RL, zoptymalizowany pod kątem rozumowania długich tekstów. Jego progresywne RL rozszerzające kontekst umożliwia stabilne przejście od krótkiego do długiego kontekstu. Przewyższa OpenAI-o3-mini i Qwen3-235B-A22B w siedmiu benchmarkach QA dokumentów z długim kontekstem, dorównując Claude-3.7-Sonnet-Thinking. Szczególnie dobrze radzi sobie z matematyką, logiką i rozumowaniem wieloetapowym.",
  "Yi-34B-Chat.description": "Yi-1.5-34B zachowuje silne ogólne zdolności językowe serii, a dzięki inkrementalnemu treningowi na 500 miliardach wysokiej jakości tokenów znacząco poprawia logikę matematyczną i kodowanie.",
  "abab5.5-chat.description": "Zaprojektowany do scenariuszy zwiększających produktywność, obsługuje złożone zadania i efektywne generowanie tekstu do zastosowań profesjonalnych.",
  "abab5.5s-chat.description": "Zaprojektowany do rozmów z chińską osobowością, zapewnia wysokiej jakości dialogi w języku chińskim do różnych zastosowań.",
  "abab6.5g-chat.description": "Zaprojektowany do wielojęzycznych rozmów z osobowością, wspiera generowanie wysokiej jakości dialogów w języku angielskim i innych językach.",
  "abab6.5s-chat.description": "Odpowiedni do szerokiego zakresu zadań NLP, w tym generowania tekstu i systemów dialogowych.",
  "abab6.5t-chat.description": "Zoptymalizowany do rozmów z chińską osobowością, zapewnia płynny dialog zgodny z chińskimi zwyczajami językowymi.",
  "accounts/fireworks/models/deepseek-r1.description": "DeepSeek-R1 to nowoczesny model językowy zoptymalizowany za pomocą uczenia przez wzmocnienie i danych cold-start, oferujący doskonałe rozumowanie, matematykę i wydajność kodowania.",
  "accounts/fireworks/models/deepseek-v3.description": "Potężny model językowy typu Mixture-of-Experts (MoE) od DeepSeek z 671 miliardami parametrów ogółem i 37 miliardami aktywnymi na token.",
  "accounts/fireworks/models/llama-v3-70b-instruct.description": "Meta opracowała i udostępniła serię modeli językowych Meta Llama 3, obejmującą modele do generowania tekstu w wersjach wstępnie wytrenowanych i dostrojonych do instrukcji o rozmiarach 8B i 70B. Modele Llama 3 dostrojone do instrukcji są zoptymalizowane pod kątem zastosowań konwersacyjnych i przewyższają wiele istniejących otwartych modeli czatu w powszechnie stosowanych branżowych testach porównawczych.",
  "accounts/fireworks/models/llama-v3-8b-instruct-hf.description": "Modele Llama 3 dostrojone do instrukcji są zoptymalizowane pod kątem zastosowań konwersacyjnych i przewyższają wiele istniejących otwartych modeli czatu w powszechnie stosowanych branżowych testach porównawczych. Llama 3 8B Instruct (wersja HF) to oryginalna wersja FP16 modelu Llama 3 8B Instruct, której wyniki odpowiadają oficjalnej implementacji Hugging Face.",
  "accounts/fireworks/models/llama-v3-8b-instruct.description": "Meta opracowała i udostępniła serię modeli językowych Meta Llama 3, obejmującą modele do generowania tekstu w wersjach wstępnie wytrenowanych i dostrojonych do instrukcji o rozmiarach 8B i 70B. Modele Llama 3 dostrojone do instrukcji są zoptymalizowane pod kątem zastosowań konwersacyjnych i przewyższają wiele istniejących otwartych modeli czatu w powszechnie stosowanych branżowych testach porównawczych.",
  "accounts/fireworks/models/llama-v3p1-405b-instruct.description": "Meta Llama 3.1 to wielojęzyczna rodzina modeli językowych z modelami do generowania tekstu w wersjach wstępnie wytrenowanych i dostrojonych do instrukcji o rozmiarach 8B, 70B i 405B. Modele dostrojone do instrukcji są zoptymalizowane pod kątem wielojęzycznego dialogu i przewyższają wiele istniejących otwartych i zamkniętych modeli czatu w powszechnie stosowanych testach branżowych. Model 405B to najbardziej zaawansowany model z rodziny Llama 3.1, wykorzystujący wnioskowanie FP8, które ściśle odpowiada implementacji referencyjnej.",
  "accounts/fireworks/models/llama-v3p1-70b-instruct.description": "Meta Llama 3.1 to wielojęzyczna rodzina modeli językowych z modelami do generowania tekstu w wersjach wstępnie wytrenowanych i dostrojonych do instrukcji o rozmiarach 8B, 70B i 405B. Modele dostrojone do instrukcji są zoptymalizowane pod kątem wielojęzycznego dialogu i przewyższają wiele istniejących otwartych i zamkniętych modeli czatu w powszechnie stosowanych testach branżowych.",
  "accounts/fireworks/models/llama-v3p1-8b-instruct.description": "Meta Llama 3.1 to wielojęzyczna rodzina modeli językowych z modelami do generowania tekstu w wersjach wstępnie wytrenowanych i dostrojonych do instrukcji o rozmiarach 8B, 70B i 405B. Modele dostrojone do instrukcji są zoptymalizowane pod kątem wielojęzycznego dialogu i przewyższają wiele istniejących otwartych i zamkniętych modeli czatu w powszechnie stosowanych testach branżowych.",
  "accounts/fireworks/models/llama-v3p2-11b-vision-instruct.description": "Model do rozumowania wizualnego dostrojony do instrukcji od Meta, zawierający 11 miliardów parametrów, zoptymalizowany pod kątem rozpoznawania obrazów, rozumowania wizualnego, opisywania obrazów i pytań związanych z obrazami. Rozumie dane wizualne, takie jak wykresy i diagramy, i łączy wizję z językiem, generując tekstowe opisy szczegółów obrazu.",
  "accounts/fireworks/models/llama-v3p2-3b-instruct.description": "Llama 3.2 3B Instruct to lekki, wielojęzyczny model od Meta, zaprojektowany z myślą o wydajnym działaniu, oferujący znaczące korzyści w zakresie opóźnień i kosztów w porównaniu do większych modeli. Typowe zastosowania obejmują przekształcanie zapytań/poleceń oraz pomoc w pisaniu.",
  "accounts/fireworks/models/llama-v3p2-90b-vision-instruct.description": "Model do rozumowania wizualnego dostrojony do instrukcji od Meta, zawierający 90 miliardów parametrów, zoptymalizowany pod kątem rozpoznawania obrazów, rozumowania wizualnego, opisywania obrazów i pytań związanych z obrazami. Rozumie dane wizualne, takie jak wykresy i diagramy, i łączy wizję z językiem, generując tekstowe opisy szczegółów obrazu. Uwaga: model ten jest obecnie udostępniany eksperymentalnie jako model bezserwerowy. W przypadku zastosowań produkcyjnych należy pamiętać, że Fireworks może wycofać wdrożenie w krótkim czasie.",
  "accounts/fireworks/models/llama-v3p3-70b-instruct.description": "Llama 3.3 70B Instruct to grudniowa aktualizacja modelu Llama 3.1 70B. Ulepsza korzystanie z narzędzi, obsługę tekstu wielojęzycznego, matematykę i programowanie w porównaniu do wersji z lipca 2024. Osiąga wiodącą w branży wydajność w zakresie rozumowania, matematyki i podążania za instrukcjami, oferując wydajność porównywalną z modelem 3.1 405B przy znacznie większej szybkości i niższych kosztach.",
  "accounts/fireworks/models/mistral-small-24b-instruct-2501.description": "Model o 24 miliardach parametrów, oferujący najnowocześniejsze możliwości porównywalne z większymi modelami.",
  "accounts/fireworks/models/mixtral-8x22b-instruct.description": "Mixtral MoE 8x22B Instruct v0.1 to wersja modelu Mixtral MoE 8x22B v0.1 dostrojona do instrukcji, z włączonym interfejsem API do uzupełniania czatu.",
  "accounts/fireworks/models/mixtral-8x7b-instruct.description": "Mixtral MoE 8x7B Instruct to wersja modelu Mixtral MoE 8x7B dostrojona do instrukcji, z włączonym interfejsem API do uzupełniania czatu.",
  "accounts/fireworks/models/mythomax-l2-13b.description": "Ulepszona wersja MythoMix, prawdopodobnie jego bardziej dopracowana forma, łącząca MythoLogic-L2 i Huginn za pomocą wysoce eksperymentalnej techniki łączenia typów tensorów. Dzięki swojej unikalnej naturze doskonale nadaje się do opowiadania historii i odgrywania ról.",
  "accounts/fireworks/models/phi-3-vision-128k-instruct.description": "Phi-3-Vision-128K-Instruct to lekki, nowoczesny otwarty model multimodalny zbudowany na danych syntetycznych i starannie dobranych publicznych zbiorach danych z sieci, koncentrujący się na wysokiej jakości danych tekstowych i wizualnych wymagających rozumowania. Należy do rodziny Phi-3 i obsługuje multimodalność z długością kontekstu do 128K tokenów. Model przechodzi rygorystyczne ulepszenia, w tym nadzorowane dostrajanie i bezpośrednią optymalizację preferencji, aby zapewnić dokładne podążanie za instrukcjami i silne środki bezpieczeństwa.",
  "accounts/fireworks/models/qwen-qwq-32b-preview.description": "Model Qwen QwQ koncentruje się na rozwoju rozumowania AI, pokazując, że otwarte modele mogą dorównywać zamkniętym modelom czołowym w zakresie rozumowania. QwQ-32B-Preview to wersja eksperymentalna, która dorównuje o1 i przewyższa GPT-4o oraz Claude 3.5 Sonnet w zakresie rozumowania i analizy w testach GPQA, AIME, MATH-500 i LiveCodeBench. Uwaga: model ten jest obecnie udostępniany eksperymentalnie jako model bezserwerowy. W przypadku zastosowań produkcyjnych należy pamiętać, że Fireworks może wycofać wdrożenie w krótkim czasie.",
  "accounts/fireworks/models/qwen2-vl-72b-instruct.description": "Model Qwen-VL 72B to najnowsza wersja modelu od Alibaba, odzwierciedlająca niemal rok innowacji.",
  "accounts/fireworks/models/qwen2p5-72b-instruct.description": "Qwen2.5 to seria modeli językowych typu decoder-only opracowana przez zespół Qwen i Alibaba Cloud, dostępna w rozmiarach 0.5B, 1.5B, 3B, 7B, 14B, 32B i 72B, zarówno w wersjach bazowych, jak i dostrojonych do instrukcji.",
  "accounts/fireworks/models/qwen2p5-coder-32b-instruct.description": "Qwen2.5-Coder to najnowszy model językowy Qwen zaprojektowany do programowania (wcześniej CodeQwen). Uwaga: model ten jest obecnie udostępniany eksperymentalnie jako model bezserwerowy. W przypadku zastosowań produkcyjnych należy pamiętać, że Fireworks może wycofać wdrożenie w krótkim czasie.",
  "accounts/yi-01-ai/models/yi-large.description": "Yi-Large to najwyższej klasy model językowy, który plasuje się tuż za GPT-4, Gemini 1.5 Pro i Claude 3 Opus w rankingu LMSYS. Wyróżnia się zdolnościami wielojęzycznymi, szczególnie w językach hiszpańskim, chińskim, japońskim, niemieckim i francuskim. Yi-Large jest również przyjazny dla programistów, korzystając z tego samego schematu API co OpenAI, co ułatwia integrację.",
  "ai21-jamba-1.5-large.description": "Wielojęzyczny model z 398 miliardami parametrów (94 miliardy aktywnych), oferujący okno kontekstowe 256K, wywoływanie funkcji, uporządkowane dane wyjściowe i generowanie oparte na faktach.",
  "ai21-jamba-1.5-mini.description": "Wielojęzyczny model z 52 miliardami parametrów (12 miliardów aktywnych), oferujący okno kontekstowe 256K, wywoływanie funkcji, uporządkowane dane wyjściowe i generowanie oparte na faktach.",
  "ai21-labs/AI21-Jamba-1.5-Large.description": "Wielojęzyczny model z 398 miliardami parametrów (94 miliardy aktywnych), oferujący okno kontekstowe 256K, wywoływanie funkcji, uporządkowane dane wyjściowe i generowanie oparte na faktach.",
  "ai21-labs/AI21-Jamba-1.5-Mini.description": "Wielojęzyczny model z 52 miliardami parametrów (12 miliardów aktywnych), oferujący okno kontekstowe 256K, wywoływanie funkcji, uporządkowane dane wyjściowe i generowanie oparte na faktach.",
  "alibaba/qwen-3-14b.description": "Qwen3 to najnowsza generacja w serii Qwen, oferująca kompleksowy zestaw modeli gęstych i MoE. Dzięki zaawansowanemu treningowi model osiąga przełomowe wyniki w rozumowaniu, podążaniu za instrukcjami, zdolnościach agentowych i obsłudze wielu języków.",
  "alibaba/qwen-3-235b.description": "Qwen3 to najnowsza generacja w serii Qwen, oferująca kompleksowy zestaw modeli gęstych i MoE. Dzięki zaawansowanemu treningowi model osiąga przełomowe wyniki w rozumowaniu, podążaniu za instrukcjami, zdolnościach agentowych i obsłudze wielu języków.",
  "alibaba/qwen-3-30b.description": "Qwen3 to najnowsza generacja w serii Qwen, oferująca kompleksowy zestaw modeli gęstych i MoE. Dzięki zaawansowanemu treningowi model osiąga przełomowe wyniki w rozumowaniu, podążaniu za instrukcjami, zdolnościach agentowych i obsłudze wielu języków.",
  "alibaba/qwen-3-32b.description": "Qwen3 to najnowsza generacja w serii Qwen, oferująca kompleksowy zestaw modeli gęstych i MoE. Dzięki zaawansowanemu treningowi model osiąga przełomowe wyniki w rozumowaniu, podążaniu za instrukcjami, zdolnościach agentowych i obsłudze wielu języków.",
  "alibaba/qwen3-coder.description": "Qwen3-Coder-480B-A35B-Instruct to najbardziej zaawansowany model kodujący Qwen, osiągający wysokie wyniki w kodowaniu agentowym, korzystaniu z przeglądarki i innych kluczowych zadaniach programistycznych, dorównując poziomowi Claude Sonnet.",
  "amazon/nova-lite.description": "Bardzo tani model multimodalny o wyjątkowo szybkim przetwarzaniu obrazów, wideo i tekstu.",
  "amazon/nova-micro.description": "Model tekstowy oferujący ultra-niskie opóźnienia przy bardzo niskim koszcie.",
  "amazon/nova-pro.description": "Wysoce wydajny model multimodalny zapewniający najlepszy balans między dokładnością, szybkością i kosztem w szerokim zakresie zadań.",
  "amazon/titan-embed-text-v2.description": "Amazon Titan Text Embeddings V2 to lekki, wydajny model osadzania tekstu obsługujący wiele języków i oferujący wymiary 1024, 512 i 256.",
  "anthropic.claude-3-5-sonnet-20240620-v1:0.description": "Claude 3.5 Sonnet ustanawia nowy standard branżowy, przewyższając konkurencję i Claude 3 Opus w szerokich testach, zachowując przy tym średni poziom kosztów i szybkości.",
  "anthropic.claude-3-5-sonnet-20241022-v2:0.description": "Claude 3.5 Sonnet ustanawia nowy standard branżowy, przewyższając konkurencję i Claude 3 Opus w szerokich testach, zachowując przy tym średni poziom kosztów i szybkości.",
  "anthropic.claude-3-haiku-20240307-v1:0.description": "Claude 3 Haiku to najszybszy i najbardziej kompaktowy model Anthropic, zapewniający niemal natychmiastowe odpowiedzi na proste zapytania. Umożliwia płynne, naturalne interakcje z AI i obsługuje wejście obrazowe z oknem kontekstowym 200K.",
  "anthropic.claude-3-opus-20240229-v1:0.description": "Claude 3 Opus to najpotężniejszy model AI od Anthropic, oferujący najwyższy poziom wydajności w złożonych zadaniach. Radzi sobie z otwartymi zapytaniami i nowymi scenariuszami z wyjątkową płynnością i zrozumieniem na poziomie ludzkim, obsługując wejście obrazowe z oknem kontekstowym 200K.",
  "anthropic.claude-3-sonnet-20240229-v1:0.description": "Claude 3 Sonnet łączy inteligencję i szybkość dla zastosowań korporacyjnych, oferując wysoką wartość przy niższych kosztach. Zaprojektowany jako niezawodny model do wdrożeń na dużą skalę, obsługuje wejście obrazowe z oknem kontekstowym 200K.",
  "anthropic.claude-instant-v1.description": "Szybki, ekonomiczny, a jednocześnie wydajny model do codziennych rozmów, analizy tekstu, podsumowań i pytań do dokumentów.",
  "anthropic.claude-v2.description": "Wysoce wydajny model do zadań od złożonego dialogu i kreatywnego generowania po szczegółowe podążanie za instrukcjami.",
  "anthropic.claude-v2:1.description": "Zaktualizowany Claude 2 z podwojonym oknem kontekstowym i poprawioną niezawodnością, mniejszą halucynacją i większą dokładnością opartą na dowodach dla długich dokumentów i RAG.",
  "anthropic/claude-3-haiku.description": "Claude 3 Haiku to najszybszy model Anthropic, zaprojektowany do zastosowań korporacyjnych z dłuższymi zapytaniami. Szybko analizuje duże dokumenty, takie jak raporty kwartalne, umowy czy sprawy prawne, przy połowie kosztów konkurencji.",
  "anthropic/claude-3-opus.description": "Claude 3 Opus to najbardziej inteligentny model Anthropic z wiodącą wydajnością w złożonych zadaniach, radzący sobie z otwartymi zapytaniami i nowymi scenariuszami z wyjątkową płynnością i zrozumieniem na poziomie ludzkim.",
  "anthropic/claude-3.5-haiku.description": "Claude 3.5 Haiku oferuje zwiększoną szybkość, dokładność kodowania i obsługę narzędzi, odpowiedni do scenariuszy wymagających szybkiej interakcji i integracji z narzędziami.",
  "anthropic/claude-3.5-sonnet.description": "Claude 3.5 Sonnet to szybki, wydajny model z rodziny Sonnet, oferujący lepsze kodowanie i rozumowanie, z niektórymi wersjami stopniowo zastępowanymi przez Sonnet 3.7 i nowsze.",
  "anthropic/claude-3.7-sonnet.description": "Claude 3.7 Sonnet to ulepszony model Sonnet z silniejszym rozumowaniem i kodowaniem, odpowiedni do złożonych zadań na poziomie korporacyjnym.",
  "anthropic/claude-haiku-4.5.description": "Claude Haiku 4.5 to szybki model o wysokiej wydajności od Anthropic, oferujący bardzo niskie opóźnienia przy zachowaniu wysokiej dokładności.",
  "anthropic/claude-opus-4.1.description": "Opus 4.1 to zaawansowany model Anthropic zoptymalizowany pod kątem programowania, złożonego rozumowania i długotrwałych zadań.",
  "anthropic/claude-opus-4.5.description": "Claude Opus 4.5 to flagowy model Anthropic, łączący najwyższą inteligencję z możliwością skalowania dla złożonych zadań wymagających wysokiej jakości rozumowania.",
  "anthropic/claude-opus-4.description": "Opus 4 to flagowy model Anthropic zaprojektowany do złożonych zadań i zastosowań korporacyjnych.",
  "anthropic/claude-sonnet-4.5.description": "Claude Sonnet 4.5 to najnowszy hybrydowy model rozumowania od Anthropic, zoptymalizowany pod kątem złożonego rozumowania i kodowania.",
  "anthropic/claude-sonnet-4.description": "Claude Sonnet 4 to hybrydowy model rozumowania Anthropic z mieszanym trybem myślenia i działania bez myślenia.",
  "ascend-tribe/pangu-pro-moe.description": "Pangu-Pro-MoE 72B-A16B to rzadki model językowy (LLM) o 72 miliardach parametrów całkowitych i 16 miliardach aktywnych, oparty na architekturze grupowanej MoE (MoGE). Grupuje ekspertów podczas selekcji i ogranicza aktywację tokenów do równej liczby ekspertów w każdej grupie, co równoważy obciążenie i zwiększa efektywność wdrażania na platformie Ascend.",
  "aya.description": "Aya 23 to wielojęzyczny model firmy Cohere, obsługujący 23 języki i różnorodne zastosowania.",
  "aya:35b.description": "Aya 23 to wielojęzyczny model firmy Cohere, obsługujący 23 języki i różnorodne zastosowania.",
  "azure-DeepSeek-R1-0528.description": "Wdrażany przez Microsoft; DeepSeek R1 został zaktualizowany do wersji DeepSeek-R1-0528. Aktualizacja zwiększa moc obliczeniową i optymalizuje algorytmy po treningu, znacząco poprawiając głębokość rozumowania i wnioskowanie. Model osiąga doskonałe wyniki w testach z matematyki, programowania i logiki ogólnej, zbliżając się do czołowych modeli, takich jak O3 i Gemini 2.5 Pro.",
  "baichuan-m2-32b.description": "Baichuan M2 32B to model MoE od Baichuan Intelligence, wyróżniający się silnymi zdolnościami rozumowania.",
  "baichuan/baichuan2-13b-chat.description": "Baichuan-13B to otwartoźródłowy model językowy z 13 miliardami parametrów, dostępny do użytku komercyjnego, osiągający najlepsze wyniki w swojej klasie w autorytatywnych testach w języku chińskim i angielskim.",
  "baidu/ERNIE-4.5-300B-A47B.description": "ERNIE-4.5-300B-A47B to model językowy MoE firmy Baidu z 300 miliardami parametrów całkowitych i 47 miliardami aktywnych na token, łączący wysoką wydajność z efektywnością obliczeniową. Jako kluczowy model serii ERNIE 4.5, wyróżnia się w rozumieniu, generowaniu, rozumowaniu i programowaniu. Wykorzystuje heterogeniczną metodę pretrenowania MoE z multimodalnym treningiem tekst-obraz, co zwiększa ogólne możliwości, szczególnie w zakresie podążania za instrukcjami i wiedzy o świecie.",
  "baidu/ernie-5.0-thinking-preview.description": "ERNIE 5.0 Thinking Preview to nowej generacji natywny multimodalny model ERNIE firmy Baidu, silny w rozumieniu multimodalnym, podążaniu za instrukcjami, tworzeniu treści, odpowiadaniu na pytania faktograficzne i korzystaniu z narzędzi.",
  "black-forest-labs/flux-1.1-pro.description": "FLUX 1.1 Pro to szybsza, ulepszona wersja modelu FLUX Pro, oferująca doskonałą jakość obrazu i zgodność z podpowiedziami.",
  "black-forest-labs/flux-dev.description": "FLUX Dev to wersja rozwojowa modelu FLUX przeznaczona do użytku niekomercyjnego.",
  "black-forest-labs/flux-pro.description": "FLUX Pro to profesjonalny model FLUX do generowania obrazów wysokiej jakości.",
  "black-forest-labs/flux-schnell.description": "FLUX Schnell to szybki model generowania obrazów zoptymalizowany pod kątem prędkości.",
  "c4ai-aya-expanse-32b.description": "Aya Expanse to wysokowydajny, wielojęzyczny model 32B, który wykorzystuje dostrajanie instrukcji, arbitraż danych, trening preferencji i łączenie modeli, aby dorównać modelom monojęzycznym. Obsługuje 23 języki.",
  "c4ai-aya-expanse-8b.description": "Aya Expanse to wysokowydajny, wielojęzyczny model 8B, który wykorzystuje dostrajanie instrukcji, arbitraż danych, trening preferencji i łączenie modeli, aby dorównać modelom monojęzycznym. Obsługuje 23 języki.",
  "c4ai-aya-vision-32b.description": "Aya Vision to nowoczesny model multimodalny, który osiąga wysokie wyniki w kluczowych testach językowych, tekstowych i wizualnych. Obsługuje 23 języki. Wersja 32B koncentruje się na najwyższej wydajności wielojęzycznej.",
  "c4ai-aya-vision-8b.description": "Aya Vision to nowoczesny model multimodalny, który osiąga wysokie wyniki w kluczowych testach językowych, tekstowych i wizualnych. Wersja 8B została zoptymalizowana pod kątem niskich opóźnień i wysokiej wydajności.",
  "charglm-3.description": "CharGLM-3 został zaprojektowany do odgrywania ról i emocjonalnego towarzyszenia, obsługując ultra-długą pamięć wieloetapową i spersonalizowany dialog.",
  "charglm-4.description": "CharGLM-4 został zaprojektowany do odgrywania ról i emocjonalnego towarzyszenia, obsługując ultra-długą pamięć wieloetapową i spersonalizowany dialog.",
  "chatgpt-4o-latest.description": "ChatGPT-4o to dynamiczny model aktualizowany w czasie rzeczywistym, łączący silne rozumienie i generowanie treści w zastosowaniach na dużą skalę, takich jak obsługa klienta, edukacja i wsparcie techniczne.",
  "claude-2.0.description": "Claude 2 wprowadza kluczowe ulepszenia dla przedsiębiorstw, w tym kontekst 200 tys. tokenów, zmniejszoną halucynację, podpowiedzi systemowe i nową funkcję testową: wywoływanie narzędzi.",
  "claude-2.1.description": "Claude 2 wprowadza kluczowe ulepszenia dla przedsiębiorstw, w tym kontekst 200 tys. tokenów, zmniejszoną halucynację, podpowiedzi systemowe i nową funkcję testową: wywoływanie narzędzi.",
  "claude-3-5-haiku-20241022.description": "Claude 3.5 Haiku to najszybszy model nowej generacji od Anthropic, oferujący ulepszone umiejętności i przewyższający poprzedni flagowy model Claude 3 Opus w wielu testach porównawczych.",
  "claude-3-5-haiku-latest.description": "Claude 3.5 Haiku zapewnia szybkie odpowiedzi w lekkich zadaniach.",
  "claude-3-7-sonnet-20250219.description": "Claude Sonnet 3.7 to najbardziej zaawansowany model Anthropic i pierwszy na rynku model hybrydowego rozumowania, umożliwiający błyskawiczne odpowiedzi lub pogłębione myślenie z precyzyjną kontrolą.",
  "claude-3-7-sonnet-latest.description": "Claude 3.7 Sonnet to najnowszy i najbardziej zaawansowany model firmy Anthropic do bardzo złożonych zadań, wyróżniający się wydajnością, inteligencją, płynnością i zrozumieniem.",
  "claude-3-haiku-20240307.description": "Claude 3 Haiku to najszybszy i najbardziej kompaktowy model firmy Anthropic, zaprojektowany do natychmiastowych odpowiedzi z szybką i dokładną wydajnością.",
  "claude-3-opus-20240229.description": "Claude 3 Opus to najpotężniejszy model firmy Anthropic do bardzo złożonych zadań, wyróżniający się wydajnością, inteligencją, płynnością i zrozumieniem.",
  "claude-3-sonnet-20240229.description": "Claude 3 Sonnet łączy inteligencję i szybkość dla obciążeń korporacyjnych, oferując wysoką użyteczność przy niższych kosztach i niezawodnym wdrażaniu na dużą skalę.",
  "claude-haiku-4-5-20251001.description": "Claude Haiku 4.5 to najszybszy i najbardziej inteligentny model Haiku od Anthropic, łączący błyskawiczne działanie z pogłębionym rozumowaniem.",
  "claude-opus-4-1-20250805-thinking.description": "Claude Opus 4.1 Thinking to zaawansowany wariant, który może ujawniać swój proces rozumowania.",
  "claude-opus-4-1-20250805.description": "Claude Opus 4.1 to najnowszy i najbardziej zaawansowany model firmy Anthropic do bardzo złożonych zadań, wyróżniający się wydajnością, inteligencją, płynnością i zrozumieniem.",
  "claude-opus-4-20250514.description": "Claude Opus 4 to najpotężniejszy model Anthropic, stworzony do realizacji wysoce złożonych zadań, wyróżniający się wydajnością, inteligencją, płynnością i zrozumieniem.",
  "claude-opus-4-5-20251101.description": "Claude Opus 4.5 to flagowy model firmy Anthropic, łączący wyjątkową inteligencję z wydajnością na dużą skalę, idealny do złożonych zadań wymagających najwyższej jakości odpowiedzi i rozumowania.",
  "claude-sonnet-4-20250514-thinking.description": "Claude Sonnet 4 Thinking może generować natychmiastowe odpowiedzi lub rozszerzone rozumowanie krok po kroku z widocznym procesem.",
  "claude-sonnet-4-20250514.description": "Claude Sonnet 4 to najbardziej inteligentny model Anthropic do tej pory, oferujący błyskawiczne odpowiedzi lub rozbudowane, krok po kroku rozumowanie z precyzyjną kontrolą dla użytkowników API.",
  "claude-sonnet-4-5-20250929.description": "Claude Sonnet 4.5 to najbardziej inteligentny model firmy Anthropic do tej pory.",
  "codegeex-4.description": "CodeGeeX-4 to potężny asystent programistyczny AI, obsługujący wielojęzyczne pytania i uzupełnianie kodu w celu zwiększenia produktywności programistów.",
  "codegeex4-all-9b.description": "CodeGeeX4-ALL-9B to wielojęzyczny model generowania kodu obsługujący uzupełnianie i generowanie kodu, interpretację kodu, wyszukiwanie w sieci, wywoływanie funkcji i pytania na poziomie repozytorium. Obejmuje szeroki zakres scenariuszy programistycznych i jest jednym z najlepszych modeli kodu poniżej 10B parametrów.",
  "codegemma.description": "CodeGemma to lekki model do różnorodnych zadań programistycznych, umożliwiający szybką iterację i integrację.",
  "codegemma:2b.description": "CodeGemma to lekki model do różnorodnych zadań programistycznych, umożliwiający szybką iterację i integrację.",
  "codellama.description": "Code Llama to duży model językowy (LLM) skoncentrowany na generowaniu i analizie kodu, obsługujący wiele języków programowania i wspierający przepływy pracy deweloperów.",
  "codellama/CodeLlama-34b-Instruct-hf.description": "Code Llama to duży model językowy (LLM) skoncentrowany na generowaniu i analizie kodu, obsługujący wiele języków programowania i wspierający przepływy pracy deweloperów.",
  "codellama:13b.description": "Code Llama to duży model językowy (LLM) skoncentrowany na generowaniu i analizie kodu, obsługujący wiele języków programowania i wspierający przepływy pracy deweloperów.",
  "codellama:34b.description": "Code Llama to duży model językowy (LLM) skoncentrowany na generowaniu i analizie kodu, obsługujący wiele języków programowania i wspierający przepływy pracy deweloperów.",
  "codellama:70b.description": "Code Llama to duży model językowy (LLM) skoncentrowany na generowaniu i analizie kodu, obsługujący wiele języków programowania i wspierający przepływy pracy deweloperów.",
  "codeqwen.description": "CodeQwen1.5 to duży model językowy wytrenowany na obszernych danych kodu, zaprojektowany do realizacji złożonych zadań programistycznych.",
  "codestral-latest.description": "Codestral to nasz najbardziej zaawansowany model kodujący; wersja 2 (styczeń 2025) została zoptymalizowana pod kątem niskich opóźnień i zadań o wysokiej częstotliwości, takich jak FIM, poprawa kodu i generowanie testów.",
  "codestral.description": "Codestral to pierwszy model kodujący od Mistral AI, oferujący solidne wsparcie dla generowania kodu.",
  "codex-mini-latest.description": "codex-mini-latest to dostrojony model o4-mini dla interfejsu Codex CLI. Do bezpośredniego użycia przez API zalecamy rozpoczęcie od gpt-4.1.",
  "cogito-2.1:671b.description": "Cogito v2.1 671B to amerykański otwartoźródłowy model LLM dostępny do użytku komercyjnego, dorównujący wydajnością czołowym modelom, oferujący wyższą efektywność rozumowania tokenów, kontekst długości 128k i ogólnie wysokie możliwości.",
  "cogview-4.description": "CogView-4 to pierwszy otwartoźródłowy model tekst-na-obraz od Zhipu, który potrafi generować chińskie znaki. Poprawia zrozumienie semantyczne, jakość obrazu i renderowanie tekstu w języku chińskim i angielskim, obsługuje dwujęzyczne podpowiedzi o dowolnej długości i generuje obrazy w dowolnej rozdzielczości w określonych zakresach.",
  "cohere-command-r-plus.description": "Command R+ to zaawansowany model zoptymalizowany pod kątem RAG, stworzony z myślą o zastosowaniach korporacyjnych.",
  "cohere-command-r.description": "Command R to skalowalny model generatywny zaprojektowany do zastosowań RAG i integracji z narzędziami, umożliwiający wdrażanie AI na poziomie produkcyjnym.",
  "cohere/Cohere-command-r-plus.description": "Command R+ to zaawansowany model zoptymalizowany pod kątem RAG, stworzony z myślą o zastosowaniach korporacyjnych.",
  "cohere/Cohere-command-r.description": "Command R to skalowalny model generatywny zaprojektowany do zastosowań RAG i integracji z narzędziami, umożliwiający wdrażanie AI na poziomie produkcyjnym.",
  "cohere/command-a.description": "Command A to najpotężniejszy model Cohere, doskonały w użyciu narzędzi, agentach, RAG i scenariuszach wielojęzycznych. Obsługuje kontekst długości 256K, działa na zaledwie dwóch GPU i zapewnia 150% większą przepustowość niż Command R+ 08-2024.",
  "cohere/command-r-plus.description": "Command R+ to najnowszy model LLM od Cohere, zoptymalizowany pod kątem czatu i długiego kontekstu, zaprojektowany z myślą o przejściu firm od prototypów do produkcji.",
  "cohere/command-r.description": "Command R jest zoptymalizowany pod kątem czatu i zadań z długim kontekstem, pozycjonowany jako model „skalowalny”, który równoważy wysoką wydajność i dokładność, umożliwiając firmom przejście od prototypów do produkcji.",
  "cohere/embed-v4.0.description": "Model klasyfikujący lub przekształcający tekst, obrazy lub treści mieszane w osadzenia (embeddings).",
  "comfyui/flux-dev.description": "FLUX.1 Dev to wysokiej jakości model tekst-na-obraz (10–50 kroków), idealny do kreatywnych i artystycznych zastosowań premium.",
  "comfyui/flux-kontext-dev.description": "FLUX.1 Kontext-dev to model edycji obrazu wspierający edycje prowadzone tekstem, w tym edycje lokalne i transfer stylu.",
  "comfyui/flux-krea-dev.description": "FLUX.1 Krea-dev to model tekst-na-obraz z wbudowanymi filtrami bezpieczeństwa, współtworzony z Krea.",
  "comfyui/flux-schnell.description": "FLUX.1 Schnell to ultraszybki model tekst-na-obraz generujący wysokiej jakości obrazy w 1–4 krokach, idealny do zastosowań w czasie rzeczywistym i szybkiego prototypowania.",
  "comfyui/stable-diffusion-15.description": "Stable Diffusion 1.5 to klasyczny model tekst-na-obraz 512x512, idealny do szybkiego prototypowania i eksperymentów twórczych.",
  "comfyui/stable-diffusion-35-inclclip.description": "Stable Diffusion 3.5 z wbudowanymi enkoderami CLIP/T5 nie wymaga zewnętrznych plików enkodera, odpowiedni dla modeli takich jak sd3.5_medium_incl_clips o niższym zużyciu zasobów.",
  "comfyui/stable-diffusion-35.description": "Stable Diffusion 3.5 to nowej generacji model tekst-na-obraz w wariantach Large i Medium. Wymaga zewnętrznych plików enkodera CLIP i zapewnia doskonałą jakość obrazu oraz zgodność z podpowiedziami.",
  "comfyui/stable-diffusion-custom-refiner.description": "Niestandardowy model SDXL obraz-na-obraz. Użyj custom_sd_lobe.safetensors jako nazwy pliku modelu; jeśli posiadasz VAE, użyj custom_sd_vae_lobe.safetensors. Umieść pliki modelu w wymaganych folderach Comfy.",
  "comfyui/stable-diffusion-custom.description": "Niestandardowy model SD tekst-na-obraz. Użyj custom_sd_lobe.safetensors jako nazwy pliku modelu; jeśli posiadasz VAE, użyj custom_sd_vae_lobe.safetensors. Umieść pliki modelu w wymaganych folderach Comfy.",
  "comfyui/stable-diffusion-refiner.description": "Model SDXL obraz-na-obraz wykonuje wysokiej jakości transformacje obrazów wejściowych, wspierając transfer stylu, rekonstrukcję i kreatywne wariacje.",
  "comfyui/stable-diffusion-xl.description": "SDXL to model tekst-na-obraz obsługujący generowanie obrazów w wysokiej rozdzielczości 1024x1024 z lepszą jakością i szczegółowością.",
  "command-a-03-2025.description": "Command A to nasz najbardziej zaawansowany model, doskonały w użyciu narzędzi, agentach, RAG i scenariuszach wielojęzycznych. Obsługuje kontekst długości 256K, działa na zaledwie dwóch GPU i zapewnia 150% większą przepustowość niż Command R+ 08-2024.",
  "command-light-nightly.description": "Aby skrócić czas między głównymi wydaniami, oferujemy nocne kompilacje Command. W serii command-light nazywa się to command-light-nightly. Jest to najnowsza, najbardziej eksperymentalna (i potencjalnie niestabilna) wersja, aktualizowana regularnie bez zapowiedzi, dlatego nie jest zalecana do produkcji.",
  "command-light.description": "Mniejszy, szybszy wariant Command, niemal równie wydajny, ale szybszy.",
  "command-nightly.description": "Aby skrócić czas między głównymi wydaniami, oferujemy nocne kompilacje Command. W serii Command nazywa się to command-nightly. Jest to najnowsza, najbardziej eksperymentalna (i potencjalnie niestabilna) wersja, aktualizowana regularnie bez zapowiedzi, dlatego nie jest zalecana do produkcji.",
  "command-r-03-2024.description": "Command R to model czatu podążający za instrukcjami, oferujący wyższą jakość, większą niezawodność i dłuższe okno kontekstu niż wcześniejsze modele. Obsługuje złożone przepływy pracy, takie jak generowanie kodu, RAG, użycie narzędzi i agentów.",
  "command-r-08-2024.description": "command-r-08-2024 to zaktualizowany model Command R wydany w sierpniu 2024.",
  "command-r-plus-04-2024.description": "command-r-plus to alias modelu command-r-plus-04-2024, więc użycie command-r-plus w API wskazuje na ten model.",
  "command-r-plus-08-2024.description": "Command R+ to model czatu podążający za instrukcjami, oferujący wyższą jakość, większą niezawodność i dłuższe okno kontekstu niż wcześniejsze modele. Najlepiej sprawdza się w złożonych przepływach RAG i wieloetapowym użyciu narzędzi.",
  "command-r-plus.description": "Command R+ to wysokowydajny model LLM zaprojektowany do rzeczywistych scenariuszy korporacyjnych i złożonych aplikacji.",
  "command-r.description": "Command R to model LLM zoptymalizowany pod kątem czatu i zadań z długim kontekstem, idealny do dynamicznej interakcji i zarządzania wiedzą.",
  "command-r7b-12-2024.description": "command-r7b-12-2024 to mała, wydajna aktualizacja wydana w grudniu 2024. Doskonale sprawdza się w zadaniach RAG, użyciu narzędzi i agentach wymagających złożonego, wieloetapowego rozumowania.",
  "command.description": "Model czatu podążający za instrukcjami, oferujący wyższą jakość i niezawodność w zadaniach językowych, z dłuższym oknem kontekstu niż nasze podstawowe modele generatywne.",
  "computer-use-preview.description": "computer-use-preview to specjalistyczny model dla narzędzia „użycie komputera”, wytrenowany do rozumienia i wykonywania zadań związanych z komputerem.",
  "dall-e-2.description": "Druga generacja modelu DALL·E z bardziej realistycznym i dokładnym generowaniem obrazów oraz 4× wyższą rozdzielczością niż pierwsza generacja.",
  "dall-e-3.description": "Najnowszy model DALL·E, wydany w listopadzie 2023, oferuje bardziej realistyczne i dokładne generowanie obrazów z lepszymi szczegółami.",
  "databricks/dbrx-instruct.description": "DBRX Instruct zapewnia niezawodne przetwarzanie instrukcji w różnych branżach.",
  "deepseek-ai/DeepSeek-OCR.description": "DeepSeek-OCR to model językowo-wizualny od DeepSeek AI skoncentrowany na OCR i „optycznej kompresji kontekstowej”. Eksploruje kompresję kontekstu z obrazów, efektywnie przetwarza dokumenty i konwertuje je na ustrukturyzowany tekst (np. Markdown). Dokładnie rozpoznaje tekst na obrazach, idealny do cyfryzacji dokumentów, ekstrakcji tekstu i przetwarzania strukturalnego.",
  "deepseek-ai/DeepSeek-R1-0528-Qwen3-8B.description": "DeepSeek-R1-0528-Qwen3-8B destyluje łańcuch rozumowania z DeepSeek-R1-0528 do Qwen3 8B Base. Osiąga SOTA wśród modeli open-source, przewyższając Qwen3 8B o 10% w AIME 2024 i dorównując wydajności Qwen3-235B-thinking. Wyróżnia się w rozumowaniu matematycznym, programowaniu i testach logiki. Dzieli architekturę Qwen3-8B, ale używa tokenizera DeepSeek-R1-0528.",
  "deepseek-ai/DeepSeek-R1-0528.description": "DeepSeek R1 wykorzystuje dodatkową moc obliczeniową i optymalizacje algorytmiczne po treningu, aby pogłębić rozumowanie. Osiąga wysokie wyniki w testach matematycznych, programistycznych i logicznych, zbliżając się do liderów takich jak o3 i Gemini 2.5 Pro.",
  "deepseek-ai/DeepSeek-R1-Distill-Llama-70B.description": "Modele destylowane DeepSeek-R1 wykorzystują RL i dane cold-start do poprawy rozumowania i ustanawiają nowe rekordy w testach wielozadaniowych modeli open-source.",
  "deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B.description": "Modele destylowane DeepSeek-R1 wykorzystują RL i dane cold-start do poprawy rozumowania i ustanawiają nowe rekordy w testach wielozadaniowych modeli open-source.",
  "deepseek-ai/DeepSeek-R1-Distill-Qwen-14B.description": "Modele destylowane DeepSeek-R1 wykorzystują RL i dane cold-start do poprawy rozumowania i ustanawiają nowe rekordy w testach wielozadaniowych modeli open-source.",
  "deepseek-ai/DeepSeek-R1-Distill-Qwen-32B.description": "DeepSeek-R1-Distill-Qwen-32B to model destylowany z Qwen2.5-32B i dostrojony na 800 tys. starannie dobranych próbkach DeepSeek-R1. Wyróżnia się w matematyce, programowaniu i rozumowaniu, osiągając wysokie wyniki w AIME 2024, MATH-500 (94,3% trafności) i GPQA Diamond.",
  "deepseek-ai/DeepSeek-R1-Distill-Qwen-7B.description": "DeepSeek-R1-Distill-Qwen-7B to model destylowany z Qwen2.5-Math-7B i dostrojony na 800 tys. starannie dobranych próbkach DeepSeek-R1. Osiąga wysokie wyniki: 92,8% w MATH-500, 55,5% w AIME 2024 i ocenę 1189 w CodeForces dla modelu 7B.",
  "deepseek-ai/DeepSeek-R1.description": "DeepSeek-R1 poprawia rozumowanie dzięki RL i danym cold-start, ustanawiając nowe rekordy w testach wielozadaniowych modeli open-source i przewyższając OpenAI-o1-mini.",
  "deepseek-ai/DeepSeek-V2.5.description": "DeepSeek-V2.5 to ulepszona wersja DeepSeek-V2-Chat i DeepSeek-Coder-V2-Instruct, łącząca ogólne i programistyczne zdolności. Poprawia pisanie i wykonywanie instrukcji, lepiej dopasowując się do preferencji użytkownika, i osiąga znaczące wyniki w AlpacaEval 2.0, ArenaHard, AlignBench i MT-Bench.",
  "deepseek-ai/DeepSeek-V3.1-Terminus.description": "DeepSeek-V3.1-Terminus to zaktualizowany model V3.1 pełniący rolę hybrydowego agenta LLM. Naprawia zgłoszone przez użytkowników problemy, poprawia stabilność, spójność językową i redukuje mieszane znaki chińskie/angielskie oraz anomalie. Integruje tryby myślenia i nie-myślenia z szablonami czatu dla elastycznego przełączania. Ulepsza także działanie Code Agent i Search Agent, zapewniając bardziej niezawodne korzystanie z narzędzi i realizację zadań wieloetapowych.",
  "deepseek-ai/DeepSeek-V3.1.description": "DeepSeek V3.1 wykorzystuje hybrydową architekturę rozumowania i obsługuje zarówno tryby myślenia, jak i nie-myślenia.",
  "deepseek-ai/DeepSeek-V3.2-Exp.description": "DeepSeek-V3.2-Exp to eksperymentalna wersja V3.2, stanowiąca pomost do nowej architektury. Dodaje DeepSeek Sparse Attention (DSA) do V3.1-Terminus, poprawiając efektywność treningu i wnioskowania w długim kontekście, z optymalizacjami dla użycia narzędzi, rozumienia długich dokumentów i rozumowania wieloetapowego. Idealny do eksploracji wyższej efektywności rozumowania przy dużych budżetach kontekstowych.",
  "deepseek-ai/DeepSeek-V3.description": "DeepSeek-V3 to model MoE z 671 miliardami parametrów, wykorzystujący MLA i DeepSeekMoE z bezstratnym równoważeniem obciążenia dla efektywnego treningu i wnioskowania. Wytrenowany na 14,8T wysokiej jakości tokenach z SFT i RL, przewyższa inne modele open-source i zbliża się do czołowych modeli zamkniętych.",
  "deepseek-ai/deepseek-llm-67b-chat.description": "DeepSeek LLM Chat (67B) to innowacyjny model oferujący głębokie zrozumienie języka i interakcję.",
  "deepseek-ai/deepseek-r1.description": "Nowoczesny, wydajny LLM o wysokich zdolnościach w rozumowaniu, matematyce i programowaniu.",
  "deepseek-ai/deepseek-v3.1-terminus.description": "DeepSeek V3.1 to model nowej generacji do rozumowania z silniejszym rozumowaniem złożonym i łańcuchem myśli do zadań wymagających głębokiej analizy.",
  "deepseek-ai/deepseek-v3.1.description": "DeepSeek V3.1 to model nowej generacji do rozumowania z silniejszym rozumowaniem złożonym i łańcuchem myśli do zadań wymagających głębokiej analizy.",
  "deepseek-ai/deepseek-vl2.description": "DeepSeek-VL2 to model językowo-wizualny MoE oparty na DeepSeekMoE-27B z rzadką aktywacją, osiągający wysoką wydajność przy zaledwie 4,5B aktywnych parametrów. Wyróżnia się w zadaniach QA wizualnych, OCR, rozumieniu dokumentów/tabel/wykresów i ugruntowaniu wizualnym.",
  "deepseek-chat.description": "DeepSeek V3.2 zapewnia równowagę między rozumowaniem a długością odpowiedzi w codziennych zadaniach QA i agentowych. W testach publicznych osiąga poziom GPT-5 i jako pierwszy integruje myślenie z użyciem narzędzi, prowadząc w ocenach agentów open-source.",
  "deepseek-coder-33B-instruct.description": "DeepSeek Coder 33B to model języka kodu wytrenowany na 2T tokenach (87% kod, 13% tekst chiński/angielski). Wprowadza okno kontekstu 16K i zadania uzupełniania w środku, oferując uzupełnianie kodu na poziomie projektu i wypełnianie fragmentów.",
  "deepseek-coder-v2.description": "DeepSeek Coder V2 to open-source’owy model kodu MoE, który osiąga wysokie wyniki w zadaniach programistycznych, porównywalne z GPT-4 Turbo.",
  "deepseek-coder-v2:236b.description": "DeepSeek Coder V2 to open-source’owy model kodu MoE, który osiąga wysokie wyniki w zadaniach programistycznych, porównywalne z GPT-4 Turbo.",
  "deepseek-ocr.description": "DeepSeek-OCR to model językowo-wizualny od DeepSeek AI skoncentrowany na OCR i „optycznej kompresji kontekstowej”. Eksploruje kompresję informacji kontekstowych z obrazów, efektywnie przetwarza dokumenty i konwertuje je do ustrukturyzowanych formatów tekstowych, takich jak Markdown. Dokładnie rozpoznaje tekst na obrazach, idealny do cyfryzacji dokumentów, ekstrakcji tekstu i przetwarzania strukturalnego.",
  "deepseek-r1-0528.description": "Model pełny 685B wydany 28.05.2025. DeepSeek-R1 wykorzystuje uczenie przez wzmocnienie (RL) na dużą skalę po etapie trenowania, znacznie poprawiając rozumowanie przy minimalnej ilości oznaczonych danych. Wyróżnia się w zadaniach matematycznych, programistycznych i językowych.",
  "deepseek-r1-250528.description": "DeepSeek R1 250528 to pełna wersja modelu DeepSeek-R1 przeznaczona do trudnych zadań matematycznych i logicznych.",
  "deepseek-r1-70b-fast-online.description": "Szybka edycja DeepSeek R1 70B z wyszukiwaniem w czasie rzeczywistym, zapewniająca szybsze odpowiedzi przy zachowaniu wysokiej wydajności.",
  "deepseek-r1-70b-online.description": "Standardowa edycja DeepSeek R1 70B z wyszukiwaniem w czasie rzeczywistym, idealna do aktualnych zadań konwersacyjnych i tekstowych.",
  "deepseek-r1-distill-llama-70b.description": "DeepSeek R1 Distill Llama 70B łączy rozumowanie R1 z ekosystemem Llama.",
  "deepseek-r1-distill-llama-8b.description": "DeepSeek-R1-Distill-Llama-8B to model zdestylowany z Llama-3.1-8B przy użyciu wyników DeepSeek R1.",
  "deepseek-r1-distill-llama.description": "deepseek-r1-distill-llama to model zdestylowany z DeepSeek-R1 na bazie Llama.",
  "deepseek-r1-distill-qianfan-70b.description": "DeepSeek R1 Distill Qianfan 70B to destylacja R1 oparta na Qianfan-70B o wysokiej wartości użytkowej.",
  "deepseek-r1-distill-qianfan-8b.description": "DeepSeek R1 Distill Qianfan 8B to destylacja R1 oparta na Qianfan-8B, przeznaczona do małych i średnich aplikacji.",
  "deepseek-r1-distill-qianfan-llama-70b.description": "DeepSeek R1 Distill Qianfan Llama 70B to destylacja R1 oparta na Llama-70B.",
  "deepseek-r1-distill-qwen-1.5b.description": "DeepSeek R1 Distill Qwen 1.5B to ultralekki model destylowany do środowisk o bardzo ograniczonych zasobach.",
  "deepseek-r1-distill-qwen-14b.description": "DeepSeek R1 Distill Qwen 14B to model średniej wielkości do wdrożeń w różnych scenariuszach.",
  "deepseek-r1-distill-qwen-32b.description": "DeepSeek R1 Distill Qwen 32B to destylacja R1 oparta na Qwen-32B, zapewniająca równowagę między wydajnością a kosztem.",
  "deepseek-r1-distill-qwen-7b.description": "DeepSeek R1 Distill Qwen 7B to lekki model destylowany do zastosowań brzegowych i środowisk korporacyjnych.",
  "deepseek-r1-distill-qwen.description": "deepseek-r1-distill-qwen to model zdestylowany z DeepSeek-R1 na bazie Qwen.",
  "deepseek-r1-fast-online.description": "Szybka pełna wersja DeepSeek R1 z wyszukiwaniem w czasie rzeczywistym, łącząca możliwości modelu 671B z szybszymi odpowiedziami.",
  "deepseek-r1-online.description": "Pełna wersja DeepSeek R1 z 671 miliardami parametrów i wyszukiwaniem w czasie rzeczywistym, oferująca lepsze rozumienie i generowanie.",
  "deepseek-r1.description": "DeepSeek-R1 wykorzystuje dane startowe przed RL i osiąga wyniki porównywalne z OpenAI-o1 w zadaniach matematycznych, programistycznych i logicznych.",
  "deepseek-reasoner.description": "DeepSeek V3.2 Thinking to model głębokiego rozumowania, który generuje łańcuch myśli przed odpowiedzią dla większej precyzji. Osiąga czołowe wyniki w konkursach i rozumowaniu porównywalnym z Gemini-3.0-Pro.",
  "deepseek-v2.description": "DeepSeek V2 to wydajny model MoE zoptymalizowany pod kątem efektywności kosztowej.",
  "deepseek-v2:236b.description": "DeepSeek V2 236B to model skoncentrowany na kodzie, oferujący zaawansowane generowanie kodu.",
  "deepseek-v3-0324.description": "DeepSeek-V3-0324 to model MoE z 671 miliardami parametrów, wyróżniający się w programowaniu, rozumieniu kontekstu i obsłudze długich tekstów.",
  "deepseek-v3.1-terminus.description": "DeepSeek-V3.1-Terminus to zoptymalizowany pod terminale model LLM od DeepSeek, dostosowany do urządzeń końcowych.",
  "deepseek-v3.1-think-250821.description": "DeepSeek V3.1 Think 250821 to model głębokiego rozumowania odpowiadający wersji Terminus, stworzony do zadań wymagających wysokiej wydajności rozumowania.",
  "deepseek-v3.1.description": "DeepSeek-V3.1 to nowy hybrydowy model rozumowania od DeepSeek, obsługujący tryby myślenia i bezmyślenia, oferujący wyższą efektywność rozumowania niż DeepSeek-R1-0528. Optymalizacje po etapie trenowania znacznie poprawiają wykorzystanie narzędzi i wydajność zadań agentowych. Obsługuje okno kontekstowe 128k i do 64k tokenów wyjściowych.",
  "deepseek-v3.1:671b.description": "DeepSeek V3.1 to model nowej generacji do złożonego rozumowania i łańcuchów myślowych, odpowiedni do zadań wymagających głębokiej analizy.",
  "deepseek-v3.2-exp.description": "deepseek-v3.2-exp wprowadza rzadką uwagę (sparse attention), poprawiając efektywność trenowania i wnioskowania na długich tekstach przy niższej cenie niż deepseek-v3.1.",
  "deepseek-v3.2-think.description": "DeepSeek V3.2 Think to pełny model głębokiego rozumowania z silniejszymi zdolnościami do długich łańcuchów myślowych.",
  "deepseek-v3.2.description": "DeepSeek-V3.2 to pierwszy model hybrydowego rozumowania od DeepSeek, który integruje myślenie z użyciem narzędzi. Dzięki wydajnej architekturze oszczędza moc obliczeniową, wykorzystuje RL na dużą skalę do zwiększenia możliwości oraz dane zadań syntetycznych do poprawy uogólnienia. Wydajność porównywalna z GPT-5-High, znacznie skrócony czas odpowiedzi i mniejsze zużycie zasobów.",
  "deepseek-v3.description": "DeepSeek-V3 to potężny model MoE z 671 miliardami parametrów ogółem i 37 miliardami aktywnymi na token.",
  "deepseek-vl2-small.description": "DeepSeek VL2 Small to lekka wersja multimodalna do środowisk o ograniczonych zasobach i wysokiej równoczesności.",
  "deepseek-vl2.description": "DeepSeek VL2 to model multimodalny do rozumienia obrazu i tekstu oraz precyzyjnych zadań wizualnych typu pytanie-odpowiedź.",
  "deepseek/deepseek-chat-v3-0324.description": "DeepSeek V3 to model MoE z 685 miliardami parametrów i najnowsza wersja flagowej serii czatów DeepSeek.\n\nBazuje na [DeepSeek V3](/deepseek/deepseek-chat-v3) i osiąga wysokie wyniki w różnych zadaniach.",
  "deepseek/deepseek-chat-v3-0324:free.description": "DeepSeek V3 to model MoE z 685 miliardami parametrów i najnowsza wersja flagowej serii czatów DeepSeek.\n\nBazuje na [DeepSeek V3](/deepseek/deepseek-chat-v3) i osiąga wysokie wyniki w różnych zadaniach.",
  "deepseek/deepseek-chat-v3.1.description": "DeepSeek-V3.1 to model hybrydowego rozumowania z długim kontekstem, obsługujący tryby myślenia i bezmyślenia oraz integrację z narzędziami.",
  "deepseek/deepseek-chat.description": "DeepSeek-V3 to model hybrydowego rozumowania o wysokiej wydajności, przeznaczony do złożonych zadań i integracji z narzędziami.",
  "deepseek/deepseek-r1-0528.description": "DeepSeek R1 0528 to zaktualizowana wersja skoncentrowana na otwartej dostępności i głębszym rozumowaniu.",
  "deepseek/deepseek-r1-0528:free.description": "DeepSeek-R1 znacznie poprawia rozumowanie przy minimalnej ilości oznaczonych danych i generuje łańcuch rozumowania przed odpowiedzią końcową, zwiększając trafność.",
  "deepseek/deepseek-r1-distill-llama-70b.description": "DeepSeek R1 Distill Llama 70B to zdestylowany model LLM oparty na Llama 3.3 70B, dostrojony przy użyciu wyników DeepSeek R1, osiągający konkurencyjne wyniki względem czołowych modeli.",
  "deepseek/deepseek-r1-distill-llama-8b.description": "DeepSeek R1 Distill Llama 8B to zdestylowany model LLM oparty na Llama-3.1-8B-Instruct, trenowany przy użyciu wyników DeepSeek R1.",
  "deepseek/deepseek-r1-distill-qwen-14b.description": "DeepSeek R1 Distill Qwen 14B to odchudzony model LLM oparty na Qwen 2.5 14B, wytrenowany na danych wyjściowych DeepSeek R1. Przewyższa OpenAI o1-mini w wielu testach porównawczych, osiągając najnowocześniejsze wyniki wśród modeli gęstych. Najważniejsze wyniki benchmarków:\nAIME 2024 pass@1: 69,7\nMATH-500 pass@1: 93,9\nOcena CodeForces: 1481\nDostrajanie na danych DeepSeek R1 zapewnia konkurencyjną wydajność względem większych modeli czołowych.",
  "deepseek/deepseek-r1-distill-qwen-32b.description": "DeepSeek R1 Distill Qwen 32B to odchudzony model LLM oparty na Qwen 2.5 32B, wytrenowany na danych wyjściowych DeepSeek R1. Przewyższa OpenAI o1-mini w wielu testach porównawczych, osiągając najnowocześniejsze wyniki wśród modeli gęstych. Najważniejsze wyniki benchmarków:\nAIME 2024 pass@1: 72,6\nMATH-500 pass@1: 94,3\nOcena CodeForces: 1691\nDostrajanie na danych DeepSeek R1 zapewnia konkurencyjną wydajność względem większych modeli czołowych.",
  "deepseek/deepseek-r1.description": "DeepSeek R1 został zaktualizowany do wersji DeepSeek-R1-0528. Dzięki większej mocy obliczeniowej i optymalizacjom algorytmicznym po treningu, znacząco poprawiono głębokość i zdolność rozumowania. Model osiąga wysokie wyniki w testach z zakresu matematyki, programowania i logiki ogólnej, zbliżając się do liderów takich jak o3 i Gemini 2.5 Pro.",
  "deepseek/deepseek-r1/community.description": "DeepSeek R1 to najnowszy model open-source wydany przez zespół DeepSeek, charakteryzujący się bardzo silnymi zdolnościami rozumowania, szczególnie w zadaniach matematycznych, programistycznych i logicznych, porównywalnymi z OpenAI o1.",
  "deepseek/deepseek-r1:free.description": "DeepSeek-R1 znacząco poprawia rozumowanie przy minimalnej ilości oznaczonych danych, generując łańcuch rozumowania przed ostateczną odpowiedzią w celu zwiększenia dokładności.",
  "deepseek/deepseek-reasoner.description": "DeepSeek-V3 Thinking (reasoner) to eksperymentalny model rozumowania od DeepSeek, odpowiedni do zadań wymagających wysokiego poziomu złożoności logicznej.",
  "deepseek/deepseek-v3.1-base.description": "DeepSeek V3.1 Base to ulepszona wersja modelu DeepSeek V3.",
  "deepseek/deepseek-v3.description": "Szybki, uniwersalny model LLM z ulepszonymi zdolnościami rozumowania.",
  "deepseek/deepseek-v3/community.description": "DeepSeek-V3 stanowi przełom w szybkości rozumowania względem poprzednich modeli. Zajmuje pierwsze miejsce wśród modeli open-source i dorównuje najbardziej zaawansowanym modelom zamkniętym. DeepSeek-V3 wykorzystuje Multi-Head Latent Attention (MLA) oraz architekturę DeepSeekMoE, obie w pełni sprawdzone w DeepSeek-V2. Wprowadza również bezstratną strategię pomocniczą dla równoważenia obciążenia oraz cel treningowy oparty na przewidywaniu wielu tokenów dla lepszej wydajności.",
  "deepseek_r1.description": "DeepSeek-R1 to model rozumowania oparty na uczeniu przez wzmacnianie, który rozwiązuje problemy powtórzeń i czytelności. Przed etapem RL wykorzystuje dane startowe do dalszego zwiększenia zdolności rozumowania. Dorównuje OpenAI-o1 w zadaniach matematycznych, programistycznych i logicznych, a starannie zaprojektowany proces treningowy poprawia ogólne wyniki.",
  "deepseek_r1_distill_llama_70b.description": "DeepSeek-R1-Distill-Llama-70B to model odchudzony z Llama-3.3-70B-Instruct. Jako część serii DeepSeek-R1, został dostrojony na próbkach wygenerowanych przez DeepSeek-R1 i osiąga wysokie wyniki w matematyce, programowaniu i rozumowaniu.",
  "deepseek_r1_distill_qwen_14b.description": "DeepSeek-R1-Distill-Qwen-14B to model odchudzony z Qwen2.5-14B, dostrojony na 800 tysiącach starannie wyselekcjonowanych próbek wygenerowanych przez DeepSeek-R1, zapewniający silne zdolności rozumowania.",
  "deepseek_r1_distill_qwen_32b.description": "DeepSeek-R1-Distill-Qwen-32B to model odchudzony z Qwen2.5-32B, dostrojony na 800 tysiącach starannie wyselekcjonowanych próbek wygenerowanych przez DeepSeek-R1, wyróżniający się w matematyce, programowaniu i rozumowaniu.",
  "devstral-2:123b.description": "Devstral 2 123B doskonale wykorzystuje narzędzia do eksploracji baz kodu, edycji wielu plików i wspierania agentów inżynierii oprogramowania.",
  "doubao-1.5-lite-32k.description": "Doubao-1.5-lite to nowy, lekki model o ultrabłyskawicznej odpowiedzi, oferujący najwyższą jakość i niskie opóźnienia.",
  "doubao-1.5-pro-256k.description": "Doubao-1.5-pro-256k to kompleksowa aktualizacja modelu Doubao-1.5-Pro, poprawiająca ogólną wydajność o 10%. Obsługuje kontekst do 256k i do 12k tokenów wyjściowych, oferując wyższą wydajność, większe okno i dużą wartość dla szerokiego zakresu zastosowań.",
  "doubao-1.5-pro-32k.description": "Doubao-1.5-pro to flagowy model nowej generacji z kompleksowymi ulepszeniami, wyróżniający się w wiedzy, kodowaniu i rozumowaniu.",
  "doubao-1.5-thinking-pro-m.description": "Doubao-1.5 to nowy model głębokiego rozumowania (wersja m obejmuje natywne multimodalne rozumowanie), który doskonale radzi sobie z matematyką, kodowaniem, rozumowaniem naukowym i ogólnymi zadaniami, takimi jak twórcze pisanie. Osiąga lub zbliża się do wyników najwyższej klasy w testach takich jak AIME 2024, Codeforces i GPQA. Obsługuje kontekst 128k i 16k tokenów wyjściowych.",
  "doubao-1.5-thinking-pro.description": "Doubao-1.5 to nowy model głębokiego rozumowania, który doskonale radzi sobie z matematyką, kodowaniem, rozumowaniem naukowym i ogólnymi zadaniami, takimi jak twórcze pisanie. Osiąga lub zbliża się do wyników najwyższej klasy w testach takich jak AIME 2024, Codeforces i GPQA. Obsługuje kontekst 128k i 16k tokenów wyjściowych.",
  "doubao-1.5-thinking-vision-pro.description": "Nowy model wizualnego głębokiego rozumowania z silniejszym multimodalnym zrozumieniem i rozumowaniem, osiągający SOTA na 37 z 59 publicznych benchmarków.",
  "doubao-1.5-ui-tars.description": "Doubao-1.5-UI-TARS to natywny model agenta GUI, który płynnie współdziała z interfejsami dzięki percepcji, rozumowaniu i działaniu zbliżonym do ludzkiego.",
  "doubao-1.5-vision-lite.description": "Doubao-1.5-vision-lite to ulepszony model multimodalny obsługujący obrazy w dowolnej rozdzielczości i ekstremalnych proporcjach, poprawiający rozumowanie wizualne, rozpoznawanie dokumentów, zrozumienie szczegółów i wykonywanie instrukcji. Obsługuje kontekst 128k i do 16k tokenów wyjściowych.",
  "doubao-1.5-vision-pro-32k.description": "Doubao-1.5-vision-pro to ulepszony model multimodalny obsługujący obrazy w dowolnej rozdzielczości i ekstremalnych proporcjach, poprawiający rozumowanie wizualne, rozpoznawanie dokumentów, zrozumienie szczegółów i wykonywanie instrukcji.",
  "doubao-1.5-vision-pro.description": "Doubao-1.5-vision-pro to ulepszony model multimodalny obsługujący obrazy w dowolnej rozdzielczości i ekstremalnych proporcjach, poprawiający rozumowanie wizualne, rozpoznawanie dokumentów, zrozumienie szczegółów i wykonywanie instrukcji.",
  "doubao-lite-128k.description": "Ultraszybka odpowiedź i lepsza wartość, oferująca bardziej elastyczne opcje w różnych scenariuszach. Obsługuje rozumowanie i dostrajanie z kontekstem 128k.",
  "doubao-lite-32k.description": "Ultraszybka odpowiedź i lepsza wartość, oferująca bardziej elastyczne opcje w różnych scenariuszach. Obsługuje rozumowanie i dostrajanie z kontekstem 32k.",
  "doubao-lite-4k.description": "Ultraszybka odpowiedź i lepsza wartość, oferująca bardziej elastyczne opcje w różnych scenariuszach. Obsługuje rozumowanie i dostrajanie z kontekstem 4k.",
  "doubao-pro-256k.description": "Najlepszy flagowy model do złożonych zadań, z doskonałymi wynikami w QA z odniesieniami, streszczaniu, tworzeniu treści, klasyfikacji tekstu i odgrywaniu ról. Obsługuje rozumowanie i dostrajanie z kontekstem 256k.",
  "doubao-pro-32k.description": "Najlepszy flagowy model do złożonych zadań, z doskonałymi wynikami w QA z odniesieniami, streszczaniu, tworzeniu treści, klasyfikacji tekstu i odgrywaniu ról. Obsługuje rozumowanie i dostrajanie z kontekstem 32k.",
  "doubao-seed-1.6-flash.description": "Doubao-Seed-1.6-flash to ultraszybki multimodalny model głębokiego rozumowania z TPOT na poziomie 10 ms. Obsługuje tekst i obraz, przewyższa poprzedni model lite w rozumieniu tekstu i dorównuje konkurencyjnym modelom pro w wizji. Obsługuje kontekst 256k i do 16k tokenów wyjściowych.",
  "doubao-seed-1.6-lite.description": "Doubao-Seed-1.6-lite to nowy multimodalny model głębokiego rozumowania z regulowanym wysiłkiem rozumowania (Minimalny, Niski, Średni, Wysoki), oferujący lepszą wartość i silny wybór do typowych zadań, z kontekstem do 256k.",
  "doubao-seed-1.6-thinking.description": "Doubao-Seed-1.6 znacząco wzmacnia rozumowanie, dodatkowo poprawiając kluczowe umiejętności w kodowaniu, matematyce i logice względem Doubao-1.5-thinking-pro, dodając jednocześnie rozumienie wizji. Obsługuje kontekst 256k i do 16k tokenów wyjściowych.",
  "doubao-seed-1.6-vision.description": "Doubao-Seed-1.6-vision to model wizualnego głębokiego rozumowania, oferujący silniejsze multimodalne zrozumienie i rozumowanie dla edukacji, przeglądu obrazów, inspekcji/bezpieczeństwa i QA z wykorzystaniem AI. Obsługuje kontekst 256k i do 64k tokenów wyjściowych.",
  "doubao-seed-1.6.description": "Doubao-Seed-1.6 to nowy multimodalny model głębokiego rozumowania z trybami auto, thinking i non-thinking. W trybie non-thinking znacznie przewyższa Doubao-1.5-pro/250115. Obsługuje kontekst 256k i do 16k tokenów wyjściowych.",
  "doubao-seed-1.8.description": "Doubao-Seed-1.8 oferuje silniejsze możliwości multimodalnego rozumienia i działania agentów, obsługuje wejścia tekstowe/obrazowe/wideo oraz buforowanie kontekstu, zapewniając lepsze wyniki w złożonych zadaniach.",
  "doubao-seed-code.description": "Doubao-Seed-Code jest głęboko zoptymalizowany pod kątem kodowania agentowego, obsługuje wejścia multimodalne (tekst/obraz/wideo) i kontekst 256k, jest kompatybilny z API Anthropic i nadaje się do kodowania, rozumienia wizji i przepływów pracy agentów.",
  "doubao-seededit-3-0-i2i-250628.description": "Model obrazowy Doubao z ByteDance Seed obsługuje wejścia tekstowe i obrazowe z wysoką kontrolą i jakością generowania obrazów. Obsługuje edycję obrazów kierowaną tekstem, z rozmiarami wyjściowymi od 512 do 1536 po dłuższym boku.",
  "doubao-seedream-3-0-t2i-250415.description": "Seedream 3.0 to model generowania obrazów od ByteDance Seed, obsługujący wejścia tekstowe i obrazowe z wysoką kontrolą i jakością. Generuje obrazy na podstawie tekstowych promptów.",
  "doubao-seedream-4-0-250828.description": "Seedream 4.0 to model generowania obrazów od ByteDance Seed, obsługujący wejścia tekstowe i obrazowe z wysoką kontrolą i jakością. Generuje obrazy na podstawie tekstowych promptów.",
  "doubao-vision-lite-32k.description": "Doubao-vision to multimodalny model od Doubao z silnym rozumieniem obrazów i rozumowaniem oraz precyzyjnym wykonywaniem instrukcji. Dobrze radzi sobie z ekstrakcją tekstu z obrazów i zadaniami rozumowania obrazowego, umożliwiając bardziej złożone i szerokie scenariusze QA wizualnego.",
  "doubao-vision-pro-32k.description": "Doubao-vision to multimodalny model od Doubao z silnym rozumieniem obrazów i rozumowaniem oraz precyzyjnym wykonywaniem instrukcji. Dobrze radzi sobie z ekstrakcją tekstu z obrazów i zadaniami rozumowania obrazowego, umożliwiając bardziej złożone i szerokie scenariusze QA wizualnego.",
  "emohaa.description": "Emohaa to model zdrowia psychicznego z profesjonalnymi umiejętnościami doradczymi, pomagający użytkownikom zrozumieć problemy emocjonalne.",
  "meta.llama3-8b-instruct-v1:0.description": "Meta Llama 3 to otwarty model językowy (LLM) stworzony z myślą o programistach, naukowcach i przedsiębiorstwach, zaprojektowany, by wspierać ich w budowaniu, eksperymentowaniu i odpowiedzialnym skalowaniu pomysłów z zakresu generatywnej sztucznej inteligencji. Jako fundament globalnej innowacji społecznościowej, doskonale sprawdza się przy ograniczonych zasobach obliczeniowych, na urządzeniach brzegowych oraz przy szybszym czasie trenowania.",
  "meta/Llama-3.2-11B-Vision-Instruct.description": "Zaawansowane rozumowanie obrazów w wysokiej rozdzielczości, idealne do aplikacji zrozumienia wizualnego.",
  "meta/Llama-3.2-90B-Vision-Instruct.description": "Zaawansowane rozumowanie obrazów dla aplikacji agentów opartych na zrozumieniu wizualnym.",
  "meta/Llama-3.3-70B-Instruct.description": "Llama 3.3 to najbardziej zaawansowany wielojęzyczny otwartoźródłowy model Llama, oferujący wydajność zbliżoną do modeli 405B przy bardzo niskim koszcie. Opiera się na architekturze Transformer i został udoskonalony za pomocą SFT i RLHF, by zwiększyć jego użyteczność i bezpieczeństwo. Wersja dostrojona do instrukcji została zoptymalizowana pod kątem wielojęzycznych rozmów i przewyższa wiele otwartych i zamkniętych modeli konwersacyjnych w branżowych testach. Data odcięcia wiedzy: grudzień 2023.",
  "meta/Meta-Llama-3-70B-Instruct.description": "Potężny model z 70 miliardami parametrów, doskonały w rozumowaniu, programowaniu i szerokim zakresie zadań językowych.",
  "meta/Meta-Llama-3-8B-Instruct.description": "Wszechstronny model z 8 miliardami parametrów, zoptymalizowany do rozmów i generowania tekstu.",
  "meta/Meta-Llama-3.1-405B-Instruct.description": "Model tekstowy Llama 3.1 dostrojony do instrukcji, zoptymalizowany pod kątem wielojęzycznych rozmów, osiągający wysokie wyniki w branżowych testach porównawczych wśród modeli otwartych i zamkniętych.",
  "meta/Meta-Llama-3.1-70B-Instruct.description": "Model tekstowy Llama 3.1 dostrojony do instrukcji, zoptymalizowany pod kątem wielojęzycznych rozmów, osiągający wysokie wyniki w branżowych testach porównawczych wśród modeli otwartych i zamkniętych.",
  "meta/Meta-Llama-3.1-8B-Instruct.description": "Model tekstowy Llama 3.1 dostrojony do instrukcji, zoptymalizowany pod kątem wielojęzycznych rozmów, osiągający wysokie wyniki w branżowych testach porównawczych wśród modeli otwartych i zamkniętych.",
  "meta/llama-3-70b.description": "Otwarty model z 70 miliardami parametrów, dostrojony przez Meta do podążania za instrukcjami, udostępniany przez Groq na sprzęcie LPU dla szybkiego i wydajnego wnioskowania.",
  "meta/llama-3-8b.description": "Otwarty model z 8 miliardami parametrów, dostrojony przez Meta do podążania za instrukcjami, udostępniany przez Groq na sprzęcie LPU dla szybkiego i wydajnego wnioskowania.",
  "meta/llama-3.1-405b-instruct.description": "Zaawansowany model LLM wspierający generowanie danych syntetycznych, destylację wiedzy i rozumowanie w chatbotach, programowaniu i zadaniach dziedzinowych.",
  "meta/llama-3.1-70b-instruct.description": "Zaprojektowany do złożonych dialogów z doskonałym rozumieniem kontekstu, rozumowaniem i generowaniem tekstu.",
  "meta/llama-3.1-70b.description": "Zaktualizowany model Meta Llama 3 70B Instruct z kontekstem 128K, wsparciem wielojęzycznym i ulepszonym rozumowaniem.",
  "meta/llama-3.1-8b-instruct.description": "Nowoczesny model z silnym rozumieniem języka, rozumowaniem i generowaniem tekstu.",
  "meta/llama-3.1-8b.description": "Llama 3.1 8B obsługuje okno kontekstu 128K, idealne do rozmów w czasie rzeczywistym i analizy danych, oferując znaczne oszczędności kosztów w porównaniu do większych modeli. Udostępniany przez Groq na sprzęcie LPU dla szybkiego i wydajnego wnioskowania.",
  "meta/llama-3.2-11b-vision-instruct.description": "Nowatorski model językowo-wizualny, który wyróżnia się wysokiej jakości rozumowaniem na podstawie obrazów.",
  "meta/llama-3.2-11b.description": "Model dostrojony do instrukcji w zakresie rozumowania obrazów (wejście: tekst + obraz, wyjście: tekst), zoptymalizowany do rozpoznawania wizualnego, rozumowania obrazów, opisywania i ogólnego QA obrazów.",
  "meta/llama-3.2-1b-instruct.description": "Nowoczesny mały model językowy z silnym rozumieniem, rozumowaniem i generowaniem tekstu.",
  "meta/llama-3.2-1b.description": "Model tylko tekstowy do zastosowań na urządzeniach, takich jak lokalne wyszukiwanie wielojęzyczne, streszczanie i przepisywanie.",
  "meta/llama-3.2-3b-instruct.description": "Nowoczesny mały model językowy z silnym rozumieniem, rozumowaniem i generowaniem tekstu.",
  "meta/llama-3.2-3b.description": "Model tylko tekstowy dostrojony do zastosowań na urządzeniach, takich jak lokalne wyszukiwanie wielojęzyczne, streszczanie i przepisywanie.",
  "meta/llama-3.2-90b-vision-instruct.description": "Nowatorski model językowo-wizualny, który wyróżnia się wysokiej jakości rozumowaniem na podstawie obrazów.",
  "meta/llama-3.2-90b.description": "Model dostrojony do instrukcji w zakresie rozumowania obrazów (wejście: tekst + obraz, wyjście: tekst), zoptymalizowany do rozpoznawania wizualnego, rozumowania obrazów, opisywania i ogólnego QA obrazów.",
  "meta/llama-3.3-70b-instruct.description": "Zaawansowany model LLM, silny w rozumowaniu, matematyce, zdrowym rozsądku i wywoływaniu funkcji.",
  "meta/llama-3.3-70b.description": "Idealne połączenie wydajności i efektywności. Zbudowany z myślą o wysokowydajnej konwersacyjnej AI w tworzeniu treści, aplikacjach biznesowych i badaniach, z silnym rozumieniem języka do streszczania, klasyfikacji, analizy sentymentu i generowania kodu.",
  "meta/llama-4-maverick.description": "Rodzina Llama 4 to natywne modele multimodalne wspierające tekst i doświadczenia multimodalne, wykorzystujące MoE do wiodącego rozumienia tekstu i obrazu. Llama 4 Maverick to model 17B z 128 ekspertami, udostępniany przez DeepInfra.",
  "meta/llama-4-scout.description": "Rodzina Llama 4 to natywne modele multimodalne wspierające tekst i doświadczenia multimodalne, wykorzystujące MoE do wiodącego rozumienia tekstu i obrazu. Llama 4 Scout to model 17B z 16 ekspertami, udostępniany przez DeepInfra.",
  "mistralai/Mistral-7B-v0.1.description": "Mistral 7B to kompaktowy, ale wydajny model, doskonały do przetwarzania wsadowego i prostych zadań, takich jak klasyfikacja i generowanie tekstu, z solidnym rozumowaniem.",
  "mistralai/Mixtral-8x22B-Instruct-v0.1.description": "Mixtral-8x22B Instruct (141B) to bardzo duży model językowy przeznaczony do obsługi wymagających obciążeń.",
  "mistralai/Mixtral-8x7B-Instruct-v0.1.description": "Mixtral-8x7B Instruct (46,7B) oferuje wysoką wydajność w przetwarzaniu danych na dużą skalę.",
  "mistralai/Mixtral-8x7B-v0.1.description": "Mixtral 8x7B to rzadki model MoE, który przyspiesza wnioskowanie i nadaje się do zadań wielojęzycznych oraz generowania kodu.",
  "mistralai/mistral-nemo.description": "Mistral Nemo to model 7,3B z obsługą wielu języków i silną wydajnością w programowaniu.",
  "mixtral-8x7b-32768.description": "Mixtral 8x7B zapewnia odporną na błędy równoległą moc obliczeniową do złożonych zadań.",
  "mixtral.description": "Mixtral to model MoE od Mistral AI z otwartymi wagami, wspierający generowanie kodu i rozumienie języka.",
  "mixtral:8x22b.description": "Mixtral to model MoE od Mistral AI z otwartymi wagami, wspierający generowanie kodu i rozumienie języka.",
  "moonshot-v1-128k-vision-preview.description": "Modele wizji Kimi (w tym moonshot-v1-8k-vision-preview/moonshot-v1-32k-vision-preview/moonshot-v1-128k-vision-preview) potrafią rozumieć zawartość obrazów, taką jak tekst, kolory i kształty obiektów.",
  "moonshot-v1-128k.description": "Moonshot V1 128K oferuje bardzo długi kontekst do generowania długich tekstów, obsługując do 128 000 tokenów w scenariuszach badawczych, akademickich i dokumentacyjnych.",
  "moonshot-v1-32k-vision-preview.description": "Modele wizji Kimi (w tym moonshot-v1-8k-vision-preview/moonshot-v1-32k-vision-preview/moonshot-v1-128k-vision-preview) potrafią rozumieć zawartość obrazów, taką jak tekst, kolory i kształty obiektów.",
  "moonshot-v1-32k.description": "Moonshot V1 32K obsługuje 32 768 tokenów dla średniej długości kontekstu, idealny do długich dokumentów i złożonych dialogów w tworzeniu treści, raportach i systemach czatu.",
  "moonshot-v1-8k-vision-preview.description": "Modele wizji Kimi (w tym moonshot-v1-8k-vision-preview/moonshot-v1-32k-vision-preview/moonshot-v1-128k-vision-preview) potrafią rozumieć zawartość obrazów, taką jak tekst, kolory i kształty obiektów.",
  "moonshot-v1-8k.description": "Moonshot V1 8K jest zoptymalizowany do generowania krótkich tekstów z wydajną pracą, obsługując 8192 tokeny do krótkich rozmów, notatek i szybkich treści.",
  "moonshot-v1-auto.description": "Moonshot V1 Auto automatycznie wybiera odpowiedni model na podstawie bieżącego użycia tokenów kontekstu.",
  "moonshotai/Kimi-Dev-72B.description": "Kimi-Dev-72B to otwartoźródłowy model kodu LLM zoptymalizowany za pomocą RL na dużą skalę, generujący solidne, gotowe do produkcji poprawki. Osiąga wynik 60,4% w SWE-bench Verified, ustanawiając nowy rekord wśród otwartych modeli dla zadań inżynierii oprogramowania, takich jak naprawa błędów i przegląd kodu.",
  "moonshotai/Kimi-K2-Instruct-0905.description": "Kimi K2-Instruct-0905 to najnowszy i najpotężniejszy model Kimi K2. To model MoE najwyższej klasy z 1T łącznych i 32B aktywnych parametrów. Kluczowe cechy to silniejsza inteligencja agentowa w kodowaniu, znaczne postępy w testach i zadaniach agentowych, a także ulepszona estetyka i użyteczność kodu frontendowego.",
  "moonshotai/Kimi-K2-Thinking.description": "Kimi K2 Thinking to najnowszy i najpotężniejszy otwartoźródłowy model myślenia. Znacznie zwiększa głębokość rozumowania wieloetapowego i utrzymuje stabilne użycie narzędzi przez 200–300 kolejnych wywołań, ustanawiając nowe rekordy w Humanity's Last Exam (HLE), BrowseComp i innych testach. Doskonale sprawdza się w kodowaniu, matematyce, logice i scenariuszach agentowych. Zbudowany na architekturze MoE z ~1T parametrów, obsługuje okno kontekstu 256K i wywoływanie narzędzi.",
  "moonshotai/kimi-k2-0711.description": "Kimi K2 0711 to wariant instruct z serii Kimi, odpowiedni do wysokiej jakości kodu i użycia narzędzi.",
  "moonshotai/kimi-k2-0905.description": "Kimi K2 0905 to aktualizacja rozszerzająca kontekst i wydajność rozumowania z optymalizacjami kodu.",
  "moonshotai/kimi-k2-instruct-0905.description": "Model kimi-k2-0905-preview obsługuje okno kontekstu 256K, z silniejszym kodowaniem agentowym, bardziej dopracowanym i praktycznym kodem frontendowym oraz lepszym rozumieniem kontekstu.",
  "moonshotai/kimi-k2-thinking-turbo.description": "Kimi K2 Thinking Turbo to szybka wersja Kimi K2 Thinking, znacznie zmniejszająca opóźnienia przy zachowaniu głębokiego rozumowania.",
  "moonshotai/kimi-k2-thinking.description": "Kimi K2 Thinking to model rozumowania Moonshot zoptymalizowany do zadań wymagających głębokiego rozumowania, z ogólnymi możliwościami agentowymi.",
  "moonshotai/kimi-k2.description": "Kimi K2 to duży model MoE od Moonshot AI z 1T łącznych parametrów i 32B aktywnych na przebieg, zoptymalizowany pod kątem możliwości agentowych, w tym zaawansowanego użycia narzędzi, rozumowania i syntezy kodu.",
  "morph/morph-v3-fast.description": "Morph to wyspecjalizowany model do stosowania zmian w kodzie sugerowanych przez czołowe modele (np. Claude lub GPT-4o) w istniejących plikach z prędkością 4500+ tokenów/sek. To końcowy etap w przepływie pracy AI w kodowaniu i obsługuje 16k tokenów wejścia/wyjścia.",
  "morph/morph-v3-large.description": "Morph to wyspecjalizowany model do stosowania zmian w kodzie sugerowanych przez czołowe modele (np. Claude lub GPT-4o) w istniejących plikach z prędkością 2500+ tokenów/sek. To końcowy etap w przepływie pracy AI w kodowaniu i obsługuje 16k tokenów wejścia/wyjścia.",
  "nousresearch/hermes-2-pro-llama-3-8b.description": "Hermes 2 Pro Llama 3 8B to zaktualizowana wersja Nous Hermes 2 z najnowszymi wewnętrznie opracowanymi zbiorami danych.",
  "nvidia/Llama-3.1-Nemotron-70B-Instruct-HF.description": "Llama 3.1 Nemotron 70B to dostosowany przez NVIDIA model LLM poprawiający pomocność. Osiąga najwyższe wyniki w Arena Hard, AlpacaEval 2 LC i GPT-4-Turbo MT-Bench, zajmując 1. miejsce we wszystkich trzech testach auto-alignment na dzień 1 października 2024. Trening oparty na Llama-3.1-70B-Instruct z użyciem RLHF (REINFORCE), Llama-3.1-Nemotron-70B-Reward i HelpSteer2-Preference prompts.",
  "nvidia/llama-3.1-nemotron-51b-instruct.description": "Wyjątkowy model językowy zapewniający doskonałą dokładność i wydajność.",
  "nvidia/llama-3.1-nemotron-70b-instruct.description": "Llama-3.1-Nemotron-70B-Instruct to dostosowany model NVIDIA zaprojektowany w celu poprawy pomocności odpowiedzi LLM.",
  "pixtral-12b-2409.description": "Pixtral doskonale radzi sobie z analizą wykresów i obrazów, odpowiadaniem na pytania dotyczące dokumentów, rozumowaniem multimodalnym oraz wykonywaniem poleceń. Obsługuje obrazy w natywnej rozdzielczości i proporcjach oraz dowolną liczbę obrazów w kontekście do 128K.",
  "pixtral-large-latest.description": "Pixtral Large to otwarty model multimodalny z 124 miliardami parametrów, oparty na Mistral Large 2 – drugiej generacji naszej rodziny modeli multimodalnych, oferujący zaawansowane rozumienie obrazów.",
  "pro-128k.description": "Spark Pro 128K oferuje bardzo dużą pojemność kontekstu – do 128K, idealną do analizy długich dokumentów wymagających pełnej analizy tekstu i spójności logicznej, z płynnym rozumowaniem i wsparciem dla różnorodnych cytowań w złożonych dyskusjach.",
  "pro-deepseek-r1.description": "Dedykowany model usługowy dla przedsiębiorstw z wbudowaną obsługą współbieżności.",
  "pro-deepseek-v3.description": "Dedykowany model usługowy dla przedsiębiorstw z wbudowaną obsługą współbieżności.",
  "qianfan-70b.description": "Qianfan 70B to duży chiński model do generowania wysokiej jakości treści i złożonego rozumowania.",
  "qianfan-8b.description": "Qianfan 8B to średniej wielkości model ogólnego przeznaczenia, łączący niskie koszty z wysoką jakością generowania tekstu i odpowiadania na pytania.",
  "qianfan-agent-intent-32k.description": "Qianfan Agent Intent 32K koncentruje się na rozpoznawaniu intencji i orkiestracji agentów z obsługą długiego kontekstu.",
  "qianfan-agent-lite-8k.description": "Qianfan Agent Lite 8K to lekki model agenta do tanich dialogów wieloetapowych i przepływów pracy.",
  "qianfan-agent-speed-32k.description": "Qianfan Agent Speed 32K to model agenta o wysokiej przepustowości, przeznaczony do aplikacji wielozadaniowych na dużą skalę.",
  "qianfan-agent-speed-8k.description": "Qianfan Agent Speed 8K to model agenta o wysokiej współbieżności, przeznaczony do krótkich i średnich rozmów z szybką odpowiedzią.",
  "qianfan-check-vl.description": "Qianfan Check VL to multimodalny model do przeglądu treści, oceniający zgodność obrazów i tekstów oraz wykonujący zadania rozpoznawania.",
  "qianfan-composition.description": "Qianfan Composition to multimodalny model twórczy do zrozumienia i generowania treści łączących obrazy i tekst.",
  "qianfan-engcard-vl.description": "Qianfan EngCard VL to multimodalny model rozpoznawania skoncentrowany na scenariuszach w języku angielskim.",
  "qianfan-lightning-128b-a19b.description": "Qianfan Lightning 128B A19B to wysokowydajny chiński model ogólnego przeznaczenia do złożonego odpowiadania na pytania i rozumowania na dużą skalę.",
  "qianfan-llama-vl-8b.description": "Qianfan Llama VL 8B to multimodalny model oparty na Llama, przeznaczony do ogólnego zrozumienia obrazów i tekstu.",
  "qianfan-multipicocr.description": "Qianfan MultiPicOCR to model OCR do wielu obrazów, wykrywający i rozpoznający tekst na różnych obrazach.",
  "qianfan-qi-vl.description": "Qianfan QI VL to multimodalny model QA do precyzyjnego wyszukiwania i odpowiadania na pytania w złożonych scenariuszach obraz-tekst.",
  "qianfan-singlepicocr.description": "Qianfan SinglePicOCR to model OCR do pojedynczych obrazów z wysoką dokładnością rozpoznawania znaków.",
  "qianfan-vl-70b.description": "Qianfan VL 70B to duży model językowo-wizualny do złożonego zrozumienia obrazów i tekstu.",
  "qianfan-vl-8b.description": "Qianfan VL 8B to lekki model językowo-wizualny do codziennego QA obraz-tekst i analizy.",
  "qvq-72b-preview.description": "QVQ-72B-Preview to eksperymentalny model badawczy od Qwen, skoncentrowany na ulepszonym rozumowaniu wizualnym.",
  "qvq-max.description": "Model rozumowania wizualnego Qwen QVQ obsługuje wejścia wizualne i wyjścia w formie łańcucha myśli, oferując lepsze wyniki w matematyce, kodowaniu, analizie wizualnej, twórczości i zadaniach ogólnych.",
  "qvq-plus.description": "Model rozumowania wizualnego z wejściem wizualnym i wyjściem w formie łańcucha myśli. Seria qvq-plus kontynuuje qvq-max, oferując szybsze rozumowanie przy lepszym stosunku jakości do kosztu.",
  "qwen-3-32b.description": "Qwen 3 32B: silny w zadaniach wielojęzycznych i programistycznych, odpowiedni do średnioskalowej produkcji.",
  "qwen-coder-plus.description": "Model kodowania Qwen.",
  "qwen-coder-turbo-latest.description": "Model kodowania Qwen.",
  "qwen-coder-turbo.description": "Model kodowania Qwen.",
  "qwen-flash.description": "Najszybszy i najtańszy model Qwen, idealny do prostych zadań.",
  "qwen-image-edit.description": "Qwen Image Edit to model obraz-do-obrazu, który edytuje obrazy na podstawie wejściowych obrazów i tekstowych poleceń, umożliwiając precyzyjne korekty i twórcze przekształcenia.",
  "qwen-image.description": "Qwen-Image to ogólny model generowania obrazów, obsługujący wiele stylów artystycznych i zaawansowane renderowanie złożonego tekstu, szczególnie w języku chińskim i angielskim. Obsługuje układy wieloliniowe, tekst na poziomie akapitu i drobne szczegóły w złożonych układach tekst-obraz.",
  "qwen-long.description": "Ultraduży model Qwen z długim kontekstem i możliwością prowadzenia rozmów obejmujących wiele dokumentów.",
  "qwen-math-plus-latest.description": "Qwen Math to model językowy wyspecjalizowany w rozwiązywaniu problemów matematycznych.",
  "qwen-math-plus.description": "Qwen Math to model językowy wyspecjalizowany w rozwiązywaniu problemów matematycznych.",
  "qwen-math-turbo-latest.description": "Qwen Math to model językowy wyspecjalizowany w rozwiązywaniu problemów matematycznych.",
  "qwen-math-turbo.description": "Qwen Math to model językowy wyspecjalizowany w rozwiązywaniu problemów matematycznych.",
  "qwen-max.description": "Model Qwen w skali setek miliardów parametrów, obsługujący język chiński, angielski i inne; model API wykorzystywany w produktach Qwen2.5.",
  "qwen-omni-turbo.description": "Modele Qwen-Omni obsługują wejścia multimodalne (wideo, audio, obrazy, tekst) i generują wyjścia w formie dźwięku i tekstu.",
  "qwen-plus.description": "Ulepszony ultraduży model Qwen obsługujący język chiński, angielski i inne języki.",
  "qwen-turbo.description": "Qwen Turbo nie będzie już aktualizowany; zalecana jest migracja do Qwen Flash. Ultraduży model Qwen obsługujący język chiński, angielski i inne języki.",
  "qwen-vl-chat-v1.description": "Qwen VL obsługuje elastyczne interakcje, w tym wejścia z wielu obrazów, wieloetapowe QA i zadania twórcze.",
  "qwen-vl-max-latest.description": "Ultraduży model językowo-wizualny Qwen. W porównaniu do wersji ulepszonej oferuje lepsze rozumowanie wizualne i wykonywanie poleceń, zapewniając silniejsze postrzeganie i poznanie.",
  "qwen-vl-max.description": "Ultraduży model językowo-wizualny Qwen. W porównaniu do wersji ulepszonej oferuje lepsze rozumowanie wizualne i wykonywanie poleceń, zapewniając silniejsze postrzeganie wizualne i poznanie.",
  "qwen-vl-ocr.description": "Qwen OCR to model ekstrakcji tekstu z dokumentów, tabel, obrazów egzaminacyjnych i rękopisów. Obsługuje język chiński, angielski, francuski, japoński, koreański, niemiecki, rosyjski, włoski, wietnamski i arabski.",
  "qwen-vl-plus-latest.description": "Ulepszony model językowo-wizualny Qwen na dużą skalę z dużym postępem w rozpoznawaniu szczegółów i tekstu, obsługujący rozdzielczość powyżej jednego megapiksela i dowolne proporcje obrazu.",
  "qwen-vl-plus.description": "Ulepszony model językowo-wizualny Qwen na dużą skalę z dużym postępem w rozpoznawaniu szczegółów i tekstu, obsługujący rozdzielczość powyżej jednego megapiksela i dowolne proporcje obrazu.",
  "qwen-vl-v1.description": "Model wstępnie wytrenowany na bazie Qwen-7B z dodanym modułem wizualnym i wejściem obrazu o rozdzielczości 448.",
  "qwen/qwen-2-7b-instruct.description": "Qwen2 to nowa seria dużych modeli językowych Qwen. Qwen2 7B to model oparty na transformatorze, który wyróżnia się w rozumieniu języka, wielojęzyczności, programowaniu, matematyce i rozumowaniu.",
  "qwen/qwen-2-7b-instruct:free.description": "Qwen2 to nowa rodzina dużych modeli językowych o lepszym rozumieniu i generowaniu treści.",
  "qwen2.5-7b-instruct.description": "Qwen2.5 7B Instruct to dojrzały, otwartoźródłowy model instrukcyjny do rozmów i generowania treści w różnych scenariuszach.",
  "qwen2.5-coder-1.5b-instruct.description": "Otwartoźródłowy model kodujący Qwen.",
  "qwen2.5-coder-14b-instruct.description": "Otwartoźródłowy model kodujący Qwen.",
  "qwen2.5-coder-32b-instruct.description": "Otwartoźródłowy model kodujący Qwen.",
  "qwen2.5-coder-7b-instruct.description": "Otwartoźródłowy model kodujący Qwen.",
  "qwen2.5-coder-instruct.description": "Qwen2.5-Coder to najnowszy model LLM z rodziny Qwen skoncentrowany na kodzie (wcześniej CodeQwen).",
  "qwen2.5-instruct.description": "Qwen2.5 to najnowsza seria modeli językowych Qwen, obejmująca modele bazowe i dostrojone instrukcyjnie od 0.5B do 72B parametrów.",
  "qwen2.5-math-1.5b-instruct.description": "Qwen-Math zapewnia wysoką skuteczność w rozwiązywaniu zadań matematycznych.",
  "qwen2.5-math-72b-instruct.description": "Qwen-Math zapewnia wysoką skuteczność w rozwiązywaniu zadań matematycznych.",
  "qwen2.5-math-7b-instruct.description": "Qwen-Math zapewnia wysoką skuteczność w rozwiązywaniu zadań matematycznych.",
  "qwen2.5-omni-7b.description": "Modele Qwen-Omni obsługują wejścia multimodalne (wideo, audio, obrazy, tekst) i generują wyjścia w formie dźwięku lub tekstu.",
  "qwen2.5-vl-32b-instruct.description": "Qwen2.5 VL 32B Instruct to otwartoźródłowy model multimodalny odpowiedni do prywatnego wdrożenia i zastosowań w różnych scenariuszach.",
  "qwen2.5-vl-72b-instruct.description": "Ulepszone podążanie za instrukcjami, matematyka, rozwiązywanie problemów i kodowanie, z lepszym rozpoznawaniem obiektów. Obsługuje precyzyjną lokalizację elementów wizualnych w różnych formatach, rozumienie długich filmów (do 10 minut) z dokładnością do sekundy, porządkowanie czasowe i rozumienie prędkości, a także agentów sterujących systemem operacyjnym lub urządzeniami mobilnymi poprzez analizę i lokalizację. Silne wydobywanie kluczowych informacji i generowanie danych w formacie JSON. To wersja 72B – najmocniejsza w serii.",
  "qwen2.5-vl-7b-instruct.description": "Qwen2.5 VL 7B Instruct to lekki model multimodalny łączący niskie koszty wdrożenia z dobrą zdolnością rozpoznawania.",
  "qwen2.5-vl-instruct.description": "Qwen2.5-VL to najnowszy model językowo-wizualny z rodziny Qwen.",
  "qwen2.5.description": "Qwen2.5 to nowej generacji duży model językowy Alibaba o wysokiej wydajności w różnych zastosowaniach.",
  "qwen2.5:0.5b.description": "Qwen2.5 to nowej generacji duży model językowy Alibaba o wysokiej wydajności w różnych zastosowaniach.",
  "qwen2.5:1.5b.description": "Qwen2.5 to nowej generacji duży model językowy Alibaba o wysokiej wydajności w różnych zastosowaniach.",
  "qwen2.5:72b.description": "Qwen2.5 to nowej generacji duży model językowy Alibaba o wysokiej wydajności w różnych zastosowaniach.",
  "qwen2.description": "Qwen2 to nowej generacji duży model językowy Alibaba o wysokiej wydajności w różnych zastosowaniach.",
  "qwen2:0.5b.description": "Qwen2 to nowej generacji duży model językowy Alibaba o wysokiej wydajności w różnych zastosowaniach.",
  "qwen2:1.5b.description": "Qwen2 to nowej generacji duży model językowy Alibaba o wysokiej wydajności w różnych zastosowaniach.",
  "qwen2:72b.description": "Qwen2 to nowej generacji duży model językowy Alibaba o wysokiej wydajności w różnych zastosowaniach.",
  "qwen3-0.6b.description": "Qwen3 0.6B to model podstawowy do prostego rozumowania i bardzo ograniczonych środowisk.",
  "qwen3-1.7b.description": "Qwen3 1.7B to ultralekki model do wdrożeń na urządzeniach brzegowych.",
  "qwen3-14b.description": "Qwen3 14B to średniej wielkości model do wielojęzycznego QA i generowania tekstu.",
  "qwen3-235b-a22b-instruct-2507.description": "Qwen3 235B A22B Instruct 2507 to flagowy model instrukcyjny do szerokiego zakresu zadań generacyjnych i rozumowania.",
  "qwen3-235b-a22b-thinking-2507.description": "Qwen3 235B A22B Thinking 2507 to ultraduży model myślący do trudnych zadań wymagających rozumowania.",
  "qwen3-235b-a22b.description": "Qwen3 235B A22B to ogólny duży model do złożonych zadań.",
  "qwen3-30b-a3b-instruct-2507.description": "Qwen3 30B A3B Instruct 2507 to średnio-duży model instrukcyjny do wysokiej jakości generowania i QA.",
  "qwen3-30b-a3b-thinking-2507.description": "Qwen3 30B A3B Thinking 2507 to średnio-duży model myślący, łączący dokładność i efektywność kosztową.",
  "qwen3-30b-a3b.description": "Qwen3 30B A3B to średnio-duży model ogólny, równoważący koszty i jakość.",
  "qwen3-32b.description": "Qwen3 32B nadaje się do ogólnych zadań wymagających lepszego rozumienia.",
  "qwen3-4b.description": "Qwen3 4B nadaje się do małych i średnich aplikacji oraz lokalnego wnioskowania.",
  "qwen3-8b.description": "Qwen3 8B to lekki model z elastycznym wdrożeniem do obciążeń o wysokiej równoczesności.",
  "qwen3-coder-30b-a3b-instruct.description": "Otwartoźródłowy model kodujący Qwen. Najnowszy qwen3-coder-30b-a3b-instruct oparty jest na Qwen3 i oferuje zaawansowane możliwości agenta kodującego, korzystania z narzędzi i interakcji ze środowiskiem do autonomicznego programowania, z doskonałą wydajnością kodu i solidnymi zdolnościami ogólnymi.",
  "qwen3-coder-480b-a35b-instruct.description": "Qwen3 Coder 480B A35B Instruct to flagowy model kodujący do programowania wielojęzycznego i złożonego rozumienia kodu.",
  "qwen3-coder-flash.description": "Model kodujący Qwen. Najnowsza seria Qwen3-Coder oparta jest na Qwen3 i oferuje zaawansowane możliwości agenta kodującego, korzystania z narzędzi i interakcji ze środowiskiem do autonomicznego programowania, z doskonałą wydajnością kodu i solidnymi zdolnościami ogólnymi.",
  "qwen3-coder-plus.description": "Model kodujący Qwen. Najnowsza seria Qwen3-Coder oparta jest na Qwen3 i oferuje zaawansowane możliwości agenta kodującego, korzystania z narzędzi i interakcji ze środowiskiem do autonomicznego programowania, z doskonałą wydajnością kodu i solidnymi zdolnościami ogólnymi.",
  "qwen3-coder:480b.description": "Wysokowydajny model Alibaba do zadań agenta i kodowania z długim kontekstem.",
  "qwen3-max-preview.description": "Najlepszy model Qwen do złożonych, wieloetapowych zadań. Wersja podglądowa obsługuje myślenie.",
  "qwen3-max.description": "Modele Qwen3 Max oferują znaczne ulepszenia względem serii 2.5 w zakresie ogólnych zdolności, rozumienia chińskiego/angielskiego, złożonych instrukcji, zadań otwartych, wielojęzyczności i korzystania z narzędzi, z mniejszą liczbą halucynacji. Najnowszy qwen3-max poprawia programowanie agentowe i korzystanie z narzędzi względem qwen3-max-preview. Wersja ta osiąga SOTA w swojej klasie i jest przeznaczona do bardziej złożonych potrzeb agentów.",
  "qwen3-next-80b-a3b-instruct.description": "Nowej generacji otwartoźródłowy model Qwen3 bez myślenia. W porównaniu do poprzedniej wersji (Qwen3-235B-A22B-Instruct-2507) oferuje lepsze rozumienie chińskiego, silniejsze rozumowanie logiczne i ulepszone generowanie tekstu.",
  "qwen3-next-80b-a3b-thinking.description": "Qwen3 Next 80B A3B Thinking to flagowa wersja modelu rozumującego do złożonych zadań.",
  "qwen3-omni-flash.description": "Qwen-Omni przyjmuje połączone dane wejściowe z tekstu, obrazów, dźwięku i wideo, a generuje tekst lub mowę. Oferuje wiele naturalnych stylów głosu, obsługuje mowę wielojęzyczną i dialektyczną, i nadaje się do zastosowań takich jak pisanie, rozpoznawanie wizji i asystenci głosowi.",
  "qwen3-vl-235b-a22b-instruct.description": "Qwen3 VL 235B A22B Instruct to flagowy model multimodalny do wymagających zadań rozumienia i tworzenia treści.",
  "qwen3-vl-235b-a22b-thinking.description": "Qwen3 VL 235B A22B Thinking to flagowa wersja myśląca do złożonego multimodalnego rozumowania i planowania.",
  "qwen3-vl-30b-a3b-instruct.description": "Qwen3 VL 30B A3B Instruct to duży model multimodalny równoważący dokładność i wydajność rozumowania.",
  "qwen3-vl-30b-a3b-thinking.description": "Qwen3 VL 30B A3B Thinking to wersja głęboko rozumująca do złożonych zadań multimodalnych.",
  "qwen3-vl-32b-instruct.description": "Qwen3 VL 32B Instruct to multimodalny model dostrojony instrukcyjnie do wysokiej jakości QA obraz-tekst i tworzenia treści.",
  "qwen3-vl-32b-thinking.description": "Qwen3 VL 32B Thinking to głęboko rozumująca wersja multimodalna do złożonego rozumowania i analizy łańcuchowej.",
  "qwen3-vl-8b-instruct.description": "Qwen3 VL 8B Instruct to lekki model multimodalny do codziennego QA wizualnego i integracji z aplikacjami.",
  "qwen3-vl-8b-thinking.description": "Qwen3 VL 8B Thinking to multimodalny model łańcucha myśli do szczegółowego rozumowania wizualnego.",
  "qwen3-vl-flash.description": "Qwen3 VL Flash: lekka, szybka wersja rozumująca do zadań wrażliwych na opóźnienia lub o dużym wolumenie.",
  "qwen3-vl-plus.description": "Qwen VL to model generowania tekstu z rozumieniem wizji. Potrafi wykonywać OCR, podsumowywać i rozumować, np. wyodrębniać atrybuty ze zdjęć produktów lub rozwiązywać problemy na podstawie obrazów.",
  "qwen3.description": "Qwen3 to nowej generacji duży model językowy Alibaba o wysokiej wydajności w różnych zastosowaniach.",
  "taichu_o1.description": "taichu_o1 to nowej generacji model rozumowania, który wykorzystuje interakcję multimodalną i uczenie przez wzmacnianie do osiągnięcia ludzkiego łańcucha myślowego. Obsługuje symulację złożonych decyzji, ujawnia ścieżki rozumowania przy zachowaniu wysokiej dokładności wyników, idealny do analizy strategicznej i głębokiego myślenia.",
  "taichu_vl.description": "Łączy rozumienie obrazu, transfer wiedzy i logiczną atrybucję, wyróżniając się w zadaniach pytanie-odpowiedź obraz-tekst.",
  "tencent/Hunyuan-A13B-Instruct.description": "Hunyuan-A13B-Instruct wykorzystuje 80 miliardów parametrów całkowitych, z czego 13 miliardów aktywnych, aby dorównać większym modelom. Obsługuje hybrydowe rozumowanie szybkie/wolne, stabilne rozumienie długich tekstów i wiodące możliwości agenta w BFCL-v3 i τ-Bench. GQA i formaty wielokrotnej kwantyzacji umożliwiają wydajne wnioskowanie.",
  "tencent/Hunyuan-MT-7B.description": "Model tłumaczeniowy Hunyuan obejmuje Hunyuan-MT-7B oraz zespół Hunyuan-MT-Chimera. Hunyuan-MT-7B to lekki model tłumaczeniowy o 7 miliardach parametrów, obsługujący 33 języki oraz 5 języków mniejszości chińskich. W WMT25 zdobył 30 pierwszych miejsc w 31 parach językowych. Tencent Hunyuan wykorzystuje pełny cykl treningowy od pretreningu przez SFT po RL tłumaczeniowe i zespołowe, osiągając wiodącą wydajność przy łatwym wdrożeniu.",
  "text-embedding-3-large.description": "Najbardziej zaawansowany model osadzania tekstu dla zadań w języku angielskim i innych.",
  "text-embedding-3-small.description": "Wydajny, opłacalny model osadzania nowej generacji do wyszukiwania i scenariuszy RAG.",
  "thudm/glm-4-32b.description": "GLM-4-32B-0414 to 32-miliardowy model dwujęzyczny (chiński/angielski) z otwartymi wagami, zoptymalizowany do generowania kodu, wywoływania funkcji i zadań agenta. Trenowany na 15T wysokiej jakości danych z naciskiem na rozumowanie, udoskonalony przez dopasowanie do preferencji użytkownika, próbkowanie odrzuceń i RL. Wyróżnia się w złożonym rozumowaniu, generowaniu artefaktów i strukturze wyjściowej, osiągając poziom GPT-4o i DeepSeek-V3-0324 w wielu benchmarkach.",
  "thudm/glm-4-32b:free.description": "GLM-4-32B-0414 to 32-miliardowy model dwujęzyczny (chiński/angielski) z otwartymi wagami, zoptymalizowany do generowania kodu, wywoływania funkcji i zadań agenta. Trenowany na 15T wysokiej jakości danych z naciskiem na rozumowanie, udoskonalony przez dopasowanie do preferencji użytkownika, próbkowanie odrzuceń i RL. Wyróżnia się w złożonym rozumowaniu, generowaniu artefaktów i strukturze wyjściowej, osiągając poziom GPT-4o i DeepSeek-V3-0324 w wielu benchmarkach.",
  "thudm/glm-4-9b-chat.description": "Wersja open-source najnowszego modelu pretreningowego GLM-4 od Zhipu AI.",
  "thudm/glm-z1-32b.description": "GLM-Z1-32B-0414 to ulepszona wersja rozumowania modelu GLM-4-32B, stworzona do głębokiego rozwiązywania problemów matematycznych, logicznych i kodowych. Wykorzystuje rozszerzone RL (specyficzne dla zadań i ogólne preferencje parowe), aby poprawić złożone zadania wieloetapowe. W porównaniu do GLM-4-32B, Z1 znacząco poprawia rozumowanie strukturalne i zdolności w formalnych dziedzinach.\n\nObsługuje wymuszanie kroków „myślenia” przez inżynierię promptów, poprawioną spójność długich odpowiedzi i jest zoptymalizowany do przepływów pracy agentów z długim kontekstem (przez YaRN), wywoływaniem narzędzi JSON i precyzyjnym próbkowaniem dla stabilnego rozumowania. Idealny do przypadków wymagających starannego rozumowania wieloetapowego lub formalnych wyprowadzeń.",
  "thudm/glm-z1-rumination-32b.description": "GLM Z1 Rumination 32B to 32-miliardowy model głębokiego rozumowania z serii GLM-4-Z1, zoptymalizowany do złożonych, otwartych zadań wymagających długiego myślenia. Bazując na glm-4-32b-0414, dodaje dodatkowe etapy RL i wieloetapowe dopasowanie, wprowadzając zdolność „rozmyślania”, która symuluje rozszerzone przetwarzanie poznawcze. Obejmuje to iteracyjne rozumowanie, analizę wieloetapową i przepływy pracy wspomagane narzędziami, takie jak wyszukiwanie, pobieranie i synteza z uwzględnieniem cytowań.\n\nWyróżnia się w pisaniu naukowym, analizie porównawczej i złożonych pytaniach. Obsługuje wywoływanie funkcji dla prymitywów wyszukiwania/nawigacji (`search`, `click`, `open`, `finish`) w pipeline'ach agentów. Zachowanie rozmyślania jest kontrolowane przez pętle wieloetapowe z kształtowaniem nagród opartym na regułach i opóźnionymi decyzjami, testowane w porównaniu do głębokich frameworków badawczych, takich jak wewnętrzny stos dopasowania OpenAI. Ta wersja stawia na głębię zamiast szybkości.",
  "tngtech/deepseek-r1t-chimera:free.description": "DeepSeek-R1T-Chimera powstał przez połączenie DeepSeek-R1 i DeepSeek-V3 (0324), łącząc rozumowanie R1 z efektywnością tokenów V3. Bazuje na transformatorze DeepSeek-MoE i jest zoptymalizowany do ogólnej generacji tekstu.\n\nŁączy wagi pretrenowane, aby zrównoważyć rozumowanie, wydajność i podążanie za instrukcjami. Wydany na licencji MIT do użytku badawczego i komercyjnego.",
  "togethercomputer/StripedHyena-Nous-7B.description": "StripedHyena Nous (7B) zapewnia zwiększoną wydajność obliczeniową dzięki swojej architekturze i strategii.",
  "tts-1-hd.description": "Najnowszy model tekst-na-mowę zoptymalizowany pod kątem jakości.",
  "tts-1.description": "Najnowszy model tekst-na-mowę zoptymalizowany pod kątem szybkości działania w czasie rzeczywistym.",
  "upstage/SOLAR-10.7B-Instruct-v1.0.description": "Upstage SOLAR Instruct v1 (11B) jest dostrojony do precyzyjnych zadań instrukcyjnych z silną wydajnością językową.",
  "us.anthropic.claude-3-5-sonnet-20241022-v2:0.description": "Claude 3.5 Sonnet podnosi standard branżowy, przewyższając konkurencję i Claude 3 Opus w szerokich ocenach, zachowując jednocześnie średni poziom szybkości i kosztów.",
  "us.anthropic.claude-3-7-sonnet-20250219-v1:0.description": "Claude 3.7 Sonnet to najszybszy model nowej generacji od Anthropic. W porównaniu do Claude 3 Haiku poprawia się we wszystkich umiejętnościach i przewyższa poprzedni flagowy model Claude 3 Opus w wielu benchmarkach inteligencji.",
  "us.anthropic.claude-haiku-4-5-20251001-v1:0.description": "Claude Haiku 4.5 to najszybszy i najbardziej inteligentny model Haiku od Anthropic, oferujący błyskawiczną szybkość i rozszerzone myślenie.",
  "us.anthropic.claude-sonnet-4-5-20250929-v1:0.description": "Claude Sonnet 4.5 to najbardziej inteligentny model Anthropic do tej pory.",
  "v0-1.0-md.description": "v0-1.0-md to model starszej generacji udostępniany przez API v0.",
  "v0-1.5-lg.description": "v0-1.5-lg jest odpowiedni do zaawansowanych zadań myślowych i rozumowania.",
  "v0-1.5-md.description": "v0-1.5-md jest odpowiedni do codziennych zadań i generowania interfejsów użytkownika.",
  "vercel/v0-1.0-md.description": "Uzyskaj dostęp do modeli stojących za v0, aby generować, naprawiać i optymalizować nowoczesne aplikacje webowe z rozumowaniem specyficznym dla frameworków i aktualną wiedzą.",
  "vercel/v0-1.5-md.description": "Uzyskaj dostęp do modeli stojących za v0, aby generować, naprawiać i optymalizować nowoczesne aplikacje webowe z rozumowaniem specyficznym dla frameworków i aktualną wiedzą.",
  "volcengine/doubao-seed-code.description": "Doubao-Seed-Code to model LLM od ByteDance Volcano Engine zoptymalizowany do programowania agentowego, osiągający wysokie wyniki w benchmarkach programistycznych i agentowych z obsługą kontekstu 256K.",
  "wan2.2-t2i-flash.description": "Wanxiang 2.2 Speed to najnowszy model z ulepszeniami w zakresie kreatywności, stabilności i realizmu, oferujący szybkie generowanie i wysoką wartość.",
  "wan2.2-t2i-plus.description": "Wanxiang 2.2 Pro to najnowszy model z ulepszeniami w zakresie kreatywności, stabilności i realizmu, generujący bogatsze detale.",
  "wanx-v1.description": "Bazowy model tekst-na-obraz. Odpowiada Tongyi Wanxiang 1.0 General.",
  "wanx2.0-t2i-turbo.description": "Wyróżnia się w portretach z teksturą przy umiarkowanej szybkości i niższym koszcie. Odpowiada Tongyi Wanxiang 2.0 Speed.",
  "wanx2.1-t2i-plus.description": "W pełni zaktualizowana wersja z bogatszymi detalami obrazu i nieco wolniejszą szybkością. Odpowiada Tongyi Wanxiang 2.1 Pro.",
  "wanx2.1-t2i-turbo.description": "W pełni zaktualizowana wersja z szybkim generowaniem, wysoką jakością ogólną i dużą wartością. Odpowiada Tongyi Wanxiang 2.1 Speed.",
  "whisper-1.description": "Ogólny model rozpoznawania mowy obsługujący wielojęzyczne ASR, tłumaczenie mowy i identyfikację języka.",
  "wizardlm2.description": "WizardLM 2 to model językowy od Microsoft AI, który wyróżnia się w złożonych dialogach, zadaniach wielojęzycznych, rozumowaniu i asystentach.",
  "wizardlm2:8x22b.description": "WizardLM 2 to model językowy od Microsoft AI, który wyróżnia się w złożonych dialogach, zadaniach wielojęzycznych, rozumowaniu i asystentach.",
  "z-ai/glm-4.5-air.description": "GLM 4.5 Air to lekka wersja GLM 4.5 przeznaczona do scenariuszy wrażliwych na koszty, zachowująca jednocześnie wysoką jakość rozumowania.",
  "z-ai/glm-4.5.description": "GLM 4.5 to flagowy model Z.AI z hybrydowym rozumowaniem, zoptymalizowany do zadań inżynieryjnych i pracy z długim kontekstem.",
  "z-ai/glm-4.6.description": "GLM 4.6 to flagowy model Z.AI z rozszerzoną długością kontekstu i zaawansowanymi możliwościami kodowania.",
  "zai-glm-4.6.description": "Osiąga wysokie wyniki w zadaniach związanych z kodowaniem i rozumowaniem, obsługuje strumieniowanie i wywołania narzędzi, idealnie nadaje się do kodowania agentowego i złożonego rozumowania.",
  "zai-org/GLM-4.5-Air.description": "GLM-4.5-Air to bazowy model dla aplikacji agentowych, oparty na architekturze Mixture-of-Experts. Zoptymalizowany do korzystania z narzędzi, przeglądania internetu, inżynierii oprogramowania i kodowania frontendowego. Integruje się z agentami kodu, takimi jak Claude Code i Roo Code. Wykorzystuje hybrydowe rozumowanie do obsługi zarówno złożonych, jak i codziennych scenariuszy.",
  "zai-org/GLM-4.5.description": "GLM-4.5 to bazowy model stworzony dla aplikacji agentowych, oparty na architekturze Mixture-of-Experts. Głęboko zoptymalizowany do korzystania z narzędzi, przeglądania internetu, inżynierii oprogramowania i kodowania frontendowego. Integruje się z agentami kodu, takimi jak Claude Code i Roo Code. Wykorzystuje hybrydowe rozumowanie do obsługi zarówno złożonych, jak i codziennych scenariuszy.",
  "zai-org/GLM-4.5V.description": "GLM-4.5V to najnowszy VLM Zhipu AI, oparty na flagowym modelu tekstowym GLM-4.5-Air (106B parametrów ogółem, 12B aktywnych) z architekturą MoE zapewniającą wysoką wydajność przy niższych kosztach. Podąża ścieżką GLM-4.1V-Thinking i dodaje 3D-RoPE dla lepszego rozumienia przestrzeni 3D. Zoptymalizowany poprzez pretrening, SFT i RL, obsługuje obrazy, wideo i długie dokumenty, zajmując czołowe miejsca wśród otwartych modeli w 41 publicznych benchmarkach multimodalnych. Przełącznik trybu Thinking pozwala użytkownikom balansować między szybkością a głębokością analizy.",
  "zai-org/GLM-4.6.description": "W porównaniu do GLM-4.5, GLM-4.6 rozszerza kontekst z 128K do 200K, umożliwiając realizację bardziej złożonych zadań agentowych. Osiąga lepsze wyniki w benchmarkach kodu i wykazuje wyższą skuteczność w aplikacjach takich jak Claude Code, Cline, Roo Code i Kilo Code, w tym lepsze generowanie stron frontendowych. Ulepszono rozumowanie oraz obsługę narzędzi w trakcie rozumowania, co wzmacnia ogólne możliwości. Lepsza integracja z frameworkami agentowymi, usprawnione działanie agentów narzędziowych i wyszukiwawczych oraz bardziej naturalny styl pisania i odgrywania ról preferowany przez użytkowników.",
  "zai/glm-4.5-air.description": "GLM-4.5 i GLM-4.5-Air to nasze najnowsze flagowe modele dla aplikacji agentowych, oba oparte na architekturze MoE. GLM-4.5 ma 355B parametrów ogółem i 32B aktywnych na jedno przejście; GLM-4.5-Air jest lżejszy – 106B ogółem i 12B aktywnych.",
  "zai/glm-4.5.description": "Seria GLM-4.5 została zaprojektowana z myślą o agentach. Flagowy model GLM-4.5 łączy rozumowanie, kodowanie i umiejętności agentowe, posiada 355B parametrów ogółem (32B aktywnych) i oferuje dwa tryby działania jako system hybrydowego rozumowania.",
  "zai/glm-4.5v.description": "GLM-4.5V bazuje na GLM-4.5-Air, dziedzicząc sprawdzone techniki GLM-4.1V-Thinking i skalując się dzięki silnej architekturze MoE z 106 miliardami parametrów.",
  "zenmux/auto.description": "Automatyczne trasowanie ZenMux wybiera najlepiej wyceniony i najbardziej wydajny model spośród obsługiwanych opcji na podstawie Twojego zapytania."
}
