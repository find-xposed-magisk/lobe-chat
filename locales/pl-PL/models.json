{
  "01-ai/yi-1.5-34b-chat.description": "Najnowszy otwartoźródłowy model 01.AI z 34 miliardami parametrów, dostrojony do różnych scenariuszy dialogowych, trenowany na wysokiej jakości danych i dostosowany do preferencji użytkowników.",
  "01-ai/yi-1.5-9b-chat.description": "Najnowszy otwartoźródłowy model 01.AI z 9 miliardami parametrów, dostrojony do różnych scenariuszy dialogowych, trenowany na wysokiej jakości danych i dostosowany do preferencji użytkowników.",
  "360/deepseek-r1.description": "DeepSeek-R1 wdrożony przez 360 wykorzystuje skalowane uczenie przez wzmocnienie (RL) w fazie post-treningowej, znacząco poprawiając zdolności rozumowania przy minimalnym oznakowaniu danych. Dorównuje modelowi OpenAI o1 w zadaniach z matematyki, programowania i rozumowania językowego.",
  "360gpt-pro-trans.description": "Model wyspecjalizowany w tłumaczeniach, głęboko dostrojony w celu zapewnienia najwyższej jakości przekładów.",
  "360gpt-pro.description": "360GPT Pro to kluczowy model AI od 360, oferujący wydajne przetwarzanie tekstu w różnorodnych scenariuszach NLP, z obsługą długich tekstów i dialogów wieloetapowych.",
  "360gpt-turbo-responsibility-8k.description": "360GPT Turbo Responsibility 8K kładzie nacisk na bezpieczeństwo semantyczne i odpowiedzialność w aplikacjach wrażliwych na treść, zapewniając precyzyjne i niezawodne doświadczenia użytkownika.",
  "360gpt-turbo.description": "360GPT Turbo oferuje wysoką wydajność obliczeniową i zdolności konwersacyjne, z doskonałym rozumieniem semantycznym i efektywnością generowania — idealny dla firm i deweloperów.",
  "360gpt2-o1.description": "360gpt2-o1 buduje łańcuch rozumowania poprzez przeszukiwanie drzewa z mechanizmem refleksji i treningiem RL, umożliwiając samorefleksję i autokorektę.",
  "360gpt2-pro.description": "360GPT2 Pro to zaawansowany model NLP od 360, wyróżniający się w generowaniu i rozumieniu tekstu, szczególnie w zadaniach kreatywnych, transformacjach i odgrywaniu ról.",
  "360zhinao2-o1.description": "360zhinao2-o1 buduje łańcuch rozumowania poprzez przeszukiwanie drzewa z mechanizmem refleksji i treningiem RL, umożliwiając samorefleksję i autokorektę.",
  "4.0Ultra.description": "Spark Ultra to najpotężniejszy model z serii Spark, ulepszający rozumienie tekstu i podsumowywanie oraz wzbogacający wyszukiwanie internetowe. Stanowi kompleksowe rozwiązanie zwiększające produktywność w pracy i precyzję odpowiedzi, pozycjonując się jako wiodący produkt inteligentny.",
  "AnimeSharp.description": "AnimeSharp (znany również jako „4x-AnimeSharp”) to otwartoźródłowy model super-rozdzielczości oparty na ESRGAN autorstwa Kim2091, skoncentrowany na skalowaniu i wyostrzaniu obrazów w stylu anime. W lutym 2022 roku zmieniono jego nazwę z „4x-TextSharpV1”; pierwotnie służył również do obrazów tekstowych, ale został silnie zoptymalizowany pod kątem treści anime.",
  "Baichuan2-Turbo.description": "Wykorzystuje rozszerzenie wyszukiwania do połączenia modelu z wiedzą dziedzinową i internetową. Obsługuje przesyłanie plików PDF/Word oraz wprowadzanie adresów URL w celu szybkiego i kompleksowego pozyskiwania informacji oraz generowania profesjonalnych i precyzyjnych odpowiedzi.",
  "Baichuan3-Turbo-128k.description": "Dzięki ultradługiemu kontekstowi 128K, zoptymalizowany do intensywnych zastosowań biznesowych, oferuje znaczne korzyści i wysoką wartość. W porównaniu z Baichuan2, tworzenie treści wzrasta o 20%, pytania i odpowiedzi oparte na wiedzy o 17%, a odgrywanie ról o 40%. Ogólna wydajność przewyższa GPT-3.5.",
  "Baichuan3-Turbo.description": "Zoptymalizowany do intensywnych zastosowań biznesowych, oferuje znaczne korzyści i wysoką wartość. W porównaniu z Baichuan2, tworzenie treści wzrasta o 20%, pytania i odpowiedzi oparte na wiedzy o 17%, a odgrywanie ról o 40%. Ogólna wydajność przewyższa GPT-3.5.",
  "Baichuan4-Air.description": "Model o najwyższej wydajności w Chinach, przewyższający czołowe modele zagraniczne w zadaniach w języku chińskim, takich jak wiedza, długie teksty i generowanie kreatywne. Oferuje również wiodące w branży możliwości multimodalne z silnymi wynikami w autorytatywnych testach porównawczych.",
  "Baichuan4-Turbo.description": "Model o najwyższej wydajności w Chinach, przewyższający czołowe modele zagraniczne w zadaniach w języku chińskim, takich jak wiedza, długie teksty i generowanie kreatywne. Oferuje również wiodące w branży możliwości multimodalne z silnymi wynikami w autorytatywnych testach porównawczych.",
  "Baichuan4.description": "Najlepsza krajowa wydajność, przewyższająca czołowe modele zagraniczne w zadaniach w języku chińskim, takich jak wiedza encyklopedyczna, długie teksty i generowanie kreatywne. Oferuje również wiodące w branży możliwości multimodalne i silne wyniki w testach porównawczych.",
  "ByteDance-Seed/Seed-OSS-36B-Instruct.description": "Seed-OSS to rodzina otwartoźródłowych modeli LLM od ByteDance Seed, zaprojektowana z myślą o obsłudze długiego kontekstu, rozumowaniu, zadaniach agentowych i ogólnych możliwościach. Seed-OSS-36B-Instruct to model z 36 miliardami parametrów dostrojony do instrukcji, z natywnym ultradługim kontekstem do przetwarzania dużych dokumentów lub baz kodu. Zoptymalizowany pod kątem rozumowania, generowania kodu i zadań agentowych (użycie narzędzi), zachowując przy tym silne ogólne zdolności. Kluczową cechą jest „Budżet Myślenia”, umożliwiający elastyczną długość rozumowania w celu zwiększenia efektywności.",
  "DeepSeek-R1-Distill-Llama-70B.description": "DeepSeek R1, większy i inteligentniejszy model z rodziny DeepSeek, został zdestylowany do architektury Llama 70B. Testy porównawcze i oceny ludzkie pokazują, że przewyższa bazowy Llama 70B, szczególnie w zadaniach matematycznych i wymagających precyzji faktów.",
  "DeepSeek-R1-Distill-Qwen-1.5B.description": "Model zdestylowany z DeepSeek-R1 na bazie Qwen2.5-Math-1.5B. Uczenie przez wzmocnienie i dane cold-start optymalizują wydajność rozumowania, ustanawiając nowe standardy dla otwartych modeli wielozadaniowych.",
  "DeepSeek-R1-Distill-Qwen-14B.description": "Modele DeepSeek-R1-Distill są dostrajane z otwartoźródłowych modeli przy użyciu próbek danych generowanych przez DeepSeek-R1.",
  "DeepSeek-R1-Distill-Qwen-32B.description": "Modele DeepSeek-R1-Distill są dostrajane z otwartoźródłowych modeli przy użyciu próbek danych generowanych przez DeepSeek-R1.",
  "DeepSeek-R1-Distill-Qwen-7B.description": "Model zdestylowany z DeepSeek-R1 na bazie Qwen2.5-Math-7B. Uczenie przez wzmocnienie i dane cold-start optymalizują wydajność rozumowania, ustanawiając nowe standardy dla otwartych modeli wielozadaniowych.",
  "DeepSeek-R1.description": "DeepSeek-R1 stosuje skalowane uczenie przez wzmocnienie w fazie post-treningowej, znacząco poprawiając zdolności rozumowania przy bardzo małej liczbie oznakowanych danych. Dorównuje produkcyjnemu modelowi OpenAI o1 w zadaniach z matematyki, programowania i rozumowania językowego.",
  "DeepSeek-V3-1.description": "DeepSeek V3.1 to model nowej generacji do rozumowania, z ulepszonym rozumowaniem złożonym i łańcuchowym, odpowiedni do zadań wymagających głębokiej analizy.",
  "DeepSeek-V3-Fast.description": "Dostawca: sophnet. DeepSeek V3 Fast to wersja o wysokim TPS modelu DeepSeek V3 0324, w pełnej precyzji (bez kwantyzacji), z lepszymi wynikami w kodzie i matematyce oraz szybszymi odpowiedziami.",
  "DeepSeek-V3.1-Fast.description": "DeepSeek V3.1 Fast to szybka wersja modelu DeepSeek V3.1 o wysokim TPS. Tryb hybrydowego myślenia: dzięki szablonom czatu jeden model obsługuje zarówno tryb myślący, jak i niemyslący. Inteligentniejsze użycie narzędzi: optymalizacje po treningu poprawiają wydajność zadań agentowych i użycia narzędzi.",
  "DeepSeek-V3.1-Think.description": "Tryb myślenia DeepSeek-V3.1: nowy hybrydowy model rozumowania z trybami myślącym i niemyslącym, bardziej wydajny niż DeepSeek-R1-0528. Optymalizacje po treningu znacząco poprawiają użycie narzędzi agentowych i wydajność zadań agentowych.",
  "DeepSeek-V3.description": "DeepSeek-V3 to model MoE opracowany przez DeepSeek. Przewyższa inne otwarte modele, takie jak Qwen2.5-72B i Llama-3.1-405B w wielu testach porównawczych i konkuruje z czołowymi zamkniętymi modelami, takimi jak GPT-4o i Claude 3.5 Sonnet.",
  "Doubao-lite-128k.description": "Doubao-lite oferuje ultraszybkie odpowiedzi i lepszy stosunek jakości do ceny, z elastycznymi opcjami dla różnych scenariuszy. Obsługuje kontekst 128K do wnioskowania i dostrajania.",
  "Doubao-lite-32k.description": "Doubao-lite oferuje ultraszybkie odpowiedzi i lepszy stosunek jakości do ceny, z elastycznymi opcjami dla różnych scenariuszy. Obsługuje kontekst 32K do wnioskowania i dostrajania.",
  "Doubao-lite-4k.description": "Doubao-lite oferuje ultraszybkie odpowiedzi i lepszy stosunek jakości do ceny, z elastycznymi opcjami dla różnych scenariuszy. Obsługuje kontekst 4K do wnioskowania i dostrajania.",
  "Doubao-pro-128k.description": "Najlepszy model flagowy do złożonych zadań, doskonały w zadaniach typu QA z odniesieniami, streszczaniu, tworzeniu treści, klasyfikacji i odgrywaniu ról. Obsługuje kontekst 128K do wnioskowania i dostrajania.",
  "Doubao-pro-32k.description": "Najlepszy model flagowy do złożonych zadań, doskonały w zadaniach typu QA z odniesieniami, streszczaniu, tworzeniu treści, klasyfikacji i odgrywaniu ról. Obsługuje kontekst 32K do wnioskowania i dostrajania.",
  "Doubao-pro-4k.description": "Najlepszy model flagowy do złożonych zadań, doskonały w zadaniach typu QA z odniesieniami, streszczaniu, tworzeniu treści, klasyfikacji i odgrywaniu ról. Obsługuje kontekst 4K do wnioskowania i dostrajania.",
  "DreamO.description": "DreamO to otwartoźródłowy model personalizacji obrazów opracowany wspólnie przez ByteDance i Uniwersytet Pekiński, wykorzystujący zunifikowaną architekturę do obsługi wielozadaniowego generowania obrazów. Wykorzystuje wydajne modelowanie kompozycyjne do generowania spójnych, dostosowanych obrazów na podstawie tożsamości, tematu, stylu, tła i innych warunków określonych przez użytkownika.",
  "ERNIE-3.5-128K.description": "Flagowy model LLM Baidu, wytrenowany na ogromnych korpusach chińsko-angielskich, o silnych ogólnych możliwościach w zakresie czatu, tworzenia treści i korzystania z wtyczek; obsługuje automatyczną integrację z wtyczką Baidu Search dla aktualnych odpowiedzi.",
  "ERNIE-3.5-8K-Preview.description": "Flagowy model LLM Baidu, wytrenowany na ogromnych korpusach chińsko-angielskich, o silnych ogólnych możliwościach w zakresie czatu, tworzenia treści i korzystania z wtyczek; obsługuje automatyczną integrację z wtyczką Baidu Search dla aktualnych odpowiedzi.",
  "ERNIE-3.5-8K.description": "Flagowy model LLM Baidu, wytrenowany na ogromnych korpusach chińsko-angielskich, o silnych ogólnych możliwościach w zakresie czatu, tworzenia treści i korzystania z wtyczek; obsługuje automatyczną integrację z wtyczką Baidu Search dla aktualnych odpowiedzi.",
  "ERNIE-4.0-8K-Latest.description": "Flagowy ultraduży model LLM Baidu z kompleksowymi ulepszeniami względem ERNIE 3.5, odpowiedni do złożonych zadań w różnych dziedzinach; obsługuje integrację z wtyczką Baidu Search dla aktualnych odpowiedzi.",
  "ERNIE-4.0-8K-Preview.description": "Flagowy ultraduży model LLM Baidu z kompleksowymi ulepszeniami względem ERNIE 3.5, odpowiedni do złożonych zadań w różnych dziedzinach; obsługuje integrację z wtyczką Baidu Search dla aktualnych odpowiedzi.",
  "ERNIE-4.0-Turbo-8K-Latest.description": "Flagowy ultraduży model LLM Baidu o wysokiej wydajności ogólnej do złożonych zadań, z integracją wtyczki Baidu Search dla aktualnych odpowiedzi. Przewyższa ERNIE 4.0.",
  "ERNIE-4.0-Turbo-8K-Preview.description": "Flagowy ultraduży model LLM Baidu o wysokiej wydajności ogólnej do złożonych zadań, z integracją wtyczki Baidu Search dla aktualnych odpowiedzi. Przewyższa ERNIE 4.0.",
  "ERNIE-Character-8K.description": "Model LLM Baidu dla domen wertykalnych, takich jak NPC w grach, obsługa klienta i odgrywanie ról, z lepszą spójnością postaci, silniejszym podążaniem za instrukcjami i lepszym rozumowaniem.",
  "ERNIE-Lite-Pro-128K.description": "Lekki model LLM Baidu, łączący jakość i wydajność wnioskowania, lepszy niż ERNIE Lite i odpowiedni dla akceleratorów o niskiej mocy obliczeniowej.",
  "ERNIE-Speed-128K.description": "Najnowszy model LLM Baidu o wysokiej wydajności (2024), o silnych ogólnych możliwościach, odpowiedni jako baza do dostrajania w celu obsługi konkretnych scenariuszy, z doskonałą wydajnością rozumowania.",
  "ERNIE-Speed-Pro-128K.description": "Najnowszy model LLM Baidu o wysokiej wydajności (2024), o silnych ogólnych możliwościach, lepszy niż ERNIE Speed, odpowiedni jako baza do dostrajania z doskonałą wydajnością rozumowania.",
  "FLUX-1.1-pro.description": "FLUX.1.1 Pro",
  "FLUX.1-Kontext-dev.description": "FLUX.1-Kontext-dev to multimodalny model generowania i edycji obrazów od Black Forest Labs, oparty na architekturze Rectified Flow Transformer z 12 miliardami parametrów. Skupia się na generowaniu, rekonstrukcji, ulepszaniu lub edytowaniu obrazów w określonym kontekście. Łączy kontrolowaną generację modeli dyfuzyjnych z modelowaniem kontekstu przez Transformery, wspierając wysokiej jakości wyniki w zadaniach takich jak inpainting, outpainting i rekonstrukcja scen wizualnych.",
  "FLUX.1-Kontext-pro.description": "FLUX.1 Kontext [pro]",
  "FLUX.1-dev.description": "FLUX.1-dev to otwartoźródłowy multimodalny model językowy (MLLM) od Black Forest Labs, zoptymalizowany do zadań obraz-tekst, łączący rozumienie i generowanie obrazów/tekstu. Zbudowany na zaawansowanych LLM (np. Mistral-7B), wykorzystuje starannie zaprojektowany enkoder wizji i wieloetapowe dostrajanie instrukcji, umożliwiając multimodalną koordynację i złożone rozumowanie.",
  "Gryphe/MythoMax-L2-13b.description": "MythoMax-L2 (13B) to innowacyjny model do różnorodnych dziedzin i złożonych zadań.",
  "HelloMeme.description": "HelloMeme to narzędzie AI do generowania memów, GIF-ów lub krótkich filmów z dostarczonych obrazów lub ruchów. Nie wymaga umiejętności rysowania ani kodowania — wystarczy obraz referencyjny, aby stworzyć zabawne, atrakcyjne i stylistycznie spójne treści.",
  "HiDream-I1-Full.description": "HiDream-E1-Full to otwartoźródłowy multimodalny model edycji obrazów od HiDream.ai, oparty na zaawansowanej architekturze Diffusion Transformer i silnym rozumieniu języka (wbudowany LLaMA 3.1-8B-Instruct). Obsługuje generowanie obrazów sterowane językiem naturalnym, transfer stylu, lokalne edycje i przemalowywanie, z doskonałym rozumieniem i wykonaniem obraz-tekst.",
  "HunyuanDiT-v1.2-Diffusers-Distilled.description": "hunyuandit-v1.2-distilled to lekki model tekst-na-obraz zoptymalizowany przez destylację do szybkiego generowania wysokiej jakości obrazów, szczególnie odpowiedni dla środowisk o ograniczonych zasobach i generowania w czasie rzeczywistym.",
  "InstantCharacter.description": "InstantCharacter to model generowania spersonalizowanych postaci bez potrzeby dostrajania, wydany przez Tencent AI w 2025 roku, mający na celu wierne i spójne generowanie postaci w różnych scenariuszach. Może modelować postać na podstawie jednego obrazu referencyjnego i elastycznie przenosić ją między stylami, działaniami i tłami.",
  "InternVL2-8B.description": "InternVL2-8B to potężny model wizja-język obsługujący multimodalne przetwarzanie obraz-tekst, dokładnie rozpoznający zawartość obrazu i generujący odpowiednie opisy lub odpowiedzi.",
  "InternVL2.5-26B.description": "InternVL2.5-26B to potężny model wizja-język obsługujący multimodalne przetwarzanie obraz-tekst, dokładnie rozpoznający zawartość obrazu i generujący odpowiednie opisy lub odpowiedzi.",
  "Kolors.description": "Kolors to model tekst-na-obraz opracowany przez zespół Kuaishou Kolors. Wytrenowany na miliardach parametrów, wyróżnia się jakością wizualną, rozumieniem semantyki chińskiej i renderowaniem tekstu.",
  "Kwai-Kolors/Kolors.description": "Kolors to wielkoskalowy model latent-diffusion tekst-na-obraz od zespołu Kuaishou Kolors. Wytrenowany na miliardach par tekst-obraz, wyróżnia się jakością wizualną, dokładnością semantyczną i renderowaniem tekstu w języku chińskim/angielskim, z silnym rozumieniem i generowaniem treści w języku chińskim.",
  "Kwaipilot/KAT-Dev.description": "KAT-Dev (32B) to otwartoźródłowy model 32B do zadań inżynierii oprogramowania. Osiąga 62,4% skuteczności na SWE-Bench Verified, zajmując 5. miejsce wśród otwartych modeli. Zoptymalizowany przez mid-training, SFT i RL do uzupełniania kodu, naprawy błędów i przeglądu kodu.",
  "Llama-3.2-11B-Vision-Instruct.description": "Silne rozumowanie obrazowe na obrazach wysokiej rozdzielczości, odpowiednie do zastosowań wymagających rozumienia wizualnego.",
  "Llama-3.2-90B-Vision-Instruct\t.description": "Zaawansowane rozumowanie obrazowe dla aplikacji agentów rozumiejących wizję.",
  "Meta-Llama-3-3-70B-Instruct.description": "Llama 3.3 70B to wszechstronny model Transformer do zadań czatu i generowania treści.",
  "Meta-Llama-3.1-405B-Instruct.description": "Model tekstowy Llama 3.1 dostrojony do instrukcji, zoptymalizowany do czatu wielojęzycznego, osiągający wysokie wyniki w branżowych benchmarkach wśród modeli otwartych i zamkniętych.",
  "Meta-Llama-3.1-70B-Instruct.description": "Model tekstowy Llama 3.1 dostrojony do instrukcji, zoptymalizowany do czatu wielojęzycznego, osiągający wysokie wyniki w branżowych benchmarkach wśród modeli otwartych i zamkniętych.",
  "Meta-Llama-3.1-8B-Instruct.description": "Model tekstowy Llama 3.1 dostrojony do instrukcji, zoptymalizowany do czatu wielojęzycznego, osiągający wysokie wyniki w branżowych benchmarkach wśród modeli otwartych i zamkniętych.",
  "Meta-Llama-3.2-1B-Instruct.description": "Nowoczesny mały model językowy o silnym rozumieniu języka, doskonałym rozumowaniu i generowaniu tekstu.",
  "Meta-Llama-3.2-3B-Instruct.description": "Nowoczesny mały model językowy o silnym rozumieniu języka, doskonałym rozumowaniu i generowaniu tekstu.",
  "Meta-Llama-3.3-70B-Instruct.description": "Llama 3.3 to najbardziej zaawansowany wielojęzyczny otwartoźródłowy model Llama, oferujący wydajność zbliżoną do 405B przy bardzo niskim koszcie. Opiera się na architekturze Transformer i został ulepszony za pomocą SFT i RLHF dla użyteczności i bezpieczeństwa. Wersja dostrojona do instrukcji jest zoptymalizowana do czatu wielojęzycznego i przewyższa wiele modeli otwartych i zamkniętych w branżowych benchmarkach. Data odcięcia wiedzy: grudzień 2023.",
  "Meta-Llama-4-Maverick-17B-128E-Instruct-FP8.description": "Llama 4 Maverick to duży model MoE z efektywną aktywacją ekspertów, zapewniający wysoką wydajność rozumowania.",
  "MiniMax-M1.description": "Nowy wewnętrzny model rozumowania z 80 tys. łańcuchów myślowych i 1 mln tokenów wejściowych, oferujący wydajność porównywalną z czołowymi modelami światowymi.",
  "MiniMax-M2-Stable.description": "Zaprojektowany z myślą o wydajnym kodowaniu i przepływach pracy agentów, z większą równoległością dla zastosowań komercyjnych.",
  "MiniMax-M2.description": "Zaprojektowany z myślą o wydajnym kodowaniu i przepływach pracy agentów.",
  "MiniMax-Text-01.description": "MiniMax-01 wprowadza dużą skalę uwagi liniowej wykraczającą poza klasyczne Transformatory, z 456 mld parametrów i 45,9 mld aktywowanych na przebieg. Osiąga najwyższą wydajność i obsługuje do 4 mln tokenów kontekstu (32× GPT-4o, 20× Claude-3.5-Sonnet).",
  "MiniMaxAI/MiniMax-M1-80k.description": "MiniMax-M1 to model rozumowania o otwartych wagach, oparty na hybrydowej uwadze, z 456 mld parametrów ogółem i ~45,9 mld aktywnych na token. Natywnie obsługuje kontekst 1 mln tokenów i wykorzystuje Flash Attention, redukując FLOPs o 75% przy generowaniu 100 tys. tokenów w porównaniu do DeepSeek R1. Dzięki architekturze MoE, CISPO i treningowi RL z hybrydową uwagą, osiąga czołowe wyniki w zadaniach rozumowania z długim wejściem i rzeczywistym inżynierii oprogramowania.",
  "MiniMaxAI/MiniMax-M2.description": "MiniMax-M2 redefiniuje efektywność agentów. To kompaktowy, szybki i opłacalny model MoE z 230 mld parametrów ogółem i 10 mld aktywnych, zaprojektowany do zadań kodowania i agentowych najwyższej klasy, przy zachowaniu silnej inteligencji ogólnej. Dzięki tylko 10 mld aktywnych parametrów dorównuje znacznie większym modelom, co czyni go idealnym do zastosowań wymagających wysokiej wydajności.",
  "Moonshot-Kimi-K2-Instruct.description": "1 bln parametrów ogółem, z 32 mld aktywnych. Wśród modeli bez trybu myślenia, wyróżnia się w wiedzy czołowej, matematyce i kodowaniu, a także w zadaniach ogólnych agentów. Optymalizowany pod kątem obciążeń agentowych – potrafi podejmować działania, a nie tylko odpowiadać. Najlepszy do improwizowanych rozmów, ogólnego czatu i doświadczeń agentowych jako model reagujący bez długiego namysłu.",
  "NousResearch/Nous-Hermes-2-Mixtral-8x7B-DPO.description": "Nous Hermes 2 - Mixtral 8x7B-DPO (46,7 mld) to model instrukcyjny o wysokiej precyzji do złożonych obliczeń.",
  "OmniConsistency.description": "OmniConsistency poprawia spójność stylu i uogólnianie w zadaniach obraz-do-obrazu, wprowadzając duże Transformatory Dyfuzyjne (DiTs) i sparowane dane stylizowane, unikając degradacji stylu.",
  "Phi-3-medium-128k-instruct.description": "Ten sam model Phi-3-medium z większym oknem kontekstu do zadań RAG lub few-shot.",
  "Phi-3-medium-4k-instruct.description": "Model z 14 mld parametrów, o wyższej jakości niż Phi-3-mini, skoncentrowany na danych wymagających intensywnego rozumowania.",
  "Phi-3-mini-128k-instruct.description": "Ten sam model Phi-3-mini z większym oknem kontekstu do zadań RAG lub few-shot.",
  "Phi-3-mini-4k-instruct.description": "Najmniejszy członek rodziny Phi-3, zoptymalizowany pod kątem jakości i niskich opóźnień.",
  "Phi-3-small-128k-instruct.description": "Ten sam model Phi-3-small z większym oknem kontekstu do zadań RAG lub few-shot.",
  "Phi-3-small-8k-instruct.description": "Model z 7 mld parametrów, o wyższej jakości niż Phi-3-mini, skoncentrowany na danych wymagających intensywnego rozumowania.",
  "Phi-3.5-mini-instruct.description": "Zaktualizowana wersja modelu Phi-3-mini.",
  "Phi-3.5-vision-instrust.description": "Zaktualizowana wersja modelu Phi-3-vision.",
  "Pro/Qwen/Qwen2-7B-Instruct.description": "Qwen2-7B-Instruct to 7-miliardowy model LLM z serii Qwen2, dostrojony do instrukcji. Wykorzystuje architekturę Transformera z SwiGLU, biasem QKV i grupowaną uwagę zapytań, obsługuje duże wejścia. Wyróżnia się w rozumieniu języka, generowaniu, zadaniach wielojęzycznych, kodowaniu, matematyce i rozumowaniu, przewyższając większość modeli otwartych i konkurując z zamkniętymi. Przewyższa Qwen1.5-7B-Chat w wielu testach.",
  "Pro/Qwen/Qwen2.5-7B-Instruct.description": "Qwen2.5-7B-Instruct to część najnowszej serii LLM Alibaba Cloud. Model 7B przynosi znaczące ulepszenia w kodowaniu i matematyce, obsługuje ponad 29 języków i poprawia wykonywanie instrukcji, rozumienie danych strukturalnych i generowanie strukturalnych wyników (szczególnie JSON).",
  "Pro/Qwen/Qwen2.5-Coder-7B-Instruct.description": "Qwen2.5-Coder-7B-Instruct to najnowszy model LLM Alibaba Cloud skoncentrowany na kodzie. Zbudowany na bazie Qwen2.5 i wytrenowany na 5,5 bln tokenów, znacząco poprawia generowanie kodu, rozumowanie i naprawę, zachowując mocne strony w matematyce i ogólnych zadaniach, stanowiąc solidną bazę dla agentów kodujących.",
  "Pro/Qwen/Qwen2.5-VL-7B-Instruct.description": "Qwen2.5-VL to nowy model językowo-wizualny Qwen z silnym rozumieniem wizualnym. Analizuje tekst, wykresy i układy na obrazach, rozumie długie filmy i zdarzenia, wspiera rozumowanie i użycie narzędzi, uziemienie obiektów w wielu formatach i strukturalne wyniki. Poprawia rozdzielczość dynamiczną i trening z różnymi klatkami dla lepszego rozumienia wideo oraz zwiększa efektywność enkodera wizji.",
  "Pro/THUDM/GLM-4.1V-9B-Thinking.description": "GLM-4.1V-9B-Thinking to otwartoźródłowy model VLM od Zhipu AI i laboratorium KEG Uniwersytetu Tsinghua, zaprojektowany do złożonego poznania multimodalnego. Zbudowany na bazie GLM-4-9B-0414, dodaje rozumowanie łańcuchowe i RL, znacząco poprawiając rozumowanie między modalnościami i stabilność.",
  "Pro/THUDM/glm-4-9b-chat.description": "GLM-4-9B-Chat to otwartoźródłowy model GLM-4 od Zhipu AI. Wyróżnia się w semantyce, matematyce, rozumowaniu, kodzie i wiedzy. Poza wieloetapowym czatem obsługuje przeglądanie sieci, wykonywanie kodu, niestandardowe wywołania narzędzi i rozumowanie długich tekstów. Obsługuje 26 języków (w tym chiński, angielski, japoński, koreański, niemiecki). Osiąga dobre wyniki w AlignBench-v2, MT-Bench, MMLU i C-Eval, obsługuje do 128 tys. tokenów kontekstu do zastosowań akademickich i biznesowych.",
  "Pro/deepseek-ai/DeepSeek-R1-Distill-Qwen-7B.description": "DeepSeek-R1-Distill-Qwen-7B to model zdestylowany z Qwen2.5-Math-7B i dostrojony na 800 tys. starannie dobranych próbkach DeepSeek-R1. Osiąga wysokie wyniki: 92,8% na MATH-500, 55,5% na AIME 2024 i ocenę 1189 na CodeForces dla modelu 7B.",
  "Pro/deepseek-ai/DeepSeek-R1.description": "DeepSeek-R1 to model rozumowania oparty na RL, który redukuje powtórzenia i poprawia czytelność. Wykorzystuje dane cold-start przed RL, by dodatkowo zwiększyć zdolności rozumowania, dorównuje OpenAI-o1 w zadaniach matematycznych, kodowych i rozumowania, a dzięki starannemu treningowi poprawia ogólne wyniki.",
  "Pro/deepseek-ai/DeepSeek-V3.1-Terminus.description": "DeepSeek-V3.1-Terminus to zaktualizowany model V3.1, pozycjonowany jako hybrydowy agent LLM. Naprawia zgłoszone przez użytkowników problemy, poprawia stabilność, spójność językową i redukuje mieszane znaki chińskie/angielskie oraz nieprawidłowe znaki. Integruje tryby myślenia i nie-myślenia z szablonami czatu dla elastycznego przełączania. Poprawia również wydajność agentów kodu i wyszukiwania dla bardziej niezawodnego użycia narzędzi i zadań wieloetapowych.",
  "Pro/deepseek-ai/DeepSeek-V3.2-Exp.description": "DeepSeek-V3.2-Exp to eksperymentalne wydanie V3.2, łączące się z nową architekturą. Dodaje DeepSeek Sparse Attention (DSA) do V3.1-Terminus, poprawiając efektywność treningu i wnioskowania w długim kontekście, z optymalizacjami dla użycia narzędzi, rozumienia długich dokumentów i rozumowania wieloetapowego. Idealny do eksploracji wyższej efektywności rozumowania przy dużych budżetach kontekstu.",
  "Pro/deepseek-ai/DeepSeek-V3.description": "DeepSeek-V3 to model MoE z 671 mld parametrów, wykorzystujący MLA i DeepSeekMoE z równoważeniem obciążenia bez strat, zapewniający efektywne wnioskowanie i trening. Wstępnie wytrenowany na 14,8 bln wysokiej jakości tokenów i dalej dostrojony za pomocą SFT i RL, przewyższa inne modele otwarte i zbliża się do czołowych modeli zamkniętych.",
  "Pro/moonshotai/Kimi-K2-Instruct-0905.description": "Kimi K2-Instruct-0905 to najnowsza i najpotężniejsza wersja Kimi K2. Jest to model MoE najwyższej klasy z 1T łącznych i 32B aktywnych parametrów. Kluczowe cechy to silniejsza inteligencja kodowania agentowego z istotnymi poprawami w testach porównawczych i zadaniach agentowych w rzeczywistych warunkach, a także ulepszona estetyka i użyteczność kodowania frontendowego.",
  "Pro/moonshotai/Kimi-K2-Thinking.description": "Kimi K2 Thinking Turbo to wariant Turbo zoptymalizowany pod kątem szybkości rozumowania i przepustowości, zachowując jednocześnie wieloetapowe rozumowanie i obsługę narzędzi znane z K2 Thinking. Jest to model MoE z około 1T łącznych parametrów, natywnym kontekstem 256K i stabilnym wywoływaniem narzędzi na dużą skalę, przeznaczony do zastosowań produkcyjnych z rygorystycznymi wymaganiami dotyczącymi opóźnień i współbieżności.",
  "QwQ-32B-Preview.description": "Qwen QwQ to eksperymentalny model badawczy skoncentrowany na ulepszaniu zdolności rozumowania.",
  "Qwen/QVQ-72B-Preview.description": "QVQ-72B-Preview to model badawczy od Qwen, skoncentrowany na rozumowaniu wizualnym, wyróżniający się w złożonym rozumieniu scen i problemach matematycznych opartych na obrazie.",
  "Qwen/QwQ-32B-Preview.description": "Qwen QwQ to eksperymentalny model badawczy skoncentrowany na ulepszonym rozumowaniu sztucznej inteligencji.",
  "Qwen/QwQ-32B.description": "QwQ to model rozumowania z rodziny Qwen. W porównaniu do standardowych modeli dostrojonych do instrukcji, dodaje warstwę myślenia i rozumowania, co znacząco poprawia wydajność w zadaniach końcowych, szczególnie w trudnych problemach. QwQ-32B to model średniej wielkości konkurujący z czołowymi modelami rozumowania, takimi jak DeepSeek-R1 i o1-mini. Wykorzystuje RoPE, SwiGLU, RMSNorm i bias QKV w mechanizmie uwagi, z 64 warstwami i 40 głowicami uwagi Q (8 KV w GQA).",
  "Qwen/Qwen-Image-Edit-2509.description": "Qwen-Image-Edit-2509 to najnowsza wersja edycyjna Qwen-Image od zespołu Qwen. Bazując na modelu Qwen-Image 20B, rozszerza możliwości renderowania tekstu na edycję obrazów, umożliwiając precyzyjne modyfikacje tekstowe. Wykorzystuje architekturę podwójnej kontroli, przesyłając dane wejściowe do Qwen2.5-VL w celu kontroli semantycznej oraz do kodera VAE w celu kontroli wyglądu, co umożliwia edycję zarówno na poziomie semantycznym, jak i wizualnym. Obsługuje lokalne zmiany (dodawanie/usuwanie/modyfikacja) oraz edycje semantyczne wyższego poziomu, takie jak tworzenie IP i transfer stylu, zachowując przy tym znaczenie. Osiąga najlepsze wyniki w wielu testach porównawczych.",
  "Qwen/Qwen-Image.description": "Qwen-Image to bazowy model generowania obrazów o 20 miliardach parametrów od zespołu Qwen. Oferuje znaczące postępy w renderowaniu złożonego tekstu i precyzyjnej edycji obrazów, szczególnie w przypadku tekstu chińskiego i angielskiego o wysokiej wierności. Obsługuje układy wieloliniowe i akapity, zachowując spójność typograficzną. Poza renderowaniem tekstu, wspiera szeroki zakres stylów – od fotorealistycznych po anime – oraz zaawansowane techniki edycji, takie jak transfer stylu, dodawanie/usuwanie obiektów, poprawa szczegółów, edycja tekstu i kontrola pozycji, dążąc do bycia kompleksową bazą do tworzenia wizualnego.",
  "Qwen/Qwen2-72B-Instruct.description": "Qwen 2 Instruct (72B) zapewnia precyzyjne wykonywanie instrukcji dla zastosowań korporacyjnych.",
  "Qwen/Qwen2-7B-Instruct.description": "Qwen2-7B-Instruct to model o 7 miliardach parametrów z serii Qwen2, dostrojony do instrukcji, wykorzystujący architekturę Transformer, SwiGLU, bias QKV i grupowaną uwagę zapytań. Obsługuje duże dane wejściowe i osiąga wysokie wyniki w testach rozumienia, generowania, wielojęzyczności, kodowania, matematyki i rozumowania, przewyższając większość otwartych modeli i wyprzedzając Qwen1.5-7B-Chat w wielu ocenach.",
  "Qwen/Qwen2-VL-72B-Instruct.description": "Qwen2-VL to najnowszy model Qwen-VL, osiągający najlepsze wyniki w testach wizualnych, takich jak MathVista, DocVQA, RealWorldQA i MTVQA. Potrafi rozumieć filmy trwające ponad 20 minut w kontekście pytań wideo, dialogów i tworzenia treści. Obsługuje również złożone rozumowanie i podejmowanie decyzji, integrując się z urządzeniami/robotami do działań opartych na wizji. Poza językiem angielskim i chińskim, potrafi czytać tekst w wielu językach, w tym większości języków europejskich, japońskim, koreańskim, arabskim i wietnamskim.",
  "Qwen/Qwen2.5-14B-Instruct.description": "Qwen2.5-14B-Instruct to część najnowszej serii LLM Alibaba Cloud. Model 14B przynosi znaczące postępy w kodowaniu i matematyce, obsługuje ponad 29 języków i poprawia wykonywanie instrukcji, rozumienie danych strukturalnych oraz generowanie danych strukturalnych (szczególnie JSON).",
  "Qwen/Qwen2.5-32B-Instruct.description": "Qwen2.5-32B-Instruct to część najnowszej serii LLM Alibaba Cloud. Model 32B przynosi znaczące postępy w kodowaniu i matematyce, obsługuje ponad 29 języków i poprawia wykonywanie instrukcji, rozumienie danych strukturalnych oraz generowanie danych strukturalnych (szczególnie JSON).",
  "Qwen/Qwen2.5-72B-Instruct-128K.description": "Qwen2.5-72B-Instruct to część najnowszej serii LLM Alibaba Cloud. Model 72B poprawia kodowanie i matematykę, obsługuje do 128K danych wejściowych i ponad 8K danych wyjściowych, oferuje wsparcie dla ponad 29 języków oraz ulepsza wykonywanie instrukcji i generowanie danych strukturalnych (szczególnie JSON).",
  "Qwen/Qwen2.5-72B-Instruct-Turbo.description": "Qwen2.5 to nowa rodzina LLM zoptymalizowana pod kątem zadań w stylu instrukcji.",
  "Qwen/Qwen2.5-72B-Instruct.description": "Qwen2.5-72B-Instruct to część najnowszej serii LLM Alibaba Cloud. Model 72B przynosi znaczące postępy w kodowaniu i matematyce, obsługuje ponad 29 języków i poprawia wykonywanie instrukcji, rozumienie danych strukturalnych oraz generowanie danych strukturalnych (szczególnie JSON).",
  "Qwen/Qwen2.5-7B-Instruct-Turbo.description": "Qwen2.5 to nowa rodzina LLM zoptymalizowana pod kątem zadań w stylu instrukcji.",
  "Qwen/Qwen2.5-7B-Instruct.description": "Qwen2.5-7B-Instruct to część najnowszej serii LLM Alibaba Cloud. Model 7B przynosi znaczące postępy w kodowaniu i matematyce, obsługuje ponad 29 języków i poprawia wykonywanie instrukcji, rozumienie danych strukturalnych oraz generowanie danych strukturalnych (szczególnie JSON).",
  "Qwen/Qwen2.5-Coder-32B-Instruct.description": "Qwen2.5 Coder 32B Instruct to najnowszy model LLM Alibaba Cloud skoncentrowany na kodzie. Zbudowany na bazie Qwen2.5 i wytrenowany na 5,5T tokenów, znacząco poprawia generowanie kodu, rozumowanie i naprawę błędów, zachowując przy tym mocne strony w matematyce i ogólnych zadaniach, stanowiąc solidną bazę dla agentów kodujących.",
  "Qwen/Qwen2.5-Coder-7B-Instruct.description": "Qwen2.5-Coder-7B-Instruct to najnowszy model LLM Alibaba Cloud skoncentrowany na kodzie. Zbudowany na bazie Qwen2.5 i wytrenowany na 5,5T tokenów, znacząco poprawia generowanie kodu, rozumowanie i naprawę błędów, zachowując przy tym mocne strony w matematyce i ogólnych zadaniach, stanowiąc solidną bazę dla agentów kodujących.",
  "Qwen/Qwen2.5-VL-32B-Instruct.description": "Qwen2.5-VL-32B-Instruct to model multimodalny od zespołu Qwen. Rozpoznaje powszechne obiekty i analizuje tekst, wykresy, ikony, grafiki i układy. Jako agent wizualny potrafi rozumować i dynamicznie kontrolować narzędzia, w tym korzystanie z komputera i telefonu. Precyzyjnie lokalizuje obiekty i generuje dane strukturalne dla faktur i tabel. W porównaniu do Qwen2-VL, RL dodatkowo poprawia matematykę i rozwiązywanie problemów, oferując bardziej preferowane przez ludzi odpowiedzi.",
  "Qwen/Qwen2.5-VL-72B-Instruct.description": "Qwen2.5-VL to model językowo-wizualny z serii Qwen2.5 z dużymi ulepszeniami: silniejsze rozumienie wizualne obiektów, tekstu, wykresów i układów; rozumowanie jako agent wizualny z dynamicznym użyciem narzędzi; rozumienie filmów trwających ponad godzinę i wychwytywanie kluczowych wydarzeń; precyzyjne lokalizowanie obiektów za pomocą ramek lub punktów; oraz generowanie danych strukturalnych dla zeskanowanych danych, takich jak faktury i tabele.",
  "Qwen/Qwen3-14B.description": "Qwen3 to nowej generacji model Tongyi Qwen, oferujący znaczne ulepszenia w zakresie rozumowania, ogólnych zdolności, możliwości działania jako agent oraz wydajności wielojęzycznej. Obsługuje przełączanie trybów myślenia.",
  "Qwen/Qwen3-235B-A22B-Instruct-2507.description": "Qwen3-235B-A22B-Instruct-2507 to flagowy model Qwen3 MoE z 235 miliardami parametrów ogólnych i 22 miliardami aktywnych. Jest to zaktualizowana wersja bez trybu myślenia, skoncentrowana na poprawie wykonywania instrukcji, rozumowania logicznego, rozumienia tekstu, matematyki, nauk ścisłych, programowania i obsługi narzędzi. Rozszerza również wiedzę długiego ogona w wielu językach i lepiej dopasowuje się do preferencji użytkowników w zadaniach subiektywnych i otwartych.",
  "Qwen/Qwen3-235B-A22B-Thinking-2507.description": "Qwen3-235B-A22B-Thinking-2507 to model Qwen3 skoncentrowany na złożonym rozumowaniu. Wykorzystuje architekturę MoE z 235 miliardami parametrów ogólnych i około 22 miliardami aktywnych na token, co zwiększa efektywność. Jako dedykowany model myślący, osiąga znaczne postępy w logice, matematyce, naukach ścisłych, programowaniu i testach akademickich, osiągając najwyższy poziom otwartego rozumowania. Poprawia również wykonywanie instrukcji, obsługę narzędzi i generowanie tekstu, a także natywnie obsługuje kontekst 256K dla głębokiego rozumowania i długich dokumentów.",
  "Qwen/Qwen3-235B-A22B.description": "Qwen3 to nowej generacji model Tongyi Qwen, oferujący znaczne ulepszenia w zakresie rozumowania, ogólnych zdolności, możliwości działania jako agent oraz wydajności wielojęzycznej. Obsługuje przełączanie trybów myślenia.",
  "Qwen/Qwen3-30B-A3B-Instruct-2507.description": "Qwen3-30B-A3B-Instruct-2507 to zaktualizowana wersja modelu Qwen3-30B-A3B bez trybu myślenia. Jest to model MoE z 30,5 miliardami parametrów ogólnych i 3,3 miliardami aktywnych. Znacząco poprawia wykonywanie instrukcji, rozumowanie logiczne, rozumienie tekstu, matematykę, nauki ścisłe, programowanie i obsługę narzędzi, rozszerza wiedzę długiego ogona w wielu językach i lepiej dopasowuje się do preferencji użytkowników w zadaniach subiektywnych. Obsługuje kontekst 256K. Ten model działa wyłącznie w trybie bez myślenia i nie generuje znaczników `<think></think>`.",
  "Qwen/Qwen3-30B-A3B-Thinking-2507.description": "Qwen3-30B-A3B-Thinking-2507 to najnowszy model myślący z serii Qwen3. Jest to model MoE z 30,5 miliardami parametrów ogólnych i 3,3 miliardami aktywnych, skoncentrowany na złożonych zadaniach. Osiąga znaczące postępy w logice, matematyce, naukach ścisłych, programowaniu i testach akademickich, a także poprawia wykonywanie instrukcji, obsługę narzędzi, generowanie tekstu i dopasowanie do preferencji. Natywnie obsługuje kontekst 256K i może zostać rozszerzony do 1 miliona tokenów. Ta wersja została zaprojektowana do trybu myślenia z dokładnym rozumowaniem krok po kroku i silnymi możliwościami agenta.",
  "Qwen/Qwen3-30B-A3B.description": "Qwen3 to nowej generacji model Tongyi Qwen, oferujący znaczne ulepszenia w zakresie rozumowania, ogólnych zdolności, możliwości działania jako agent oraz wydajności wielojęzycznej. Obsługuje przełączanie trybów myślenia.",
  "Qwen/Qwen3-32B.description": "Qwen3 to nowej generacji model Tongyi Qwen, oferujący znaczne ulepszenia w zakresie rozumowania, ogólnych zdolności, możliwości działania jako agent oraz wydajności wielojęzycznej. Obsługuje przełączanie trybów myślenia.",
  "Qwen/Qwen3-8B.description": "Qwen3 to nowej generacji model Tongyi Qwen, oferujący znaczne ulepszenia w zakresie rozumowania, ogólnych zdolności, możliwości działania jako agent oraz wydajności wielojęzycznej. Obsługuje przełączanie trybów myślenia.",
  "Qwen/Qwen3-Coder-30B-A3B-Instruct.description": "Qwen3-Coder-30B-A3B-Instruct to model kodowania z serii Qwen3 opracowany przez zespół Qwen. Został zoptymalizowany pod kątem wysokiej wydajności i efektywności, jednocześnie zwiększając możliwości kodowania. Wyróżnia się w kodowaniu agentowym, automatyzacji przeglądarki i obsłudze narzędzi wśród modeli otwartych. Natywnie obsługuje kontekst 256K i może zostać rozszerzony do 1 miliona tokenów dla zrozumienia na poziomie całej bazy kodu. Obsługuje kodowanie agentowe na platformach takich jak Qwen Code i CLINE z dedykowanym formatem wywoływania funkcji.",
  "Qwen/Qwen3-Coder-480B-A35B-Instruct.description": "Qwen3-Coder-480B-A35B-Instruct to najbardziej zaawansowany model kodowania agentowego firmy Alibaba. Jest to model MoE z 480 miliardami parametrów ogólnych i 35 miliardami aktywnych, łączący efektywność z wydajnością. Natywnie obsługuje kontekst 256K i może zostać rozszerzony do 1 miliona tokenów za pomocą YaRN, umożliwiając obsługę dużych baz kodu. Zaprojektowany do przepływów pracy kodowania agentowego, potrafi współdziałać z narzędziami i środowiskami w celu rozwiązywania złożonych zadań programistycznych. Osiąga najlepsze wyniki wśród modeli otwartych w testach kodowania i agentów, porównywalne z wiodącymi modelami, takimi jak Claude Sonnet 4.",
  "Qwen/Qwen3-Next-80B-A3B-Instruct.description": "Qwen3-Next-80B-A3B-Instruct to nowej generacji model bazowy oparty na architekturze Qwen3-Next, zaprojektowany z myślą o ekstremalnej wydajności trenowania i wnioskowania. Łączy hybrydową uwagę (Gated DeltaNet + Gated Attention), silnie rozrzedzoną architekturę MoE oraz optymalizacje stabilności treningu. Choć posiada 80 miliardów parametrów, podczas wnioskowania aktywnych jest jedynie około 3 miliardów, co znacząco redukuje zapotrzebowanie na zasoby obliczeniowe i zapewnia ponad 10-krotnie większą przepustowość niż Qwen3-32B przy kontekstach >32K. Wersja dostrojona do instrukcji jest przeznaczona do ogólnych zadań (bez trybu myślenia). Osiąga porównywalne wyniki z Qwen3-235B w niektórych testach i wykazuje wyraźną przewagę w zadaniach z ultradługim kontekstem.",
  "Qwen/Qwen3-Next-80B-A3B-Thinking.description": "Qwen3-Next-80B-A3B-Thinking to nowej generacji model bazowy przeznaczony do złożonego rozumowania. Wykorzystuje architekturę Qwen3-Next z hybrydową uwagą (Gated DeltaNet + Gated Attention) oraz silnie rozrzedzoną architekturę MoE, zapewniając ekstremalną wydajność trenowania i wnioskowania. Choć posiada 80 miliardów parametrów, podczas wnioskowania aktywnych jest jedynie około 3 miliardów, co znacząco redukuje zapotrzebowanie na zasoby obliczeniowe i zapewnia ponad 10-krotnie większą przepustowość niż Qwen3-32B przy kontekstach >32K. Wersja Thinking jest zoptymalizowana pod kątem zadań wieloetapowych, takich jak dowodzenie, synteza kodu, analiza logiczna i planowanie, generując uporządkowany łańcuch myślowy. Przewyższa Qwen3-32B-Thinking i pokonuje Gemini-2.5-Flash-Thinking w wielu testach porównawczych.",
  "Qwen/Qwen3-Omni-30B-A3B-Captioner.description": "Qwen3-Omni-30B-A3B-Captioner to model VLM z serii Qwen3, stworzony do generowania wysokiej jakości, szczegółowych i precyzyjnych opisów obrazów. Wykorzystuje architekturę MoE z 30 miliardami parametrów, aby dogłębnie analizować obrazy i tworzyć płynne opisy, wyróżniając się w uchwyceniu detali, rozumieniu scen, rozpoznawaniu obiektów i relacyjnym rozumowaniu.",
  "Qwen/Qwen3-Omni-30B-A3B-Instruct.description": "Qwen3-Omni-30B-A3B-Instruct to model MoE z serii Qwen3, posiadający 30 miliardów parametrów ogółem i 3 miliardy aktywnych, oferujący wysoką wydajność przy niskim koszcie wnioskowania. Trenowany na wysokiej jakości danych wielojęzycznych z wielu źródeł, obsługuje pełne wejścia modalne (tekst, obrazy, dźwięk, wideo) oraz rozumienie i generowanie między modalnościami.",
  "Qwen/Qwen3-Omni-30B-A3B-Thinking.description": "Qwen3-Omni-30B-A3B-Thinking to kluczowy komponent „Myślący” w Qwen3-Omni. Przetwarza dane multimodalne (tekst, dźwięk, obrazy, wideo) i wykonuje złożone rozumowanie łańcuchowe, łącząc dane wejściowe w jedną reprezentację dla głębokiego rozumienia między modalnościami. Jest to model MoE z 30 miliardami parametrów ogółem i 3 miliardami aktywnych, łączący silne zdolności rozumowania z efektywnością obliczeniową.",
  "Qwen/Qwen3-VL-235B-A22B-Instruct.description": "Qwen3-VL-235B-A22B-Instruct to duży model Qwen3-VL dostrojony do instrukcji, oparty na architekturze MoE, zapewniający doskonałe rozumienie i generowanie multimodalne. Obsługuje natywnie kontekst 256K i nadaje się do produkcyjnych usług multimodalnych o wysokiej współbieżności.",
  "Qwen/Qwen3-VL-235B-A22B-Thinking.description": "Qwen3-VL-235B-A22B-Thinking to flagowa wersja myśląca modelu Qwen3-VL, zoptymalizowana pod kątem złożonego rozumowania multimodalnego, rozumowania w długim kontekście oraz interakcji agentów w zastosowaniach korporacyjnych.",
  "Qwen/Qwen3-VL-30B-A3B-Instruct.description": "Qwen3-VL-30B-A3B-Instruct to model Qwen3-VL dostrojony do instrukcji, oferujący silne rozumienie i generowanie wizualno-językowe. Obsługuje natywnie kontekst 256K dla czatu multimodalnego i generowania warunkowanego obrazem.",
  "Qwen/Qwen3-VL-30B-A3B-Thinking.description": "Qwen3-VL-30B-A3B-Thinking to wersja modelu Qwen3-VL wzbogacona o zdolności rozumowania, zoptymalizowana pod kątem rozumowania multimodalnego, konwersji obrazu na kod oraz złożonego rozumienia wizualnego. Obsługuje kontekst 256K z silniejszymi zdolnościami łańcucha myślowego.",
  "Qwen/Qwen3-VL-32B-Instruct.description": "Qwen3-VL-32B-Instruct to model wizualno-językowy zespołu Qwen, osiągający czołowe wyniki SOTA w wielu testach VL. Obsługuje obrazy w rozdzielczości megapikselowej i oferuje silne rozumienie wizualne, wielojęzyczne OCR, precyzyjne osadzanie wizualne oraz dialog wizualny. Radzi sobie ze złożonymi zadaniami multimodalnymi i obsługuje wywoływanie narzędzi oraz uzupełnianie prefiksów.",
  "Qwen/Qwen3-VL-32B-Thinking.description": "Qwen3-VL-32B-Thinking jest zoptymalizowany do złożonego rozumowania wizualnego. Zawiera wbudowany tryb myślenia, który generuje pośrednie kroki rozumowania przed odpowiedziami, zwiększając logikę wieloetapową, planowanie i złożone rozumowanie. Obsługuje obrazy megapikselowe, silne rozumienie wizualne, wielojęzyczne OCR, precyzyjne osadzanie, dialog wizualny, wywoływanie narzędzi i uzupełnianie prefiksów.",
  "Qwen/Qwen3-VL-8B-Instruct.description": "Qwen3-VL-8B-Instruct to model wizualno-językowy Qwen3 oparty na Qwen3-8B-Instruct, trenowany na dużych zbiorach danych obraz-tekst. Wyróżnia się w ogólnym rozumieniu wizualnym, dialogu skoncentrowanym na obrazie oraz wielojęzycznym rozpoznawaniu tekstu w obrazach, odpowiedni do wizualnego QA, opisywania, multimodalnego podążania za instrukcjami i użycia narzędzi.",
  "Qwen/Qwen3-VL-8B-Thinking.description": "Qwen3-VL-8B-Thinking to wizualna wersja myśląca Qwen3, zoptymalizowana do złożonego rozumowania wieloetapowego. Generuje łańcuch myślowy przed odpowiedziami, aby poprawić dokładność, idealna do głębokiego wizualnego QA i szczegółowej analizy obrazów.",
  "Qwen2-72B-Instruct.description": "Qwen2 to najnowsza seria Qwen, obsługująca okno kontekstu 128k. W porównaniu z najlepszymi obecnie otwartymi modelami, Qwen2-72B znacznie przewyższa czołowe modele w zakresie rozumienia języka naturalnego, wiedzy, kodu, matematyki i możliwości wielojęzycznych.",
  "Qwen2-7B-Instruct.description": "Qwen2 to najnowsza seria Qwen, przewyższająca najlepsze otwarte modele o podobnej wielkości, a nawet większe. Qwen2 7B wykazuje znaczną przewagę w wielu testach, szczególnie w zakresie kodu i rozumienia języka chińskiego.",
  "Qwen2-VL-72B.description": "Qwen2-VL-72B to potężny model wizualno-językowy obsługujący przetwarzanie multimodalne obraz-tekst, dokładnie rozpoznający zawartość obrazów i generujący odpowiednie opisy lub odpowiedzi.",
  "Qwen2.5-14B-Instruct.description": "Qwen2.5-14B-Instruct to model językowy LLM z 14 miliardami parametrów, oferujący wysoką wydajność, zoptymalizowany pod kątem scenariuszy chińskich i wielojęzycznych, wspierający inteligentne pytania i odpowiedzi oraz generowanie treści.",
  "Qwen2.5-32B-Instruct.description": "Qwen2.5-32B-Instruct to model językowy LLM z 32 miliardami parametrów, oferujący zrównoważoną wydajność, zoptymalizowany pod kątem scenariuszy chińskich i wielojęzycznych, wspierający inteligentne pytania i odpowiedzi oraz generowanie treści.",
  "Qwen2.5-72B-Instruct.description": "Model LLM dla języka chińskiego i angielskiego, dostrojony do języka, kodowania, matematyki i rozumowania.",
  "Qwen2.5-7B-Instruct.description": "Qwen2.5-7B-Instruct to model językowy LLM z 7 miliardami parametrów, obsługujący wywoływanie funkcji i płynną integrację z systemami zewnętrznymi, znacznie zwiększając elastyczność i rozszerzalność. Zoptymalizowany pod kątem scenariuszy chińskich i wielojęzycznych, wspierający inteligentne pytania i odpowiedzi oraz generowanie treści.",
  "Qwen2.5-Coder-14B-Instruct.description": "Qwen2.5-Coder-14B-Instruct to duży model kodowania dostrojony do instrukcji, oferujący silne rozumienie i generowanie kodu. Skutecznie obsługuje szeroki zakres zadań programistycznych, idealny do inteligentnego kodowania, automatycznego generowania skryptów i pytań i odpowiedzi związanych z programowaniem.",
  "Qwen2.5-Coder-32B-Instruct.description": "Zaawansowany model LLM do generowania kodu, rozumowania i naprawy błędów w głównych językach programowania.",
  "Qwen3-235B-A22B-Instruct-2507-FP8.description": "Qwen3 235B A22B Instruct 2507 jest zoptymalizowany pod kątem zaawansowanego rozumowania i podążania za instrukcjami, wykorzystując architekturę MoE, aby zapewnić efektywność rozumowania w dużej skali.",
  "Qwen3-235B.description": "Qwen3-235B-A22B to model MoE, który wprowadza hybrydowy tryb rozumowania, umożliwiając użytkownikom płynne przełączanie się między trybem myślenia i niemyslenia. Obsługuje rozumienie i rozumowanie w 119 językach i dialektach oraz posiada silne możliwości wywoływania narzędzi, konkurując z głównymi modelami, takimi jak DeepSeek R1, OpenAI o1, o3-mini, Grok 3 i Google Gemini 2.5 Pro w testach ogólnych, kodowania i matematyki, możliwości wielojęzycznych oraz rozumowania wiedzy.",
  "Qwen3-32B.description": "Qwen3-32B to gęsty model, który wprowadza hybrydowy tryb rozumowania, umożliwiając użytkownikom przełączanie się między trybem myślenia i niemyslenia. Dzięki ulepszeniom architektury, większej ilości danych i lepszemu treningowi, osiąga wydajność porównywalną z Qwen2.5-72B.",
  "meta.llama3-8b-instruct-v1:0.description": "Meta Llama 3 to otwarty model językowy (LLM) stworzony z myślą o programistach, naukowcach i przedsiębiorstwach, zaprojektowany, by wspierać ich w budowaniu, eksperymentowaniu i odpowiedzialnym skalowaniu pomysłów z zakresu generatywnej sztucznej inteligencji. Jako fundament globalnej innowacji społecznościowej, doskonale sprawdza się przy ograniczonych zasobach obliczeniowych, na urządzeniach brzegowych oraz przy szybszym czasie trenowania.",
  "meta/Llama-3.2-11B-Vision-Instruct.description": "Zaawansowane rozumowanie obrazów w wysokiej rozdzielczości, idealne do aplikacji zrozumienia wizualnego.",
  "meta/Llama-3.2-90B-Vision-Instruct.description": "Zaawansowane rozumowanie obrazów dla aplikacji agentów opartych na zrozumieniu wizualnym.",
  "meta/Llama-3.3-70B-Instruct.description": "Llama 3.3 to najbardziej zaawansowany wielojęzyczny otwartoźródłowy model Llama, oferujący wydajność zbliżoną do modeli 405B przy bardzo niskim koszcie. Opiera się na architekturze Transformer i został udoskonalony za pomocą SFT i RLHF, by zwiększyć jego użyteczność i bezpieczeństwo. Wersja dostrojona do instrukcji została zoptymalizowana pod kątem wielojęzycznych rozmów i przewyższa wiele otwartych i zamkniętych modeli konwersacyjnych w branżowych testach. Data odcięcia wiedzy: grudzień 2023.",
  "meta/Meta-Llama-3-70B-Instruct.description": "Potężny model z 70 miliardami parametrów, doskonały w rozumowaniu, programowaniu i szerokim zakresie zadań językowych.",
  "meta/Meta-Llama-3-8B-Instruct.description": "Wszechstronny model z 8 miliardami parametrów, zoptymalizowany do rozmów i generowania tekstu.",
  "meta/Meta-Llama-3.1-405B-Instruct.description": "Model tekstowy Llama 3.1 dostrojony do instrukcji, zoptymalizowany pod kątem wielojęzycznych rozmów, osiągający wysokie wyniki w branżowych testach porównawczych wśród modeli otwartych i zamkniętych.",
  "meta/Meta-Llama-3.1-70B-Instruct.description": "Model tekstowy Llama 3.1 dostrojony do instrukcji, zoptymalizowany pod kątem wielojęzycznych rozmów, osiągający wysokie wyniki w branżowych testach porównawczych wśród modeli otwartych i zamkniętych.",
  "meta/Meta-Llama-3.1-8B-Instruct.description": "Model tekstowy Llama 3.1 dostrojony do instrukcji, zoptymalizowany pod kątem wielojęzycznych rozmów, osiągający wysokie wyniki w branżowych testach porównawczych wśród modeli otwartych i zamkniętych.",
  "meta/llama-3-70b.description": "Otwarty model z 70 miliardami parametrów, dostrojony przez Meta do podążania za instrukcjami, udostępniany przez Groq na sprzęcie LPU dla szybkiego i wydajnego wnioskowania.",
  "meta/llama-3-8b.description": "Otwarty model z 8 miliardami parametrów, dostrojony przez Meta do podążania za instrukcjami, udostępniany przez Groq na sprzęcie LPU dla szybkiego i wydajnego wnioskowania.",
  "meta/llama-3.1-405b-instruct.description": "Zaawansowany model LLM wspierający generowanie danych syntetycznych, destylację wiedzy i rozumowanie w chatbotach, programowaniu i zadaniach dziedzinowych.",
  "meta/llama-3.1-70b-instruct.description": "Zaprojektowany do złożonych dialogów z doskonałym rozumieniem kontekstu, rozumowaniem i generowaniem tekstu.",
  "meta/llama-3.1-70b.description": "Zaktualizowany model Meta Llama 3 70B Instruct z kontekstem 128K, wsparciem wielojęzycznym i ulepszonym rozumowaniem.",
  "meta/llama-3.1-8b-instruct.description": "Nowoczesny model z silnym rozumieniem języka, rozumowaniem i generowaniem tekstu.",
  "meta/llama-3.1-8b.description": "Llama 3.1 8B obsługuje okno kontekstu 128K, idealne do rozmów w czasie rzeczywistym i analizy danych, oferując znaczne oszczędności kosztów w porównaniu do większych modeli. Udostępniany przez Groq na sprzęcie LPU dla szybkiego i wydajnego wnioskowania.",
  "meta/llama-3.2-11b-vision-instruct.description": "Nowatorski model językowo-wizualny, który wyróżnia się wysokiej jakości rozumowaniem na podstawie obrazów.",
  "meta/llama-3.2-11b.description": "Model dostrojony do instrukcji w zakresie rozumowania obrazów (wejście: tekst + obraz, wyjście: tekst), zoptymalizowany do rozpoznawania wizualnego, rozumowania obrazów, opisywania i ogólnego QA obrazów.",
  "meta/llama-3.2-1b-instruct.description": "Nowoczesny mały model językowy z silnym rozumieniem, rozumowaniem i generowaniem tekstu.",
  "meta/llama-3.2-1b.description": "Model tylko tekstowy do zastosowań na urządzeniach, takich jak lokalne wyszukiwanie wielojęzyczne, streszczanie i przepisywanie.",
  "meta/llama-3.2-3b-instruct.description": "Nowoczesny mały model językowy z silnym rozumieniem, rozumowaniem i generowaniem tekstu.",
  "meta/llama-3.2-3b.description": "Model tylko tekstowy dostrojony do zastosowań na urządzeniach, takich jak lokalne wyszukiwanie wielojęzyczne, streszczanie i przepisywanie.",
  "meta/llama-3.2-90b-vision-instruct.description": "Nowatorski model językowo-wizualny, który wyróżnia się wysokiej jakości rozumowaniem na podstawie obrazów.",
  "meta/llama-3.2-90b.description": "Model dostrojony do instrukcji w zakresie rozumowania obrazów (wejście: tekst + obraz, wyjście: tekst), zoptymalizowany do rozpoznawania wizualnego, rozumowania obrazów, opisywania i ogólnego QA obrazów.",
  "meta/llama-3.3-70b-instruct.description": "Zaawansowany model LLM, silny w rozumowaniu, matematyce, zdrowym rozsądku i wywoływaniu funkcji.",
  "meta/llama-3.3-70b.description": "Idealne połączenie wydajności i efektywności. Zbudowany z myślą o wysokowydajnej konwersacyjnej AI w tworzeniu treści, aplikacjach biznesowych i badaniach, z silnym rozumieniem języka do streszczania, klasyfikacji, analizy sentymentu i generowania kodu.",
  "meta/llama-4-maverick.description": "Rodzina Llama 4 to natywne modele multimodalne wspierające tekst i doświadczenia multimodalne, wykorzystujące MoE do wiodącego rozumienia tekstu i obrazu. Llama 4 Maverick to model 17B z 128 ekspertami, udostępniany przez DeepInfra.",
  "meta/llama-4-scout.description": "Rodzina Llama 4 to natywne modele multimodalne wspierające tekst i doświadczenia multimodalne, wykorzystujące MoE do wiodącego rozumienia tekstu i obrazu. Llama 4 Scout to model 17B z 16 ekspertami, udostępniany przez DeepInfra.",
  "mistralai/Mistral-7B-v0.1.description": "Mistral 7B to kompaktowy, ale wydajny model, doskonały do przetwarzania wsadowego i prostych zadań, takich jak klasyfikacja i generowanie tekstu, z solidnym rozumowaniem.",
  "mistralai/Mixtral-8x22B-Instruct-v0.1.description": "Mixtral-8x22B Instruct (141B) to bardzo duży model językowy przeznaczony do obsługi wymagających obciążeń.",
  "mistralai/Mixtral-8x7B-Instruct-v0.1.description": "Mixtral-8x7B Instruct (46,7B) oferuje wysoką wydajność w przetwarzaniu danych na dużą skalę.",
  "mistralai/Mixtral-8x7B-v0.1.description": "Mixtral 8x7B to rzadki model MoE, który przyspiesza wnioskowanie i nadaje się do zadań wielojęzycznych oraz generowania kodu.",
  "mistralai/mistral-nemo.description": "Mistral Nemo to model 7,3B z obsługą wielu języków i silną wydajnością w programowaniu.",
  "mixtral-8x7b-32768.description": "Mixtral 8x7B zapewnia odporną na błędy równoległą moc obliczeniową do złożonych zadań.",
  "mixtral.description": "Mixtral to model MoE od Mistral AI z otwartymi wagami, wspierający generowanie kodu i rozumienie języka.",
  "mixtral:8x22b.description": "Mixtral to model MoE od Mistral AI z otwartymi wagami, wspierający generowanie kodu i rozumienie języka.",
  "moonshot-v1-128k-vision-preview.description": "Modele wizji Kimi (w tym moonshot-v1-8k-vision-preview/moonshot-v1-32k-vision-preview/moonshot-v1-128k-vision-preview) potrafią rozumieć zawartość obrazów, taką jak tekst, kolory i kształty obiektów.",
  "moonshot-v1-128k.description": "Moonshot V1 128K oferuje bardzo długi kontekst do generowania długich tekstów, obsługując do 128 000 tokenów w scenariuszach badawczych, akademickich i dokumentacyjnych.",
  "moonshot-v1-32k-vision-preview.description": "Modele wizji Kimi (w tym moonshot-v1-8k-vision-preview/moonshot-v1-32k-vision-preview/moonshot-v1-128k-vision-preview) potrafią rozumieć zawartość obrazów, taką jak tekst, kolory i kształty obiektów.",
  "moonshot-v1-32k.description": "Moonshot V1 32K obsługuje 32 768 tokenów dla średniej długości kontekstu, idealny do długich dokumentów i złożonych dialogów w tworzeniu treści, raportach i systemach czatu.",
  "moonshot-v1-8k-vision-preview.description": "Modele wizji Kimi (w tym moonshot-v1-8k-vision-preview/moonshot-v1-32k-vision-preview/moonshot-v1-128k-vision-preview) potrafią rozumieć zawartość obrazów, taką jak tekst, kolory i kształty obiektów.",
  "moonshot-v1-8k.description": "Moonshot V1 8K jest zoptymalizowany do generowania krótkich tekstów z wydajną pracą, obsługując 8192 tokeny do krótkich rozmów, notatek i szybkich treści.",
  "moonshot-v1-auto.description": "Moonshot V1 Auto automatycznie wybiera odpowiedni model na podstawie bieżącego użycia tokenów kontekstu.",
  "moonshotai/Kimi-Dev-72B.description": "Kimi-Dev-72B to otwartoźródłowy model kodu LLM zoptymalizowany za pomocą RL na dużą skalę, generujący solidne, gotowe do produkcji poprawki. Osiąga wynik 60,4% w SWE-bench Verified, ustanawiając nowy rekord wśród otwartych modeli dla zadań inżynierii oprogramowania, takich jak naprawa błędów i przegląd kodu.",
  "moonshotai/Kimi-K2-Instruct-0905.description": "Kimi K2-Instruct-0905 to najnowszy i najpotężniejszy model Kimi K2. To model MoE najwyższej klasy z 1T łącznych i 32B aktywnych parametrów. Kluczowe cechy to silniejsza inteligencja agentowa w kodowaniu, znaczne postępy w testach i zadaniach agentowych, a także ulepszona estetyka i użyteczność kodu frontendowego.",
  "moonshotai/Kimi-K2-Thinking.description": "Kimi K2 Thinking to najnowszy i najpotężniejszy otwartoźródłowy model myślenia. Znacznie zwiększa głębokość rozumowania wieloetapowego i utrzymuje stabilne użycie narzędzi przez 200–300 kolejnych wywołań, ustanawiając nowe rekordy w Humanity's Last Exam (HLE), BrowseComp i innych testach. Doskonale sprawdza się w kodowaniu, matematyce, logice i scenariuszach agentowych. Zbudowany na architekturze MoE z ~1T parametrów, obsługuje okno kontekstu 256K i wywoływanie narzędzi.",
  "moonshotai/kimi-k2-0711.description": "Kimi K2 0711 to wariant instruct z serii Kimi, odpowiedni do wysokiej jakości kodu i użycia narzędzi.",
  "moonshotai/kimi-k2-0905.description": "Kimi K2 0905 to aktualizacja rozszerzająca kontekst i wydajność rozumowania z optymalizacjami kodu.",
  "moonshotai/kimi-k2-instruct-0905.description": "Model kimi-k2-0905-preview obsługuje okno kontekstu 256K, z silniejszym kodowaniem agentowym, bardziej dopracowanym i praktycznym kodem frontendowym oraz lepszym rozumieniem kontekstu.",
  "moonshotai/kimi-k2-thinking-turbo.description": "Kimi K2 Thinking Turbo to szybka wersja Kimi K2 Thinking, znacznie zmniejszająca opóźnienia przy zachowaniu głębokiego rozumowania.",
  "moonshotai/kimi-k2-thinking.description": "Kimi K2 Thinking to model rozumowania Moonshot zoptymalizowany do zadań wymagających głębokiego rozumowania, z ogólnymi możliwościami agentowymi.",
  "moonshotai/kimi-k2.description": "Kimi K2 to duży model MoE od Moonshot AI z 1T łącznych parametrów i 32B aktywnych na przebieg, zoptymalizowany pod kątem możliwości agentowych, w tym zaawansowanego użycia narzędzi, rozumowania i syntezy kodu.",
  "morph/morph-v3-fast.description": "Morph to wyspecjalizowany model do stosowania zmian w kodzie sugerowanych przez czołowe modele (np. Claude lub GPT-4o) w istniejących plikach z prędkością 4500+ tokenów/sek. To końcowy etap w przepływie pracy AI w kodowaniu i obsługuje 16k tokenów wejścia/wyjścia.",
  "morph/morph-v3-large.description": "Morph to wyspecjalizowany model do stosowania zmian w kodzie sugerowanych przez czołowe modele (np. Claude lub GPT-4o) w istniejących plikach z prędkością 2500+ tokenów/sek. To końcowy etap w przepływie pracy AI w kodowaniu i obsługuje 16k tokenów wejścia/wyjścia.",
  "nousresearch/hermes-2-pro-llama-3-8b.description": "Hermes 2 Pro Llama 3 8B to zaktualizowana wersja Nous Hermes 2 z najnowszymi wewnętrznie opracowanymi zbiorami danych.",
  "nvidia/Llama-3.1-Nemotron-70B-Instruct-HF.description": "Llama 3.1 Nemotron 70B to dostosowany przez NVIDIA model LLM poprawiający pomocność. Osiąga najwyższe wyniki w Arena Hard, AlpacaEval 2 LC i GPT-4-Turbo MT-Bench, zajmując 1. miejsce we wszystkich trzech testach auto-alignment na dzień 1 października 2024. Trening oparty na Llama-3.1-70B-Instruct z użyciem RLHF (REINFORCE), Llama-3.1-Nemotron-70B-Reward i HelpSteer2-Preference prompts.",
  "nvidia/llama-3.1-nemotron-51b-instruct.description": "Wyjątkowy model językowy zapewniający doskonałą dokładność i wydajność.",
  "nvidia/llama-3.1-nemotron-70b-instruct.description": "Llama-3.1-Nemotron-70B-Instruct to dostosowany model NVIDIA zaprojektowany w celu poprawy pomocności odpowiedzi LLM.",
  "pixtral-12b-2409.description": "Pixtral doskonale radzi sobie z analizą wykresów i obrazów, odpowiadaniem na pytania dotyczące dokumentów, rozumowaniem multimodalnym oraz wykonywaniem poleceń. Obsługuje obrazy w natywnej rozdzielczości i proporcjach oraz dowolną liczbę obrazów w kontekście do 128K.",
  "pixtral-large-latest.description": "Pixtral Large to otwarty model multimodalny z 124 miliardami parametrów, oparty na Mistral Large 2 – drugiej generacji naszej rodziny modeli multimodalnych, oferujący zaawansowane rozumienie obrazów.",
  "pro-128k.description": "Spark Pro 128K oferuje bardzo dużą pojemność kontekstu – do 128K, idealną do analizy długich dokumentów wymagających pełnej analizy tekstu i spójności logicznej, z płynnym rozumowaniem i wsparciem dla różnorodnych cytowań w złożonych dyskusjach.",
  "pro-deepseek-r1.description": "Dedykowany model usługowy dla przedsiębiorstw z wbudowaną obsługą współbieżności.",
  "pro-deepseek-v3.description": "Dedykowany model usługowy dla przedsiębiorstw z wbudowaną obsługą współbieżności.",
  "qianfan-70b.description": "Qianfan 70B to duży chiński model do generowania wysokiej jakości treści i złożonego rozumowania.",
  "qianfan-8b.description": "Qianfan 8B to średniej wielkości model ogólnego przeznaczenia, łączący niskie koszty z wysoką jakością generowania tekstu i odpowiadania na pytania.",
  "qianfan-agent-intent-32k.description": "Qianfan Agent Intent 32K koncentruje się na rozpoznawaniu intencji i orkiestracji agentów z obsługą długiego kontekstu.",
  "qianfan-agent-lite-8k.description": "Qianfan Agent Lite 8K to lekki model agenta do tanich dialogów wieloetapowych i przepływów pracy.",
  "qianfan-agent-speed-32k.description": "Qianfan Agent Speed 32K to model agenta o wysokiej przepustowości, przeznaczony do aplikacji wielozadaniowych na dużą skalę.",
  "qianfan-agent-speed-8k.description": "Qianfan Agent Speed 8K to model agenta o wysokiej współbieżności, przeznaczony do krótkich i średnich rozmów z szybką odpowiedzią.",
  "qianfan-check-vl.description": "Qianfan Check VL to multimodalny model do przeglądu treści, oceniający zgodność obrazów i tekstów oraz wykonujący zadania rozpoznawania.",
  "qianfan-composition.description": "Qianfan Composition to multimodalny model twórczy do zrozumienia i generowania treści łączących obrazy i tekst.",
  "qianfan-engcard-vl.description": "Qianfan EngCard VL to multimodalny model rozpoznawania skoncentrowany na scenariuszach w języku angielskim.",
  "qianfan-lightning-128b-a19b.description": "Qianfan Lightning 128B A19B to wysokowydajny chiński model ogólnego przeznaczenia do złożonego odpowiadania na pytania i rozumowania na dużą skalę.",
  "qianfan-llama-vl-8b.description": "Qianfan Llama VL 8B to multimodalny model oparty na Llama, przeznaczony do ogólnego zrozumienia obrazów i tekstu.",
  "qianfan-multipicocr.description": "Qianfan MultiPicOCR to model OCR do wielu obrazów, wykrywający i rozpoznający tekst na różnych obrazach.",
  "qianfan-qi-vl.description": "Qianfan QI VL to multimodalny model QA do precyzyjnego wyszukiwania i odpowiadania na pytania w złożonych scenariuszach obraz-tekst.",
  "qianfan-singlepicocr.description": "Qianfan SinglePicOCR to model OCR do pojedynczych obrazów z wysoką dokładnością rozpoznawania znaków.",
  "qianfan-vl-70b.description": "Qianfan VL 70B to duży model językowo-wizualny do złożonego zrozumienia obrazów i tekstu.",
  "qianfan-vl-8b.description": "Qianfan VL 8B to lekki model językowo-wizualny do codziennego QA obraz-tekst i analizy.",
  "qvq-72b-preview.description": "QVQ-72B-Preview to eksperymentalny model badawczy od Qwen, skoncentrowany na ulepszonym rozumowaniu wizualnym.",
  "qvq-max.description": "Model rozumowania wizualnego Qwen QVQ obsługuje wejścia wizualne i wyjścia w formie łańcucha myśli, oferując lepsze wyniki w matematyce, kodowaniu, analizie wizualnej, twórczości i zadaniach ogólnych.",
  "qvq-plus.description": "Model rozumowania wizualnego z wejściem wizualnym i wyjściem w formie łańcucha myśli. Seria qvq-plus kontynuuje qvq-max, oferując szybsze rozumowanie przy lepszym stosunku jakości do kosztu.",
  "qwen-3-32b.description": "Qwen 3 32B: silny w zadaniach wielojęzycznych i programistycznych, odpowiedni do średnioskalowej produkcji.",
  "qwen-coder-plus.description": "Model kodowania Qwen.",
  "qwen-coder-turbo-latest.description": "Model kodowania Qwen.",
  "qwen-coder-turbo.description": "Model kodowania Qwen.",
  "qwen-flash.description": "Najszybszy i najtańszy model Qwen, idealny do prostych zadań.",
  "qwen-image-edit.description": "Qwen Image Edit to model obraz-do-obrazu, który edytuje obrazy na podstawie wejściowych obrazów i tekstowych poleceń, umożliwiając precyzyjne korekty i twórcze przekształcenia.",
  "qwen-image.description": "Qwen-Image to ogólny model generowania obrazów, obsługujący wiele stylów artystycznych i zaawansowane renderowanie złożonego tekstu, szczególnie w języku chińskim i angielskim. Obsługuje układy wieloliniowe, tekst na poziomie akapitu i drobne szczegóły w złożonych układach tekst-obraz.",
  "qwen-long.description": "Ultraduży model Qwen z długim kontekstem i możliwością prowadzenia rozmów obejmujących wiele dokumentów.",
  "qwen-math-plus-latest.description": "Qwen Math to model językowy wyspecjalizowany w rozwiązywaniu problemów matematycznych.",
  "qwen-math-plus.description": "Qwen Math to model językowy wyspecjalizowany w rozwiązywaniu problemów matematycznych.",
  "qwen-math-turbo-latest.description": "Qwen Math to model językowy wyspecjalizowany w rozwiązywaniu problemów matematycznych.",
  "qwen-math-turbo.description": "Qwen Math to model językowy wyspecjalizowany w rozwiązywaniu problemów matematycznych.",
  "qwen-max.description": "Model Qwen w skali setek miliardów parametrów, obsługujący język chiński, angielski i inne; model API wykorzystywany w produktach Qwen2.5.",
  "qwen-omni-turbo.description": "Modele Qwen-Omni obsługują wejścia multimodalne (wideo, audio, obrazy, tekst) i generują wyjścia w formie dźwięku i tekstu.",
  "qwen-plus.description": "Ulepszony ultraduży model Qwen obsługujący język chiński, angielski i inne języki.",
  "qwen-turbo.description": "Qwen Turbo nie będzie już aktualizowany; zalecana jest migracja do Qwen Flash. Ultraduży model Qwen obsługujący język chiński, angielski i inne języki.",
  "qwen-vl-chat-v1.description": "Qwen VL obsługuje elastyczne interakcje, w tym wejścia z wielu obrazów, wieloetapowe QA i zadania twórcze.",
  "qwen-vl-max-latest.description": "Ultraduży model językowo-wizualny Qwen. W porównaniu do wersji ulepszonej oferuje lepsze rozumowanie wizualne i wykonywanie poleceń, zapewniając silniejsze postrzeganie i poznanie.",
  "qwen-vl-max.description": "Ultraduży model językowo-wizualny Qwen. W porównaniu do wersji ulepszonej oferuje lepsze rozumowanie wizualne i wykonywanie poleceń, zapewniając silniejsze postrzeganie wizualne i poznanie.",
  "qwen-vl-ocr.description": "Qwen OCR to model ekstrakcji tekstu z dokumentów, tabel, obrazów egzaminacyjnych i rękopisów. Obsługuje język chiński, angielski, francuski, japoński, koreański, niemiecki, rosyjski, włoski, wietnamski i arabski.",
  "qwen-vl-plus-latest.description": "Ulepszony model językowo-wizualny Qwen na dużą skalę z dużym postępem w rozpoznawaniu szczegółów i tekstu, obsługujący rozdzielczość powyżej jednego megapiksela i dowolne proporcje obrazu.",
  "qwen-vl-plus.description": "Ulepszony model językowo-wizualny Qwen na dużą skalę z dużym postępem w rozpoznawaniu szczegółów i tekstu, obsługujący rozdzielczość powyżej jednego megapiksela i dowolne proporcje obrazu.",
  "qwen-vl-v1.description": "Model wstępnie wytrenowany na bazie Qwen-7B z dodanym modułem wizualnym i wejściem obrazu o rozdzielczości 448.",
  "qwen/qwen-2-7b-instruct.description": "Qwen2 to nowa seria dużych modeli językowych Qwen. Qwen2 7B to model oparty na transformatorze, który wyróżnia się w rozumieniu języka, wielojęzyczności, programowaniu, matematyce i rozumowaniu.",
  "qwen/qwen-2-7b-instruct:free.description": "Qwen2 to nowa rodzina dużych modeli językowych o lepszym rozumieniu i generowaniu treści.",
  "qwen2.5-7b-instruct.description": "Qwen2.5 7B Instruct to dojrzały, otwartoźródłowy model instrukcyjny do rozmów i generowania treści w różnych scenariuszach.",
  "qwen2.5-coder-1.5b-instruct.description": "Otwartoźródłowy model kodujący Qwen.",
  "qwen2.5-coder-14b-instruct.description": "Otwartoźródłowy model kodujący Qwen.",
  "qwen2.5-coder-32b-instruct.description": "Otwartoźródłowy model kodujący Qwen.",
  "qwen2.5-coder-7b-instruct.description": "Otwartoźródłowy model kodujący Qwen.",
  "qwen2.5-coder-instruct.description": "Qwen2.5-Coder to najnowszy model LLM z rodziny Qwen skoncentrowany na kodzie (wcześniej CodeQwen).",
  "qwen2.5-instruct.description": "Qwen2.5 to najnowsza seria modeli językowych Qwen, obejmująca modele bazowe i dostrojone instrukcyjnie od 0.5B do 72B parametrów.",
  "qwen2.5-math-1.5b-instruct.description": "Qwen-Math zapewnia wysoką skuteczność w rozwiązywaniu zadań matematycznych.",
  "qwen2.5-math-72b-instruct.description": "Qwen-Math zapewnia wysoką skuteczność w rozwiązywaniu zadań matematycznych.",
  "qwen2.5-math-7b-instruct.description": "Qwen-Math zapewnia wysoką skuteczność w rozwiązywaniu zadań matematycznych.",
  "qwen2.5-omni-7b.description": "Modele Qwen-Omni obsługują wejścia multimodalne (wideo, audio, obrazy, tekst) i generują wyjścia w formie dźwięku lub tekstu.",
  "qwen2.5-vl-32b-instruct.description": "Qwen2.5 VL 32B Instruct to otwartoźródłowy model multimodalny odpowiedni do prywatnego wdrożenia i zastosowań w różnych scenariuszach.",
  "qwen2.5-vl-72b-instruct.description": "Ulepszone podążanie za instrukcjami, matematyka, rozwiązywanie problemów i kodowanie, z lepszym rozpoznawaniem obiektów. Obsługuje precyzyjną lokalizację elementów wizualnych w różnych formatach, rozumienie długich filmów (do 10 minut) z dokładnością do sekundy, porządkowanie czasowe i rozumienie prędkości, a także agentów sterujących systemem operacyjnym lub urządzeniami mobilnymi poprzez analizę i lokalizację. Silne wydobywanie kluczowych informacji i generowanie danych w formacie JSON. To wersja 72B – najmocniejsza w serii.",
  "qwen2.5-vl-7b-instruct.description": "Qwen2.5 VL 7B Instruct to lekki model multimodalny łączący niskie koszty wdrożenia z dobrą zdolnością rozpoznawania.",
  "qwen2.5-vl-instruct.description": "Qwen2.5-VL to najnowszy model językowo-wizualny z rodziny Qwen.",
  "qwen2.5.description": "Qwen2.5 to nowej generacji duży model językowy Alibaba o wysokiej wydajności w różnych zastosowaniach.",
  "qwen2.5:0.5b.description": "Qwen2.5 to nowej generacji duży model językowy Alibaba o wysokiej wydajności w różnych zastosowaniach.",
  "qwen2.5:1.5b.description": "Qwen2.5 to nowej generacji duży model językowy Alibaba o wysokiej wydajności w różnych zastosowaniach.",
  "qwen2.5:72b.description": "Qwen2.5 to nowej generacji duży model językowy Alibaba o wysokiej wydajności w różnych zastosowaniach.",
  "qwen2.description": "Qwen2 to nowej generacji duży model językowy Alibaba o wysokiej wydajności w różnych zastosowaniach.",
  "qwen2:0.5b.description": "Qwen2 to nowej generacji duży model językowy Alibaba o wysokiej wydajności w różnych zastosowaniach.",
  "qwen2:1.5b.description": "Qwen2 to nowej generacji duży model językowy Alibaba o wysokiej wydajności w różnych zastosowaniach.",
  "qwen2:72b.description": "Qwen2 to nowej generacji duży model językowy Alibaba o wysokiej wydajności w różnych zastosowaniach.",
  "qwen3-0.6b.description": "Qwen3 0.6B to model podstawowy do prostego rozumowania i bardzo ograniczonych środowisk.",
  "qwen3-1.7b.description": "Qwen3 1.7B to ultralekki model do wdrożeń na urządzeniach brzegowych.",
  "qwen3-14b.description": "Qwen3 14B to średniej wielkości model do wielojęzycznego QA i generowania tekstu.",
  "qwen3-235b-a22b-instruct-2507.description": "Qwen3 235B A22B Instruct 2507 to flagowy model instrukcyjny do szerokiego zakresu zadań generacyjnych i rozumowania.",
  "qwen3-235b-a22b-thinking-2507.description": "Qwen3 235B A22B Thinking 2507 to ultraduży model myślący do trudnych zadań wymagających rozumowania.",
  "qwen3-235b-a22b.description": "Qwen3 235B A22B to ogólny duży model do złożonych zadań.",
  "qwen3-30b-a3b-instruct-2507.description": "Qwen3 30B A3B Instruct 2507 to średnio-duży model instrukcyjny do wysokiej jakości generowania i QA.",
  "qwen3-30b-a3b-thinking-2507.description": "Qwen3 30B A3B Thinking 2507 to średnio-duży model myślący, łączący dokładność i efektywność kosztową.",
  "qwen3-30b-a3b.description": "Qwen3 30B A3B to średnio-duży model ogólny, równoważący koszty i jakość.",
  "qwen3-32b.description": "Qwen3 32B nadaje się do ogólnych zadań wymagających lepszego rozumienia.",
  "qwen3-4b.description": "Qwen3 4B nadaje się do małych i średnich aplikacji oraz lokalnego wnioskowania.",
  "qwen3-8b.description": "Qwen3 8B to lekki model z elastycznym wdrożeniem do obciążeń o wysokiej równoczesności.",
  "qwen3-coder-30b-a3b-instruct.description": "Otwartoźródłowy model kodujący Qwen. Najnowszy qwen3-coder-30b-a3b-instruct oparty jest na Qwen3 i oferuje zaawansowane możliwości agenta kodującego, korzystania z narzędzi i interakcji ze środowiskiem do autonomicznego programowania, z doskonałą wydajnością kodu i solidnymi zdolnościami ogólnymi.",
  "qwen3-coder-480b-a35b-instruct.description": "Qwen3 Coder 480B A35B Instruct to flagowy model kodujący do programowania wielojęzycznego i złożonego rozumienia kodu.",
  "qwen3-coder-flash.description": "Model kodujący Qwen. Najnowsza seria Qwen3-Coder oparta jest na Qwen3 i oferuje zaawansowane możliwości agenta kodującego, korzystania z narzędzi i interakcji ze środowiskiem do autonomicznego programowania, z doskonałą wydajnością kodu i solidnymi zdolnościami ogólnymi.",
  "qwen3-coder-plus.description": "Model kodujący Qwen. Najnowsza seria Qwen3-Coder oparta jest na Qwen3 i oferuje zaawansowane możliwości agenta kodującego, korzystania z narzędzi i interakcji ze środowiskiem do autonomicznego programowania, z doskonałą wydajnością kodu i solidnymi zdolnościami ogólnymi.",
  "qwen3-coder:480b.description": "Wysokowydajny model Alibaba do zadań agenta i kodowania z długim kontekstem.",
  "qwen3-max-preview.description": "Najlepszy model Qwen do złożonych, wieloetapowych zadań. Wersja podglądowa obsługuje myślenie.",
  "qwen3-max.description": "Modele Qwen3 Max oferują znaczne ulepszenia względem serii 2.5 w zakresie ogólnych zdolności, rozumienia chińskiego/angielskiego, złożonych instrukcji, zadań otwartych, wielojęzyczności i korzystania z narzędzi, z mniejszą liczbą halucynacji. Najnowszy qwen3-max poprawia programowanie agentowe i korzystanie z narzędzi względem qwen3-max-preview. Wersja ta osiąga SOTA w swojej klasie i jest przeznaczona do bardziej złożonych potrzeb agentów.",
  "qwen3-next-80b-a3b-instruct.description": "Nowej generacji otwartoźródłowy model Qwen3 bez myślenia. W porównaniu do poprzedniej wersji (Qwen3-235B-A22B-Instruct-2507) oferuje lepsze rozumienie chińskiego, silniejsze rozumowanie logiczne i ulepszone generowanie tekstu.",
  "qwen3-next-80b-a3b-thinking.description": "Qwen3 Next 80B A3B Thinking to flagowa wersja modelu rozumującego do złożonych zadań.",
  "qwen3-omni-flash.description": "Qwen-Omni przyjmuje połączone dane wejściowe z tekstu, obrazów, dźwięku i wideo, a generuje tekst lub mowę. Oferuje wiele naturalnych stylów głosu, obsługuje mowę wielojęzyczną i dialektyczną, i nadaje się do zastosowań takich jak pisanie, rozpoznawanie wizji i asystenci głosowi.",
  "qwen3-vl-235b-a22b-instruct.description": "Qwen3 VL 235B A22B Instruct to flagowy model multimodalny do wymagających zadań rozumienia i tworzenia treści.",
  "qwen3-vl-235b-a22b-thinking.description": "Qwen3 VL 235B A22B Thinking to flagowa wersja myśląca do złożonego multimodalnego rozumowania i planowania.",
  "qwen3-vl-30b-a3b-instruct.description": "Qwen3 VL 30B A3B Instruct to duży model multimodalny równoważący dokładność i wydajność rozumowania.",
  "qwen3-vl-30b-a3b-thinking.description": "Qwen3 VL 30B A3B Thinking to wersja głęboko rozumująca do złożonych zadań multimodalnych.",
  "qwen3-vl-32b-instruct.description": "Qwen3 VL 32B Instruct to multimodalny model dostrojony instrukcyjnie do wysokiej jakości QA obraz-tekst i tworzenia treści.",
  "qwen3-vl-32b-thinking.description": "Qwen3 VL 32B Thinking to głęboko rozumująca wersja multimodalna do złożonego rozumowania i analizy łańcuchowej.",
  "qwen3-vl-8b-instruct.description": "Qwen3 VL 8B Instruct to lekki model multimodalny do codziennego QA wizualnego i integracji z aplikacjami.",
  "qwen3-vl-8b-thinking.description": "Qwen3 VL 8B Thinking to multimodalny model łańcucha myśli do szczegółowego rozumowania wizualnego.",
  "qwen3-vl-flash.description": "Qwen3 VL Flash: lekka, szybka wersja rozumująca do zadań wrażliwych na opóźnienia lub o dużym wolumenie.",
  "qwen3-vl-plus.description": "Qwen VL to model generowania tekstu z rozumieniem wizji. Potrafi wykonywać OCR, podsumowywać i rozumować, np. wyodrębniać atrybuty ze zdjęć produktów lub rozwiązywać problemy na podstawie obrazów.",
  "qwen3.description": "Qwen3 to nowej generacji duży model językowy Alibaba o wysokiej wydajności w różnych zastosowaniach.",
  "taichu_o1.description": "taichu_o1 to nowej generacji model rozumowania, który wykorzystuje interakcję multimodalną i uczenie przez wzmacnianie do osiągnięcia ludzkiego łańcucha myślowego. Obsługuje symulację złożonych decyzji, ujawnia ścieżki rozumowania przy zachowaniu wysokiej dokładności wyników, idealny do analizy strategicznej i głębokiego myślenia.",
  "taichu_vl.description": "Łączy rozumienie obrazu, transfer wiedzy i logiczną atrybucję, wyróżniając się w zadaniach pytanie-odpowiedź obraz-tekst.",
  "tencent/Hunyuan-A13B-Instruct.description": "Hunyuan-A13B-Instruct wykorzystuje 80 miliardów parametrów całkowitych, z czego 13 miliardów aktywnych, aby dorównać większym modelom. Obsługuje hybrydowe rozumowanie szybkie/wolne, stabilne rozumienie długich tekstów i wiodące możliwości agenta w BFCL-v3 i τ-Bench. GQA i formaty wielokrotnej kwantyzacji umożliwiają wydajne wnioskowanie.",
  "tencent/Hunyuan-MT-7B.description": "Model tłumaczeniowy Hunyuan obejmuje Hunyuan-MT-7B oraz zespół Hunyuan-MT-Chimera. Hunyuan-MT-7B to lekki model tłumaczeniowy o 7 miliardach parametrów, obsługujący 33 języki oraz 5 języków mniejszości chińskich. W WMT25 zdobył 30 pierwszych miejsc w 31 parach językowych. Tencent Hunyuan wykorzystuje pełny cykl treningowy od pretreningu przez SFT po RL tłumaczeniowe i zespołowe, osiągając wiodącą wydajność przy łatwym wdrożeniu.",
  "text-embedding-3-large.description": "Najbardziej zaawansowany model osadzania tekstu dla zadań w języku angielskim i innych.",
  "text-embedding-3-small.description": "Wydajny, opłacalny model osadzania nowej generacji do wyszukiwania i scenariuszy RAG.",
  "thudm/glm-4-32b.description": "GLM-4-32B-0414 to 32-miliardowy model dwujęzyczny (chiński/angielski) z otwartymi wagami, zoptymalizowany do generowania kodu, wywoływania funkcji i zadań agenta. Trenowany na 15T wysokiej jakości danych z naciskiem na rozumowanie, udoskonalony przez dopasowanie do preferencji użytkownika, próbkowanie odrzuceń i RL. Wyróżnia się w złożonym rozumowaniu, generowaniu artefaktów i strukturze wyjściowej, osiągając poziom GPT-4o i DeepSeek-V3-0324 w wielu benchmarkach.",
  "thudm/glm-4-32b:free.description": "GLM-4-32B-0414 to 32-miliardowy model dwujęzyczny (chiński/angielski) z otwartymi wagami, zoptymalizowany do generowania kodu, wywoływania funkcji i zadań agenta. Trenowany na 15T wysokiej jakości danych z naciskiem na rozumowanie, udoskonalony przez dopasowanie do preferencji użytkownika, próbkowanie odrzuceń i RL. Wyróżnia się w złożonym rozumowaniu, generowaniu artefaktów i strukturze wyjściowej, osiągając poziom GPT-4o i DeepSeek-V3-0324 w wielu benchmarkach.",
  "thudm/glm-4-9b-chat.description": "Wersja open-source najnowszego modelu pretreningowego GLM-4 od Zhipu AI.",
  "thudm/glm-z1-32b.description": "GLM-Z1-32B-0414 to ulepszona wersja rozumowania modelu GLM-4-32B, stworzona do głębokiego rozwiązywania problemów matematycznych, logicznych i kodowych. Wykorzystuje rozszerzone RL (specyficzne dla zadań i ogólne preferencje parowe), aby poprawić złożone zadania wieloetapowe. W porównaniu do GLM-4-32B, Z1 znacząco poprawia rozumowanie strukturalne i zdolności w formalnych dziedzinach.\n\nObsługuje wymuszanie kroków „myślenia” przez inżynierię promptów, poprawioną spójność długich odpowiedzi i jest zoptymalizowany do przepływów pracy agentów z długim kontekstem (przez YaRN), wywoływaniem narzędzi JSON i precyzyjnym próbkowaniem dla stabilnego rozumowania. Idealny do przypadków wymagających starannego rozumowania wieloetapowego lub formalnych wyprowadzeń.",
  "thudm/glm-z1-rumination-32b.description": "GLM Z1 Rumination 32B to 32-miliardowy model głębokiego rozumowania z serii GLM-4-Z1, zoptymalizowany do złożonych, otwartych zadań wymagających długiego myślenia. Bazując na glm-4-32b-0414, dodaje dodatkowe etapy RL i wieloetapowe dopasowanie, wprowadzając zdolność „rozmyślania”, która symuluje rozszerzone przetwarzanie poznawcze. Obejmuje to iteracyjne rozumowanie, analizę wieloetapową i przepływy pracy wspomagane narzędziami, takie jak wyszukiwanie, pobieranie i synteza z uwzględnieniem cytowań.\n\nWyróżnia się w pisaniu naukowym, analizie porównawczej i złożonych pytaniach. Obsługuje wywoływanie funkcji dla prymitywów wyszukiwania/nawigacji (`search`, `click`, `open`, `finish`) w pipeline'ach agentów. Zachowanie rozmyślania jest kontrolowane przez pętle wieloetapowe z kształtowaniem nagród opartym na regułach i opóźnionymi decyzjami, testowane w porównaniu do głębokich frameworków badawczych, takich jak wewnętrzny stos dopasowania OpenAI. Ta wersja stawia na głębię zamiast szybkości.",
  "tngtech/deepseek-r1t-chimera:free.description": "DeepSeek-R1T-Chimera powstał przez połączenie DeepSeek-R1 i DeepSeek-V3 (0324), łącząc rozumowanie R1 z efektywnością tokenów V3. Bazuje na transformatorze DeepSeek-MoE i jest zoptymalizowany do ogólnej generacji tekstu.\n\nŁączy wagi pretrenowane, aby zrównoważyć rozumowanie, wydajność i podążanie za instrukcjami. Wydany na licencji MIT do użytku badawczego i komercyjnego.",
  "togethercomputer/StripedHyena-Nous-7B.description": "StripedHyena Nous (7B) zapewnia zwiększoną wydajność obliczeniową dzięki swojej architekturze i strategii.",
  "tts-1-hd.description": "Najnowszy model tekst-na-mowę zoptymalizowany pod kątem jakości.",
  "tts-1.description": "Najnowszy model tekst-na-mowę zoptymalizowany pod kątem szybkości działania w czasie rzeczywistym.",
  "upstage/SOLAR-10.7B-Instruct-v1.0.description": "Upstage SOLAR Instruct v1 (11B) jest dostrojony do precyzyjnych zadań instrukcyjnych z silną wydajnością językową.",
  "us.anthropic.claude-3-5-sonnet-20241022-v2:0.description": "Claude 3.5 Sonnet podnosi standard branżowy, przewyższając konkurencję i Claude 3 Opus w szerokich ocenach, zachowując jednocześnie średni poziom szybkości i kosztów.",
  "us.anthropic.claude-3-7-sonnet-20250219-v1:0.description": "Claude 3.7 Sonnet to najszybszy model nowej generacji od Anthropic. W porównaniu do Claude 3 Haiku poprawia się we wszystkich umiejętnościach i przewyższa poprzedni flagowy model Claude 3 Opus w wielu benchmarkach inteligencji.",
  "us.anthropic.claude-haiku-4-5-20251001-v1:0.description": "Claude Haiku 4.5 to najszybszy i najbardziej inteligentny model Haiku od Anthropic, oferujący błyskawiczną szybkość i rozszerzone myślenie.",
  "us.anthropic.claude-sonnet-4-5-20250929-v1:0.description": "Claude Sonnet 4.5 to najbardziej inteligentny model Anthropic do tej pory.",
  "v0-1.0-md.description": "v0-1.0-md to model starszej generacji udostępniany przez API v0.",
  "v0-1.5-lg.description": "v0-1.5-lg jest odpowiedni do zaawansowanych zadań myślowych i rozumowania.",
  "v0-1.5-md.description": "v0-1.5-md jest odpowiedni do codziennych zadań i generowania interfejsów użytkownika.",
  "vercel/v0-1.0-md.description": "Uzyskaj dostęp do modeli stojących za v0, aby generować, naprawiać i optymalizować nowoczesne aplikacje webowe z rozumowaniem specyficznym dla frameworków i aktualną wiedzą.",
  "vercel/v0-1.5-md.description": "Uzyskaj dostęp do modeli stojących za v0, aby generować, naprawiać i optymalizować nowoczesne aplikacje webowe z rozumowaniem specyficznym dla frameworków i aktualną wiedzą.",
  "volcengine/doubao-seed-code.description": "Doubao-Seed-Code to model LLM od ByteDance Volcano Engine zoptymalizowany do programowania agentowego, osiągający wysokie wyniki w benchmarkach programistycznych i agentowych z obsługą kontekstu 256K.",
  "wan2.2-t2i-flash.description": "Wanxiang 2.2 Speed to najnowszy model z ulepszeniami w zakresie kreatywności, stabilności i realizmu, oferujący szybkie generowanie i wysoką wartość.",
  "wan2.2-t2i-plus.description": "Wanxiang 2.2 Pro to najnowszy model z ulepszeniami w zakresie kreatywności, stabilności i realizmu, generujący bogatsze detale.",
  "wanx-v1.description": "Bazowy model tekst-na-obraz. Odpowiada Tongyi Wanxiang 1.0 General.",
  "wanx2.0-t2i-turbo.description": "Wyróżnia się w portretach z teksturą przy umiarkowanej szybkości i niższym koszcie. Odpowiada Tongyi Wanxiang 2.0 Speed.",
  "wanx2.1-t2i-plus.description": "W pełni zaktualizowana wersja z bogatszymi detalami obrazu i nieco wolniejszą szybkością. Odpowiada Tongyi Wanxiang 2.1 Pro.",
  "wanx2.1-t2i-turbo.description": "W pełni zaktualizowana wersja z szybkim generowaniem, wysoką jakością ogólną i dużą wartością. Odpowiada Tongyi Wanxiang 2.1 Speed.",
  "whisper-1.description": "Ogólny model rozpoznawania mowy obsługujący wielojęzyczne ASR, tłumaczenie mowy i identyfikację języka.",
  "wizardlm2.description": "WizardLM 2 to model językowy od Microsoft AI, który wyróżnia się w złożonych dialogach, zadaniach wielojęzycznych, rozumowaniu i asystentach.",
  "wizardlm2:8x22b.description": "WizardLM 2 to model językowy od Microsoft AI, który wyróżnia się w złożonych dialogach, zadaniach wielojęzycznych, rozumowaniu i asystentach.",
  "z-ai/glm-4.5-air.description": "GLM 4.5 Air to lekka wersja GLM 4.5 przeznaczona do scenariuszy wrażliwych na koszty, zachowująca jednocześnie wysoką jakość rozumowania.",
  "z-ai/glm-4.5.description": "GLM 4.5 to flagowy model Z.AI z hybrydowym rozumowaniem, zoptymalizowany do zadań inżynieryjnych i pracy z długim kontekstem.",
  "z-ai/glm-4.6.description": "GLM 4.6 to flagowy model Z.AI z rozszerzoną długością kontekstu i zaawansowanymi możliwościami kodowania.",
  "zai-glm-4.6.description": "Osiąga wysokie wyniki w zadaniach związanych z kodowaniem i rozumowaniem, obsługuje strumieniowanie i wywołania narzędzi, idealnie nadaje się do kodowania agentowego i złożonego rozumowania.",
  "zai-org/GLM-4.5-Air.description": "GLM-4.5-Air to bazowy model dla aplikacji agentowych, oparty na architekturze Mixture-of-Experts. Zoptymalizowany do korzystania z narzędzi, przeglądania internetu, inżynierii oprogramowania i kodowania frontendowego. Integruje się z agentami kodu, takimi jak Claude Code i Roo Code. Wykorzystuje hybrydowe rozumowanie do obsługi zarówno złożonych, jak i codziennych scenariuszy.",
  "zai-org/GLM-4.5.description": "GLM-4.5 to bazowy model stworzony dla aplikacji agentowych, oparty na architekturze Mixture-of-Experts. Głęboko zoptymalizowany do korzystania z narzędzi, przeglądania internetu, inżynierii oprogramowania i kodowania frontendowego. Integruje się z agentami kodu, takimi jak Claude Code i Roo Code. Wykorzystuje hybrydowe rozumowanie do obsługi zarówno złożonych, jak i codziennych scenariuszy.",
  "zai-org/GLM-4.5V.description": "GLM-4.5V to najnowszy VLM Zhipu AI, oparty na flagowym modelu tekstowym GLM-4.5-Air (106B parametrów ogółem, 12B aktywnych) z architekturą MoE zapewniającą wysoką wydajność przy niższych kosztach. Podąża ścieżką GLM-4.1V-Thinking i dodaje 3D-RoPE dla lepszego rozumienia przestrzeni 3D. Zoptymalizowany poprzez pretrening, SFT i RL, obsługuje obrazy, wideo i długie dokumenty, zajmując czołowe miejsca wśród otwartych modeli w 41 publicznych benchmarkach multimodalnych. Przełącznik trybu Thinking pozwala użytkownikom balansować między szybkością a głębokością analizy.",
  "zai-org/GLM-4.6.description": "W porównaniu do GLM-4.5, GLM-4.6 rozszerza kontekst z 128K do 200K, umożliwiając realizację bardziej złożonych zadań agentowych. Osiąga lepsze wyniki w benchmarkach kodu i wykazuje wyższą skuteczność w aplikacjach takich jak Claude Code, Cline, Roo Code i Kilo Code, w tym lepsze generowanie stron frontendowych. Ulepszono rozumowanie oraz obsługę narzędzi w trakcie rozumowania, co wzmacnia ogólne możliwości. Lepsza integracja z frameworkami agentowymi, usprawnione działanie agentów narzędziowych i wyszukiwawczych oraz bardziej naturalny styl pisania i odgrywania ról preferowany przez użytkowników.",
  "zai/glm-4.5-air.description": "GLM-4.5 i GLM-4.5-Air to nasze najnowsze flagowe modele dla aplikacji agentowych, oba oparte na architekturze MoE. GLM-4.5 ma 355B parametrów ogółem i 32B aktywnych na jedno przejście; GLM-4.5-Air jest lżejszy – 106B ogółem i 12B aktywnych.",
  "zai/glm-4.5.description": "Seria GLM-4.5 została zaprojektowana z myślą o agentach. Flagowy model GLM-4.5 łączy rozumowanie, kodowanie i umiejętności agentowe, posiada 355B parametrów ogółem (32B aktywnych) i oferuje dwa tryby działania jako system hybrydowego rozumowania.",
  "zai/glm-4.5v.description": "GLM-4.5V bazuje na GLM-4.5-Air, dziedzicząc sprawdzone techniki GLM-4.1V-Thinking i skalując się dzięki silnej architekturze MoE z 106 miliardami parametrów.",
  "zenmux/auto.description": "Automatyczne trasowanie ZenMux wybiera najlepiej wyceniony i najbardziej wydajny model spośród obsługiwanych opcji na podstawie Twojego zapytania."
}
