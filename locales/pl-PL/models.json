{
  "01-ai/yi-1.5-34b-chat.description": "Najnowszy otwartoźródłowy model 01.AI z 34 miliardami parametrów, dostosowany do różnych scenariuszy dialogowych, wytrenowany na wysokiej jakości danych i zgodny z preferencjami użytkowników.",
  "01-ai/yi-1.5-9b-chat.description": "Najnowszy otwartoźródłowy model 01.AI z 9 miliardami parametrów, dostosowany do różnych scenariuszy dialogowych, wytrenowany na wysokiej jakości danych i zgodny z preferencjami użytkowników.",
  "360/deepseek-r1.description": "DeepSeek-R1 wdrożony przez 360 wykorzystuje uczenie przez wzmocnienie na dużą skalę w fazie post-treningowej, znacząco poprawiając zdolności rozumowania przy minimalnym oznakowaniu danych. Dorównuje modelowi OpenAI o1 w zadaniach z matematyki, kodowania i rozumowania językowego.",
  "360gpt-pro-trans.description": "Model wyspecjalizowany w tłumaczeniach, głęboko dostrojony w celu zapewnienia najwyższej jakości przekładów.",
  "360gpt-pro.description": "360GPT Pro to kluczowy model AI od 360, zapewniający wydajne przetwarzanie tekstu w różnorodnych scenariuszach NLP, wspierający rozumienie długich tekstów i dialogi wieloetapowe.",
  "360gpt-turbo-responsibility-8k.description": "360GPT Turbo Responsibility 8K kładzie nacisk na bezpieczeństwo semantyczne i odpowiedzialność w aplikacjach wrażliwych na treść, zapewniając dokładne i niezawodne doświadczenia użytkownika.",
  "360gpt-turbo.description": "360GPT Turbo oferuje wysoką wydajność obliczeniową i zdolności konwersacyjne z doskonałym rozumieniem semantycznym i efektywnością generowania, idealny dla firm i deweloperów.",
  "360gpt2-o1.description": "360gpt2-o1 buduje łańcuch rozumowania poprzez przeszukiwanie drzewa z mechanizmem refleksji i treningiem RL, umożliwiając samorefleksję i autokorektę.",
  "360gpt2-pro.description": "360GPT2 Pro to zaawansowany model NLP od 360, oferujący doskonałe generowanie i rozumienie tekstu, szczególnie w zadaniach kreatywnych, transformacjach i odgrywaniu ról.",
  "360zhinao2-o1.description": "360zhinao2-o1 buduje łańcuch rozumowania poprzez przeszukiwanie drzewa z mechanizmem refleksji i treningiem RL, umożliwiając samorefleksję i autokorektę.",
  "4.0Ultra.description": "Spark Ultra to najpotężniejszy model z serii Spark, ulepszający rozumienie tekstu i podsumowywanie oraz wzbogacający wyszukiwanie internetowe. Stanowi kompleksowe rozwiązanie zwiększające produktywność w pracy i dokładność odpowiedzi, pozycjonując się jako wiodący produkt inteligentny.",
  "AnimeSharp.description": "AnimeSharp (znany również jako „4x-AnimeSharp”) to otwartoźródłowy model super-rozdzielczości oparty na ESRGAN autorstwa Kim2091, skoncentrowany na skalowaniu i wyostrzaniu obrazów w stylu anime. W lutym 2022 roku zmieniono jego nazwę z „4x-TextSharpV1”, pierwotnie przeznaczonego również do obrazów tekstowych, ale silnie zoptymalizowanego pod kątem treści anime.",
  "Baichuan2-Turbo.description": "Wykorzystuje rozszerzenie wyszukiwania do połączenia modelu z wiedzą dziedzinową i internetową. Obsługuje przesyłanie plików PDF/Word oraz wprowadzanie adresów URL w celu szybkiego i kompleksowego pozyskiwania informacji oraz generowania profesjonalnych i dokładnych wyników.",
  "Baichuan3-Turbo-128k.description": "Dzięki ultradługiemu oknu kontekstowemu 128K, zoptymalizowany pod kątem intensywnych zastosowań biznesowych, oferuje znaczące korzyści i wysoką wartość. W porównaniu z Baichuan2, tworzenie treści poprawia się o 20%, pytania i odpowiedzi oparte na wiedzy o 17%, a odgrywanie ról o 40%. Ogólna wydajność przewyższa GPT-3.5.",
  "Baichuan3-Turbo.description": "Zoptymalizowany pod kątem intensywnych zastosowań biznesowych, oferuje znaczące korzyści i wysoką wartość. W porównaniu z Baichuan2, tworzenie treści poprawia się o 20%, pytania i odpowiedzi oparte na wiedzy o 17%, a odgrywanie ról o 40%. Ogólna wydajność przewyższa GPT-3.5.",
  "Baichuan4-Air.description": "Model o najwyższej wydajności w Chinach, przewyższający czołowe modele zagraniczne w zadaniach w języku chińskim, takich jak wiedza, długie teksty i generowanie kreatywne. Posiada również wiodące w branży możliwości multimodalne i osiąga wysokie wyniki w autorytatywnych testach porównawczych.",
  "Baichuan4-Turbo.description": "Model o najwyższej wydajności w Chinach, przewyższający czołowe modele zagraniczne w zadaniach w języku chińskim, takich jak wiedza, długie teksty i generowanie kreatywne. Posiada również wiodące w branży możliwości multimodalne i osiąga wysokie wyniki w autorytatywnych testach porównawczych.",
  "Baichuan4.description": "Najlepsza krajowa wydajność, przewyższająca czołowe modele zagraniczne w zadaniach w języku chińskim, takich jak wiedza encyklopedyczna, długie teksty i generowanie kreatywne. Oferuje również wiodące w branży możliwości multimodalne i wysokie wyniki w testach porównawczych.",
  "ByteDance-Seed/Seed-OSS-36B-Instruct.description": "Seed-OSS to rodzina otwartoźródłowych modeli LLM od ByteDance Seed, zaprojektowana z myślą o obsłudze długiego kontekstu, rozumowaniu, zadaniach agentowych i ogólnych możliwościach. Seed-OSS-36B-Instruct to model z 36 miliardami parametrów dostrojony do instrukcji, z natywnym ultradługim kontekstem do przetwarzania dużych dokumentów lub baz kodu. Zoptymalizowany pod kątem rozumowania, generowania kodu i zadań agentowych (użycie narzędzi), zachowując przy tym silne ogólne zdolności. Kluczową cechą jest „Budżet Myślenia”, umożliwiający elastyczną długość rozumowania w celu poprawy wydajności.",
  "DeepSeek-R1-Distill-Llama-70B.description": "DeepSeek R1, większy i inteligentniejszy model z pakietu DeepSeek, został zdestylowany do architektury Llama 70B. Testy porównawcze i oceny ludzkie pokazują, że jest inteligentniejszy niż bazowy Llama 70B, szczególnie w zadaniach matematycznych i wymagających precyzji faktów.",
  "DeepSeek-R1-Distill-Qwen-1.5B.description": "Model zdestylowany z DeepSeek-R1 oparty na Qwen2.5-Math-1.5B. Uczenie przez wzmocnienie i dane startowe optymalizują wydajność rozumowania, ustanawiając nowe standardy w zadaniach wielozadaniowych dla modeli otwartych.",
  "DeepSeek-R1-Distill-Qwen-14B.description": "Modele DeepSeek-R1-Distill są dostrajane z otwartoźródłowych modeli przy użyciu danych próbnych generowanych przez DeepSeek-R1.",
  "DeepSeek-R1-Distill-Qwen-32B.description": "Modele DeepSeek-R1-Distill są dostrajane z otwartoźródłowych modeli przy użyciu danych próbnych generowanych przez DeepSeek-R1.",
  "DeepSeek-R1-Distill-Qwen-7B.description": "Model zdestylowany z DeepSeek-R1 oparty na Qwen2.5-Math-7B. Uczenie przez wzmocnienie i dane startowe optymalizują wydajność rozumowania, ustanawiając nowe standardy w zadaniach wielozadaniowych dla modeli otwartych.",
  "DeepSeek-R1.description": "DeepSeek-R1 stosuje uczenie przez wzmocnienie na dużą skalę w fazie post-treningowej, znacząco poprawiając zdolności rozumowania przy bardzo małej liczbie oznakowanych danych. Dorównuje produkcyjnemu modelowi OpenAI o1 w zadaniach z matematyki, kodowania i rozumowania językowego.",
  "DeepSeek-V3-1.description": "DeepSeek V3.1 to model nowej generacji do rozumowania, z ulepszonym rozumowaniem złożonym i łańcuchem myślenia, odpowiedni do zadań wymagających głębokiej analizy.",
  "DeepSeek-V3-Fast.description": "Dostawca: sophnet. DeepSeek V3 Fast to wersja o wysokim TPS modelu DeepSeek V3 0324, w pełnej precyzji (bez kwantyzacji), z lepszymi wynikami w kodzie i matematyce oraz szybszymi odpowiedziami.",
  "DeepSeek-V3.1-Fast.description": "DeepSeek V3.1 Fast to szybka wersja modelu DeepSeek V3.1 o wysokim TPS. Tryb hybrydowego myślenia: za pomocą szablonów czatu jeden model obsługuje zarówno tryb myślący, jak i niemyslący. Inteligentniejsze użycie narzędzi: optymalizacje po treningu znacznie poprawiają wydajność zadań agentowych i użycia narzędzi.",
  "DeepSeek-V3.1-Think.description": "Tryb myślenia DeepSeek-V3.1: nowy hybrydowy model rozumowania z trybami myślącym i niemyslącym, bardziej wydajny niż DeepSeek-R1-0528. Optymalizacje po treningu znacząco poprawiają użycie narzędzi agentowych i wydajność zadań agentowych.",
  "DeepSeek-V3.description": "DeepSeek-V3 to model MoE opracowany przez DeepSeek. Przewyższa inne otwarte modele, takie jak Qwen2.5-72B i Llama-3.1-405B w wielu testach porównawczych i konkuruje z czołowymi zamkniętymi modelami, takimi jak GPT-4o i Claude 3.5 Sonnet.",
  "amazon/titan-embed-text-v2.description": "Amazon Titan Text Embeddings V2 to lekki, wydajny model wielojęzycznych osadzeń, obsługujący wymiary 1024, 512 i 256.",
  "gemini-flash-latest.description": "Najnowsze wydanie Gemini Flash",
  "gemini-flash-lite-latest.description": "Najnowsze wydanie Gemini Flash-Lite",
  "gemini-pro-latest.description": "Najnowsze wydanie Gemini Pro",
  "meta/Llama-3.2-90B-Vision-Instruct.description": "Zaawansowane rozumowanie obrazów dla aplikacji agentów rozumiejących treści wizualne.",
  "meta/Llama-3.3-70B-Instruct.description": "Llama 3.3 to najbardziej zaawansowany wielojęzyczny model open-source z rodziny Llama, oferujący wydajność zbliżoną do modeli 405B przy bardzo niskim koszcie. Opiera się na architekturze Transformer i został udoskonalony za pomocą SFT i RLHF, aby zwiększyć jego użyteczność i bezpieczeństwo. Wersja dostrojona do instrukcji została zoptymalizowana pod kątem wielojęzycznych rozmów i przewyższa wiele otwartych i zamkniętych modeli konwersacyjnych w branżowych testach. Data odcięcia wiedzy: grudzień 2023.",
  "meta/Meta-Llama-3-70B-Instruct.description": "Potężny model z 70 miliardami parametrów, który wyróżnia się w rozumowaniu, programowaniu i szerokim zakresie zadań językowych.",
  "meta/Meta-Llama-3-8B-Instruct.description": "Wszechstronny model z 8 miliardami parametrów, zoptymalizowany do rozmów i generowania tekstu.",
  "meta/Meta-Llama-3.1-405B-Instruct.description": "Model tekstowy Llama 3.1 dostrojony do instrukcji, zoptymalizowany pod kątem wielojęzycznych rozmów, osiągający wysokie wyniki w branżowych testach wśród modeli otwartych i zamkniętych.",
  "meta/Meta-Llama-3.1-70B-Instruct.description": "Model tekstowy Llama 3.1 dostrojony do instrukcji, zoptymalizowany pod kątem wielojęzycznych rozmów, osiągający wysokie wyniki w branżowych testach wśród modeli otwartych i zamkniętych.",
  "meta/Meta-Llama-3.1-8B-Instruct.description": "Model tekstowy Llama 3.1 dostrojony do instrukcji, zoptymalizowany pod kątem wielojęzycznych rozmów, osiągający wysokie wyniki w branżowych testach wśród modeli otwartych i zamkniętych.",
  "meta/llama-3-70b.description": "Model open-source z 70 miliardami parametrów, dostrojony przez Meta do podążania za instrukcjami, udostępniany przez Groq na sprzęcie LPU dla szybkiego i wydajnego wnioskowania.",
  "meta/llama-3-8b.description": "Model open-source z 8 miliardami parametrów, dostrojony przez Meta do podążania za instrukcjami, udostępniany przez Groq na sprzęcie LPU dla szybkiego i wydajnego wnioskowania.",
  "meta/llama-3.1-405b-instruct.description": "Zaawansowany model językowy wspierający generowanie danych syntetycznych, destylację wiedzy i rozumowanie dla chatbotów, programowania i zadań dziedzinowych.",
  "meta/llama-3.1-70b-instruct.description": "Zaprojektowany do złożonych dialogów z doskonałym rozumieniem kontekstu, rozumowaniem i generowaniem tekstu.",
  "meta/llama-3.1-70b.description": "Zaktualizowany model Meta Llama 3 70B Instruct z kontekstem 128K, wsparciem wielojęzycznym i ulepszonym rozumowaniem.",
  "meta/llama-3.1-8b-instruct.description": "Nowoczesny model z silnym rozumieniem języka, rozumowaniem i generowaniem tekstu.",
  "meta/llama-3.1-8b.description": "Llama 3.1 8B obsługuje okno kontekstu 128K, idealne do rozmów w czasie rzeczywistym i analizy danych, oferując znaczne oszczędności kosztów w porównaniu do większych modeli. Udostępniany przez Groq na sprzęcie LPU dla szybkiego i wydajnego wnioskowania.",
  "meta/llama-3.2-11b-vision-instruct.description": "Nowatorski model językowo-wizualny, który wyróżnia się wysokiej jakości rozumowaniem na podstawie obrazów.",
  "meta/llama-3.2-11b.description": "Model dostrojony do instrukcji w zakresie rozumowania obrazów (wejście: tekst + obraz, wyjście: tekst), zoptymalizowany do rozpoznawania wizualnego, rozumowania obrazów, opisywania i ogólnego QA obrazów.",
  "meta/llama-3.2-1b-instruct.description": "Nowoczesny mały model językowy z silnym rozumieniem, rozumowaniem i generowaniem tekstu.",
  "meta/llama-3.2-1b.description": "Model tylko tekstowy do zastosowań lokalnych na urządzeniach, takich jak wielojęzyczne wyszukiwanie lokalne, streszczanie i przepisywanie.",
  "meta/llama-3.2-3b-instruct.description": "Nowoczesny mały model językowy z silnym rozumieniem, rozumowaniem i generowaniem tekstu.",
  "meta/llama-3.2-3b.description": "Model tylko tekstowy dostrojony do zastosowań lokalnych na urządzeniach, takich jak wielojęzyczne wyszukiwanie lokalne, streszczanie i przepisywanie.",
  "meta/llama-3.2-90b-vision-instruct.description": "Nowatorski model językowo-wizualny, który wyróżnia się wysokiej jakości rozumowaniem na podstawie obrazów.",
  "meta/llama-3.2-90b.description": "Model dostrojony do instrukcji w zakresie rozumowania obrazów (wejście: tekst + obraz, wyjście: tekst), zoptymalizowany do rozpoznawania wizualnego, rozumowania obrazów, opisywania i ogólnego QA obrazów.",
  "meta/llama-3.3-70b-instruct.description": "Zaawansowany model językowy, silny w rozumowaniu, matematyce, zdrowym rozsądku i wywoływaniu funkcji.",
  "meta/llama-3.3-70b.description": "Idealne połączenie wydajności i efektywności. Zbudowany z myślą o wysokowydajnej konwersacyjnej AI w tworzeniu treści, aplikacjach biznesowych i badaniach, z silnym rozumieniem języka do streszczania, klasyfikacji, analizy sentymentu i generowania kodu.",
  "meta/llama-4-maverick.description": "Rodzina Llama 4 to natywne modele multimodalne obsługujące tekst i doświadczenia multimodalne, wykorzystujące MoE do wiodącego rozumienia tekstu i obrazu. Llama 4 Maverick to model 17B z 128 ekspertami, udostępniany przez DeepInfra.",
  "meta/llama-4-scout.description": "Rodzina Llama 4 to natywne modele multimodalne obsługujące tekst i doświadczenia multimodalne, wykorzystujące MoE do wiodącego rozumienia tekstu i obrazu. Llama 4 Scout to model 17B z 16 ekspertami, udostępniany przez DeepInfra."
}
