{
  "01-ai/yi-1.5-34b-chat.description": "01.AI 最新开源微调模型，拥有 340 亿参数，支持多种对话场景，基于高质量数据训练，并对齐人类偏好。",
  "01-ai/yi-1.5-9b-chat.description": "01.AI 最新开源微调模型，拥有 90 亿参数，支持多种对话场景，基于高质量数据训练，并对齐人类偏好。",
  "360/deepseek-r1.description": "360 部署的 DeepSeek-R1 在后训练阶段应用大规模强化学习，在极少标注数据下显著提升推理能力，在数学、编程和自然语言推理任务上可与 OpenAI o1 相媲美。",
  "360gpt-pro-trans.description": "专为翻译任务优化的模型，深度微调以实现领先的翻译质量。",
  "360gpt-pro.description": "360GPT Pro 是 360 的核心 AI 模型，具备高效文本处理能力，适用于多种自然语言处理场景，支持长文本理解和多轮对话。",
  "360gpt-turbo-responsibility-8k.description": "360GPT Turbo Responsibility 8K 强调语义安全与内容责任，适用于内容敏感型应用，确保用户体验的准确性与稳健性。",
  "360gpt-turbo.description": "360GPT Turbo 具备强大的计算与对话能力，语义理解与生成效率出色，适合企业与开发者使用。",
  "360gpt2-o1.description": "360gpt2-o1 通过树搜索构建思维链，结合反思机制与强化学习训练，实现自我反思与自我纠错。",
  "360gpt2-pro.description": "360GPT2 Pro 是 360 推出的高级自然语言处理模型，擅长文本生成与理解，尤其适用于创意任务，能处理复杂转换与角色扮演。",
  "360zhinao2-o1.description": "360zhinao2-o1 通过树搜索构建思维链，结合反思机制与强化学习训练，实现自我反思与自我纠错。",
  "4.0Ultra.description": "讯飞星火 Ultra 是星火系列中最强大的模型，提升了文本理解与摘要能力，并升级了网页搜索功能。它是提升职场效率与响应准确性的综合解决方案，定位为领先的智能产品。",
  "AnimeSharp.description": "AnimeSharp（又名“4x-AnimeSharp”）是由 Kim2091 基于 ESRGAN 开发的开源超分辨率模型，专注于提升和锐化动漫风格图像。该模型于 2022 年 2 月由原名“4x-TextSharpV1”更名，最初也用于文本图像，但已针对动漫内容进行了深度优化。",
  "Baichuan2-Turbo.description": "通过搜索增强技术将模型与领域知识和网页知识连接，支持 PDF/Word 上传和 URL 输入，实现及时、全面的检索与专业、准确的输出。",
  "Baichuan3-Turbo-128k.description": "拥有 128K 超长上下文窗口，专为高频企业场景优化，带来显著提升与高价值。相比 Baichuan2，内容创作提升 20%，知识问答提升 17%，角色扮演提升 40%。整体性能优于 GPT-3.5。",
  "Baichuan3-Turbo.description": "专为高频企业场景优化，带来显著提升与高价值。相比 Baichuan2，内容创作提升 20%，知识问答提升 17%，角色扮演提升 40%。整体性能优于 GPT-3.5。",
  "Baichuan4-Air.description": "国内领先模型，在中文任务如知识问答、长文本处理和创意生成方面超越海外主流模型。具备行业领先的多模态能力，在权威评测中表现优异。",
  "Baichuan4-Turbo.description": "国内领先模型，在中文任务如知识问答、长文本处理和创意生成方面超越海外主流模型。具备行业领先的多模态能力，在权威评测中表现优异。",
  "Baichuan4.description": "国内顶尖性能，在中文任务如百科知识、长文本处理和创意生成方面超越海外主流模型。具备行业领先的多模态能力，在权威评测中表现出色。",
  "ByteDance-Seed/Seed-OSS-36B-Instruct.description": "Seed-OSS 是字节跳动 Seed 团队推出的开源大模型系列，具备强大的长上下文处理、推理、智能体和通用能力。Seed-OSS-36B-Instruct 是一款 360 亿参数的指令微调模型，原生支持超长上下文，适用于处理大型文档或代码库。该模型在推理、代码生成和智能体任务（工具使用）方面表现出色，同时保留强大的通用能力。其核心特性“思维预算”可灵活控制推理长度，提升效率。",
  "DeepSeek-R1-Distill-Llama-70B.description": "DeepSeek R1 是 DeepSeek 系列中更大更智能的模型，已蒸馏至 Llama 70B 架构。基准测试和人工评估显示其在数学和事实精度任务上优于原始 Llama 70B。",
  "DeepSeek-R1-Distill-Qwen-1.5B.description": "基于 Qwen2.5-Math-1.5B 的 DeepSeek-R1 蒸馏模型。通过强化学习与冷启动数据优化推理性能，在开源模型中树立多任务新基准。",
  "DeepSeek-R1-Distill-Qwen-14B.description": "DeepSeek-R1-Distill 模型基于开源模型，使用 DeepSeek-R1 生成的样本数据进行微调。",
  "DeepSeek-R1-Distill-Qwen-32B.description": "DeepSeek-R1-Distill 模型基于开源模型，使用 DeepSeek-R1 生成的样本数据进行微调。",
  "DeepSeek-R1-Distill-Qwen-7B.description": "基于 Qwen2.5-Math-7B 的 DeepSeek-R1 蒸馏模型。通过强化学习与冷启动数据优化推理性能，在开源模型中树立多任务新基准。",
  "DeepSeek-R1.description": "DeepSeek-R1 在后训练阶段应用大规模强化学习，在极少标注数据下显著提升推理能力，在数学、编程和自然语言推理任务上可与 OpenAI o1 生产模型相媲美。",
  "DeepSeek-V3-1.description": "DeepSeek V3.1 是新一代推理模型，提升了复杂推理与思维链能力，适用于深度分析任务。",
  "DeepSeek-V3-Fast.description": "提供方：sophnet。DeepSeek V3 Fast 是 DeepSeek V3 0324 的高 TPS 版本，采用全精度（非量化），在代码与数学方面更强，响应更快。",
  "DeepSeek-V3.1-Fast.description": "DeepSeek V3.1 Fast 是 DeepSeek V3.1 的高 TPS 快速版本。混合思维模式：通过对话模板，一个模型支持思考与非思考模式。更智能的工具使用：后训练优化提升工具与智能体任务表现。",
  "DeepSeek-V3.1-Think.description": "DeepSeek-V3.1 思考模式：新型混合推理模型，支持思考与非思考模式，效率优于 DeepSeek-R1-0528。后训练优化显著提升智能体工具使用与任务表现。",
  "DeepSeek-V3.description": "DeepSeek-V3 是 DeepSeek 开发的 MoE 模型，在多个基准测试中超越 Qwen2.5-72B 和 Llama-3.1-405B 等开源模型，并与 GPT-4o 和 Claude 3.5 Sonnet 等领先闭源模型竞争。",
  "amazon/titan-embed-text-v2.description": "Amazon Titan Text Embeddings V2 是一个轻量级、高效的多语言嵌入模型，支持 1024、512 和 256 维度。",
  "gemini-flash-latest.description": "Latest release of Gemini Flash",
  "gemini-flash-lite-latest.description": "Latest release of Gemini Flash-Lite",
  "gemini-pro-latest.description": "Latest release of Gemini Pro",
  "meta/Llama-3.2-90B-Vision-Instruct.description": "适用于视觉理解代理应用的高级图像推理模型。",
  "meta/Llama-3.3-70B-Instruct.description": "Llama 3.3 是最先进的多语言开源 Llama 模型，在极低成本下实现接近 405B 的性能。该模型基于 Transformer 架构，并通过 SFT 和 RLHF 提升实用性与安全性。其指令微调版本专为多语言对话优化，在行业基准测试中超越众多开源与闭源聊天模型。知识截止时间：2023 年 12 月。",
  "meta/Meta-Llama-3-70B-Instruct.description": "一款功能强大的 700 亿参数模型，擅长推理、编程和广泛的语言任务。",
  "meta/Meta-Llama-3-8B-Instruct.description": "一款多功能的 80 亿参数模型，专为对话和文本生成优化。",
  "meta/Meta-Llama-3.1-405B-Instruct.description": "Llama 3.1 指令微调文本模型，专为多语言对话优化，在开源与闭源聊天模型中在常见行业基准测试中表现出色。",
  "meta/Meta-Llama-3.1-70B-Instruct.description": "Llama 3.1 指令微调文本模型，专为多语言对话优化，在开源与闭源聊天模型中在常见行业基准测试中表现出色。",
  "meta/Meta-Llama-3.1-8B-Instruct.description": "Llama 3.1 指令微调文本模型，专为多语言对话优化，在开源与闭源聊天模型中在常见行业基准测试中表现出色。",
  "meta/llama-3-70b.description": "由 Meta 微调的 700 亿参数开源模型，专注于指令跟随，由 Groq 在 LPU 硬件上提供服务，实现快速高效的推理。",
  "meta/llama-3-8b.description": "由 Meta 微调的 80 亿参数开源模型，专注于指令跟随，由 Groq 在 LPU 硬件上提供服务，实现快速高效的推理。",
  "meta/llama-3.1-405b-instruct.description": "一款先进的大语言模型，支持合成数据生成、知识蒸馏和用于聊天机器人、编程及领域任务的推理。",
  "meta/llama-3.1-70b-instruct.description": "专为复杂对话设计，具备出色的上下文理解、推理和文本生成能力。",
  "meta/llama-3.1-70b.description": "更新版 Meta Llama 3 70B Instruct，支持 128K 上下文、多语言能力，并提升推理表现。",
  "meta/llama-3.1-8b-instruct.description": "一款前沿模型，具备强大的语言理解、推理和文本生成能力。",
  "meta/llama-3.1-8b.description": "Llama 3.1 8B 支持 128K 上下文窗口，适用于实时对话和数据分析，相较于更大模型具有显著成本优势。由 Groq 在 LPU 硬件上提供服务，实现快速高效的推理。",
  "meta/llama-3.2-11b-vision-instruct.description": "一款前沿视觉语言模型，擅长从图像中进行高质量推理。",
  "meta/llama-3.2-11b.description": "一款指令微调的图像推理模型（文本+图像输入，文本输出），专为视觉识别、图像推理、图像描述和通用图像问答优化。",
  "meta/llama-3.2-1b-instruct.description": "一款前沿的小型语言模型，具备强大的理解、推理和文本生成能力。",
  "meta/llama-3.2-1b.description": "纯文本模型，适用于设备端的多语言本地检索、摘要和改写等场景。",
  "meta/llama-3.2-3b-instruct.description": "一款前沿的小型语言模型，具备强大的理解、推理和文本生成能力。",
  "meta/llama-3.2-3b.description": "纯文本模型，针对设备端的多语言本地检索、摘要和改写等场景进行微调。",
  "meta/llama-3.2-90b-vision-instruct.description": "一款前沿视觉语言模型，擅长从图像中进行高质量推理。",
  "meta/llama-3.2-90b.description": "一款指令微调的图像推理模型（文本+图像输入，文本输出），专为视觉识别、图像推理、图像描述和通用图像问答优化。",
  "meta/llama-3.3-70b-instruct.description": "一款先进的大语言模型，擅长推理、数学、常识和函数调用。",
  "meta/llama-3.3-70b.description": "性能与效率的完美平衡。专为内容创作、企业应用和研究中的高性能对话式 AI 而构建，具备强大的语言理解能力，适用于摘要、分类、情感分析和代码生成。",
  "meta/llama-4-maverick.description": "Llama 4 系列是原生多模态 AI 模型集，支持文本与多模态体验，采用 MoE 架构，实现领先的文本与图像理解。Llama 4 Maverick 是一款拥有 128 个专家的 170 亿参数模型，由 DeepInfra 提供服务。",
  "meta/llama-4-scout.description": "Llama 4 系列是原生多模态 AI 模型集，支持文本与多模态体验，采用 MoE 架构，实现领先的文本与图像理解。Llama 4 Scout 是一款拥有 16 个专家的 170 亿参数模型，由 DeepInfra 提供服务。",
  "microsoft/Phi-3-medium-128k-instruct.description": "与 Phi-3-medium 相同的模型，但具有更大的上下文窗口，适用于 RAG 或少样本提示。",
  "microsoft/Phi-3-medium-4k-instruct.description": "一款 140 亿参数模型，质量高于 Phi-3-mini，专注于高质量、推理密集型数据。",
  "microsoft/Phi-3-mini-128k-instruct.description": "与 Phi-3-mini 相同的模型，但具有更大的上下文窗口，适用于 RAG 或少样本提示。",
  "microsoft/Phi-3-mini-4k-instruct.description": "Phi-3 系列中最小的成员，优化以实现高质量和低延迟。",
  "microsoft/Phi-3-small-128k-instruct.description": "与 Phi-3-small 相同的模型，但具有更大的上下文窗口，适用于 RAG 或少样本提示。",
  "microsoft/Phi-3-small-8k-instruct.description": "一款 70 亿参数模型，质量高于 Phi-3-mini，专注于高质量、推理密集型数据。",
  "microsoft/Phi-3.5-mini-instruct.description": "Phi-3-mini 模型的更新版本。",
  "microsoft/Phi-3.5-vision-instruct.description": "Phi-3-vision 模型的更新版本。",
  "microsoft/WizardLM-2-8x22B.description": "WizardLM 2 是微软 AI 推出的语言模型，擅长复杂对话、多语言任务、推理和助手应用。",
  "microsoft/wizardlm-2-8x22b.description": "WizardLM-2 8x22B 是微软 AI 最先进的 Wizard 模型，具备极具竞争力的性能。",
  "minicpm-v.description": "MiniCPM-V 是 OpenBMB 的下一代多模态模型，具备出色的 OCR 和多模态理解能力，适用于广泛场景。",
  "minimax-m2.description": "MiniMax M2 是一款高效的大语言模型，专为编程和智能体工作流设计。",
  "minimax/minimax-m2.description": "MiniMax-M2 是一款高性价比模型，擅长编程和智能体任务，适用于多种工程场景。",
  "minimaxai/minimax-m2.description": "MiniMax-M2 是一款紧凑、快速、成本效益高的 MoE 模型（总参数 230B，激活参数 10B），在保持强大通用智能的同时，专为顶级编程和智能体性能打造。擅长多文件编辑、代码运行修复循环、测试验证和复杂工具链。",
  "ministral-3b-latest.description": "Ministral 3B 是 Mistral 推出的顶级边缘模型。",
  "ministral-8b-latest.description": "Ministral 8B 是 Mistral 推出的高性价比边缘模型。",
  "mistral-ai/Mistral-Large-2411.description": "Mistral 的旗舰模型，适用于需要大规模推理或专业化的复杂任务（如合成文本生成、代码生成、RAG 或智能体）。",
  "mistral-ai/Mistral-Nemo.description": "Mistral Nemo 是一款前沿大语言模型，在其参数规模下具备最先进的推理、世界知识和编程能力。",
  "mistral-ai/mistral-small-2503.description": "Mistral Small 适用于任何需要高效率和低延迟的语言任务。",
  "mistral-large-instruct.description": "Mistral-Large-Instruct-2407 是一款先进的密集型大语言模型，拥有 1230 亿参数，具备最先进的推理、知识和编程能力。",
  "mistral-large-latest.description": "Mistral Large 是旗舰模型，擅长多语言任务、复杂推理和代码生成，适用于高端应用。",
  "mistral-large.description": "Mixtral Large 是 Mistral 的旗舰模型，结合代码生成、数学和推理能力，支持 128K 上下文窗口。",
  "mistral-medium-latest.description": "Mistral Medium 3 以 8 倍更低的成本实现最先进性能，并简化企业部署。",
  "mistral-nemo-instruct.description": "Mistral-Nemo-Instruct-2407 是 Mistral-Nemo-Base-2407 的指令微调版本。",
  "mistral-nemo.description": "Mistral Nemo 是 Mistral AI 与 NVIDIA 联合开发的高效 120 亿参数模型。",
  "mistral-small-latest.description": "Mistral Small 是一款高性价比、快速且可靠的模型，适用于翻译、摘要和情感分析。",
  "mistral-small.description": "Mistral Small 适用于任何需要高效率和低延迟的语言任务。",
  "mistral.description": "Mistral 是 Mistral AI 推出的 70 亿参数模型，适用于多种语言任务。",
  "mistral/codestral-embed.description": "一款代码嵌入模型，用于嵌入代码库和仓库，支持编程助手。",
  "mistral/codestral.description": "Mistral Codestral 25.01 是一款最先进的编程模型，优化以实现低延迟和高频使用。支持 80 多种语言，擅长 FIM、代码修复和测试生成。",
  "mistral/devstral-small.description": "Devstral 是一款面向软件工程任务的智能体大语言模型，是软件工程智能体的强力选择。",
  "mistral/magistral-medium.description": "通过深度理解支持复杂思维，具备可追踪、可验证的透明推理能力。即使在任务中途，也能在多语言环境中保持高保真推理。",
  "mistral/magistral-small.description": "通过深度理解支持复杂思维，具备可追踪、可验证的透明推理能力。即使在任务中途，也能在多语言环境中保持高保真推理。",
  "mistral/ministral-3b.description": "一款紧凑高效的模型，适用于设备端任务，如助手和本地分析，提供低延迟性能。",
  "mistral/ministral-8b.description": "一款更强大的模型，推理速度更快、内存效率更高，适用于复杂工作流和高要求的边缘应用。",
  "mistral/mistral-embed.description": "一款通用文本嵌入模型，适用于语义搜索、相似度计算、聚类和 RAG 工作流。",
  "mistral/mistral-large.description": "Mistral Large 适用于需要强大推理或专业化的复杂任务，如合成文本生成、代码生成、RAG 或智能体。",
  "mistral/mistral-small.description": "Mistral Small 适用于分类、客户支持或文本生成等简单、可批处理任务，具备出色性能和实惠价格。",
  "mistral/mixtral-8x22b-instruct.description": "8x22B 指令模型。8x22B 是由 Mistral 提供服务的开源 MoE 模型。",
  "mistral/pixtral-12b.description": "一款具备图像理解与文本处理能力的 120 亿参数模型。",
  "mistral/pixtral-large.description": "Pixtral Large 是我们多模态系列的第二款模型，具备前沿级图像理解能力。可处理文档、图表和自然图像，同时保留 Mistral Large 2 的领先文本理解能力。",
  "mistralai/Mistral-7B-Instruct-v0.1.description": "Mistral（7B）Instruct 以其在多种语言任务中的强大表现而闻名。",
  "mistralai/Mistral-7B-Instruct-v0.2.description": "Mistral（7B）Instruct v0.2 提升了指令处理能力和结果准确性。",
  "mistralai/Mistral-7B-Instruct-v0.3.description": "Mistral（7B）Instruct v0.3 提供高效计算和强大的语言理解，适用于多种场景。",
  "mistralai/Mistral-7B-v0.1.description": "Mistral 7B 虽小巧但性能强劲，适合批处理和分类、文本生成等简单任务，具备扎实的推理能力。",
  "mistralai/Mixtral-8x22B-Instruct-v0.1.description": "Mixtral-8x22B Instruct（141B）是一款适用于重负载任务的超大语言模型。",
  "mistralai/Mixtral-8x7B-Instruct-v0.1.description": "Mixtral-8x7B Instruct（46.7B）为大规模数据处理提供高容量支持。",
  "mistralai/Mixtral-8x7B-v0.1.description": "Mixtral 8x7B 是一款稀疏 MoE 模型，提升推理速度，适用于多语言和代码生成任务。",
  "mistralai/mistral-nemo.description": "Mistral Nemo 是一款 73 亿参数模型，支持多语言，具备强大的编程能力。"
}
