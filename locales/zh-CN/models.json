{
  "01-ai/yi-1.5-34b-chat.description": "01.AI 最新开源微调模型，拥有 340 亿参数，支持多种对话场景，基于高质量数据训练，并对齐人类偏好。",
  "01-ai/yi-1.5-9b-chat.description": "01.AI 最新开源微调模型，拥有 90 亿参数，支持多种对话场景，基于高质量数据训练，并对齐人类偏好。",
  "360/deepseek-r1.description": "360 部署的 DeepSeek-R1 在后训练阶段应用大规模强化学习，在极少标注数据下显著提升推理能力，在数学、编程和自然语言推理任务上可与 OpenAI o1 相媲美。",
  "360gpt-pro-trans.description": "专为翻译任务优化的模型，深度微调以实现领先的翻译质量。",
  "360gpt-pro.description": "360GPT Pro 是 360 的核心 AI 模型，具备高效文本处理能力，适用于多种自然语言处理场景，支持长文本理解和多轮对话。",
  "360gpt-turbo-responsibility-8k.description": "360GPT Turbo Responsibility 8K 强调语义安全与内容责任，适用于内容敏感型应用，确保用户体验的准确性与稳健性。",
  "360gpt-turbo.description": "360GPT Turbo 具备强大的计算与对话能力，语义理解与生成效率出色，适合企业与开发者使用。",
  "360gpt2-o1.description": "360gpt2-o1 通过树搜索构建思维链，结合反思机制与强化学习训练，实现自我反思与自我纠错。",
  "360gpt2-pro.description": "360GPT2 Pro 是 360 推出的高级自然语言处理模型，擅长文本生成与理解，尤其适用于创意任务，能处理复杂转换与角色扮演。",
  "360zhinao2-o1.description": "360zhinao2-o1 通过树搜索构建思维链，结合反思机制与强化学习训练，实现自我反思与自我纠错。",
  "4.0Ultra.description": "讯飞星火 Ultra 是星火系列中最强大的模型，提升了文本理解与摘要能力，并升级了网页搜索功能。它是提升职场效率与响应准确性的综合解决方案，定位为领先的智能产品。",
  "AnimeSharp.description": "AnimeSharp（又名“4x-AnimeSharp”）是由 Kim2091 基于 ESRGAN 开发的开源超分辨率模型，专注于提升和锐化动漫风格图像。该模型于 2022 年 2 月由原名“4x-TextSharpV1”更名，最初也用于文本图像，但已针对动漫内容进行了深度优化。",
  "Baichuan2-Turbo.description": "通过搜索增强技术将模型与领域知识和网页知识连接，支持 PDF/Word 上传和 URL 输入，实现及时、全面的检索与专业、准确的输出。",
  "Baichuan3-Turbo-128k.description": "拥有 128K 超长上下文窗口，专为高频企业场景优化，带来显著提升与高价值。相比 Baichuan2，内容创作提升 20%，知识问答提升 17%，角色扮演提升 40%。整体性能优于 GPT-3.5。",
  "Baichuan3-Turbo.description": "专为高频企业场景优化，带来显著提升与高价值。相比 Baichuan2，内容创作提升 20%，知识问答提升 17%，角色扮演提升 40%。整体性能优于 GPT-3.5。",
  "Baichuan4-Air.description": "国内领先模型，在中文任务如知识问答、长文本处理和创意生成方面超越海外主流模型。具备行业领先的多模态能力，在权威评测中表现优异。",
  "Baichuan4-Turbo.description": "国内领先模型，在中文任务如知识问答、长文本处理和创意生成方面超越海外主流模型。具备行业领先的多模态能力，在权威评测中表现优异。",
  "Baichuan4.description": "国内顶尖性能，在中文任务如百科知识、长文本处理和创意生成方面超越海外主流模型。具备行业领先的多模态能力，在权威评测中表现出色。",
  "ByteDance-Seed/Seed-OSS-36B-Instruct.description": "Seed-OSS 是字节跳动 Seed 团队推出的开源大模型系列，具备强大的长上下文处理、推理、智能体和通用能力。Seed-OSS-36B-Instruct 是一款 360 亿参数的指令微调模型，原生支持超长上下文，适用于处理大型文档或代码库。该模型在推理、代码生成和智能体任务（工具使用）方面表现出色，同时保留强大的通用能力。其核心特性“思维预算”可灵活控制推理长度，提升效率。",
  "DeepSeek-R1-Distill-Llama-70B.description": "DeepSeek R1 是 DeepSeek 系列中更大更智能的模型，已蒸馏至 Llama 70B 架构。基准测试和人工评估显示其在数学和事实精度任务上优于原始 Llama 70B。",
  "DeepSeek-R1-Distill-Qwen-1.5B.description": "基于 Qwen2.5-Math-1.5B 的 DeepSeek-R1 蒸馏模型。通过强化学习与冷启动数据优化推理性能，在开源模型中树立多任务新基准。",
  "DeepSeek-R1-Distill-Qwen-14B.description": "DeepSeek-R1-Distill 模型基于开源模型，使用 DeepSeek-R1 生成的样本数据进行微调。",
  "DeepSeek-R1-Distill-Qwen-32B.description": "DeepSeek-R1-Distill 模型基于开源模型，使用 DeepSeek-R1 生成的样本数据进行微调。",
  "DeepSeek-R1-Distill-Qwen-7B.description": "基于 Qwen2.5-Math-7B 的 DeepSeek-R1 蒸馏模型。通过强化学习与冷启动数据优化推理性能，在开源模型中树立多任务新基准。",
  "DeepSeek-R1.description": "DeepSeek-R1 在后训练阶段应用大规模强化学习，在极少标注数据下显著提升推理能力，在数学、编程和自然语言推理任务上可与 OpenAI o1 生产模型相媲美。",
  "DeepSeek-V3-1.description": "DeepSeek V3.1 是新一代推理模型，提升了复杂推理与思维链能力，适用于深度分析任务。",
  "DeepSeek-V3-Fast.description": "提供方：sophnet。DeepSeek V3 Fast 是 DeepSeek V3 0324 的高 TPS 版本，采用全精度（非量化），在代码与数学方面更强，响应更快。",
  "DeepSeek-V3.1-Fast.description": "DeepSeek V3.1 Fast 是 DeepSeek V3.1 的高 TPS 快速版本。混合思维模式：通过对话模板，一个模型支持思考与非思考模式。更智能的工具使用：后训练优化提升工具与智能体任务表现。",
  "DeepSeek-V3.1-Think.description": "DeepSeek-V3.1 思考模式：新型混合推理模型，支持思考与非思考模式，效率优于 DeepSeek-R1-0528。后训练优化显著提升智能体工具使用与任务表现。",
  "DeepSeek-V3.description": "DeepSeek-V3 是 DeepSeek 开发的 MoE 模型，在多个基准测试中超越 Qwen2.5-72B 和 Llama-3.1-405B 等开源模型，并与 GPT-4o 和 Claude 3.5 Sonnet 等领先闭源模型竞争。",
  "Doubao-lite-128k.description": "豆包-lite 提供超快响应和更高性价比，适用于多种场景，支持 128K 上下文推理与微调。",
  "Doubao-lite-32k.description": "豆包-lite 提供超快响应和更高性价比，适用于多种场景，支持 32K 上下文推理与微调。",
  "Doubao-lite-4k.description": "豆包-lite 提供超快响应和更高性价比，适用于多种场景，支持 4K 上下文推理与微调。",
  "Doubao-pro-128k.description": "旗舰性能最强模型，擅长复杂任务，在参考问答、摘要、创作、分类和角色扮演方面表现出色。支持 128K 上下文推理与微调。",
  "Doubao-pro-32k.description": "旗舰性能最强模型，擅长复杂任务，在参考问答、摘要、创作、分类和角色扮演方面表现出色。支持 32K 上下文推理与微调。",
  "Doubao-pro-4k.description": "旗舰性能最强模型，擅长复杂任务，在参考问答、摘要、创作、分类和角色扮演方面表现出色。支持 4K 上下文推理与微调。",
  "DreamO.description": "DreamO 是由字节跳动与北京大学联合开发的开源图像定制模型，采用统一架构支持多任务图像生成。通过高效的组合建模，可根据用户指定的身份、主题、风格、背景等条件生成高度一致的定制图像。",
  "ERNIE-3.5-128K.description": "百度旗舰级大模型，基于海量中英文语料训练，具备强大的通用对话、创作和插件使用能力；支持自动集成百度搜索插件，提供最新答案。",
  "ERNIE-3.5-8K-Preview.description": "百度旗舰级大模型，基于海量中英文语料训练，具备强大的通用对话、创作和插件使用能力；支持自动集成百度搜索插件，提供最新答案。",
  "ERNIE-3.5-8K.description": "百度旗舰级大模型，基于海量中英文语料训练，具备强大的通用对话、创作和插件使用能力；支持自动集成百度搜索插件，提供最新答案。",
  "ERNIE-4.0-8K-Latest.description": "百度旗舰级超大模型，全面升级自 ERNIE 3.5，适用于各领域复杂任务；支持百度搜索插件集成，提供实时答案。",
  "ERNIE-4.0-8K-Preview.description": "百度旗舰级超大模型，全面升级自 ERNIE 3.5，适用于各领域复杂任务；支持百度搜索插件集成，提供实时答案。",
  "ERNIE-4.0-Turbo-8K-Latest.description": "百度旗舰级超大模型，综合性能强劲，适用于复杂任务，集成百度搜索插件，提供实时答案。性能优于 ERNIE 4.0。",
  "ERNIE-4.0-Turbo-8K-Preview.description": "百度旗舰级超大模型，综合性能强劲，适用于复杂任务，集成百度搜索插件，提供实时答案。性能优于 ERNIE 4.0。",
  "ERNIE-Character-8K.description": "百度面向游戏 NPC、客服和角色扮演的垂直领域大模型，具备更清晰的人设一致性、更强的指令理解能力和更优的推理能力。",
  "ERNIE-Lite-Pro-128K.description": "百度轻量级大模型，在质量与推理性能之间取得平衡，优于 ERNIE Lite，适用于低算力加速器。",
  "ERNIE-Speed-128K.description": "百度最新高性能大模型（2024），具备强大的通用能力，适合作为微调基础模型，适应特定场景，推理能力出色。",
  "ERNIE-Speed-Pro-128K.description": "百度最新高性能大模型（2024），具备强大的通用能力，优于 ERNIE Speed，适合作为微调基础模型，推理能力出色。",
  "FLUX-1.1-pro.description": "FLUX.1.1 Pro",
  "FLUX.1-Kontext-dev.description": "FLUX.1-Kontext-dev 是 Black Forest Labs 推出的多模态图像生成与编辑模型，基于 Rectified Flow Transformer 架构，拥有 120 亿参数。专注于在给定上下文条件下生成、重建、增强或编辑图像。结合扩散模型的可控生成能力与 Transformer 的上下文建模，支持图像修复、扩图和视觉场景重建等高质量任务。",
  "FLUX.1-Kontext-pro.description": "FLUX.1 Kontext [pro]",
  "FLUX.1-dev.description": "FLUX.1-dev 是 Black Forest Labs 推出的开源多模态语言模型（MLLM），优化用于图文任务，融合图像/文本理解与生成能力。基于先进的大语言模型（如 Mistral-7B），采用精心设计的视觉编码器和多阶段指令微调，实现多模态协同与复杂任务推理。",
  "Gryphe/MythoMax-L2-13b.description": "MythoMax-L2（13B）是一款面向多领域和复杂任务的创新模型。",
  "HelloMeme.description": "HelloMeme 是一款 AI 工具，可根据用户提供的图像或动作生成表情包、GIF 或短视频。无需绘画或编程技能，仅需参考图像即可生成有趣、吸引人且风格统一的内容。",
  "HiDream-I1-Full.description": "HiDream-E1-Full 是来自 HiDream.ai 的开源多模态图像编辑模型，基于先进的 Diffusion Transformer 架构和强大的语言理解能力（内置 LLaMA 3.1-8B-Instruct）。支持自然语言驱动的图像生成、风格迁移、局部编辑和重绘，具备出色的图文理解与执行能力。",
  "HunyuanDiT-v1.2-Diffusers-Distilled.description": "hunyuandit-v1.2-distilled 是一款轻量级文本生成图像模型，通过蒸馏优化以快速生成高质量图像，特别适合低资源环境和实时生成场景。",
  "InstantCharacter.description": "InstantCharacter 是腾讯 AI 于 2025 年发布的免调优个性化角色生成模型，致力于高保真、跨场景一致的角色生成。可通过单张参考图像建模角色，并灵活迁移至不同风格、动作和背景。",
  "InternVL2-8B.description": "InternVL2-8B 是一款强大的视觉语言模型，支持多模态图文处理，能够准确识别图像内容并生成相关描述或答案。",
  "InternVL2.5-26B.description": "InternVL2.5-26B 是一款强大的视觉语言模型，支持多模态图文处理，能够准确识别图像内容并生成相关描述或答案。",
  "Kolors.description": "Kolors 是快手 Kolors 团队开发的文本生成图像模型。拥有数十亿参数，在视觉质量、中文语义理解和文本渲染方面具有显著优势。",
  "Kwai-Kolors/Kolors.description": "Kolors 是快手 Kolors 团队推出的大规模潜变量扩散文本生成图像模型。基于数十亿图文对训练，在视觉质量、复杂语义准确性以及中英文文本渲染方面表现出色，具备强大的中文内容理解与生成能力。",
  "Kwaipilot/KAT-Dev.description": "KAT-Dev（32B）是一个面向软件工程任务的开源 32B 模型。在 SWE-Bench Verified 上达到 62.4% 的解决率，在开源模型中排名第五。通过中间训练、SFT 和 RL 优化，适用于代码补全、Bug 修复和代码审查。",
  "Llama-3.2-11B-Vision-Instruct.description": "在高分辨率图像上具备强大的图像推理能力，适用于视觉理解类应用。",
  "Llama-3.2-90B-Vision-Instruct\t.description": "面向视觉理解智能体应用的高级图像推理模型。",
  "Meta-Llama-3-3-70B-Instruct.description": "Llama 3.3 70B 是一款多用途的 Transformer 模型，适用于对话和文本生成任务。",
  "Meta-Llama-3.1-405B-Instruct.description": "Llama 3.1 是一款经过指令微调的文本模型，专为多语言对话优化，在开放与闭源聊天模型中，在行业通用基准测试中表现出色。",
  "Meta-Llama-3.1-70B-Instruct.description": "Llama 3.1 是一款经过指令微调的文本模型，专为多语言对话优化，在开放与闭源聊天模型中，在行业通用基准测试中表现出色。",
  "Meta-Llama-3.1-8B-Instruct.description": "Llama 3.1 是一款经过指令微调的文本模型，专为多语言对话优化，在开放与闭源聊天模型中，在行业通用基准测试中表现出色。",
  "Meta-Llama-3.2-1B-Instruct.description": "前沿的小型语言模型，具备出色的语言理解、推理能力和文本生成能力。",
  "Meta-Llama-3.2-3B-Instruct.description": "前沿的小型语言模型，具备出色的语言理解、推理能力和文本生成能力。",
  "Meta-Llama-3.3-70B-Instruct.description": "Llama 3.3 是最先进的多语言开源 Llama 模型，在极低成本下实现接近 405B 的性能。基于 Transformer 架构，并通过 SFT 和 RLHF 提升实用性与安全性。指令微调版本专为多语言对话优化，在行业基准测试中超越众多开放与闭源聊天模型。知识截止时间：2023 年 12 月。",
  "Meta-Llama-4-Maverick-17B-128E-Instruct-FP8.description": "Llama 4 Maverick 是一款大型 MoE 模型，采用高效专家激活机制，具备强大的推理能力。",
  "MiniMax-M1.description": "一款全新自研推理模型，支持 80K 思维链和 100 万输入，性能媲美全球顶尖模型。",
  "MiniMax-M2-Stable.description": "专为高效编程与智能体工作流打造，具备更高并发能力，适用于商业场景。",
  "MiniMax-M2.1-Lightning.description": "强大的多语言编程能力，全面升级编程体验。更快、更高效。",
  "MiniMax-M2.1.description": "强大的多语言编程能力，全面升级编程体验",
  "MiniMax-M2.description": "专为高效编码与智能体工作流打造",
  "MiniMax-Text-01.description": "MiniMax-01 引入超越传统 Transformer 的大规模线性注意力机制，拥有 4560 亿参数，每次激活 459 亿，支持最长 400 万上下文（为 GPT-4o 的 32 倍，Claude-3.5-Sonnet 的 20 倍），性能顶尖。",
  "MiniMaxAI/MiniMax-M1-80k.description": "MiniMax-M1 是一款开源权重的大规模混合注意力推理模型，总参数 4560 亿，每个 token 激活约 459 亿。原生支持 100 万上下文，使用 Flash Attention，在生成 10 万 token 时比 DeepSeek R1 减少 75% FLOPs。采用 MoE 架构，结合 CISPO 和混合注意力 RL 训练，在长输入推理和真实软件工程任务中表现领先。",
  "MiniMaxAI/MiniMax-M2.description": "MiniMax-M2 重新定义了智能体效率。这是一款紧凑、快速、性价比高的 MoE 模型，总参数 2300 亿，激活参数仅 100 亿，专为顶级编程与智能体任务设计，同时保留强大的通用智能。仅用 100 亿激活参数即可媲美更大模型，适用于高效应用场景。",
  "Moonshot-Kimi-K2-Instruct.description": "总参数 1 万亿，激活参数 320 亿。在非思维模型中，在前沿知识、数学和编程方面表现顶尖，通用智能体任务能力更强。专为智能体工作负载优化，具备行动能力而非仅限问答。适合即兴对话、通用聊天和智能体体验，具备反射级响应能力，无需长时间思考。",
  "NousResearch/Nous-Hermes-2-Mixtral-8x7B-DPO.description": "Nous Hermes 2 - Mixtral 8x7B-DPO（总参数 46.7B）是一款高精度指令模型，适用于复杂计算任务。",
  "OmniConsistency.description": "OmniConsistency 通过引入大规模扩散 Transformer（DiTs）和配对风格化数据，提升图像到图像任务中的风格一致性与泛化能力，避免风格退化。",
  "Phi-3-medium-128k-instruct.description": "与 Phi-3-medium 模型相同，但支持更大上下文窗口，适用于 RAG 或少样本提示。",
  "Phi-3-medium-4k-instruct.description": "一款拥有 140 亿参数的模型，质量优于 Phi-3-mini，专注于高质量、推理密集型数据。",
  "Phi-3-mini-128k-instruct.description": "与 Phi-3-mini 模型相同，但支持更大上下文窗口，适用于 RAG 或少样本提示。",
  "Phi-3-mini-4k-instruct.description": "Phi-3 系列中最小的成员，优化了质量与低延迟表现。",
  "Phi-3-small-128k-instruct.description": "与 Phi-3-small 模型相同，但支持更大上下文窗口，适用于 RAG 或少样本提示。",
  "Phi-3-small-8k-instruct.description": "一款拥有 70 亿参数的模型，质量优于 Phi-3-mini，专注于高质量、推理密集型数据。",
  "Phi-3.5-mini-instruct.description": "Phi-3-mini 模型的更新版本。",
  "Phi-3.5-vision-instrust.description": "Phi-3-vision 模型的更新版本。",
  "Pro/Qwen/Qwen2-7B-Instruct.description": "Qwen2-7B-Instruct 是 Qwen2 系列中的一款 70 亿参数指令微调大模型。采用 Transformer 架构，结合 SwiGLU、注意力 QKV 偏置和分组查询注意力，支持大输入，语言理解、生成、多语言、编程、数学和推理能力强，超越大多数开源模型，媲美闭源模型。在多个基准测试中优于 Qwen1.5-7B-Chat。",
  "Pro/Qwen/Qwen2.5-7B-Instruct.description": "Qwen2.5-7B-Instruct 是阿里云最新大模型系列的一部分。该 70 亿参数模型在编程和数学方面有显著提升，支持 29+ 种语言，增强了指令理解、结构化数据处理和结构化输出（特别是 JSON）。",
  "Pro/Qwen/Qwen2.5-Coder-7B-Instruct.description": "Qwen2.5-Coder-7B-Instruct 是阿里云最新面向编程的大模型。基于 Qwen2.5 构建，训练数据达 5.5 万亿 token，显著提升代码生成、推理与修复能力，同时保留数学与通用能力，为编程智能体提供坚实基础。",
  "Pro/Qwen/Qwen2.5-VL-7B-Instruct.description": "Qwen2.5-VL 是 Qwen 系列最新的视觉语言模型，具备强大的视觉理解能力。可分析图像中的文本、图表和布局，理解长视频与事件，支持推理与工具使用、多格式目标定位和结构化输出。通过动态分辨率与帧率训练提升视频理解能力，并增强视觉编码器效率。",
  "Pro/THUDM/GLM-4.1V-9B-Thinking.description": "GLM-4.1V-9B-Thinking 是由智谱 AI 与清华 KEG 实验室联合开发的开源视觉语言模型，专为复杂多模态认知设计。基于 GLM-4-9B-0414 构建，加入思维链推理与强化学习，显著提升跨模态推理能力与稳定性。",
  "Pro/THUDM/glm-4-9b-chat.description": "GLM-4-9B-Chat 是智谱 AI 发布的开源 GLM-4 模型，在语义、数学、推理、编程和知识方面表现出色。除多轮对话外，还支持网页浏览、代码执行、自定义工具调用和长文本推理。支持 26 种语言（包括中文、英文、日语、韩语、德语），在 AlignBench-v2、MT-Bench、MMLU 和 C-Eval 等基准测试中表现优异，支持最长 128K 上下文，适用于学术与商业场景。",
  "Pro/deepseek-ai/DeepSeek-R1-Distill-Qwen-7B.description": "DeepSeek-R1-Distill-Qwen-7B 是从 Qwen2.5-Math-7B 蒸馏而来，并在 80 万条精心挑选的 DeepSeek-R1 样本上进行微调。该模型表现出色，在 MATH-500 上达到 92.8%，在 AIME 2024 上达到 55.5%，在 CodeForces 上的评分为 1189（7B 模型）。",
  "Pro/deepseek-ai/DeepSeek-R1.description": "DeepSeek-R1 是一个基于强化学习（RL）的推理模型，旨在减少重复并提升可读性。在 RL 之前使用冷启动数据进一步增强推理能力，在数学、编程和推理任务上可与 OpenAI-o1 相媲美，并通过精细训练提升整体表现。",
  "Pro/deepseek-ai/DeepSeek-V3.1-Terminus.description": "DeepSeek-V3.1-Terminus 是 V3.1 的更新版本，定位为混合代理大模型。该版本修复了用户反馈的问题，提升了稳定性、语言一致性，并减少了中英文混杂和异常字符。它集成了思维模式与非思维模式，并配备聊天模板以实现灵活切换。同时还提升了代码代理和搜索代理的性能，使工具使用和多步骤任务更加可靠。",
  "Pro/deepseek-ai/DeepSeek-V3.2-Exp.description": "DeepSeek-V3.2-Exp 是 V3.2 的实验性版本，作为通往下一代架构的桥梁。在 V3.1-Terminus 的基础上引入了 DeepSeek 稀疏注意力（DSA），以提升长上下文训练与推理效率，并针对工具使用、长文档理解和多步骤推理进行了优化。非常适合探索在大上下文预算下的高效推理能力。",
  "Pro/deepseek-ai/DeepSeek-V3.description": "DeepSeek-V3 是一个拥有 6710 亿参数的 MoE 模型，采用 MLA 和 DeepSeekMoE 架构，并通过无损负载均衡实现高效推理与训练。预训练数据量达 14.8 万亿高质量 token，并通过 SFT 和 RL 进一步调优，性能超越其他开源模型，接近领先的闭源模型。",
  "Pro/moonshotai/Kimi-K2-Instruct-0905.description": "Kimi K2-Instruct-0905 是最新且最强大的 Kimi K2 模型。作为顶级 MoE 模型，拥有 1 万亿总参数和 320 亿激活参数。其主要特点包括更强的代理式编程智能，在基准测试和真实代理任务中取得显著提升，同时前端代码美观性和可用性也得到优化。",
  "Pro/moonshotai/Kimi-K2-Thinking.description": "Kimi K2 Thinking Turbo 是 K2 Thinking 的高性能变体，在保持多步骤推理和工具使用能力的同时，优化了推理速度和吞吐量。该模型为 MoE 架构，拥有约 1 万亿总参数，原生支持 256K 上下文，并在生产场景中具备稳定的大规模工具调用能力，满足更严格的延迟与并发需求。",
  "Pro/zai-org/glm-4.7.description": "GLM-4.7 是智谱新一代旗舰模型，总参数量达 355B，激活参数量为 32B，在通用对话、推理和智能体能力方面实现了全面升级。GLM-4.7 强化了交错思考（Interleaved Thinking），并引入了保留思考（Preserved Thinking）和轮级思考（Turn-level Thinking）。",
  "QwQ-32B-Preview.description": "Qwen QwQ 是一个实验性研究模型，专注于提升推理能力。",
  "Qwen/QVQ-72B-Preview.description": "QVQ-72B-Preview 是 Qwen 团队推出的研究模型，专注于视觉推理，擅长复杂场景理解和视觉数学问题。",
  "Qwen/QwQ-32B-Preview.description": "Qwen QwQ 是一个实验性研究模型，致力于提升 AI 的推理能力。",
  "Qwen/QwQ-32B.description": "QwQ 是 Qwen 系列中的推理模型。与标准的指令微调模型相比，它引入了思维与推理机制，显著提升了下游任务表现，尤其在处理复杂问题时表现突出。QwQ-32B 是一款中等规模的推理模型，在性能上可与 DeepSeek-R1 和 o1-mini 等顶级推理模型竞争。该模型采用 RoPE、SwiGLU、RMSNorm 和带偏置的注意力 QKV，拥有 64 层和 40 个 Q 注意力头（GQA 中为 8 个 KV）。",
  "Qwen/Qwen-Image-Edit-2509.description": "Qwen-Image-Edit-2509 是 Qwen 团队推出的最新图像编辑版本，基于 200 亿参数的 Qwen-Image 模型构建，将强大的文本渲染能力扩展至图像编辑，实现精确的文本修改。该模型采用双重控制架构，输入分别传递至 Qwen2.5-VL 进行语义控制和 VAE 编码器进行外观控制，从而实现语义层与外观层的编辑。支持局部编辑（添加/删除/修改）及更高层次的语义编辑，如 IP 创作与风格迁移，同时保持语义一致性，在多个基准测试中取得 SOTA 表现。",
  "Qwen/Qwen-Image.description": "Qwen-Image 是 Qwen 团队推出的 200 亿参数图像生成基础模型，在复杂文本渲染和精确图像编辑方面取得重大突破，尤其擅长高保真中英文文本渲染。支持多行及段落排版，保持排版一致性。除文本渲染外，还支持从写实风格到动漫风格的多种图像风格，以及风格迁移、对象添加/删除、细节增强、文本编辑和姿态控制等高级编辑功能，致力于打造全面的视觉创作基础模型。",
  "Qwen/Qwen2-72B-Instruct.description": "Qwen 2 Instruct（72B）在企业级任务中提供精准的指令执行能力。",
  "Qwen/Qwen2-7B-Instruct.description": "Qwen2-7B-Instruct 是 Qwen2 系列中的 7B 指令微调模型，采用 Transformer 架构，结合 SwiGLU、QKV 偏置和分组查询注意力。该模型可处理大规模输入，在理解、生成、多语言、编程、数学和推理等基准测试中表现优异，超越大多数开源模型，并在多项评估中优于 Qwen1.5-7B-Chat。",
  "Qwen/Qwen2-VL-72B-Instruct.description": "Qwen2-VL 是最新的 Qwen-VL 模型，在 MathVista、DocVQA、RealWorldQA 和 MTVQA 等视觉基准测试中达到 SOTA 水平。支持超过 20 分钟的视频理解，适用于视频问答、对话和内容创作。具备复杂推理与决策能力，可与设备/机器人集成，实现视觉驱动的操作。除中英文外，还能识别多种语言文本，包括大多数欧洲语言、日语、韩语、阿拉伯语和越南语。",
  "Qwen/Qwen2.5-14B-Instruct.description": "Qwen2.5-14B-Instruct 是阿里云最新大语言模型系列的一部分。该 14B 模型在编程和数学方面有显著提升，支持 29 种以上语言，并在指令理解、结构化数据理解和结构化输出（尤其是 JSON）方面表现更优。",
  "Qwen/Qwen2.5-32B-Instruct.description": "Qwen2.5-32B-Instruct 是阿里云最新大语言模型系列的一部分。该 32B 模型在编程和数学方面有显著提升，支持 29 种以上语言，并在指令理解、结构化数据理解和结构化输出（尤其是 JSON）方面表现更优。",
  "Qwen/Qwen2.5-72B-Instruct-128K.description": "Qwen2.5-72B-Instruct 是阿里云最新大语言模型系列的一部分。该 72B 模型在编程和数学方面表现更强，支持最多 128K 输入和超过 8K 输出，覆盖 29 种以上语言，并在指令理解和结构化输出（尤其是 JSON）方面有显著提升。",
  "Qwen/Qwen2.5-72B-Instruct-Turbo.description": "Qwen2.5 是一个专为指令类任务优化的大语言模型系列。",
  "Qwen/Qwen2.5-72B-Instruct.description": "Qwen2.5-72B-Instruct 是阿里云最新大语言模型系列的一部分。该 72B 模型在编程和数学方面有显著提升，支持 29 种以上语言，并在指令理解、结构化数据理解和结构化输出（尤其是 JSON）方面表现更优。",
  "Qwen/Qwen2.5-7B-Instruct-Turbo.description": "Qwen2.5 是一个专为指令类任务优化的大语言模型系列。",
  "Qwen/Qwen2.5-7B-Instruct.description": "Qwen2.5-7B-Instruct 是阿里云最新大语言模型系列的一部分。该 7B 模型在编程和数学方面有显著提升，支持 29 种以上语言，并在指令理解、结构化数据理解和结构化输出（尤其是 JSON）方面表现更优。",
  "Qwen/Qwen2.5-Coder-32B-Instruct.description": "Qwen2.5 Coder 32B Instruct 是阿里云最新面向编程的大语言模型。基于 Qwen2.5 构建，并使用 5.5 万亿 tokens 进行训练，在代码生成、推理和修复方面有显著提升，同时保留数学和通用能力，为构建编程智能体提供强大基础。",
  "Qwen/Qwen2.5-Coder-7B-Instruct.description": "Qwen2.5-Coder-7B-Instruct 是阿里云最新面向编程的大语言模型。基于 Qwen2.5 构建，并使用 5.5 万亿 tokens 进行训练，在代码生成、推理和修复方面有显著提升，同时保留数学和通用能力，为构建编程智能体提供坚实基础。",
  "Qwen/Qwen2.5-VL-32B-Instruct.description": "Qwen2.5-VL-32B-Instruct 是 Qwen 团队推出的多模态模型。它能够识别常见物体并分析文本、图表、图标、图形和布局。作为视觉智能体，它可进行推理并动态控制工具，包括电脑和手机操作。它能精准定位物体，并为发票和表格生成结构化输出。相比 Qwen2-VL，强化学习进一步提升了数学和问题解决能力，生成更符合人类偏好的响应。",
  "Qwen/Qwen2.5-VL-72B-Instruct.description": "Qwen2.5-VL 是 Qwen2.5 系列中的视觉语言模型，具备重大升级：更强的视觉理解能力，涵盖物体、文本、图表和布局；作为视觉智能体具备动态工具使用能力；支持超过 1 小时的视频理解并捕捉关键事件；通过框或点实现精准物体定位；为扫描数据如发票和表格生成结构化输出。",
  "Qwen/Qwen3-14B.description": "Qwen3 是新一代通义千问模型，在推理能力、通用能力、智能体能力和多语言表现方面有重大提升，支持思维模式切换。",
  "Qwen/Qwen3-235B-A22B-Instruct-2507.description": "Qwen3-235B-A22B-Instruct-2507 是 Qwen3 的旗舰 MoE 模型，总参数 235B，激活参数 22B。该版本为非思维模式，专注于提升指令理解、逻辑推理、文本理解、数学、科学、编程和工具使用能力。同时扩展多语言长尾知识，更好地契合用户在主观开放任务中的偏好。",
  "Qwen/Qwen3-235B-A22B-Thinking-2507.description": "Qwen3-235B-A22B-Thinking-2507 是专注于复杂推理的 Qwen3 模型。采用 MoE 架构，总参数 235B，每个 token 激活约 22B 参数，提升效率。作为专用思维模型，在逻辑、数学、科学、编程和学术基准测试中表现卓越，达到顶级开放思维性能。同时提升了指令理解、工具使用和文本生成能力，原生支持 256K 上下文，适用于深度推理和长文档处理。",
  "Qwen/Qwen3-235B-A22B.description": "Qwen3 是新一代通义千问模型，在推理能力、通用能力、智能体能力和多语言表现方面有重大提升，支持思维模式切换。",
  "Qwen/Qwen3-30B-A3B-Instruct-2507.description": "Qwen3-30B-A3B-Instruct-2507 是 Qwen3-30B-A3B 的更新版非思维模型。该模型为 MoE 架构，总参数 30.5B，激活参数 3.3B。显著提升了指令理解、逻辑推理、文本理解、数学、科学、编程和工具使用能力，扩展多语言长尾知识，并更好地契合用户在主观开放任务中的偏好。支持 256K 上下文。该模型仅为非思维模式，不会输出 `<think></think>` 标签。",
  "Qwen/Qwen3-30B-A3B-Thinking-2507.description": "Qwen3-30B-A3B-Thinking-2507 是 Qwen3 系列中最新的思维模型。采用 MoE 架构，总参数 30.5B，激活参数 3.3B，专注于复杂任务。在逻辑、数学、科学、编程和学术基准测试中表现显著提升，同时增强了指令理解、工具使用、文本生成和偏好对齐能力。原生支持 256K 上下文，并可扩展至 1M tokens。该版本专为思维模式设计，具备详细的逐步推理能力和强大的智能体能力。",
  "Qwen/Qwen3-30B-A3B.description": "Qwen3 是新一代通义千问模型，在推理能力、通用能力、智能体能力和多语言表现方面有重大提升，支持思维模式切换。",
  "Qwen/Qwen3-32B.description": "Qwen3 是新一代通义千问模型，在推理能力、通用能力、智能体能力和多语言表现方面有重大提升，支持思维模式切换。",
  "Qwen/Qwen3-8B.description": "Qwen3 是新一代通义千问模型，在推理能力、通用能力、智能体能力和多语言表现方面有重大提升，支持思维模式切换。",
  "Qwen/Qwen3-Coder-30B-A3B-Instruct.description": "Qwen3-Coder-30B-A3B-Instruct 是 Qwen 团队推出的 Qwen3 系列代码模型。该模型在保持高性能和高效率的同时，显著增强了代码能力。在智能体编程、自动化浏览器操作和工具使用等开放模型中表现出色。原生支持 256K 上下文，并可扩展至 1M tokens，适用于代码库级理解。支持 Qwen Code 和 CLINE 等平台的智能体编程，采用专用函数调用格式。",
  "Qwen/Qwen3-Coder-480B-A35B-Instruct.description": "Qwen3-Coder-480B-A35B-Instruct 是阿里巴巴迄今为止最具智能体能力的代码模型。该模型为 MoE 架构，总参数 480B，激活参数 35B，在效率与性能之间实现平衡。原生支持 256K 上下文，并可通过 YaRN 扩展至 1M tokens，支持大规模代码库处理。专为智能体编程工作流设计，能够与工具和环境交互，解决复杂编程任务。在代码和智能体基准测试中表现优异，可媲美 Claude Sonnet 4 等领先模型。",
  "Qwen/Qwen3-Next-80B-A3B-Instruct.description": "Qwen3-Next-80B-A3B-Instruct 是一款基于 Qwen3-Next 架构的下一代基础模型，具备极高的训练与推理效率。该模型融合了混合注意力机制（门控 DeltaNet + 门控注意力）、高度稀疏的 MoE 架构以及训练稳定性优化。尽管总参数量为 800 亿，但推理时仅激活约 30 亿参数，大幅降低计算成本，在超过 32K 上下文长度下，相较 Qwen3-32B 实现了 10 倍以上的吞吐提升。该版本经过指令微调，面向通用任务（不启用“思考”模式），在部分基准测试中表现可与 Qwen3-235B 相媲美，尤其在超长上下文任务中展现出显著优势。",
  "Qwen/Qwen3-Next-80B-A3B-Thinking.description": "Qwen3-Next-80B-A3B-Thinking 是一款面向复杂推理任务的下一代基础模型，采用 Qwen3-Next 架构，结合混合注意力机制（门控 DeltaNet + 门控注意力）与高度稀疏的 MoE 架构，实现极致的训练与推理效率。模型总参数为 800 亿，推理时仅激活约 30 亿参数，在超过 32K 上下文长度下，相较 Qwen3-32B 实现了 10 倍以上的吞吐提升。该“思考”版本专为多步骤任务设计，如证明、代码生成、逻辑分析与规划，能够输出结构化的思维链条。其性能超越 Qwen3-32B-Thinking，并在多个基准测试中优于 Gemini-2.5-Flash-Thinking。",
  "Qwen/Qwen3-Omni-30B-A3B-Captioner.description": "Qwen3-Omni-30B-A3B-Captioner 是 Qwen3 系列的视觉语言模型（VLM），专为生成高质量、细致且准确的图像描述而设计。该模型采用 300 亿参数的 MoE 架构，具备深度图像理解能力，能够流畅生成描述，擅长捕捉细节、理解场景、识别物体及进行关系推理。",
  "Qwen/Qwen3-Omni-30B-A3B-Instruct.description": "Qwen3-Omni-30B-A3B-Instruct 是 Qwen3 系列的 MoE 模型，拥有 300 亿总参数和 30 亿激活参数，在保持强大性能的同时降低推理成本。该模型基于高质量多源多语种数据训练，支持全模态输入（文本、图像、音频、视频）及跨模态理解与生成。",
  "Qwen/Qwen3-Omni-30B-A3B-Thinking.description": "Qwen3-Omni-30B-A3B-Thinking 是 Qwen3-Omni 的核心“思考者”组件，能够处理多模态输入（文本、音频、图像、视频），并执行复杂的思维链推理。它将多模态信息统一为共享表示，实现深度跨模态理解。该模型采用 MoE 架构，拥有 300 亿总参数和 30 亿激活参数，在推理能力与计算效率之间实现良好平衡。",
  "Qwen/Qwen3-VL-235B-A22B-Instruct.description": "Qwen3-VL-235B-A22B-Instruct 是一款基于 MoE 架构的大型指令微调视觉语言模型，具备卓越的多模态理解与生成能力。原生支持 256K 上下文长度，适用于高并发生产级多模态服务场景。",
  "Qwen/Qwen3-VL-235B-A22B-Thinking.description": "Qwen3-VL-235B-A22B-Thinking 是 Qwen3-VL 的旗舰“思考”版本，专为复杂多模态推理、长上下文推理及企业级智能体交互优化。",
  "Qwen/Qwen3-VL-30B-A3B-Instruct.description": "Qwen3-VL-30B-A3B-Instruct 是一款经过指令微调的 Qwen3-VL 模型，具备强大的视觉语言理解与生成能力。原生支持 256K 上下文长度，适用于多模态对话与图像条件生成任务。",
  "Qwen/Qwen3-VL-30B-A3B-Thinking.description": "Qwen3-VL-30B-A3B-Thinking 是 Qwen3-VL 的推理增强版本，专为多模态推理、图像转代码及复杂视觉理解任务优化。支持 256K 上下文，具备更强的思维链能力。",
  "Qwen/Qwen3-VL-32B-Instruct.description": "Qwen3-VL-32B-Instruct 是 Qwen 团队推出的视觉语言模型，在多个 VL 基准测试中取得领先 SOTA 成绩。支持百万像素分辨率图像，具备强大的视觉理解、多语种 OCR、细粒度视觉定位与视觉对话能力，能够处理复杂多模态任务，并支持工具调用与前缀补全。",
  "Qwen/Qwen3-VL-32B-Thinking.description": "Qwen3-VL-32B-Thinking 针对复杂视觉推理任务进行了优化，内置“思考模式”，在生成答案前输出中间推理步骤，提升多步骤逻辑、规划与复杂推理能力。支持百万像素图像，具备强大的视觉理解、多语种 OCR、细粒度定位、视觉对话、工具调用与前缀补全能力。",
  "Qwen/Qwen3-VL-8B-Instruct.description": "Qwen3-VL-8B-Instruct 是基于 Qwen3-8B-Instruct 构建的视觉语言模型，训练于大规模图文数据，擅长通用视觉理解、以视觉为中心的对话及图像中的多语种文本识别，适用于视觉问答、图像描述、多模态指令跟随与工具使用等任务。",
  "Qwen/Qwen3-VL-8B-Thinking.description": "Qwen3-VL-8B-Thinking 是 Qwen3 的视觉思考版本，专为复杂多步骤推理任务优化。在生成答案前输出思维链，提升准确性，适用于深度视觉问答与图像细节分析。",
  "Qwen2-72B-Instruct.description": "Qwen2 是 Qwen 系列的最新版本，支持 128K 上下文窗口。与当前最强的开源模型相比，Qwen2-72B 在自然语言理解、知识、代码、数学及多语种能力方面显著领先。",
  "Qwen2-7B-Instruct.description": "Qwen2 是 Qwen 系列的最新版本，超越同尺寸甚至更大尺寸的开源模型。Qwen2 7B 在多个基准测试中表现出显著优势，尤其在代码与中文理解方面。",
  "Qwen2-VL-72B.description": "Qwen2-VL-72B 是一款强大的视觉语言模型，支持多模态图文处理，能够准确识别图像内容并生成相关描述或答案。",
  "Qwen2.5-14B-Instruct.description": "Qwen2.5-14B-Instruct 是一款拥有 140 亿参数的大语言模型，性能强劲，针对中文及多语种场景优化，支持智能问答与内容生成。",
  "Qwen2.5-32B-Instruct.description": "Qwen2.5-32B-Instruct 是一款拥有 320 亿参数的大语言模型，性能均衡，针对中文及多语种场景优化，支持智能问答与内容生成。",
  "Qwen2.5-72B-Instruct.description": "一款面向中英文的 LLM，针对语言、编程、数学与推理任务进行调优。",
  "Qwen2.5-7B-Instruct.description": "Qwen2.5-7B-Instruct 是一款拥有 70 亿参数的大语言模型，支持函数调用与外部系统无缝集成，极大提升灵活性与可扩展性。针对中文及多语种场景优化，支持智能问答与内容生成。",
  "Qwen2.5-Coder-14B-Instruct.description": "Qwen2.5-Coder-14B-Instruct 是一款大规模预训练的编程指令模型，具备强大的代码理解与生成能力，能够高效处理多种编程任务，适用于智能编程、自动脚本生成与编程问答。",
  "Qwen2.5-Coder-32B-Instruct.description": "高级 LLM，支持多种主流编程语言的代码生成、推理与错误修复。",
  "Qwen3-235B-A22B-Instruct-2507-FP8.description": "Qwen3 235B A22B Instruct 2507 通过 MoE 架构优化推理效率，专为高级推理与指令跟随任务设计。",
  "Qwen3-235B.description": "Qwen3-235B-A22B 是一款 MoE 模型，引入混合推理模式，用户可在“思考”与“非思考”之间无缝切换。支持 119 种语言与方言的理解与推理，具备强大的工具调用能力，在通用能力、代码与数学、多语种能力及知识推理等多个基准测试中，与 DeepSeek R1、OpenAI o1、o3-mini、Grok 3 及 Google Gemini 2.5 Pro 等主流模型展开竞争。",
  "Qwen3-32B.description": "Qwen3-32B 是一款稠密模型，引入混合推理模式，用户可在“思考”与“非思考”之间切换。通过架构改进、数据增强与训练优化，其性能可与 Qwen2.5-72B 相媲美。",
  "SenseChat-128K.description": "基于V4的128K上下文模型，擅长长文本理解与生成。",
  "SenseChat-32K.description": "基于V4的32K上下文模型，适用于多种场景，灵活高效。",
  "SenseChat-5-1202.description": "基于V5.5的最新版本，在中英文基础能力、对话、理工知识、人文知识、写作、数学/逻辑及长度控制方面有显著提升。",
  "SenseChat-5-Cantonese.description": "专为香港本地对话习惯、俚语及本地知识设计；粤语理解超越GPT-4，知识、推理、数学与编程能力媲美GPT-4 Turbo。",
  "SenseChat-5-beta.description": "部分性能超越SenseChat-5-1202。",
  "SenseChat-5.description": "最新V5.5版本，支持128K上下文；在数学推理、英文对话、指令理解及长文本处理方面有重大提升，整体表现可与GPT-4o媲美。",
  "SenseChat-Character-Pro.description": "高级角色对话模型，支持32K上下文，能力增强，支持中英文。",
  "SenseChat-Character.description": "标准角色对话模型，支持8K上下文，响应速度快。",
  "SenseChat-Turbo-1202.description": "最新轻量模型，在推理成本大幅降低的同时，达到90%以上的全模型能力。",
  "SenseChat-Turbo.description": "适用于快速问答及模型微调场景。",
  "SenseChat-Vision.description": "最新V5.5版本，支持多图输入，在属性识别、空间关系、动作/事件检测、场景理解、情感识别、常识推理及文本理解/生成方面全面提升。",
  "SenseChat.description": "基于V4的4K上下文模型，具备强大的通用能力。",
  "SenseNova-V6-5-Pro.description": "通过多模态、语言与推理数据的全面更新及训练策略优化，新模型在多模态推理与通用指令理解方面显著提升，支持最多128K上下文窗口，擅长OCR与文旅IP识别任务。",
  "SenseNova-V6-5-Turbo.description": "通过多模态、语言与推理数据的全面更新及训练策略优化，新模型在多模态推理与通用指令理解方面显著提升，支持最多128K上下文窗口，擅长OCR与文旅IP识别任务。",
  "SenseNova-V6-Pro.description": "原生统一图像、文本与视频，打破传统多模态壁垒；在OpenCompass与SuperCLUE等评测中名列前茅。",
  "SenseNova-V6-Reasoner.description": "融合视觉与语言的深度推理，支持慢思考与完整思维链。",
  "SenseNova-V6-Turbo.description": "原生统一图像、文本与视频，打破传统多模态壁垒；在核心多模态与语言能力方面领先，在多项评测中表现优异。",
  "Skylark2-lite-8k.description": "Skylark第二代模型。Skylark2-lite响应迅速，适用于对准确率要求不高的实时、成本敏感场景，支持8K上下文窗口。",
  "Skylark2-pro-32k.description": "Skylark第二代模型。Skylark2-pro具备更高准确率，适用于专业文案、小说创作及高质量翻译等复杂文本生成任务，支持32K上下文窗口。",
  "Skylark2-pro-4k.description": "Skylark第二代模型。Skylark2-pro具备更高准确率，适用于专业文案、小说创作及高质量翻译等复杂文本生成任务，支持4K上下文窗口。",
  "Skylark2-pro-character-4k.description": "Skylark第二代模型。Skylark2-pro-character擅长角色扮演与对话，能根据提示展现鲜明人设风格，适用于聊天机器人、虚拟助手与客服场景，响应迅速。",
  "Skylark2-pro-turbo-8k.description": "Skylark第二代模型。Skylark2-pro-turbo-8k在保持8K上下文窗口的同时，实现更快推理与更低成本。",
  "THUDM/GLM-4-32B-0414.description": "GLM-4-32B-0414是下一代开放GLM模型，拥有32B参数，性能可与OpenAI GPT及DeepSeek V3/R1系列媲美。",
  "THUDM/GLM-4-9B-0414.description": "GLM-4-9B-0414是9B参数的GLM模型，继承GLM-4-32B技术，部署更轻量，擅长代码生成、网页设计、SVG生成与基于搜索的写作。",
  "THUDM/GLM-4.1V-9B-Thinking.description": "GLM-4.1V-9B-Thinking是由智谱AI与清华KEG实验室联合推出的开源视觉语言模型，专为复杂多模态认知设计。基于GLM-4-9B-0414，加入思维链推理与强化学习，显著提升跨模态推理能力与稳定性。",
  "THUDM/GLM-Z1-32B-0414.description": "GLM-Z1-32B-0414是基于GLM-4-32B-0414构建的深度推理模型，结合冷启动数据与扩展强化学习，在数学、代码与逻辑任务上显著优于基础模型。",
  "THUDM/GLM-Z1-9B-0414.description": "GLM-Z1-9B-0414是9B参数的小型GLM模型，保留开源优势，具备强大能力，在数学推理与通用任务上表现出色，在同类开源模型中领先。",
  "THUDM/GLM-Z1-Rumination-32B-0414.description": "GLM-Z1-Rumination-32B-0414是具备深度思考能力的推理模型（对标OpenAI Deep Research）。与传统深度思考模型不同，它通过更长时间的思考解决更开放复杂的问题。",
  "THUDM/glm-4-9b-chat.description": "GLM-4-9B-Chat是智谱AI开源的GLM-4模型，在语义、数学、推理、代码与知识方面表现出色。除多轮对话外，还支持网页浏览、代码执行、自定义工具调用与长文本推理。支持26种语言（包括中文、英文、日文、韩文、德文），在AlignBench-v2、MT-Bench、MMLU与C-Eval等评测中表现优异，支持128K上下文，适用于学术与商业场景。",
  "Tongyi-Zhiwen/QwenLong-L1-32B.description": "QwenLong-L1-32B是首个通过强化学习训练的长上下文推理模型（LRM），专为长文本推理优化。其渐进式上下文扩展RL策略实现从短到长上下文的稳定迁移。在七个长文档问答基准上超越OpenAI-o3-mini与Qwen3-235B-A22B，媲美Claude-3.7-Sonnet-Thinking，尤其擅长数学、逻辑与多跳推理。",
  "Yi-34B-Chat.description": "Yi-1.5-34B在保留系列强大通用语言能力的基础上，通过对5000亿高质量token的增量训练，显著提升数学逻辑与编程能力。",
  "abab5.5-chat.description": "专为高效文本生成与复杂任务处理的专业场景设计，提升工作效率。",
  "abab5.5s-chat.description": "专为中文人设对话设计，提供高质量中文对话体验，适用于多种应用场景。",
  "abab6.5g-chat.description": "专为多语言人设对话设计，支持高质量英文及其他语言的对话生成。",
  "abab6.5s-chat.description": "适用于多种自然语言处理任务，包括文本生成与对话系统。",
  "abab6.5t-chat.description": "针对中文人设对话优化，提供符合中文表达习惯的流畅对话体验。",
  "accounts/fireworks/models/deepseek-r1.description": "DeepSeek-R1是最先进的大语言模型，结合强化学习与冷启动数据优化，具备卓越的推理、数学与编程能力。",
  "accounts/fireworks/models/deepseek-v3.description": "DeepSeek推出的强大专家混合（MoE）语言模型，总参数671B，每个token激活37B参数。",
  "accounts/fireworks/models/llama-v3-70b-instruct.description": "Meta 开发并发布了 Meta Llama 3 大语言模型系列，包括 8B 和 70B 参数规模的预训练与指令微调文本生成模型。Llama 3 的指令微调模型专为对话场景优化，在多个行业通用基准测试中优于许多现有的开源聊天模型。",
  "accounts/fireworks/models/llama-v3-8b-instruct-hf.description": "Meta Llama 3 的指令微调模型专为对话场景优化，在多个行业通用基准测试中优于许多现有的开源聊天模型。Llama 3 8B Instruct（HF 版本）是 Llama 3 8B Instruct 的原始 FP16 版本，预期结果与 Hugging Face 官方实现一致。",
  "accounts/fireworks/models/llama-v3-8b-instruct.description": "Meta 开发并发布了 Meta Llama 3 大语言模型系列，包括 8B 和 70B 参数规模的预训练与指令微调文本生成模型。Llama 3 的指令微调模型专为对话场景优化，在多个行业通用基准测试中优于许多现有的开源聊天模型。",
  "accounts/fireworks/models/llama-v3p1-405b-instruct.description": "Meta Llama 3.1 是一个多语言大语言模型系列，提供 8B、70B 和 405B 参数规模的预训练与指令微调生成模型。指令微调模型专为多语言对话优化，在多个行业通用基准测试中优于许多开源和闭源聊天模型。405B 是 Llama 3.1 系列中最强大的模型，采用 FP8 推理，性能接近参考实现。",
  "accounts/fireworks/models/llama-v3p1-70b-instruct.description": "Meta Llama 3.1 是一个多语言大语言模型系列，提供 8B、70B 和 405B 参数规模的预训练与指令微调生成模型。指令微调模型专为多语言对话优化，在多个行业通用基准测试中优于许多开源和闭源聊天模型。",
  "accounts/fireworks/models/llama-v3p1-8b-instruct.description": "Meta Llama 3.1 是一个多语言大语言模型系列，提供 8B、70B 和 405B 参数规模的预训练与指令微调生成模型。指令微调模型专为多语言对话优化，在多个行业通用基准测试中优于许多开源和闭源聊天模型。",
  "accounts/fireworks/models/llama-v3p2-11b-vision-instruct.description": "Meta 推出的一个拥有 110 亿参数的指令微调视觉推理模型，专为图像识别、图像推理、图像描述和图像相关问答优化。该模型能够理解图表等视觉数据，并通过生成图像细节的文本描述实现视觉与语言的融合。",
  "accounts/fireworks/models/llama-v3p2-3b-instruct.description": "Llama 3.2 3B Instruct 是 Meta 推出的轻量级多语言模型，具备高效运行能力，在延迟和成本方面相较于大型模型具有显著优势。典型应用包括查询/提示重写和写作辅助。",
  "accounts/fireworks/models/llama-v3p2-90b-vision-instruct.description": "Meta 推出的一个拥有 900 亿参数的指令微调视觉推理模型，专为图像识别、图像推理、图像描述和图像相关问答优化。该模型能够理解图表等视觉数据，并通过生成图像细节的文本描述实现视觉与语言的融合。注意：该模型目前作为无服务器模型实验性提供，Fireworks 可能会在短时间内终止部署，生产环境使用请注意。",
  "accounts/fireworks/models/llama-v3p3-70b-instruct.description": "Llama 3.3 70B Instruct 是 Llama 3.1 70B 的 12 月更新版本，在工具使用、多语言文本支持、数学和编程方面相较 2024 年 7 月版本有显著提升。该模型在推理、数学和指令遵循方面达到行业领先水平，性能接近 3.1 405B，同时具备更高的速度和成本优势。",
  "accounts/fireworks/models/mistral-small-24b-instruct-2501.description": "一个拥有 240 亿参数的模型，具备与更大模型相当的先进能力。",
  "accounts/fireworks/models/mixtral-8x22b-instruct.description": "Mixtral MoE 8x22B Instruct v0.1 是 Mixtral MoE 8x22B v0.1 的指令微调版本，启用了聊天补全 API。",
  "accounts/fireworks/models/mixtral-8x7b-instruct.description": "Mixtral MoE 8x7B Instruct 是 Mixtral MoE 8x7B 的指令微调版本，启用了聊天补全 API。",
  "accounts/fireworks/models/mythomax-l2-13b.description": "MythoMix 的改进版本，可能是其更精致的形式，融合了 MythoLogic-L2 和 Huginn，并采用高度实验性的张量合并技术。其独特性使其在讲故事和角色扮演方面表现出色。",
  "accounts/fireworks/models/phi-3-vision-128k-instruct.description": "Phi-3-Vision-128K-Instruct 是一个轻量级、先进的开源多模态模型，基于合成数据和精选的公共网络数据集构建，专注于高质量、推理密集型的文本与视觉数据。该模型属于 Phi-3 系列，支持 128K 上下文长度（以 token 计）。通过监督微调和偏好优化等严格增强过程，确保指令遵循的准确性和强大的安全性。",
  "accounts/fireworks/models/qwen-qwq-32b-preview.description": "Qwen QwQ 模型专注于推动 AI 推理能力，展示了开源模型在推理方面可与闭源前沿模型媲美。QwQ-32B-Preview 是一个实验性版本，在 GPQA、AIME、MATH-500 和 LiveCodeBench 等推理与分析任务中达到 o1 水平并超越 GPT-4o 和 Claude 3.5 Sonnet。注意：该模型目前作为无服务器模型实验性提供，Fireworks 可能会在短时间内终止部署，生产环境使用请注意。",
  "accounts/fireworks/models/qwen2-vl-72b-instruct.description": "72B Qwen-VL 模型是阿里巴巴最新版本，体现了近一年的创新成果。",
  "accounts/fireworks/models/qwen2p5-72b-instruct.description": "Qwen2.5 是由 Qwen 团队与阿里云联合开发的仅解码器大语言模型系列，提供 0.5B、1.5B、3B、7B、14B、32B 和 72B 参数规模，涵盖基础模型与指令微调版本。",
  "accounts/fireworks/models/qwen2p5-coder-32b-instruct.description": "Qwen2.5-Coder 是最新的 Qwen 编码大语言模型（前身为 CodeQwen）。注意：该模型目前作为无服务器模型实验性提供，Fireworks 可能会在短时间内终止部署，生产环境使用请注意。",
  "accounts/yi-01-ai/models/yi-large.description": "Yi-Large 是一款顶级大语言模型，在 LMSYS 排行榜上仅次于 GPT-4、Gemini 1.5 Pro 和 Claude 3 Opus。该模型在多语言能力方面表现出色，尤其擅长西班牙语、中文、日语、德语和法语。Yi-Large 也非常适合开发者使用，采用与 OpenAI 相同的 API 架构，便于集成。",
  "ai21-jamba-1.5-large.description": "一个拥有 3980 亿参数（其中 940 亿激活）的多语言模型，支持 256K 上下文窗口、函数调用、结构化输出和基于事实的生成。",
  "ai21-jamba-1.5-mini.description": "一个拥有 520 亿参数（其中 120 亿激活）的多语言模型，支持 256K 上下文窗口、函数调用、结构化输出和基于事实的生成。",
  "ai21-labs/AI21-Jamba-1.5-Large.description": "一个拥有 3980 亿参数（其中 940 亿激活）的多语言模型，支持 256K 上下文窗口、函数调用、结构化输出和基于事实的生成。",
  "ai21-labs/AI21-Jamba-1.5-Mini.description": "一个拥有 520 亿参数（其中 120 亿激活）的多语言模型，支持 256K 上下文窗口、函数调用、结构化输出和基于事实的生成。",
  "alibaba/qwen-3-14b.description": "Qwen3 是 Qwen 系列的最新一代，提供全面的稠密与 MoE 模型组合。基于大规模训练，在推理、指令遵循、智能体能力和多语言支持方面实现突破。",
  "alibaba/qwen-3-235b.description": "Qwen3 是 Qwen 系列的最新一代，提供全面的稠密与 MoE 模型组合。基于大规模训练，在推理、指令遵循、智能体能力和多语言支持方面实现突破。",
  "alibaba/qwen-3-30b.description": "Qwen3 是 Qwen 系列的最新一代，提供全面的稠密与 MoE 模型组合。基于大规模训练，在推理、指令遵循、智能体能力和多语言支持方面实现突破。",
  "alibaba/qwen-3-32b.description": "Qwen3 是 Qwen 系列的最新一代，提供全面的稠密与 MoE 模型组合。基于大规模训练，在推理、指令遵循、智能体能力和多语言支持方面实现突破。",
  "alibaba/qwen3-coder.description": "Qwen3-Coder-480B-A35B-Instruct 是 Qwen 系列中最具智能体能力的代码模型，在智能体编程、浏览器操作等核心编程任务中表现强劲，达到 Claude Sonnet 水平。",
  "amazon/nova-lite.description": "一款极低成本的多模态模型，能够以极快速度处理图像、视频和文本输入。",
  "amazon/nova-micro.description": "一款仅支持文本的模型，具备超低延迟和极低成本。",
  "amazon/nova-pro.description": "一款功能强大的多模态模型，在准确性、速度和成本之间实现最佳平衡，适用于多种任务。",
  "amazon/titan-embed-text-v2.description": "Amazon Titan Text Embeddings V2 是一个轻量级、高效的多语言嵌入模型，支持 1024、512 和 256 维度。",
  "anthropic.claude-3-5-sonnet-20240620-v1:0.description": "Claude 3.5 Sonnet 提升了行业标准，在广泛评估中超越竞争对手和 Claude 3 Opus，同时保持中等速度和成本。",
  "anthropic.claude-3-5-sonnet-20241022-v2:0.description": "Claude 3.5 Sonnet 提升了行业标准，在广泛评估中超越竞争对手和 Claude 3 Opus，同时保持中等速度和成本。",
  "anthropic.claude-3-haiku-20240307-v1:0.description": "Claude 3 Haiku 是 Anthropic 迄今最快、最紧凑的模型，能为简单查询提供近乎即时的响应。它支持图像输入，具备 200K 上下文窗口，带来流畅自然的 AI 交互体验。",
  "anthropic.claude-3-opus-20240229-v1:0.description": "Claude 3 Opus 是 Anthropic 最强大的 AI 模型，在处理高度复杂任务方面表现卓越。它能流畅应对开放式提示和新颖场景，具备类人理解能力，并支持图像输入和 200K 上下文窗口。",
  "anthropic.claude-3-sonnet-20240229-v1:0.description": "Claude 3 Sonnet 在智能与速度之间实现平衡，适用于企业级工作负载，具备高性价比。支持图像输入和 200K 上下文窗口，是大规模 AI 部署的可靠选择。",
  "anthropic.claude-instant-v1.description": "一款快速、经济且功能强大的模型，适用于日常对话、文本分析、摘要生成和文档问答。",
  "anthropic.claude-v2.description": "一款功能全面的模型，擅长处理复杂对话、创意生成和详细指令执行等任务。",
  "anthropic.claude-v2:1.description": "Claude 2 的升级版，具备双倍上下文窗口，并在长文档处理和 RAG 场景中提升了可靠性、幻觉率和基于证据的准确性。",
  "anthropic/claude-3-haiku.description": "Claude 3 Haiku 是 Anthropic 迄今最快的模型，专为企业级长提示工作负载设计。可快速分析季度报告、合同或法律案件等大型文档，成本仅为同类模型的一半。",
  "anthropic/claude-3-opus.description": "Claude 3 Opus 是 Anthropic 最智能的模型，在处理高度复杂任务方面表现领先，能流畅应对开放式提示和新颖场景，具备类人理解能力。",
  "anthropic/claude-3.5-haiku.description": "Claude 3.5 Haiku 提升了速度、编程准确性和工具使用能力，适用于对速度和工具交互要求较高的场景。",
  "anthropic/claude-3.5-sonnet.description": "Claude 3.5 Sonnet 是 Sonnet 系列中快速高效的模型，具备更强的编程和推理能力，部分版本将逐步被 Sonnet 3.7 及后续版本取代。",
  "anthropic/claude-3.7-sonnet.description": "Claude 3.7 Sonnet 是升级版 Sonnet 模型，具备更强的推理和编程能力，适用于企业级复杂任务。",
  "anthropic/claude-haiku-4.5.description": "Claude Haiku 4.5 是 Anthropic 的高性能快速模型，在保持高准确率的同时实现极低延迟。",
  "anthropic/claude-opus-4.1.description": "Opus 4.1 是 Anthropic 的高端模型，专为编程、复杂推理和长时间任务优化。",
  "anthropic/claude-opus-4.5.description": "Claude Opus 4.5 是 Anthropic 的旗舰模型，结合顶级智能与可扩展性能，适用于复杂、高质量推理任务。",
  "anthropic/claude-opus-4.description": "Opus 4 是 Anthropic 的旗舰模型，专为复杂任务和企业应用设计。",
  "anthropic/claude-sonnet-4.5.description": "Claude Sonnet 4.5 是 Anthropic 最新的混合推理模型，专为复杂推理和编程优化。",
  "anthropic/claude-sonnet-4.description": "Claude Sonnet 4 是 Anthropic 的混合推理模型，具备思考与非思考能力的结合。",
  "ascend-tribe/pangu-pro-moe.description": "Pangu-Pro-MoE 72B-A16B 是一款稀疏大语言模型，拥有 720 亿总参数和 160 亿激活参数，基于分组专家混合（MoGE）架构。该模型在专家选择时进行分组，并限制每组激活相同数量的专家，从而实现负载均衡并提升在昇腾平台上的部署效率。",
  "aya.description": "Aya 23 是 Cohere 推出的多语言模型，支持 23 种语言，适用于多样化的应用场景。",
  "aya:35b.description": "Aya 23 是 Cohere 推出的多语言模型，支持 23 种语言，适用于多样化的应用场景。",
  "azure-DeepSeek-R1-0528.description": "由微软部署的 DeepSeek R1 已升级为 DeepSeek-R1-0528。此次更新增强了计算能力和后训练算法优化，显著提升了推理深度和推理能力，在数学、编程和通用逻辑基准测试中表现优异，接近 O3 和 Gemini 2.5 Pro 等领先模型。",
  "baichuan-m2-32b.description": "Baichuan M2 32B 是百川智能推出的 MoE 模型，具备强大的推理能力。",
  "baichuan/baichuan2-13b-chat.description": "Baichuan-13B 是百川推出的开源、可商用的 130 亿参数大语言模型，在权威中英文基准测试中取得同类模型中的最佳表现。",
  "baidu/ERNIE-4.5-300B-A47B.description": "ERNIE-4.5-300B-A47B 是百度推出的 MoE 大语言模型，拥有 3000 亿总参数和每个 token 激活 470 亿参数，兼顾强大性能与计算效率。作为 ERNIE 4.5 的核心模型，在理解、生成、推理和编程方面表现出色。采用多模态异构 MoE 预训练方法，结合文本与视觉联合训练，显著提升了指令跟随能力和世界知识。",
  "baidu/ernie-5.0-thinking-preview.description": "ERNIE 5.0 思维预览版是百度下一代原生多模态 ERNIE 模型，擅长多模态理解、指令跟随、创作、事实问答和工具调用。",
  "black-forest-labs/flux-1.1-pro.description": "FLUX 1.1 Pro 是一款速度更快、质量更高的图像生成模型，具备卓越的图像质量和提示响应能力。",
  "black-forest-labs/flux-dev.description": "FLUX Dev 是 FLUX 的开发版本，仅供非商业用途使用。",
  "black-forest-labs/flux-pro.description": "FLUX Pro 是专业级图像生成模型，输出高质量图像。",
  "black-forest-labs/flux-schnell.description": "FLUX Schnell 是一款专为速度优化的快速图像生成模型。",
  "c4ai-aya-expanse-32b.description": "Aya Expanse 是一款高性能的 320 亿参数多语言模型，结合指令微调、数据套利、偏好训练和模型融合，性能媲美单语模型，支持 23 种语言。",
  "c4ai-aya-expanse-8b.description": "Aya Expanse 是一款高性能的 80 亿参数多语言模型，结合指令微调、数据套利、偏好训练和模型融合，性能媲美单语模型，支持 23 种语言。",
  "c4ai-aya-vision-32b.description": "Aya Vision 是一款先进的多模态模型，在语言、文本和视觉基准测试中表现出色。该 320 亿参数版本专注于顶级多语言性能，支持 23 种语言。",
  "c4ai-aya-vision-8b.description": "Aya Vision 是一款先进的多模态模型，在语言、文本和视觉基准测试中表现出色。该 80 亿参数版本专注于低延迟和强大性能。",
  "charglm-3.description": "CharGLM-3 专为角色扮演和情感陪伴设计，支持超长多轮记忆和个性化对话。",
  "charglm-4.description": "CharGLM-4 专为角色扮演和情感陪伴设计，支持超长多轮记忆和个性化对话。",
  "chatgpt-4o-latest.description": "ChatGPT-4o 是一款实时更新的动态模型，结合强大的理解与生成能力，适用于客户支持、教育和技术支持等大规模应用场景。",
  "claude-2.0.description": "Claude 2 提供关键的企业级改进，包括领先的 20 万 token 上下文窗口、减少幻觉、系统提示支持，以及新测试功能：工具调用。",
  "claude-2.1.description": "Claude 2 提供关键的企业级改进，包括领先的 20 万 token 上下文窗口、减少幻觉、系统提示支持，以及新测试功能：工具调用。",
  "claude-3-5-haiku-20241022.description": "Claude 3.5 Haiku 是 Anthropic 推出的下一代最快模型，在多项能力上实现提升，并在多个基准测试中超越前代旗舰 Claude 3 Opus。",
  "claude-3-5-haiku-latest.description": "Claude 3.5 Haiku 提供快速响应，适用于轻量级任务。",
  "claude-3-7-sonnet-20250219.description": "Claude Sonnet 3.7 是 Anthropic 最智能的模型，也是市场上首个混合推理模型，支持近乎即时响应或细致的深度思考，具备精细化控制能力。",
  "claude-3-7-sonnet-latest.description": "Claude 3.7 Sonnet 是 Anthropic 最新、最强大的模型，适用于高度复杂的任务，在性能、智能、流畅性和理解力方面表现卓越。",
  "claude-3-haiku-20240307.description": "Claude 3 Haiku 是 Anthropic 推出的最快、最紧凑的模型，专为近乎即时响应而设计，具备快速且准确的性能。",
  "claude-3-opus-20240229.description": "Claude 3 Opus 是 Anthropic 最强大的模型，适用于高度复杂的任务，在性能、智能、流畅性和理解力方面表现卓越。",
  "claude-3-sonnet-20240229.description": "Claude 3 Sonnet 在智能与速度之间取得平衡，适用于企业级工作负载，提供高效能与低成本的可靠部署。",
  "claude-haiku-4-5-20251001.description": "Claude Haiku 4.5 是 Anthropic 推出的最快且最智能的 Haiku 模型，兼具闪电般的速度与深度思考能力。",
  "claude-opus-4-1-20250805-thinking.description": "Claude Opus 4.1 Thinking 是一款高级变体，能够展示其推理过程。",
  "claude-opus-4-1-20250805.description": "Claude Opus 4.1 是 Anthropic 最新、最强大的模型，适用于高度复杂的任务，在性能、智能、流畅性和理解力方面表现卓越。",
  "claude-opus-4-20250514.description": "Claude Opus 4 是 Anthropic 最强大的模型，专为处理高度复杂任务而设计，在性能、智能、流畅性和理解力方面表现卓越。",
  "claude-opus-4-5-20251101.description": "Claude Opus 4.5 是 Anthropic 的旗舰模型，结合卓越智能与可扩展性能，适用于需要最高质量响应与推理的复杂任务。",
  "claude-sonnet-4-20250514-thinking.description": "Claude Sonnet 4 Thinking 可生成近乎即时的响应或可视化的逐步推理过程。",
  "claude-sonnet-4-20250514.description": "Claude Sonnet 4 是 Anthropic 迄今为止最智能的模型，支持近乎即时响应或逐步深入思考，API 用户可实现精细化控制。",
  "claude-sonnet-4-5-20250929.description": "Claude Sonnet 4.5 是 Anthropic 迄今为止最智能的模型。",
  "codegeex-4.description": "CodeGeeX-4 是一款强大的 AI 编程助手，支持多语言问答和代码补全，提升开发者效率。",
  "codegeex4-all-9b.description": "CodeGeeX4-ALL-9B 是一款多语言代码生成模型，支持代码补全与生成、代码解释器、网页搜索、函数调用和仓库级代码问答，覆盖广泛的软件开发场景。是 100 亿参数以下的顶级代码模型。",
  "codegemma.description": "CodeGemma 是一款轻量级模型，适用于多种编程任务，支持快速迭代与集成。",
  "codegemma:2b.description": "CodeGemma 是一款轻量级模型，适用于多种编程任务，支持快速迭代与集成。",
  "codellama.description": "Code Llama 是一款专注于代码生成与讨论的大语言模型，支持多种编程语言，适用于开发者工作流。",
  "codellama/CodeLlama-34b-Instruct-hf.description": "Code Llama 是一款专注于代码生成与讨论的大语言模型，支持多种编程语言，适用于开发者工作流。",
  "codellama:13b.description": "Code Llama 是一款专注于代码生成与讨论的大语言模型，支持多种编程语言，适用于开发者工作流。",
  "codellama:34b.description": "Code Llama 是一款专注于代码生成与讨论的大语言模型，支持多种编程语言，适用于开发者工作流。",
  "codellama:70b.description": "Code Llama 是一款专注于代码生成与讨论的大语言模型，支持多种编程语言，适用于开发者工作流。",
  "codeqwen.description": "CodeQwen1.5 是一款在大规模代码数据上训练的大语言模型，专为复杂编程任务设计。",
  "codestral-latest.description": "Codestral 是我们最先进的代码模型；v2（2025年1月）专为低延迟、高频任务（如 FIM、代码修复和测试生成）而设计。",
  "codestral.description": "Codestral 是 Mistral AI 推出的首个代码模型，具备强大的代码生成能力。",
  "codex-mini-latest.description": "codex-mini-latest 是为 Codex CLI 微调的 o4-mini 模型。若需直接通过 API 使用，建议从 gpt-4.1 开始。",
  "cogito-2.1:671b.description": "Cogito v2.1 671B 是一款美国开源大语言模型，可免费商用，性能媲美顶级模型，具备更高的 Token 推理效率、128k 长上下文能力以及强大的综合能力。",
  "cogview-4.description": "CogView-4 是智谱推出的首个支持中文字符生成的开源文生图模型，提升了语义理解、图像质量和中英文文本渲染能力，支持任意长度的中英文提示词，并可在指定范围内生成任意分辨率图像。",
  "cohere-command-r-plus.description": "Command R+ 是一款为企业级工作负载优化的先进 RAG 模型。",
  "cohere-command-r.description": "Command R 是一款可扩展的生成模型，专为 RAG 和工具使用场景设计，支持生产级 AI 应用。",
  "cohere/Cohere-command-r-plus.description": "Command R+ 是一款为企业级工作负载优化的先进 RAG 模型。",
  "cohere/Cohere-command-r.description": "Command R 是一款可扩展的生成模型，专为 RAG 和工具使用场景设计，支持生产级 AI 应用。",
  "cohere/command-a.description": "Command A 是 Cohere 迄今为止最强大的模型，擅长工具使用、智能体、RAG 和多语言场景。支持 256K 上下文长度，仅需两块 GPU 即可运行，吞吐量比 Command R+ 08-2024 提高 150%。",
  "cohere/command-r-plus.description": "Command R+ 是 Cohere 最新的大语言模型，针对聊天和长上下文任务进行了优化，旨在实现卓越性能，助力企业从原型走向生产部署。",
  "cohere/command-r.description": "Command R 针对聊天和长上下文任务进行了优化，定位为“可扩展”模型，在高性能与准确性之间实现平衡，助力企业从原型走向生产部署。",
  "cohere/embed-v4.0.description": "一个可将文本、图像或混合内容分类或转换为嵌入向量的模型。",
  "comfyui/flux-dev.description": "FLUX.1 Dev 是一款高质量的文生图模型（10–50 步），非常适合高端创意和艺术输出。",
  "comfyui/flux-kontext-dev.description": "FLUX.1 Kontext-dev 是一款图像编辑模型，支持基于文本的局部编辑和风格迁移。",
  "comfyui/flux-krea-dev.description": "FLUX.1 Krea-dev 是与 Krea 联合开发的安全增强型文生图模型，内置安全过滤机制。",
  "comfyui/flux-schnell.description": "FLUX.1 Schnell 是一款超高速文生图模型，可在 1-4 步内生成高质量图像，适用于实时使用和快速原型开发。",
  "comfyui/stable-diffusion-15.description": "Stable Diffusion 1.5 是一款经典的 512x512 文生图模型，适合快速原型开发和创意实验。",
  "comfyui/stable-diffusion-35-inclclip.description": "Stable Diffusion 3.5 内置 CLIP/T5 编码器，无需外部编码器文件，适用于如 sd3.5_medium_incl_clips 等资源占用较低的模型。",
  "comfyui/stable-diffusion-35.description": "Stable Diffusion 3.5 是下一代文生图模型，提供 Large 和 Medium 两个版本。需使用外部 CLIP 编码器文件，图像质量和提示词响应能力出色。",
  "comfyui/stable-diffusion-custom-refiner.description": "自定义 SDXL 图生图模型。模型文件名应为 custom_sd_lobe.safetensors；如有 VAE，请使用 custom_sd_vae_lobe.safetensors。将模型文件放入 Comfy 指定文件夹中。",
  "comfyui/stable-diffusion-custom.description": "自定义 SD 文生图模型。模型文件名应为 custom_sd_lobe.safetensors；如有 VAE，请使用 custom_sd_vae_lobe.safetensors。将模型文件放入 Comfy 指定文件夹中。",
  "comfyui/stable-diffusion-refiner.description": "SDXL 图生图模型，可对输入图像进行高质量转换，支持风格迁移、图像修复和创意变体生成。",
  "comfyui/stable-diffusion-xl.description": "SDXL 是一款支持 1024x1024 高分辨率生成的文生图模型，图像质量和细节表现更佳。",
  "command-a-03-2025.description": "Command A 是我们迄今为止最强大的模型，擅长工具使用、智能体、RAG 和多语言场景。支持 256K 上下文窗口，仅需两块 GPU 即可运行，吞吐量比 Command R+ 08-2024 提高 150%。",
  "command-light-nightly.description": "为缩短主要版本之间的发布间隔，我们提供 Command 系列的每晚构建版本。command-light-nightly 是 command-light 系列中最新、最具实验性（可能不稳定）的版本，定期更新，适合测试用途，不建议用于生产环境。",
  "command-light.description": "Command 的轻量快速版本，几乎同样强大但响应更快。",
  "command-nightly.description": "为缩短主要版本之间的发布间隔，我们提供 Command 系列的每晚构建版本。command-nightly 是 Command 系列中最新、最具实验性（可能不稳定）的版本，定期更新，适合测试用途，不建议用于生产环境。",
  "command-r-03-2024.description": "Command R 是一款遵循指令的聊天模型，质量更高、可靠性更强、上下文窗口更长，支持代码生成、RAG、工具使用和智能体等复杂工作流。",
  "command-r-08-2024.description": "command-r-08-2024 是 2024 年 8 月发布的 Command R 模型更新版本。",
  "command-r-plus-04-2024.description": "command-r-plus 是 command-r-plus-04-2024 的别名，API 中使用 command-r-plus 即指向该模型。",
  "command-r-plus-08-2024.description": "Command R+ 是一款遵循指令的聊天模型，质量更高、可靠性更强、上下文窗口更长，特别适用于复杂的 RAG 工作流和多步骤工具使用。",
  "command-r-plus.description": "Command R+ 是一款高性能大语言模型，专为真实企业场景和复杂应用设计。",
  "command-r.description": "Command R 是一款针对聊天和长上下文任务优化的大语言模型，适用于动态交互和知识管理。",
  "command-r7b-12-2024.description": "command-r7b-12-2024 是 2024 年 12 月发布的小型高效更新版本，擅长 RAG、工具使用和需要复杂多步骤推理的智能体任务。",
  "command.description": "一款遵循指令的聊天模型，在语言任务中提供更高质量和可靠性，拥有比基础生成模型更长的上下文窗口。",
  "computer-use-preview.description": "computer-use-preview 是为“计算机使用工具”专门训练的模型，能够理解并执行与计算机相关的任务。",
  "dall-e-2.description": "第二代 DALL·E 模型，图像生成更真实、准确，分辨率是第一代的 4 倍。",
  "dall-e-3.description": "最新的 DALL·E 模型，于 2023 年 11 月发布，图像生成更真实、准确，细节表现更强。",
  "databricks/dbrx-instruct.description": "DBRX Instruct 提供跨行业高度可靠的指令处理能力。",
  "deepseek-ai/DeepSeek-OCR.description": "DeepSeek-OCR 是 DeepSeek AI 推出的视觉语言模型，专注于光学字符识别（OCR）和“上下文光学压缩”。该模型探索从图像中压缩上下文信息，能够高效处理文档并将其转换为结构化文本（如 Markdown）。它在图像文字识别方面表现精准，适用于文档数字化、文本提取和结构化处理。",
  "deepseek-ai/DeepSeek-R1-0528-Qwen3-8B.description": "DeepSeek-R1-0528-Qwen3-8B 将 DeepSeek-R1-0528 的链式思维能力蒸馏至 Qwen3 8B Base 模型中。在开源模型中达到 SOTA 水平，在 AIME 2024 上超越 Qwen3 8B 10%，并与 Qwen3-235B-thinking 表现相当。擅长数学推理、编程和通用逻辑任务，采用 Qwen3-8B 架构，并使用 DeepSeek-R1-0528 的分词器。",
  "deepseek-ai/DeepSeek-R1-0528.description": "DeepSeek R1 利用更强的计算资源和后训练算法优化，显著增强推理能力。在数学、编程和通用逻辑等基准测试中表现优异，接近 o3 和 Gemini 2.5 Pro 等领先模型。",
  "deepseek-ai/DeepSeek-R1-Distill-Llama-70B.description": "DeepSeek-R1 蒸馏模型通过强化学习和冷启动数据提升推理能力，刷新开源多任务模型基准。",
  "deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B.description": "DeepSeek-R1 蒸馏模型通过强化学习和冷启动数据提升推理能力，刷新开源多任务模型基准。",
  "deepseek-ai/DeepSeek-R1-Distill-Qwen-14B.description": "DeepSeek-R1 蒸馏模型通过强化学习和冷启动数据提升推理能力，刷新开源多任务模型基准。",
  "deepseek-ai/DeepSeek-R1-Distill-Qwen-32B.description": "DeepSeek-R1-Distill-Qwen-32B 由 Qwen2.5-32B 蒸馏而来，并在 80 万条精挑细选的 DeepSeek-R1 样本上微调。擅长数学、编程和推理任务，在 AIME 2024、MATH-500（94.3% 准确率）和 GPQA Diamond 上表现出色。",
  "deepseek-ai/DeepSeek-R1-Distill-Qwen-7B.description": "DeepSeek-R1-Distill-Qwen-7B 由 Qwen2.5-Math-7B 蒸馏而来，并在 80 万条 DeepSeek-R1 精选样本上微调。在 MATH-500 上达到 92.8%、AIME 2024 达到 55.5%、CodeForces 评分为 1189（7B 模型）。",
  "deepseek-ai/DeepSeek-R1.description": "DeepSeek-R1 通过强化学习和冷启动数据提升推理能力，刷新开源多任务模型基准，超越 OpenAI-o1-mini。",
  "deepseek-ai/DeepSeek-V2.5.description": "DeepSeek-V2.5 升级了 DeepSeek-V2-Chat 和 DeepSeek-Coder-V2-Instruct，融合通用与编程能力。提升了写作和指令遵循能力，实现更好的偏好对齐，在 AlpacaEval 2.0、ArenaHard、AlignBench 和 MT-Bench 上取得显著进步。",
  "deepseek-ai/DeepSeek-V3.1-Terminus.description": "DeepSeek-V3.1-Terminus 是 V3.1 的更新版本，定位为混合智能体大模型。修复用户反馈问题，提升稳定性、语言一致性，减少中英混杂和异常字符。集成思考与非思考模式，支持通过聊天模板灵活切换。Code Agent 和 Search Agent 性能也得到提升，工具使用更可靠，多步任务执行更高效。",
  "deepseek-ai/DeepSeek-V3.1.description": "DeepSeek V3.1 采用混合推理架构，支持思考与非思考模式。",
  "deepseek-ai/DeepSeek-V3.2-Exp.description": "DeepSeek-V3.2-Exp 是 V3.2 的实验版本，连接下一代架构。在 V3.1-Terminus 基础上引入 DeepSeek 稀疏注意力（DSA），提升长上下文训练与推理效率，优化工具使用、长文档理解和多步推理。适合探索大上下文预算下的高效推理。",
  "deepseek-ai/DeepSeek-V3.description": "DeepSeek-V3 是一个拥有 671B 参数的 MoE 模型，采用 MLA 和 DeepSeekMoE 架构，具备无损负载均衡，实现高效训练与推理。在 14.8T 高质量数据上预训练，并结合 SFT 与 RL，性能超越其他开源模型，接近领先闭源模型。",
  "deepseek-ai/deepseek-llm-67b-chat.description": "DeepSeek LLM Chat（67B）是一款创新模型，具备深度语言理解与交互能力。",
  "deepseek-ai/deepseek-r1.description": "一款高效的最先进大模型，在推理、数学和编程方面表现强劲。",
  "deepseek-ai/deepseek-v3.1-terminus.description": "DeepSeek V3.1 是下一代推理模型，具备更强的复杂推理与链式思维能力，适用于深度分析任务。",
  "deepseek-ai/deepseek-v3.1.description": "DeepSeek V3.1 是下一代推理模型，具备更强的复杂推理与链式思维能力，适用于深度分析任务。",
  "deepseek-ai/deepseek-vl2.description": "DeepSeek-VL2 是基于 DeepSeekMoE-27B 的 MoE 视觉语言模型，采用稀疏激活，仅使用 4.5B 激活参数即可实现强大性能。擅长视觉问答、OCR、文档/表格/图表理解和视觉定位。",
  "deepseek-chat.description": "DeepSeek V3.2 在推理能力与输出长度之间实现平衡，适用于日常问答与智能体任务。在公开基准测试中达到 GPT-5 水平，并率先将思考能力融入工具使用，在开源智能体评估中表现领先。",
  "deepseek-coder-33B-instruct.description": "DeepSeek Coder 33B 是一款代码语言模型，训练于 2T 数据（87% 代码，13% 中英文文本）。支持 16K 上下文窗口与中间填充任务，提供项目级代码补全与片段填充。",
  "deepseek-coder-v2.description": "DeepSeek Coder V2 是一款开源 MoE 编程模型，在编程任务中表现强劲，可媲美 GPT-4 Turbo。",
  "deepseek-coder-v2:236b.description": "DeepSeek Coder V2 是一款开源 MoE 编程模型，在编程任务中表现强劲，可媲美 GPT-4 Turbo。",
  "deepseek-ocr.description": "DeepSeek-OCR 是 DeepSeek AI 推出的视觉语言模型，专注于 OCR 和“上下文光学压缩”。该模型探索从图像中压缩上下文信息，能够高效处理文档并将其转换为结构化文本格式（如 Markdown）。它在图像文字识别方面表现精准，适用于文档数字化、文本提取和结构化处理。",
  "deepseek-r1-0528.description": "2025 年 5 月 28 日发布的 685B 全量模型。DeepSeek-R1 在后训练阶段使用大规模强化学习，显著提升推理能力，仅需极少标注数据即可在数学、编程和自然语言推理方面表现出色。",
  "deepseek-r1-250528.description": "DeepSeek R1 250528 是 DeepSeek-R1 的完整推理模型，专为高难度数学与逻辑任务设计。",
  "deepseek-r1-70b-fast-online.description": "DeepSeek R1 70B 快速版，支持实时网页搜索，在保持性能的同时提供更快响应。",
  "deepseek-r1-70b-online.description": "DeepSeek R1 70B 标准版，支持实时网页搜索，适用于最新聊天与文本任务。",
  "deepseek-r1-distill-llama-70b.description": "DeepSeek R1 Distill Llama 70B 将 R1 推理能力与 Llama 生态系统结合。",
  "deepseek-r1-distill-llama-8b.description": "DeepSeek-R1-Distill-Llama-8B 由 Llama-3.1-8B 蒸馏而来，使用 DeepSeek R1 输出进行训练。",
  "deepseek-r1-distill-llama.description": "deepseek-r1-distill-llama 是在 Llama 上基于 DeepSeek-R1 蒸馏而成。",
  "deepseek-r1-distill-qianfan-70b.description": "DeepSeek R1 Distill Qianfan 70B 是基于 Qianfan-70B 的 R1 蒸馏模型，具备强大价值。",
  "deepseek-r1-distill-qianfan-8b.description": "DeepSeek R1 Distill Qianfan 8B 是基于 Qianfan-8B 的 R1 蒸馏模型，适用于中小型应用。",
  "deepseek-r1-distill-qianfan-llama-70b.description": "DeepSeek R1 Distill Qianfan Llama 70B 是基于 Llama-70B 的 R1 蒸馏模型。",
  "deepseek-r1-distill-qwen-1.5b.description": "DeepSeek R1 Distill Qwen 1.5B 是一款超轻量蒸馏模型，适用于极低资源环境。",
  "deepseek-r1-distill-qwen-14b.description": "DeepSeek R1 Distill Qwen 14B 是一款中型蒸馏模型，适用于多场景部署。",
  "deepseek-r1-distill-qwen-32b.description": "DeepSeek R1 Distill Qwen 32B 是基于 Qwen-32B 的 R1 蒸馏模型，在性能与成本之间取得平衡。",
  "deepseek-r1-distill-qwen-7b.description": "DeepSeek R1 Distill Qwen 7B 是一款轻量蒸馏模型，适用于边缘计算与企业私有部署环境。",
  "deepseek-r1-distill-qwen.description": "deepseek-r1-distill-qwen 是在 Qwen 上基于 DeepSeek-R1 蒸馏而成。",
  "deepseek-r1-fast-online.description": "DeepSeek R1 快速全量版本，支持实时网页搜索，结合 671B 规模能力与更快响应。",
  "deepseek-r1-online.description": "DeepSeek R1 全量版本，具备 671B 参数与实时网页搜索，提供更强理解与生成能力。",
  "deepseek-r1.description": "DeepSeek-R1 在强化学习前使用冷启动数据，在数学、编程和推理任务中表现可与 OpenAI-o1 相媲美。",
  "deepseek-reasoner.description": "DeepSeek V3.2 Thinking 是一款深度推理模型，在输出前生成思维链以提升准确率，在多个竞赛中取得优异成绩，其推理能力可媲美 Gemini-3.0-Pro。",
  "deepseek-v2.description": "DeepSeek V2 是一款高效的 MoE 模型，适用于成本敏感型处理任务。",
  "deepseek-v2:236b.description": "DeepSeek V2 236B 是 DeepSeek 推出的代码专用模型，具备强大代码生成能力。",
  "deepseek-v3-0324.description": "DeepSeek-V3-0324 是一款拥有 671B 参数的 MoE 模型，在编程与技术能力、上下文理解和长文本处理方面表现突出。",
  "deepseek-v3.1-terminus.description": "DeepSeek-V3.1-Terminus 是 DeepSeek 推出的终端优化大模型，专为终端设备定制。",
  "deepseek-v3.1-think-250821.description": "DeepSeek V3.1 Think 250821 是对应 Terminus 版本的深度思考模型，专为高性能推理任务打造。",
  "deepseek-v3.1.description": "DeepSeek-V3.1 是 DeepSeek 推出的新一代混合推理模型，支持思考与非思考模式，推理效率高于 DeepSeek-R1-0528。后训练优化显著提升智能体工具使用与任务执行能力，支持 128k 上下文窗口与最多 64k 输出。",
  "deepseek-v3.1:671b.description": "DeepSeek V3.1 是下一代推理模型，具备更强的复杂推理与链式思维能力，适用于需要深度分析的任务。",
  "deepseek-v3.2-exp.description": "deepseek-v3.2-exp 引入稀疏注意力机制，在处理长文本时提升训练与推理效率，价格低于 deepseek-v3.1。",
  "deepseek-v3.2-think.description": "DeepSeek V3.2 Think 是一款完整的深度思考模型，具备更强的长链推理能力。",
  "deepseek-v3.2.description": "DeepSeek-V3.2 是深度求索推出的首个将思考融入工具使用的混合推理模型，采用高效架构节省算力，结合大规模强化学习提升能力与大规模合成任务数据增强泛化能力，三者融合使其性能媲美 GPT-5-High，输出长度大幅降低，显著减少计算开销与用户等待时间。",
  "deepseek-v3.description": "DeepSeek-V3 是一款强大的 MoE 模型，总参数量为 671B，每个 token 激活参数为 37B。",
  "deepseek-vl2-small.description": "DeepSeek VL2 Small 是一款轻量级多模态模型，适用于资源受限和高并发场景。",
  "deepseek-vl2.description": "DeepSeek VL2 是一款多模态模型，专注于图文理解和细粒度视觉问答。",
  "deepseek/deepseek-chat-v3-0324.description": "DeepSeek V3 是一款拥有 685B 参数的 MoE 模型，是 DeepSeek 旗舰聊天系列的最新版本。\n\n该模型基于 [DeepSeek V3](/deepseek/deepseek-chat-v3) 构建，在多项任务中表现出色。",
  "deepseek/deepseek-chat-v3-0324:free.description": "DeepSeek V3 是一款拥有 685B 参数的 MoE 模型，是 DeepSeek 旗舰聊天系列的最新版本。\n\n该模型基于 [DeepSeek V3](/deepseek/deepseek-chat-v3) 构建，在多项任务中表现出色。",
  "deepseek/deepseek-chat-v3.1.description": "DeepSeek-V3.1 是 DeepSeek 推出的长上下文混合推理模型，支持思考/非思考模式切换及工具集成。",
  "deepseek/deepseek-chat.description": "DeepSeek-V3 是 DeepSeek 面向复杂任务和工具集成的高性能混合推理模型。",
  "deepseek/deepseek-r1-0528.description": "DeepSeek R1 0528 是一款更新版本，专注于开放可用性和更深层次的推理能力。",
  "deepseek/deepseek-r1-0528:free.description": "DeepSeek-R1 在仅需极少标注数据的情况下显著提升推理能力，并在最终答案前输出思维链以提高准确性。",
  "deepseek/deepseek-r1-distill-llama-70b.description": "DeepSeek R1 Distill Llama 70B 是基于 Llama 3.3 70B 蒸馏而成的大语言模型，使用 DeepSeek R1 输出进行微调，在性能上可媲美大型前沿模型。",
  "deepseek/deepseek-r1-distill-llama-8b.description": "DeepSeek R1 Distill Llama 8B 是基于 Llama-3.1-8B-Instruct 蒸馏而成的大语言模型，使用 DeepSeek R1 输出进行训练。",
  "deepseek/deepseek-r1-distill-qwen-14b.description": "DeepSeek R1 Distill Qwen 14B 是基于 Qwen 2.5 14B 蒸馏而成的大语言模型，使用 DeepSeek R1 输出进行训练。在多个基准测试中超越 OpenAI o1-mini，在密集模型中达到 SOTA 水平。基准亮点：\nAIME 2024 pass@1: 69.7\nMATH-500 pass@1: 93.9\nCodeForces Rating: 1481\n基于 DeepSeek R1 输出的微调实现了与更大前沿模型的竞争性能。",
  "deepseek/deepseek-r1-distill-qwen-32b.description": "DeepSeek R1 Distill Qwen 32B 是基于 Qwen 2.5 32B 蒸馏而成的大语言模型，使用 DeepSeek R1 输出进行训练。在多个基准测试中超越 OpenAI o1-mini，在密集模型中达到 SOTA 水平。基准亮点：\nAIME 2024 pass@1: 72.6\nMATH-500 pass@1: 94.3\nCodeForces Rating: 1691\n基于 DeepSeek R1 输出的微调实现了与更大前沿模型的竞争性能。",
  "deepseek/deepseek-r1.description": "DeepSeek R1 已更新为 DeepSeek-R1-0528。通过更强的计算资源和后训练算法优化，显著提升了推理深度与能力。在数学、编程和通用逻辑基准测试中表现优异，接近 o3 和 Gemini 2.5 Pro 等领先模型。",
  "deepseek/deepseek-r1/community.description": "DeepSeek R1 是 DeepSeek 团队最新开源模型，在数学、编程和推理任务中表现出色，性能可与 OpenAI o1 相媲美。",
  "deepseek/deepseek-r1:free.description": "DeepSeek-R1 在仅需极少标注数据的情况下显著提升推理能力，并在最终答案前输出思维链以提高准确性。",
  "deepseek/deepseek-reasoner.description": "DeepSeek-V3 Thinking（reasoner）是 DeepSeek 的实验性推理模型，适用于高复杂度推理任务。",
  "deepseek/deepseek-v3.1-base.description": "DeepSeek V3.1 Base 是 DeepSeek V3 模型的改进版本。",
  "deepseek/deepseek-v3.description": "一款快速的通用大语言模型，具备增强的推理能力。",
  "deepseek/deepseek-v3/community.description": "DeepSeek-V3 在推理速度方面相较前代实现重大突破，在开源模型中排名第一，并可媲美最先进的闭源模型。DeepSeek-V3 采用了在 DeepSeek-V2 中验证的多头潜在注意力（MLA）和 DeepSeekMoE 架构，并引入了无损辅助策略以实现负载均衡，以及多 token 预测训练目标以增强性能。",
  "deepseek_r1.description": "DeepSeek-R1 是一款基于强化学习的推理模型，解决了重复性和可读性问题。在强化学习前，使用冷启动数据进一步提升推理能力。在数学、编程和推理任务中表现与 OpenAI-o1 相当，训练过程精心设计以提升整体效果。",
  "deepseek_r1_distill_llama_70b.description": "DeepSeek-R1-Distill-Llama-70B 是基于 Llama-3.3-70B-Instruct 蒸馏而成。作为 DeepSeek-R1 系列的一部分，使用 DeepSeek-R1 生成的样本进行微调，在数学、编程和推理方面表现出色。",
  "deepseek_r1_distill_qwen_14b.description": "DeepSeek-R1-Distill-Qwen-14B 是基于 Qwen2.5-14B 蒸馏而成，并使用 DeepSeek-R1 生成的 80 万高质量样本进行微调，具备强大的推理能力。",
  "deepseek_r1_distill_qwen_32b.description": "DeepSeek-R1-Distill-Qwen-32B 是基于 Qwen2.5-32B 蒸馏而成，并使用 DeepSeek-R1 生成的 80 万高质量样本进行微调，在数学、编程和推理方面表现卓越。",
  "devstral-2:123b.description": "Devstral 2 123B 擅长使用工具探索代码库、编辑多个文件，并支持软件工程代理。",
  "doubao-1.5-lite-32k.description": "Doubao-1.5-lite 是一款全新轻量级模型，响应速度极快，兼具卓越质量与低延迟。",
  "doubao-1.5-pro-256k.description": "Doubao-1.5-pro-256k 是 Doubao-1.5-Pro 的全面升级版，整体性能提升 10%。支持 256k 上下文窗口和最多 12k 输出 token，性能更强、窗口更大，适用于更广泛的场景。",
  "doubao-1.5-pro-32k.description": "Doubao-1.5-pro 是新一代旗舰模型，全面升级，在知识、编程和推理方面表现出色。",
  "doubao-1.5-thinking-pro-m.description": "Doubao-1.5 是一款全新的深度推理模型（m 版本原生支持多模态深度推理），在数学、编程、科学推理以及创意写作等通用任务中表现卓越。其在 AIME 2024、Codeforces 和 GPQA 等基准测试中达到或接近顶级水平。支持 128k 上下文窗口和 16k 输出。",
  "doubao-1.5-thinking-pro.description": "Doubao-1.5 是一款全新的深度推理模型，在数学、编程、科学推理以及创意写作等通用任务中表现卓越。其在 AIME 2024、Codeforces 和 GPQA 等基准测试中达到或接近顶级水平。支持 128k 上下文窗口和 16k 输出。",
  "doubao-1.5-thinking-vision-pro.description": "全新视觉深度推理模型，具备更强的多模态理解与推理能力，在 59 个公开基准中有 37 项达到 SOTA 水平。",
  "doubao-1.5-ui-tars.description": "Doubao-1.5-UI-TARS 是一款原生面向图形界面的代理模型，具备类人感知、推理与操作能力，可与界面无缝交互。",
  "doubao-1.5-vision-lite.description": "Doubao-1.5-vision-lite 是升级版多模态模型，支持任意分辨率和极端长宽比图像，提升视觉推理、文档识别、细节理解与指令遵循能力。支持 128k 上下文窗口和最多 16k 输出 token。",
  "doubao-1.5-vision-pro-32k.description": "Doubao-1.5-vision-pro 是升级版多模态模型，支持任意分辨率和极端长宽比图像，提升视觉推理、文档识别、细节理解与指令遵循能力。",
  "doubao-1.5-vision-pro.description": "Doubao-1.5-vision-pro 是升级版多模态模型，支持任意分辨率和极端长宽比图像，提升视觉推理、文档识别、细节理解与指令遵循能力。",
  "doubao-lite-128k.description": "超快响应，性价比更高，适用于多种场景，支持推理与微调，具备 128k 上下文窗口。",
  "doubao-lite-32k.description": "超快响应，性价比更高，适用于多种场景，支持推理与微调，具备 32k 上下文窗口。",
  "doubao-lite-4k.description": "超快响应，性价比更高，适用于多种场景，支持推理与微调，具备 4k 上下文窗口。",
  "doubao-pro-256k.description": "性能最强的旗舰模型，适用于复杂任务，在参考问答、摘要、创作、文本分类和角色扮演等方面表现优异。支持推理与微调，具备 256k 上下文窗口。",
  "doubao-pro-32k.description": "性能最强的旗舰模型，适用于复杂任务，在参考问答、摘要、创作、文本分类和角色扮演等方面表现优异。支持推理与微调，具备 32k 上下文窗口。",
  "doubao-seed-1.6-flash.description": "Doubao-Seed-1.6-flash 是一款超快多模态深度推理模型，TPOT 低至 10ms，支持文本与图像输入，在文本理解上超越前代 lite 模型，在视觉方面媲美主流 pro 模型。支持 256k 上下文窗口和最多 16k 输出 token。",
  "doubao-seed-1.6-lite.description": "Doubao-Seed-1.6-lite 是一款全新多模态深度推理模型，支持可调推理强度（最小、低、中、高），性价比更高，是通用任务的优选，支持最长 256k 上下文窗口。",
  "doubao-seed-1.6-thinking.description": "Doubao-Seed-1.6-thinking 在推理能力上显著增强，相较 Doubao-1.5-thinking-pro 在编程、数学和逻辑推理方面进一步提升，并新增视觉理解能力。支持 256k 上下文窗口和最多 16k 输出 token。",
  "doubao-seed-1.6-vision.description": "Doubao-Seed-1.6-vision 是一款视觉深度推理模型，具备更强的多模态理解与推理能力，适用于教育、图像审核、安检和 AI 搜索问答等场景。支持 256k 上下文窗口和最多 64k 输出 token。",
  "doubao-seed-1.6.description": "Doubao-Seed-1.6 是一款全新多模态深度推理模型，支持自动、思考与非思考模式。在非思考模式下，其性能显著优于 Doubao-1.5-pro/250115。支持 256k 上下文窗口和最多 16k 输出 token。",
  "doubao-seed-1.8.description": "Doubao-Seed-1.8 拥有更强的多模态理解能力与 Agent 能力，支持文本/图像/视频输入与上下文缓存，在复杂任务中表现更加出色。",
  "doubao-seed-code.description": "Doubao-Seed-Code 针对代理式编程深度优化，支持多模态输入（文本/图像/视频）和 256k 上下文窗口，兼容 Anthropic API，适用于编程、视觉理解与代理工作流。",
  "doubao-seededit-3-0-i2i-250628.description": "字节跳动 Seed 推出的 Doubao 图像模型，支持文本与图像输入，具备高度可控的高质量图像生成能力。支持文本引导的图像编辑，输出尺寸长边在 512 至 1536 之间。",
  "doubao-seedream-3-0-t2i-250415.description": "Seedream 3.0 是字节跳动 Seed 推出的图像生成模型，支持文本与图像输入，具备高度可控的高质量图像生成能力。可根据文本提示生成图像。",
  "doubao-seedream-4-0-250828.description": "Seedream 4.0 是字节跳动 Seed 推出的图像生成模型，支持文本与图像输入，具备高度可控的高质量图像生成能力。可根据文本提示生成图像。",
  "doubao-vision-lite-32k.description": "Doubao-vision 是 Doubao 推出的多模态模型，具备强大的图像理解与推理能力，并能精准执行指令。在图文提取与基于图像的推理任务中表现优异，支持更复杂、更广泛的视觉问答场景。",
  "doubao-vision-pro-32k.description": "Doubao-vision 是 Doubao 推出的多模态模型，具备强大的图像理解与推理能力，并能精准执行指令。在图文提取与基于图像的推理任务中表现优异，支持更复杂、更广泛的视觉问答场景。",
  "emohaa.description": "Emohaa 是一款心理健康模型，具备专业咨询能力，帮助用户理解情绪问题。",
  "ernie-4.5-0.3b.description": "ERNIE 4.5 0.3B 是一款开源轻量级模型，适用于本地和定制化部署。",
  "ernie-4.5-21b-a3b.description": "ERNIE 4.5 21B A3B 是一款开源大参数模型，具备更强的理解与生成能力。",
  "ernie-4.5-300b-a47b.description": "ERNIE 4.5 300B A47B 是百度 ERNIE 的超大规模 MoE 模型，推理能力卓越。",
  "ernie-4.5-8k-preview.description": "ERNIE 4.5 8K Preview 是一款用于评估 ERNIE 4.5 的 8K 上下文预览模型。",
  "ernie-4.5-turbo-128k-preview.description": "ERNIE 4.5 Turbo 128K 预览版，具备发布级能力，适用于集成与灰度测试。",
  "ernie-4.5-turbo-128k.description": "ERNIE 4.5 Turbo 128K 是一款高性能通用模型，支持搜索增强与工具调用，适用于问答、编程与代理场景。",
  "ernie-4.5-turbo-32k.description": "ERNIE 4.5 Turbo 32K 是一款中等长度上下文版本，适用于问答、知识库检索与多轮对话。",
  "ernie-4.5-turbo-latest.description": "最新 ERNIE 4.5 Turbo，整体性能优化，适合作为主力生产模型。",
  "ernie-4.5-turbo-vl-32k-preview.description": "ERNIE 4.5 Turbo VL 32K Preview 是一款 32K 多模态预览模型，用于评估长上下文视觉能力。",
  "ernie-4.5-turbo-vl-32k.description": "ERNIE 4.5 Turbo VL 32K 是一款中长上下文多模态模型，适用于长文档与图像联合理解。",
  "ernie-4.5-turbo-vl-latest.description": "ERNIE 4.5 Turbo VL 最新版，图文理解与推理能力进一步提升。",
  "ernie-4.5-turbo-vl-preview.description": "ERNIE 4.5 Turbo VL Preview 是一款多模态预览模型，适用于图文理解与生成，支持视觉问答与内容理解。",
  "ernie-4.5-turbo-vl.description": "ERNIE 4.5 Turbo VL 是一款成熟的多模态模型，适用于生产级图文理解与识别。",
  "ernie-4.5-vl-28b-a3b.description": "ERNIE 4.5 VL 28B A3B 是一款开源多模态模型，支持图文理解与推理。",
  "ernie-5.0-thinking-latest.description": "文心 5.0 Thinking 是一款原生全模态旗舰模型，统一建模文本、图像、音频与视频，在复杂问答、创作与智能体场景中实现全面能力升级。",
  "ernie-5.0-thinking-preview.description": "文心 5.0 Thinking Preview 是一款原生全模态旗舰模型，统一建模文本、图像、音频与视频，在复杂问答、创作与智能体场景中实现全面能力升级。",
  "ernie-char-8k.description": "ERNIE Character 8K 是一款角色对话模型，适用于 IP 角色构建与长期陪伴聊天。",
  "ernie-char-fiction-8k-preview.description": "ERNIE Character Fiction 8K 预览版是一款用于角色与情节创作的模型预览，适用于功能评估与测试。",
  "ernie-char-fiction-8k.description": "ERNIE Character Fiction 8K 是一款面向小说与情节创作的角色模型，适合长篇故事生成。",
  "ernie-irag-edit.description": "ERNIE iRAG Edit 是一款图像编辑模型，支持擦除、重绘与变体生成。",
  "ernie-lite-8k.description": "ERNIE Lite 8K 是一款轻量级通用模型，适用于对成本敏感的日常问答与内容生成任务。",
  "ernie-lite-pro-128k.description": "ERNIE Lite Pro 128K 是一款高性能轻量模型，适用于对延迟与成本敏感的场景。",
  "ernie-novel-8k.description": "ERNIE Novel 8K 专为长篇小说与 IP 剧情创作打造，支持多角色叙事。",
  "ernie-speed-128k.description": "ERNIE Speed 128K 是一款免 I/O 费用模型，适用于长文本理解与大规模试验。",
  "ernie-speed-8k.description": "ERNIE Speed 8K 是一款免费且快速的模型，适合日常聊天与轻量文本任务。",
  "ernie-speed-pro-128k.description": "ERNIE Speed Pro 128K 是一款高并发、高价值模型，适用于大规模在线服务与企业应用。",
  "ernie-tiny-8k.description": "ERNIE Tiny 8K 是一款超轻量模型，适用于简单问答、分类与低成本推理。",
  "ernie-x1-turbo-32k.description": "ERNIE X1 Turbo 32K 是一款快速思考模型，具备 32K 上下文能力，适合复杂推理与多轮对话。",
  "ernie-x1.1-preview.description": "ERNIE X1.1 Preview 是一款用于评估与测试的思考模型预览版。",
  "fal-ai/bytedance/seedream/v4.description": "Seedream 4.0 由字节跳动 Seed 团队构建，支持文本与图像输入，可根据提示生成高质量、可控性强的图像。",
  "fal-ai/flux-kontext/dev.description": "FLUX.1 模型专注于图像编辑，支持文本与图像输入。",
  "fal-ai/flux-pro/kontext.description": "FLUX.1 Kontext [pro] 接受文本与参考图像输入，支持局部精准编辑与复杂全局场景变换。",
  "fal-ai/flux/krea.description": "Flux Krea [dev] 是一款图像生成模型，偏好更真实自然的美学风格。",
  "fal-ai/flux/schnell.description": "FLUX.1 [schnell] 是一款拥有 120 亿参数的图像生成模型，专为快速高质量输出而设计。",
  "fal-ai/hunyuan-image/v3.description": "一款强大的原生多模态图像生成模型。",
  "fal-ai/imagen4/preview.description": "来自 Google 的高质量图像生成模型。",
  "fal-ai/nano-banana.description": "Nano Banana 是 Google 最新、最快、最高效的原生多模态模型，支持通过对话生成与编辑图像。",
  "fal-ai/qwen-image-edit.description": "来自 Qwen 团队的专业图像编辑模型，支持语义与外观编辑、中英文文本精修、风格迁移、旋转等功能。",
  "fal-ai/qwen-image.description": "来自 Qwen 团队的强大图像生成模型，具备出色的中文文本渲染能力与多样化视觉风格。",
  "flux-1-schnell.description": "来自 Black Forest Labs 的 120 亿参数文本转图像模型，采用潜在对抗扩散蒸馏技术，可在 1-4 步内生成高质量图像。性能媲美闭源模型，采用 Apache-2.0 许可，适用于个人、研究与商业用途。",
  "flux-dev.description": "FLUX.1 [dev] 是一款开源权重蒸馏模型，仅限非商业用途。保持接近专业图像质量与指令遵循能力，同时运行更高效，资源利用优于同等规模标准模型。",
  "flux-kontext-max.description": "最先进的上下文图像生成与编辑模型，结合文本与图像输入，实现精准一致的结果。",
  "flux-kontext-pro.description": "最先进的上下文图像生成与编辑模型，结合文本与图像输入，实现精准一致的结果。",
  "flux-merged.description": "FLUX.1-merged 融合了“DEV”版本的深度特征与“Schnell”版本的高速优势，拓展性能边界，拓宽应用场景。",
  "flux-pro-1.1-ultra.description": "超高分辨率图像生成，支持 4MP 输出，10 秒内生成清晰图像。",
  "flux-pro-1.1.description": "升级版专业图像生成模型，图像质量卓越，提示词遵循精准。",
  "flux-pro.description": "顶级商业图像生成模型，图像质量无与伦比，输出多样丰富。",
  "flux-schnell.description": "FLUX.1 [schnell] 是最先进的开源少步图像生成模型，超越同类竞品，甚至优于 Midjourney v6.0 与 DALL·E 3（高清版）等强大非蒸馏模型。精调保留预训练多样性，显著提升视觉质量、指令遵循、尺寸/比例变化、字体处理与输出多样性。",
  "flux.1-schnell.description": "FLUX.1-schnell 是一款高性能图像生成模型，支持快速多风格输出。",
  "gemini-1.0-pro-001.description": "Gemini 1.0 Pro 001（调优版）为复杂任务提供稳定、可调性能。",
  "gemini-1.0-pro-002.description": "Gemini 1.0 Pro 002（调优版）为复杂任务提供强大的多模态支持。",
  "gemini-1.0-pro-latest.description": "Gemini 1.0 Pro 是 Google 的高性能 AI 模型，适用于大规模任务处理。",
  "gemini-1.5-flash-001.description": "Gemini 1.5 Flash 001 是一款高效多模态模型，适用于广泛应用场景。",
  "gemini-1.5-flash-002.description": "Gemini 1.5 Flash 002 是一款高效多模态模型，适用于大规模部署。",
  "gemini-1.5-flash-8b-exp-0924.description": "Gemini 1.5 Flash 8B 0924 是最新实验模型，在文本与多模态用例中取得显著提升。",
  "gemini-1.5-flash-8b-latest.description": "Gemini 1.5 Flash 8B 是一款高效多模态模型，适用于大规模部署。",
  "gemini-1.5-flash-8b.description": "Gemini 1.5 Flash 8B 是一款高效多模态模型，适用于广泛应用场景。",
  "gemini-1.5-flash-exp-0827.description": "Gemini 1.5 Flash 0827 优化多模态处理，适用于复杂任务。",
  "gemini-1.5-flash-latest.description": "Gemini 1.5 Flash 是 Google 最新的多模态 AI 模型，处理速度快，支持文本、图像与视频输入，适用于高效任务扩展。",
  "gemini-flash-latest.description": "Latest release of Gemini Flash",
  "gemini-flash-lite-latest.description": "Latest release of Gemini Flash-Lite",
  "gemini-pro-latest.description": "Latest release of Gemini Pro",
  "meta/Llama-3.2-90B-Vision-Instruct.description": "适用于视觉理解代理应用的高级图像推理模型。",
  "meta/Llama-3.3-70B-Instruct.description": "Llama 3.3 是最先进的多语言开源 Llama 模型，在极低成本下实现接近 405B 的性能。该模型基于 Transformer 架构，并通过 SFT 和 RLHF 提升实用性与安全性。其指令微调版本专为多语言对话优化，在行业基准测试中超越众多开源与闭源聊天模型。知识截止时间：2023 年 12 月。",
  "meta/Meta-Llama-3-70B-Instruct.description": "一款功能强大的 700 亿参数模型，擅长推理、编程和广泛的语言任务。",
  "meta/Meta-Llama-3-8B-Instruct.description": "一款多功能的 80 亿参数模型，专为对话和文本生成优化。",
  "meta/Meta-Llama-3.1-405B-Instruct.description": "Llama 3.1 指令微调文本模型，专为多语言对话优化，在开源与闭源聊天模型中在常见行业基准测试中表现出色。",
  "meta/Meta-Llama-3.1-70B-Instruct.description": "Llama 3.1 指令微调文本模型，专为多语言对话优化，在开源与闭源聊天模型中在常见行业基准测试中表现出色。",
  "meta/Meta-Llama-3.1-8B-Instruct.description": "Llama 3.1 指令微调文本模型，专为多语言对话优化，在开源与闭源聊天模型中在常见行业基准测试中表现出色。",
  "meta/llama-3-70b.description": "由 Meta 微调的 700 亿参数开源模型，专注于指令跟随，由 Groq 在 LPU 硬件上提供服务，实现快速高效的推理。",
  "meta/llama-3-8b.description": "由 Meta 微调的 80 亿参数开源模型，专注于指令跟随，由 Groq 在 LPU 硬件上提供服务，实现快速高效的推理。",
  "meta/llama-3.1-405b-instruct.description": "一款先进的大语言模型，支持合成数据生成、知识蒸馏和用于聊天机器人、编程及领域任务的推理。",
  "meta/llama-3.1-70b-instruct.description": "专为复杂对话设计，具备出色的上下文理解、推理和文本生成能力。",
  "meta/llama-3.1-70b.description": "更新版 Meta Llama 3 70B Instruct，支持 128K 上下文、多语言能力，并提升推理表现。",
  "meta/llama-3.1-8b-instruct.description": "一款前沿模型，具备强大的语言理解、推理和文本生成能力。",
  "meta/llama-3.1-8b.description": "Llama 3.1 8B 支持 128K 上下文窗口，适用于实时对话和数据分析，相较于更大模型具有显著成本优势。由 Groq 在 LPU 硬件上提供服务，实现快速高效的推理。",
  "meta/llama-3.2-11b-vision-instruct.description": "一款前沿视觉语言模型，擅长从图像中进行高质量推理。",
  "meta/llama-3.2-11b.description": "一款指令微调的图像推理模型（文本+图像输入，文本输出），专为视觉识别、图像推理、图像描述和通用图像问答优化。",
  "meta/llama-3.2-1b-instruct.description": "一款前沿的小型语言模型，具备强大的理解、推理和文本生成能力。",
  "meta/llama-3.2-1b.description": "纯文本模型，适用于设备端的多语言本地检索、摘要和改写等场景。",
  "meta/llama-3.2-3b-instruct.description": "一款前沿的小型语言模型，具备强大的理解、推理和文本生成能力。",
  "meta/llama-3.2-3b.description": "纯文本模型，针对设备端的多语言本地检索、摘要和改写等场景进行微调。",
  "meta/llama-3.2-90b-vision-instruct.description": "一款前沿视觉语言模型，擅长从图像中进行高质量推理。",
  "meta/llama-3.2-90b.description": "一款指令微调的图像推理模型（文本+图像输入，文本输出），专为视觉识别、图像推理、图像描述和通用图像问答优化。",
  "meta/llama-3.3-70b-instruct.description": "一款先进的大语言模型，擅长推理、数学、常识和函数调用。",
  "meta/llama-3.3-70b.description": "性能与效率的完美平衡。专为内容创作、企业应用和研究中的高性能对话式 AI 而构建，具备强大的语言理解能力，适用于摘要、分类、情感分析和代码生成。",
  "meta/llama-4-maverick.description": "Llama 4 系列是原生多模态 AI 模型集，支持文本与多模态体验，采用 MoE 架构，实现领先的文本与图像理解。Llama 4 Maverick 是一款拥有 128 个专家的 170 亿参数模型，由 DeepInfra 提供服务。",
  "meta/llama-4-scout.description": "Llama 4 系列是原生多模态 AI 模型集，支持文本与多模态体验，采用 MoE 架构，实现领先的文本与图像理解。Llama 4 Scout 是一款拥有 16 个专家的 170 亿参数模型，由 DeepInfra 提供服务。",
  "microsoft/Phi-3-medium-128k-instruct.description": "与 Phi-3-medium 相同的模型，但具有更大的上下文窗口，适用于 RAG 或少样本提示。",
  "microsoft/Phi-3-medium-4k-instruct.description": "一款 140 亿参数模型，质量高于 Phi-3-mini，专注于高质量、推理密集型数据。",
  "microsoft/Phi-3-mini-128k-instruct.description": "与 Phi-3-mini 相同的模型，但具有更大的上下文窗口，适用于 RAG 或少样本提示。",
  "microsoft/Phi-3-mini-4k-instruct.description": "Phi-3 系列中最小的成员，优化以实现高质量和低延迟。",
  "microsoft/Phi-3-small-128k-instruct.description": "与 Phi-3-small 相同的模型，但具有更大的上下文窗口，适用于 RAG 或少样本提示。",
  "microsoft/Phi-3-small-8k-instruct.description": "一款 70 亿参数模型，质量高于 Phi-3-mini，专注于高质量、推理密集型数据。",
  "microsoft/Phi-3.5-mini-instruct.description": "Phi-3-mini 模型的更新版本。",
  "microsoft/Phi-3.5-vision-instruct.description": "Phi-3-vision 模型的更新版本。",
  "microsoft/WizardLM-2-8x22B.description": "WizardLM 2 是微软 AI 推出的语言模型，擅长复杂对话、多语言任务、推理和助手应用。",
  "microsoft/wizardlm-2-8x22b.description": "WizardLM-2 8x22B 是微软 AI 最先进的 Wizard 模型，具备极具竞争力的性能。",
  "minicpm-v.description": "MiniCPM-V 是 OpenBMB 的下一代多模态模型，具备出色的 OCR 和多模态理解能力，适用于广泛场景。",
  "minimax/minimax-m2.description": "MiniMax-M2 是一款高性价比模型，擅长编程和智能体任务，适用于多种工程场景。",
  "minimaxai/minimax-m2.description": "MiniMax-M2 是一款紧凑、快速、成本效益高的 MoE 模型（总参数 230B，激活参数 10B），在保持强大通用智能的同时，专为顶级编程和智能体性能打造。擅长多文件编辑、代码运行修复循环、测试验证和复杂工具链。",
  "ministral-3b-latest.description": "Ministral 3B 是 Mistral 推出的顶级边缘模型。",
  "ministral-8b-latest.description": "Ministral 8B 是 Mistral 推出的高性价比边缘模型。",
  "mistral-ai/Mistral-Large-2411.description": "Mistral 的旗舰模型，适用于需要大规模推理或专业化的复杂任务（如合成文本生成、代码生成、RAG 或智能体）。",
  "mistral-ai/Mistral-Nemo.description": "Mistral Nemo 是一款前沿大语言模型，在其参数规模下具备最先进的推理、世界知识和编程能力。",
  "mistral-ai/mistral-small-2503.description": "Mistral Small 适用于任何需要高效率和低延迟的语言任务。",
  "mistral-large-instruct.description": "Mistral-Large-Instruct-2407 是一款先进的密集型大语言模型，拥有 1230 亿参数，具备最先进的推理、知识和编程能力。",
  "mistral-large-latest.description": "Mistral Large 是旗舰模型，擅长多语言任务、复杂推理和代码生成，适用于高端应用。",
  "mistral-large.description": "Mixtral Large 是 Mistral 的旗舰模型，结合代码生成、数学和推理能力，支持 128K 上下文窗口。",
  "mistral-medium-latest.description": "Mistral Medium 3 以 8 倍更低的成本实现最先进性能，并简化企业部署。",
  "mistral-nemo-instruct.description": "Mistral-Nemo-Instruct-2407 是 Mistral-Nemo-Base-2407 的指令微调版本。",
  "mistral-nemo.description": "Mistral Nemo 是 Mistral AI 与 NVIDIA 联合开发的高效 120 亿参数模型。",
  "mistral-small-latest.description": "Mistral Small 是一款高性价比、快速且可靠的模型，适用于翻译、摘要和情感分析。",
  "mistral-small.description": "Mistral Small 适用于任何需要高效率和低延迟的语言任务。",
  "mistral.description": "Mistral 是 Mistral AI 推出的 70 亿参数模型，适用于多种语言任务。",
  "mistral/codestral-embed.description": "一款代码嵌入模型，用于嵌入代码库和仓库，支持编程助手。",
  "mistral/codestral.description": "Mistral Codestral 25.01 是一款最先进的编程模型，优化以实现低延迟和高频使用。支持 80 多种语言，擅长 FIM、代码修复和测试生成。",
  "mistral/devstral-small.description": "Devstral 是一款面向软件工程任务的智能体大语言模型，是软件工程智能体的强力选择。",
  "mistral/magistral-medium.description": "通过深度理解支持复杂思维，具备可追踪、可验证的透明推理能力。即使在任务中途，也能在多语言环境中保持高保真推理。",
  "mistral/magistral-small.description": "通过深度理解支持复杂思维，具备可追踪、可验证的透明推理能力。即使在任务中途，也能在多语言环境中保持高保真推理。",
  "mistral/ministral-3b.description": "一款紧凑高效的模型，适用于设备端任务，如助手和本地分析，提供低延迟性能。",
  "mistral/ministral-8b.description": "一款更强大的模型，推理速度更快、内存效率更高，适用于复杂工作流和高要求的边缘应用。",
  "mistral/mistral-embed.description": "一款通用文本嵌入模型，适用于语义搜索、相似度计算、聚类和 RAG 工作流。",
  "mistral/mistral-large.description": "Mistral Large 适用于需要强大推理或专业化的复杂任务，如合成文本生成、代码生成、RAG 或智能体。",
  "mistral/mistral-small.description": "Mistral Small 适用于分类、客户支持或文本生成等简单、可批处理任务，具备出色性能和实惠价格。",
  "mistral/mixtral-8x22b-instruct.description": "8x22B 指令模型。8x22B 是由 Mistral 提供服务的开源 MoE 模型。",
  "mistral/pixtral-12b.description": "一款具备图像理解与文本处理能力的 120 亿参数模型。",
  "mistral/pixtral-large.description": "Pixtral Large 是我们多模态系列的第二款模型，具备前沿级图像理解能力。可处理文档、图表和自然图像，同时保留 Mistral Large 2 的领先文本理解能力。",
  "mistralai/Mistral-7B-Instruct-v0.1.description": "Mistral（7B）Instruct 以其在多种语言任务中的强大表现而闻名。",
  "mistralai/Mistral-7B-Instruct-v0.2.description": "Mistral（7B）Instruct v0.2 提升了指令处理能力和结果准确性。",
  "mistralai/Mistral-7B-Instruct-v0.3.description": "Mistral（7B）Instruct v0.3 提供高效计算和强大的语言理解，适用于多种场景。",
  "mistralai/Mistral-7B-v0.1.description": "Mistral 7B 虽小巧但性能强劲，适合批处理和分类、文本生成等简单任务，具备扎实的推理能力。",
  "mistralai/Mixtral-8x22B-Instruct-v0.1.description": "Mixtral-8x22B Instruct（141B）是一款适用于重负载任务的超大语言模型。",
  "mistralai/Mixtral-8x7B-Instruct-v0.1.description": "Mixtral-8x7B Instruct（46.7B）为大规模数据处理提供高容量支持。",
  "mistralai/Mixtral-8x7B-v0.1.description": "Mixtral 8x7B 是一款稀疏 MoE 模型，提升推理速度，适用于多语言和代码生成任务。",
  "mistralai/mistral-nemo.description": "Mistral Nemo 是一款 73 亿参数模型，支持多语言，具备强大的编程能力。",
  "o3-deep-research.description": "o3-deep-research 是我们最先进的深度研究模型，适用于复杂的多步骤任务。它可以通过 MCP 连接器访问您的数据并进行网页搜索。",
  "o3-mini.description": "o3-mini 是我们最新的小型推理模型，在保持与 o1-mini 相同成本和延迟的前提下，提供更高的智能表现。",
  "o3-pro-2025-06-10.description": "o3 Pro 是 OpenAI 推出的新一代推理模型，支持文本+图像输入和文本输出，适用于需要广泛知识的复杂任务。",
  "o3-pro.description": "o3-pro 使用更多计算资源以实现更深入的思考，持续提供更优质的答案；仅通过 Responses API 提供。",
  "o3.description": "o3 是一款功能强大的通用模型，在数学、科学、编程和视觉推理方面树立了新标杆。它擅长技术写作和指令执行，能够分析文本、代码和图像，解决多步骤问题。",
  "o4-mini-2025-04-16.description": "o4-mini 是 OpenAI 的推理模型，支持文本+图像输入和文本输出，适用于需要广泛知识的复杂任务，具备 200K 上下文窗口。",
  "o4-mini-deep-research.description": "o4-mini-deep-research 是一款更快速、更经济的深度研究模型，适用于复杂的多步骤研究任务。它可以进行网页搜索，并通过 MCP 连接器访问您的数据。",
  "o4-mini.description": "o4-mini 是最新的小型 o 系列模型，专为快速、高效的推理任务优化，在编程和视觉任务中表现出色。",
  "open-codestral-mamba.description": "Codestral Mamba 是一款专注于代码生成的 Mamba 2 语言模型，支持高级编程与推理任务。",
  "open-mistral-7b.description": "Mistral 7B 是一款紧凑但高性能的模型，适合批量处理和分类、文本生成等简单任务，具备良好的推理能力。",
  "open-mistral-nemo.description": "Mistral Nemo 是与 Nvidia 联合开发的 12B 模型，在推理和编程方面表现强劲，易于集成。",
  "open-mixtral-8x22b.description": "Mixtral 8x22B 是一款大型 MoE 模型，适用于复杂任务，具备强大的推理能力和更高的吞吐量。",
  "open-mixtral-8x7b.description": "Mixtral 8x7B 是一款稀疏 MoE 模型，提升了推理速度，适用于多语言和代码生成任务。",
  "openai/gpt-3.5-turbo-instruct.description": "具备 GPT-3 时代模型的类似能力，兼容传统补全接口而非聊天接口。",
  "openai/gpt-3.5-turbo.description": "OpenAI 最具性价比的 GPT-3.5 模型，优化用于聊天，同时在传统补全任务中也表现出色。",
  "openai/gpt-4-turbo.description": "OpenAI 的 gpt-4-turbo 拥有广泛的通识知识和专业领域能力，能够理解复杂的自然语言指令，并准确解决难题。知识截止时间为 2023 年 4 月，支持 128K 上下文窗口。",
  "openai/gpt-4.1-mini.description": "GPT-4.1 Mini 提供更低延迟和更高性价比，适用于中等上下文任务。",
  "openai/gpt-4.1-nano.description": "GPT-4.1 Nano 是一款超低成本、低延迟的模型，适用于高频短对话或分类任务。",
  "openai/gpt-4.1.description": "GPT-4.1 系列提供更大的上下文窗口和更强的工程与推理能力。",
  "openai/gpt-4o-mini.description": "GPT-4o-mini 是一款快速的小型 GPT-4o 变体，适用于低延迟的多模态应用场景。",
  "openai/gpt-4o.description": "GPT-4o 系列是 OpenAI 的 Omni 模型，支持文本+图像输入和文本输出。",
  "openai/gpt-5-chat.description": "GPT-5 Chat 是 GPT-5 的对话优化版本，具备更低延迟和更强交互性。",
  "openai/gpt-5-codex.description": "GPT-5-Codex 是 GPT-5 的代码优化版本，适用于大规模代码工作流。",
  "openai/gpt-5-mini.description": "GPT-5 Mini 是一款小型 GPT-5 变体，适用于低延迟、低成本场景。",
  "openai/gpt-5-nano.description": "GPT-5 Nano 是超小型变体，适用于对成本和延迟要求极高的场景。",
  "openai/gpt-5-pro.description": "GPT-5 Pro 是 OpenAI 的旗舰模型，具备更强的推理、代码生成能力和企业级功能，支持测试时路由和更严格的安全策略。",
  "openai/gpt-5.1-chat.description": "GPT-5.1 Chat 是 GPT-5.1 系列中轻量级成员，优化用于低延迟对话，同时保持强大的推理和指令执行能力。",
  "openai/gpt-5.1-codex-mini.description": "GPT-5.1-Codex-Mini 是 GPT-5.1-Codex 的小型快速版本，适用于对延迟和成本敏感的编程场景。",
  "openai/gpt-5.1-codex.description": "GPT-5.1-Codex 是 GPT-5.1 的编程优化版本，适用于大型重构、复杂调试和长时间自主编程任务。",
  "openai/gpt-5.1.description": "GPT-5.1 是 GPT-5 系列的最新旗舰，在通用推理、指令执行和对话自然性方面相较 GPT-5 有显著提升，适用于广泛任务。",
  "openai/gpt-5.description": "GPT-5 是 OpenAI 的高性能模型，适用于各种生产和研究任务。",
  "openai/gpt-oss-120b.description": "一款功能强大的通用大语言模型，具备强大且可控的推理能力。",
  "openai/gpt-oss-20b.description": "一款紧凑的开源权重语言模型，优化用于低延迟和资源受限环境，包括本地和边缘部署。",
  "openai/o1-mini.description": "o1-mini 是一款快速、经济高效的推理模型，专为编程、数学和科学任务设计。支持 128K 上下文，知识截止时间为 2023 年 10 月。",
  "openai/o1-preview.description": "o1 是 OpenAI 推出的新型推理模型，适用于需要广泛知识的复杂任务。支持 128K 上下文，知识截止时间为 2023 年 10 月。",
  "openai/o1.description": "OpenAI o1 是一款旗舰推理模型，专为需要深度思考的复杂问题设计，在多步骤任务中展现出强大的推理能力和更高的准确性。",
  "openai/o3-mini-high.description": "o3-mini（高推理）在保持与 o1-mini 相同成本和延迟的前提下，提供更高的智能表现。",
  "openai/o3-mini.description": "o3-mini 是 OpenAI 最新的小型推理模型，在保持与 o1-mini 相同成本和延迟的前提下，提供更高的智能表现。",
  "openai/o3.description": "OpenAI o3 是最强大的推理模型，在编程、数学、科学和视觉感知方面树立了新标准。它擅长处理复杂、多维度的问题，尤其在图像、图表和示意图分析方面表现出色。",
  "openai/o4-mini-high.description": "o4-mini 高推理版本，优化用于快速、高效的推理任务，具备强大的编程和视觉能力。",
  "openai/o4-mini.description": "OpenAI o4-mini 是一款小型高效的推理模型，适用于低延迟场景。",
  "qwen-vl-ocr.description": "Qwen OCR 是一款用于文档、表格、考试图片和手写文字的文本提取模型，支持中文、英文、法语、日语、韩语、德语、俄语、意大利语、越南语和阿拉伯语。",
  "qwen-vl-plus-latest.description": "增强版大规模 Qwen 视觉语言模型，在细节和文本识别方面有显著提升，支持超过百万像素分辨率和任意宽高比。",
  "qwen-vl-plus.description": "增强版大规模 Qwen 视觉语言模型，在细节和文本识别方面有显著提升，支持超过百万像素分辨率和任意宽高比。",
  "qwen-vl-v1.description": "基于 Qwen-7B 预训练模型，加入视觉模块，支持 448 分辨率图像输入。",
  "qwen/qwen-2-7b-instruct.description": "Qwen2 是全新的 Qwen 大语言模型系列。Qwen2 7B 是一款基于 Transformer 架构的模型，擅长语言理解、多语言处理、编程、数学和推理。",
  "qwen/qwen-2-7b-instruct:free.description": "Qwen2 是一个全新的大语言模型系列，具备更强的理解与生成能力。",
  "qwen/qwen-2-vl-72b-instruct.description": "Qwen2-VL 是 Qwen-VL 的最新版本，在 MathVista、DocVQA、RealWorldQA 和 MTVQA 等视觉基准测试中达到业界领先水平。支持 20 分钟以上视频的高质量问答、对话和内容创作，具备复杂推理与决策能力，可与移动设备和机器人集成，根据视觉上下文和文本指令执行操作。除中英文外，还支持图像中的多种语言文本识别，包括大多数欧洲语言、日语、韩语、阿拉伯语和越南语。",
  "qwen/qwen-2.5-72b-instruct.description": "Qwen2.5-72B-Instruct 是阿里云最新发布的大语言模型之一。该 72B 模型在编程和数学方面有显著提升，支持超过 29 种语言（包括中英文），在指令理解、结构化数据处理和结构化输出（尤其是 JSON）方面表现优异。",
  "qwen/qwen2.5-32b-instruct.description": "Qwen2.5-32B-Instruct 是阿里云最新发布的大语言模型之一。该 32B 模型在编程和数学方面有显著提升，支持超过 29 种语言（包括中英文），在指令理解、结构化数据处理和结构化输出（尤其是 JSON）方面表现优异。",
  "qwen/qwen2.5-7b-instruct.description": "一款中英文双语大语言模型，覆盖语言、编程、数学和推理任务。",
  "qwen/qwen2.5-coder-32b-instruct.description": "一款面向主流编程语言的高级代码生成、推理与修复模型。",
  "qwen/qwen2.5-coder-7b-instruct.description": "一款中型强力代码模型，支持 32K 上下文，擅长多语言编程。",
  "qwen/qwen3-14b.description": "Qwen3-14B 是一款适用于通用推理与对话场景的 14B 模型。",
  "qwen/qwen3-14b:free.description": "Qwen3-14B 是一款拥有 14.8B 参数的稠密因果语言模型，专为复杂推理与高效对话设计。可在数学、编程、逻辑等“思考模式”与通用对话“非思考模式”之间切换。针对指令跟随、工具使用和创意写作进行了微调，支持 100 多种语言和方言。原生支持 32K 上下文，使用 YaRN 可扩展至 131K。",
  "qwen/qwen3-235b-a22b-2507.description": "Qwen3-235B-A22B-Instruct-2507 是 Qwen3 系列的 Instruct 版本，兼顾多语言指令使用与长上下文场景。",
  "qwen/qwen3-235b-a22b-thinking-2507.description": "Qwen3-235B-A22B-Thinking-2507 是 Qwen3 的思考版本，专为复杂数学与推理任务强化。",
  "qwen/qwen3-235b-a22b.description": "Qwen3-235B-A22B 是一款拥有 235B 参数的 MoE 模型，每次前向激活 22B 参数。可在复杂推理、数学、编程的“思考模式”与高效对话的“非思考模式”之间切换。具备强大的推理能力、多语言支持（100+ 种语言/方言）、高级指令跟随与工具使用能力。原生支持 32K 上下文，使用 YaRN 可扩展至 131K。",
  "qwen/qwen3-235b-a22b:free.description": "Qwen3-235B-A22B 是一款拥有 235B 参数的 MoE 模型，每次前向激活 22B 参数。可在复杂推理、数学、编程的“思考模式”与高效对话的“非思考模式”之间切换。具备强大的推理能力、多语言支持（100+ 种语言/方言）、高级指令跟随与工具使用能力。原生支持 32K 上下文，使用 YaRN 可扩展至 131K。",
  "qwen/qwen3-30b-a3b.description": "Qwen3 是最新一代 Qwen 大语言模型，采用稠密与 MoE 架构，擅长推理、多语言支持和高级智能体任务。其独特的“思考模式”与“非思考模式”切换能力，确保在多场景下实现高质量表现。\n\nQwen3 显著超越 QwQ 和 Qwen2.5 等前代模型，在数学、编程、常识推理、创意写作和交互对话方面表现卓越。Qwen3-30B-A3B 版本拥有 30.5B 参数（3.3B 激活），48 层，128 个专家（每任务激活 8 个），支持使用 YaRN 扩展至 131K 上下文，树立开源模型新标杆。",
  "qwen/qwen3-30b-a3b:free.description": "Qwen3 是最新一代 Qwen 大语言模型，采用稠密与 MoE 架构，擅长推理、多语言支持和高级智能体任务。其独特的“思考模式”与“非思考模式”切换能力，确保在多场景下实现高质量表现。\n\nQwen3 显著超越 QwQ 和 Qwen2.5 等前代模型，在数学、编程、常识推理、创意写作和交互对话方面表现卓越。Qwen3-30B-A3B 版本拥有 30.5B 参数（3.3B 激活），48 层，128 个专家（每任务激活 8 个），支持使用 YaRN 扩展至 131K 上下文，树立开源模型新标杆。",
  "qwen/qwen3-32b.description": "Qwen3-32B 是一款稠密的 32.8B 参数因果语言模型，专为复杂推理与高效对话优化。可在数学、编程、逻辑的“思考模式”与通用对话的“非思考模式”之间切换。擅长指令跟随、工具使用和创意写作，支持 100 多种语言和方言。原生支持 32K 上下文，使用 YaRN 可扩展至 131K。",
  "qwen/qwen3-32b:free.description": "Qwen3-32B 是一款稠密的 32.8B 参数因果语言模型，专为复杂推理与高效对话优化。可在数学、编程、逻辑的“思考模式”与通用对话的“非思考模式”之间切换。擅长指令跟随、工具使用和创意写作，支持 100 多种语言和方言。原生支持 32K 上下文，使用 YaRN 可扩展至 131K。",
  "qwen/qwen3-8b:free.description": "Qwen3-8B 是一款稠密的 8.2B 参数因果语言模型，专为推理密集型任务与高效对话设计。可在数学、编程、逻辑的“思考模式”与通用对话的“非思考模式”之间切换。针对指令跟随、智能体集成和创意写作进行了微调，支持 100 多种语言和方言。原生支持 32K 上下文，使用 YaRN 可扩展至 131K。",
  "qwen/qwen3-coder-plus.description": "Qwen3-Coder-Plus 是 Qwen 系列的代码智能体模型，优化了复杂工具使用和长时间会话能力。",
  "qwen/qwen3-coder.description": "Qwen3-Coder 是 Qwen3 的代码生成系列，擅长长文档代码理解与生成。",
  "qwen/qwen3-max-preview.description": "Qwen3 Max（预览版）是面向高级推理与工具集成的 Max 版本。",
  "qwen/qwen3-max.description": "Qwen3 Max 是 Qwen3 系列的高端推理模型，专注于多语言推理与工具集成。",
  "qwen3-next-80b-a3b-instruct.description": "下一代 Qwen3 非推理开源模型。相比上一版本（Qwen3-235B-A22B-Instruct-2507），在中文理解、逻辑推理和文本生成方面均有显著提升。",
  "qwen3-next-80b-a3b-thinking.description": "Qwen3 Next 80B A3B Thinking 是面向复杂任务的旗舰推理模型版本。",
  "qwen3-omni-flash.description": "Qwen-Omni 支持文本、图像、音频和视频的多模态输入，输出为文本或语音。具备多种自然语音风格，支持多语言及方言语音，适用于写作、视觉识别和语音助手等场景。",
  "qwen3-vl-235b-a22b-instruct.description": "Qwen3 VL 235B A22B Instruct 是面向高要求理解与创作任务的旗舰多模态模型。",
  "qwen3-vl-235b-a22b-thinking.description": "Qwen3 VL 235B A22B Thinking 是面向复杂多模态推理与规划的旗舰推理版本。",
  "qwen3-vl-30b-a3b-instruct.description": "Qwen3 VL 30B A3B Instruct 是一款在准确性与推理性能之间取得平衡的大型多模态模型。",
  "qwen3-vl-30b-a3b-thinking.description": "Qwen3 VL 30B A3B Thinking 是面向复杂多模态任务的深度推理版本。",
  "qwen3-vl-32b-instruct.description": "Qwen3 VL 32B Instruct 是一款多模态指令微调模型，适用于高质量图文问答与创作。",
  "qwen3-vl-32b-thinking.description": "Qwen3 VL 32B Thinking 是一款深度推理多模态模型，擅长复杂推理与长链分析。",
  "qwen3-vl-8b-instruct.description": "Qwen3 VL 8B Instruct 是一款轻量级多模态模型，适用于日常视觉问答与应用集成。",
  "qwen3-vl-8b-thinking.description": "Qwen3 VL 8B Thinking 是一款多模态思维链模型，适用于细致的视觉推理任务。",
  "qwen3-vl-flash.description": "Qwen3 VL Flash：轻量级、高速推理版本，适用于对延迟敏感或高并发请求。",
  "qwen3-vl-plus.description": "Qwen VL 是一款具备视觉理解能力的文本生成模型，支持 OCR、摘要与推理，可从商品图片中提取属性或解决图像问题。",
  "qwen3.description": "Qwen3 是阿里巴巴推出的下一代大语言模型，在多种应用场景中表现出色。",
  "qwq-32b-preview.description": "QwQ 是 Qwen 推出的实验性研究模型，专注于推理能力的提升。",
  "qwq-32b.description": "QwQ 是 Qwen 系列中的推理模型。相比标准指令微调模型，具备更强的思维与推理能力，显著提升下游复杂任务表现。QwQ-32B 是一款中型推理模型，性能可媲美 DeepSeek-R1 和 o1-mini 等顶级模型。",
  "qwq-plus.description": "QwQ 推理模型基于 Qwen2.5 训练，并通过强化学习大幅提升推理能力。在数学/代码（AIME 24/25、LiveCodeBench）及通用评测（IFEval、LiveBench）中达到 DeepSeek-R1 的水平。",
  "qwq.description": "QwQ 是 Qwen 系列中的推理模型。相比标准指令微调模型，具备更强的思维与推理能力，显著提升下游复杂任务表现。QwQ-32B 是一款中型推理模型，性能可媲美 DeepSeek-R1 和 o1-mini 等顶级模型。",
  "qwq_32b.description": "Qwen 系列中的中型推理模型。相比标准指令微调模型，QwQ 的思维与推理能力显著提升下游复杂任务表现。",
  "r1-1776.description": "R1-1776 是 DeepSeek R1 的后训练版本，旨在提供无审查、无偏见的真实信息。",
  "solar-mini-ja.description": "Solar Mini (Ja) 是 Solar Mini 的日语增强版本，同时保持在英语和韩语中的高效强性能。",
  "solar-mini.description": "Solar Mini 是一款紧凑型大语言模型，性能超越 GPT-3.5，具备强大的多语言能力，支持英语和韩语，提供高效的小体积解决方案。",
  "solar-pro.description": "Solar Pro 是 Upstage 推出的高智能大语言模型，专注于单 GPU 上的指令跟随任务，IFEval 得分超过 80。目前支持英语，完整版本计划于 2024 年 11 月发布，届时将扩展语言支持并提升上下文长度。",
  "sonar-deep-research.description": "Deep Research 提供专家级的深度研究，并将其整合为易于理解和可操作的报告。",
  "sonar-pro.description": "一款高级搜索产品，支持复杂查询与后续问题的搜索溯源。",
  "sonar-reasoning-pro.description": "一款高级搜索产品，支持复杂查询与后续问题的搜索溯源。",
  "sonar-reasoning.description": "一款高级搜索产品，支持复杂查询与后续问题的搜索溯源。",
  "sonar.description": "一款轻量级搜索溯源产品，速度更快、成本更低，适用于对资源敏感的场景。",
  "spark-x.description": "X1.5 更新内容：（1）新增由 `thinking` 字段控制的动态思维模式；（2）支持 64K 输入与 64K 输出的超长上下文；（3）支持 FunctionCall 功能。",
  "stable-diffusion-3-medium.description": "Stability AI 最新的文本生成图像模型。该版本显著提升图像质量、文本理解与风格多样性，能更准确地解析复杂自然语言提示并生成更精确多样的图像。",
  "stable-diffusion-3.5-large-turbo.description": "stable-diffusion-3.5-large-turbo 通过对 stable-diffusion-3.5-large 应用对抗扩散蒸馏（ADD）技术，实现更快的生成速度。",
  "stable-diffusion-3.5-large.description": "stable-diffusion-3.5-large 是一款拥有 8 亿参数的 MMDiT 文本生成图像模型，具备卓越的图像质量与提示对齐能力，支持百万像素图像，并可高效运行于消费级硬件。",
  "stable-diffusion-v1.5.description": "stable-diffusion-v1.5 基于 v1.2 检查点初始化，并在 512x512 分辨率下对 \"laion-aesthetics v2 5+\" 数据集进行 595k 步微调，通过减少 10% 文本条件依赖提升无分类器引导采样效果。",
  "stable-diffusion-xl-base-1.0.description": "Stability AI 开源的文本生成图像模型，具备行业领先的创意图像生成能力。具备强指令理解能力，支持反向提示定义，实现精确生成。",
  "stable-diffusion-xl.description": "stable-diffusion-xl 相较 v1.5 有重大改进，达到开源文本生成图像模型的顶级水平。改进包括 3 倍大的 UNet 主干网络、图像质量优化模块及更高效的训练技术。",
  "step-1-128k.description": "在性能与成本之间取得平衡，适用于通用场景。",
  "step-1-256k.description": "支持超长上下文，适合长文档分析。",
  "step-1-32k.description": "支持中等长度对话，适用于多种场景。",
  "step-1-8k.description": "小型模型，适合轻量级任务。",
  "step-1-flash.description": "高速模型，适用于实时聊天场景。",
  "step-1.5v-mini.description": "具备强大视频理解能力。",
  "step-1o-turbo-vision.description": "图像理解能力强，在数学与编程方面优于 1o。体积更小，输出更快。",
  "step-1o-vision-32k.description": "图像理解能力强，视觉表现优于 Step-1V 系列。",
  "step-1v-32k.description": "支持视觉输入，实现更丰富的多模态交互。",
  "step-1v-8k.description": "小型视觉模型，适用于基础图文任务。",
  "step-1x-edit.description": "专注于图像编辑的模型，可根据用户提供的图像与文本进行修改与增强。支持多种输入格式，包括文本描述与示例图像，生成符合用户意图的编辑结果。",
  "step-1x-medium.description": "具备强大图像生成能力，支持中文提示输入，能更好理解中文语义并转化为视觉特征，实现高分辨率、高质量图像生成，并支持一定程度的风格迁移。",
  "step-2-16k-exp.description": "Step-2 实验版本，包含最新功能与持续更新。不建议用于生产环境。",
  "step-2-16k.description": "支持大上下文交互，适用于复杂对话。",
  "step-2-mini.description": "基于下一代自研 MFA 注意力架构构建，在大幅降低成本的同时实现 Step-1 级别效果，具备更高吞吐与更低延迟，适用于通用任务，编程能力强。",
  "step-2x-large.description": "新一代 StepFun 图像模型，专注于图像生成，可根据文本提示生成高质量图像，具备更真实的纹理与更强的中英文文本渲染能力。",
  "step-3.description": "该模型具备强大的视觉感知与复杂推理能力，能准确处理跨领域知识理解、数学与视觉交叉分析及多种日常视觉分析任务。",
  "step-r1-v-mini.description": "具备强图像理解能力的推理模型，可处理图像与文本，并在深度推理后生成文本。擅长视觉推理，在数学、编程与文本推理方面表现出色，支持 100K 上下文窗口。",
  "stepfun-ai/step3.description": "Step3 是 StepFun 推出的前沿多模态推理模型，基于 MoE 架构，总参数 321B，激活参数 38B。端到端设计降低解码成本，同时实现顶级视觉语言推理能力。采用 MFA 与 AFD 架构，在旗舰与低端加速器上均保持高效。预训练使用超过 20T 文本与 4T 图文数据，覆盖多种语言，在数学、编程与多模态评测中表现领先。",
  "us.anthropic.claude-sonnet-4-5-20250929-v1:0.description": "Claude Sonnet 4.5 是 Anthropic 迄今为止最智能的模型。",
  "v0-1.0-md.description": "v0-1.0-md 是通过 v0 API 提供的旧版模型。",
  "v0-1.5-lg.description": "v0-1.5-lg 适用于高级思维或推理任务。",
  "v0-1.5-md.description": "v0-1.5-md 适用于日常任务和用户界面生成。",
  "vercel/v0-1.0-md.description": "访问 v0 背后的模型，结合框架特定的推理能力和最新知识，用于生成、修复和优化现代 Web 应用。",
  "vercel/v0-1.5-md.description": "访问 v0 背后的模型，结合框架特定的推理能力和最新知识，用于生成、修复和优化现代 Web 应用。",
  "volcengine/doubao-seed-code.description": "豆包-Seed-Code 是字节跳动火山引擎推出的面向智能体编程优化的大模型，在编程和智能体基准测试中表现出色，支持 256K 上下文。",
  "wan2.2-t2i-flash.description": "万象 2.2 极速版是最新模型，在创意性、稳定性和真实感方面全面升级，生成速度快，性价比高。",
  "wan2.2-t2i-plus.description": "万象 2.2 专业版是最新模型，在创意性、稳定性和真实感方面全面升级，图像细节更丰富。",
  "wanx-v1.description": "基础文本转图像模型。对应通义万象 1.0 通用版。",
  "wanx2.0-t2i-turbo.description": "擅长纹理人像，速度适中，成本较低。对应通义万象 2.0 极速版。",
  "wanx2.1-t2i-plus.description": "全面升级版本，图像细节更丰富，生成速度略慢。对应通义万象 2.1 专业版。",
  "wanx2.1-t2i-turbo.description": "全面升级版本，生成速度快，整体质量强，性价比高。对应通义万象 2.1 极速版。",
  "whisper-1.description": "通用语音识别模型，支持多语言 ASR、语音翻译和语言识别。",
  "wizardlm2.description": "WizardLM 2 是微软 AI 推出的语言模型，擅长复杂对话、多语言任务、推理和助手应用。",
  "wizardlm2:8x22b.description": "WizardLM 2 是微软 AI 推出的语言模型，擅长复杂对话、多语言任务、推理和助手应用。",
  "x-ai/grok-4-fast-non-reasoning.description": "Grok 4 Fast（非推理版）是 xAI 推出的高吞吐、低成本多模态模型（支持 2M 上下文窗口），适用于对延迟和成本敏感但不需要模型内推理的场景。可通过 API 的 reasoning 参数启用推理功能。提示词和生成内容可能被 xAI 或 OpenRouter 用于改进未来模型。",
  "x-ai/grok-4-fast.description": "Grok 4 Fast 是 xAI 推出的高吞吐、低成本模型（支持 2M 上下文窗口），适用于高并发和长上下文场景。",
  "x-ai/grok-4.1-fast-non-reasoning.description": "Grok 4 Fast（非推理版）是 xAI 推出的高吞吐、低成本多模态模型（支持 2M 上下文窗口），适用于对延迟和成本敏感但不需要模型内推理的场景。可通过 API 的 reasoning 参数启用推理功能。提示词和生成内容可能被 xAI 或 OpenRouter 用于改进未来模型。",
  "x-ai/grok-4.1-fast.description": "Grok 4 Fast 是 xAI 推出的高吞吐、低成本模型（支持 2M 上下文窗口），适用于高并发和长上下文场景。",
  "x-ai/grok-4.description": "Grok 4 是 xAI 的旗舰推理模型，具备强大的推理和多模态能力。",
  "x-ai/grok-code-fast-1.description": "Grok Code Fast 1 是 xAI 推出的快速代码模型，输出可读性强，适合工程使用。",
  "xai/grok-2-vision.description": "Grok 2 Vision 擅长视觉任务，在视觉数学推理（MathVista）和文档问答（DocVQA）方面表现卓越，支持文档、图表、截图和照片等多种图像类型。",
  "xai/grok-2.description": "Grok 2 是一款前沿模型，具备先进的推理能力，强大的对话、编程和推理表现，在 LMSYS 排名中优于 Claude 3.5 Sonnet 和 GPT-4 Turbo。",
  "xai/grok-3-fast.description": "xAI 的旗舰模型，擅长企业场景如数据提取、编程和摘要，具备金融、医疗、法律和科学等领域的深度知识。快速版本运行在更快的基础设施上，响应速度更快但每个 token 成本更高。",
  "xai/grok-3-mini-fast.description": "xAI 的轻量模型，在回答前进行思考，适用于简单或基于逻辑的任务，无需深度领域知识。提供原始推理轨迹。快速版本运行在更快的基础设施上，响应速度更快但每个 token 成本更高。",
  "xai/grok-3-mini.description": "xAI 的轻量模型，在回答前进行思考，适用于简单或基于逻辑的任务，无需深度领域知识。提供原始推理轨迹。",
  "xai/grok-3.description": "xAI 的旗舰模型，擅长企业场景如数据提取、编程和摘要，具备金融、医疗、法律和科学等领域的深度知识。",
  "xai/grok-4.description": "xAI 最新旗舰模型，在自然语言、数学和推理方面表现卓越，是理想的全能型模型。",
  "yi-large-fc.description": "基于 yi-large 构建，增强了工具调用能力，适用于智能体和工作流场景。",
  "yi-large-preview.description": "早期版本，推荐使用更新的 yi-large。",
  "yi-large-rag.description": "基于 yi-large 的高级服务，结合检索与生成，支持实时网页搜索，提供精准答案。",
  "yi-large-turbo.description": "在质量、速度和成本之间实现出色平衡，具备卓越性价比和性能。",
  "yi-large.description": "一款全新 1000 亿参数模型，擅长问答和文本生成。",
  "yi-lightning-lite.description": "轻量版本，推荐使用 yi-lightning。",
  "yi-lightning.description": "最新高性能模型，推理速度更快，输出质量更高。",
  "yi-medium-200k.description": "支持 200K 长上下文的模型，适用于深度长文本理解与生成。",
  "yi-medium.description": "调优后的中型模型，能力与性价比平衡，优化用于指令跟随任务。",
  "yi-spark.description": "紧凑快速的模型，强化了数学和编程能力。",
  "yi-vision-v2.description": "适用于复杂任务的视觉模型，具备强大的多图理解与分析能力。",
  "yi-vision.description": "适用于复杂任务的视觉模型，具备强大的图像理解与分析能力。",
  "z-ai/glm-4.5-air.description": "GLM 4.5 Air 是 GLM 4.5 的轻量版本，适用于对成本敏感的场景，同时保留强大的推理能力。",
  "z-ai/glm-4.5.description": "GLM 4.5 是 Z.AI 的旗舰模型，采用混合推理，优化用于工程和长上下文任务。",
  "z-ai/glm-4.6.description": "GLM 4.6 是 Z.AI 的旗舰模型，具备更长上下文和更强编程能力。",
  "zai-glm-4.6.description": "在编程和推理任务中表现出色，支持流式输出和工具调用，适用于智能体编程和复杂推理。",
  "zai-org/GLM-4.5-Air.description": "GLM-4.5-Air 是一款面向智能体应用的基础模型，采用专家混合架构，优化用于工具使用、网页浏览、软件工程和前端编程，并可与 Claude Code 和 Roo Code 等代码智能体集成。采用混合推理，兼顾复杂推理与日常任务。",
  "zai-org/GLM-4.5.description": "GLM-4.5 是一款面向智能体应用的基础模型，采用专家混合架构，深度优化用于工具使用、网页浏览、软件工程和前端编程，并可与 Claude Code 和 Roo Code 等代码智能体集成。采用混合推理，兼顾复杂推理与日常任务。",
  "zai-org/GLM-4.5V.description": "GLM-4.5V 是智谱 AI 最新的多模态语言模型，基于 GLM-4.5-Air 旗舰文本模型（总参数 106B，激活参数 12B），采用 MoE 架构，在成本更低的同时保持强大性能。继承 GLM-4.1V-Thinking 路线，加入 3D-RoPE 提升三维空间推理能力。通过预训练、SFT 和 RL 优化，支持图像、视频和长文档，在 41 个公开多模态基准中排名领先。提供“思考模式”切换，平衡速度与深度。",
  "zai-org/GLM-4.6.description": "相比 GLM-4.5，GLM-4.6 将上下文长度从 128K 扩展至 200K，适用于更复杂的智能体任务。在代码基准测试中得分更高，在 Claude Code、Cline、Roo Code 和 Kilo Code 等应用中表现更强，包括更好的前端页面生成。推理能力增强，支持推理过程中的工具使用，整体能力更强。更好地集成于智能体框架，提升工具/搜索智能体能力，具备更符合人类偏好的写作风格和角色扮演自然度。",
  "zai/glm-4.5-air.description": "GLM-4.5 和 GLM-4.5-Air 是我们面向智能体应用的最新旗舰模型，均采用 MoE 架构。GLM-4.5 总参数 355B，每次前向激活 32B；GLM-4.5-Air 更轻量，总参数 106B，激活参数 12B。",
  "zai/glm-4.5.description": "GLM-4.5 系列专为智能体设计，旗舰版 GLM-4.5 结合推理、编程和智能体能力，总参数 355B（激活 32B），提供双模式混合推理系统。",
  "zai/glm-4.5v.description": "GLM-4.5V 基于 GLM-4.5-Air 构建，继承 GLM-4.1V-Thinking 的成熟技术，采用强大的 106B 参数 MoE 架构扩展能力。",
  "zenmux/auto.description": "ZenMux 自动路由根据请求自动选择性价比最高、性能最优的支持模型。"
}
