{
  "01-ai/yi-1.5-34b-chat.description": "01.AI 最新开源微调模型，拥有 340 亿参数，支持多种对话场景，基于高质量数据训练，并对齐人类偏好。",
  "01-ai/yi-1.5-9b-chat.description": "01.AI 最新开源微调模型，拥有 90 亿参数，支持多种对话场景，基于高质量数据训练，并对齐人类偏好。",
  "360/deepseek-r1.description": "360 部署的 DeepSeek-R1 在后训练阶段应用大规模强化学习，在极少标注数据下显著提升推理能力，在数学、编程和自然语言推理任务上可与 OpenAI o1 相媲美。",
  "360gpt-pro-trans.description": "专为翻译任务优化的模型，深度微调以实现领先的翻译质量。",
  "360gpt-pro.description": "360GPT Pro 是 360 的核心 AI 模型，具备高效文本处理能力，适用于多种自然语言处理场景，支持长文本理解和多轮对话。",
  "360gpt-turbo-responsibility-8k.description": "360GPT Turbo Responsibility 8K 强调语义安全与内容责任，适用于内容敏感型应用，确保用户体验的准确性与稳健性。",
  "360gpt-turbo.description": "360GPT Turbo 具备强大的计算与对话能力，语义理解与生成效率出色，适合企业与开发者使用。",
  "360gpt2-o1.description": "360gpt2-o1 通过树搜索构建思维链，结合反思机制与强化学习训练，实现自我反思与自我纠错。",
  "360gpt2-pro.description": "360GPT2 Pro 是 360 推出的高级自然语言处理模型，擅长文本生成与理解，尤其适用于创意任务，能处理复杂转换与角色扮演。",
  "360zhinao2-o1.description": "360zhinao2-o1 通过树搜索构建思维链，结合反思机制与强化学习训练，实现自我反思与自我纠错。",
  "4.0Ultra.description": "讯飞星火 Ultra 是星火系列中最强大的模型，提升了文本理解与摘要能力，并升级了网页搜索功能。它是提升职场效率与响应准确性的综合解决方案，定位为领先的智能产品。",
  "AnimeSharp.description": "AnimeSharp（又名“4x-AnimeSharp”）是由 Kim2091 基于 ESRGAN 开发的开源超分辨率模型，专注于提升和锐化动漫风格图像。该模型于 2022 年 2 月由原名“4x-TextSharpV1”更名，最初也用于文本图像，但已针对动漫内容进行了深度优化。",
  "Baichuan2-Turbo.description": "通过搜索增强技术将模型与领域知识和网页知识连接，支持 PDF/Word 上传和 URL 输入，实现及时、全面的检索与专业、准确的输出。",
  "Baichuan3-Turbo-128k.description": "拥有 128K 超长上下文窗口，专为高频企业场景优化，带来显著提升与高价值。相比 Baichuan2，内容创作提升 20%，知识问答提升 17%，角色扮演提升 40%。整体性能优于 GPT-3.5。",
  "Baichuan3-Turbo.description": "专为高频企业场景优化，带来显著提升与高价值。相比 Baichuan2，内容创作提升 20%，知识问答提升 17%，角色扮演提升 40%。整体性能优于 GPT-3.5。",
  "Baichuan4-Air.description": "国内领先模型，在中文任务如知识问答、长文本处理和创意生成方面超越海外主流模型。具备行业领先的多模态能力，在权威评测中表现优异。",
  "Baichuan4-Turbo.description": "国内领先模型，在中文任务如知识问答、长文本处理和创意生成方面超越海外主流模型。具备行业领先的多模态能力，在权威评测中表现优异。",
  "Baichuan4.description": "国内顶尖性能，在中文任务如百科知识、长文本处理和创意生成方面超越海外主流模型。具备行业领先的多模态能力，在权威评测中表现出色。",
  "ByteDance-Seed/Seed-OSS-36B-Instruct.description": "Seed-OSS 是字节跳动 Seed 团队推出的开源大模型系列，具备强大的长上下文处理、推理、智能体和通用能力。Seed-OSS-36B-Instruct 是一款 360 亿参数的指令微调模型，原生支持超长上下文，适用于处理大型文档或代码库。该模型在推理、代码生成和智能体任务（工具使用）方面表现出色，同时保留强大的通用能力。其核心特性“思维预算”可灵活控制推理长度，提升效率。",
  "DeepSeek-R1-Distill-Llama-70B.description": "DeepSeek R1 是 DeepSeek 系列中更大更智能的模型，已蒸馏至 Llama 70B 架构。基准测试和人工评估显示其在数学和事实精度任务上优于原始 Llama 70B。",
  "DeepSeek-R1-Distill-Qwen-1.5B.description": "基于 Qwen2.5-Math-1.5B 的 DeepSeek-R1 蒸馏模型。通过强化学习与冷启动数据优化推理性能，在开源模型中树立多任务新基准。",
  "DeepSeek-R1-Distill-Qwen-14B.description": "DeepSeek-R1-Distill 模型基于开源模型，使用 DeepSeek-R1 生成的样本数据进行微调。",
  "DeepSeek-R1-Distill-Qwen-32B.description": "DeepSeek-R1-Distill 模型基于开源模型，使用 DeepSeek-R1 生成的样本数据进行微调。",
  "DeepSeek-R1-Distill-Qwen-7B.description": "基于 Qwen2.5-Math-7B 的 DeepSeek-R1 蒸馏模型。通过强化学习与冷启动数据优化推理性能，在开源模型中树立多任务新基准。",
  "DeepSeek-R1.description": "DeepSeek-R1 在后训练阶段应用大规模强化学习，在极少标注数据下显著提升推理能力，在数学、编程和自然语言推理任务上可与 OpenAI o1 生产模型相媲美。",
  "DeepSeek-V3-1.description": "DeepSeek V3.1 是新一代推理模型，提升了复杂推理与思维链能力，适用于深度分析任务。",
  "DeepSeek-V3-Fast.description": "提供方：sophnet。DeepSeek V3 Fast 是 DeepSeek V3 0324 的高 TPS 版本，采用全精度（非量化），在代码与数学方面更强，响应更快。",
  "DeepSeek-V3.1-Fast.description": "DeepSeek V3.1 Fast 是 DeepSeek V3.1 的高 TPS 快速版本。混合思维模式：通过对话模板，一个模型支持思考与非思考模式。更智能的工具使用：后训练优化提升工具与智能体任务表现。",
  "DeepSeek-V3.1-Think.description": "DeepSeek-V3.1 思考模式：新型混合推理模型，支持思考与非思考模式，效率优于 DeepSeek-R1-0528。后训练优化显著提升智能体工具使用与任务表现。",
  "DeepSeek-V3.description": "DeepSeek-V3 是 DeepSeek 开发的 MoE 模型，在多个基准测试中超越 Qwen2.5-72B 和 Llama-3.1-405B 等开源模型，并与 GPT-4o 和 Claude 3.5 Sonnet 等领先闭源模型竞争。",
  "Doubao-lite-128k.description": "豆包-lite 提供超快响应和更高性价比，适用于多种场景，支持 128K 上下文推理与微调。",
  "Doubao-lite-32k.description": "豆包-lite 提供超快响应和更高性价比，适用于多种场景，支持 32K 上下文推理与微调。",
  "Doubao-lite-4k.description": "豆包-lite 提供超快响应和更高性价比，适用于多种场景，支持 4K 上下文推理与微调。",
  "Doubao-pro-128k.description": "旗舰性能最强模型，擅长复杂任务，在参考问答、摘要、创作、分类和角色扮演方面表现出色。支持 128K 上下文推理与微调。",
  "Doubao-pro-32k.description": "旗舰性能最强模型，擅长复杂任务，在参考问答、摘要、创作、分类和角色扮演方面表现出色。支持 32K 上下文推理与微调。",
  "Doubao-pro-4k.description": "旗舰性能最强模型，擅长复杂任务，在参考问答、摘要、创作、分类和角色扮演方面表现出色。支持 4K 上下文推理与微调。",
  "DreamO.description": "DreamO 是由字节跳动与北京大学联合开发的开源图像定制模型，采用统一架构支持多任务图像生成。通过高效的组合建模，可根据用户指定的身份、主题、风格、背景等条件生成高度一致的定制图像。",
  "ERNIE-3.5-128K.description": "百度旗舰级大模型，基于海量中英文语料训练，具备强大的通用对话、创作和插件使用能力；支持自动集成百度搜索插件，提供最新答案。",
  "ERNIE-3.5-8K-Preview.description": "百度旗舰级大模型，基于海量中英文语料训练，具备强大的通用对话、创作和插件使用能力；支持自动集成百度搜索插件，提供最新答案。",
  "ERNIE-3.5-8K.description": "百度旗舰级大模型，基于海量中英文语料训练，具备强大的通用对话、创作和插件使用能力；支持自动集成百度搜索插件，提供最新答案。",
  "ERNIE-4.0-8K-Latest.description": "百度旗舰级超大模型，全面升级自 ERNIE 3.5，适用于各领域复杂任务；支持百度搜索插件集成，提供实时答案。",
  "ERNIE-4.0-8K-Preview.description": "百度旗舰级超大模型，全面升级自 ERNIE 3.5，适用于各领域复杂任务；支持百度搜索插件集成，提供实时答案。",
  "ERNIE-4.0-Turbo-8K-Latest.description": "百度旗舰级超大模型，综合性能强劲，适用于复杂任务，集成百度搜索插件，提供实时答案。性能优于 ERNIE 4.0。",
  "ERNIE-4.0-Turbo-8K-Preview.description": "百度旗舰级超大模型，综合性能强劲，适用于复杂任务，集成百度搜索插件，提供实时答案。性能优于 ERNIE 4.0。",
  "ERNIE-Character-8K.description": "百度面向游戏 NPC、客服和角色扮演的垂直领域大模型，具备更清晰的人设一致性、更强的指令理解能力和更优的推理能力。",
  "ERNIE-Lite-Pro-128K.description": "百度轻量级大模型，在质量与推理性能之间取得平衡，优于 ERNIE Lite，适用于低算力加速器。",
  "ERNIE-Speed-128K.description": "百度最新高性能大模型（2024），具备强大的通用能力，适合作为微调基础模型，适应特定场景，推理能力出色。",
  "ERNIE-Speed-Pro-128K.description": "百度最新高性能大模型（2024），具备强大的通用能力，优于 ERNIE Speed，适合作为微调基础模型，推理能力出色。",
  "FLUX-1.1-pro.description": "FLUX.1.1 Pro",
  "FLUX.1-Kontext-dev.description": "FLUX.1-Kontext-dev 是 Black Forest Labs 推出的多模态图像生成与编辑模型，基于 Rectified Flow Transformer 架构，拥有 120 亿参数。专注于在给定上下文条件下生成、重建、增强或编辑图像。结合扩散模型的可控生成能力与 Transformer 的上下文建模，支持图像修复、扩图和视觉场景重建等高质量任务。",
  "FLUX.1-Kontext-pro.description": "FLUX.1 Kontext [pro]",
  "FLUX.1-dev.description": "FLUX.1-dev 是 Black Forest Labs 推出的开源多模态语言模型（MLLM），优化用于图文任务，融合图像/文本理解与生成能力。基于先进的大语言模型（如 Mistral-7B），采用精心设计的视觉编码器和多阶段指令微调，实现多模态协同与复杂任务推理。",
  "Gryphe/MythoMax-L2-13b.description": "MythoMax-L2（13B）是一款面向多领域和复杂任务的创新模型。",
  "HelloMeme.description": "HelloMeme 是一款 AI 工具，可根据用户提供的图像或动作生成表情包、GIF 或短视频。无需绘画或编程技能，仅需参考图像即可生成有趣、吸引人且风格统一的内容。",
  "HiDream-I1-Full.description": "HiDream-E1-Full 是来自 HiDream.ai 的开源多模态图像编辑模型，基于先进的 Diffusion Transformer 架构和强大的语言理解能力（内置 LLaMA 3.1-8B-Instruct）。支持自然语言驱动的图像生成、风格迁移、局部编辑和重绘，具备出色的图文理解与执行能力。",
  "HunyuanDiT-v1.2-Diffusers-Distilled.description": "hunyuandit-v1.2-distilled 是一款轻量级文本生成图像模型，通过蒸馏优化以快速生成高质量图像，特别适合低资源环境和实时生成场景。",
  "InstantCharacter.description": "InstantCharacter 是腾讯 AI 于 2025 年发布的免调优个性化角色生成模型，致力于高保真、跨场景一致的角色生成。可通过单张参考图像建模角色，并灵活迁移至不同风格、动作和背景。",
  "InternVL2-8B.description": "InternVL2-8B 是一款强大的视觉语言模型，支持多模态图文处理，能够准确识别图像内容并生成相关描述或答案。",
  "InternVL2.5-26B.description": "InternVL2.5-26B 是一款强大的视觉语言模型，支持多模态图文处理，能够准确识别图像内容并生成相关描述或答案。",
  "Kolors.description": "Kolors 是快手 Kolors 团队开发的文本生成图像模型。拥有数十亿参数，在视觉质量、中文语义理解和文本渲染方面具有显著优势。",
  "Kwai-Kolors/Kolors.description": "Kolors 是快手 Kolors 团队推出的大规模潜变量扩散文本生成图像模型。基于数十亿图文对训练，在视觉质量、复杂语义准确性以及中英文文本渲染方面表现出色，具备强大的中文内容理解与生成能力。",
  "Kwaipilot/KAT-Dev.description": "KAT-Dev（32B）是一个面向软件工程任务的开源 32B 模型。在 SWE-Bench Verified 上达到 62.4% 的解决率，在开源模型中排名第五。通过中间训练、SFT 和 RL 优化，适用于代码补全、Bug 修复和代码审查。",
  "Llama-3.2-11B-Vision-Instruct.description": "在高分辨率图像上具备强大的图像推理能力，适用于视觉理解类应用。",
  "Llama-3.2-90B-Vision-Instruct\t.description": "面向视觉理解智能体应用的高级图像推理模型。",
  "Meta-Llama-3-3-70B-Instruct.description": "Llama 3.3 70B 是一款多用途的 Transformer 模型，适用于对话和文本生成任务。",
  "Meta-Llama-3.1-405B-Instruct.description": "Llama 3.1 是一款经过指令微调的文本模型，专为多语言对话优化，在开放与闭源聊天模型中，在行业通用基准测试中表现出色。",
  "Meta-Llama-3.1-70B-Instruct.description": "Llama 3.1 是一款经过指令微调的文本模型，专为多语言对话优化，在开放与闭源聊天模型中，在行业通用基准测试中表现出色。",
  "Meta-Llama-3.1-8B-Instruct.description": "Llama 3.1 是一款经过指令微调的文本模型，专为多语言对话优化，在开放与闭源聊天模型中，在行业通用基准测试中表现出色。",
  "Meta-Llama-3.2-1B-Instruct.description": "前沿的小型语言模型，具备出色的语言理解、推理能力和文本生成能力。",
  "Meta-Llama-3.2-3B-Instruct.description": "前沿的小型语言模型，具备出色的语言理解、推理能力和文本生成能力。",
  "Meta-Llama-3.3-70B-Instruct.description": "Llama 3.3 是最先进的多语言开源 Llama 模型，在极低成本下实现接近 405B 的性能。基于 Transformer 架构，并通过 SFT 和 RLHF 提升实用性与安全性。指令微调版本专为多语言对话优化，在行业基准测试中超越众多开放与闭源聊天模型。知识截止时间：2023 年 12 月。",
  "Meta-Llama-4-Maverick-17B-128E-Instruct-FP8.description": "Llama 4 Maverick 是一款大型 MoE 模型，采用高效专家激活机制，具备强大的推理能力。",
  "MiniMax-M1.description": "一款全新自研推理模型，支持 80K 思维链和 100 万输入，性能媲美全球顶尖模型。",
  "MiniMax-M2-Stable.description": "专为高效编程与智能体工作流打造，具备更高并发能力，适用于商业场景。",
  "MiniMax-M2.1-Lightning.description": "强大的多语言编程能力，全面升级的编程体验。更快、更高效。",
  "MiniMax-M2.1.description": "MiniMax-M2.1 是 MiniMax 推出的旗舰开源大模型，专注于解决复杂的现实世界任务。其核心优势在于多语言编程能力以及作为智能体解决复杂任务的能力。",
  "MiniMax-M2.description": "专为高效编程与智能体工作流打造",
  "MiniMax-Text-01.description": "MiniMax-01 引入超越传统 Transformer 的大规模线性注意力机制，拥有 4560 亿参数，每次激活 459 亿，支持最长 400 万上下文（为 GPT-4o 的 32 倍，Claude-3.5-Sonnet 的 20 倍），性能顶尖。",
  "MiniMaxAI/MiniMax-M1-80k.description": "MiniMax-M1 是一款开源权重的大规模混合注意力推理模型，总参数 4560 亿，每个 token 激活约 459 亿。原生支持 100 万上下文，使用 Flash Attention，在生成 10 万 token 时比 DeepSeek R1 减少 75% FLOPs。采用 MoE 架构，结合 CISPO 和混合注意力 RL 训练，在长输入推理和真实软件工程任务中表现领先。",
  "MiniMaxAI/MiniMax-M2.description": "MiniMax-M2 重新定义了智能体效率。这是一款紧凑、快速、性价比高的 MoE 模型，总参数 2300 亿，激活参数仅 100 亿，专为顶级编程与智能体任务设计，同时保留强大的通用智能。仅用 100 亿激活参数即可媲美更大模型，适用于高效应用场景。",
  "Moonshot-Kimi-K2-Instruct.description": "总参数 1 万亿，激活参数 320 亿。在非思维模型中，在前沿知识、数学和编程方面表现顶尖，通用智能体任务能力更强。专为智能体工作负载优化，具备行动能力而非仅限问答。适合即兴对话、通用聊天和智能体体验，具备反射级响应能力，无需长时间思考。",
  "NousResearch/Nous-Hermes-2-Mixtral-8x7B-DPO.description": "Nous Hermes 2 - Mixtral 8x7B-DPO（总参数 46.7B）是一款高精度指令模型，适用于复杂计算任务。",
  "OmniConsistency.description": "OmniConsistency 通过引入大规模扩散 Transformer（DiTs）和配对风格化数据，提升图像到图像任务中的风格一致性与泛化能力，避免风格退化。",
  "PaddlePaddle/PaddleOCR-VL-1.5.description": "PaddleOCR-VL-1.5 是 PaddleOCR-VL 系列的升级版本，在 OmniDocBench v1.5 文档解析基准测试中取得了 94.5% 的准确率，超越了主流通用大模型和专业文档解析模型。该模型创新性地支持文档元素的不规则边界框定位，能够高效处理扫描、倾斜和屏幕截图图像。",
  "Phi-3-medium-128k-instruct.description": "与 Phi-3-medium 模型相同，但支持更大上下文窗口，适用于 RAG 或少样本提示。",
  "Phi-3-medium-4k-instruct.description": "一款拥有 140 亿参数的模型，质量优于 Phi-3-mini，专注于高质量、推理密集型数据。",
  "Phi-3-mini-128k-instruct.description": "与 Phi-3-mini 模型相同，但支持更大上下文窗口，适用于 RAG 或少样本提示。",
  "Phi-3-mini-4k-instruct.description": "Phi-3 系列中最小的成员，优化了质量与低延迟表现。",
  "Phi-3-small-128k-instruct.description": "与 Phi-3-small 模型相同，但支持更大上下文窗口，适用于 RAG 或少样本提示。",
  "Phi-3-small-8k-instruct.description": "一款拥有 70 亿参数的模型，质量优于 Phi-3-mini，专注于高质量、推理密集型数据。",
  "Phi-3.5-mini-instruct.description": "Phi-3-mini 模型的更新版本。",
  "Phi-3.5-vision-instrust.description": "Phi-3-vision 模型的更新版本。",
  "Pro/MiniMaxAI/MiniMax-M2.1.description": "MiniMax-M2.1 是一个开源的大型语言模型，专为智能体能力优化，擅长编程、工具使用、指令执行和长期规划。该模型支持多语言软件开发和复杂的多步骤工作流执行，在 SWE-bench Verified 中获得 74.0 分，在多语言场景中超越了 Claude Sonnet 4.5。",
  "Pro/Qwen/Qwen2-7B-Instruct.description": "Qwen2-7B-Instruct 是 Qwen2 系列中的一款 70 亿参数指令微调大模型。采用 Transformer 架构，结合 SwiGLU、注意力 QKV 偏置和分组查询注意力，支持大输入，语言理解、生成、多语言、编程、数学和推理能力强，超越大多数开源模型，媲美闭源模型。在多个基准测试中优于 Qwen1.5-7B-Chat。",
  "Pro/Qwen/Qwen2.5-7B-Instruct.description": "Qwen2.5-7B-Instruct 是阿里云最新大模型系列的一部分。该 70 亿参数模型在编程和数学方面有显著提升，支持 29+ 种语言，增强了指令理解、结构化数据处理和结构化输出（特别是 JSON）。",
  "Pro/Qwen/Qwen2.5-Coder-7B-Instruct.description": "Qwen2.5-Coder-7B-Instruct 是阿里云最新面向编程的大模型。基于 Qwen2.5 构建，训练数据达 5.5 万亿 token，显著提升代码生成、推理与修复能力，同时保留数学与通用能力，为编程智能体提供坚实基础。",
  "Pro/Qwen/Qwen2.5-VL-7B-Instruct.description": "Qwen2.5-VL 是 Qwen 系列最新的视觉语言模型，具备强大的视觉理解能力。可分析图像中的文本、图表和布局，理解长视频与事件，支持推理与工具使用、多格式目标定位和结构化输出。通过动态分辨率与帧率训练提升视频理解能力，并增强视觉编码器效率。",
  "Pro/THUDM/GLM-4.1V-9B-Thinking.description": "GLM-4.1V-9B-Thinking 是由智谱 AI 与清华 KEG 实验室联合开发的开源视觉语言模型，专为复杂多模态认知设计。基于 GLM-4-9B-0414 构建，加入思维链推理与强化学习，显著提升跨模态推理能力与稳定性。",
  "Pro/THUDM/glm-4-9b-chat.description": "GLM-4-9B-Chat 是智谱 AI 发布的开源 GLM-4 模型，在语义、数学、推理、编程和知识方面表现出色。除多轮对话外，还支持网页浏览、代码执行、自定义工具调用和长文本推理。支持 26 种语言（包括中文、英文、日语、韩语、德语），在 AlignBench-v2、MT-Bench、MMLU 和 C-Eval 等基准测试中表现优异，支持最长 128K 上下文，适用于学术与商业场景。",
  "Pro/deepseek-ai/DeepSeek-R1-Distill-Qwen-7B.description": "DeepSeek-R1-Distill-Qwen-7B 是从 Qwen2.5-Math-7B 蒸馏而来，并在 80 万条精心挑选的 DeepSeek-R1 样本上进行微调。该模型表现出色，在 MATH-500 上达到 92.8%，在 AIME 2024 上达到 55.5%，在 CodeForces 上的评分为 1189（7B 模型）。",
  "Pro/deepseek-ai/DeepSeek-R1.description": "DeepSeek-R1 是一个基于强化学习（RL）的推理模型，旨在减少重复并提升可读性。在 RL 之前使用冷启动数据进一步增强推理能力，在数学、编程和推理任务上可与 OpenAI-o1 相媲美，并通过精细训练提升整体表现。",
  "Pro/deepseek-ai/DeepSeek-V3.1-Terminus.description": "DeepSeek-V3.1-Terminus 是 V3.1 的更新版本，定位为混合代理大模型。该版本修复了用户反馈的问题，提升了稳定性、语言一致性，并减少了中英文混杂和异常字符。它集成了思维模式与非思维模式，并配备聊天模板以实现灵活切换。同时还提升了代码代理和搜索代理的性能，使工具使用和多步骤任务更加可靠。",
  "Pro/deepseek-ai/DeepSeek-V3.2-Exp.description": "DeepSeek-V3.2-Exp 是 V3.2 的实验性版本，作为通往下一代架构的桥梁。在 V3.1-Terminus 的基础上引入了 DeepSeek 稀疏注意力（DSA），以提升长上下文训练与推理效率，并针对工具使用、长文档理解和多步骤推理进行了优化。非常适合探索在大上下文预算下的高效推理能力。",
  "Pro/deepseek-ai/DeepSeek-V3.description": "DeepSeek-V3 是一个拥有 6710 亿参数的 MoE 模型，采用 MLA 和 DeepSeekMoE 架构，并通过无损负载均衡实现高效推理与训练。预训练数据量达 14.8 万亿高质量 token，并通过 SFT 和 RL 进一步调优，性能超越其他开源模型，接近领先的闭源模型。",
  "Pro/moonshotai/Kimi-K2-Instruct-0905.description": "Kimi K2-Instruct-0905 是最新且最强大的 Kimi K2 模型。作为顶级 MoE 模型，拥有 1 万亿总参数和 320 亿激活参数。其主要特点包括更强的代理式编程智能，在基准测试和真实代理任务中取得显著提升，同时前端代码美观性和可用性也得到优化。",
  "Pro/moonshotai/Kimi-K2-Thinking.description": "Kimi K2 Thinking Turbo 是 K2 Thinking 的高性能变体，在保持多步骤推理和工具使用能力的同时，优化了推理速度和吞吐量。该模型为 MoE 架构，拥有约 1 万亿总参数，原生支持 256K 上下文，并在生产场景中具备稳定的大规模工具调用能力，满足更严格的延迟与并发需求。",
  "Pro/moonshotai/Kimi-K2.5.description": "Kimi K2.5 是一款原生开源多模态智能体模型，基于 Kimi-K2-Base 构建，训练数据包含约 1.5 万亿视觉与文本混合标记。该模型采用 MoE 架构，总参数量达 1 万亿，活跃参数为 320 亿，支持 256K 上下文窗口，能够无缝融合视觉与语言理解能力。",
  "Pro/zai-org/glm-4.7.description": "GLM-4.7 是智谱推出的新一代旗舰大模型，拥有 3550 亿总参数和 320 亿激活参数，在通用对话、推理和智能体能力方面实现全面升级。GLM-4.7 强化了交错式思维，并引入了保留式思维和轮次级思维。",
  "QwQ-32B-Preview.description": "Qwen QwQ 是一个实验性研究模型，专注于提升推理能力。",
  "Qwen/QVQ-72B-Preview.description": "QVQ-72B-Preview 是 Qwen 团队推出的研究模型，专注于视觉推理，擅长复杂场景理解和视觉数学问题。",
  "Qwen/QwQ-32B-Preview.description": "Qwen QwQ 是一个实验性研究模型，致力于提升 AI 的推理能力。",
  "Qwen/QwQ-32B.description": "QwQ 是 Qwen 系列中的推理模型。与标准的指令微调模型相比，它引入了思维与推理机制，显著提升了下游任务表现，尤其在处理复杂问题时表现突出。QwQ-32B 是一款中等规模的推理模型，在性能上可与 DeepSeek-R1 和 o1-mini 等顶级推理模型竞争。该模型采用 RoPE、SwiGLU、RMSNorm 和带偏置的注意力 QKV，拥有 64 层和 40 个 Q 注意力头（GQA 中为 8 个 KV）。",
  "Qwen/Qwen-Image-Edit-2509.description": "Qwen-Image-Edit-2509 是 Qwen 团队推出的最新图像编辑版本，基于 200 亿参数的 Qwen-Image 模型构建，将强大的文本渲染能力扩展至图像编辑，实现精确的文本修改。该模型采用双重控制架构，输入分别传递至 Qwen2.5-VL 进行语义控制和 VAE 编码器进行外观控制，从而实现语义层与外观层的编辑。支持局部编辑（添加/删除/修改）及更高层次的语义编辑，如 IP 创作与风格迁移，同时保持语义一致性，在多个基准测试中取得 SOTA 表现。",
  "Qwen/Qwen-Image.description": "Qwen-Image 是 Qwen 团队推出的 200 亿参数图像生成基础模型，在复杂文本渲染和精确图像编辑方面取得重大突破，尤其擅长高保真中英文文本渲染。支持多行及段落排版，保持排版一致性。除文本渲染外，还支持从写实风格到动漫风格的多种图像风格，以及风格迁移、对象添加/删除、细节增强、文本编辑和姿态控制等高级编辑功能，致力于打造全面的视觉创作基础模型。",
  "Qwen/Qwen2-72B-Instruct.description": "Qwen 2 Instruct（72B）在企业级任务中提供精准的指令执行能力。",
  "Qwen/Qwen2-7B-Instruct.description": "Qwen2-7B-Instruct 是 Qwen2 系列中的 7B 指令微调模型，采用 Transformer 架构，结合 SwiGLU、QKV 偏置和分组查询注意力。该模型可处理大规模输入，在理解、生成、多语言、编程、数学和推理等基准测试中表现优异，超越大多数开源模型，并在多项评估中优于 Qwen1.5-7B-Chat。",
  "Qwen/Qwen2-VL-72B-Instruct.description": "Qwen2-VL 是最新的 Qwen-VL 模型，在 MathVista、DocVQA、RealWorldQA 和 MTVQA 等视觉基准测试中达到 SOTA 水平。支持超过 20 分钟的视频理解，适用于视频问答、对话和内容创作。具备复杂推理与决策能力，可与设备/机器人集成，实现视觉驱动的操作。除中英文外，还能识别多种语言文本，包括大多数欧洲语言、日语、韩语、阿拉伯语和越南语。",
  "Qwen/Qwen2.5-14B-Instruct.description": "Qwen2.5-14B-Instruct 是阿里云最新大语言模型系列的一部分。该 14B 模型在编程和数学方面有显著提升，支持 29 种以上语言，并在指令理解、结构化数据理解和结构化输出（尤其是 JSON）方面表现更优。",
  "Qwen/Qwen2.5-32B-Instruct.description": "Qwen2.5-32B-Instruct 是阿里云最新大语言模型系列的一部分。该 32B 模型在编程和数学方面有显著提升，支持 29 种以上语言，并在指令理解、结构化数据理解和结构化输出（尤其是 JSON）方面表现更优。",
  "Qwen/Qwen2.5-72B-Instruct-128K.description": "Qwen2.5-72B-Instruct 是阿里云最新大语言模型系列的一部分。该 72B 模型在编程和数学方面表现更强，支持最多 128K 输入和超过 8K 输出，覆盖 29 种以上语言，并在指令理解和结构化输出（尤其是 JSON）方面有显著提升。",
  "Qwen/Qwen2.5-72B-Instruct-Turbo.description": "Qwen2.5 是一个专为指令类任务优化的大语言模型系列。",
  "Qwen/Qwen2.5-72B-Instruct.description": "Qwen2.5-72B-Instruct 是阿里云最新大语言模型系列的一部分。该 72B 模型在编程和数学方面有显著提升，支持 29 种以上语言，并在指令理解、结构化数据理解和结构化输出（尤其是 JSON）方面表现更优。",
  "Qwen/Qwen2.5-7B-Instruct-Turbo.description": "Qwen2.5 是一个专为指令类任务优化的大语言模型系列。",
  "Qwen/Qwen2.5-7B-Instruct.description": "Qwen2.5-7B-Instruct 是阿里云最新大语言模型系列的一部分。该 7B 模型在编程和数学方面有显著提升，支持 29 种以上语言，并在指令理解、结构化数据理解和结构化输出（尤其是 JSON）方面表现更优。",
  "Qwen/Qwen2.5-Coder-32B-Instruct.description": "Qwen2.5 Coder 32B Instruct 是阿里云最新面向编程的大语言模型。基于 Qwen2.5 构建，并使用 5.5 万亿 tokens 进行训练，在代码生成、推理和修复方面有显著提升，同时保留数学和通用能力，为构建编程智能体提供强大基础。",
  "Qwen/Qwen2.5-Coder-7B-Instruct.description": "Qwen2.5-Coder-7B-Instruct 是阿里云最新面向编程的大语言模型。基于 Qwen2.5 构建，并使用 5.5 万亿 tokens 进行训练，在代码生成、推理和修复方面有显著提升，同时保留数学和通用能力，为构建编程智能体提供坚实基础。",
  "Qwen/Qwen2.5-VL-32B-Instruct.description": "Qwen2.5-VL-32B-Instruct 是 Qwen 团队推出的多模态模型。它能够识别常见物体并分析文本、图表、图标、图形和布局。作为视觉智能体，它可进行推理并动态控制工具，包括电脑和手机操作。它能精准定位物体，并为发票和表格生成结构化输出。相比 Qwen2-VL，强化学习进一步提升了数学和问题解决能力，生成更符合人类偏好的响应。",
  "Qwen/Qwen2.5-VL-72B-Instruct.description": "Qwen2.5-VL 是 Qwen2.5 系列中的视觉语言模型，具备重大升级：更强的视觉理解能力，涵盖物体、文本、图表和布局；作为视觉智能体具备动态工具使用能力；支持超过 1 小时的视频理解并捕捉关键事件；通过框或点实现精准物体定位；为扫描数据如发票和表格生成结构化输出。",
  "Qwen/Qwen3-14B.description": "Qwen3 是新一代通义千问模型，在推理能力、通用能力、智能体能力和多语言表现方面有重大提升，支持思维模式切换。",
  "Qwen/Qwen3-235B-A22B-Instruct-2507.description": "Qwen3-235B-A22B-Instruct-2507 是 Qwen3 的旗舰 MoE 模型，总参数 235B，激活参数 22B。该版本为非思维模式，专注于提升指令理解、逻辑推理、文本理解、数学、科学、编程和工具使用能力。同时扩展多语言长尾知识，更好地契合用户在主观开放任务中的偏好。",
  "Qwen/Qwen3-235B-A22B-Thinking-2507.description": "Qwen3-235B-A22B-Thinking-2507 是专注于复杂推理的 Qwen3 模型。采用 MoE 架构，总参数 235B，每个 token 激活约 22B 参数，提升效率。作为专用思维模型，在逻辑、数学、科学、编程和学术基准测试中表现卓越，达到顶级开放思维性能。同时提升了指令理解、工具使用和文本生成能力，原生支持 256K 上下文，适用于深度推理和长文档处理。",
  "Qwen/Qwen3-235B-A22B.description": "Qwen3 是新一代通义千问模型，在推理能力、通用能力、智能体能力和多语言表现方面有重大提升，支持思维模式切换。",
  "Qwen/Qwen3-30B-A3B-Instruct-2507.description": "Qwen3-30B-A3B-Instruct-2507 是 Qwen3-30B-A3B 的更新版非思维模型。该模型为 MoE 架构，总参数 30.5B，激活参数 3.3B。显著提升了指令理解、逻辑推理、文本理解、数学、科学、编程和工具使用能力，扩展多语言长尾知识，并更好地契合用户在主观开放任务中的偏好。支持 256K 上下文。该模型仅为非思维模式，不会输出 `<think></think>` 标签。",
  "Qwen/Qwen3-30B-A3B-Thinking-2507.description": "Qwen3-30B-A3B-Thinking-2507 是 Qwen3 系列中最新的思维模型。采用 MoE 架构，总参数 30.5B，激活参数 3.3B，专注于复杂任务。在逻辑、数学、科学、编程和学术基准测试中表现显著提升，同时增强了指令理解、工具使用、文本生成和偏好对齐能力。原生支持 256K 上下文，并可扩展至 1M tokens。该版本专为思维模式设计，具备详细的逐步推理能力和强大的智能体能力。",
  "Qwen/Qwen3-30B-A3B.description": "Qwen3 是新一代通义千问模型，在推理能力、通用能力、智能体能力和多语言表现方面有重大提升，支持思维模式切换。",
  "Qwen/Qwen3-32B.description": "Qwen3 是新一代通义千问模型，在推理能力、通用能力、智能体能力和多语言表现方面有重大提升，支持思维模式切换。",
  "Qwen/Qwen3-8B.description": "Qwen3 是新一代通义千问模型，在推理能力、通用能力、智能体能力和多语言表现方面有重大提升，支持思维模式切换。",
  "Qwen/Qwen3-Coder-30B-A3B-Instruct.description": "Qwen3-Coder-30B-A3B-Instruct 是 Qwen 团队推出的 Qwen3 系列代码模型。该模型在保持高性能和高效率的同时，显著增强了代码能力。在智能体编程、自动化浏览器操作和工具使用等开放模型中表现出色。原生支持 256K 上下文，并可扩展至 1M tokens，适用于代码库级理解。支持 Qwen Code 和 CLINE 等平台的智能体编程，采用专用函数调用格式。",
  "Qwen/Qwen3-Coder-480B-A35B-Instruct.description": "Qwen3-Coder-480B-A35B-Instruct 是阿里巴巴迄今为止最具智能体能力的代码模型。该模型为 MoE 架构，总参数 480B，激活参数 35B，在效率与性能之间实现平衡。原生支持 256K 上下文，并可通过 YaRN 扩展至 1M tokens，支持大规模代码库处理。专为智能体编程工作流设计，能够与工具和环境交互，解决复杂编程任务。在代码和智能体基准测试中表现优异，可媲美 Claude Sonnet 4 等领先模型。",
  "Qwen/Qwen3-Next-80B-A3B-Instruct.description": "Qwen3-Next-80B-A3B-Instruct 是一款基于 Qwen3-Next 架构的下一代基础模型，具备极高的训练与推理效率。该模型融合了混合注意力机制（门控 DeltaNet + 门控注意力）、高度稀疏的 MoE 架构以及训练稳定性优化。尽管总参数量为 800 亿，但推理时仅激活约 30 亿参数，大幅降低计算成本，在超过 32K 上下文长度下，相较 Qwen3-32B 实现了 10 倍以上的吞吐提升。该版本经过指令微调，面向通用任务（不启用“思考”模式），在部分基准测试中表现可与 Qwen3-235B 相媲美，尤其在超长上下文任务中展现出显著优势。",
  "Qwen/Qwen3-Next-80B-A3B-Thinking.description": "Qwen3-Next-80B-A3B-Thinking 是一款面向复杂推理任务的下一代基础模型，采用 Qwen3-Next 架构，结合混合注意力机制（门控 DeltaNet + 门控注意力）与高度稀疏的 MoE 架构，实现极致的训练与推理效率。模型总参数为 800 亿，推理时仅激活约 30 亿参数，在超过 32K 上下文长度下，相较 Qwen3-32B 实现了 10 倍以上的吞吐提升。该“思考”版本专为多步骤任务设计，如证明、代码生成、逻辑分析与规划，能够输出结构化的思维链条。其性能超越 Qwen3-32B-Thinking，并在多个基准测试中优于 Gemini-2.5-Flash-Thinking。",
  "Qwen/Qwen3-Omni-30B-A3B-Captioner.description": "Qwen3-Omni-30B-A3B-Captioner 是 Qwen3 系列的视觉语言模型（VLM），专为生成高质量、细致且准确的图像描述而设计。该模型采用 300 亿参数的 MoE 架构，具备深度图像理解能力，能够流畅生成描述，擅长捕捉细节、理解场景、识别物体及进行关系推理。",
  "Qwen/Qwen3-Omni-30B-A3B-Instruct.description": "Qwen3-Omni-30B-A3B-Instruct 是 Qwen3 系列的 MoE 模型，拥有 300 亿总参数和 30 亿激活参数，在保持强大性能的同时降低推理成本。该模型基于高质量多源多语种数据训练，支持全模态输入（文本、图像、音频、视频）及跨模态理解与生成。",
  "Qwen/Qwen3-Omni-30B-A3B-Thinking.description": "Qwen3-Omni-30B-A3B-Thinking 是 Qwen3-Omni 的核心“思考者”组件，能够处理多模态输入（文本、音频、图像、视频），并执行复杂的思维链推理。它将多模态信息统一为共享表示，实现深度跨模态理解。该模型采用 MoE 架构，拥有 300 亿总参数和 30 亿激活参数，在推理能力与计算效率之间实现良好平衡。",
  "Qwen/Qwen3-VL-235B-A22B-Instruct.description": "Qwen3-VL-235B-A22B-Instruct 是一款基于 MoE 架构的大型指令微调视觉语言模型，具备卓越的多模态理解与生成能力。原生支持 256K 上下文长度，适用于高并发生产级多模态服务场景。",
  "Qwen/Qwen3-VL-235B-A22B-Thinking.description": "Qwen3-VL-235B-A22B-Thinking 是 Qwen3-VL 的旗舰“思考”版本，专为复杂多模态推理、长上下文推理及企业级智能体交互优化。",
  "Qwen/Qwen3-VL-30B-A3B-Instruct.description": "Qwen3-VL-30B-A3B-Instruct 是一款经过指令微调的 Qwen3-VL 模型，具备强大的视觉语言理解与生成能力。原生支持 256K 上下文长度，适用于多模态对话与图像条件生成任务。",
  "Qwen/Qwen3-VL-30B-A3B-Thinking.description": "Qwen3-VL-30B-A3B-Thinking 是 Qwen3-VL 的推理增强版本，专为多模态推理、图像转代码及复杂视觉理解任务优化。支持 256K 上下文，具备更强的思维链能力。",
  "Qwen/Qwen3-VL-32B-Instruct.description": "Qwen3-VL-32B-Instruct 是 Qwen 团队推出的视觉语言模型，在多个 VL 基准测试中取得领先 SOTA 成绩。支持百万像素分辨率图像，具备强大的视觉理解、多语种 OCR、细粒度视觉定位与视觉对话能力，能够处理复杂多模态任务，并支持工具调用与前缀补全。",
  "Qwen/Qwen3-VL-32B-Thinking.description": "Qwen3-VL-32B-Thinking 针对复杂视觉推理任务进行了优化，内置“思考模式”，在生成答案前输出中间推理步骤，提升多步骤逻辑、规划与复杂推理能力。支持百万像素图像，具备强大的视觉理解、多语种 OCR、细粒度定位、视觉对话、工具调用与前缀补全能力。",
  "Qwen/Qwen3-VL-8B-Instruct.description": "Qwen3-VL-8B-Instruct 是基于 Qwen3-8B-Instruct 构建的视觉语言模型，训练于大规模图文数据，擅长通用视觉理解、以视觉为中心的对话及图像中的多语种文本识别，适用于视觉问答、图像描述、多模态指令跟随与工具使用等任务。",
  "Qwen/Qwen3-VL-8B-Thinking.description": "Qwen3-VL-8B-Thinking 是 Qwen3 的视觉思考版本，专为复杂多步骤推理任务优化。在生成答案前输出思维链，提升准确性，适用于深度视觉问答与图像细节分析。",
  "Qwen2-72B-Instruct.description": "Qwen2 是 Qwen 系列的最新版本，支持 128K 上下文窗口。与当前最强的开源模型相比，Qwen2-72B 在自然语言理解、知识、代码、数学及多语种能力方面显著领先。",
  "Qwen2-7B-Instruct.description": "Qwen2 是 Qwen 系列的最新版本，超越同尺寸甚至更大尺寸的开源模型。Qwen2 7B 在多个基准测试中表现出显著优势，尤其在代码与中文理解方面。",
  "Qwen2-VL-72B.description": "Qwen2-VL-72B 是一款强大的视觉语言模型，支持多模态图文处理，能够准确识别图像内容并生成相关描述或答案。",
  "Qwen2.5-14B-Instruct.description": "Qwen2.5-14B-Instruct 是一款拥有 140 亿参数的大语言模型，性能强劲，针对中文及多语种场景优化，支持智能问答与内容生成。",
  "Qwen2.5-32B-Instruct.description": "Qwen2.5-32B-Instruct 是一款拥有 320 亿参数的大语言模型，性能均衡，针对中文及多语种场景优化，支持智能问答与内容生成。",
  "Qwen2.5-72B-Instruct.description": "一款面向中英文的 LLM，针对语言、编程、数学与推理任务进行调优。",
  "Qwen2.5-7B-Instruct.description": "Qwen2.5-7B-Instruct 是一款拥有 70 亿参数的大语言模型，支持函数调用与外部系统无缝集成，极大提升灵活性与可扩展性。针对中文及多语种场景优化，支持智能问答与内容生成。",
  "Qwen2.5-Coder-14B-Instruct.description": "Qwen2.5-Coder-14B-Instruct 是一款大规模预训练的编程指令模型，具备强大的代码理解与生成能力，能够高效处理多种编程任务，适用于智能编程、自动脚本生成与编程问答。",
  "Qwen2.5-Coder-32B-Instruct.description": "高级 LLM，支持多种主流编程语言的代码生成、推理与错误修复。",
  "Qwen3-235B-A22B-Instruct-2507-FP8.description": "Qwen3 235B A22B Instruct 2507 通过 MoE 架构优化推理效率，专为高级推理与指令跟随任务设计。",
  "Qwen3-235B.description": "Qwen3-235B-A22B 是一款 MoE 模型，引入混合推理模式，用户可在“思考”与“非思考”之间无缝切换。支持 119 种语言与方言的理解与推理，具备强大的工具调用能力，在通用能力、代码与数学、多语种能力及知识推理等多个基准测试中，与 DeepSeek R1、OpenAI o1、o3-mini、Grok 3 及 Google Gemini 2.5 Pro 等主流模型展开竞争。",
  "Qwen3-32B.description": "Qwen3-32B 是一款稠密模型，引入混合推理模式，用户可在“思考”与“非思考”之间切换。通过架构改进、数据增强与训练优化，其性能可与 Qwen2.5-72B 相媲美。",
  "SenseChat-128K.description": "基于V4的128K上下文模型，擅长长文本理解与生成。",
  "SenseChat-32K.description": "基于V4的32K上下文模型，适用于多种场景，灵活高效。",
  "SenseChat-5-1202.description": "基于V5.5的最新版本，在中英文基础能力、对话、理工知识、人文知识、写作、数学/逻辑及长度控制方面有显著提升。",
  "SenseChat-5-Cantonese.description": "专为香港本地对话习惯、俚语及本地知识设计；粤语理解超越GPT-4，知识、推理、数学与编程能力媲美GPT-4 Turbo。",
  "SenseChat-5-beta.description": "部分性能超越SenseChat-5-1202。",
  "SenseChat-5.description": "最新V5.5版本，支持128K上下文；在数学推理、英文对话、指令理解及长文本处理方面有重大提升，整体表现可与GPT-4o媲美。",
  "SenseChat-Character-Pro.description": "高级角色对话模型，支持32K上下文，能力增强，支持中英文。",
  "SenseChat-Character.description": "标准角色对话模型，支持8K上下文，响应速度快。",
  "SenseChat-Turbo-1202.description": "最新轻量模型，在推理成本大幅降低的同时，达到90%以上的全模型能力。",
  "SenseChat-Turbo.description": "适用于快速问答及模型微调场景。",
  "SenseChat-Vision.description": "最新V5.5版本，支持多图输入，在属性识别、空间关系、动作/事件检测、场景理解、情感识别、常识推理及文本理解/生成方面全面提升。",
  "SenseChat.description": "基于V4的4K上下文模型，具备强大的通用能力。",
  "SenseNova-V6-5-Pro.description": "通过多模态、语言与推理数据的全面更新及训练策略优化，新模型在多模态推理与通用指令理解方面显著提升，支持最多128K上下文窗口，擅长OCR与文旅IP识别任务。",
  "SenseNova-V6-5-Turbo.description": "通过多模态、语言与推理数据的全面更新及训练策略优化，新模型在多模态推理与通用指令理解方面显著提升，支持最多128K上下文窗口，擅长OCR与文旅IP识别任务。",
  "SenseNova-V6-Pro.description": "原生统一图像、文本与视频，打破传统多模态壁垒；在OpenCompass与SuperCLUE等评测中名列前茅。",
  "SenseNova-V6-Reasoner.description": "融合视觉与语言的深度推理，支持慢思考与完整思维链。",
  "SenseNova-V6-Turbo.description": "原生统一图像、文本与视频，打破传统多模态壁垒；在核心多模态与语言能力方面领先，在多项评测中表现优异。",
  "Skylark2-lite-8k.description": "Skylark第二代模型。Skylark2-lite响应迅速，适用于对准确率要求不高的实时、成本敏感场景，支持8K上下文窗口。",
  "Skylark2-pro-32k.description": "Skylark第二代模型。Skylark2-pro具备更高准确率，适用于专业文案、小说创作及高质量翻译等复杂文本生成任务，支持32K上下文窗口。",
  "Skylark2-pro-4k.description": "Skylark第二代模型。Skylark2-pro具备更高准确率，适用于专业文案、小说创作及高质量翻译等复杂文本生成任务，支持4K上下文窗口。",
  "Skylark2-pro-character-4k.description": "Skylark第二代模型。Skylark2-pro-character擅长角色扮演与对话，能根据提示展现鲜明人设风格，适用于聊天机器人、虚拟助手与客服场景，响应迅速。",
  "Skylark2-pro-turbo-8k.description": "Skylark第二代模型。Skylark2-pro-turbo-8k在保持8K上下文窗口的同时，实现更快推理与更低成本。",
  "THUDM/GLM-4-32B-0414.description": "GLM-4-32B-0414是下一代开放GLM模型，拥有32B参数，性能可与OpenAI GPT及DeepSeek V3/R1系列媲美。",
  "THUDM/GLM-4-9B-0414.description": "GLM-4-9B-0414是9B参数的GLM模型，继承GLM-4-32B技术，部署更轻量，擅长代码生成、网页设计、SVG生成与基于搜索的写作。",
  "THUDM/GLM-4.1V-9B-Thinking.description": "GLM-4.1V-9B-Thinking是由智谱AI与清华KEG实验室联合推出的开源视觉语言模型，专为复杂多模态认知设计。基于GLM-4-9B-0414，加入思维链推理与强化学习，显著提升跨模态推理能力与稳定性。",
  "THUDM/GLM-Z1-32B-0414.description": "GLM-Z1-32B-0414是基于GLM-4-32B-0414构建的深度推理模型，结合冷启动数据与扩展强化学习，在数学、代码与逻辑任务上显著优于基础模型。",
  "THUDM/GLM-Z1-9B-0414.description": "GLM-Z1-9B-0414是9B参数的小型GLM模型，保留开源优势，具备强大能力，在数学推理与通用任务上表现出色，在同类开源模型中领先。",
  "THUDM/GLM-Z1-Rumination-32B-0414.description": "GLM-Z1-Rumination-32B-0414是具备深度思考能力的推理模型（对标OpenAI Deep Research）。与传统深度思考模型不同，它通过更长时间的思考解决更开放复杂的问题。",
  "THUDM/glm-4-9b-chat.description": "GLM-4-9B-Chat是智谱AI开源的GLM-4模型，在语义、数学、推理、代码与知识方面表现出色。除多轮对话外，还支持网页浏览、代码执行、自定义工具调用与长文本推理。支持26种语言（包括中文、英文、日文、韩文、德文），在AlignBench-v2、MT-Bench、MMLU与C-Eval等评测中表现优异，支持128K上下文，适用于学术与商业场景。",
  "Tongyi-Zhiwen/QwenLong-L1-32B.description": "QwenLong-L1-32B是首个通过强化学习训练的长上下文推理模型（LRM），专为长文本推理优化。其渐进式上下文扩展RL策略实现从短到长上下文的稳定迁移。在七个长文档问答基准上超越OpenAI-o3-mini与Qwen3-235B-A22B，媲美Claude-3.7-Sonnet-Thinking，尤其擅长数学、逻辑与多跳推理。",
  "Yi-34B-Chat.description": "Yi-1.5-34B在保留系列强大通用语言能力的基础上，通过对5000亿高质量token的增量训练，显著提升数学逻辑与编程能力。",
  "abab5.5-chat.description": "专为高效文本生成与复杂任务处理的专业场景设计，提升工作效率。",
  "abab5.5s-chat.description": "专为中文人设对话设计，提供高质量中文对话体验，适用于多种应用场景。",
  "abab6.5g-chat.description": "专为多语言人设对话设计，支持高质量英文及其他语言的对话生成。",
  "abab6.5s-chat.description": "适用于多种自然语言处理任务，包括文本生成与对话系统。",
  "abab6.5t-chat.description": "针对中文人设对话优化，提供符合中文表达习惯的流畅对话体验。",
  "accounts/fireworks/models/deepseek-r1.description": "DeepSeek-R1是最先进的大语言模型，结合强化学习与冷启动数据优化，具备卓越的推理、数学与编程能力。",
  "accounts/fireworks/models/deepseek-v3.description": "DeepSeek推出的强大专家混合（MoE）语言模型，总参数671B，每个token激活37B参数。",
  "accounts/fireworks/models/llama-v3-70b-instruct.description": "Meta 开发并发布了 Meta Llama 3 大语言模型系列，包括 8B 和 70B 参数规模的预训练与指令微调文本生成模型。Llama 3 的指令微调模型专为对话场景优化，在多个行业通用基准测试中优于许多现有的开源聊天模型。",
  "accounts/fireworks/models/llama-v3-8b-instruct-hf.description": "Meta Llama 3 的指令微调模型专为对话场景优化，在多个行业通用基准测试中优于许多现有的开源聊天模型。Llama 3 8B Instruct（HF 版本）是 Llama 3 8B Instruct 的原始 FP16 版本，预期结果与 Hugging Face 官方实现一致。",
  "accounts/fireworks/models/llama-v3-8b-instruct.description": "Meta 开发并发布了 Meta Llama 3 大语言模型系列，包括 8B 和 70B 参数规模的预训练与指令微调文本生成模型。Llama 3 的指令微调模型专为对话场景优化，在多个行业通用基准测试中优于许多现有的开源聊天模型。",
  "accounts/fireworks/models/llama-v3p1-405b-instruct.description": "Meta Llama 3.1 是一个多语言大语言模型系列，提供 8B、70B 和 405B 参数规模的预训练与指令微调生成模型。指令微调模型专为多语言对话优化，在多个行业通用基准测试中优于许多开源和闭源聊天模型。405B 是 Llama 3.1 系列中最强大的模型，采用 FP8 推理，性能接近参考实现。",
  "accounts/fireworks/models/llama-v3p1-70b-instruct.description": "Meta Llama 3.1 是一个多语言大语言模型系列，提供 8B、70B 和 405B 参数规模的预训练与指令微调生成模型。指令微调模型专为多语言对话优化，在多个行业通用基准测试中优于许多开源和闭源聊天模型。",
  "accounts/fireworks/models/llama-v3p1-8b-instruct.description": "Meta Llama 3.1 是一个多语言大语言模型系列，提供 8B、70B 和 405B 参数规模的预训练与指令微调生成模型。指令微调模型专为多语言对话优化，在多个行业通用基准测试中优于许多开源和闭源聊天模型。",
  "accounts/fireworks/models/llama-v3p2-11b-vision-instruct.description": "Meta 推出的一个拥有 110 亿参数的指令微调视觉推理模型，专为图像识别、图像推理、图像描述和图像相关问答优化。该模型能够理解图表等视觉数据，并通过生成图像细节的文本描述实现视觉与语言的融合。",
  "accounts/fireworks/models/llama-v3p2-3b-instruct.description": "Llama 3.2 3B Instruct 是 Meta 推出的轻量级多语言模型，具备高效运行能力，在延迟和成本方面相较于大型模型具有显著优势。典型应用包括查询/提示重写和写作辅助。",
  "accounts/fireworks/models/llama-v3p2-90b-vision-instruct.description": "Meta 推出的一个拥有 900 亿参数的指令微调视觉推理模型，专为图像识别、图像推理、图像描述和图像相关问答优化。该模型能够理解图表等视觉数据，并通过生成图像细节的文本描述实现视觉与语言的融合。注意：该模型目前作为无服务器模型实验性提供，Fireworks 可能会在短时间内终止部署，生产环境使用请注意。",
  "accounts/fireworks/models/llama-v3p3-70b-instruct.description": "Llama 3.3 70B Instruct 是 Llama 3.1 70B 的 12 月更新版本，在工具使用、多语言文本支持、数学和编程方面相较 2024 年 7 月版本有显著提升。该模型在推理、数学和指令遵循方面达到行业领先水平，性能接近 3.1 405B，同时具备更高的速度和成本优势。",
  "accounts/fireworks/models/mistral-small-24b-instruct-2501.description": "一个拥有 240 亿参数的模型，具备与更大模型相当的先进能力。",
  "accounts/fireworks/models/mixtral-8x22b-instruct.description": "Mixtral MoE 8x22B Instruct v0.1 是 Mixtral MoE 8x22B v0.1 的指令微调版本，启用了聊天补全 API。",
  "accounts/fireworks/models/mixtral-8x7b-instruct.description": "Mixtral MoE 8x7B Instruct 是 Mixtral MoE 8x7B 的指令微调版本，启用了聊天补全 API。",
  "accounts/fireworks/models/mythomax-l2-13b.description": "MythoMix 的改进版本，可能是其更精致的形式，融合了 MythoLogic-L2 和 Huginn，并采用高度实验性的张量合并技术。其独特性使其在讲故事和角色扮演方面表现出色。",
  "accounts/fireworks/models/phi-3-vision-128k-instruct.description": "Phi-3-Vision-128K-Instruct 是一个轻量级、先进的开源多模态模型，基于合成数据和精选的公共网络数据集构建，专注于高质量、推理密集型的文本与视觉数据。该模型属于 Phi-3 系列，支持 128K 上下文长度（以 token 计）。通过监督微调和偏好优化等严格增强过程，确保指令遵循的准确性和强大的安全性。",
  "accounts/fireworks/models/qwen-qwq-32b-preview.description": "Qwen QwQ 模型专注于推动 AI 推理能力，展示了开源模型在推理方面可与闭源前沿模型媲美。QwQ-32B-Preview 是一个实验性版本，在 GPQA、AIME、MATH-500 和 LiveCodeBench 等推理与分析任务中达到 o1 水平并超越 GPT-4o 和 Claude 3.5 Sonnet。注意：该模型目前作为无服务器模型实验性提供，Fireworks 可能会在短时间内终止部署，生产环境使用请注意。",
  "accounts/fireworks/models/qwen2-vl-72b-instruct.description": "72B Qwen-VL 模型是阿里巴巴最新版本，体现了近一年的创新成果。",
  "accounts/fireworks/models/qwen2p5-72b-instruct.description": "Qwen2.5 是由 Qwen 团队与阿里云联合开发的仅解码器大语言模型系列，提供 0.5B、1.5B、3B、7B、14B、32B 和 72B 参数规模，涵盖基础模型与指令微调版本。",
  "accounts/fireworks/models/qwen2p5-coder-32b-instruct.description": "Qwen2.5-Coder 是最新的 Qwen 编码大语言模型（前身为 CodeQwen）。注意：该模型目前作为无服务器模型实验性提供，Fireworks 可能会在短时间内终止部署，生产环境使用请注意。",
  "accounts/yi-01-ai/models/yi-large.description": "Yi-Large 是一款顶级大语言模型，在 LMSYS 排行榜上仅次于 GPT-4、Gemini 1.5 Pro 和 Claude 3 Opus。该模型在多语言能力方面表现出色，尤其擅长西班牙语、中文、日语、德语和法语。Yi-Large 也非常适合开发者使用，采用与 OpenAI 相同的 API 架构，便于集成。",
  "ai21-jamba-1.5-large.description": "一个拥有 3980 亿参数（其中 940 亿激活）的多语言模型，支持 256K 上下文窗口、函数调用、结构化输出和基于事实的生成。",
  "ai21-jamba-1.5-mini.description": "一个拥有 520 亿参数（其中 120 亿激活）的多语言模型，支持 256K 上下文窗口、函数调用、结构化输出和基于事实的生成。",
  "ai21-labs/AI21-Jamba-1.5-Large.description": "一个拥有 3980 亿参数（其中 940 亿激活）的多语言模型，支持 256K 上下文窗口、函数调用、结构化输出和基于事实的生成。",
  "ai21-labs/AI21-Jamba-1.5-Mini.description": "一个拥有 520 亿参数（其中 120 亿激活）的多语言模型，支持 256K 上下文窗口、函数调用、结构化输出和基于事实的生成。",
  "alibaba/qwen-3-14b.description": "Qwen3 是 Qwen 系列的最新一代，提供全面的稠密与 MoE 模型组合。基于大规模训练，在推理、指令遵循、智能体能力和多语言支持方面实现突破。",
  "alibaba/qwen-3-235b.description": "Qwen3 是 Qwen 系列的最新一代，提供全面的稠密与 MoE 模型组合。基于大规模训练，在推理、指令遵循、智能体能力和多语言支持方面实现突破。",
  "alibaba/qwen-3-30b.description": "Qwen3 是 Qwen 系列的最新一代，提供全面的稠密与 MoE 模型组合。基于大规模训练，在推理、指令遵循、智能体能力和多语言支持方面实现突破。",
  "alibaba/qwen-3-32b.description": "Qwen3 是 Qwen 系列的最新一代，提供全面的稠密与 MoE 模型组合。基于大规模训练，在推理、指令遵循、智能体能力和多语言支持方面实现突破。",
  "alibaba/qwen3-coder.description": "Qwen3-Coder-480B-A35B-Instruct 是 Qwen 系列中最具智能体能力的代码模型，在智能体编程、浏览器操作等核心编程任务中表现强劲，达到 Claude Sonnet 水平。",
  "amazon/nova-lite.description": "一款极低成本的多模态模型，能够以极快速度处理图像、视频和文本输入。",
  "amazon/nova-micro.description": "一款仅支持文本的模型，具备超低延迟和极低成本。",
  "amazon/nova-pro.description": "一款功能强大的多模态模型，在准确性、速度和成本之间实现最佳平衡，适用于多种任务。",
  "amazon/titan-embed-text-v2.description": "Amazon Titan Text Embeddings V2 是一个轻量级、高效的多语言嵌入模型，支持 1024、512 和 256 维度。",
  "anthropic.claude-3-5-sonnet-20240620-v1:0.description": "Claude 3.5 Sonnet 提升了行业标准，在广泛评估中超越竞争对手和 Claude 3 Opus，同时保持中等速度和成本。",
  "anthropic.claude-3-5-sonnet-20241022-v2:0.description": "Claude 3.5 Sonnet 提升了行业标准，在广泛评估中超越竞争对手和 Claude 3 Opus，同时保持中等速度和成本。",
  "anthropic.claude-3-haiku-20240307-v1:0.description": "Claude 3 Haiku 是 Anthropic 迄今最快、最紧凑的模型，能为简单查询提供近乎即时的响应。它支持图像输入，具备 200K 上下文窗口，带来流畅自然的 AI 交互体验。",
  "anthropic.claude-3-opus-20240229-v1:0.description": "Claude 3 Opus 是 Anthropic 最强大的 AI 模型，在处理高度复杂任务方面表现卓越。它能流畅应对开放式提示和新颖场景，具备类人理解能力，并支持图像输入和 200K 上下文窗口。",
  "anthropic.claude-3-sonnet-20240229-v1:0.description": "Claude 3 Sonnet 在智能与速度之间实现平衡，适用于企业级工作负载，具备高性价比。支持图像输入和 200K 上下文窗口，是大规模 AI 部署的可靠选择。",
  "anthropic.claude-instant-v1.description": "一款快速、经济且功能强大的模型，适用于日常对话、文本分析、摘要生成和文档问答。",
  "anthropic.claude-v2.description": "一款功能全面的模型，擅长处理复杂对话、创意生成和详细指令执行等任务。",
  "anthropic.claude-v2:1.description": "Claude 2 的升级版，具备双倍上下文窗口，并在长文档处理和 RAG 场景中提升了可靠性、幻觉率和基于证据的准确性。",
  "anthropic/claude-3-haiku.description": "Claude 3 Haiku 是 Anthropic 迄今最快的模型，专为企业级长提示工作负载设计。可快速分析季度报告、合同或法律案件等大型文档，成本仅为同类模型的一半。",
  "anthropic/claude-3-opus.description": "Claude 3 Opus 是 Anthropic 最智能的模型，在处理高度复杂任务方面表现领先，能流畅应对开放式提示和新颖场景，具备类人理解能力。",
  "anthropic/claude-3.5-haiku.description": "Claude 3.5 Haiku 提升了速度、编程准确性和工具使用能力，适用于对速度和工具交互要求较高的场景。",
  "anthropic/claude-3.5-sonnet.description": "Claude 3.5 Sonnet 是 Sonnet 系列中快速高效的模型，具备更强的编程和推理能力，部分版本将逐步被 Sonnet 3.7 及后续版本取代。",
  "anthropic/claude-3.7-sonnet.description": "Claude 3.7 Sonnet 是升级版 Sonnet 模型，具备更强的推理和编程能力，适用于企业级复杂任务。",
  "anthropic/claude-haiku-4.5.description": "Claude Haiku 4.5 是 Anthropic 的高性能快速模型，在保持高准确率的同时实现极低延迟。",
  "anthropic/claude-opus-4.1.description": "Opus 4.1 是 Anthropic 的高端模型，专为编程、复杂推理和长时间任务优化。",
  "anthropic/claude-opus-4.5.description": "Claude Opus 4.5 是 Anthropic 的旗舰模型，结合顶级智能与可扩展性能，适用于复杂、高质量推理任务。",
  "anthropic/claude-opus-4.description": "Opus 4 是 Anthropic 的旗舰模型，专为复杂任务和企业应用设计。",
  "anthropic/claude-sonnet-4.5.description": "Claude Sonnet 4.5 是 Anthropic 最新的混合推理模型，专为复杂推理和编程优化。",
  "anthropic/claude-sonnet-4.description": "Claude Sonnet 4 是 Anthropic 的混合推理模型，具备思考与非思考能力的结合。",
  "ascend-tribe/pangu-pro-moe.description": "Pangu-Pro-MoE 72B-A16B 是一款稀疏大语言模型，拥有 720 亿总参数和 160 亿激活参数，基于分组专家混合（MoGE）架构。该模型在专家选择时进行分组，并限制每组激活相同数量的专家，从而实现负载均衡并提升在昇腾平台上的部署效率。",
  "aya.description": "Aya 23 是 Cohere 推出的多语言模型，支持 23 种语言，适用于多样化的应用场景。",
  "aya:35b.description": "Aya 23 是 Cohere 推出的多语言模型，支持 23 种语言，适用于多样化的应用场景。",
  "azure-DeepSeek-R1-0528.description": "由微软部署的 DeepSeek R1 已升级为 DeepSeek-R1-0528。此次更新增强了计算能力和后训练算法优化，显著提升了推理深度和推理能力，在数学、编程和通用逻辑基准测试中表现优异，接近 O3 和 Gemini 2.5 Pro 等领先模型。",
  "baichuan-m2-32b.description": "Baichuan M2 32B 是百川智能推出的 MoE 模型，具备强大的推理能力。",
  "baichuan/baichuan2-13b-chat.description": "Baichuan-13B 是百川推出的开源、可商用的 130 亿参数大语言模型，在权威中英文基准测试中取得同类模型中的最佳表现。",
  "baidu/ERNIE-4.5-300B-A47B.description": "ERNIE-4.5-300B-A47B 是百度推出的 MoE 大语言模型，拥有 3000 亿总参数和每个 token 激活 470 亿参数，兼顾强大性能与计算效率。作为 ERNIE 4.5 的核心模型，在理解、生成、推理和编程方面表现出色。采用多模态异构 MoE 预训练方法，结合文本与视觉联合训练，显著提升了指令跟随能力和世界知识。",
  "baidu/ernie-5.0-thinking-preview.description": "ERNIE 5.0 思维预览版是百度下一代原生多模态 ERNIE 模型，擅长多模态理解、指令跟随、创作、事实问答和工具调用。",
  "black-forest-labs/flux-1.1-pro.description": "FLUX 1.1 Pro 是一款速度更快、质量更高的图像生成模型，具备卓越的图像质量和提示响应能力。",
  "black-forest-labs/flux-dev.description": "FLUX Dev 是 FLUX 的开发版本，仅供非商业用途使用。",
  "black-forest-labs/flux-pro.description": "FLUX Pro 是专业级图像生成模型，输出高质量图像。",
  "black-forest-labs/flux-schnell.description": "FLUX Schnell 是一款专为速度优化的快速图像生成模型。",
  "c4ai-aya-expanse-32b.description": "Aya Expanse 是一款高性能的 320 亿参数多语言模型，结合指令微调、数据套利、偏好训练和模型融合，性能媲美单语模型，支持 23 种语言。",
  "c4ai-aya-expanse-8b.description": "Aya Expanse 是一款高性能的 80 亿参数多语言模型，结合指令微调、数据套利、偏好训练和模型融合，性能媲美单语模型，支持 23 种语言。",
  "c4ai-aya-vision-32b.description": "Aya Vision 是一款先进的多模态模型，在语言、文本和视觉基准测试中表现出色。该 320 亿参数版本专注于顶级多语言性能，支持 23 种语言。",
  "c4ai-aya-vision-8b.description": "Aya Vision 是一款先进的多模态模型，在语言、文本和视觉基准测试中表现出色。该 80 亿参数版本专注于低延迟和强大性能。",
  "charglm-3.description": "CharGLM-3 专为角色扮演和情感陪伴设计，支持超长多轮记忆和个性化对话。",
  "charglm-4.description": "CharGLM-4 专为角色扮演和情感陪伴设计，支持超长多轮记忆和个性化对话。",
  "chatgpt-4o-latest.description": "ChatGPT-4o 是一款实时更新的动态模型，结合强大的理解与生成能力，适用于客户支持、教育和技术支持等大规模应用场景。",
  "claude-2.0.description": "Claude 2 提供关键的企业级改进，包括领先的 20 万 token 上下文窗口、减少幻觉、系统提示支持，以及新测试功能：工具调用。",
  "claude-2.1.description": "Claude 2 提供关键的企业级改进，包括领先的 20 万 token 上下文窗口、减少幻觉、系统提示支持，以及新测试功能：工具调用。",
  "claude-3-5-haiku-20241022.description": "Claude 3.5 Haiku 是 Anthropic 推出的下一代最快模型。与 Claude 3 Haiku 相比，它在多项技能上有所提升，并在多个智能基准测试中超越了此前最大的模型 Claude 3 Opus。",
  "claude-3-5-haiku-latest.description": "Claude 3.5 Haiku 提供快速响应，适用于轻量级任务。",
  "claude-3-7-sonnet-20250219.description": "Claude 3.7 Sonnet 是 Anthropic 最智能的模型，也是市场上首个混合推理模型。它既能快速响应，也能进行用户可见的逐步推理。Sonnet 在编程、数据科学、视觉处理和智能体任务方面表现尤为出色。",
  "claude-3-7-sonnet-latest.description": "Claude 3.7 Sonnet 是 Anthropic 最新、最强大的模型，适用于高度复杂的任务，在性能、智能、流畅性和理解力方面表现卓越。",
  "claude-3-haiku-20240307.description": "Claude 3 Haiku 是 Anthropic 推出的最快、最紧凑的模型，专为近乎即时响应而设计，具备快速且准确的性能。",
  "claude-3-opus-20240229.description": "Claude 3 Opus 是 Anthropic 最强大的模型，适用于高度复杂的任务，在性能、智能、流畅性和理解力方面表现卓越。",
  "claude-3-sonnet-20240229.description": "Claude 3 Sonnet 在智能与速度之间取得平衡，适用于企业级工作负载，提供高效能与低成本的可靠部署。",
  "claude-haiku-4-5-20251001.description": "Claude Haiku 4.5 是 Anthropic 推出的最快、最智能的 Haiku 模型，具备闪电般的速度和增强的推理能力。",
  "claude-opus-4-1-20250805-thinking.description": "Claude Opus 4.1 Thinking 是一款高级变体，能够展示其推理过程。",
  "claude-opus-4-1-20250805.description": "Claude Opus 4.1 是 Anthropic 最新、最强大的模型，专为处理高度复杂的任务而设计，在性能、智能、流畅性和理解力方面表现卓越。",
  "claude-opus-4-20250514.description": "Claude Opus 4 是 Anthropic 最强大的模型，擅长处理高度复杂的任务，在性能、智能、流畅性和理解力方面均表现出色。",
  "claude-opus-4-5-20251101.description": "Claude Opus 4.5 是 Anthropic 的旗舰模型，结合卓越智能与可扩展性能，适用于需要最高质量响应与推理的复杂任务。",
  "claude-opus-4-6.description": "Claude Opus 4.6 是 Anthropic 最智能的模型，专为构建智能体和编程任务而优化。",
  "claude-sonnet-4-20250514-thinking.description": "Claude Sonnet 4 Thinking 可生成近乎即时的响应或可视化的逐步推理过程。",
  "claude-sonnet-4-20250514.description": "Claude Sonnet 4 能够快速响应，也能进行可视化的逐步思考过程。",
  "claude-sonnet-4-5-20250929.description": "Claude Sonnet 4.5 是 Anthropic 迄今为止最智能的模型。",
  "codegeex-4.description": "CodeGeeX-4 是一款强大的 AI 编程助手，支持多语言问答和代码补全，提升开发者效率。",
  "codegeex4-all-9b.description": "CodeGeeX4-ALL-9B 是一款多语言代码生成模型，支持代码补全与生成、代码解释器、网页搜索、函数调用和仓库级代码问答，覆盖广泛的软件开发场景。是 100 亿参数以下的顶级代码模型。",
  "codegemma.description": "CodeGemma 是一款轻量级模型，适用于多种编程任务，支持快速迭代与集成。",
  "codegemma:2b.description": "CodeGemma 是一款轻量级模型，适用于多种编程任务，支持快速迭代与集成。",
  "codellama.description": "Code Llama 是一款专注于代码生成与讨论的大语言模型，支持多种编程语言，适用于开发者工作流。",
  "codellama/CodeLlama-34b-Instruct-hf.description": "Code Llama 是一款专注于代码生成与讨论的大语言模型，支持多种编程语言，适用于开发者工作流。",
  "codellama:13b.description": "Code Llama 是一款专注于代码生成与讨论的大语言模型，支持多种编程语言，适用于开发者工作流。",
  "codellama:34b.description": "Code Llama 是一款专注于代码生成与讨论的大语言模型，支持多种编程语言，适用于开发者工作流。",
  "codellama:70b.description": "Code Llama 是一款专注于代码生成与讨论的大语言模型，支持多种编程语言，适用于开发者工作流。",
  "codeqwen.description": "CodeQwen1.5 是一款在大规模代码数据上训练的大语言模型，专为复杂编程任务设计。",
  "codestral-latest.description": "Codestral 是我们最先进的代码模型；v2（2025年1月）专为低延迟、高频任务（如 FIM、代码修复和测试生成）而设计。",
  "codestral.description": "Codestral 是 Mistral AI 推出的首个代码模型，具备强大的代码生成能力。",
  "codex-mini-latest.description": "codex-mini-latest 是为 Codex CLI 微调的 o4-mini 模型。若需直接通过 API 使用，建议从 gpt-4.1 开始。",
  "cogito-2.1:671b.description": "Cogito v2.1 671B 是一款美国开源大语言模型，可免费商用，性能媲美顶级模型，具备更高的 Token 推理效率、128k 长上下文能力以及强大的综合能力。",
  "cogview-4.description": "CogView-4 是智谱推出的首个支持中文字符生成的开源文生图模型，提升了语义理解、图像质量和中英文文本渲染能力，支持任意长度的中英文提示词，并可在指定范围内生成任意分辨率图像。",
  "cohere-command-r-plus.description": "Command R+ 是一款为企业级工作负载优化的先进 RAG 模型。",
  "cohere-command-r.description": "Command R 是一款可扩展的生成模型，专为 RAG 和工具使用场景设计，支持生产级 AI 应用。",
  "cohere/Cohere-command-r-plus.description": "Command R+ 是一款为企业级工作负载优化的先进 RAG 模型。",
  "cohere/Cohere-command-r.description": "Command R 是一款可扩展的生成模型，专为 RAG 和工具使用场景设计，支持生产级 AI 应用。",
  "cohere/command-a.description": "Command A 是 Cohere 迄今为止最强大的模型，擅长工具使用、智能体、RAG 和多语言场景。支持 256K 上下文长度，仅需两块 GPU 即可运行，吞吐量比 Command R+ 08-2024 提高 150%。",
  "cohere/command-r-plus.description": "Command R+ 是 Cohere 最新的大语言模型，针对聊天和长上下文任务进行了优化，旨在实现卓越性能，助力企业从原型走向生产部署。",
  "cohere/command-r.description": "Command R 针对聊天和长上下文任务进行了优化，定位为“可扩展”模型，在高性能与准确性之间实现平衡，助力企业从原型走向生产部署。",
  "cohere/embed-v4.0.description": "一个可将文本、图像或混合内容分类或转换为嵌入向量的模型。",
  "comfyui/flux-dev.description": "FLUX.1 Dev 是一款高质量的文生图模型（10–50 步），非常适合高端创意和艺术输出。",
  "comfyui/flux-kontext-dev.description": "FLUX.1 Kontext-dev 是一款图像编辑模型，支持基于文本的局部编辑和风格迁移。",
  "comfyui/flux-krea-dev.description": "FLUX.1 Krea-dev 是与 Krea 联合开发的安全增强型文生图模型，内置安全过滤机制。",
  "comfyui/flux-schnell.description": "FLUX.1 Schnell 是一款超高速文生图模型，可在 1-4 步内生成高质量图像，适用于实时使用和快速原型开发。",
  "comfyui/stable-diffusion-15.description": "Stable Diffusion 1.5 是一款经典的 512x512 文生图模型，适合快速原型开发和创意实验。",
  "comfyui/stable-diffusion-35-inclclip.description": "Stable Diffusion 3.5 内置 CLIP/T5 编码器，无需外部编码器文件，适用于如 sd3.5_medium_incl_clips 等资源占用较低的模型。",
  "comfyui/stable-diffusion-35.description": "Stable Diffusion 3.5 是下一代文生图模型，提供 Large 和 Medium 两个版本。需使用外部 CLIP 编码器文件，图像质量和提示词响应能力出色。",
  "comfyui/stable-diffusion-custom-refiner.description": "自定义 SDXL 图生图模型。模型文件名应为 custom_sd_lobe.safetensors；如有 VAE，请使用 custom_sd_vae_lobe.safetensors。将模型文件放入 Comfy 指定文件夹中。",
  "comfyui/stable-diffusion-custom.description": "自定义 SD 文生图模型。模型文件名应为 custom_sd_lobe.safetensors；如有 VAE，请使用 custom_sd_vae_lobe.safetensors。将模型文件放入 Comfy 指定文件夹中。",
  "comfyui/stable-diffusion-refiner.description": "SDXL 图生图模型，可对输入图像进行高质量转换，支持风格迁移、图像修复和创意变体生成。",
  "comfyui/stable-diffusion-xl.description": "SDXL 是一款支持 1024x1024 高分辨率生成的文生图模型，图像质量和细节表现更佳。",
  "command-a-03-2025.description": "Command A 是我们迄今为止最强大的模型，擅长工具使用、智能体、RAG 和多语言场景。支持 256K 上下文窗口，仅需两块 GPU 即可运行，吞吐量比 Command R+ 08-2024 提高 150%。",
  "command-light-nightly.description": "为缩短主要版本之间的发布间隔，我们提供 Command 系列的每晚构建版本。command-light-nightly 是 command-light 系列中最新、最具实验性（可能不稳定）的版本，定期更新，适合测试用途，不建议用于生产环境。",
  "command-light.description": "Command 的轻量快速版本，几乎同样强大但响应更快。",
  "command-nightly.description": "为缩短主要版本之间的发布间隔，我们提供 Command 系列的每晚构建版本。command-nightly 是 Command 系列中最新、最具实验性（可能不稳定）的版本，定期更新，适合测试用途，不建议用于生产环境。",
  "command-r-03-2024.description": "Command R 是一款遵循指令的聊天模型，质量更高、可靠性更强、上下文窗口更长，支持代码生成、RAG、工具使用和智能体等复杂工作流。",
  "command-r-08-2024.description": "command-r-08-2024 是 2024 年 8 月发布的 Command R 模型更新版本。",
  "command-r-plus-04-2024.description": "command-r-plus 是 command-r-plus-04-2024 的别名，API 中使用 command-r-plus 即指向该模型。",
  "command-r-plus-08-2024.description": "Command R+ 是一款遵循指令的聊天模型，质量更高、可靠性更强、上下文窗口更长，特别适用于复杂的 RAG 工作流和多步骤工具使用。",
  "command-r-plus.description": "Command R+ 是一款高性能大语言模型，专为真实企业场景和复杂应用设计。",
  "command-r.description": "Command R 是一款针对聊天和长上下文任务优化的大语言模型，适用于动态交互和知识管理。",
  "command-r7b-12-2024.description": "command-r7b-12-2024 是 2024 年 12 月发布的小型高效更新版本，擅长 RAG、工具使用和需要复杂多步骤推理的智能体任务。",
  "command.description": "一款遵循指令的聊天模型，在语言任务中提供更高质量和可靠性，拥有比基础生成模型更长的上下文窗口。",
  "computer-use-preview.description": "computer-use-preview 是为“计算机使用工具”专门训练的模型，能够理解并执行与计算机相关的任务。",
  "dall-e-2.description": "第二代 DALL·E 模型，图像生成更真实、准确，分辨率是第一代的 4 倍。",
  "dall-e-3.description": "最新的 DALL·E 模型，于 2023 年 11 月发布，图像生成更真实、准确，细节表现更强。",
  "databricks/dbrx-instruct.description": "DBRX Instruct 提供跨行业高度可靠的指令处理能力。",
  "deepseek-ai/DeepSeek-OCR.description": "DeepSeek-OCR 是 DeepSeek AI 推出的视觉语言模型，专注于光学字符识别（OCR）和“上下文光学压缩”。该模型探索从图像中压缩上下文信息，能够高效处理文档并将其转换为结构化文本（如 Markdown）。它在图像文字识别方面表现精准，适用于文档数字化、文本提取和结构化处理。",
  "deepseek-ai/DeepSeek-R1-0528-Qwen3-8B.description": "DeepSeek-R1-0528-Qwen3-8B 将 DeepSeek-R1-0528 的链式思维能力蒸馏至 Qwen3 8B Base 模型中。在开源模型中达到 SOTA 水平，在 AIME 2024 上超越 Qwen3 8B 10%，并与 Qwen3-235B-thinking 表现相当。擅长数学推理、编程和通用逻辑任务，采用 Qwen3-8B 架构，并使用 DeepSeek-R1-0528 的分词器。",
  "deepseek-ai/DeepSeek-R1-0528.description": "DeepSeek R1 利用更强的计算资源和后训练算法优化，显著增强推理能力。在数学、编程和通用逻辑等基准测试中表现优异，接近 o3 和 Gemini 2.5 Pro 等领先模型。",
  "deepseek-ai/DeepSeek-R1-Distill-Llama-70B.description": "DeepSeek-R1 蒸馏模型通过强化学习和冷启动数据提升推理能力，刷新开源多任务模型基准。",
  "deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B.description": "DeepSeek-R1 蒸馏模型通过强化学习和冷启动数据提升推理能力，刷新开源多任务模型基准。",
  "deepseek-ai/DeepSeek-R1-Distill-Qwen-14B.description": "DeepSeek-R1 蒸馏模型通过强化学习和冷启动数据提升推理能力，刷新开源多任务模型基准。",
  "deepseek-ai/DeepSeek-R1-Distill-Qwen-32B.description": "DeepSeek-R1-Distill-Qwen-32B 由 Qwen2.5-32B 蒸馏而来，并在 80 万条精挑细选的 DeepSeek-R1 样本上微调。擅长数学、编程和推理任务，在 AIME 2024、MATH-500（94.3% 准确率）和 GPQA Diamond 上表现出色。",
  "deepseek-ai/DeepSeek-R1-Distill-Qwen-7B.description": "DeepSeek-R1-Distill-Qwen-7B 由 Qwen2.5-Math-7B 蒸馏而来，并在 80 万条 DeepSeek-R1 精选样本上微调。在 MATH-500 上达到 92.8%、AIME 2024 达到 55.5%、CodeForces 评分为 1189（7B 模型）。",
  "deepseek-ai/DeepSeek-R1.description": "DeepSeek-R1 通过强化学习和冷启动数据提升推理能力，刷新开源多任务模型基准，超越 OpenAI-o1-mini。",
  "deepseek-ai/DeepSeek-V2.5.description": "DeepSeek-V2.5 升级了 DeepSeek-V2-Chat 和 DeepSeek-Coder-V2-Instruct，融合通用与编程能力。提升了写作和指令遵循能力，实现更好的偏好对齐，在 AlpacaEval 2.0、ArenaHard、AlignBench 和 MT-Bench 上取得显著进步。",
  "deepseek-ai/DeepSeek-V3.1-Terminus.description": "DeepSeek-V3.1-Terminus 是 V3.1 的更新版本，定位为混合智能体大模型。修复用户反馈问题，提升稳定性、语言一致性，减少中英混杂和异常字符。集成思考与非思考模式，支持通过聊天模板灵活切换。Code Agent 和 Search Agent 性能也得到提升，工具使用更可靠，多步任务执行更高效。",
  "deepseek-ai/DeepSeek-V3.1.description": "DeepSeek V3.1 采用混合推理架构，支持思考与非思考模式。",
  "deepseek-ai/DeepSeek-V3.2-Exp.description": "DeepSeek-V3.2-Exp 是 V3.2 的实验版本，连接下一代架构。在 V3.1-Terminus 基础上引入 DeepSeek 稀疏注意力（DSA），提升长上下文训练与推理效率，优化工具使用、长文档理解和多步推理。适合探索大上下文预算下的高效推理。",
  "deepseek-ai/DeepSeek-V3.description": "DeepSeek-V3 是一个拥有 671B 参数的 MoE 模型，采用 MLA 和 DeepSeekMoE 架构，具备无损负载均衡，实现高效训练与推理。在 14.8T 高质量数据上预训练，并结合 SFT 与 RL，性能超越其他开源模型，接近领先闭源模型。",
  "deepseek-ai/deepseek-llm-67b-chat.description": "DeepSeek LLM Chat（67B）是一款创新模型，具备深度语言理解与交互能力。",
  "deepseek-ai/deepseek-v3.1-terminus.description": "DeepSeek V3.1 是下一代推理模型，具备更强的复杂推理与链式思维能力，适用于深度分析任务。",
  "deepseek-ai/deepseek-v3.1.description": "DeepSeek V3.1 是下一代推理模型，具备更强的复杂推理与链式思维能力，适用于深度分析任务。",
  "deepseek-ai/deepseek-vl2.description": "DeepSeek-VL2 是基于 DeepSeekMoE-27B 的 MoE 视觉语言模型，采用稀疏激活，仅使用 4.5B 激活参数即可实现强大性能。擅长视觉问答、OCR、文档/表格/图表理解和视觉定位。",
  "deepseek-chat.description": "一款结合通用能力与编程能力的开源新模型。它保留了聊天模型的对话能力和编程模型的强大编程能力，并在偏好对齐方面有所提升。DeepSeek-V2.5 还改进了写作和指令执行能力。",
  "deepseek-coder-33B-instruct.description": "DeepSeek Coder 33B 是一款代码语言模型，训练于 2T 数据（87% 代码，13% 中英文文本）。支持 16K 上下文窗口与中间填充任务，提供项目级代码补全与片段填充。",
  "deepseek-coder-v2.description": "DeepSeek Coder V2 是一款开源 MoE 编程模型，在编程任务中表现强劲，可媲美 GPT-4 Turbo。",
  "deepseek-coder-v2:236b.description": "DeepSeek Coder V2 是一款开源 MoE 编程模型，在编程任务中表现强劲，可媲美 GPT-4 Turbo。",
  "deepseek-ocr.description": "DeepSeek-OCR 是 DeepSeek AI 推出的视觉语言模型，专注于 OCR 和“上下文光学压缩”。该模型探索从图像中压缩上下文信息，能够高效处理文档并将其转换为结构化文本格式（如 Markdown）。它在图像文字识别方面表现精准，适用于文档数字化、文本提取和结构化处理。",
  "deepseek-r1-0528.description": "2025 年 5 月 28 日发布的 685B 全量模型。DeepSeek-R1 在后训练阶段使用大规模强化学习，显著提升推理能力，仅需极少标注数据即可在数学、编程和自然语言推理方面表现出色。",
  "deepseek-r1-250528.description": "DeepSeek R1 250528 是 DeepSeek-R1 的完整推理模型，专为高难度数学与逻辑任务设计。",
  "deepseek-r1-70b-fast-online.description": "DeepSeek R1 70B 快速版，支持实时网页搜索，在保持性能的同时提供更快响应。",
  "deepseek-r1-70b-online.description": "DeepSeek R1 70B 标准版，支持实时网页搜索，适用于最新聊天与文本任务。",
  "deepseek-r1-distill-llama-70b.description": "DeepSeek R1 Distill Llama 70B 将 R1 推理能力与 Llama 生态系统结合。",
  "deepseek-r1-distill-llama-8b.description": "DeepSeek-R1-Distill-Llama-8B 由 Llama-3.1-8B 蒸馏而来，使用 DeepSeek R1 输出进行训练。",
  "deepseek-r1-distill-llama.description": "deepseek-r1-distill-llama 是在 Llama 上基于 DeepSeek-R1 蒸馏而成。",
  "deepseek-r1-distill-qianfan-70b.description": "DeepSeek R1 Distill Qianfan 70B 是基于 Qianfan-70B 的 R1 蒸馏模型，具备强大价值。",
  "deepseek-r1-distill-qianfan-8b.description": "DeepSeek R1 Distill Qianfan 8B 是基于 Qianfan-8B 的 R1 蒸馏模型，适用于中小型应用。",
  "deepseek-r1-distill-qianfan-llama-70b.description": "DeepSeek R1 Distill Qianfan Llama 70B 是基于 Llama-70B 的 R1 蒸馏模型。",
  "deepseek-r1-distill-qwen-1.5b.description": "DeepSeek R1 Distill Qwen 1.5B 是一款超轻量蒸馏模型，适用于极低资源环境。",
  "deepseek-r1-distill-qwen-14b.description": "DeepSeek R1 Distill Qwen 14B 是一款中型蒸馏模型，适用于多场景部署。",
  "deepseek-r1-distill-qwen-32b.description": "DeepSeek R1 Distill Qwen 32B 是基于 Qwen-32B 的 R1 蒸馏模型，在性能与成本之间取得平衡。",
  "deepseek-r1-distill-qwen-7b.description": "DeepSeek R1 Distill Qwen 7B 是一款轻量蒸馏模型，适用于边缘计算与企业私有部署环境。",
  "deepseek-r1-distill-qwen.description": "deepseek-r1-distill-qwen 是在 Qwen 上基于 DeepSeek-R1 蒸馏而成。",
  "deepseek-r1-fast-online.description": "DeepSeek R1 快速全量版本，支持实时网页搜索，结合 671B 规模能力与更快响应。",
  "deepseek-r1-online.description": "DeepSeek R1 全量版本，具备 671B 参数与实时网页搜索，提供更强理解与生成能力。",
  "deepseek-r1.description": "DeepSeek-R1 在强化学习前使用冷启动数据，在数学、编程和推理任务中表现可与 OpenAI-o1 相媲美。",
  "deepseek-reasoner.description": "DeepSeek V3.2 推理模式在给出最终答案前会输出思维链，以提升准确性。",
  "deepseek-v2.description": "DeepSeek V2 是一款高效的 MoE 模型，适用于成本敏感型处理任务。",
  "deepseek-v2:236b.description": "DeepSeek V2 236B 是 DeepSeek 推出的代码专用模型，具备强大代码生成能力。",
  "deepseek-v3-0324.description": "DeepSeek-V3-0324 是一款拥有 671B 参数的 MoE 模型，在编程与技术能力、上下文理解和长文本处理方面表现突出。",
  "deepseek-v3.1-terminus.description": "DeepSeek-V3.1-Terminus 是 DeepSeek 推出的终端优化大模型，专为终端设备定制。",
  "deepseek-v3.1-think-250821.description": "DeepSeek V3.1 Think 250821 是对应 Terminus 版本的深度思考模型，专为高性能推理任务打造。",
  "deepseek-v3.1.description": "DeepSeek-V3.1 是 DeepSeek 推出的新一代混合推理模型，支持思考与非思考模式，推理效率高于 DeepSeek-R1-0528。后训练优化显著提升智能体工具使用与任务执行能力，支持 128k 上下文窗口与最多 64k 输出。",
  "deepseek-v3.1:671b.description": "DeepSeek V3.1 是下一代推理模型，具备更强的复杂推理与链式思维能力，适用于需要深度分析的任务。",
  "deepseek-v3.2-exp.description": "deepseek-v3.2-exp 引入稀疏注意力机制，在处理长文本时提升训练与推理效率，价格低于 deepseek-v3.1。",
  "deepseek-v3.2-think.description": "DeepSeek V3.2 Think 是一款完整的深度思考模型，具备更强的长链推理能力。",
  "deepseek-v3.2.description": "DeepSeek-V3.2 是 DeepSeek 推出的首个融合推理能力的混合模型，将思维过程融入工具使用。该模型采用高效架构以节省计算资源，结合大规模强化学习提升能力，并利用大规模合成任务数据增强泛化能力。三者结合使其在性能上可媲美 GPT-5-High，同时显著缩短输出长度，降低计算开销并减少用户等待时间。",
  "deepseek-v3.description": "DeepSeek-V3 是一款强大的 MoE 模型，总参数量为 671B，每个 token 激活参数为 37B。",
  "deepseek-vl2-small.description": "DeepSeek VL2 Small 是一款轻量级多模态模型，适用于资源受限和高并发场景。",
  "deepseek-vl2.description": "DeepSeek VL2 是一款多模态模型，专注于图文理解和细粒度视觉问答。",
  "deepseek/deepseek-chat-v3-0324.description": "DeepSeek V3 是一款拥有 685B 参数的 MoE 模型，是 DeepSeek 旗舰聊天系列的最新版本。\n\n该模型基于 [DeepSeek V3](/deepseek/deepseek-chat-v3) 构建，在多项任务中表现出色。",
  "deepseek/deepseek-chat-v3-0324:free.description": "DeepSeek V3 是一款拥有 685B 参数的 MoE 模型，是 DeepSeek 旗舰聊天系列的最新版本。\n\n该模型基于 [DeepSeek V3](/deepseek/deepseek-chat-v3) 构建，在多项任务中表现出色。",
  "deepseek/deepseek-chat-v3.1.description": "DeepSeek-V3.1 是 DeepSeek 推出的长上下文混合推理模型，支持思考/非思考模式切换及工具集成。",
  "deepseek/deepseek-chat.description": "DeepSeek-V3 是 DeepSeek 面向复杂任务和工具集成的高性能混合推理模型。",
  "deepseek/deepseek-math-v2.description": "DeepSeek Math V2 是一款在数学推理能力上取得重大突破的模型。其核心创新在于“自我验证”训练机制，并在多个顶级数学竞赛中达到了金牌水平。",
  "deepseek/deepseek-r1-0528.description": "DeepSeek R1 0528 是一款更新版本，专注于开放可用性和更深层次的推理能力。",
  "deepseek/deepseek-r1-0528:free.description": "DeepSeek-R1 在仅需极少标注数据的情况下显著提升推理能力，并在最终答案前输出思维链以提高准确性。",
  "deepseek/deepseek-r1-distill-llama-70b.description": "DeepSeek R1 Distill Llama 70B 是基于 Llama 3.3 70B 蒸馏而成的大语言模型，使用 DeepSeek R1 输出进行微调，在性能上可媲美大型前沿模型。",
  "deepseek/deepseek-r1-distill-llama-8b.description": "DeepSeek R1 Distill Llama 8B 是基于 Llama-3.1-8B-Instruct 蒸馏而成的大语言模型，使用 DeepSeek R1 输出进行训练。",
  "deepseek/deepseek-r1-distill-qwen-14b.description": "DeepSeek R1 Distill Qwen 14B 是基于 Qwen 2.5 14B 蒸馏而成的大语言模型，使用 DeepSeek R1 输出进行训练。在多个基准测试中超越 OpenAI o1-mini，在密集模型中达到 SOTA 水平。基准亮点：\nAIME 2024 pass@1: 69.7\nMATH-500 pass@1: 93.9\nCodeForces Rating: 1481\n基于 DeepSeek R1 输出的微调实现了与更大前沿模型的竞争性能。",
  "deepseek/deepseek-r1-distill-qwen-32b.description": "DeepSeek R1 Distill Qwen 32B 是基于 Qwen 2.5 32B 蒸馏而成的大语言模型，使用 DeepSeek R1 输出进行训练。在多个基准测试中超越 OpenAI o1-mini，在密集模型中达到 SOTA 水平。基准亮点：\nAIME 2024 pass@1: 72.6\nMATH-500 pass@1: 94.3\nCodeForces Rating: 1691\n基于 DeepSeek R1 输出的微调实现了与更大前沿模型的竞争性能。",
  "deepseek/deepseek-r1.description": "DeepSeek R1 已更新为 DeepSeek-R1-0528。通过更强的计算资源和后训练算法优化，显著提升了推理深度与能力。在数学、编程和通用逻辑基准测试中表现优异，接近 o3 和 Gemini 2.5 Pro 等领先模型。",
  "deepseek/deepseek-r1/community.description": "DeepSeek R1 是 DeepSeek 团队最新开源模型，在数学、编程和推理任务中表现出色，性能可与 OpenAI o1 相媲美。",
  "deepseek/deepseek-r1:free.description": "DeepSeek-R1 在仅需极少标注数据的情况下显著提升推理能力，并在最终答案前输出思维链以提高准确性。",
  "deepseek/deepseek-reasoner.description": "DeepSeek-V3 Thinking（reasoner）是 DeepSeek 的实验性推理模型，适用于高复杂度推理任务。",
  "deepseek/deepseek-v3.1-base.description": "DeepSeek V3.1 Base 是 DeepSeek V3 模型的改进版本。",
  "deepseek/deepseek-v3.description": "一款快速的通用大语言模型，具备增强的推理能力。",
  "deepseek/deepseek-v3/community.description": "DeepSeek-V3 在推理速度方面相较前代实现重大突破，在开源模型中排名第一，并可媲美最先进的闭源模型。DeepSeek-V3 采用了在 DeepSeek-V2 中验证的多头潜在注意力（MLA）和 DeepSeekMoE 架构，并引入了无损辅助策略以实现负载均衡，以及多 token 预测训练目标以增强性能。",
  "deepseek_r1.description": "DeepSeek-R1 是一款基于强化学习的推理模型，解决了重复性和可读性问题。在强化学习前，使用冷启动数据进一步提升推理能力。在数学、编程和推理任务中表现与 OpenAI-o1 相当，训练过程精心设计以提升整体效果。",
  "deepseek_r1_distill_llama_70b.description": "DeepSeek-R1-Distill-Llama-70B 是基于 Llama-3.3-70B-Instruct 蒸馏而成。作为 DeepSeek-R1 系列的一部分，使用 DeepSeek-R1 生成的样本进行微调，在数学、编程和推理方面表现出色。",
  "deepseek_r1_distill_qwen_14b.description": "DeepSeek-R1-Distill-Qwen-14B 是基于 Qwen2.5-14B 蒸馏而成，并使用 DeepSeek-R1 生成的 80 万高质量样本进行微调，具备强大的推理能力。",
  "deepseek_r1_distill_qwen_32b.description": "DeepSeek-R1-Distill-Qwen-32B 是基于 Qwen2.5-32B 蒸馏而成，并使用 DeepSeek-R1 生成的 80 万高质量样本进行微调，在数学、编程和推理方面表现卓越。",
  "devstral-2:123b.description": "Devstral 2 123B 擅长使用工具探索代码库、编辑多个文件，并支持软件工程代理。",
  "doubao-1.5-lite-32k.description": "Doubao-1.5-lite 是一款全新轻量级模型，响应速度极快，兼具卓越质量与低延迟。",
  "doubao-1.5-pro-256k.description": "Doubao-1.5-pro-256k 是 Doubao-1.5-Pro 的全面升级版，整体性能提升 10%。支持 256k 上下文窗口和最多 12k 输出 token，性能更强、窗口更大，适用于更广泛的场景。",
  "doubao-1.5-pro-32k.description": "Doubao-1.5-pro 是新一代旗舰模型，全面升级，在知识、编程和推理方面表现出色。",
  "doubao-1.5-thinking-pro-m.description": "Doubao-1.5 是一款全新的深度推理模型（m 版本原生支持多模态深度推理），在数学、编程、科学推理以及创意写作等通用任务中表现卓越。其在 AIME 2024、Codeforces 和 GPQA 等基准测试中达到或接近顶级水平。支持 128k 上下文窗口和 16k 输出。",
  "doubao-1.5-thinking-pro.description": "Doubao-1.5 是一款全新的深度推理模型，在数学、编程、科学推理以及创意写作等通用任务中表现卓越。其在 AIME 2024、Codeforces 和 GPQA 等基准测试中达到或接近顶级水平。支持 128k 上下文窗口和 16k 输出。",
  "doubao-1.5-thinking-vision-pro.description": "全新视觉深度推理模型，具备更强的多模态理解与推理能力，在 59 个公开基准中有 37 项达到 SOTA 水平。",
  "doubao-1.5-ui-tars.description": "Doubao-1.5-UI-TARS 是一款原生面向图形界面的代理模型，具备类人感知、推理与操作能力，可与界面无缝交互。",
  "doubao-1.5-vision-lite.description": "Doubao-1.5-vision-lite 是升级版多模态模型，支持任意分辨率和极端长宽比图像，提升视觉推理、文档识别、细节理解与指令遵循能力。支持 128k 上下文窗口和最多 16k 输出 token。",
  "doubao-1.5-vision-pro-32k.description": "Doubao-1.5-vision-pro 是升级版多模态模型，支持任意分辨率和极端长宽比图像，提升视觉推理、文档识别、细节理解与指令遵循能力。",
  "doubao-1.5-vision-pro.description": "Doubao-1.5-vision-pro 是升级版多模态模型，支持任意分辨率和极端长宽比图像，提升视觉推理、文档识别、细节理解与指令遵循能力。",
  "doubao-lite-128k.description": "超快响应，性价比更高，适用于多种场景，支持推理与微调，具备 128k 上下文窗口。",
  "doubao-lite-32k.description": "超快响应，性价比更高，适用于多种场景，支持推理与微调，具备 32k 上下文窗口。",
  "doubao-lite-4k.description": "超快响应，性价比更高，适用于多种场景，支持推理与微调，具备 4k 上下文窗口。",
  "doubao-pro-256k.description": "性能最强的旗舰模型，适用于复杂任务，在参考问答、摘要、创作、文本分类和角色扮演等方面表现优异。支持推理与微调，具备 256k 上下文窗口。",
  "doubao-pro-32k.description": "性能最强的旗舰模型，适用于复杂任务，在参考问答、摘要、创作、文本分类和角色扮演等方面表现优异。支持推理与微调，具备 32k 上下文窗口。",
  "doubao-seed-1.6-flash.description": "Doubao-Seed-1.6-flash 是一款超快多模态深度推理模型，TPOT 低至 10ms，支持文本与图像输入，在文本理解上超越前代 lite 模型，在视觉方面媲美主流 pro 模型。支持 256k 上下文窗口和最多 16k 输出 token。",
  "doubao-seed-1.6-lite.description": "Doubao-Seed-1.6-lite 是一款全新多模态深度推理模型，支持可调推理强度（最小、低、中、高），性价比更高，是通用任务的优选，支持最长 256k 上下文窗口。",
  "doubao-seed-1.6-thinking.description": "Doubao-Seed-1.6-thinking 在推理能力上显著增强，相较 Doubao-1.5-thinking-pro 在编程、数学和逻辑推理方面进一步提升，并新增视觉理解能力。支持 256k 上下文窗口和最多 16k 输出 token。",
  "doubao-seed-1.6-vision.description": "Doubao-Seed-1.6-vision 是一款视觉深度推理模型，具备更强的多模态理解与推理能力，适用于教育、图像审核、安检和 AI 搜索问答等场景。支持 256k 上下文窗口和最多 64k 输出 token。",
  "doubao-seed-1.6.description": "Doubao-Seed-1.6 是一款全新多模态深度推理模型，支持自动、思考与非思考模式。在非思考模式下，其性能显著优于 Doubao-1.5-pro/250115。支持 256k 上下文窗口和最多 16k 输出 token。",
  "doubao-seed-1.8.description": "豆包 Seed-1.8 拥有更强的多模态理解与智能体能力，支持文本/图像/视频输入与上下文缓存，在复杂任务中表现出色。",
  "doubao-seed-code.description": "Doubao-Seed-Code 针对代理式编程深度优化，支持多模态输入（文本/图像/视频）和 256k 上下文窗口，兼容 Anthropic API，适用于编程、视觉理解与代理工作流。",
  "doubao-seededit-3-0-i2i-250628.description": "字节跳动 Seed 推出的 Doubao 图像模型，支持文本与图像输入，具备高度可控的高质量图像生成能力。支持文本引导的图像编辑，输出尺寸长边在 512 至 1536 之间。",
  "doubao-seedream-3-0-t2i-250415.description": "Seedream 3.0 是字节跳动 Seed 推出的图像生成模型，支持文本与图像输入，具备高度可控的高质量图像生成能力。可根据文本提示生成图像。",
  "doubao-seedream-4-0-250828.description": "Seedream 4.0 是字节跳动 Seed 推出的图像生成模型，支持文本与图像输入，具备高度可控的高质量图像生成能力。可根据文本提示生成图像。",
  "doubao-vision-lite-32k.description": "Doubao-vision 是 Doubao 推出的多模态模型，具备强大的图像理解与推理能力，并能精准执行指令。在图文提取与基于图像的推理任务中表现优异，支持更复杂、更广泛的视觉问答场景。",
  "doubao-vision-pro-32k.description": "Doubao-vision 是 Doubao 推出的多模态模型，具备强大的图像理解与推理能力，并能精准执行指令。在图文提取与基于图像的推理任务中表现优异，支持更复杂、更广泛的视觉问答场景。",
  "emohaa.description": "Emohaa 是一款心理健康模型，具备专业咨询能力，帮助用户理解情绪问题。",
  "ernie-4.5-0.3b.description": "ERNIE 4.5 0.3B 是一款开源轻量级模型，适用于本地和定制化部署。",
  "ernie-4.5-21b-a3b.description": "ERNIE 4.5 21B A3B 是一款开源大参数模型，具备更强的理解与生成能力。",
  "ernie-4.5-300b-a47b.description": "ERNIE 4.5 300B A47B 是百度 ERNIE 的超大规模 MoE 模型，推理能力卓越。",
  "ernie-4.5-8k-preview.description": "ERNIE 4.5 8K Preview 是一款用于评估 ERNIE 4.5 的 8K 上下文预览模型。",
  "ernie-4.5-turbo-128k-preview.description": "ERNIE 4.5 Turbo 128K 预览版，具备发布级能力，适用于集成与灰度测试。",
  "ernie-4.5-turbo-128k.description": "ERNIE 4.5 Turbo 128K 是一款高性能通用模型，支持搜索增强与工具调用，适用于问答、编程与代理场景。",
  "ernie-4.5-turbo-32k.description": "ERNIE 4.5 Turbo 32K 是一款中等长度上下文版本，适用于问答、知识库检索与多轮对话。",
  "ernie-4.5-turbo-latest.description": "最新 ERNIE 4.5 Turbo，整体性能优化，适合作为主力生产模型。",
  "ernie-4.5-turbo-vl-32k-preview.description": "ERNIE 4.5 Turbo VL 32K Preview 是一款 32K 多模态预览模型，用于评估长上下文视觉能力。",
  "ernie-4.5-turbo-vl-32k.description": "ERNIE 4.5 Turbo VL 32K 是一款中长上下文多模态模型，适用于长文档与图像联合理解。",
  "ernie-4.5-turbo-vl-latest.description": "ERNIE 4.5 Turbo VL 最新版，图文理解与推理能力进一步提升。",
  "ernie-4.5-turbo-vl-preview.description": "ERNIE 4.5 Turbo VL Preview 是一款多模态预览模型，适用于图文理解与生成，支持视觉问答与内容理解。",
  "ernie-4.5-turbo-vl.description": "ERNIE 4.5 Turbo VL 是一款成熟的多模态模型，适用于生产级图文理解与识别。",
  "ernie-4.5-vl-28b-a3b.description": "ERNIE 4.5 VL 28B A3B 是一款开源多模态模型，支持图文理解与推理。",
  "ernie-5.0-thinking-latest.description": "文心 5.0 Thinking 是一款原生全模态旗舰模型，统一建模文本、图像、音频与视频，在复杂问答、创作与智能体场景中实现全面能力升级。",
  "ernie-5.0-thinking-preview.description": "文心 5.0 Thinking Preview 是一款原生全模态旗舰模型，统一建模文本、图像、音频与视频，在复杂问答、创作与智能体场景中实现全面能力升级。",
  "ernie-char-8k.description": "ERNIE Character 8K 是一款角色对话模型，适用于 IP 角色构建与长期陪伴聊天。",
  "ernie-char-fiction-8k-preview.description": "ERNIE Character Fiction 8K 预览版是一款用于角色与情节创作的模型预览，适用于功能评估与测试。",
  "ernie-char-fiction-8k.description": "ERNIE Character Fiction 8K 是一款面向小说与情节创作的角色模型，适合长篇故事生成。",
  "ernie-irag-edit.description": "ERNIE iRAG Edit 是一款图像编辑模型，支持擦除、重绘与变体生成。",
  "ernie-lite-pro-128k.description": "ERNIE Lite Pro 128K 是一款高性能轻量模型，适用于对延迟与成本敏感的场景。",
  "ernie-novel-8k.description": "ERNIE Novel 8K 专为长篇小说与 IP 剧情创作打造，支持多角色叙事。",
  "ernie-speed-pro-128k.description": "ERNIE Speed Pro 128K 是一款高并发、高价值模型，适用于大规模在线服务与企业应用。",
  "ernie-x1-turbo-32k.description": "ERNIE X1 Turbo 32K 是一款快速思考模型，具备 32K 上下文能力，适合复杂推理与多轮对话。",
  "ernie-x1.1-preview.description": "ERNIE X1.1 Preview 是一款用于评估与测试的思考模型预览版。",
  "fal-ai/bytedance/seedream/v4.description": "Seedream 4.0 是字节跳动 Seed 团队推出的图像生成模型，支持文本和图像输入，具备高度可控的高质量图像生成能力，可根据文本提示生成图像。",
  "fal-ai/flux-kontext/dev.description": "FLUX.1 模型专注于图像编辑，支持文本与图像输入。",
  "fal-ai/flux-pro/kontext.description": "FLUX.1 Kontext [pro] 接受文本与参考图像输入，支持局部精准编辑与复杂全局场景变换。",
  "fal-ai/flux/krea.description": "Flux Krea [dev] 是一款图像生成模型，偏好更真实自然的美学风格。",
  "fal-ai/flux/schnell.description": "FLUX.1 [schnell] 是一款拥有 120 亿参数的图像生成模型，专为快速高质量输出而设计。",
  "fal-ai/hunyuan-image/v3.description": "一款强大的原生多模态图像生成模型。",
  "fal-ai/imagen4/preview.description": "来自 Google 的高质量图像生成模型。",
  "fal-ai/nano-banana.description": "Nano Banana 是 Google 最新、最快、最高效的原生多模态模型，支持通过对话生成与编辑图像。",
  "fal-ai/qwen-image-edit.description": "Qwen 团队推出的专业图像编辑模型，支持语义和外观编辑，能够精确编辑中英文文本，并实现风格迁移、物体旋转等高质量编辑效果。",
  "fal-ai/qwen-image.description": "Qwen 团队推出的强大图像生成模型，具备出色的中文文本渲染能力和多样化的视觉风格。",
  "flux-1-schnell.description": "来自 Black Forest Labs 的 120 亿参数文本转图像模型，采用潜在对抗扩散蒸馏技术，可在 1-4 步内生成高质量图像。性能媲美闭源模型，采用 Apache-2.0 许可，适用于个人、研究与商业用途。",
  "flux-dev.description": "FLUX.1 [dev] 是一款开源权重蒸馏模型，仅限非商业用途。保持接近专业图像质量与指令遵循能力，同时运行更高效，资源利用优于同等规模标准模型。",
  "flux-kontext-max.description": "最先进的上下文图像生成与编辑模型，结合文本与图像输入，实现精准一致的结果。",
  "flux-kontext-pro.description": "最先进的上下文图像生成与编辑模型，结合文本与图像输入，实现精准一致的结果。",
  "flux-merged.description": "FLUX.1-merged 融合了“DEV”版本的深度特征与“Schnell”版本的高速优势，拓展性能边界，拓宽应用场景。",
  "flux-pro-1.1-ultra.description": "超高分辨率图像生成，支持 4MP 输出，10 秒内生成清晰图像。",
  "flux-pro-1.1.description": "升级版专业图像生成模型，图像质量卓越，提示词遵循精准。",
  "flux-pro.description": "顶级商业图像生成模型，图像质量无与伦比，输出多样丰富。",
  "flux-schnell.description": "FLUX.1 [schnell] 是最先进的开源少步图像生成模型，超越同类竞品，甚至优于 Midjourney v6.0 与 DALL·E 3（高清版）等强大非蒸馏模型。精调保留预训练多样性，显著提升视觉质量、指令遵循、尺寸/比例变化、字体处理与输出多样性。",
  "flux.1-schnell.description": "FLUX.1-schnell 是一款高性能图像生成模型，支持快速多风格输出。",
  "gemini-1.0-pro-001.description": "Gemini 1.0 Pro 001（调优版）为复杂任务提供稳定、可调性能。",
  "gemini-1.0-pro-002.description": "Gemini 1.0 Pro 002（调优版）为复杂任务提供强大的多模态支持。",
  "gemini-1.0-pro-latest.description": "Gemini 1.0 Pro 是 Google 的高性能 AI 模型，适用于大规模任务处理。",
  "gemini-1.5-flash-001.description": "Gemini 1.5 Flash 001 是一款高效多模态模型，适用于广泛应用场景。",
  "gemini-1.5-flash-002.description": "Gemini 1.5 Flash 002 是一款高效多模态模型，适用于大规模部署。",
  "gemini-1.5-flash-8b-exp-0924.description": "Gemini 1.5 Flash 8B 0924 是最新实验模型，在文本与多模态用例中取得显著提升。",
  "gemini-1.5-flash-8b-latest.description": "Gemini 1.5 Flash 8B 是一款高效多模态模型，适用于大规模部署。",
  "gemini-1.5-flash-8b.description": "Gemini 1.5 Flash 8B 是一款高效多模态模型，适用于广泛应用场景。",
  "gemini-1.5-flash-exp-0827.description": "Gemini 1.5 Flash 0827 优化多模态处理，适用于复杂任务。",
  "gemini-1.5-flash-latest.description": "Gemini 1.5 Flash 是 Google 最新的多模态 AI 模型，处理速度快，支持文本、图像与视频输入，适用于高效任务扩展。",
  "gemini-1.5-pro-001.description": "Gemini 1.5 Pro 001 是一款可扩展的多模态 AI 解决方案，适用于复杂任务。",
  "gemini-1.5-pro-002.description": "Gemini 1.5 Pro 002 是最新的生产级模型，在数学、长上下文和视觉任务方面输出质量更高。",
  "gemini-1.5-pro-exp-0801.description": "Gemini 1.5 Pro 0801 提供强大的多模态处理能力，为应用开发带来更大灵活性。",
  "gemini-1.5-pro-exp-0827.description": "Gemini 1.5 Pro 0827 应用了最新优化，提升多模态处理效率。",
  "gemini-1.5-pro-latest.description": "Gemini 1.5 Pro 支持最多 200 万个 token，是一款适用于复杂任务的中型多模态模型。",
  "gemini-2.0-flash-001.description": "Gemini 2.0 Flash 提供下一代功能，包括卓越速度、原生工具使用、多模态生成以及 100 万 token 上下文窗口。",
  "gemini-2.0-flash-exp-image-generation.description": "Gemini 2.0 Flash 实验模型，支持图像生成。",
  "gemini-2.0-flash-lite-001.description": "Gemini 2.0 Flash 的一个轻量变体，优化了成本效率与低延迟表现。",
  "gemini-2.0-flash-lite.description": "Gemini 2.0 Flash 的一个轻量变体，优化了成本效率与低延迟表现。",
  "gemini-2.0-flash.description": "Gemini 2.0 Flash 提供下一代功能，包括卓越速度、原生工具使用、多模态生成以及 100 万 token 上下文窗口。",
  "gemini-2.5-flash-image.description": "Nano Banana 是 Google 最新、最快、最高效的原生多模态模型，支持对话式图像生成与编辑。",
  "gemini-2.5-flash-image:image.description": "Nano Banana 是 Google 最新、最快、最高效的原生多模态模型，支持对话式图像生成与编辑。",
  "gemini-2.5-flash-lite-preview-06-17.description": "Gemini 2.5 Flash-Lite Preview 是 Google 最小、性价比最高的模型，适用于大规模使用场景。",
  "gemini-2.5-flash-lite-preview-09-2025.description": "Gemini 2.5 Flash-Lite 的预览版本（2025 年 9 月 25 日发布）",
  "gemini-2.5-flash-lite.description": "Gemini 2.5 Flash-Lite 是 Google 最小、性价比最高的模型，适用于大规模使用场景。",
  "gemini-2.5-flash-preview-04-17.description": "Gemini 2.5 Flash Preview 是 Google 功能最全、性价比最高的模型。",
  "gemini-2.5-flash-preview-09-2025.description": "Gemini 2.5 Flash 的预览版本（2025 年 9 月 25 日发布）",
  "gemini-2.5-flash.description": "Gemini 2.5 Flash 是 Google 功能最全、性价比最高的模型。",
  "gemini-2.5-pro-preview-03-25.description": "Gemini 2.5 Pro Preview 是 Google 最先进的推理模型，能够处理代码、数学、STEM 问题，并分析大规模数据集、代码库和长文档。",
  "gemini-2.5-pro-preview-05-06.description": "Gemini 2.5 Pro Preview 是 Google 最先进的推理模型，能够处理代码、数学、STEM 问题，并分析大规模数据集、代码库和长文档。",
  "gemini-2.5-pro-preview-06-05.description": "Gemini 2.5 Pro Preview 是 Google 最先进的推理模型，能够处理代码、数学、STEM 问题，并分析大规模数据集、代码库和长文档。",
  "gemini-2.5-pro.description": "Gemini 2.5 Pro 是 Google 的旗舰推理模型，支持长上下文，适用于复杂任务。",
  "gemini-3-flash-preview.description": "Gemini 3 Flash 是一款以速度为核心的智能模型，融合前沿智能与卓越的搜索能力。",
  "gemini-3-pro-image-preview.description": "Gemini 3 Pro Image（Nano Banana Pro）是 Google 的图像生成模型，同时支持多模态对话。",
  "gemini-3-pro-image-preview:image.description": "Gemini 3 Pro Image（Nano Banana Pro）是 Google 推出的图像生成模型，同时支持多模态对话。",
  "gemini-3-pro-preview.description": "Gemini 3 Pro 是 Google 最强大的智能体与编程模型，在最先进推理基础上提供更丰富的视觉效果与更深入的交互体验。",
  "gemini-flash-latest.description": "Latest release of Gemini Flash",
  "gemini-flash-lite-latest.description": "Latest release of Gemini Flash-Lite",
  "gemini-pro-latest.description": "Latest release of Gemini Pro",
  "gemma-7b-it.description": "Gemma 7B 是一款适用于中小规模任务的高性价比模型。",
  "gemma2-9b-it.description": "Gemma 2 9B 针对特定任务与工具集成进行了优化。",
  "gemma2.description": "Gemma 2 是 Google 推出的高效模型，适用于从小型应用到复杂数据处理的多种场景。",
  "gemma2:27b.description": "Gemma 2 是 Google 推出的高效模型，适用于从小型应用到复杂数据处理的多种场景。",
  "gemma2:2b.description": "Gemma 2 是 Google 推出的高效模型，适用于从小型应用到复杂数据处理的多种场景。",
  "generalv3.5.description": "讯飞星火 Max 是功能最全面的版本，支持网页搜索与多种内置插件。其核心能力、系统角色与函数调用均经过全面优化，适用于复杂应用场景，表现卓越。",
  "generalv3.description": "讯飞星火 Pro 是一款面向专业领域优化的大模型，专注于数学、编程、医疗与教育，支持网页搜索与天气、日期等内置插件。在复杂知识问答、语言理解与高级文本创作方面表现出色，是专业场景的理想选择。",
  "glm-4-0520.description": "GLM-4-0520 是最新版本模型，专为处理高度复杂与多样化任务而设计，性能卓越。",
  "glm-4-7.description": "GLM-4.7 是智谱 AI 最新的旗舰模型。GLM-4.7 在编程能力、长期任务规划和工具协作方面实现了提升，适用于 Agentic Coding 场景，在多个公开基准测试中表现领先于其他开源模型。其通用能力也得到增强，回复更简洁自然，写作更具沉浸感。在复杂智能体任务中，工具调用时的指令遵循性更强，Artifacts 和 Agentic Coding 前端的美学表现及长期任务完成效率进一步提升。• 更强的编程能力：多语言编程和终端智能体性能显著提升；GLM-4.7 可在 Claude Code、Kilo Code、TRAE、Cline 和 Roo Code 等编程框架中实现“先思考，后行动”的机制，在复杂任务中表现更稳定。• 前端美学提升：GLM-4.7 在前端生成质量上取得显著进展，能够生成更具视觉吸引力的网站、PPT 和海报。• 更强的工具调用能力：GLM-4.7 工具调用能力增强，在 BrowseComp 网页任务评估中得分 67；在 τ²-Bench 交互式工具调用评估中得分 84.7，超越 Claude Sonnet 4.5，成为开源 SOTA。• 推理能力提升：数学与推理能力显著增强，在 HLE（“人类终极考试”）基准测试中得分 42.8%，比 GLM-4.6 提升 41%，超越 GPT-5.1。• 通用能力增强：GLM-4.7 对话更简洁、智能且具人性化；写作与角色扮演更具文学性和沉浸感。",
  "glm-4-9b-chat.description": "GLM-4-9B-Chat 在语义、数学、推理、编程与知识方面表现强劲，支持网页浏览、代码执行、自定义工具调用与长文本推理，支持包括日语、韩语、德语在内的 26 种语言。",
  "glm-4-air-250414.description": "GLM-4-Air 是一款高性价比模型，性能接近 GLM-4，速度快、成本低。",
  "glm-4-air.description": "GLM-4-Air 是一款高性价比模型，性能接近 GLM-4，速度快、成本低。",
  "glm-4-airx.description": "GLM-4-AirX 是 GLM-4-Air 的高效变体，推理速度提升至 2.6 倍。",
  "glm-4-alltools.description": "GLM-4-AllTools 是一款多功能智能体模型，优化用于复杂指令规划与工具使用，如网页浏览、代码解释与文本生成，适合多任务执行。",
  "glm-4-flash-250414.description": "GLM-4-Flash 适用于简单任务：速度最快且免费。",
  "glm-4-flash.description": "GLM-4-Flash 适用于简单任务：速度最快且免费。",
  "glm-4-flashx.description": "GLM-4-FlashX 是 Flash 的增强版，具备超快推理能力。",
  "glm-4-long.description": "GLM-4-Long 支持超长输入，适用于记忆类任务与大规模文档处理。",
  "glm-4-plus.description": "GLM-4-Plus 是一款高智能旗舰模型，具备强大的长文本与复杂任务处理能力，整体性能全面升级。",
  "glm-4.1v-thinking-flash.description": "GLM-4.1V-Thinking 是目前已知最强的约 100 亿参数视觉语言模型，覆盖视频理解、图像问答、学科解题、OCR、文档与图表阅读、GUI 智能体、前端编程与视觉定位等 SOTA 任务。通过先进的强化学习，采用思维链推理提升准确性与丰富性，在结果与可解释性方面均优于传统非思考模型。",
  "glm-4.1v-thinking-flashx.description": "GLM-4.1V-Thinking 是目前已知最强的约 100 亿参数视觉语言模型，覆盖视频理解、图像问答、学科解题、OCR、文档与图表阅读、GUI 智能体、前端编程与视觉定位等 SOTA 任务。通过先进的强化学习，采用思维链推理提升准确性与丰富性，在结果与可解释性方面均优于传统非思考模型。",
  "glm-4.5-air.description": "GLM-4.5 轻量版，兼顾性能与成本，支持灵活的混合思维模式。",
  "glm-4.5-airx.description": "GLM-4.5-Air 快速版，响应更快，适用于大规模高速使用场景。",
  "glm-4.5-x.description": "GLM-4.5 快速版，生成速度高达每秒 100 个 token，性能强劲。",
  "glm-4.5.description": "智谱旗舰模型，支持可切换思维模式，整体性能达开源 SOTA，支持最长 128K 上下文。",
  "glm-4.5v.description": "智谱下一代 MoE 视觉推理模型，总参数 106B，激活参数 12B，在图像、视频、文档理解与 GUI 任务中，在同规模开源多模态模型中表现领先。",
  "glm-4.6.description": "智谱最新旗舰模型 GLM-4.6（3550 亿参数）在高级编程、长文本处理、推理和智能体能力方面全面超越前代，尤其在编程能力上对标 Claude Sonnet 4，成为中国顶尖的编程模型。",
  "glm-4.7-flash.description": "GLM-4.7-Flash 是一款 30B 级别的 SOTA 模型，在性能与效率之间实现平衡。它提升了编程能力、长期任务规划和工具协作能力，适用于 Agentic Coding 场景，在多个当前基准排行榜中，在同体量开源模型中表现领先。在执行复杂智能体任务时，工具调用的指令遵循性更强，进一步提升了 Artifacts 和 Agentic Coding 的前端美学和长期任务完成效率。",
  "glm-4.7-flashx.description": "GLM-4.7-Flash 是一款 30B 级别的 SOTA 模型，在性能与效率之间实现平衡。它提升了编程能力、长期任务规划和工具协作能力，适用于 Agentic Coding 场景，在多个当前基准排行榜中，在同体量开源模型中表现领先。在执行复杂智能体任务时，工具调用的指令遵循性更强，进一步提升了 Artifacts 和 Agentic Coding 的前端美学和长期任务完成效率。",
  "glm-4.7.description": "GLM-4.7 是智谱最新旗舰模型，专为智能体编程场景优化，具备更强的编程能力、长期任务规划与工具协作能力。在多个公开基准测试中，在开源模型中表现领先。通用能力方面，回复更简洁自然，写作更具沉浸感。在复杂智能体任务中，工具调用时的指令遵循能力更强，Artifacts 与智能体编程的前端美学与长期任务完成效率也进一步提升。",
  "glm-4.description": "GLM-4 是 2024 年 1 月发布的旧版旗舰模型，现已由更强的 GLM-4-0520 替代。",
  "glm-4v-flash.description": "GLM-4V-Flash 专注于高效的单图像理解，适用于实时或批量图像处理等快速分析场景。",
  "glm-4v-plus-0111.description": "GLM-4V-Plus 支持视频与多图像理解，适用于多模态任务。",
  "glm-4v-plus.description": "GLM-4V-Plus 支持视频与多图像理解，适用于多模态任务。",
  "glm-4v.description": "GLM-4V 在视觉任务中具备强大的图像理解与推理能力。",
  "glm-z1-air.description": "具备强大推理能力的模型，适用于需要深度推理的任务。",
  "glm-z1-airx.description": "超快推理，兼具高质量推理表现。",
  "glm-z1-flash.description": "GLM-Z1 系列具备强大的复杂推理能力，在逻辑、数学与编程方面表现出色。",
  "glm-z1-flashx.description": "快速且低成本：Flash 增强版，具备超快推理与更高并发能力。",
  "glm-zero-preview.description": "GLM-Zero-Preview 具备强大的复杂推理能力，在逻辑、数学与编程方面表现出色。",
  "global.anthropic.claude-opus-4-5-20251101-v1:0.description": "Claude Opus 4.5 是 Anthropic 的旗舰模型，结合卓越的智能与可扩展性能，专为需要高质量响应与推理的复杂任务而设计。",
  "google/gemini-2.0-flash-001.description": "Gemini 2.0 Flash 提供下一代能力，包括卓越速度、原生工具使用、多模态生成与 100 万 token 上下文窗口支持。",
  "google/gemini-2.0-flash-lite-001.description": "Gemini 2.0 Flash Lite 是轻量级 Gemini 变体，默认关闭推理功能以优化延迟和成本，但可通过参数启用。",
  "google/gemini-2.0-flash-lite.description": "Gemini 2.0 Flash Lite 提供下一代特性，包括极快速度、内置工具使用、多模态生成和 100 万 token 上下文窗口。",
  "google/gemini-2.0-flash.description": "Gemini 2.0 Flash 是 Google 面向扩展多模态任务的高性能推理模型。",
  "google/gemini-2.5-flash-image-free.description": "Gemini 2.5 Flash Image 免费版，支持有限配额的多模态生成。",
  "google/gemini-2.5-flash-image-preview.description": "Gemini 2.5 Flash 实验模型，支持图像生成。",
  "google/gemini-2.5-flash-image.description": "Gemini 2.5 Flash Image（Nano Banana）是 Google 的图像生成模型，支持多模态对话。",
  "google/gemini-2.5-flash-lite.description": "Gemini 2.5 Flash Lite 是 Gemini 2.5 的轻量级变体，优化延迟和成本，适用于高吞吐场景。",
  "google/gemini-2.5-flash-preview.description": "Gemini 2.5 Flash 是 Google 最先进的旗舰模型，专为高级推理、编程、数学和科学任务打造。内置“思考”机制，提供更高准确率和更精细的上下文处理。\n\n注意：该模型有两个变体——思考版与非思考版。启用思考功能将显著影响输出计费。\n\n如需启用思考并接收思考 token，请选择带“:thinking”后缀的变体。\n\nGemini 2.5 Flash 还可通过“max reasoning tokens”参数进行配置，详见文档：https://openrouter.ai/docs/use-cases/reasoning-tokens#max-tokens-for-reasoning。",
  "google/gemini-2.5-flash-preview:thinking.description": "Gemini 2.5 Flash 是 Google 最先进的旗舰模型，专为高级推理、编程、数学和科学任务打造。内置“思考”机制，提供更高准确率和更精细的上下文处理。\n\n注意：该模型有两个变体——思考版与非思考版。启用思考功能将显著影响输出计费。\n\n如需启用思考并接收思考 token，请选择带“:thinking”后缀的变体。\n\nGemini 2.5 Flash 还可通过“max reasoning tokens”参数进行配置，详见文档：https://openrouter.ai/docs/use-cases/reasoning-tokens#max-tokens-for-reasoning。",
  "google/gemini-2.5-flash.description": "Gemini 2.5 Flash（Lite/Pro/Flash）是 Google 的模型家族，覆盖从低延迟到高性能推理的多种需求。",
  "google/gemini-2.5-pro-free.description": "Gemini 2.5 Pro 免费版提供有限配额的多模态长上下文支持，适合试用和轻量工作流。",
  "google/gemini-2.5-pro-preview.description": "Gemini 2.5 Pro Preview 是 Google 最先进的思考模型，擅长处理代码、数学、STEM 等复杂问题，并能分析大规模数据集、代码库和长文档。",
  "google/gemini-2.5-pro.description": "Gemini 2.5 Pro 是 Google 的旗舰推理模型，支持长上下文，适用于复杂任务。",
  "google/gemini-3-pro-image-preview-free.description": "Gemini 3 Pro Image 免费版，支持有限配额的多模态生成。",
  "google/gemini-3-pro-image-preview.description": "Gemini 3 Pro Image（Nano Banana Pro）是 Google 的图像生成模型，支持多模态对话。",
  "google/gemini-3-pro-preview-free.description": "Gemini 3 Pro Preview 免费版具备与标准版相同的多模态理解与推理能力，但有配额和速率限制，适合试用和低频使用。",
  "google/gemini-3-pro-preview.description": "Gemini 3 Pro 是 Gemini 系列的下一代多模态推理模型，支持文本、音频、图像和视频理解，能处理复杂任务和大型代码库。",
  "google/gemini-embedding-001.description": "一款先进的嵌入模型，在英文、多语言和代码任务中表现出色。",
  "google/gemini-flash-1.5.description": "Gemini 1.5 Flash 针对多模态处理进行了优化，适用于多种复杂任务。",
  "google/gemini-pro-1.5.description": "Gemini 1.5 Pro 融合最新优化技术，实现更高效的多模态数据处理。",
  "google/gemma-2-27b-it.description": "Gemma 2 27B 是一款通用大型语言模型，在多种场景下表现优异。",
  "google/gemma-2-27b.description": "Gemma 2 是 Google 推出的高效模型家族，适用于从小型应用到复杂数据处理的多种场景。",
  "google/gemma-2-2b-it.description": "一款专为边缘应用设计的先进小型语言模型。",
  "google/gemma-2-9b-it.description": "Gemma 2 9B 是 Google 开发的高效模型，具备良好的指令遵循能力和整体性能。",
  "google/gemma-2-9b-it:free.description": "Gemma 2 是 Google 推出的轻量级开源文本模型家族。",
  "google/gemma-2-9b.description": "Gemma 2 是 Google 推出的高效模型家族，适用于从小型应用到复杂数据处理的多种场景。",
  "google/gemma-2b-it.description": "Gemma Instruct（2B）为轻量级应用提供基础指令处理能力。",
  "google/gemma-3-12b-it.description": "Gemma 3 12B 是 Google 推出的开源语言模型，在效率和性能方面树立了新标杆。",
  "google/gemma-3-27b-it.description": "Gemma 3 27B 是 Google 推出的开源语言模型，在效率和性能方面树立了新标杆。",
  "google/text-embedding-005.description": "一款专注于英文任务的文本嵌入模型，针对代码和英文任务进行了优化。",
  "google/text-multilingual-embedding-002.description": "一款多语言文本嵌入模型，针对跨语言任务进行了优化，支持多种语言。",
  "gpt-3.5-turbo-0125.description": "GPT-3.5 Turbo 用于文本生成与理解；当前指向 gpt-3.5-turbo-0125。",
  "gpt-3.5-turbo-1106.description": "GPT-3.5 Turbo 用于文本生成与理解；当前指向 gpt-3.5-turbo-0125。",
  "gpt-3.5-turbo-instruct.description": "GPT-3.5 Turbo 优化用于指令跟随的文本生成与理解任务。",
  "gpt-3.5-turbo.description": "GPT-3.5 Turbo 用于文本生成与理解；当前指向 gpt-3.5-turbo-0125。",
  "gpt-35-turbo-16k.description": "GPT-3.5 Turbo 16k 是一款高容量文本生成模型，适用于复杂任务。",
  "gpt-35-turbo.description": "GPT-3.5 Turbo 是 OpenAI 高效的聊天与文本生成模型，支持并行函数调用。",
  "gpt-4-0125-preview.description": "最新的 GPT-4 Turbo 增加了视觉能力。视觉请求支持 JSON 模式与函数调用。该模型在实时应用中兼顾准确性与效率，性价比高。",
  "gpt-4-0613.description": "GPT-4 提供更大的上下文窗口，适用于处理更长的输入，适合信息整合与数据分析。",
  "gpt-4-1106-preview.description": "最新的 GPT-4 Turbo 增加了视觉能力。视觉请求支持 JSON 模式与函数调用。该模型在实时应用中兼顾准确性与效率，性价比高。",
  "gpt-4-32k-0613.description": "GPT-4 提供更大的上下文窗口，适用于需要广泛信息整合与数据分析的场景。",
  "gpt-4-32k.description": "GPT-4 提供更大的上下文窗口，适用于需要广泛信息整合与数据分析的场景。",
  "gpt-4-turbo-2024-04-09.description": "最新的 GPT-4 Turbo 增加了视觉能力。视觉请求支持 JSON 模式与函数调用。该模型在实时应用中兼顾准确性与效率，性价比高。",
  "gpt-4-turbo-preview.description": "最新的 GPT-4 Turbo 增加了视觉能力。视觉请求支持 JSON 模式与函数调用。该模型在实时应用中兼顾准确性与效率，性价比高。",
  "gpt-4-turbo.description": "最新的 GPT-4 Turbo 增加了视觉能力。视觉请求支持 JSON 模式与函数调用。该模型在实时应用中兼顾准确性与效率，性价比高。",
  "gpt-4-vision-preview.description": "GPT-4 Vision 预览版，专为图像分析与处理任务设计。",
  "gpt-4.1-mini.description": "GPT-4.1 mini 在智能、速度与成本之间实现平衡，适用于多种场景。",
  "gpt-4.1-nano.description": "GPT-4.1 nano 是最快且最具性价比的 GPT-4.1 模型。",
  "gpt-4.1.description": "GPT-4.1 是我们面向复杂任务与跨领域问题解决的旗舰模型。",
  "gpt-4.5-preview.description": "GPT-4.5-preview 是最新的通用模型，具备更深的世界知识与更强的意图理解能力，擅长创意任务与智能体规划。知识截止时间为 2023 年 10 月。",
  "gpt-4.description": "GPT-4 提供更大的上下文窗口，适用于信息整合与数据分析等任务。",
  "gpt-4o-2024-05-13.description": "ChatGPT-4o 是一款实时更新的动态模型，结合强大的理解与生成能力，适用于客户支持、教育与技术支持等大规模应用场景。",
  "gpt-4o-2024-08-06.description": "ChatGPT-4o 是一款实时更新的动态模型，结合强大的语言理解与生成能力，适用于客户支持、教育与技术协助等大规模应用场景。",
  "gpt-4o-2024-11-20.description": "ChatGPT-4o 是一款实时更新的动态模型，结合强大的理解与生成能力，适用于客户支持、教育与技术支持等大规模应用场景。",
  "gpt-4o-audio-preview.description": "GPT-4o 音频预览模型，支持音频输入与输出。",
  "gpt-4o-mini-audio-preview.description": "GPT-4o mini 音频模型，支持音频输入与输出。",
  "gpt-4o-mini-realtime-preview.description": "GPT-4o-mini 实时变体，支持音频与文本的实时输入输出。",
  "gpt-4o-mini-search-preview.description": "GPT-4o mini 搜索预览版，训练用于理解并执行网页搜索请求，通过 Chat Completions API 实现。网页搜索按工具调用计费，另加 token 成本。",
  "gpt-4o-mini-transcribe.description": "GPT-4o Mini 转录模型是一款语音转文本模型，使用 GPT-4o 进行音频转录，在词错误率、语言识别与准确性方面优于原始 Whisper 模型。",
  "gpt-4o-mini-tts.description": "GPT-4o mini TTS 是一款基于 GPT-4o mini 的文本转语音模型，可将文本转换为自然语音，最大输入为 2000 个 token。",
  "gpt-4o-mini.description": "GPT-4o mini 是 OpenAI 在 GPT-4 Omni 之后推出的最新模型，支持文本+图像输入与文本输出。作为最先进的小型模型，其价格远低于前沿模型，比 GPT-3.5 Turbo 便宜 60% 以上，同时保持顶级智能水平（MMLU 达 82%）。",
  "gpt-4o-realtime-preview-2024-10-01.description": "GPT-4o 实时变体，支持音频与文本的实时输入输出。",
  "gpt-4o-realtime-preview-2025-06-03.description": "GPT-4o 实时变体，支持音频与文本的实时输入输出。",
  "gpt-4o-realtime-preview.description": "GPT-4o 实时变体，支持音频与文本的实时输入输出。",
  "gpt-4o-search-preview.description": "GPT-4o 搜索预览版，训练用于理解并执行网页搜索请求，通过 Chat Completions API 实现。网页搜索按工具调用计费，另加 token 成本。",
  "gpt-4o-transcribe.description": "GPT-4o 转录模型是一款语音转文本模型，使用 GPT-4o 进行音频转录，在词错误率、语言识别与准确性方面优于原始 Whisper 模型。",
  "gpt-4o.description": "ChatGPT-4o 是一款实时更新的动态模型，结合强大的理解与生成能力，适用于客户支持、教育与技术支持等大规模应用场景。",
  "gpt-5-chat-latest.description": "GPT-5 模型用于 ChatGPT，结合强大的理解与生成能力，适用于对话类应用。",
  "gpt-5-chat.description": "GPT-5 Chat 是一款预览模型，专为对话场景优化。支持文本与图像输入，仅输出文本，适用于聊天机器人与对话式 AI 应用。",
  "gpt-5-codex.description": "GPT-5 Codex 是 GPT-5 的一个变体，专为 Codex 类环境中的智能编程任务优化。",
  "gpt-5-mini.description": "GPT-5 的快速、低成本变体，适用于定义明确的任务，在保持质量的同时提供更快响应。",
  "gpt-5-nano.description": "GPT-5 的最快、最具性价比的变体，适用于对延迟与成本敏感的应用。",
  "gpt-5-pro.description": "GPT-5 Pro 使用更多计算资源以实现更深入的思考，持续提供更优质的答案。",
  "gpt-5.1-chat-latest.description": "GPT-5.1 Chat：GPT-5.1 的 ChatGPT 变体，专为对话场景打造。",
  "gpt-5.1-codex-mini.description": "GPT-5.1 Codex mini：更小、更低成本的 Codex 变体，专为智能编程任务优化。",
  "gpt-5.1-codex.description": "GPT-5.1 Codex：GPT-5.1 的一个变体，专为复杂代码/智能体工作流优化，适用于 Responses API。",
  "gpt-5.1.description": "GPT-5.1 — 一款旗舰模型，专为编程与智能体任务优化，支持可配置的推理深度与更长上下文。",
  "gpt-5.2-chat-latest.description": "GPT-5.2 Chat 是 ChatGPT 的最新对话版本，带来最新的对话体验改进。",
  "gpt-5.2-pro.description": "GPT-5.2 Pro：更智能、更精准的 GPT-5.2 变体（仅限 Responses API），适用于复杂问题和多轮推理。",
  "gpt-5.2.description": "GPT-5.2 是一款旗舰模型，适用于编程与智能体工作流，具备更强推理能力与长上下文处理能力。",
  "gpt-5.description": "跨领域编程与智能体任务的最佳模型。GPT-5 在准确性、速度、推理、上下文感知、结构化思维与问题解决方面实现飞跃。",
  "gpt-audio.description": "GPT Audio 是支持音频输入/输出的通用对话模型，可通过 Chat Completions API 使用。",
  "gpt-image-1-mini.description": "GPT Image 1 的低成本变体，原生支持文本与图像输入，以及图像输出。",
  "gpt-image-1.5.description": "GPT Image 1 的增强版本，生成速度提升 4 倍，编辑更精准，文本渲染效果更佳。",
  "gpt-image-1.description": "ChatGPT 原生多模态图像生成模型。",
  "gpt-oss-120b.description": "需申请访问。GPT-OSS-120B 是 OpenAI 开源的大型语言模型，具备强大的文本生成能力。",
  "gpt-oss-20b.description": "需申请访问。GPT-OSS-20B 是 OpenAI 开源的中型语言模型，具备高效的文本生成能力。",
  "gpt-oss:120b.description": "GPT-OSS 120B 是 OpenAI 推出的大型开源语言模型，采用 MXFP4 量化技术，定位为旗舰模型。需多 GPU 或高端工作站环境支持，在复杂推理、代码生成和多语言处理方面表现出色，具备先进的函数调用与工具集成能力。",
  "gpt-oss:20b.description": "GPT-OSS 20B 是 OpenAI 推出的开源语言模型，采用 MXFP4 量化技术，适用于高端消费级 GPU 或 Apple Silicon Mac。擅长对话生成、编程与推理任务，支持函数调用与工具使用。",
  "gpt-realtime.description": "通用实时模型，支持实时文本与音频输入/输出，并支持图像输入。",
  "grok-2-image-1212.description": "我们最新的图像生成模型可根据提示生成生动逼真的图像，特别适用于营销、社交媒体和娱乐场景。",
  "grok-2-vision-1212.description": "提升了准确性、指令遵循能力和多语言支持能力。",
  "grok-3-mini.description": "轻量级模型，在回答前进行思考。适用于不需要深度领域知识的逻辑任务，响应快速且智能，并可访问原始推理轨迹。",
  "grok-3.description": "旗舰模型，擅长企业级应用，如数据提取、编程和摘要，具备金融、医疗、法律和科学等领域的深度知识。",
  "grok-4-0709.description": "xAI 的 Grok 4，具备强大的推理能力。",
  "grok-4-1-fast-non-reasoning.description": "前沿多模态模型，针对高性能智能体工具使用进行了优化。",
  "grok-4-1-fast-reasoning.description": "前沿多模态模型，针对高性能智能体工具使用进行了优化。",
  "grok-4-fast-non-reasoning.description": "我们很高兴发布 Grok 4 Fast，这是我们在高性价比推理模型方面的最新进展。",
  "grok-4-fast-reasoning.description": "我们很高兴发布 Grok 4 Fast，这是我们在高性价比推理模型方面的最新进展。",
  "grok-4.description": "我们最新最强的旗舰模型，在自然语言处理、数学和推理方面表现卓越，是理想的全能型模型。",
  "grok-code-fast-1.description": "我们很高兴推出 grok-code-fast-1，这是一款快速且高性价比的推理模型，擅长智能体编程。",
  "groq/compound-mini.description": "Compound-mini 是一个由 GroqCloud 支持的复合 AI 系统，基于公开模型构建，能够智能选择工具回答用户问题。",
  "groq/compound.description": "Compound 是一个由 GroqCloud 支持的复合 AI 系统，基于多个公开模型构建，能够智能选择工具回答用户问题。",
  "gryphe/mythomax-l2-13b.description": "MythoMax L2 13B 是一个融合多个顶级模型的创意型智能语言模型。",
  "hunyuan-a13b.description": "混合推理模型 Hunyuan-A13B 是混元推出的首个此类模型，由 hunyuan-standard-256K（总参数 800 亿，激活参数 130 亿）升级而来。默认采用慢思考模式，可通过参数或前缀 /no_think 切换快/慢思维。整体能力较前代显著提升，尤其在数学、科学、长文本理解和智能体任务方面表现优异。",
  "hunyuan-code.description": "最新代码生成模型，使用 2000 亿高质量代码训练，并经过六个月的 SFT 微调；上下文扩展至 8K。在五种编程语言的自动评测中排名前列，并在十项人工评估指标中表现优异。",
  "hunyuan-functioncall.description": "最新 MoE 架构函数调用模型，使用高质量函数调用数据训练，具备 32K 上下文窗口，在多个维度的基准测试中表现领先。",
  "hunyuan-large-longcontext.description": "擅长长文档任务，如摘要与问答，同时具备通用生成能力。对复杂、细致内容的长文本分析与生成能力强。",
  "hunyuan-large-vision.description": "基于混元大模型训练的视觉语言模型，支持任意分辨率的多图+文本输入，提升多语言视觉理解能力。",
  "hunyuan-large.description": "Hunyuan-large 拥有约 3890 亿总参数和约 520 亿激活参数，是目前最大的开源 MoE Transformer 架构模型，性能最强。",
  "hunyuan-lite-vision.description": "最新 70 亿参数多模态模型，具备 32K 上下文窗口，支持中英文多模态对话、目标识别、文档表格理解和多模态数学任务，在多个基准测试中超越同类 7B 模型。",
  "hunyuan-lite.description": "升级为 MoE 架构，具备 256K 上下文窗口，在 NLP、代码、数学和行业基准测试中领先众多开源模型。",
  "hunyuan-pro.description": "万亿参数的 MOE-32K 长上下文模型，在复杂指令与推理、高级数学、函数调用等方面表现强劲，针对多语言翻译、金融、法律和医疗等领域进行了优化。",
  "hunyuan-role.description": "最新角色扮演模型，基于角色扮演数据集官方微调，在角色扮演场景中提供更强的基础表现。",
  "hunyuan-standard-256K.description": "通过改进路由机制缓解负载均衡与专家崩溃问题。在长上下文任务中实现 99.9% 的“针在大海捞”准确率。MOE-256K 进一步扩展上下文长度与质量。",
  "hunyuan-standard-vision.description": "最新多模态模型，具备多语言响应能力，中英文能力均衡。",
  "hunyuan-standard.description": "通过改进路由机制缓解负载均衡与专家崩溃问题。在长上下文任务中实现 99.9% 的“针在大海捞”准确率。MOE-32K 在处理长输入时性价比高，表现强劲。",
  "hunyuan-t1-20250321.description": "在文艺与 STEM 能力之间实现平衡，具备强大的长文本信息捕捉能力。支持各类难度的数学、逻辑、科学与编程问题的推理解答。",
  "hunyuan-t1-20250403.description": "提升项目级代码生成与写作质量，加强多轮话题理解与 ToB 指令遵循能力，提升词级理解能力，减少简繁混用与中英文混输问题。",
  "hunyuan-t1-20250529.description": "提升创意写作与内容构思能力，加强前端编程、数学与逻辑推理能力，增强指令遵循能力。",
  "hunyuan-t1-20250711.description": "大幅提升高难数学、逻辑与编程能力，增强输出稳定性与长文本处理能力。",
  "hunyuan-t1-latest.description": "显著提升慢思考模型在高难数学、复杂推理、困难编程、指令遵循与创意写作方面的能力。",
  "hunyuan-t1-vision-20250619.description": "最新 t1-vision 多模态深度推理模型，具备原生长链式思维能力，相较前代默认版本有显著提升。",
  "hunyuan-t1-vision-20250916.description": "最新 t1-vision 深度推理模型，在 VQA、视觉定位、OCR、图表理解、拍照题解与图像创作等方面有重大提升，同时增强英文与低资源语言能力。",
  "hunyuan-turbo-20241223.description": "本版本提升指令泛化能力，显著增强数学/代码/逻辑推理能力，提升词级理解与写作质量。",
  "hunyuan-turbo-latest.description": "在 NLP 理解、写作、对话、问答、翻译与专业领域方面全面优化；响应更具人性化，模糊意图澄清更清晰，词法解析更准确，创意质量与交互性更高，多轮对话能力更强。",
  "hunyuan-turbo-vision.description": "下一代视觉语言旗舰模型，采用全新 MoE 架构，在识别、内容创作、知识问答与分析推理方面全面提升。",
  "hunyuan-turbo.description": "混元下一代大模型预览版，采用全新 MoE 架构，推理速度更快，性能超越 hunyuan-pro。",
  "hunyuan-turbos-20250313.description": "统一数学解题风格，增强多轮数学问答能力。优化写作风格，减少 AI 语气，提升表达质量。",
  "hunyuan-turbos-20250416.description": "升级预训练基座，提升指令理解与执行能力；对齐优化增强数学、编程、逻辑与科学能力；提升写作质量、理解力、翻译准确性与知识问答表现；强化智能体能力，尤其是多轮理解。",
  "hunyuan-turbos-20250604.description": "升级预训练基座，提升写作与阅读理解能力，在编程与 STEM 领域取得显著进展，复杂指令执行能力更强。",
  "hunyuan-turbos-20250926.description": "优化预训练数据质量与后训练策略，提升智能体能力、英语及低资源语言支持、指令执行、编程与 STEM 表现。",
  "hunyuan-turbos-latest.description": "最新的 Hunyuan TurboS 旗舰模型，具备更强推理能力与更优整体体验。",
  "hunyuan-turbos-longtext-128k-20250325.description": "擅长长文档任务，如摘要生成与问答，同时具备通用生成能力。对复杂、细节丰富内容的长文本分析与生成表现出色。",
  "hunyuan-turbos-role-plus.description": "最新角色扮演模型，基于角色扮演数据集官方微调，在角色扮演场景中具备更强的基础表现。",
  "hunyuan-turbos-vision-20250619.description": "最新 TurboS 视觉语言旗舰模型，在图文任务如实体识别、知识问答、文案创作与图像题解方面取得重大进展。",
  "hunyuan-turbos-vision.description": "基于最新 TurboS 的下一代视觉语言旗舰模型，专注于图文理解任务，如实体识别、知识问答、文案创作与图像题解。",
  "hunyuan-vision-1.5-instruct.description": "基于文本 TurboS 基座打造的图生文快思考模型，相较上一版本在图像基础识别、图像分析推理等方面有显著提升。",
  "hunyuan-vision.description": "最新多模态模型，支持图像+文本输入，生成文本输出。",
  "image-01-live.description": "一款细节精致的图像生成模型，支持文本生成图像与可控风格预设。",
  "image-01.description": "一款全新图像生成模型，细节表现出色，支持文本生成图像与图像转图像。",
  "imagen-4.0-fast-generate-001.description": "Imagen 第四代文本生成图像模型系列 Fast 版本",
  "imagen-4.0-generate-001.description": "Imagen 第四代文本生成图像模型系列",
  "imagen-4.0-generate-preview-06-06.description": "Imagen 第四代文本生成图像模型家族。",
  "imagen-4.0-ultra-generate-001.description": "Imagen 第四代文本生成图像模型系列 Ultra 版本",
  "imagen-4.0-ultra-generate-preview-06-06.description": "Imagen 第四代文本生成图像 Ultra 变体。",
  "inception/mercury-coder-small.description": "Mercury Coder Small 是一款适用于代码生成、调试与重构的低延迟模型。",
  "inclusionAI/Ling-flash-2.0.description": "Ling-flash-2.0 是蚂蚁集团百灵团队推出的第三款 Ling 2.0 架构模型。该模型采用 MoE 架构，总参数量为 100B，每个 token 激活参数仅为 6.1B（非嵌入部分为 4.8B）。尽管配置轻量，但在多个基准测试中表现与 40B 密集模型甚至更大 MoE 模型相当甚至更优，探索了通过架构与训练策略实现高效能的路径。",
  "inclusionAI/Ling-mini-2.0.description": "Ling-mini-2.0 是一款小型高性能 MoE 大模型，总参数量为 16B，每个 token 激活参数仅为 1.4B（非嵌入部分为 789M），生成速度极快。凭借高效的 MoE 设计与大规模高质量训练数据，在性能上可媲美 10B 以下密集模型及更大 MoE 模型。",
  "inclusionAI/Ring-flash-2.0.description": "Ring-flash-2.0 是一款从 Ling-flash-2.0-base 优化而来的高性能思维模型，采用 MoE 架构，总参数量为 100B，每次推理激活参数仅为 6.1B。其 icepop 算法稳定了 MoE 模型的强化学习训练，使其在复杂推理任务中持续进步。在数学竞赛、代码生成、逻辑推理等高难度基准测试中取得重大突破，超越 40B 以下顶级密集模型，媲美更大规模的开放或闭源推理模型。同时在创意写作方面表现优异，架构高效，推理速度快，部署成本低，适合高并发场景。",
  "inclusionai/ling-1t.description": "Ling-1T 是 inclusionAI 推出的 1T MoE 模型，专为高强度推理任务与大上下文工作负载优化。",
  "inclusionai/ling-flash-2.0.description": "Ling-flash-2.0 是 inclusionAI 推出的 MoE 模型，优化了效率与推理性能，适用于中大型任务。",
  "inclusionai/ling-mini-2.0.description": "Ling-mini-2.0 是 inclusionAI 推出的轻量级 MoE 模型，在保留推理能力的同时大幅降低成本。",
  "inclusionai/ming-flash-omini-preview.description": "Ming-flash-omni Preview 是 inclusionAI 推出的多模态模型，支持语音、图像与视频输入，图像渲染与语音识别能力提升。",
  "inclusionai/ring-1t.description": "Ring-1T 是 inclusionAI 推出的万亿参数 MoE 推理模型，适用于大规模推理与科研任务。",
  "inclusionai/ring-flash-2.0.description": "Ring-flash-2.0 是 inclusionAI 推出的 Ring 系列变体，面向高吞吐场景，强调速度与成本效率。",
  "inclusionai/ring-mini-2.0.description": "Ring-mini-2.0 是 inclusionAI 推出的高吞吐轻量级 MoE 模型，专为高并发设计。",
  "internlm/internlm2_5-7b-chat.description": "InternLM2.5-7B-Chat 是基于 InternLM2 架构的开源聊天模型。该 7B 模型专注于中英文对话生成，采用现代训练方法，具备流畅、智能的对话能力，适用于客服、个人助手等多种聊天场景。",
  "internlm2.5-latest.description": "经典模型仍在维护，经过多轮迭代后表现稳定优异。提供 7B 与 20B 两种规格，支持 1M 上下文，具备更强的指令执行与工具使用能力。默认使用最新 InternLM2.5 系列（当前为 internlm2.5-20b-chat）。",
  "internlm3-latest.description": "我们最新的模型系列，在推理性能方面表现卓越，在同类开源模型中处于领先地位。默认使用最新 InternLM3 系列（当前为 internlm3-8b-instruct）。",
  "internvl2.5-38b-mpo.description": "InternVL2.5 38B MPO 是一款多模态预训练模型，专注于复杂图文推理任务。",
  "internvl2.5-latest.description": "InternVL2.5 仍在维护，性能稳定强劲。默认使用最新 InternVL2.5 系列（当前为 internvl2.5-78b）。",
  "internvl3-14b.description": "InternVL3 14B 是一款中等规模的多模态模型，在性能与成本之间取得平衡。",
  "internvl3-1b.description": "InternVL3 1B 是一款轻量级多模态模型，适用于资源受限的部署场景。",
  "internvl3-38b.description": "InternVL3 38B 是一款大型开源多模态模型，专注于高精度图文理解。",
  "internvl3-latest.description": "我们最新的多模态模型，具备更强的图文理解与长序列图像理解能力，表现媲美顶级闭源模型。默认使用最新 InternVL 系列（当前为 internvl3-78b）。",
  "irag-1.0.description": "ERNIE iRAG 是一款图像检索增强生成模型，支持图像搜索、图文检索与内容生成任务。",
  "jamba-large.description": "我们最强大、最先进的模型，专为复杂企业任务设计，性能卓越。",
  "jamba-mini.description": "同类中效率最高的模型，在速度与质量之间实现平衡，占用资源更少。",
  "jina-deepsearch-v1.description": "DeepSearch 结合了网页搜索、阅读与推理，适用于深入研究任务。它就像一个智能代理，接收你的研究任务后，进行多轮广泛搜索，最终才生成答案。整个过程包含持续的信息检索、逻辑推理和多角度问题解决，区别于仅依赖预训练数据的传统大模型或一次性检索的RAG系统。",
  "kimi-k2-0711-preview.description": "kimi-k2 是一款具备强大编程与智能体能力的 MoE 基础模型（总参数量 1T，活跃参数 32B），在推理、编程、数学与智能体基准测试中超越主流开源模型。",
  "kimi-k2-0905-preview.description": "kimi-k2-0905-preview 提供 256k 上下文窗口，具备更强的智能体编程能力、更优的前端代码质量与更好的上下文理解能力。",
  "kimi-k2-instruct.description": "Kimi K2 Instruct 是 Kimi 官方推出的推理模型，支持长上下文，适用于代码、问答等任务。",
  "kimi-k2-thinking-turbo.description": "K2 长思考高速版本，支持 256k 上下文，具备强大的深度推理能力，输出速度达 60–100 tokens/秒。",
  "kimi-k2-thinking.description": "kimi-k2-thinking 是 Moonshot AI 推出的思考模型，具备通用智能体与推理能力，擅长深度推理，可通过多步工具使用解决复杂问题。",
  "kimi-k2-turbo-preview.description": "kimi-k2 是一款具备强大编程与智能体能力的 MoE 基础模型（总参数量 1T，活跃参数 32B），在推理、编程、数学与智能体基准测试中超越主流开源模型。",
  "kimi-k2.5.description": "Kimi K2.5 是最强大的 Kimi 模型，在智能体任务、编程与视觉理解方面实现开源 SOTA，支持多模态输入与思维/非思维模式切换。",
  "kimi-k2.description": "Kimi-K2 是 Moonshot AI 推出的 MoE 基础模型，具备强大的编程与智能体能力，总参数量达 1T，活跃参数为 32B。在通用推理、编程、数学与智能体任务的基准测试中表现优异，超越主流开源模型。",
  "kimi-k2:1t.description": "Kimi K2 是 Moonshot AI 推出的超大规模 MoE 语言模型，总参数量 1T，每次前向传播激活 32B 参数。该模型专为智能体能力优化，包括高级工具使用、推理与代码生成。",
  "kimi-latest.description": "Kimi Latest 使用最新版本的 Kimi 模型，可能包含实验性功能。支持图像理解，并根据上下文长度自动选择 8k/32k/128k 计费模型。",
  "kuaishou/kat-coder-pro-v1.description": "KAT-Coder-Pro-V1（限时免费）专注于代码理解与自动化，助力高效编程智能体。",
  "learnlm-1.5-pro-experimental.description": "LearnLM 是一款实验性、任务导向的模型，基于学习科学原理训练，能在教学/学习场景中遵循系统指令，充当专家导师。",
  "learnlm-2.0-flash-experimental.description": "LearnLM 是一款实验性、任务导向的模型，基于学习科学原理训练，能在教学/学习场景中遵循系统指令，充当专家导师。",
  "lite.description": "Spark Lite 是一款轻量级大语言模型，具备超低延迟与高效处理能力，完全免费，支持实时网页搜索。其快速响应在低算力设备与模型微调中表现出色，尤其适用于知识问答、内容生成与搜索场景，兼具高性价比与智能体验。",
  "llama-3.1-70b-versatile.description": "Llama 3.1 70B 提供更强的 AI 推理能力，适用于复杂应用，支持高效能计算与高准确率。",
  "llama-3.1-8b-instant.description": "Llama 3.1 8B 是一款高效模型，文本生成速度快，适合大规模、低成本应用。",
  "llama-3.1-instruct.description": "Llama 3.1 指令微调模型专为对话优化，在多个行业通用基准测试中超越众多开源聊天模型。",
  "llama-3.2-11b-vision-instruct.description": "具备强大的高分辨率图像推理能力，适用于视觉理解类应用。",
  "llama-3.2-11b-vision-preview.description": "Llama 3.2 专为视觉与文本结合任务设计，擅长图像描述与视觉问答，连接语言生成与视觉推理。",
  "llama-3.2-90b-vision-instruct.description": "面向视觉理解智能体应用的高级图像推理能力。",
  "llama-3.2-90b-vision-preview.description": "Llama 3.2 专为视觉与文本结合任务设计，擅长图像描述与视觉问答，连接语言生成与视觉推理。",
  "llama-3.2-vision-instruct.description": "Llama 3.2-Vision 指令微调模型，专为视觉识别、图像推理、图像描述与通用图像问答优化。",
  "llama-3.3-70b-versatile.description": "Meta Llama 3.3 是一款多语言大语言模型，拥有 70B 参数（文本输入/输出），提供预训练与指令微调版本。指令微调的文本模型专为多语言对话场景优化，在多个行业基准测试中超越众多开源与闭源聊天模型。",
  "llama-3.3-70b.description": "Llama 3.3 70B：一款中大型 Llama 模型，在推理能力与吞吐量之间实现平衡。",
  "llama-3.3-instruct.description": "Llama 3.3 指令微调模型专为对话优化，在多个行业通用基准测试中超越众多开源聊天模型。",
  "llama3-70b-8192.description": "Meta Llama 3 70B 在处理复杂任务方面表现卓越，适用于高要求项目。",
  "llama3-8b-8192.description": "Meta Llama 3 8B 在多种场景中展现出强大的推理能力。",
  "llama3-groq-70b-8192-tool-use-preview.description": "Llama 3 Groq 70B Tool Use 提供强大的工具调用能力，能高效处理复杂任务。",
  "llama3-groq-8b-8192-tool-use-preview.description": "Llama 3 Groq 8B Tool Use 针对高效工具使用进行了优化，支持快速并行计算。",
  "llama3.1-8b.description": "Llama 3.1 8B：一款小型、低延迟的 Llama 变体，适用于轻量级在线推理与对话。",
  "llama3.1.description": "Llama 3.1 是 Meta 的旗舰模型，参数规模高达 405B，适用于复杂对话、多语言翻译与数据分析。",
  "llama3.1:405b.description": "Llama 3.1 是 Meta 的旗舰模型，参数规模高达 405B，适用于复杂对话、多语言翻译与数据分析。",
  "llama3.1:70b.description": "Llama 3.1 是 Meta 的旗舰模型，参数规模高达 405B，适用于复杂对话、多语言翻译与数据分析。",
  "llava-v1.5-7b-4096-preview.description": "LLaVA 1.5 7B 融合视觉处理能力，可从视觉输入中生成复杂输出。",
  "llava.description": "LLaVA 是一款多模态模型，结合视觉编码器与 Vicuna，实现强大的视觉-语言理解能力。",
  "llava:13b.description": "LLaVA 是一款多模态模型，结合视觉编码器与 Vicuna，实现强大的视觉-语言理解能力。",
  "llava:34b.description": "LLaVA 是一款多模态模型，结合视觉编码器与 Vicuna，实现强大的视觉-语言理解能力。",
  "magistral-medium-latest.description": "Magistral Medium 1.2 是 Mistral AI 于 2025 年 9 月发布的前沿推理模型，支持视觉输入。",
  "magistral-small-2509.description": "Magistral Small 1.2 是 Mistral AI 于 2025 年 9 月发布的开源小型推理模型，支持视觉输入。",
  "mathstral.description": "MathΣtral 专为科学研究与数学推理设计，具备强大的计算与解释能力。",
  "max-32k.description": "Spark Max 32K 支持大上下文处理，具备更强的上下文理解与逻辑推理能力，支持 32K-token 输入，适用于长文档阅读与私有知识问答。",
  "megrez-3b-instruct.description": "Megrez 3B Instruct 是来自悟问星穹的小型高效模型。",
  "meituan/longcat-flash-chat.description": "美团开源的基础对话模型，专为对话与智能体任务优化，擅长工具使用与复杂多轮交互。",
  "meta-llama-3-70b-instruct.description": "一款强大的 70B 参数模型，擅长推理、编程与广泛语言任务。",
  "meta-llama-3-8b-instruct.description": "一款多功能的 8B 参数模型，针对对话与文本生成进行了优化。",
  "meta-llama-3.1-405b-instruct.description": "Llama 3.1 指令微调文本模型，针对多语言对话优化，在开源与闭源模型中在多个行业基准测试中表现优异。",
  "meta-llama-3.1-70b-instruct.description": "Llama 3.1 指令微调文本模型，针对多语言对话优化，在开源与闭源模型中在多个行业基准测试中表现优异。",
  "meta-llama-3.1-8b-instruct.description": "Llama 3.1 指令微调文本模型，针对多语言对话优化，在开源与闭源模型中在多个行业基准测试中表现优异。",
  "meta-llama/Llama-2-13b-chat-hf.description": "LLaMA-2 Chat（13B）具备强大的语言处理能力，提供出色的对话体验。",
  "meta-llama/Llama-2-70b-hf.description": "LLaMA-2 提供强大的语言处理能力与良好的交互体验。",
  "meta-llama/Llama-3-70b-chat-hf.description": "Llama 3 70B Instruct Reference 是一款强大的对话模型，适用于复杂对话场景。",
  "meta-llama/Llama-3-8b-chat-hf.description": "Llama 3 8B Instruct Reference 支持多语言，具备广泛的领域知识。",
  "meta-llama/Llama-3.2-11B-Vision-Instruct-Turbo.description": "LLaMA 3.2 专为视觉与文本结合任务设计，擅长图像描述与视觉问答，连接语言生成与视觉推理。",
  "meta-llama/Llama-3.2-3B-Instruct-Turbo.description": "LLaMA 3.2 专为视觉与文本结合任务设计，擅长图像描述与视觉问答，连接语言生成与视觉推理。",
  "meta-llama/Llama-3.2-90B-Vision-Instruct-Turbo.description": "LLaMA 3.2 专为视觉与文本结合任务设计，擅长图像描述与视觉问答，连接语言生成与视觉推理。",
  "meta-llama/Llama-3.3-70B-Instruct-Turbo.description": "Meta Llama 3.3 多语言大模型，70B 参数（文本输入/输出），经过预训练与指令微调。该文本模型针对多语言对话优化，在多个行业基准测试中超越众多开源与闭源模型。",
  "meta-llama/Llama-Vision-Free.description": "LLaMA 3.2 专为视觉与文本结合任务设计，擅长图像描述与视觉问答，连接语言生成与视觉推理。",
  "meta-llama/Meta-Llama-3-70B-Instruct-Lite.description": "Llama 3 70B Instruct Lite 旨在在低延迟下实现高性能。",
  "meta-llama/Meta-Llama-3-70B-Instruct-Turbo.description": "Llama 3 70B Instruct Turbo 在理解与生成方面表现强劲，适用于高负载任务。",
  "meta-llama/Meta-Llama-3-8B-Instruct-Lite.description": "Llama 3 8B Instruct Lite 在资源受限环境中实现性能平衡。",
  "meta-llama/Meta-Llama-3-8B-Instruct-Turbo.description": "Llama 3 8B Instruct Turbo 是一款高性能大模型，适用于多种应用场景。",
  "meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo.description": "405B 参数的 Llama 3.1 Turbo 模型具备超大上下文处理能力，适用于大数据处理与超大规模 AI 应用。",
  "meta-llama/Meta-Llama-3.1-405B-Instruct.description": "Llama 3.1 是 Meta 的旗舰模型系列，参数规模高达 405B，适用于复杂对话、多语言翻译与数据分析任务。",
  "meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo.description": "Llama 3.1 70B 针对高负载应用精细调优；FP8 量化实现高效计算与复杂场景下的准确性。",
  "meta-llama/Meta-Llama-3.1-70B.description": "Llama 3.1 是 Meta 的旗舰模型系列，参数规模高达 405B，适用于复杂对话、多语言翻译与数据分析任务。",
  "meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo.description": "Llama 3.1 8B 使用 FP8 量化，支持最多 131,072 个上下文 token，在多个基准测试中表现优异，适用于复杂任务。",
  "meta-llama/llama-3-70b-instruct.description": "Llama 3 70B Instruct 针对高质量对话进行了优化，在人工评估中表现出色。",
  "meta-llama/llama-3-8b-instruct.description": "Llama 3 8B Instruct 针对高质量对话进行了优化，超越众多闭源模型。",
  "meta-llama/llama-3.1-70b-instruct.description": "Meta 最新的 Llama 3.1 系列，70B 指令微调版本，专为高质量对话优化。在行业评估中表现优异，超越领先闭源模型。（仅对企业认证用户开放）",
  "meta-llama/llama-3.1-8b-instruct.description": "Meta 最新的 Llama 3.1 系列，8B 指令微调版本，速度快、效率高。在行业评估中表现优异，超越众多领先闭源模型。（仅对企业认证用户开放）",
  "meta-llama/llama-3.1-8b-instruct:free.description": "LLaMA 3.1 支持多语言，是领先的生成模型之一。",
  "meta-llama/llama-3.2-11b-vision-instruct.description": "LLaMA 3.2 专为视觉与文本结合任务设计，擅长图像描述与视觉问答，连接语言生成与视觉推理。",
  "meta-llama/llama-3.2-3b-instruct.description": "meta-llama/llama-3.2-3b-instruct",
  "meta-llama/llama-3.2-90b-vision-instruct.description": "LLaMA 3.2 专为视觉与文本结合任务设计，擅长图像描述与视觉问答，连接语言生成与视觉推理。",
  "meta-llama/llama-3.3-70b-instruct.description": "Llama 3.3 是最先进的多语言开源 Llama 模型，以极低成本实现接近 405B 的性能。基于 Transformer 架构，结合 SFT 与 RLHF 提升实用性与安全性。指令微调版本针对多语言对话优化，在行业基准测试中超越众多开源与闭源模型。知识截止时间：2023 年 12 月。",
  "meta-llama/llama-3.3-70b-instruct:free.description": "Llama 3.3 是最先进的多语言开源 Llama 模型，以极低成本实现接近 405B 的性能。基于 Transformer 架构，结合 SFT 与 RLHF 提升实用性与安全性。指令微调版本针对多语言对话优化，在行业基准测试中超越众多开源与闭源模型。知识截止时间：2023 年 12 月。",
  "meta.llama3-1-405b-instruct-v1:0.description": "Meta Llama 3.1 405B Instruct 是 Llama 3.1 Instruct 系列中最大且最强大的模型，专为对话推理和合成数据生成而设计，是进行领域特定持续预训练或微调的强大基础。Llama 3.1 多语言大模型（LLM）包括 8B、70B 和 405B 三种规模的预训练与指令微调生成模型（文本输入/输出）。这些指令微调模型针对多语言对话进行了优化，在多个行业通用基准测试中优于许多开源聊天模型。Llama 3.1 适用于商业和科研用途，支持多语言。指令微调模型适合助手式聊天场景，预训练模型则适用于更广泛的自然语言生成任务。Llama 3.1 的输出还可用于提升其他模型的性能，包括合成数据生成与优化。Llama 3.1 是一种自回归 Transformer 模型，采用优化架构。其微调版本结合了监督微调（SFT）和基于人类反馈的强化学习（RLHF），以更好地符合人类对有用性与安全性的偏好。",
  "meta.llama3-1-70b-instruct-v1:0.description": "更新后的 Meta Llama 3.1 70B Instruct 支持 128K 上下文窗口，具备多语言支持和更强的推理能力。Llama 3.1 多语言大模型包括 8B、70B 和 405B 三种规模的预训练与指令微调生成模型（文本输入/输出）。这些指令微调模型针对多语言对话进行了优化，在多个行业通用基准测试中优于许多开源聊天模型。Llama 3.1 适用于商业和科研用途，支持多语言。指令微调模型适合助手式聊天场景，预训练模型则适用于更广泛的自然语言生成任务。Llama 3.1 的输出还可用于提升其他模型的性能，包括合成数据生成与优化。Llama 3.1 是一种自回归 Transformer 模型，采用优化架构。其微调版本结合了监督微调（SFT）和基于人类反馈的强化学习（RLHF），以更好地符合人类对有用性与安全性的偏好。",
  "meta.llama3-1-8b-instruct-v1:0.description": "更新后的 Meta Llama 3.1 8B Instruct 支持 128K 上下文窗口，具备多语言支持和更强的推理能力。Llama 3.1 系列包括 8B、70B 和 405B 三种规模的指令微调文本模型，专为多语言聊天和强基准表现而优化。该系列适用于多语言的商业和科研用途；指令微调模型适合助手式聊天，预训练模型则适用于更广泛的生成任务。Llama 3.1 的输出还可用于提升其他模型（如合成数据生成与优化）。它是一种自回归 Transformer 模型，结合了监督微调（SFT）和基于人类反馈的强化学习（RLHF），以实现更高的有用性与安全性。",
  "meta.llama3-70b-instruct-v1:0.description": "Meta Llama 3 是一款面向开发者、研究人员和企业的开放式大语言模型，旨在帮助他们构建、实验并负责任地扩展生成式 AI 创意。作为全球社区创新的基础之一，它非常适合内容创作、对话式 AI、语言理解、研发和企业级应用。",
  "meta.llama3-8b-instruct-v1:0.description": "Meta Llama 3 是一款面向开发者、研究人员和企业的开放式大语言模型，旨在帮助他们构建、实验并负责任地扩展生成式 AI 创意。作为全球社区创新的基础之一，它特别适用于计算资源有限的场景、边缘设备以及更快的训练周期。",
  "meta/Llama-3.2-11B-Vision-Instruct.description": "在高分辨率图像上具备强大的图像推理能力，适用于视觉理解类应用。",
  "meta/Llama-3.2-90B-Vision-Instruct.description": "适用于视觉理解代理应用的高级图像推理模型。",
  "meta/Llama-3.3-70B-Instruct.description": "Llama 3.3 是最先进的多语言开源 Llama 模型，在极低成本下实现接近 405B 的性能。该模型基于 Transformer 架构，并通过 SFT 和 RLHF 提升实用性与安全性。其指令微调版本专为多语言对话优化，在行业基准测试中超越众多开源与闭源聊天模型。知识截止时间：2023 年 12 月。",
  "meta/Meta-Llama-3-70B-Instruct.description": "一款功能强大的 700 亿参数模型，擅长推理、编程和广泛的语言任务。",
  "meta/Meta-Llama-3-8B-Instruct.description": "一款多功能的 80 亿参数模型，专为对话和文本生成优化。",
  "meta/Meta-Llama-3.1-405B-Instruct.description": "Llama 3.1 指令微调文本模型，专为多语言对话优化，在开源与闭源聊天模型中在常见行业基准测试中表现出色。",
  "meta/Meta-Llama-3.1-70B-Instruct.description": "Llama 3.1 指令微调文本模型，专为多语言对话优化，在开源与闭源聊天模型中在常见行业基准测试中表现出色。",
  "meta/Meta-Llama-3.1-8B-Instruct.description": "Llama 3.1 指令微调文本模型，专为多语言对话优化，在开源与闭源聊天模型中在常见行业基准测试中表现出色。",
  "meta/llama-3-70b.description": "由 Meta 微调的 700 亿参数开源模型，专注于指令跟随，由 Groq 在 LPU 硬件上提供服务，实现快速高效的推理。",
  "meta/llama-3-8b.description": "由 Meta 微调的 80 亿参数开源模型，专注于指令跟随，由 Groq 在 LPU 硬件上提供服务，实现快速高效的推理。",
  "meta/llama-3.1-405b-instruct.description": "一款先进的大语言模型，支持合成数据生成、知识蒸馏和用于聊天机器人、编程及领域任务的推理。",
  "meta/llama-3.1-70b-instruct.description": "专为复杂对话设计，具备出色的上下文理解、推理和文本生成能力。",
  "meta/llama-3.1-70b.description": "更新版 Meta Llama 3 70B Instruct，支持 128K 上下文、多语言能力，并提升推理表现。",
  "meta/llama-3.1-8b-instruct.description": "一款前沿模型，具备强大的语言理解、推理和文本生成能力。",
  "meta/llama-3.1-8b.description": "Llama 3.1 8B 支持 128K 上下文窗口，适用于实时对话和数据分析，相较于更大模型具有显著成本优势。由 Groq 在 LPU 硬件上提供服务，实现快速高效的推理。",
  "meta/llama-3.2-11b-vision-instruct.description": "一款前沿视觉语言模型，擅长从图像中进行高质量推理。",
  "meta/llama-3.2-11b.description": "一款指令微调的图像推理模型（文本+图像输入，文本输出），专为视觉识别、图像推理、图像描述和通用图像问答优化。",
  "meta/llama-3.2-1b-instruct.description": "一款前沿的小型语言模型，具备强大的理解、推理和文本生成能力。",
  "meta/llama-3.2-1b.description": "纯文本模型，适用于设备端的多语言本地检索、摘要和改写等场景。",
  "meta/llama-3.2-3b-instruct.description": "一款前沿的小型语言模型，具备强大的理解、推理和文本生成能力。",
  "meta/llama-3.2-3b.description": "纯文本模型，针对设备端的多语言本地检索、摘要和改写等场景进行微调。",
  "meta/llama-3.2-90b-vision-instruct.description": "一款前沿视觉语言模型，擅长从图像中进行高质量推理。",
  "meta/llama-3.2-90b.description": "一款指令微调的图像推理模型（文本+图像输入，文本输出），专为视觉识别、图像推理、图像描述和通用图像问答优化。",
  "meta/llama-3.3-70b-instruct.description": "一款先进的大语言模型，擅长推理、数学、常识和函数调用。",
  "meta/llama-3.3-70b.description": "性能与效率的完美平衡。专为内容创作、企业应用和研究中的高性能对话式 AI 而构建，具备强大的语言理解能力，适用于摘要、分类、情感分析和代码生成。",
  "meta/llama-4-maverick.description": "Llama 4 系列是原生多模态 AI 模型集，支持文本与多模态体验，采用 MoE 架构，实现领先的文本与图像理解。Llama 4 Maverick 是一款拥有 128 个专家的 170 亿参数模型，由 DeepInfra 提供服务。",
  "meta/llama-4-scout.description": "Llama 4 系列是原生多模态 AI 模型集，支持文本与多模态体验，采用 MoE 架构，实现领先的文本与图像理解。Llama 4 Scout 是一款拥有 16 个专家的 170 亿参数模型，由 DeepInfra 提供服务。",
  "microsoft/Phi-3-medium-128k-instruct.description": "与 Phi-3-medium 相同的模型，但具有更大的上下文窗口，适用于 RAG 或少样本提示。",
  "microsoft/Phi-3-medium-4k-instruct.description": "一款 140 亿参数模型，质量高于 Phi-3-mini，专注于高质量、推理密集型数据。",
  "microsoft/Phi-3-mini-128k-instruct.description": "与 Phi-3-mini 相同的模型，但具有更大的上下文窗口，适用于 RAG 或少样本提示。",
  "microsoft/Phi-3-mini-4k-instruct.description": "Phi-3 系列中最小的成员，优化以实现高质量和低延迟。",
  "microsoft/Phi-3-small-128k-instruct.description": "与 Phi-3-small 相同的模型，但具有更大的上下文窗口，适用于 RAG 或少样本提示。",
  "microsoft/Phi-3-small-8k-instruct.description": "一款 70 亿参数模型，质量高于 Phi-3-mini，专注于高质量、推理密集型数据。",
  "microsoft/Phi-3.5-mini-instruct.description": "Phi-3-mini 模型的更新版本。",
  "microsoft/Phi-3.5-vision-instruct.description": "Phi-3-vision 模型的更新版本。",
  "microsoft/WizardLM-2-8x22B.description": "WizardLM 2 是微软 AI 推出的语言模型，擅长复杂对话、多语言任务、推理和助手应用。",
  "microsoft/wizardlm-2-8x22b.description": "WizardLM-2 8x22B 是微软 AI 最先进的 Wizard 模型，具备极具竞争力的性能。",
  "mimo-v2-flash.description": "MiMo-V2-Flash：一款高效模型，适用于推理、编程和智能体基础任务。",
  "minicpm-v.description": "MiniCPM-V 是 OpenBMB 的下一代多模态模型，具备出色的 OCR 和多模态理解能力，适用于广泛场景。",
  "minimax-m2.1.description": "MiniMax-M2.1 是 MiniMax 系列的最新版本，针对多语言编程和真实复杂任务进行了优化。作为原生 AI 模型，MiniMax-M2.1 在模型性能、智能体框架支持和多场景适应性方面实现了显著提升，旨在帮助企业和个人更快地实现 AI 原生的工作与生活方式。",
  "minimax-m2.description": "MiniMax M2 是一款专为编程和智能体工作流打造的高效大语言模型。",
  "minimax/minimax-m2.1.description": "MiniMax-M2.1 是一款轻量级、前沿的大语言模型，专为编程、代理工作流和现代应用开发而优化，提供更简洁的输出和更快的响应速度。",
  "minimax/minimax-m2.description": "MiniMax-M2 是一款高性价比模型，擅长编程和智能体任务，适用于多种工程场景。",
  "minimaxai/minimax-m2.description": "MiniMax-M2 是一款紧凑、快速、成本效益高的 MoE 模型（总参数 230B，激活参数 10B），在保持强大通用智能的同时，专为顶级编程和智能体性能打造。擅长多文件编辑、代码运行修复循环、测试验证和复杂工具链。",
  "ministral-3b-latest.description": "Ministral 3B 是 Mistral 推出的顶级边缘模型。",
  "ministral-8b-latest.description": "Ministral 8B 是 Mistral 推出的高性价比边缘模型。",
  "mistral-ai/Mistral-Large-2411.description": "Mistral 的旗舰模型，适用于需要大规模推理或专业化的复杂任务（如合成文本生成、代码生成、RAG 或智能体）。",
  "mistral-ai/Mistral-Nemo.description": "Mistral Nemo 是一款前沿大语言模型，在其参数规模下具备最先进的推理、世界知识和编程能力。",
  "mistral-ai/mistral-small-2503.description": "Mistral Small 适用于任何需要高效率和低延迟的语言任务。",
  "mistral-large-instruct.description": "Mistral-Large-Instruct-2407 是一款先进的密集型大语言模型，拥有 1230 亿参数，具备最先进的推理、知识和编程能力。",
  "mistral-large-latest.description": "Mistral Large 是旗舰模型，擅长多语言任务、复杂推理和代码生成，适用于高端应用。",
  "mistral-large.description": "Mixtral Large 是 Mistral 的旗舰模型，结合代码生成、数学和推理能力，支持 128K 上下文窗口。",
  "mistral-medium-latest.description": "Mistral Medium 3 以 8 倍更低的成本实现最先进性能，并简化企业部署。",
  "mistral-nemo-instruct.description": "Mistral-Nemo-Instruct-2407 是 Mistral-Nemo-Base-2407 的指令微调版本。",
  "mistral-nemo.description": "Mistral Nemo 是 Mistral AI 与 NVIDIA 联合开发的高效 120 亿参数模型。",
  "mistral-small-latest.description": "Mistral Small 是一款高性价比、快速且可靠的模型，适用于翻译、摘要和情感分析。",
  "mistral-small.description": "Mistral Small 适用于任何需要高效率和低延迟的语言任务。",
  "mistral.description": "Mistral 是 Mistral AI 推出的 70 亿参数模型，适用于多种语言任务。",
  "mistral/codestral-embed.description": "一款代码嵌入模型，用于嵌入代码库和仓库，支持编程助手。",
  "mistral/codestral.description": "Mistral Codestral 25.01 是一款最先进的编程模型，优化以实现低延迟和高频使用。支持 80 多种语言，擅长 FIM、代码修复和测试生成。",
  "mistral/devstral-small.description": "Devstral 是一款面向软件工程任务的智能体大语言模型，是软件工程智能体的强力选择。",
  "mistral/magistral-medium.description": "通过深度理解支持复杂思维，具备可追踪、可验证的透明推理能力。即使在任务中途，也能在多语言环境中保持高保真推理。",
  "mistral/magistral-small.description": "通过深度理解支持复杂思维，具备可追踪、可验证的透明推理能力。即使在任务中途，也能在多语言环境中保持高保真推理。",
  "mistral/ministral-3b.description": "一款紧凑高效的模型，适用于设备端任务，如助手和本地分析，提供低延迟性能。",
  "mistral/ministral-8b.description": "一款更强大的模型，推理速度更快、内存效率更高，适用于复杂工作流和高要求的边缘应用。",
  "mistral/mistral-embed.description": "一款通用文本嵌入模型，适用于语义搜索、相似度计算、聚类和 RAG 工作流。",
  "mistral/mistral-large.description": "Mistral Large 适用于需要强大推理或专业化的复杂任务，如合成文本生成、代码生成、RAG 或智能体。",
  "mistral/mistral-small.description": "Mistral Small 适用于分类、客户支持或文本生成等简单、可批处理任务，具备出色性能和实惠价格。",
  "mistral/mixtral-8x22b-instruct.description": "8x22B 指令模型。8x22B 是由 Mistral 提供服务的开源 MoE 模型。",
  "mistral/pixtral-12b.description": "一款具备图像理解与文本处理能力的 120 亿参数模型。",
  "mistral/pixtral-large.description": "Pixtral Large 是我们多模态系列的第二款模型，具备前沿级图像理解能力。可处理文档、图表和自然图像，同时保留 Mistral Large 2 的领先文本理解能力。",
  "mistralai/Mistral-7B-Instruct-v0.1.description": "Mistral（7B）Instruct 以其在多种语言任务中的强大表现而闻名。",
  "mistralai/Mistral-7B-Instruct-v0.2.description": "Mistral（7B）Instruct v0.2 提升了指令处理能力和结果准确性。",
  "mistralai/Mistral-7B-Instruct-v0.3.description": "Mistral（7B）Instruct v0.3 提供高效计算和强大的语言理解，适用于多种场景。",
  "mistralai/Mistral-7B-v0.1.description": "Mistral 7B 虽小巧但性能强劲，适合批处理和分类、文本生成等简单任务，具备扎实的推理能力。",
  "mistralai/Mixtral-8x22B-Instruct-v0.1.description": "Mixtral-8x22B Instruct（141B）是一款适用于重负载任务的超大语言模型。",
  "mistralai/Mixtral-8x7B-Instruct-v0.1.description": "Mixtral-8x7B Instruct（46.7B）为大规模数据处理提供高容量支持。",
  "mistralai/Mixtral-8x7B-v0.1.description": "Mixtral 8x7B 是一款稀疏 MoE 模型，提升推理速度，适用于多语言和代码生成任务。",
  "mistralai/mistral-nemo.description": "Mistral Nemo 是一款 73 亿参数模型，支持多语言，具备强大的编程能力。",
  "mixtral-8x7b-32768.description": "Mixtral 8x7B 提供容错并行计算能力，适用于复杂任务。",
  "mixtral.description": "Mixtral 是 Mistral AI 推出的 MoE 模型，采用开放权重，支持代码生成与语言理解。",
  "mixtral:8x22b.description": "Mixtral 是 Mistral AI 推出的 MoE 模型，采用开放权重，支持代码生成与语言理解。",
  "moonshot-v1-128k-vision-preview.description": "Kimi 视觉模型（包括 moonshot-v1-8k-vision-preview、moonshot-v1-32k-vision-preview、moonshot-v1-128k-vision-preview）可理解图像内容，如文字、颜色和物体形状。",
  "moonshot-v1-128k.description": "Moonshot V1 128K 提供超长上下文能力，支持最多 128,000 个 token 的文本生成，适用于科研、学术和长文档场景。",
  "moonshot-v1-32k-vision-preview.description": "Kimi 视觉模型（包括 moonshot-v1-8k-vision-preview、moonshot-v1-32k-vision-preview、moonshot-v1-128k-vision-preview）可理解图像内容，如文字、颜色和物体形状。",
  "moonshot-v1-32k.description": "Moonshot V1 32K 支持 32,768 个 token 的中等长度上下文，适用于内容创作、报告和聊天系统中的长文档与复杂对话。",
  "moonshot-v1-8k-vision-preview.description": "Kimi 视觉模型（包括 moonshot-v1-8k-vision-preview、moonshot-v1-32k-vision-preview、moonshot-v1-128k-vision-preview）可理解图像内容，如文字、颜色和物体形状。",
  "moonshot-v1-8k.description": "Moonshot V1 8K 针对短文本生成进行了优化，性能高效，支持 8,192 个 token，适用于短对话、笔记和快速内容生成。",
  "moonshot-v1-auto.description": "Moonshot V1 Auto 会根据当前上下文 token 使用情况自动选择合适的模型。",
  "moonshotai/Kimi-Dev-72B.description": "Kimi-Dev-72B 是一款开源代码大模型，结合大规模强化学习优化，能够生成稳健、可用于生产的补丁。在 SWE-bench Verified 上得分 60.4%，刷新开源模型在自动化软件工程任务（如修复 Bug 和代码审查）上的记录。",
  "moonshotai/Kimi-K2-Instruct-0905.description": "Kimi K2-Instruct-0905 是 Kimi K2 系列中最新最强的模型，采用 1 万亿总参数和 320 亿激活参数的顶级 MoE 架构。其主要特性包括更强的智能体编程能力，在基准测试和真实任务中表现显著提升，同时前端代码美观性和可用性也得到优化。",
  "moonshotai/Kimi-K2-Thinking.description": "Kimi K2 Thinking 是目前最强的开源思维模型，显著提升多步推理深度，并在 200–300 次连续调用中保持稳定工具使用能力，在 Humanity's Last Exam（HLE）、BrowseComp 等基准测试中创下新纪录。擅长编程、数学、逻辑和智能体场景。基于约 1 万亿参数的 MoE 架构，支持 256K 上下文窗口和工具调用。",
  "moonshotai/kimi-k2-0711.description": "Kimi K2 0711 是 Kimi 系列中的指令微调版本，适用于高质量代码生成和工具使用。",
  "moonshotai/kimi-k2-0905.description": "Kimi K2 0905 是一次更新，扩展了上下文和推理能力，并进行了编程优化。",
  "moonshotai/kimi-k2-instruct-0905.description": "kimi-k2-0905-preview 模型支持 256K 上下文窗口，具备更强的智能体编程能力、更精致实用的前端代码，以及更好的上下文理解能力。",
  "moonshotai/kimi-k2-thinking-turbo.description": "Kimi K2 Thinking Turbo 是 Kimi K2 Thinking 的高速版本，在保持深度推理能力的同时显著降低延迟。",
  "moonshotai/kimi-k2-thinking.description": "Kimi K2 Thinking 是 Moonshot 推出的推理模型，专为深度推理任务优化，具备通用智能体能力。",
  "moonshotai/kimi-k2.description": "Kimi K2 是 Moonshot AI 推出的超大规模 MoE 模型，拥有 1 万亿总参数和每次前向传播 320 亿激活参数，专为高级工具使用、推理和代码合成等智能体能力优化。",
  "morph/morph-v3-fast.description": "Morph 提供专用模型，将前沿模型（如 Claude 或 GPT-4o）建议的代码更改快速应用于现有文件，速度达 4500+ tokens/秒，是 AI 编程流程的最后一步，支持 16k 输入/输出。",
  "morph/morph-v3-large.description": "Morph 提供专用模型，将前沿模型（如 Claude 或 GPT-4o）建议的代码更改快速应用于现有文件，速度达 2500+ tokens/秒，是 AI 编程流程的最后一步，支持 16k 输入/输出。",
  "nousresearch/hermes-2-pro-llama-3-8b.description": "Hermes 2 Pro Llama 3 8B 是 Nous Hermes 2 的更新版本，采用最新内部开发的数据集训练。",
  "nvidia/Llama-3.1-Nemotron-70B-Instruct-HF.description": "Llama 3.1 Nemotron 70B 是 NVIDIA 定制的大语言模型，旨在提升有用性。在 Arena Hard、AlpacaEval 2 LC 和 GPT-4-Turbo MT-Bench 三项自动对齐基准测试中均排名第一（截至 2024 年 10 月 1 日）。该模型基于 Llama-3.1-70B-Instruct，通过 RLHF（REINFORCE）、Llama-3.1-Nemotron-70B-Reward 和 HelpSteer2-Preference 提示训练。",
  "nvidia/llama-3.1-nemotron-51b-instruct.description": "一款独特的语言模型，具备卓越的准确性与效率。",
  "nvidia/llama-3.1-nemotron-70b-instruct.description": "Llama-3.1-Nemotron-70B-Instruct 是 NVIDIA 定制的大语言模型，旨在提升模型响应的有用性。",
  "o1-mini.description": "比 o1-preview 更小更快，成本降低 80%，擅长代码生成和短上下文任务。",
  "o1-preview.description": "专注于高级推理和复杂问题解决，包括数学和科学，适用于需要深度上下文理解和自主工作流的应用。",
  "o1-pro.description": "o1 系列通过强化学习训练，具备先思考后作答的能力，能处理复杂推理任务。o1-pro 使用更多计算资源，提供更深入的思考和更高质量的回答。",
  "o1.description": "o1 是 OpenAI 推出的新型推理模型，支持文本+图像输入和文本输出，适用于需要广泛知识的复杂任务。具备 200K 上下文窗口，知识截止于 2023 年 10 月。",
  "o3-2025-04-16.description": "o3 是 OpenAI 推出的新型推理模型，支持文本+图像输入和文本输出，适用于需要广泛知识的复杂任务。",
  "o3-deep-research.description": "o3-deep-research 是我们最先进的深度研究模型，适用于复杂的多步骤任务。它可以通过 MCP 连接器访问您的数据并进行网页搜索。",
  "o3-mini.description": "o3-mini 是我们最新的小型推理模型，在保持与 o1-mini 相同成本和延迟的前提下，提供更高的智能表现。",
  "o3-pro-2025-06-10.description": "o3 Pro 是 OpenAI 推出的新一代推理模型，支持文本+图像输入和文本输出，适用于需要广泛知识的复杂任务。",
  "o3-pro.description": "o3-pro 使用更多计算资源以实现更深入的思考，持续提供更优质的答案；仅通过 Responses API 提供。",
  "o3.description": "o3 是一款功能强大的通用模型，在数学、科学、编程和视觉推理方面树立了新标杆。它擅长技术写作和指令执行，能够分析文本、代码和图像，解决多步骤问题。",
  "o4-mini-2025-04-16.description": "o4-mini 是 OpenAI 的推理模型，支持文本+图像输入和文本输出，适用于需要广泛知识的复杂任务，具备 200K 上下文窗口。",
  "o4-mini-deep-research.description": "o4-mini-deep-research 是一款更快速、更经济的深度研究模型，适用于复杂的多步骤研究任务。它可以进行网页搜索，并通过 MCP 连接器访问您的数据。",
  "o4-mini.description": "o4-mini 是最新的小型 o 系列模型，专为快速、高效的推理任务优化，在编程和视觉任务中表现出色。",
  "open-codestral-mamba.description": "Codestral Mamba 是一款专注于代码生成的 Mamba 2 语言模型，支持高级编程与推理任务。",
  "open-mistral-7b.description": "Mistral 7B 是一款紧凑但高性能的模型，适合批量处理和分类、文本生成等简单任务，具备良好的推理能力。",
  "open-mistral-nemo.description": "Mistral Nemo 是与 Nvidia 联合开发的 12B 模型，在推理和编程方面表现强劲，易于集成。",
  "open-mixtral-8x22b.description": "Mixtral 8x22B 是一款大型 MoE 模型，适用于复杂任务，具备强大的推理能力和更高的吞吐量。",
  "open-mixtral-8x7b.description": "Mixtral 8x7B 是一款稀疏 MoE 模型，提升了推理速度，适用于多语言和代码生成任务。",
  "openai/gpt-3.5-turbo-instruct.description": "具备 GPT-3 时代模型的类似能力，兼容传统补全接口而非聊天接口。",
  "openai/gpt-3.5-turbo.description": "OpenAI 最具性价比的 GPT-3.5 模型，优化用于聊天，同时在传统补全任务中也表现出色。",
  "openai/gpt-4-turbo.description": "OpenAI 的 gpt-4-turbo 拥有广泛的通识知识和专业领域能力，能够理解复杂的自然语言指令，并准确解决难题。知识截止时间为 2023 年 4 月，支持 128K 上下文窗口。",
  "openai/gpt-4.1-mini.description": "GPT-4.1 Mini 提供更低延迟和更高性价比，适用于中等上下文任务。",
  "openai/gpt-4.1-nano.description": "GPT-4.1 Nano 是一款超低成本、低延迟的模型，适用于高频短对话或分类任务。",
  "openai/gpt-4.1.description": "GPT-4.1 系列提供更大的上下文窗口和更强的工程与推理能力。",
  "openai/gpt-4o-mini.description": "GPT-4o-mini 是一款快速的小型 GPT-4o 变体，适用于低延迟的多模态应用场景。",
  "openai/gpt-4o.description": "GPT-4o 系列是 OpenAI 的 Omni 模型，支持文本+图像输入和文本输出。",
  "openai/gpt-5-chat.description": "GPT-5 Chat 是 GPT-5 的对话优化版本，具备更低延迟和更强交互性。",
  "openai/gpt-5-codex.description": "GPT-5-Codex 是 GPT-5 的代码优化版本，适用于大规模代码工作流。",
  "openai/gpt-5-mini.description": "GPT-5 Mini 是一款小型 GPT-5 变体，适用于低延迟、低成本场景。",
  "openai/gpt-5-nano.description": "GPT-5 Nano 是超小型变体，适用于对成本和延迟要求极高的场景。",
  "openai/gpt-5-pro.description": "GPT-5 Pro 是 OpenAI 的旗舰模型，具备更强的推理、代码生成能力和企业级功能，支持测试时路由和更严格的安全策略。",
  "openai/gpt-5.1-chat.description": "GPT-5.1 Chat 是 GPT-5.1 系列中轻量级成员，优化用于低延迟对话，同时保持强大的推理和指令执行能力。",
  "openai/gpt-5.1-codex-mini.description": "GPT-5.1-Codex-Mini 是 GPT-5.1-Codex 的小型快速版本，适用于对延迟和成本敏感的编程场景。",
  "openai/gpt-5.1-codex.description": "GPT-5.1-Codex 是 GPT-5.1 的编程优化版本，适用于大型重构、复杂调试和长时间自主编程任务。",
  "openai/gpt-5.1.description": "GPT-5.1 是 GPT-5 系列的最新旗舰，在通用推理、指令执行和对话自然性方面相较 GPT-5 有显著提升，适用于广泛任务。",
  "openai/gpt-5.2-chat.description": "GPT-5.2 Chat 是 ChatGPT 的变体，用于体验最新的对话改进。",
  "openai/gpt-5.2-pro.description": "GPT-5.2 Pro：更智能、更精准的 GPT-5.2 变体（仅限 Responses API），适用于更复杂的问题和更长的多轮推理。",
  "openai/gpt-5.2.description": "GPT-5.2 是一款旗舰模型，专为编程和智能体工作流设计，具备更强的推理能力和长上下文处理能力。",
  "openai/gpt-5.description": "GPT-5 是 OpenAI 的高性能模型，适用于各种生产和研究任务。",
  "openai/gpt-oss-120b.description": "一款功能强大的通用大语言模型，具备强大且可控的推理能力。",
  "openai/gpt-oss-20b.description": "一款紧凑的开源权重语言模型，优化用于低延迟和资源受限环境，包括本地和边缘部署。",
  "openai/o1-mini.description": "o1-mini 是一款快速、经济高效的推理模型，专为编程、数学和科学任务设计。支持 128K 上下文，知识截止时间为 2023 年 10 月。",
  "openai/o1-preview.description": "o1 是 OpenAI 推出的新型推理模型，适用于需要广泛知识的复杂任务。支持 128K 上下文，知识截止时间为 2023 年 10 月。",
  "openai/o1.description": "OpenAI o1 是一款旗舰推理模型，专为需要深度思考的复杂问题设计，在多步骤任务中展现出强大的推理能力和更高的准确性。",
  "openai/o3-mini-high.description": "o3-mini（高推理）在保持与 o1-mini 相同成本和延迟的前提下，提供更高的智能表现。",
  "openai/o3-mini.description": "o3-mini 是 OpenAI 最新的小型推理模型，在保持与 o1-mini 相同成本和延迟的前提下，提供更高的智能表现。",
  "openai/o3.description": "OpenAI o3 是最强大的推理模型，在编程、数学、科学和视觉感知方面树立了新标准。它擅长处理复杂、多维度的问题，尤其在图像、图表和示意图分析方面表现出色。",
  "openai/o4-mini-high.description": "o4-mini 高推理版本，优化用于快速、高效的推理任务，具备强大的编程和视觉能力。",
  "openai/o4-mini.description": "OpenAI o4-mini 是一款小型高效的推理模型，适用于低延迟场景。",
  "openai/text-embedding-3-large.description": "OpenAI 最强大的嵌入模型，适用于英文和非英文任务。",
  "openai/text-embedding-3-small.description": "OpenAI 提升性能的 ada 嵌入模型变体。",
  "openai/text-embedding-ada-002.description": "OpenAI 的旧版文本嵌入模型。",
  "openrouter/auto.description": "根据上下文长度、主题和复杂度，自动将请求路由至 Llama 3 70B Instruct、Claude 3.5 Sonnet（自我审查）或 GPT-4o。",
  "perplexity/sonar-pro.description": "Perplexity 的旗舰产品，具备搜索支撑，支持高级查询和追问。",
  "perplexity/sonar-reasoning-pro.description": "专注推理的高级模型，输出带搜索增强的思维链，每次请求可包含多个搜索查询。",
  "perplexity/sonar-reasoning.description": "专注推理的模型，输出详细的搜索支撑解释和思维链。",
  "perplexity/sonar.description": "Perplexity 的轻量级产品，具备搜索支撑，速度更快、成本更低于 Sonar Pro。",
  "phi3.description": "Phi-3 是微软推出的轻量级开源模型，适用于高效集成和大规模推理。",
  "phi3:14b.description": "Phi-3 是微软推出的轻量级开源模型，适用于高效集成和大规模推理。",
  "pixtral-12b-2409.description": "Pixtral 擅长图表/图像理解、文档问答、多模态推理和指令遵循。支持原始分辨率/比例图像输入，能在 128K 上下文窗口中处理任意数量图像。",
  "pixtral-large-latest.description": "Pixtral Large 是基于 Mistral Large 2 构建的 124B 参数开源多模态模型，是我们多模态系列中的第二款，具备前沿级图像理解能力。",
  "pro-128k.description": "Spark Pro 128K 提供超大上下文容量，支持最多 128K 上下文，适用于需要全文分析和长距离逻辑连贯性的长文档，具备流畅逻辑和复杂讨论中的多样引用能力。",
  "pro-deepseek-r1.description": "企业专用服务模型，支持并发打包使用。",
  "pro-deepseek-v3.description": "企业专用服务模型，支持并发打包使用。",
  "qianfan-70b.description": "千帆 70B 是一款中文大模型，适用于高质量生成和复杂推理任务。",
  "qianfan-8b.description": "千帆 8B 是一款中等规模通用模型，在生成质量与成本之间取得平衡，适用于文本生成和问答任务。",
  "qianfan-agent-intent-32k.description": "千帆 Agent Intent 32K 专注于意图识别和智能体编排，支持长上下文。",
  "qianfan-agent-lite-8k.description": "千帆 Agent Lite 8K 是一款轻量级智能体模型，适用于低成本多轮对话和工作流。",
  "qianfan-check-vl.description": "千帆 Check VL 是一款多模态内容审核模型，适用于图文合规性识别与审核任务。",
  "qianfan-composition.description": "千帆 Composition 是一款多模态创作模型，支持图文混合理解与生成。",
  "qianfan-engcard-vl.description": "千帆 EngCard VL 是一款专注于英文场景的多模态识别模型。",
  "qianfan-lightning-128b-a19b.description": "千帆 Lightning 128B A19B 是一款高性能中文通用模型，擅长复杂问答与大规模推理任务。",
  "qianfan-llama-vl-8b.description": "千帆 Llama VL 8B 是基于 Llama 的多模态模型，适用于通用图文理解任务。",
  "qianfan-multipicocr.description": "千帆 MultiPicOCR 是一款多图 OCR 模型，支持跨图像的文本检测与识别。",
  "qianfan-qi-vl.description": "千帆 QI VL 是一款多模态问答模型，适用于复杂图文场景下的精准检索与问答。",
  "qianfan-singlepicocr.description": "千帆 SinglePicOCR 是一款单图 OCR 模型，具备高精度字符识别能力。",
  "qianfan-vl-70b.description": "千帆 VL 70B 是一款大型视觉语言模型，擅长复杂图文理解任务。",
  "qianfan-vl-8b.description": "千帆 VL 8B 是一款轻量级视觉语言模型，适用于日常图文问答与分析。",
  "qvq-72b-preview.description": "QVQ-72B-Preview 是 Qwen 推出的实验性研究模型，专注于提升视觉推理能力。",
  "qvq-max.description": "Qwen QVQ 视觉推理模型支持视觉输入与链式思维输出，在数学、编程、视觉分析、创意及通用任务中表现出色。",
  "qvq-plus.description": "视觉推理模型，支持视觉输入与链式思维输出。qvq-plus 系列延续 qvq-max，推理更快，质量与成本更优平衡。",
  "qwen-3-32b.description": "Qwen 3 32B：多语言与编程任务表现强劲，适用于中型生产场景。",
  "qwen-coder-plus.description": "Qwen 编程模型。",
  "qwen-coder-turbo-latest.description": "Qwen 编程模型。",
  "qwen-coder-turbo.description": "Qwen 编程模型。",
  "qwen-flash.description": "Qwen Flash 是最快、成本最低的模型，适合处理简单任务。",
  "qwen-image-edit.description": "Qwen Image Edit 是一款图像到图像的编辑模型，基于输入图像与文本提示进行精准调整与创意变换。",
  "qwen-image.description": "Qwen-Image 是一款通用图像生成模型，支持多种艺术风格，具备强大的中英文复杂文本渲染能力，支持多行排版、段落级文本与复杂图文细节。",
  "qwen-long.description": "超大规模 Qwen 模型，支持长上下文与跨多文档场景的对话。",
  "qwen-math-plus-latest.description": "Qwen Math 是一款专注于数学问题求解的语言模型。",
  "qwen-math-plus.description": "Qwen Math 是一款专注于数学问题求解的语言模型。",
  "qwen-math-turbo-latest.description": "Qwen Math 是一款专注于数学问题求解的语言模型。",
  "qwen-math-turbo.description": "Qwen Math 是一款专注于数学问题求解的语言模型。",
  "qwen-max.description": "千亿级超大 Qwen 模型，支持中文、英文等多语言，是当前 Qwen2.5 产品背后的 API 模型。",
  "qwen-omni-turbo.description": "Qwen-Omni 模型支持多模态输入（视频、音频、图像、文本）并输出音频与文本。",
  "qwen-plus.description": "增强版超大 Qwen 模型，支持中文、英文等多语言。",
  "qwen-turbo.description": "Qwen Turbo 将不再更新，建议替换为 Qwen Flash。超大 Qwen 模型，支持中文、英文等多语言。",
  "qwen-vl-chat-v1.description": "Qwen VL 支持灵活交互，包括多图输入、多轮问答与创意任务。",
  "qwen-vl-max-latest.description": "超大 Qwen 视觉语言模型。相比增强版，进一步提升视觉推理与指令跟随能力，具备更强感知与认知能力。",
  "qwen-vl-max.description": "超大 Qwen 视觉语言模型。相比增强版，进一步提升视觉推理与指令跟随能力，具备更强视觉感知与认知能力。",
  "qwen-vl-ocr.description": "Qwen OCR 是一款用于文档、表格、考试图片和手写文字的文本提取模型，支持中文、英文、法语、日语、韩语、德语、俄语、意大利语、越南语和阿拉伯语。",
  "qwen-vl-plus-latest.description": "增强版大规模 Qwen 视觉语言模型，在细节和文本识别方面有显著提升，支持超过百万像素分辨率和任意宽高比。",
  "qwen-vl-plus.description": "增强版大规模 Qwen 视觉语言模型，在细节和文本识别方面有显著提升，支持超过百万像素分辨率和任意宽高比。",
  "qwen-vl-v1.description": "基于 Qwen-7B 预训练模型，加入视觉模块，支持 448 分辨率图像输入。",
  "qwen/qwen-2-7b-instruct.description": "Qwen2 是全新的 Qwen 大语言模型系列。Qwen2 7B 是一款基于 Transformer 架构的模型，擅长语言理解、多语言处理、编程、数学和推理。",
  "qwen/qwen-2-7b-instruct:free.description": "Qwen2 是一个全新的大语言模型系列，具备更强的理解与生成能力。",
  "qwen/qwen-2-vl-72b-instruct.description": "Qwen2-VL 是 Qwen-VL 的最新版本，在 MathVista、DocVQA、RealWorldQA 和 MTVQA 等视觉基准测试中达到业界领先水平。支持 20 分钟以上视频的高质量问答、对话和内容创作，具备复杂推理与决策能力，可与移动设备和机器人集成，根据视觉上下文和文本指令执行操作。除中英文外，还支持图像中的多种语言文本识别，包括大多数欧洲语言、日语、韩语、阿拉伯语和越南语。",
  "qwen/qwen-2.5-72b-instruct.description": "Qwen2.5-72B-Instruct 是阿里云最新发布的大语言模型之一。该 72B 模型在编程和数学方面有显著提升，支持超过 29 种语言（包括中英文），在指令理解、结构化数据处理和结构化输出（尤其是 JSON）方面表现优异。",
  "qwen/qwen2.5-32b-instruct.description": "Qwen2.5-32B-Instruct 是阿里云最新发布的大语言模型之一。该 32B 模型在编程和数学方面有显著提升，支持超过 29 种语言（包括中英文），在指令理解、结构化数据处理和结构化输出（尤其是 JSON）方面表现优异。",
  "qwen/qwen2.5-7b-instruct.description": "一款中英文双语大语言模型，覆盖语言、编程、数学和推理任务。",
  "qwen/qwen2.5-coder-32b-instruct.description": "一款面向主流编程语言的高级代码生成、推理与修复模型。",
  "qwen/qwen2.5-coder-7b-instruct.description": "一款中型强力代码模型，支持 32K 上下文，擅长多语言编程。",
  "qwen/qwen3-14b.description": "Qwen3-14B 是一款适用于通用推理与对话场景的 14B 模型。",
  "qwen/qwen3-14b:free.description": "Qwen3-14B 是一款拥有 14.8B 参数的稠密因果语言模型，专为复杂推理与高效对话设计。可在数学、编程、逻辑等“思考模式”与通用对话“非思考模式”之间切换。针对指令跟随、工具使用和创意写作进行了微调，支持 100 多种语言和方言。原生支持 32K 上下文，使用 YaRN 可扩展至 131K。",
  "qwen/qwen3-235b-a22b-2507.description": "Qwen3-235B-A22B-Instruct-2507 是 Qwen3 系列的 Instruct 版本，兼顾多语言指令使用与长上下文场景。",
  "qwen/qwen3-235b-a22b-thinking-2507.description": "Qwen3-235B-A22B-Thinking-2507 是 Qwen3 的思考版本，专为复杂数学与推理任务强化。",
  "qwen/qwen3-235b-a22b.description": "Qwen3-235B-A22B 是一款拥有 235B 参数的 MoE 模型，每次前向激活 22B 参数。可在复杂推理、数学、编程的“思考模式”与高效对话的“非思考模式”之间切换。具备强大的推理能力、多语言支持（100+ 种语言/方言）、高级指令跟随与工具使用能力。原生支持 32K 上下文，使用 YaRN 可扩展至 131K。",
  "qwen/qwen3-235b-a22b:free.description": "Qwen3-235B-A22B 是一款拥有 235B 参数的 MoE 模型，每次前向激活 22B 参数。可在复杂推理、数学、编程的“思考模式”与高效对话的“非思考模式”之间切换。具备强大的推理能力、多语言支持（100+ 种语言/方言）、高级指令跟随与工具使用能力。原生支持 32K 上下文，使用 YaRN 可扩展至 131K。",
  "qwen/qwen3-30b-a3b.description": "Qwen3 是最新一代 Qwen 大语言模型，采用稠密与 MoE 架构，擅长推理、多语言支持和高级智能体任务。其独特的“思考模式”与“非思考模式”切换能力，确保在多场景下实现高质量表现。\n\nQwen3 显著超越 QwQ 和 Qwen2.5 等前代模型，在数学、编程、常识推理、创意写作和交互对话方面表现卓越。Qwen3-30B-A3B 版本拥有 30.5B 参数（3.3B 激活），48 层，128 个专家（每任务激活 8 个），支持使用 YaRN 扩展至 131K 上下文，树立开源模型新标杆。",
  "qwen/qwen3-30b-a3b:free.description": "Qwen3 是最新一代 Qwen 大语言模型，采用稠密与 MoE 架构，擅长推理、多语言支持和高级智能体任务。其独特的“思考模式”与“非思考模式”切换能力，确保在多场景下实现高质量表现。\n\nQwen3 显著超越 QwQ 和 Qwen2.5 等前代模型，在数学、编程、常识推理、创意写作和交互对话方面表现卓越。Qwen3-30B-A3B 版本拥有 30.5B 参数（3.3B 激活），48 层，128 个专家（每任务激活 8 个），支持使用 YaRN 扩展至 131K 上下文，树立开源模型新标杆。",
  "qwen/qwen3-32b.description": "Qwen3-32B 是一款稠密的 32.8B 参数因果语言模型，专为复杂推理与高效对话优化。可在数学、编程、逻辑的“思考模式”与通用对话的“非思考模式”之间切换。擅长指令跟随、工具使用和创意写作，支持 100 多种语言和方言。原生支持 32K 上下文，使用 YaRN 可扩展至 131K。",
  "qwen/qwen3-32b:free.description": "Qwen3-32B 是一款稠密的 32.8B 参数因果语言模型，专为复杂推理与高效对话优化。可在数学、编程、逻辑的“思考模式”与通用对话的“非思考模式”之间切换。擅长指令跟随、工具使用和创意写作，支持 100 多种语言和方言。原生支持 32K 上下文，使用 YaRN 可扩展至 131K。",
  "qwen/qwen3-8b:free.description": "Qwen3-8B 是一款稠密的 8.2B 参数因果语言模型，专为推理密集型任务与高效对话设计。可在数学、编程、逻辑的“思考模式”与通用对话的“非思考模式”之间切换。针对指令跟随、智能体集成和创意写作进行了微调，支持 100 多种语言和方言。原生支持 32K 上下文，使用 YaRN 可扩展至 131K。",
  "qwen/qwen3-coder-plus.description": "Qwen3-Coder-Plus 是 Qwen 系列的代码智能体模型，优化了复杂工具使用和长时间会话能力。",
  "qwen/qwen3-coder.description": "Qwen3-Coder 是 Qwen3 的代码生成系列，擅长长文档代码理解与生成。",
  "qwen/qwen3-max-preview.description": "Qwen3 Max（预览版）是面向高级推理与工具集成的 Max 版本。",
  "qwen/qwen3-max.description": "Qwen3 Max 是 Qwen3 系列的高端推理模型，专注于多语言推理与工具集成。",
  "qwen/qwen3-vl-plus.description": "Qwen3 VL-Plus 是 Qwen3 的视觉增强版本，具备更强的多模态推理与视频处理能力。",
  "qwen2.5-14b-instruct-1m.description": "Qwen2.5 开源 72B 模型。",
  "qwen2.5-14b-instruct.description": "Qwen2.5 开源 14B 模型。",
  "qwen2.5-32b-instruct.description": "Qwen2.5 开源 32B 模型。",
  "qwen2.5-72b-instruct.description": "Qwen2.5 开源 72B 模型。",
  "qwen2.5-7b-instruct.description": "Qwen2.5 7B Instruct 是一款成熟的开源指令模型，适用于多场景对话与生成任务。",
  "qwen2.5-coder-1.5b-instruct.description": "开源 Qwen 编程模型。",
  "qwen2.5-coder-14b-instruct.description": "开源 Qwen 编程模型。",
  "qwen2.5-coder-32b-instruct.description": "开源 Qwen 编程模型。",
  "qwen2.5-coder-7b-instruct.description": "开源 Qwen 编程模型。",
  "qwen2.5-coder-instruct.description": "Qwen2.5-Coder 是 Qwen 系列最新的编程大模型（前身为 CodeQwen）。",
  "qwen2.5-instruct.description": "Qwen2.5 是 Qwen 系列最新的大语言模型，包含基础与指令微调模型，参数规模从 0.5B 到 72B 不等。",
  "qwen2.5-math-1.5b-instruct.description": "Qwen-Math 在数学问题求解方面表现出色。",
  "qwen2.5-math-72b-instruct.description": "Qwen-Math 在数学问题求解方面表现出色。",
  "qwen2.5-math-7b-instruct.description": "Qwen-Math 在数学问题求解方面表现出色。",
  "qwen2.5-omni-7b.description": "Qwen-Omni 模型支持多模态输入（视频、音频、图像、文本）并输出音频与文本。",
  "qwen2.5-vl-32b-instruct.description": "Qwen2.5 VL 32B Instruct 是一款开源多模态模型，适合私有部署与多场景应用。",
  "qwen2.5-vl-72b-instruct.description": "提升了指令跟随、数学、问题求解与编程能力，具备更强的通用物体识别能力。支持跨格式视觉元素精准定位、最长 10 分钟视频理解（秒级事件定位）、时间顺序与速度理解，以及可解析与定位的操作系统或移动端代理控制。具备强大的关键信息提取与 JSON 输出能力。此为 72B 系列中最强版本。",
  "qwen2.5-vl-7b-instruct.description": "Qwen2.5 VL 7B Instruct 是一款轻量级多模态模型，兼顾部署成本与识别能力。",
  "qwen2.5-vl-instruct.description": "Qwen2.5-VL 是 Qwen 系列最新的视觉语言模型。",
  "qwen2.5.description": "Qwen2.5 是阿里巴巴新一代大语言模型，在多种应用场景中表现出色。",
  "qwen2.5:0.5b.description": "Qwen2.5 是阿里巴巴新一代大语言模型，在多种应用场景中表现出色。",
  "qwen2.5:1.5b.description": "Qwen2.5 是阿里巴巴新一代大语言模型，在多种应用场景中表现出色。",
  "qwen2.5:72b.description": "Qwen2.5 是阿里巴巴新一代大语言模型，在多种应用场景中表现出色。",
  "qwen2.description": "Qwen2 是阿里巴巴新一代大语言模型，在多种应用场景中表现出色。",
  "qwen2:0.5b.description": "Qwen2 是阿里巴巴新一代大语言模型，在多种应用场景中表现出色。",
  "qwen2:1.5b.description": "Qwen2 是阿里巴巴新一代大语言模型，在多种应用场景中表现出色。",
  "qwen2:72b.description": "Qwen2 是阿里巴巴新一代大语言模型，在多种应用场景中表现出色。",
  "qwen3-0.6b.description": "Qwen3 0.6B 是一款入门级模型，适用于简单推理与资源受限环境。",
  "qwen3-1.7b.description": "Qwen3 1.7B 是一款超轻量模型，适合边缘设备部署。",
  "qwen3-14b.description": "Qwen3 14B 是一款中型模型，适用于多语言问答与文本生成。",
  "qwen3-235b-a22b-instruct-2507.description": "Qwen3 235B A22B Instruct 2507 是一款旗舰级指令模型，适用于广泛的生成与推理任务。",
  "qwen3-235b-a22b-thinking-2507.description": "Qwen3 235B A22B Thinking 2507 是一款超大规模思维模型，专注于复杂推理任务。",
  "qwen3-235b-a22b.description": "Qwen3 是新一代通义千问模型，在推理能力、通用能力、智能体能力与多语言表现方面实现重大突破，支持思维模式切换。",
  "qwen3-30b-a3b-instruct-2507.description": "Qwen3 30B A3B Instruct 2507 是一款中大型指令模型，适用于高质量生成与问答任务。",
  "qwen3-30b-a3b-thinking-2507.description": "Qwen3 30B A3B Thinking 2507 是一款中大型思维模型，兼顾准确性与成本。",
  "qwen3-30b-a3b.description": "Qwen3 30B A3B 是一款中大型通用模型，平衡成本与质量。",
  "qwen3-32b.description": "Qwen3 32B 适用于需要更强理解能力的通用任务。",
  "qwen3-4b.description": "Qwen3 4B 适用于中小型应用与本地推理。",
  "qwen3-8b.description": "Qwen3 8B 是一款轻量模型，支持灵活部署与高并发任务。",
  "qwen3-coder-30b-a3b-instruct.description": "开源 Qwen 编程模型。最新的 qwen3-coder-30b-a3b-instruct 基于 Qwen3，具备强大的编程代理能力、工具使用与环境交互能力，编程表现优异，通用能力扎实。",
  "qwen3-coder-480b-a35b-instruct.description": "Qwen3 Coder 480B A35B Instruct 是一款旗舰级编程模型，支持多语言编程与复杂代码理解。",
  "qwen3-coder-flash.description": "Qwen 编程模型。最新的 Qwen3-Coder 系列基于 Qwen3，具备强大的编程代理能力、工具使用与环境交互能力，编程表现优异，通用能力扎实。",
  "qwen3-coder-plus.description": "Qwen 编程模型。最新的 Qwen3-Coder 系列基于 Qwen3，具备强大的编程代理能力、工具使用与环境交互能力，编程表现优异，通用能力扎实。",
  "qwen3-coder:480b.description": "阿里巴巴高性能长上下文模型，适用于代理与编程任务。",
  "qwen3-max-2026-01-23.description": "Qwen3 Max 系列在通用能力、中英文理解、复杂指令执行、主观开放任务、多语言能力与工具使用方面相较 2.5 系列有显著提升，幻觉更少。最新版本在智能体编程与工具使用方面优于 qwen3-max-preview，达到领域 SOTA，面向更复杂的智能体需求。",
  "qwen3-max-preview.description": "Qwen 最强模型预览版，适用于复杂多步任务，支持思维能力。",
  "qwen3-max.description": "Qwen3 Max 系列在通用能力、中英文理解、复杂指令跟随、主观开放任务、多语言能力与工具使用方面相较 2.5 系列有大幅提升，幻觉更少。最新版本在编程代理与工具使用方面优于 qwen3-max-preview，达到领域 SOTA，面向更复杂的代理需求。",
  "qwen3-next-80b-a3b-instruct.description": "下一代 Qwen3 非推理开源模型。相比上一版本（Qwen3-235B-A22B-Instruct-2507），在中文理解、逻辑推理和文本生成方面均有显著提升。",
  "qwen3-next-80b-a3b-thinking.description": "Qwen3 Next 80B A3B Thinking 是面向复杂任务的旗舰推理模型版本。",
  "qwen3-omni-flash.description": "Qwen-Omni 支持文本、图像、音频和视频的多模态输入，输出为文本或语音。具备多种自然语音风格，支持多语言及方言语音，适用于写作、视觉识别和语音助手等场景。",
  "qwen3-vl-235b-a22b-instruct.description": "Qwen3 VL 235B A22B Instruct 是面向高要求理解与创作任务的旗舰多模态模型。",
  "qwen3-vl-235b-a22b-thinking.description": "Qwen3 VL 235B A22B Thinking 是面向复杂多模态推理与规划的旗舰推理版本。",
  "qwen3-vl-30b-a3b-instruct.description": "Qwen3 VL 30B A3B Instruct 是一款在准确性与推理性能之间取得平衡的大型多模态模型。",
  "qwen3-vl-30b-a3b-thinking.description": "Qwen3 VL 30B A3B Thinking 是面向复杂多模态任务的深度推理版本。",
  "qwen3-vl-32b-instruct.description": "Qwen3 VL 32B Instruct 是一款多模态指令微调模型，适用于高质量图文问答与创作。",
  "qwen3-vl-32b-thinking.description": "Qwen3 VL 32B Thinking 是一款深度推理多模态模型，擅长复杂推理与长链分析。",
  "qwen3-vl-8b-instruct.description": "Qwen3 VL 8B Instruct 是一款轻量级多模态模型，适用于日常视觉问答与应用集成。",
  "qwen3-vl-8b-thinking.description": "Qwen3 VL 8B Thinking 是一款多模态思维链模型，适用于细致的视觉推理任务。",
  "qwen3-vl-flash.description": "Qwen3 VL Flash：轻量级、高速推理版本，适用于对延迟敏感或高并发请求。",
  "qwen3-vl-plus.description": "Qwen VL 是一款具备视觉理解能力的文本生成模型，支持 OCR、摘要与推理，可从商品图片中提取属性或解决图像问题。",
  "qwen3.description": "Qwen3 是阿里巴巴推出的下一代大语言模型，在多种应用场景中表现出色。",
  "qwq-32b-preview.description": "QwQ 是 Qwen 推出的实验性研究模型，专注于推理能力的提升。",
  "qwq-32b.description": "QwQ 是 Qwen 系列中的推理模型。相比标准指令微调模型，具备更强的思维与推理能力，显著提升下游复杂任务表现。QwQ-32B 是一款中型推理模型，性能可媲美 DeepSeek-R1 和 o1-mini 等顶级模型。",
  "qwq-plus.description": "QwQ 推理模型基于 Qwen2.5 训练，并通过强化学习大幅提升推理能力。在数学/代码（AIME 24/25、LiveCodeBench）及通用评测（IFEval、LiveBench）中达到 DeepSeek-R1 的水平。",
  "qwq.description": "QwQ 是 Qwen 系列中的推理模型。相比标准指令微调模型，具备更强的思维与推理能力，显著提升下游复杂任务表现。QwQ-32B 是一款中型推理模型，性能可媲美 DeepSeek-R1 和 o1-mini 等顶级模型。",
  "qwq_32b.description": "Qwen 系列中的中型推理模型。相比标准指令微调模型，QwQ 的思维与推理能力显著提升下游复杂任务表现。",
  "r1-1776.description": "R1-1776 是 DeepSeek R1 的后训练版本，旨在提供无审查、无偏见的真实信息。",
  "solar-mini-ja.description": "Solar Mini (Ja) 是 Solar Mini 的日语增强版本，同时保持在英语和韩语中的高效强性能。",
  "solar-mini.description": "Solar Mini 是一款紧凑型大语言模型，性能超越 GPT-3.5，具备强大的多语言能力，支持英语和韩语，提供高效的小体积解决方案。",
  "solar-pro.description": "Solar Pro 是 Upstage 推出的高智能大语言模型，专注于单 GPU 上的指令跟随任务，IFEval 得分超过 80。目前支持英语，完整版本计划于 2024 年 11 月发布，届时将扩展语言支持并提升上下文长度。",
  "sonar-deep-research.description": "Deep Research 提供专家级的深度研究，并将其整合为易于理解和可操作的报告。",
  "sonar-pro.description": "一款高级搜索产品，支持复杂查询与后续问题的搜索溯源。",
  "sonar-reasoning-pro.description": "一款高级搜索产品，支持复杂查询与后续问题的搜索溯源。",
  "sonar-reasoning.description": "一款高级搜索产品，支持复杂查询与后续问题的搜索溯源。",
  "sonar.description": "一款轻量级搜索溯源产品，速度更快、成本更低，适用于对资源敏感的场景。",
  "spark-x.description": "X1.5 更新内容：（1）新增由 `thinking` 字段控制的动态思维模式；（2）支持 64K 输入与 64K 输出的超长上下文；（3）支持 FunctionCall 功能。",
  "stable-diffusion-3-medium.description": "Stability AI 最新的文本生成图像模型。该版本显著提升图像质量、文本理解与风格多样性，能更准确地解析复杂自然语言提示并生成更精确多样的图像。",
  "stable-diffusion-3.5-large-turbo.description": "stable-diffusion-3.5-large-turbo 通过对 stable-diffusion-3.5-large 应用对抗扩散蒸馏（ADD）技术，实现更快的生成速度。",
  "stable-diffusion-3.5-large.description": "stable-diffusion-3.5-large 是一款拥有 8 亿参数的 MMDiT 文本生成图像模型，具备卓越的图像质量与提示对齐能力，支持百万像素图像，并可高效运行于消费级硬件。",
  "stable-diffusion-v1.5.description": "stable-diffusion-v1.5 基于 v1.2 检查点初始化，并在 512x512 分辨率下对 \"laion-aesthetics v2 5+\" 数据集进行 595k 步微调，通过减少 10% 文本条件依赖提升无分类器引导采样效果。",
  "stable-diffusion-xl-base-1.0.description": "Stability AI 开源的文本生成图像模型，具备行业领先的创意图像生成能力。具备强指令理解能力，支持反向提示定义，实现精确生成。",
  "stable-diffusion-xl.description": "stable-diffusion-xl 相较 v1.5 有重大改进，达到开源文本生成图像模型的顶级水平。改进包括 3 倍大的 UNet 主干网络、图像质量优化模块及更高效的训练技术。",
  "step-1-128k.description": "在性能与成本之间取得平衡，适用于通用场景。",
  "step-1-256k.description": "支持超长上下文，适合长文档分析。",
  "step-1-32k.description": "支持中等长度对话，适用于多种场景。",
  "step-1-8k.description": "小型模型，适合轻量级任务。",
  "step-1-flash.description": "高速模型，适用于实时聊天场景。",
  "step-1.5v-mini.description": "具备强大视频理解能力。",
  "step-1o-turbo-vision.description": "图像理解能力强，在数学与编程方面优于 1o。体积更小，输出更快。",
  "step-1o-vision-32k.description": "图像理解能力强，视觉表现优于 Step-1V 系列。",
  "step-1v-32k.description": "支持视觉输入，实现更丰富的多模态交互。",
  "step-1v-8k.description": "小型视觉模型，适用于基础图文任务。",
  "step-1x-edit.description": "专注于图像编辑的模型，可根据用户提供的图像与文本进行修改与增强。支持多种输入格式，包括文本描述与示例图像，生成符合用户意图的编辑结果。",
  "step-1x-medium.description": "具备强大图像生成能力，支持中文提示输入，能更好理解中文语义并转化为视觉特征，实现高分辨率、高质量图像生成，并支持一定程度的风格迁移。",
  "step-2-16k-exp.description": "Step-2 实验版本，包含最新功能与持续更新。不建议用于生产环境。",
  "step-2-16k.description": "支持大上下文交互，适用于复杂对话。",
  "step-2-mini.description": "基于下一代自研 MFA 注意力架构构建，在大幅降低成本的同时实现 Step-1 级别效果，具备更高吞吐与更低延迟，适用于通用任务，编程能力强。",
  "step-2x-large.description": "新一代 StepFun 图像模型，专注于图像生成，可根据文本提示生成高质量图像，具备更真实的纹理与更强的中英文文本渲染能力。",
  "step-3.description": "该模型具备强大的视觉感知与复杂推理能力，能准确处理跨领域知识理解、数学与视觉交叉分析及多种日常视觉分析任务。",
  "step-r1-v-mini.description": "具备强图像理解能力的推理模型，可处理图像与文本，并在深度推理后生成文本。擅长视觉推理，在数学、编程与文本推理方面表现出色，支持 100K 上下文窗口。",
  "stepfun-ai/step3.description": "Step3 是 StepFun 推出的前沿多模态推理模型，基于 MoE 架构，总参数 321B，激活参数 38B。端到端设计降低解码成本，同时实现顶级视觉语言推理能力。采用 MFA 与 AFD 架构，在旗舰与低端加速器上均保持高效。预训练使用超过 20T 文本与 4T 图文数据，覆盖多种语言，在数学、编程与多模态评测中表现领先。",
  "taichu_llm.description": "基于海量高质量数据训练，具备更强的文本理解、内容创作与对话问答能力。",
  "taichu_o1.description": "taichu_o1 是一款新一代推理模型，结合多模态交互与强化学习，实现类人链式思维，支持复杂决策模拟，具备高准确率输出与推理路径可视化，适用于策略分析与深度思考。",
  "taichu_vl.description": "融合图像理解、知识迁移与逻辑归因，在图文问答任务中表现出色。",
  "tencent/Hunyuan-A13B-Instruct.description": "混元-A13B-Instruct 总参数 80B，激活参数 13B，性能媲美更大模型。支持快慢混合推理、稳定长文本理解，在 BFCL-v3 与 τ-Bench 上具备领先代理能力。支持 GQA 与多量化格式，推理高效。",
  "tencent/Hunyuan-MT-7B.description": "混元翻译模型包括 Hunyuan-MT-7B 与集成模型 Hunyuan-MT-Chimera。Hunyuan-MT-7B 是一款支持 33 种语言及 5 种中国少数民族语言的 7B 轻量翻译模型，在 WMT25 中 31 个语对中获得 30 个第一。腾讯混元采用从预训练到 SFT、翻译 RL 与集成 RL 的完整训练流程，在同等规模下实现领先性能，部署高效便捷。",
  "text-embedding-3-large.description": "最强大的嵌入模型，适用于英文与非英文任务。",
  "text-embedding-3-small.description": "高效、低成本的下一代嵌入模型，适用于检索与 RAG 场景。",
  "thudm/glm-4-32b.description": "GLM-4-32B-0414 是一款 32B 中英双语开源模型，优化用于代码生成、函数调用与代理任务。预训练数据达 15T，强调高质量与推理能力，并通过人类偏好对齐、拒绝采样与强化学习进一步优化。擅长复杂推理、结构化输出与内容生成，在多个基准测试中达到 GPT-4o 与 DeepSeek-V3-0324 水平。",
  "thudm/glm-4-32b:free.description": "GLM-4-32B-0414 是一款 32B 中英双语开源模型，优化用于代码生成、函数调用与代理任务。预训练数据达 15T，强调高质量与推理能力，并通过人类偏好对齐、拒绝采样与强化学习进一步优化。擅长复杂推理、结构化输出与内容生成，在多个基准测试中达到 GPT-4o 与 DeepSeek-V3-0324 水平。",
  "thudm/glm-4-9b-chat.description": "智谱 AI 最新 GLM-4 预训练模型的开源版本。",
  "thudm/glm-z1-32b.description": "GLM-Z1-32B-0414 是 GLM-4-32B 的增强推理版本，专为数学、逻辑与代码问题求解设计。通过扩展强化学习（任务特定与通用偏好）提升复杂多步任务能力。支持通过提示工程引导“思考”步骤，提升长文本连贯性，优化代理流程，支持长上下文（通过 YaRN）、JSON 工具调用与细粒度采样，适用于需要严谨推理的场景。",
  "thudm/glm-z1-rumination-32b.description": "GLM Z1 Rumination 32B 是 GLM-4-Z1 系列中的深度推理模型，专为需要长时间思考的复杂开放任务设计。基于 glm-4-32b-0414，增加多阶段强化学习与对齐，具备“反思”能力，模拟延时认知处理，包括迭代推理、多跳分析与工具增强流程（如搜索、检索、引用感知合成）。擅长科研写作、对比分析与复杂问答，支持函数调用实现搜索/导航操作（如 `search`、`click`、`open`、`finish`），通过多轮循环与规则奖励机制控制反思行为，参考 OpenAI 内部对齐框架进行基准测试，适用于深度优先场景。",
  "tngtech/deepseek-r1t-chimera:free.description": "DeepSeek-R1T-Chimera 由 DeepSeek-R1 与 DeepSeek-V3（0324）融合而成，结合 R1 的推理能力与 V3 的 token 效率。基于 DeepSeek-MoE Transformer，优化通用文本生成。通过预训练权重融合，平衡推理、效率与指令跟随能力。MIT 许可发布，支持研究与商业用途。",
  "togethercomputer/StripedHyena-Nous-7B.description": "StripedHyena Nous（7B）通过架构与策略提升计算效率。",
  "tts-1-hd.description": "最新文本转语音模型，优化音质表现。",
  "tts-1.description": "最新文本转语音模型，优化实时速度。",
  "upstage/SOLAR-10.7B-Instruct-v1.0.description": "Upstage SOLAR Instruct v1（11B）专为精准指令任务调优，具备强大的语言能力。",
  "us.anthropic.claude-3-5-sonnet-20241022-v2:0.description": "Claude 3.5 Sonnet 提升行业标准，在广泛评估中超越竞争对手与 Claude 3 Opus，同时保持中等速度与成本。",
  "us.anthropic.claude-3-7-sonnet-20250219-v1:0.description": "Claude 3.7 Sonnet 是 Anthropic 推出的最快速下一代模型，相较 Claude 3 Haiku，在多项技能上实现提升，并在多个智能基准测试中超越前代旗舰 Claude 3 Opus。",
  "us.anthropic.claude-haiku-4-5-20251001-v1:0.description": "Claude Haiku 4.5 是 Anthropic 推出的最快速且最智能的 Haiku 模型，具备闪电般的响应速度与深度思考能力。",
  "us.anthropic.claude-opus-4-6-v1.description": "Claude Opus 4.6 是 Anthropic 最智能的模型，专为构建智能体与编程任务而设计。",
  "us.anthropic.claude-sonnet-4-5-20250929-v1:0.description": "Claude Sonnet 4.5 是 Anthropic 迄今为止最智能的模型。",
  "v0-1.0-md.description": "v0-1.0-md 是通过 v0 API 提供的旧版模型。",
  "v0-1.5-lg.description": "v0-1.5-lg 适用于高级思维或推理任务。",
  "v0-1.5-md.description": "v0-1.5-md 适用于日常任务和用户界面生成。",
  "vercel/v0-1.0-md.description": "访问 v0 背后的模型，结合框架特定的推理能力和最新知识，用于生成、修复和优化现代 Web 应用。",
  "vercel/v0-1.5-md.description": "访问 v0 背后的模型，结合框架特定的推理能力和最新知识，用于生成、修复和优化现代 Web 应用。",
  "volcengine/doubao-seed-code.description": "豆包-Seed-Code 是字节跳动火山引擎推出的面向智能体编程优化的大模型，在编程和智能体基准测试中表现出色，支持 256K 上下文。",
  "wan2.2-t2i-flash.description": "万象 2.2 极速版是最新模型，在创意性、稳定性和真实感方面全面升级，生成速度快，性价比高。",
  "wan2.2-t2i-plus.description": "万象 2.2 专业版是最新模型，在创意性、稳定性和真实感方面全面升级，图像细节更丰富。",
  "wanx-v1.description": "基础文本转图像模型。对应通义万象 1.0 通用版。",
  "wanx2.0-t2i-turbo.description": "擅长纹理人像，速度适中，成本较低。对应通义万象 2.0 极速版。",
  "wanx2.1-t2i-plus.description": "全面升级版本，图像细节更丰富，生成速度略慢。对应通义万象 2.1 专业版。",
  "wanx2.1-t2i-turbo.description": "全面升级版本，生成速度快，整体质量强，性价比高。对应通义万象 2.1 极速版。",
  "whisper-1.description": "通用语音识别模型，支持多语言 ASR、语音翻译和语言识别。",
  "wizardlm2.description": "WizardLM 2 是微软 AI 推出的语言模型，擅长复杂对话、多语言任务、推理和助手应用。",
  "wizardlm2:8x22b.description": "WizardLM 2 是微软 AI 推出的语言模型，擅长复杂对话、多语言任务、推理和助手应用。",
  "x-ai/grok-4-fast-non-reasoning.description": "Grok 4 Fast（非推理版）是 xAI 推出的高吞吐、低成本多模态模型（支持 2M 上下文窗口），适用于对延迟和成本敏感但不需要模型内推理的场景。可通过 API 的 reasoning 参数启用推理功能。提示词和生成内容可能被 xAI 或 OpenRouter 用于改进未来模型。",
  "x-ai/grok-4-fast.description": "Grok 4 Fast 是 xAI 推出的高吞吐、低成本模型（支持 2M 上下文窗口），适用于高并发和长上下文场景。",
  "x-ai/grok-4.1-fast-non-reasoning.description": "Grok 4 Fast（非推理版）是 xAI 推出的高吞吐、低成本多模态模型（支持 2M 上下文窗口），适用于对延迟和成本敏感但不需要模型内推理的场景。可通过 API 的 reasoning 参数启用推理功能。提示词和生成内容可能被 xAI 或 OpenRouter 用于改进未来模型。",
  "x-ai/grok-4.1-fast.description": "Grok 4 Fast 是 xAI 推出的高吞吐、低成本模型（支持 2M 上下文窗口），适用于高并发和长上下文场景。",
  "x-ai/grok-4.description": "Grok 4 是 xAI 的旗舰推理模型，具备强大的推理和多模态能力。",
  "x-ai/grok-code-fast-1.description": "Grok Code Fast 1 是 xAI 推出的快速代码模型，输出可读性强，适合工程使用。",
  "xai/grok-2-vision.description": "Grok 2 Vision 擅长视觉任务，在视觉数学推理（MathVista）和文档问答（DocVQA）方面表现卓越，支持文档、图表、截图和照片等多种图像类型。",
  "xai/grok-2.description": "Grok 2 是一款前沿模型，具备先进的推理能力，强大的对话、编程和推理表现，在 LMSYS 排名中优于 Claude 3.5 Sonnet 和 GPT-4 Turbo。",
  "xai/grok-3-fast.description": "xAI 的旗舰模型，擅长企业场景如数据提取、编程和摘要，具备金融、医疗、法律和科学等领域的深度知识。快速版本运行在更快的基础设施上，响应速度更快但每个 token 成本更高。",
  "xai/grok-3-mini-fast.description": "xAI 的轻量模型，在回答前进行思考，适用于简单或基于逻辑的任务，无需深度领域知识。提供原始推理轨迹。快速版本运行在更快的基础设施上，响应速度更快但每个 token 成本更高。",
  "xai/grok-3-mini.description": "xAI 的轻量模型，在回答前进行思考，适用于简单或基于逻辑的任务，无需深度领域知识。提供原始推理轨迹。",
  "xai/grok-3.description": "xAI 的旗舰模型，擅长企业场景如数据提取、编程和摘要，具备金融、医疗、法律和科学等领域的深度知识。",
  "xai/grok-4.description": "xAI 最新旗舰模型，在自然语言、数学和推理方面表现卓越，是理想的全能型模型。",
  "yi-large-fc.description": "基于 yi-large 构建，增强了工具调用能力，适用于智能体和工作流场景。",
  "yi-large-preview.description": "早期版本，推荐使用更新的 yi-large。",
  "yi-large-rag.description": "基于 yi-large 的高级服务，结合检索与生成，支持实时网页搜索，提供精准答案。",
  "yi-large-turbo.description": "在质量、速度和成本之间实现出色平衡，具备卓越性价比和性能。",
  "yi-large.description": "一款全新 1000 亿参数模型，擅长问答和文本生成。",
  "yi-lightning-lite.description": "轻量版本，推荐使用 yi-lightning。",
  "yi-lightning.description": "最新高性能模型，推理速度更快，输出质量更高。",
  "yi-medium-200k.description": "支持 200K 长上下文的模型，适用于深度长文本理解与生成。",
  "yi-medium.description": "调优后的中型模型，能力与性价比平衡，优化用于指令跟随任务。",
  "yi-spark.description": "紧凑快速的模型，强化了数学和编程能力。",
  "yi-vision-v2.description": "适用于复杂任务的视觉模型，具备强大的多图理解与分析能力。",
  "yi-vision.description": "适用于复杂任务的视觉模型，具备强大的图像理解与分析能力。",
  "z-ai/glm-4.5-air.description": "GLM 4.5 Air 是 GLM 4.5 的轻量版本，适用于对成本敏感的场景，同时保留强大的推理能力。",
  "z-ai/glm-4.5.description": "GLM 4.5 是 Z.AI 的旗舰模型，采用混合推理，优化用于工程和长上下文任务。",
  "z-ai/glm-4.6.description": "GLM 4.6 是 Z.AI 的旗舰模型，具备更长上下文和更强编程能力。",
  "z-ai/glm-4.7.description": "GLM-4.7 是智谱最新旗舰模型，具备更强通用能力、自然简洁的回复风格与沉浸式写作体验。",
  "zai-org/GLM-4.5-Air.description": "GLM-4.5-Air 是一款面向智能体应用的基础模型，采用专家混合架构，优化用于工具使用、网页浏览、软件工程和前端编程，并可与 Claude Code 和 Roo Code 等代码智能体集成。采用混合推理，兼顾复杂推理与日常任务。",
  "zai-org/GLM-4.5.description": "GLM-4.5 是一款面向智能体应用的基础模型，采用专家混合架构，深度优化用于工具使用、网页浏览、软件工程和前端编程，并可与 Claude Code 和 Roo Code 等代码智能体集成。采用混合推理，兼顾复杂推理与日常任务。",
  "zai-org/GLM-4.5V.description": "GLM-4.5V 是智谱 AI 最新的多模态语言模型，基于 GLM-4.5-Air 旗舰文本模型（总参数 106B，激活参数 12B），采用 MoE 架构，在成本更低的同时保持强大性能。继承 GLM-4.1V-Thinking 路线，加入 3D-RoPE 提升三维空间推理能力。通过预训练、SFT 和 RL 优化，支持图像、视频和长文档，在 41 个公开多模态基准中排名领先。提供“思考模式”切换，平衡速度与深度。",
  "zai-org/GLM-4.6.description": "相比 GLM-4.5，GLM-4.6 将上下文长度从 128K 扩展至 200K，适用于更复杂的智能体任务。在代码基准测试中得分更高，在 Claude Code、Cline、Roo Code 和 Kilo Code 等应用中表现更强，包括更好的前端页面生成。推理能力增强，支持推理过程中的工具使用，整体能力更强。更好地集成于智能体框架，提升工具/搜索智能体能力，具备更符合人类偏好的写作风格和角色扮演自然度。",
  "zai/glm-4.5-air.description": "GLM-4.5 和 GLM-4.5-Air 是我们面向智能体应用的最新旗舰模型，均采用 MoE 架构。GLM-4.5 总参数 355B，每次前向激活 32B；GLM-4.5-Air 更轻量，总参数 106B，激活参数 12B。",
  "zai/glm-4.5.description": "GLM-4.5 系列专为智能体设计，旗舰版 GLM-4.5 结合推理、编程和智能体能力，总参数 355B（激活 32B），提供双模式混合推理系统。",
  "zai/glm-4.5v.description": "GLM-4.5V 基于 GLM-4.5-Air 构建，继承 GLM-4.1V-Thinking 的成熟技术，采用强大的 106B 参数 MoE 架构扩展能力。",
  "zenmux/auto.description": "ZenMux 自动路由根据请求自动选择性价比最高、性能最优的支持模型。"
}
