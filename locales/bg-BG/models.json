{
  "01-ai/yi-1.5-34b-chat.description": "Най-новият отворен модел на 01.AI с фино настройване и 34 милиарда параметъра, поддържащ множество сценарии за диалог, обучен с висококачествени данни и съобразен с човешките предпочитания.",
  "01-ai/yi-1.5-9b-chat.description": "Най-новият отворен модел на 01.AI с фино настройване и 9 милиарда параметъра, поддържащ множество сценарии за диалог, обучен с висококачествени данни и съобразен с човешките предпочитания.",
  "360/deepseek-r1.description": "DeepSeek-R1, внедрен от 360, използва мащабно подсилващо обучение в етапа след предварителното обучение, значително подобрявайки логическото мислене с минимално количество етикетирани данни. Сравнява се с OpenAI o1 при задачи по математика, програмиране и езиково разсъждение.",
  "360gpt-pro-trans.description": "Модел, специализиран в превод, дълбоко фино настроен за водещо качество на превода.",
  "360gpt-pro.description": "360GPT Pro е основен AI модел на 360 с ефективна обработка на текст за разнообразни NLP сценарии, поддържащ разбиране на дълги текстове и многократен диалог.",
  "360gpt-turbo-responsibility-8k.description": "360GPT Turbo Responsibility 8K поставя акцент върху семантичната безопасност и отговорността при чувствително съдържание, осигурявайки точни и надеждни потребителски преживявания.",
  "360gpt-turbo.description": "360GPT Turbo предлага мощни изчислителни и диалогови възможности с отлично семантично разбиране и ефективност на генериране, идеален за предприятия и разработчици.",
  "360gpt2-o1.description": "360gpt2-o1 изгражда верига на мисълта чрез дървовидно търсене с механизъм за рефлексия и обучение чрез подсилване, позволявайки саморефлексия и самокорекция.",
  "360gpt2-pro.description": "360GPT2 Pro е усъвършенстван NLP модел от 360 с отлични възможности за генериране и разбиране на текст, особено при творчески задачи, справяйки се със сложни трансформации и ролеви игри.",
  "360zhinao2-o1.description": "360zhinao2-o1 изгражда верига на мисълта чрез дървовидно търсене с механизъм за рефлексия и обучение чрез подсилване, позволявайки саморефлексия и самокорекция.",
  "4.0Ultra.description": "Spark Ultra е най-мощният модел от серията Spark, подобряващ разбирането и обобщаването на текст, както и уеб търсенето. Това е цялостно решение за повишаване на продуктивността на работното място и точността на отговорите, позиционирайки го като водещ интелигентен продукт.",
  "AnimeSharp.description": "AnimeSharp (известен още като \"4x-AnimeSharp\") е отворен модел за супер-резолюция, базиран на ESRGAN от Kim2091, фокусиран върху увеличаване и изостряне на изображения в аниме стил. Преименуван е от \"4x-TextSharpV1\" през февруари 2022 г., първоначално предназначен и за текстови изображения, но силно оптимизиран за аниме съдържание.",
  "Baichuan2-Turbo.description": "Използва разширение чрез търсене, за да свърже модела с домейн и уеб знания. Поддържа качване на PDF/Word файлове и въвеждане на URL адреси за навременно, цялостно извличане и професионални, точни резултати.",
  "Baichuan3-Turbo-128k.description": "С ултра-дълъг контекст от 128K, оптимизиран за чести бизнес сценарии с големи подобрения и висока стойност. В сравнение с Baichuan2, създаването на съдържание се подобрява с 20%, въпросите и отговорите с 17%, а ролевите игри с 40%. Общата производителност надвишава тази на GPT-3.5.",
  "Baichuan3-Turbo.description": "Оптимизиран за чести бизнес сценарии с големи подобрения и висока стойност. В сравнение с Baichuan2, създаването на съдържание се подобрява с 20%, въпросите и отговорите с 17%, а ролевите игри с 40%. Общата производителност надвишава тази на GPT-3.5.",
  "Baichuan4-Air.description": "Водещ модел в Китай, надминаващ основни чуждестранни модели при китайски задачи като знания, дълги текстове и творческо генериране. Също така предлага водещи в индустрията мултимодални възможности с отлични резултати на авторитетни бенчмаркове.",
  "Baichuan4-Turbo.description": "Водещ модел в Китай, надминаващ основни чуждестранни модели при китайски задачи като знания, дълги текстове и творческо генериране. Също така предлага водещи в индустрията мултимодални възможности с отлични резултати на авторитетни бенчмаркове.",
  "Baichuan4.description": "Водещо вътрешно представяне, надминаващо водещи чуждестранни модели при китайски задачи като енциклопедични знания, дълги текстове и творческо генериране. Също така предлага водещи в индустрията мултимодални възможности и силни резултати на бенчмаркове.",
  "ByteDance-Seed/Seed-OSS-36B-Instruct.description": "Seed-OSS е семейство от отворени LLM модели от ByteDance Seed, проектирани за силна обработка на дълъг контекст, логическо мислене, агентни и общи способности. Seed-OSS-36B-Instruct е 36B модел, настроен за инструкции, с вграден ултра-дълъг контекст за обработка на големи документи или кодови бази. Оптимизиран е за логическо мислене, генериране на код и агентни задачи (използване на инструменти), като същевременно запазва силни общи способности. Ключова характеристика е \"Бюджет за мислене\", позволяващ гъвкава дължина на разсъждение за подобрена ефективност.",
  "DeepSeek-R1-Distill-Llama-70B.description": "DeepSeek R1, по-големият и по-интелигентен модел от серията DeepSeek, е дистилиран в архитектурата Llama 70B. Бенчмаркове и човешки оценки показват, че е по-умен от базовия Llama 70B, особено при задачи по математика и точност на фактите.",
  "DeepSeek-R1-Distill-Qwen-1.5B.description": "Дистилиран модел DeepSeek-R1, базиран на Qwen2.5-Math-1.5B. Подсилващо обучение и cold-start данни оптимизират логическата производителност, поставяйки нови мултизадачни бенчмаркове за отворени модели.",
  "DeepSeek-R1-Distill-Qwen-14B.description": "Моделите DeepSeek-R1-Distill са фино настроени от отворени модели с помощта на примерни данни, генерирани от DeepSeek-R1.",
  "DeepSeek-R1-Distill-Qwen-32B.description": "Моделите DeepSeek-R1-Distill са фино настроени от отворени модели с помощта на примерни данни, генерирани от DeepSeek-R1.",
  "DeepSeek-R1-Distill-Qwen-7B.description": "Дистилиран модел DeepSeek-R1, базиран на Qwen2.5-Math-7B. Подсилващо обучение и cold-start данни оптимизират логическата производителност, поставяйки нови мултизадачни бенчмаркове за отворени модели.",
  "DeepSeek-R1.description": "DeepSeek-R1 прилага мащабно подсилващо обучение в етапа след предварителното обучение, значително подобрявайки логическото мислене с много малко етикетирани данни. Сравнява се с продукционния модел OpenAI o1 при задачи по математика, програмиране и езиково разсъждение.",
  "DeepSeek-V3-1.description": "DeepSeek V3.1 е следващо поколение модел за логическо мислене с подобрено сложно разсъждение и верига на мисълта, подходящ за задачи с дълбок анализ.",
  "DeepSeek-V3-Fast.description": "Доставчик: sophnet. DeepSeek V3 Fast е високоскоростната версия на DeepSeek V3 0324, с пълна прецизност (без квантизация), по-силен при програмиране и математика и по-бързи отговори.",
  "DeepSeek-V3.1-Fast.description": "DeepSeek V3.1 Fast е високоскоростният вариант на DeepSeek V3.1. Хибриден режим на мислене: чрез шаблони за чат, един модел поддържа както мислещ, така и немислещ режим. По-умно използване на инструменти: оптимизации след обучение подобряват производителността при задачи с инструменти и агенти.",
  "DeepSeek-V3.1-Think.description": "Режим на мислене на DeepSeek-V3.1: нов хибриден модел за разсъждение с мислещ и немислещ режим, по-ефективен от DeepSeek-R1-0528. Оптимизациите след обучение значително подобряват използването на инструменти от агенти и производителността при агентни задачи.",
  "DeepSeek-V3.description": "DeepSeek-V3 е MoE модел, разработен от DeepSeek. Надминава други отворени модели като Qwen2.5-72B и Llama-3.1-405B в много бенчмаркове и е конкурентен с водещи затворени модели като GPT-4o и Claude 3.5 Sonnet.",
  "Doubao-lite-128k.description": "Doubao-lite предлага изключително бързи отговори и по-добра стойност, с гъвкави опции за различни сценарии. Поддържа 128K контекст за извеждане и фина настройка.",
  "Doubao-lite-32k.description": "Doubao-lite предлага изключително бързи отговори и по-добра стойност, с гъвкави опции за различни сценарии. Поддържа 32K контекст за извеждане и фина настройка.",
  "Doubao-lite-4k.description": "Doubao-lite предлага изключително бързи отговори и по-добра стойност, с гъвкави опции за различни сценарии. Поддържа 4K контекст за извеждане и фина настройка.",
  "Doubao-pro-128k.description": "Водещ флагмански модел с най-добра производителност за сложни задачи, отличен в отговори с препратки, обобщения, създаване на съдържание, класификация и ролеви игри. Поддържа 128K контекст за извеждане и фина настройка.",
  "Doubao-pro-32k.description": "Водещ флагмански модел с най-добра производителност за сложни задачи, отличен в отговори с препратки, обобщения, създаване на съдържание, класификация и ролеви игри. Поддържа 32K контекст за извеждане и фина настройка.",
  "Doubao-pro-4k.description": "Водещ флагмански модел с най-добра производителност за сложни задачи, отличен в отговори с препратки, обобщения, създаване на съдържание, класификация и ролеви игри. Поддържа 4K контекст за извеждане и фина настройка.",
  "DreamO.description": "DreamO е модел с отворен код за персонализирано генериране на изображения, разработен съвместно от ByteDance и Пекинския университет. Използва унифицирана архитектура за поддръжка на многозадачно генериране на изображения. Прилага ефективно композиционно моделиране за създаване на висококачествени, персонализирани изображения въз основа на зададени от потребителя характеристики като идентичност, обект, стил, фон и други условия.",
  "ERNIE-3.5-128K.description": "Флагмански LLM модел на Baidu, обучен върху мащабни китайски и английски корпуси, с отлични общи способности за чат, създаване на съдържание и използване на плъгини. Поддържа автоматична интеграция с Baidu Search плъгин за предоставяне на актуални отговори.",
  "ERNIE-3.5-8K-Preview.description": "Флагмански LLM модел на Baidu, обучен върху мащабни китайски и английски корпуси, с отлични общи способности за чат, създаване на съдържание и използване на плъгини. Поддържа автоматична интеграция с Baidu Search плъгин за предоставяне на актуални отговори.",
  "ERNIE-3.5-8K.description": "Флагмански LLM модел на Baidu, обучен върху мащабни китайски и английски корпуси, с отлични общи способности за чат, създаване на съдържание и използване на плъгини. Поддържа автоматична интеграция с Baidu Search плъгин за предоставяне на актуални отговори.",
  "ERNIE-4.0-8K-Latest.description": "Флагмански ултра-голям LLM модел на Baidu с цялостни подобрения спрямо ERNIE 3.5, подходящ за сложни задачи в различни области. Поддържа интеграция с Baidu Search плъгин за предоставяне на актуални отговори.",
  "ERNIE-4.0-8K-Preview.description": "Флагмански ултра-голям LLM модел на Baidu с цялостни подобрения спрямо ERNIE 3.5, подходящ за сложни задачи в различни области. Поддържа интеграция с Baidu Search плъгин за предоставяне на актуални отговори.",
  "ERNIE-4.0-Turbo-8K-Latest.description": "Флагмански ултра-голям LLM модел на Baidu с отлична цялостна производителност за сложни задачи и интеграция с Baidu Search плъгин за предоставяне на актуални отговори. Надминава ERNIE 4.0.",
  "ERNIE-4.0-Turbo-8K-Preview.description": "Флагмански ултра-голям LLM модел на Baidu с отлична цялостна производителност за сложни задачи и интеграция с Baidu Search плъгин за предоставяне на актуални отговори. Надминава ERNIE 4.0.",
  "ERNIE-Character-8K.description": "Вертикално-ориентиран LLM модел на Baidu за игрови NPC, клиентско обслужване и ролеви игри, с по-ясна консистентност на персонажа, по-добро следване на инструкции и по-силно логическо мислене.",
  "ERNIE-Lite-Pro-128K.description": "Олекотен LLM модел на Baidu, балансиращ между качество и производителност при извеждане, по-добър от ERNIE Lite и подходящ за устройства с ограничени ресурси.",
  "ERNIE-Speed-128K.description": "Най-новият високопроизводителен LLM модел на Baidu (2024), с отлични общи способности, подходящ за фина настройка за специфични сценарии и с изключителна логическа производителност.",
  "ERNIE-Speed-Pro-128K.description": "Най-новият високопроизводителен LLM модел на Baidu (2024), с отлични общи способности, по-добър от ERNIE Speed, подходящ за фина настройка и с изключителна логическа производителност.",
  "FLUX-1.1-pro.description": "FLUX.1.1 Pro",
  "FLUX.1-Kontext-dev.description": "FLUX.1-Kontext-dev е мултимодален модел за генериране и редактиране на изображения от Black Forest Labs, базиран на архитектура Rectified Flow Transformer с 12B параметъра. Фокусира се върху генериране, реконструкция, подобрение и редакция на изображения според зададен контекст. Комбинира контролираната генерация на дифузионни модели с контекстното моделиране на Transformer, поддържайки висококачествени резултати за задачи като inpainting, outpainting и реконструкция на визуални сцени.",
  "FLUX.1-Kontext-pro.description": "FLUX.1 Kontext [pro]",
  "FLUX.1-dev.description": "FLUX.1-dev е мултимодален езиков модел с отворен код (MLLM) от Black Forest Labs, оптимизиран за задачи с изображения и текст, комбиниращ разбиране и генериране на изображения/текст. Изграден върху напреднали LLM модели (като Mistral-7B), използва внимателно проектиран визуален енкодер и многоетапна настройка с инструкции за постигане на мултимодална координация и логическо мислене при сложни задачи.",
  "Gryphe/MythoMax-L2-13b.description": "MythoMax-L2 (13B) е иновативен модел за разнообразни области и сложни задачи.",
  "HelloMeme.description": "HelloMeme е AI инструмент, който генерира мемета, GIF-ове или кратки видеа от предоставени изображения или движения. Не изисква умения за рисуване или програмиране — само референтно изображение — за създаване на забавно, атрактивно и стилово консистентно съдържание.",
  "HiDream-I1-Full.description": "HiDream-E1-Full е мултимодален модел за редактиране на изображения с отворен код от HiDream.ai, базиран на напреднала архитектура Diffusion Transformer и силно езиково разбиране (вграден LLaMA 3.1-8B-Instruct). Поддържа генериране на изображения чрез естествен език, трансфер на стил, локални редакции и прерисуване, с отлично разбиране и изпълнение на връзката между изображение и текст.",
  "HunyuanDiT-v1.2-Diffusers-Distilled.description": "hunyuandit-v1.2-distilled е олекотен модел за преобразуване на текст в изображение, оптимизиран чрез дистилация за бързо генериране на висококачествени изображения, особено подходящ за среди с ограничени ресурси и реално време.",
  "InstantCharacter.description": "InstantCharacter е модел за персонализирано генериране на персонажи без нужда от настройка, пуснат от Tencent AI през 2025 г., насочен към висок реализъм и консистентност на персонажа в различни сценарии. Може да моделира персонаж от едно референтно изображение и гъвкаво да го прехвърля между стилове, действия и фонове.",
  "InternVL2-8B.description": "InternVL2-8B е мощен модел за визия и език, поддържащ мултимодална обработка на изображения и текст, с точно разпознаване на съдържание и генериране на съответни описания или отговори.",
  "InternVL2.5-26B.description": "InternVL2.5-26B е мощен модел за визия и език, поддържащ мултимодална обработка на изображения и текст, с точно разпознаване на съдържание и генериране на съответни описания или отговори.",
  "Kolors.description": "Kolors е модел за преобразуване на текст в изображение, разработен от екипа на Kuaishou Kolors. Обучен с милиарди параметри, той има значителни предимства във визуалното качество, разбиране на китайски семантики и визуализиране на текст.",
  "Kwai-Kolors/Kolors.description": "Kolors е мащабен латентен дифузионен модел за преобразуване на текст в изображение от екипа на Kuaishou Kolors. Обучен върху милиарди двойки текст-изображение, той се отличава с високо визуално качество, точност при сложни семантики и визуализиране на китайски/английски текст, с отлично разбиране и генериране на китайско съдържание.",
  "Kwaipilot/KAT-Dev.description": "KAT-Dev (32B) е модел с отворен код за задачи в софтуерното инженерство. Постига 62.4% успеваемост в SWE-Bench Verified, класирайки се на 5-то място сред отворените модели. Оптимизиран чрез междинно обучение, SFT и RL за допълване на код, отстраняване на грешки и преглед на код.",
  "Llama-3.2-11B-Vision-Instruct.description": "Силен визуален анализ на изображения с висока резолюция, подходящ за приложения за визуално разбиране.",
  "Llama-3.2-90B-Vision-Instruct\t.description": "Разширено визуално разсъждение за приложения с агенти за визуално разбиране.",
  "Meta-Llama-3-3-70B-Instruct.description": "Llama 3.3 70B е универсален трансформерен модел за чат и генериране на текст.",
  "Meta-Llama-3.1-405B-Instruct.description": "Llama 3.1 е текстов модел, обучен с инструкции, оптимизиран за многоезичен чат, с отлични резултати на водещи индустриални бенчмаркове сред отворени и затворени модели.",
  "Meta-Llama-3.1-70B-Instruct.description": "Llama 3.1 е текстов модел, обучен с инструкции, оптимизиран за многоезичен чат, с отлични резултати на водещи индустриални бенчмаркове сред отворени и затворени модели.",
  "Meta-Llama-3.1-8B-Instruct.description": "Llama 3.1 е текстов модел, обучен с инструкции, оптимизиран за многоезичен чат, с отлични резултати на водещи индустриални бенчмаркове сред отворени и затворени модели.",
  "Meta-Llama-3.2-1B-Instruct.description": "Модерен малък езиков модел с отлично езиково разбиране, логическо мислене и генериране на текст.",
  "Meta-Llama-3.2-3B-Instruct.description": "Модерен малък езиков модел с отлично езиково разбиране, логическо мислене и генериране на текст.",
  "Meta-Llama-3.3-70B-Instruct.description": "Llama 3.3 е най-усъвършенстваният многоезичен отворен модел от серията Llama, предлагащ производителност, близка до 405B, на много по-ниска цена. Базиран е на трансформерна архитектура и подобрен чрез SFT и RLHF за полезност и безопасност. Версията, обучена с инструкции, е оптимизирана за многоезичен чат и надминава много отворени и затворени модели на индустриални бенчмаркове. Граница на знанието: декември 2023 г.",
  "Meta-Llama-4-Maverick-17B-128E-Instruct-FP8.description": "Llama 4 Maverick е голям MoE модел с ефективна активация на експерти за силна логическа производителност.",
  "MiniMax-M1.description": "Нов вътрешен модел за разсъждение с 80K верига на мисълта и 1M вход, предлагащ производителност, сравнима с водещите глобални модели.",
  "MiniMax-M2-Stable.description": "Създаден за ефективно програмиране и агентски работни потоци, с по-висока едновременност за търговска употреба.",
  "MiniMax-M2.1-Lightning.description": "Мощни многоезични възможности за програмиране и цялостно подобрено програмистко изживяване. По-бързо и по-ефективно.",
  "MiniMax-M2.1.description": "MiniMax-M2.1 е водеща отворена голяма езикова система от MiniMax, фокусирана върху решаването на сложни реални задачи. Основните ѝ предимства са възможностите за програмиране на множество езици и способността да действа като агент за решаване на сложни задачи.",
  "MiniMax-M2.description": "Създаден специално за ефективно програмиране и работни потоци с агенти",
  "MiniMax-Text-01.description": "MiniMax-01 въвежда мащабно линейно внимание отвъд класическите трансформери, с 456B параметри и 45.9B активирани на преминаване. Постига водеща производителност и поддържа до 4M токена контекст (32× GPT-4o, 20× Claude-3.5-Sonnet).",
  "MiniMaxAI/MiniMax-M1-80k.description": "MiniMax-M1 е отворен модел с голям мащаб и хибридно внимание, с общо 456B параметри и ~45.9B активни на токен. Поддържа нативно 1M контекст и използва Flash Attention за 75% по-малко FLOPs при генериране на 100K токена спрямо DeepSeek R1. С MoE архитектура, CISPO и хибридно обучение с внимание и RL, постига водеща производителност при дълги входове и реални задачи по софтуерно инженерство.",
  "MiniMaxAI/MiniMax-M2.description": "MiniMax-M2 преосмисля ефективността на агентите. Това е компактен, бърз и икономичен MoE модел с 230B общо и 10B активни параметри, създаден за водещи задачи по програмиране и агенти, като същевременно запазва силен общ интелект. Със само 10B активни параметри, съперничи на много по-големи модели, което го прави идеален за приложения с висока ефективност.",
  "Moonshot-Kimi-K2-Instruct.description": "1T общи параметри с 32B активни. Сред немислещите модели е водещ в гранични знания, математика и програмиране, и по-силен в общи агентски задачи. Оптимизиран за агентски натоварвания, може да предприема действия, а не само да отговаря на въпроси. Най-подходящ за импровизационен, общ чат и агентски преживявания като модел на рефлексно ниво без дълго мислене.",
  "NousResearch/Nous-Hermes-2-Mixtral-8x7B-DPO.description": "Nous Hermes 2 - Mixtral 8x7B-DPO (46.7B) е високоточен модел с инструкции за сложни изчисления.",
  "OmniConsistency.description": "OmniConsistency подобрява стиловата последователност и обобщението при задачи от изображение към изображение чрез въвеждане на мащабни дифузионни трансформери (DiTs) и сдвоени стилизирани данни, избягвайки влошаване на стила.",
  "PaddlePaddle/PaddleOCR-VL-1.5.description": "PaddleOCR-VL-1.5 е надградена версия от серията PaddleOCR-VL, постигайки 94.5% точност в бенчмарка за парсинг на документи OmniDocBench v1.5, надминавайки водещите общи големи модели и специализирани модели за парсинг на документи. Иновативно поддържа локализация на елементи с неправилни ограничителни кутии, ефективно обработвайки сканирани, наклонени и заснети от екрана изображения.",
  "Phi-3-medium-128k-instruct.description": "Същият модел Phi-3-medium с по-голям контекстен прозорец за RAG или few-shot подканвания.",
  "Phi-3-medium-4k-instruct.description": "Модел с 14B параметри с по-високо качество от Phi-3-mini, фокусиран върху данни с високо качество и интензивно разсъждение.",
  "Phi-3-mini-128k-instruct.description": "Същият модел Phi-3-mini с по-голям контекстен прозорец за RAG или few-shot подканвания.",
  "Phi-3-mini-4k-instruct.description": "Най-малкият член на семейството Phi-3, оптимизиран за качество и ниска латентност.",
  "Phi-3-small-128k-instruct.description": "Същият модел Phi-3-small с по-голям контекстен прозорец за RAG или few-shot подканвания.",
  "Phi-3-small-8k-instruct.description": "Модел с 7B параметри с по-високо качество от Phi-3-mini, фокусиран върху данни с високо качество и интензивно разсъждение.",
  "Phi-3.5-mini-instruct.description": "Актуализирана версия на модела Phi-3-mini.",
  "Phi-3.5-vision-instrust.description": "Актуализирана версия на модела Phi-3-vision.",
  "Pro/MiniMaxAI/MiniMax-M2.1.description": "MiniMax-M2.1 е отворен модел с голям езиков капацитет, оптимизиран за агентни способности, с изключителни резултати в програмиране, използване на инструменти, следване на инструкции и дългосрочно планиране. Моделът поддържа многоезична разработка на софтуер и изпълнение на сложни многoетапни работни потоци, постигайки резултат от 74.0 в SWE-bench Verified и надминава Claude Sonnet 4.5 в многоезични сценарии.",
  "Pro/Qwen/Qwen2-7B-Instruct.description": "Qwen2-7B-Instruct е 7B модел с инструкции от серията Qwen2. Използва трансформерна архитектура със SwiGLU, QKV bias и групирано внимание, и обработва големи входове. Постига отлични резултати в езиково разбиране, генериране, многоезични задачи, програмиране, математика и разсъждение, надминавайки повечето отворени модели и конкурирайки се със затворени.",
  "Pro/Qwen/Qwen2.5-7B-Instruct.description": "Qwen2.5-7B-Instruct е част от най-новата серия LLM на Alibaba Cloud. Моделът с 7B параметри носи значителни подобрения в програмирането и математиката, поддържа над 29 езика и подобрява следването на инструкции, разбирането на структурирани данни и генерирането на структурирани изходи (особено JSON).",
  "Pro/Qwen/Qwen2.5-Coder-7B-Instruct.description": "Qwen2.5-Coder-7B-Instruct е най-новият LLM на Alibaba Cloud, фокусиран върху програмиране. Изграден върху Qwen2.5 и обучен с 5.5T токена, значително подобрява генерирането на код, разсъждението и поправката, като същевременно запазва силни математически и общи способности, осигурявайки стабилна основа за кодови агенти.",
  "Pro/Qwen/Qwen2.5-VL-7B-Instruct.description": "Qwen2.5-VL е нов модел за визия и език от серията Qwen с мощно визуално разбиране. Анализира текст, графики и оформления в изображения, разбира дълги видеа и събития, поддържа разсъждение и използване на инструменти, обвързване на обекти във формати, и структурирани изходи. Подобрява динамичната резолюция и обучението с честота на кадрите за видео разбиране и повишава ефективността на визуалния енкодер.",
  "Pro/THUDM/GLM-4.1V-9B-Thinking.description": "GLM-4.1V-9B-Thinking е отворен VLM модел, разработен от Zhipu AI и лабораторията KEG на университета Цинхуа, създаден за сложна мултимодална когниция. Базиран на GLM-4-9B-0414, той добавя верижно разсъждение (chain-of-thought) и обучение чрез подсилване (RL), което значително подобрява между-модалното разсъждение и стабилността.",
  "Pro/THUDM/glm-4-9b-chat.description": "GLM-4-9B-Chat е отворен GLM-4 модел от Zhipu AI. Демонстрира високи резултати в семантика, математика, логическо мислене, програмиране и знания. Освен многозавойни разговори, поддържа уеб сърфиране, изпълнение на код, извикване на персонализирани инструменти и разсъждение върху дълги текстове. Поддържа 26 езика (включително китайски, английски, японски, корейски, немски). Представя се отлично в AlignBench-v2, MT-Bench, MMLU и C-Eval и поддържа до 128K контекст за академични и бизнес приложения.",
  "Pro/deepseek-ai/DeepSeek-R1-Distill-Qwen-7B.description": "DeepSeek-R1-Distill-Qwen-7B е дестилиран от Qwen2.5-Math-7B и фино настроен с 800K подбрани проби от DeepSeek-R1. Постига отлични резултати: 92.8% на MATH-500, 55.5% на AIME 2024 и рейтинг 1189 в CodeForces за 7B модел.",
  "Pro/deepseek-ai/DeepSeek-R1.description": "DeepSeek-R1 е модел за разсъждение, базиран на обучение чрез подсилване (RL), който намалява повторенията и подобрява четимостта. Използва cold-start данни преди RL, за да засили разсъждението, съпоставя се с OpenAI-o1 при задачи по математика, код и логика и подобрява общите резултати чрез внимателно обучение.",
  "Pro/deepseek-ai/DeepSeek-V3.1-Terminus.description": "DeepSeek-V3.1-Terminus е обновен модел от серията V3.1, позициониран като хибриден агентен LLM. Отстранява докладвани от потребители проблеми и подобрява стабилността, езиковата последователност и намалява смесването на китайски/английски и аномални символи. Интегрира режими с и без разсъждение с шаблони за чат за гъвкаво превключване. Подобрява и производителността на Code Agent и Search Agent за по-надеждно използване на инструменти и многoетапни задачи.",
  "Pro/deepseek-ai/DeepSeek-V3.2-Exp.description": "DeepSeek-V3.2-Exp е експериментална версия от серията V3.2, която служи като мост към следващата архитектура. Добавя DeepSeek Sparse Attention (DSA) върху V3.1-Terminus за по-ефективно обучение и инференция при дълъг контекст, с оптимизации за използване на инструменти, разбиране на дълги документи и многoетапно разсъждение. Идеален за изследване на по-висока ефективност при разсъждение с голям контекстов бюджет.",
  "Pro/deepseek-ai/DeepSeek-V3.description": "DeepSeek-V3 е MoE модел с 671 милиарда параметъра, използващ MLA и DeepSeekMoE с балансирано натоварване без загуби за ефективно обучение и инференция. Предварително обучен върху 14.8T висококачествени токени и допълнително настроен с SFT и RL, той надминава други отворени модели и се доближава до водещите затворени решения.",
  "Pro/moonshotai/Kimi-K2-Instruct-0905.description": "Kimi K2-Instruct-0905 е най-новият и най-мощен модел от серията Kimi K2. Това е MoE модел от най-висок клас с 1T общо и 32B активни параметъра. Основните му предимства включват по-силна агентна интелигентност при програмиране с значителни подобрения в бенчмаркове и реални задачи, както и подобрена естетика и използваемост на фронтенд кода.",
  "Pro/moonshotai/Kimi-K2-Thinking.description": "Kimi K2 Thinking Turbo е ускорен вариант, оптимизиран за скорост на разсъждение и пропускателна способност, като запазва многoетапното разсъждение и използване на инструменти от K2 Thinking. Това е MoE модел с ~1T общи параметри, роден 256K контекст и стабилно мащабируемо извикване на инструменти за производствени сценарии с по-строги изисквания за латентност и едновременност.",
  "Pro/moonshotai/Kimi-K2.5.description": "Kimi K2.5 е отворен мултимодален агентен модел, базиран на Kimi-K2-Base, обучен върху приблизително 1.5 трилиона смесени визуални и текстови токени. Моделът използва MoE архитектура с общо 1T параметри и 32B активни параметри, поддържа контекстен прозорец от 256K и безпроблемно интегрира визуално и езиково разбиране.",
  "Pro/zai-org/glm-4.7.description": "GLM-4.7 е най-новият флагмански модел на Zhipu с общо 355 милиарда параметъра и 32 милиарда активни параметъра. Той е напълно обновен в областите на общ диалог, логическо мислене и агентни способности. GLM-4.7 подобрява Междинното мислене и въвежда Запазено мислене и Мислене на ниво обръщение.",
  "QwQ-32B-Preview.description": "Qwen QwQ е експериментален изследователски модел, фокусиран върху подобряване на разсъждението.",
  "Qwen/QVQ-72B-Preview.description": "QVQ-72B-Preview е изследователски модел от Qwen, насочен към визуално разсъждение, със силни страни в разбирането на сложни сцени и визуални математически задачи.",
  "Qwen/QwQ-32B-Preview.description": "Qwen QwQ е експериментален изследователски модел, фокусиран върху подобрено AI разсъждение.",
  "Qwen/QwQ-32B.description": "QwQ е модел за разсъждение от семейството Qwen. В сравнение със стандартните модели, настроени по инструкции, той добавя мисловни и логически способности, които значително подобряват представянето при трудни задачи. QwQ-32B е среден по размер модел, съпоставим с водещи модели за разсъждение като DeepSeek-R1 и o1-mini. Използва RoPE, SwiGLU, RMSNorm и QKV bias в вниманието, с 64 слоя и 40 Q глави (8 KV в GQA).",
  "Qwen/Qwen-Image-Edit-2509.description": "Qwen-Image-Edit-2509 е най-новата версия за редактиране на изображения от екипа на Qwen. Базиран на 20B модела Qwen-Image, той разширява силното текстово рендиране към редактиране на изображения за прецизни текстови промени. Използва двуканална архитектура – входовете се подават към Qwen2.5-VL за семантичен контрол и към VAE енкодер за контрол на външния вид, което позволява редакции както на семантично, така и на визуално ниво. Поддържа локални редакции (добавяне/премахване/промяна) и по-високо ниво на семантични промени като създаване на IP и трансфер на стил, като същевременно запазва смисъла. Постига SOTA резултати в множество бенчмаркове.",
  "Qwen/Qwen-Image.description": "Qwen-Image е базов модел за генериране на изображения с 20B параметъра от екипа на Qwen. Постига значителен напредък в рендиране на сложен текст и прецизно редактиране на изображения, особено за висококачествен китайски/английски текст. Поддържа многострочни и параграфни оформления с последователна типография. Освен текстово рендиране, поддържа широк спектър от стилове – от фотореалистични до аниме, както и напреднало редактиране като трансфер на стил, добавяне/премахване на обекти, подобряване на детайли, редактиране на текст и контрол на позата, с цел да бъде цялостна основа за визуално творчество.",
  "Qwen/Qwen2-72B-Instruct.description": "Qwen 2 Instruct (72B) предоставя прецизно следване на инструкции за корпоративни натоварвания.",
  "Qwen/Qwen2-7B-Instruct.description": "Qwen2-7B-Instruct е 7B модел от серията Qwen2, обучен за следване на инструкции, използващ Transformer, SwiGLU, QKV bias и групирано внимание при заявки. Обработва големи входни данни и се представя отлично в задачи по разбиране, генериране, многоезичност, програмиране, математика и логическо мислене, надминавайки повечето отворени модели и превъзхождайки Qwen1.5-7B-Chat в множество оценки.",
  "Qwen/Qwen2-VL-72B-Instruct.description": "Qwen2-VL е най-новият модел от серията Qwen-VL, постигайки водещи резултати в задачи по компютърно зрение като MathVista, DocVQA, RealWorldQA и MTVQA. Разбира видеа с продължителност над 20 минути за видео QA, диалог и създаване на съдържание. Поддържа сложна логика и вземане на решения, интегрирайки се с устройства/роботи за действия, водени от визуална информация. Освен английски и китайски, чете текст на много езици, включително повечето европейски, японски, корейски, арабски и виетнамски.",
  "Qwen/Qwen2.5-14B-Instruct.description": "Qwen2.5-14B-Instruct е част от най-новата серия LLM на Alibaba Cloud. Моделът с 14B параметри предлага значителни подобрения в програмирането и математиката, поддържа над 29 езика и подобрява следването на инструкции, разбирането на структурирани данни и генерирането на структурирани изходи (особено JSON).",
  "Qwen/Qwen2.5-32B-Instruct.description": "Qwen2.5-32B-Instruct е част от най-новата серия LLM на Alibaba Cloud. Моделът с 32B параметри предлага значителни подобрения в програмирането и математиката, поддържа над 29 езика и подобрява следването на инструкции, разбирането на структурирани данни и генерирането на структурирани изходи (особено JSON).",
  "Qwen/Qwen2.5-72B-Instruct-128K.description": "Qwen2.5-72B-Instruct е част от най-новата серия LLM на Alibaba Cloud. Моделът с 72B параметри подобрява програмирането и математиката, поддържа до 128K вход и над 8K изход, предлага над 29 езика и подобрява следването на инструкции и структурирания изход (особено JSON).",
  "Qwen/Qwen2.5-72B-Instruct-Turbo.description": "Qwen2.5 е ново семейство LLM, оптимизирано за задачи със стил на инструкции.",
  "Qwen/Qwen2.5-72B-Instruct.description": "Qwen2.5-72B-Instruct е част от най-новата серия LLM на Alibaba Cloud. Моделът с 72B параметри предлага значителни подобрения в програмирането и математиката, поддържа над 29 езика и подобрява следването на инструкции, разбирането на структурирани данни и генерирането на структурирани изходи (особено JSON).",
  "Qwen/Qwen2.5-7B-Instruct-Turbo.description": "Qwen2.5 е ново семейство LLM, оптимизирано за задачи със стил на инструкции.",
  "Qwen/Qwen2.5-7B-Instruct.description": "Qwen2.5-7B-Instruct е част от най-новата серия LLM на Alibaba Cloud. Моделът с 7B параметри предлага значителни подобрения в програмирането и математиката, поддържа над 29 езика и подобрява следването на инструкции, разбирането на структурирани данни и генерирането на структурирани изходи (особено JSON).",
  "Qwen/Qwen2.5-Coder-32B-Instruct.description": "Qwen2.5 Coder 32B Instruct е най-новият LLM на Alibaba Cloud, фокусиран върху програмиране. Изграден върху Qwen2.5 и обучен с 5.5T токена, той значително подобрява генерирането на код, логическото мислене и поправката на грешки, като същевременно запазва силни математически и общи способности, предоставяйки стабилна основа за агенти за програмиране.",
  "Qwen/Qwen2.5-Coder-7B-Instruct.description": "Qwen2.5-Coder-7B-Instruct е най-новият LLM на Alibaba Cloud, фокусиран върху програмиране. Изграден върху Qwen2.5 и обучен с 5.5T токена, той значително подобрява генерирането на код, логическото мислене и поправката на грешки, като същевременно запазва силни математически и общи способности, предоставяйки стабилна основа за агенти за програмиране.",
  "Qwen/Qwen2.5-VL-32B-Instruct.description": "Qwen2.5-VL-32B-Instruct е мултимодален модел от екипа на Qwen. Разпознава често срещани обекти и анализира текст, диаграми, икони, графики и оформления. Като визуален агент, може да разсъждава и динамично да управлява инструменти, включително използване на компютър и телефон. Прецизно локализира обекти и генерира структурирани изходи за фактури и таблици. В сравнение с Qwen2-VL, RL допълнително подобрява математиката и решаването на проблеми, с по-предпочитани от хората отговори.",
  "Qwen/Qwen2.5-VL-72B-Instruct.description": "Qwen2.5-VL е модел за визия и език от серията Qwen2.5 с основни подобрения: по-силно визуално разбиране за обекти, текст, диаграми и оформления; разсъждение като визуален агент с динамично използване на инструменти; разбиране на видеа над 1 час и улавяне на ключови събития; прецизно позициониране на обекти чрез кутии или точки; и структурирани изходи за сканирани данни като фактури и таблици.",
  "Qwen/Qwen3-14B.description": "Qwen3 е следващо поколение модел Tongyi Qwen с основни подобрения в логическото мислене, общите способности, агентните възможности и многоезичната производителност, като поддържа превключване между режими на мислене.",
  "Qwen/Qwen3-235B-A22B-Instruct-2507.description": "Qwen3-235B-A22B-Instruct-2507 е водещ MoE модел от серията Qwen3 с общо 235B и 22B активни параметри. Това е актуализирана версия без мислене, фокусирана върху подобряване на следването на инструкции, логическото мислене, разбирането на текст, математика, наука, програмиране и използване на инструменти. Разширява също така многоезичните знания и се съобразява по-добре с предпочитанията на потребителите при субективни отворени задачи.",
  "Qwen/Qwen3-235B-A22B-Thinking-2507.description": "Qwen3-235B-A22B-Thinking-2507 е модел от серията Qwen3, фокусиран върху сложни логически задачи. Използва MoE архитектура с общо 235B и ~22B активни параметри на токен за повишена ефективност. Като специализиран мислещ модел, показва значителни подобрения в логика, математика, наука, програмиране и академични оценки, достигайки водещи резултати сред отворените мислещи модели. Подобрява също следването на инструкции, използването на инструменти и генерирането на текст, като нативно поддържа 256K контекст за дълбоко разсъждение и дълги документи.",
  "Qwen/Qwen3-235B-A22B.description": "Qwen3 е следващо поколение модел Tongyi Qwen с основни подобрения в логическото мислене, общите способности, агентните възможности и многоезичната производителност, като поддържа превключване между режими на мислене.",
  "Qwen/Qwen3-30B-A3B-Instruct-2507.description": "Qwen3-30B-A3B-Instruct-2507 е актуализираната немислеща версия на Qwen3-30B-A3B. Това е MoE модел с общо 30.5B и 3.3B активни параметри. Значително подобрява следването на инструкции, логическото мислене, разбирането на текст, математика, наука, програмиране и използване на инструменти, разширява многоезичните знания и се съобразява по-добре с предпочитанията на потребителите при субективни отворени задачи. Поддържа 256K контекст. Този модел е само немислещ и няма да генерира тагове `<think></think>`.",
  "Qwen/Qwen3-30B-A3B-Thinking-2507.description": "Qwen3-30B-A3B-Thinking-2507 е най-новият мислещ модел от серията Qwen3. Това е MoE модел с общо 30.5B и 3.3B активни параметри, фокусиран върху сложни задачи. Показва значителни подобрения в логика, математика, наука, програмиране и академични оценки, и подобрява следването на инструкции, използването на инструменти, генерирането на текст и съобразяването с предпочитания. Нативно поддържа 256K контекст и може да се разшири до 1M токена. Тази версия е проектирана за мислещ режим с детайлно стъпково разсъждение и силни агентни възможности.",
  "Qwen/Qwen3-30B-A3B.description": "Qwen3 е следващо поколение модел Tongyi Qwen с основни подобрения в логическото мислене, общите способности, агентните възможности и многоезичната производителност, като поддържа превключване между режими на мислене.",
  "Qwen/Qwen3-32B.description": "Qwen3 е следващо поколение модел Tongyi Qwen с основни подобрения в логическото мислене, общите способности, агентните възможности и многоезичната производителност, като поддържа превключване между режими на мислене.",
  "Qwen/Qwen3-8B.description": "Qwen3 е следващо поколение модел Tongyi Qwen с основни подобрения в логическото мислене, общите способности, агентните възможности и многоезичната производителност, като поддържа превключване между режими на мислене.",
  "Qwen/Qwen3-Coder-30B-A3B-Instruct.description": "Qwen3-Coder-30B-A3B-Instruct е модел за програмиране от серията Qwen3, разработен от екипа на Qwen. Той е оптимизиран за висока производителност и ефективност, като същевременно подобрява възможностите за работа с код. Демонстрира силни предимства при агентно програмиране, автоматизирани операции в браузър и използване на инструменти сред отворените модели. Поддържа нативно контекст от 256K токена и може да се разшири до 1M токена за разбиране на цели кодови бази. Използва се за агентно програмиране в платформи като Qwen Code и CLINE с посветен формат за извикване на функции.",
  "Qwen/Qwen3-Coder-480B-A35B-Instruct.description": "Qwen3-Coder-480B-A35B-Instruct е най-агентният модел за програмиране на Alibaba до момента. Това е MoE модел с общо 480 милиарда параметъра и 35 милиарда активни, осигуряващ баланс между ефективност и производителност. Поддържа нативно контекст от 256K токена и може да се разшири до 1M токена чрез YaRN, което позволява работа с големи кодови бази. Създаден е за агентни работни потоци при програмиране и може да взаимодейства с инструменти и среди за решаване на сложни задачи. Постига водещи резултати сред отворените модели в бенчмаркове за програмиране и агенти, сравними с Claude Sonnet 4.",
  "Qwen/Qwen3-Next-80B-A3B-Instruct.description": "Qwen3-Next-80B-A3B-Instruct е базов модел от ново поколение, използващ архитектурата Qwen3-Next за изключителна ефективност при обучение и инференция. Комбинира хибридно внимание (Gated DeltaNet + Gated Attention), силно разреден MoE и оптимизации за стабилност при обучение. С общо 80 милиарда параметъра, но само ~3 милиарда активни при инференция, значително намалява изчислителните ресурси и осигурява над 10 пъти по-висока пропускателност спрямо Qwen3-32B при контексти над 32K. Тази версия, настроена за инструкции, е насочена към общи задачи (без режим на мислене). Представя се наравно с Qwen3-235B в някои бенчмаркове и показва силни предимства при задачи с ултра-дълъг контекст.",
  "Qwen/Qwen3-Next-80B-A3B-Thinking.description": "Qwen3-Next-80B-A3B-Thinking е базов модел от ново поколение, предназначен за сложни разсъждения. Използва архитектурата Qwen3-Next с хибридно внимание (Gated DeltaNet + Gated Attention) и силно разреден MoE за изключителна ефективност при обучение и инференция. С общо 80 милиарда параметъра и ~3 милиарда активни при инференция, намалява изчислителните разходи и осигурява над 10 пъти по-висока пропускателност спрямо Qwen3-32B при контексти над 32K. Тази версия „Thinking“ е насочена към многoетапни задачи като доказателства, синтез на код, логически анализ и планиране, като генерира структурирана верига от мисли. Надминава Qwen3-32B-Thinking и побеждава Gemini-2.5-Flash-Thinking в няколко бенчмарка.",
  "Qwen/Qwen3-Omni-30B-A3B-Captioner.description": "Qwen3-Omni-30B-A3B-Captioner е VLM модел от серията Qwen3, създаден за висококачествени, детайлни и точни описания на изображения. Използва MoE архитектура с 30 милиарда параметъра за дълбоко разбиране на изображения и генериране на плавни описания, като се отличава в улавянето на детайли, разбиране на сцени, разпознаване на обекти и логически връзки.",
  "Qwen/Qwen3-Omni-30B-A3B-Instruct.description": "Qwen3-Omni-30B-A3B-Instruct е MoE модел от серията Qwen3 с общо 30 милиарда и 3 милиарда активни параметъра, осигуряващ висока производителност при ниска цена на инференция. Обучен е върху висококачествени многоезични данни от различни източници и поддържа пълноформатни входове (текст, изображения, аудио, видео), както и кросмодално разбиране и генериране.",
  "Qwen/Qwen3-Omni-30B-A3B-Thinking.description": "Qwen3-Omni-30B-A3B-Thinking е основният компонент „Мислител“ на Qwen3-Omni. Обработва мултимодални входове (текст, аудио, изображения, видео) и извършва сложни разсъждения чрез верига от мисли, обединявайки входовете в споделено представяне за дълбоко кросмодално разбиране. Това е MoE модел с 30 милиарда общи и 3 милиарда активни параметъра, балансиращ силни разсъждения и изчислителна ефективност.",
  "Qwen/Qwen3-VL-235B-A22B-Instruct.description": "Qwen3-VL-235B-A22B-Instruct е голям модел от серията Qwen3-VL, настроен за инструкции и изграден върху MoE архитектура, осигуряващ отлично мултимодално разбиране и генериране. Поддържа нативно контекст от 256K токена и е подходящ за високонагружени производствени мултимодални услуги.",
  "Qwen/Qwen3-VL-235B-A22B-Thinking.description": "Qwen3-VL-235B-A22B-Thinking е водещата версия за разсъждение на Qwen3-VL, оптимизирана за сложни мултимодални разсъждения, дълъг контекст и взаимодействие с агенти в корпоративни сценарии.",
  "Qwen/Qwen3-VL-30B-A3B-Instruct.description": "Qwen3-VL-30B-A3B-Instruct е настроен за инструкции модел от серията Qwen3-VL с високо ниво на разбиране и генериране на визия и език. Поддържа нативно контекст от 256K токена за мултимодален чат и генериране, базирано на изображения.",
  "Qwen/Qwen3-VL-30B-A3B-Thinking.description": "Qwen3-VL-30B-A3B-Thinking е версия с подобрени разсъждения на Qwen3-VL, оптимизирана за мултимодални разсъждения, преобразуване на изображения в код и сложно визуално разбиране. Поддържа контекст от 256K токена с по-силна способност за верига от мисли.",
  "Qwen/Qwen3-VL-32B-Instruct.description": "Qwen3-VL-32B-Instruct е модел за визия и език от екипа на Qwen с водещи резултати в множество VL бенчмаркове. Поддържа изображения с мегапикселова резолюция и предлага силно визуално разбиране, многоезичен OCR, прецизно визуално позициониране и визуален диалог. Обработва сложни мултимодални задачи и поддържа извикване на инструменти и допълване на префикси.",
  "Qwen/Qwen3-VL-32B-Thinking.description": "Qwen3-VL-32B-Thinking е оптимизиран за сложно визуално разсъждение. Включва вграден режим на мислене, който генерира междинни стъпки на разсъждение преди отговорите, подобрявайки логиката на многоетапни задачи, планиране и сложни разсъждения. Поддържа изображения с мегапикселова резолюция, силно визуално разбиране, многоезичен OCR, прецизно позициониране, визуален диалог, извикване на инструменти и допълване на префикси.",
  "Qwen/Qwen3-VL-8B-Instruct.description": "Qwen3-VL-8B-Instruct е модел за визия и език от серията Qwen3, изграден върху Qwen3-8B-Instruct и обучен върху големи обеми от данни с изображения и текст. Отличава се с общо визуално разбиране, диалог, фокусиран върху визията, и многоезично разпознаване на текст в изображения. Подходящ е за визуални въпроси и отговори, описания, следване на мултимодални инструкции и използване на инструменти.",
  "Qwen/Qwen3-VL-8B-Thinking.description": "Qwen3-VL-8B-Thinking е визуалната версия за разсъждение на Qwen3, оптимизирана за сложно многоетапно разсъждение. Генерира верига от мисли преди отговорите за подобрена точност, идеална за задълбочени визуални въпроси и отговори и детайлен анализ на изображения.",
  "Qwen2-72B-Instruct.description": "Qwen2 е най-новата версия от серията Qwen, поддържаща контекстен прозорец от 128k. В сравнение с най-добрите отворени модели днес, Qwen2-72B значително превъзхожда водещите модели в разбирането на естествен език, знания, програмиране, математика и многоезични възможности.",
  "Qwen2-7B-Instruct.description": "Qwen2 е най-новата версия от серията Qwen, която превъзхожда най-добрите отворени модели със сходен или дори по-голям размер. Qwen2 7B показва значителни предимства в множество бенчмаркове, особено в програмиране и разбиране на китайски език.",
  "Qwen2-VL-72B.description": "Qwen2-VL-72B е мощен модел за визия и език, поддържащ мултимодална обработка на изображения и текст, като точно разпознава съдържанието на изображения и генерира съответни описания или отговори.",
  "Qwen2.5-14B-Instruct.description": "Qwen2.5-14B-Instruct е LLM с 14 милиарда параметъра и висока производителност, оптимизиран за китайски и многоезични сценарии, поддържащ интелигентни въпроси и отговори и генериране на съдържание.",
  "Qwen2.5-32B-Instruct.description": "Qwen2.5-32B-Instruct е LLM с 32 милиарда параметъра и балансирана производителност, оптимизиран за китайски и многоезични сценарии, поддържащ интелигентни въпроси и отговори и генериране на съдържание.",
  "Qwen2.5-72B-Instruct.description": "LLM за китайски и английски език, настроен за език, програмиране, математика и логическо разсъждение.",
  "Qwen2.5-7B-Instruct.description": "Qwen2.5-7B-Instruct е LLM с 7 милиарда параметъра, който поддържа извикване на функции и безпроблемна интеграция с външни системи, значително подобрявайки гъвкавостта и разширяемостта. Оптимизиран е за китайски и многоезични сценарии, поддържащ интелигентни въпроси и отговори и генериране на съдържание.",
  "Qwen2.5-Coder-14B-Instruct.description": "Qwen2.5-Coder-14B-Instruct е мащабен предварително обучен модел за програмиране с отлични способности за разбиране и генериране на код. Ефективно се справя с широк спектър от програмни задачи, идеален за интелигентно програмиране, автоматично генериране на скриптове и въпроси и отговори, свързани с програмиране.",
  "Qwen2.5-Coder-32B-Instruct.description": "Разширен LLM за генериране на код, логическо разсъждение и отстраняване на грешки на основните програмни езици.",
  "Qwen3-235B-A22B-Instruct-2507-FP8.description": "Qwen3 235B A22B Instruct 2507 е оптимизиран за напреднало разсъждение и следване на инструкции, използвайки MoE за ефективно мащабиране на разсъждението.",
  "Qwen3-235B.description": "Qwen3-235B-A22B е MoE модел, който въвежда хибриден режим на разсъждение, позволяващ на потребителите да превключват безпроблемно между мислещ и немислещ режим. Поддържа разбиране и разсъждение на 119 езика и диалекта и има силни възможности за извикване на инструменти, конкурирайки се с водещи модели като DeepSeek R1, OpenAI o1, o3-mini, Grok 3 и Google Gemini 2.5 Pro в бенчмаркове за общи способности, програмиране и математика, многоезичност и логическо разсъждение.",
  "Qwen3-32B.description": "Qwen3-32B е плътен модел, който въвежда хибриден режим на разсъждение, позволяващ на потребителите да превключват между мислещ и немислещ режим. С архитектурни подобрения, повече данни и по-добро обучение, той се представя наравно с Qwen2.5-72B.",
  "SenseChat-128K.description": "Базов модел V4 с контекст от 128K, силен в разбиране и генериране на дълги текстове.",
  "SenseChat-32K.description": "Базов модел V4 с контекст от 32K, гъвкав за различни сценарии.",
  "SenseChat-5-1202.description": "Най-новата версия, базирана на V5.5, с значителни подобрения в основни знания по китайски/английски, чат, STEM, хуманитарни науки, писане, математика/логика и контрол на дължината.",
  "SenseChat-5-Cantonese.description": "Проектиран за диалектни навици, жаргон и местни знания в Хонконг; надминава GPT-4 в разбирането на кантонски и съперничи на GPT-4 Turbo в знания, логика, математика и програмиране.",
  "SenseChat-5-beta.description": "Някои показатели надвишават тези на SenseChat-5-1202.",
  "SenseChat-5.description": "Най-новият V5.5 с контекст от 128K; значителни подобрения в математическо разсъждение, чат на английски, следване на инструкции и разбиране на дълги текстове, сравним с GPT-4o.",
  "SenseChat-Character-Pro.description": "Разширен модел за чат с персонажи с контекст от 32K, подобрени възможности и поддръжка на китайски/английски.",
  "SenseChat-Character.description": "Стандартен модел за чат с персонажи с контекст от 8K и висока скорост на отговор.",
  "SenseChat-Turbo-1202.description": "Най-новият лек модел, достигащ над 90% от възможностите на пълния модел с значително по-ниска цена за инференция.",
  "SenseChat-Turbo.description": "Подходящ за бързи въпроси и отговори и сценарии за фина настройка на модели.",
  "SenseChat-Vision.description": "Най-новият V5.5 с вход от множество изображения и широки основни подобрения в разпознаване на атрибути, пространствени отношения, действия/събития, разбиране на сцени, разпознаване на емоции, логическо разсъждение и разбиране/генериране на текст.",
  "SenseChat.description": "Базов модел V4 с контекст от 4K и силни общи възможности.",
  "SenseNova-V6-5-Pro.description": "Със значителни подобрения в мултимодалните, езиковите и логическите данни, както и с оптимизация на стратегията за обучение, новият модел значително подобрява мултимодалното разсъждение и следването на обобщени инструкции, поддържа контекстен прозорец до 128k и се отличава в задачи по OCR и разпознаване на културен и туристически IP.",
  "SenseNova-V6-5-Turbo.description": "Със значителни подобрения в мултимодалните, езиковите и логическите данни, както и с оптимизация на стратегията за обучение, новият модел значително подобрява мултимодалното разсъждение и следването на обобщени инструкции, поддържа контекстен прозорец до 128k и се отличава в задачи по OCR и разпознаване на културен и туристически IP.",
  "SenseNova-V6-Pro.description": "Нативно обединява изображение, текст и видео, преодолявайки традиционните мултимодални ограничения; заема водещи позиции в OpenCompass и SuperCLUE.",
  "SenseNova-V6-Reasoner.description": "Комбинира дълбоко разсъждение чрез зрение и език, поддържа бавно мислене и пълна верига на мисълта.",
  "SenseNova-V6-Turbo.description": "Нативно обединява изображение, текст и видео, преодолявайки традиционните мултимодални ограничения. Води в основните мултимодални и езикови възможности и заема челни позиции в множество оценки.",
  "Skylark2-lite-8k.description": "Модел от второ поколение Skylark. Skylark2-lite осигурява бързи отговори за реалновремеви, чувствителни към разходите сценарии с по-ниски изисквания за точност, с контекстен прозорец от 8K.",
  "Skylark2-pro-32k.description": "Модел от второ поколение Skylark. Skylark2-pro предлага по-висока точност за сложни задачи по генериране на текст като професионално копирайтинг, писане на романи и висококачествен превод, с контекстен прозорец от 32K.",
  "Skylark2-pro-4k.description": "Модел от второ поколение Skylark. Skylark2-pro предлага по-висока точност за сложни задачи по генериране на текст като професионално копирайтинг, писане на романи и висококачествен превод, с контекстен прозорец от 4K.",
  "Skylark2-pro-character-4k.description": "Модел от второ поколение Skylark. Skylark2-pro-character се отличава в ролеви игри и чат, съчетавайки подканите с отличителни стилове на персонажи и естествен диалог за чатботи, виртуални асистенти и обслужване на клиенти, с бързи отговори.",
  "Skylark2-pro-turbo-8k.description": "Модел от второ поколение Skylark. Skylark2-pro-turbo-8k предлага по-бърза инференция на по-ниска цена с контекстен прозорец от 8K.",
  "THUDM/GLM-4-32B-0414.description": "GLM-4-32B-0414 е следващо поколение отворен GLM модел с 32 милиарда параметъра, сравним по производителност с OpenAI GPT и сериите DeepSeek V3/R1.",
  "THUDM/GLM-4-9B-0414.description": "GLM-4-9B-0414 е 9-милиарден GLM модел, който наследява технологиите на GLM-4-32B, като същевременно предлага по-леко внедряване. Представя се добре в генериране на код, уеб дизайн, създаване на SVG и писане, базирано на търсене.",
  "THUDM/GLM-4.1V-9B-Thinking.description": "GLM-4.1V-9B-Thinking е отворен VLM модел от Zhipu AI и лабораторията KEG на Цинхуа, създаден за сложна мултимодална когниция. Изграден върху GLM-4-9B-0414, добавя верижно разсъждение и подсилено обучение (RL), значително подобрявайки между-модалното разсъждение и стабилността.",
  "THUDM/GLM-Z1-32B-0414.description": "GLM-Z1-32B-0414 е модел за дълбоко разсъждение, изграден от GLM-4-32B-0414 с данни за студен старт и разширено подсилено обучение, допълнително обучен върху математика, код и логика. Значително подобрява способността за решаване на сложни задачи спрямо базовия модел.",
  "THUDM/GLM-Z1-9B-0414.description": "GLM-Z1-9B-0414 е компактен GLM модел с 9 милиарда параметъра, който запазва силните страни на отворения код, като същевременно предлага впечатляващи възможности. Представя се отлично в математическо разсъждение и общи задачи, водещ в своя клас сред отворените модели.",
  "THUDM/GLM-Z1-Rumination-32B-0414.description": "GLM-Z1-Rumination-32B е модел за дълбоко разсъждение с възможности за „размисъл“ (сравним с OpenAI Deep Research). За разлика от типичните модели за дълбоко мислене, той отделя повече време за обмисляне, за да решава по-отворени и сложни проблеми.",
  "THUDM/glm-4-9b-chat.description": "GLM-4-9B-Chat е отвореният GLM-4 модел от Zhipu AI. Представя се силно в семантика, математика, разсъждение, код и знания. Освен многозавойни чатове, поддържа уеб браузване, изпълнение на код, извикване на персонализирани инструменти и разсъждение върху дълги текстове. Поддържа 26 езика (включително китайски, английски, японски, корейски, немски). Представя се добре в AlignBench-v2, MT-Bench, MMLU и C-Eval и поддържа до 128K контекст за академична и бизнес употреба.",
  "Tongyi-Zhiwen/QwenLong-L1-32B.description": "QwenLong-L1-32B е първият модел за разсъждение с дълъг контекст (LRM), обучен с подсилено обучение, оптимизиран за разсъждение върху дълги текстове. Неговото прогресивно разширяване на контекста чрез RL позволява стабилен преход от кратък към дълъг контекст. Надминава OpenAI-o3-mini и Qwen3-235B-A22B в седем бенчмарка за въпроси и отговори върху документи с дълъг контекст, съперничи на Claude-3.7-Sonnet-Thinking. Особено силен е в математика, логика и многозвенно разсъждение.",
  "Yi-34B-Chat.description": "Yi-1.5-34B запазва силните езикови способности на серията, като използва инкрементално обучение върху 500 милиарда висококачествени токена, за да подобри значително логиката в математиката и програмирането.",
  "abab5.5-chat.description": "Създаден за продуктивни сценарии с обработка на сложни задачи и ефективно генериране на текст за професионална употреба.",
  "abab5.5s-chat.description": "Проектиран за чат с китайски персонажи, осигуряващ висококачествен диалог на китайски език за различни приложения.",
  "abab6.5g-chat.description": "Проектиран за многоезичен чат с персонажи, поддържащ висококачествено генериране на диалог на английски и други езици.",
  "abab6.5s-chat.description": "Подходящ за широк спектър от NLP задачи, включително генериране на текст и диалогови системи.",
  "abab6.5t-chat.description": "Оптимизиран за чат с китайски персонажи, осигуряващ плавен диалог, съобразен с китайските езикови навици.",
  "accounts/fireworks/models/deepseek-r1.description": "DeepSeek-R1 е модерен LLM, оптимизиран с обучение чрез подсилване и cold-start данни, осигуряващ отлично представяне при логическо разсъждение, математика и програмиране.",
  "accounts/fireworks/models/deepseek-v3.description": "Мощен езиков модел от тип Mixture-of-Experts (MoE) от DeepSeek с общо 671 милиарда параметъра и 37 милиарда активни параметъра на токен.",
  "accounts/fireworks/models/llama-v3-70b-instruct.description": "Meta разработи и пусна серията Meta Llama 3 LLM, която включва предварително обучени и фино настроени за инструкции модели за генериране на текст с размери 8B и 70B. Моделите Llama 3, фино настроени за инструкции, са оптимизирани за разговорна употреба и надминават много от съществуващите отворени чат модели по общи индустриални показатели.",
  "accounts/fireworks/models/llama-v3-8b-instruct-hf.description": "Моделите Meta Llama 3, фино настроени за инструкции, са оптимизирани за разговорна употреба и надминават много от съществуващите отворени чат модели по общи индустриални показатели. Llama 3 8B Instruct (HF версия) е оригиналната FP16 версия на Llama 3 8B Instruct, като се очаква резултатите да съвпадат с официалната имплементация на Hugging Face.",
  "accounts/fireworks/models/llama-v3-8b-instruct.description": "Meta разработи и пусна серията Meta Llama 3 LLM — колекция от предварително обучени и фино настроени за инструкции модели за генериране на текст с размери 8B и 70B. Моделите Llama 3, фино настроени за инструкции, са оптимизирани за разговорна употреба и надминават много от съществуващите отворени чат модели по общи индустриални показатели.",
  "accounts/fireworks/models/llama-v3p1-405b-instruct.description": "Meta Llama 3.1 е многоезично LLM семейство с предварително обучени и фино настроени за инструкции модели за генериране с размери 8B, 70B и 405B. Моделите, фино настроени за текстови инструкции, са оптимизирани за многоезичен диалог и надминават много от съществуващите отворени и затворени чат модели по общи индустриални показатели. 405B е най-способният модел в семейството Llama 3.1, използващ FP8 извод, който точно съвпада с референтната имплементация.",
  "accounts/fireworks/models/llama-v3p1-70b-instruct.description": "Meta Llama 3.1 е многоезично LLM семейство с предварително обучени и фино настроени за инструкции модели за генериране с размери 8B, 70B и 405B. Моделите, фино настроени за текстови инструкции, са оптимизирани за многоезичен диалог и надминават много от съществуващите отворени и затворени чат модели по общи индустриални показатели.",
  "accounts/fireworks/models/llama-v3p1-8b-instruct.description": "Meta Llama 3.1 е многоезично LLM семейство с предварително обучени и фино настроени за инструкции модели за генериране с размери 8B, 70B и 405B. Моделите, фино настроени за текстови инструкции, са оптимизирани за многоезичен диалог и надминават много от съществуващите отворени и затворени чат модели по общи индустриални показатели.",
  "accounts/fireworks/models/llama-v3p2-11b-vision-instruct.description": "Фино настроен за инструкции модел за визуално разсъждение от Meta с 11 милиарда параметъра, оптимизиран за визуално разпознаване, логическо разсъждение по изображения, надписи и въпроси и отговори, свързани с изображения. Разбира визуални данни като диаграми и графики и свързва визията и езика чрез генериране на текстови описания на детайли от изображенията.",
  "accounts/fireworks/models/llama-v3p2-3b-instruct.description": "Llama 3.2 3B Instruct е лек многоезичен модел от Meta, проектиран за ефективна работа с предимства по отношение на латентност и разходи спрямо по-големите модели. Типични случаи на употреба включват пренаписване на заявки/подсказки и помощ при писане.",
  "accounts/fireworks/models/llama-v3p2-90b-vision-instruct.description": "Фино настроен за инструкции модел за визуално разсъждение от Meta с 90 милиарда параметъра, оптимизиран за визуално разпознаване, логическо разсъждение по изображения, надписи и въпроси и отговори, свързани с изображения. Разбира визуални данни като диаграми и графики и свързва визията и езика чрез генериране на текстови описания на детайли от изображенията. Забележка: този модел се предоставя експериментално като безсървърен модел. За производствена употреба имайте предвид, че Fireworks може да прекрати разполагането без предизвестие.",
  "accounts/fireworks/models/llama-v3p3-70b-instruct.description": "Llama 3.3 70B Instruct е декемврийската актуализация на Llama 3.1 70B. Подобрява използването на инструменти, поддръжката на многоезичен текст, математиката и програмирането спрямо изданието от юли 2024 г. Достига водещо в индустрията представяне при логическо разсъждение, математика и следване на инструкции, като предлага производителност, сравнима с 3.1 405B, но със значителни предимства по отношение на скорост и разходи.",
  "accounts/fireworks/models/mistral-small-24b-instruct-2501.description": "Модел с 24 милиарда параметъра и водещи възможности, сравними с по-големи модели.",
  "accounts/fireworks/models/mixtral-8x22b-instruct.description": "Mixtral MoE 8x22B Instruct v0.1 е фино настроената за инструкции версия на Mixtral MoE 8x22B v0.1, с активиран API за завършване на чат.",
  "accounts/fireworks/models/mixtral-8x7b-instruct.description": "Mixtral MoE 8x7B Instruct е фино настроената за инструкции версия на Mixtral MoE 8x7B, с активиран API за завършване на чат.",
  "accounts/fireworks/models/mythomax-l2-13b.description": "Подобрена версия на MythoMix, вероятно по-усъвършенствана форма, обединяваща MythoLogic-L2 и Huginn с експериментална техника за сливане на тензори. Уникалната ѝ природа я прави отлична за разказване на истории и ролеви игри.",
  "accounts/fireworks/models/phi-3-vision-128k-instruct.description": "Phi-3-Vision-128K-Instruct е лек, модерен отворен мултимодален модел, изграден от синтетични данни и подбрани публични уеб набори от данни, фокусиран върху висококачествени текстови и визуални данни, изискващи логическо разсъждение. Принадлежи към семейството Phi-3, с мултимодална версия, поддържаща контекст с дължина 128K токена. Моделът преминава през задълбочено подобрение, включително фино обучение под надзор и директна оптимизация на предпочитанията, за да осигури точно следване на инструкции и силни мерки за безопасност.",
  "accounts/fireworks/models/qwen-qwq-32b-preview.description": "Моделът Qwen QwQ се фокусира върху напредъка в логическото разсъждение на ИИ, демонстрирайки, че отворените модели могат да съперничат на затворените водещи модели. QwQ-32B-Preview е експериментално издание, което съвпада с o1 и надминава GPT-4o и Claude 3.5 Sonnet по логическо разсъждение и анализ в GPQA, AIME, MATH-500 и LiveCodeBench. Забележка: този модел се предоставя експериментално като безсървърен модел. За производствена употреба имайте предвид, че Fireworks може да прекрати разполагането без предизвестие.",
  "accounts/fireworks/models/qwen2-vl-72b-instruct.description": "Моделът Qwen-VL с 72 милиарда параметъра е най-новата итерация на Alibaba, отразяваща почти година иновации.",
  "accounts/fireworks/models/qwen2p5-72b-instruct.description": "Qwen2.5 е серия LLM само с декодер, разработена от екипа на Qwen и Alibaba Cloud, предлагаща размери 0.5B, 1.5B, 3B, 7B, 14B, 32B и 72B, с базови и фино настроени за инструкции варианти.",
  "accounts/fireworks/models/qwen2p5-coder-32b-instruct.description": "Qwen2.5-Coder е най-новият LLM от Qwen, проектиран за програмиране (преди CodeQwen). Забележка: този модел се предоставя експериментално като безсървърен модел. За производствена употреба имайте предвид, че Fireworks може да прекрати разполагането без предизвестие.",
  "accounts/yi-01-ai/models/yi-large.description": "Yi-Large е LLM от най-висок клас, който се нарежда непосредствено под GPT-4, Gemini 1.5 Pro и Claude 3 Opus в класацията LMSYS. Отличава се с многоезични възможности, особено на испански, китайски, японски, немски и френски. Yi-Large е също така удобен за разработчици, използвайки същата API схема като OpenAI за лесна интеграция.",
  "ai21-jamba-1.5-large.description": "Многоезичен модел с 398 милиарда параметъра (94 милиарда активни), с прозорец на контекста от 256 хиляди токена, поддръжка на извикване на функции, структурирани изходи и обосновано генериране.",
  "ai21-jamba-1.5-mini.description": "Многоезичен модел с 52 милиарда параметъра (12 милиарда активни), с прозорец на контекста от 256 хиляди токена, поддръжка на извикване на функции, структурирани изходи и обосновано генериране.",
  "ai21-labs/AI21-Jamba-1.5-Large.description": "Многоезичен модел с 398 милиарда параметъра (94 милиарда активни), с прозорец на контекста от 256 хиляди токена, поддръжка на извикване на функции, структурирани изходи и обосновано генериране.",
  "ai21-labs/AI21-Jamba-1.5-Mini.description": "Многоезичен модел с 52 милиарда параметъра (12 милиарда активни), с прозорец на контекста от 256 хиляди токена, поддръжка на извикване на функции, структурирани изходи и обосновано генериране.",
  "alibaba/qwen-3-14b.description": "Qwen3 е най-новото поколение от серията Qwen, предлагащо пълен набор от плътни и MoE модели. Обучен върху обширни данни, той постига пробиви в логическото мислене, следване на инструкции, агентни способности и многоезична поддръжка.",
  "alibaba/qwen-3-235b.description": "Qwen3 е най-новото поколение от серията Qwen, предлагащо пълен набор от плътни и MoE модели. Обучен върху обширни данни, той постига пробиви в логическото мислене, следване на инструкции, агентни способности и многоезична поддръжка.",
  "alibaba/qwen-3-30b.description": "Qwen3 е най-новото поколение от серията Qwen, предлагащо пълен набор от плътни и MoE модели. Обучен върху обширни данни, той постига пробиви в логическото мислене, следване на инструкции, агентни способности и многоезична поддръжка.",
  "alibaba/qwen-3-32b.description": "Qwen3 е най-новото поколение от серията Qwen, предлагащо пълен набор от плътни и MoE модели. Обучен върху обширни данни, той постига пробиви в логическото мислене, следване на инструкции, агентни способности и многоезична поддръжка.",
  "alibaba/qwen3-coder.description": "Qwen3-Coder-480B-A35B-Instruct е най-агентният кодов модел на Qwen, с отлични резултати при агентно програмиране, използване на браузър и други основни задачи, съпоставим с Claude Sonnet.",
  "amazon/nova-lite.description": "Многофункционален модел с изключително ниска цена и много бърза обработка на изображения, видео и текст.",
  "amazon/nova-micro.description": "Само текстов модел с ултраниска латентност и много ниска цена.",
  "amazon/nova-pro.description": "Многофункционален модел с отличен баланс между точност, скорост и цена за широк спектър от задачи.",
  "amazon/titan-embed-text-v2.description": "Amazon Titan Text Embeddings V2 е лек и ефективен многоезичен embedding модел, поддържащ 1024, 512 и 256 измерения.",
  "anthropic.claude-3-5-sonnet-20240620-v1:0.description": "Claude 3.5 Sonnet поставя нов стандарт в индустрията, надминавайки конкурентите и Claude 3 Opus в широки оценки, като същевременно запазва средно ниво на скорост и цена.",
  "anthropic.claude-3-5-sonnet-20241022-v2:0.description": "Claude 3.5 Sonnet поставя нов стандарт в индустрията, надминавайки конкурентите и Claude 3 Opus в широки оценки, като същевременно запазва средно ниво на скорост и цена.",
  "anthropic.claude-3-haiku-20240307-v1:0.description": "Claude 3 Haiku е най-бързият и най-компактен модел на Anthropic, осигуряващ почти мигновени отговори на прости заявки. Поддържа вход от изображения и прозорец на контекста от 200 хиляди токена.",
  "anthropic.claude-3-opus-20240229-v1:0.description": "Claude 3 Opus е най-мощният AI модел на Anthropic с водеща производителност при сложни задачи. Обработва отворени заявки и нови сценарии с изключителна плавност и човешко разбиране, поддържа вход от изображения и прозорец на контекста от 200 хиляди токена.",
  "anthropic.claude-3-sonnet-20240229-v1:0.description": "Claude 3 Sonnet балансира интелигентност и скорост за корпоративни натоварвания, предлага висока стойност при по-ниска цена. Поддържа вход от изображения и прозорец на контекста от 200 хиляди токена.",
  "anthropic.claude-instant-v1.description": "Бърз, икономичен и способен модел за ежедневен чат, анализ на текст, обобщение и въпроси по документи.",
  "anthropic.claude-v2.description": "Много способен модел за задачи от сложен диалог и творческо генериране до точно следване на инструкции.",
  "anthropic.claude-v2:1.description": "Обновен Claude 2 с удвоен прозорец на контекста и подобрена надеждност, по-ниска честота на халюцинации и по-точни отговори, базирани на доказателства, за дълги документи и RAG.",
  "anthropic/claude-3-haiku.description": "Claude 3 Haiku е най-бързият модел на Anthropic, проектиран за корпоративни натоварвания с по-дълги заявки. Бързо анализира големи документи като тримесечни отчети, договори или правни случаи на половин цена спрямо конкурентите.",
  "anthropic/claude-3-opus.description": "Claude 3 Opus е най-интелигентният модел на Anthropic с водеща производителност при сложни задачи, обработва отворени заявки и нови сценарии с изключителна плавност и човешко разбиране.",
  "anthropic/claude-3.5-haiku.description": "Claude 3.5 Haiku предлага подобрена скорост, точност при програмиране и използване на инструменти, подходящ за сценарии с високи изисквания към скорост и взаимодействие с инструменти.",
  "anthropic/claude-3.5-sonnet.description": "Claude 3.5 Sonnet е бърз и ефективен модел от семейството Sonnet, с подобрена производителност при програмиране и логическо мислене. Някои версии постепенно се заменят от Sonnet 3.7 и по-нови.",
  "anthropic/claude-3.7-sonnet.description": "Claude 3.7 Sonnet е подобрен модел от серията Sonnet с по-силно логическо мислене и програмиране, подходящ за сложни корпоративни задачи.",
  "anthropic/claude-haiku-4.5.description": "Claude Haiku 4.5 е високопроизводителен и бърз модел на Anthropic, осигуряващ много ниска латентност при запазване на висока точност.",
  "anthropic/claude-opus-4.1.description": "Opus 4.1 е висок клас модел на Anthropic, оптимизиран за програмиране, сложно логическо мислене и дълготрайни задачи.",
  "anthropic/claude-opus-4.5.description": "Claude Opus 4.5 е флагманският модел на Anthropic, съчетаващ върхова интелигентност с мащабируема производителност за сложни задачи с високо качество на разсъждение.",
  "anthropic/claude-opus-4.description": "Opus 4 е флагманският модел на Anthropic, проектиран за сложни задачи и корпоративни приложения.",
  "anthropic/claude-sonnet-4.5.description": "Claude Sonnet 4.5 е най-новият хибриден модел за логическо мислене на Anthropic, оптимизиран за сложни разсъждения и програмиране.",
  "anthropic/claude-sonnet-4.description": "Claude Sonnet 4 е хибриден модел за логическо мислене на Anthropic с комбинирани способности за мислене и бързи отговори.",
  "ascend-tribe/pangu-pro-moe.description": "Pangu-Pro-MoE 72B-A16B е разреден LLM с общо 72 милиарда и 16 милиарда активни параметри, базиран на групирана MoE (MoGE) архитектура. Групира експерти при избора и ограничава токените да активират равен брой експерти на група, което балансира натоварването и подобрява ефективността на внедряване върху Ascend.",
  "aya.description": "Aya 23 е многоезичен модел на Cohere, поддържащ 23 езика за разнообразни приложения.",
  "aya:35b.description": "Aya 23 е многоезичен модел на Cohere, поддържащ 23 езика за разнообразни приложения.",
  "azure-DeepSeek-R1-0528.description": "Разположен от Microsoft; DeepSeek R1 е надграден до DeepSeek-R1-0528. Актуализацията увеличава изчислителната мощ и оптимизациите след обучение, значително подобрявайки дълбочината на разсъждение и извеждането. Представя се отлично в тестове по математика, програмиране и логика, доближавайки се до водещи модели като O3 и Gemini 2.5 Pro.",
  "baichuan-m2-32b.description": "Baichuan M2 32B е MoE модел от Baichuan Intelligence със силни способности за разсъждение.",
  "baichuan/baichuan2-13b-chat.description": "Baichuan-13B е отворен, търговски използваем LLM с 13 милиарда параметри от Baichuan, постигайки водещи резултати за своя размер в авторитетни китайски и английски тестове.",
  "baidu/ERNIE-4.5-300B-A47B.description": "ERNIE-4.5-300B-A47B е MoE LLM на Baidu с общо 300 милиарда параметри и 47 милиарда активни на токен, балансирайки висока производителност и изчислителна ефективност. Като основен модел от серията ERNIE 4.5, той се отличава в разбиране, генериране, разсъждение и програмиране. Използва мултимодален хетерогенен MoE метод за предварително обучение с комбинирано текстово и визуално обучение за повишаване на цялостните способности, особено при следване на инструкции и световни знания.",
  "baidu/ernie-5.0-thinking-preview.description": "ERNIE 5.0 Thinking Preview е следващото поколение нативен мултимодален модел на Baidu, силен в мултимодално разбиране, следване на инструкции, създаване, фактологични въпроси и отговори и използване на инструменти.",
  "black-forest-labs/flux-1.1-pro.description": "FLUX 1.1 Pro е по-бърза, подобрена версия на FLUX Pro с отлично качество на изображенията и спазване на подканите.",
  "black-forest-labs/flux-dev.description": "FLUX Dev е развойната версия на FLUX за нетърговска употреба.",
  "black-forest-labs/flux-pro.description": "FLUX Pro е професионалният модел FLUX за висококачествено генериране на изображения.",
  "black-forest-labs/flux-schnell.description": "FLUX Schnell е бърз модел за генериране на изображения, оптимизиран за скорост.",
  "c4ai-aya-expanse-32b.description": "Aya Expanse е високопроизводителен многоезичен модел с 32 милиарда параметри, използващ обучение по инструкции, арбитраж на данни, обучение по предпочитания и сливане на модели, за да се конкурира с едноезични модели. Поддържа 23 езика.",
  "c4ai-aya-expanse-8b.description": "Aya Expanse е високопроизводителен многоезичен модел с 8 милиарда параметри, използващ обучение по инструкции, арбитраж на данни, обучение по предпочитания и сливане на модели, за да се конкурира с едноезични модели. Поддържа 23 езика.",
  "c4ai-aya-vision-32b.description": "Aya Vision е авангарден мултимодален модел, който се представя отлично в ключови езикови, текстови и визуални тестове. Поддържа 23 езика. Тази версия с 32 милиарда параметри е фокусирана върху най-високо ниво на многоезична производителност.",
  "c4ai-aya-vision-8b.description": "Aya Vision е авангарден мултимодален модел, който се представя отлично в ключови езикови, текстови и визуални тестове. Тази версия с 8 милиарда параметри е фокусирана върху ниска латентност и силна производителност.",
  "charglm-3.description": "CharGLM-3 е създаден за ролеви игри и емоционално общуване, поддържа ултра-дълга многозавойна памет и персонализиран диалог.",
  "charglm-4.description": "CharGLM-4 е създаден за ролеви игри и емоционално общуване, поддържа ултра-дълга многозавойна памет и персонализиран диалог.",
  "chatgpt-4o-latest.description": "ChatGPT-4o е динамичен модел, актуализиран в реално време, комбиниращ силно разбиране и генериране за мащабни приложения като клиентска поддръжка, образование и техническа помощ.",
  "claude-2.0.description": "Claude 2 предлага ключови подобрения за предприятия, включително водещ контекст от 200 000 токена, намалени халюцинации, системни подканвания и нова тестова функция: използване на инструменти.",
  "claude-2.1.description": "Claude 2 предлага ключови подобрения за предприятия, включително водещ контекст от 200 000 токена, намалени халюцинации, системни подканвания и нова тестова функция: използване на инструменти.",
  "claude-3-5-haiku-20241022.description": "Claude 3.5 Haiku е най-бързият модел от ново поколение на Anthropic. В сравнение с Claude 3 Haiku, той показва подобрения в различни умения и надминава предишния най-голям модел Claude 3 Opus в много интелигентни бенчмаркове.",
  "claude-3-5-haiku-latest.description": "Claude 3.5 Haiku осигурява бързи отговори за леки задачи.",
  "claude-3-7-sonnet-20250219.description": "Claude 3.7 Sonnet е най-интелигентният модел на Anthropic и първият хибриден модел за разсъждение на пазара. Той може да генерира почти мигновени отговори или разширено поетапно разсъждение, което потребителите могат да проследят. Sonnet е особено силен в програмиране, анализ на данни, визуални задачи и задачи за агенти.",
  "claude-3-7-sonnet-latest.description": "Claude 3.7 Sonnet е най-новият и най-способен модел на Anthropic за силно сложни задачи, отличаващ се с производителност, интелигентност, плавност и разбиране.",
  "claude-3-haiku-20240307.description": "Claude 3 Haiku е най-бързият и най-компактен модел на Anthropic, проектиран за почти мигновени отговори с бърза и точна производителност.",
  "claude-3-opus-20240229.description": "Claude 3 Opus е най-мощният модел на Anthropic за силно сложни задачи, отличаващ се с производителност, интелигентност, плавност и разбиране.",
  "claude-3-sonnet-20240229.description": "Claude 3 Sonnet балансира интелигентност и скорост за корпоративни натоварвания, осигурявайки висока полезност на по-ниска цена и надеждно мащабно внедряване.",
  "claude-haiku-4-5-20251001.description": "Claude Haiku 4.5 е най-бързият и най-интелигентен Haiku модел на Anthropic, с мълниеносна скорост и разширено разсъждение.",
  "claude-opus-4-1-20250805-thinking.description": "Claude Opus 4.1 Thinking е усъвършенстван вариант, който може да разкрие процеса си на разсъждение.",
  "claude-opus-4-1-20250805.description": "Claude Opus 4.1 е най-новият и най-способен модел на Anthropic за изключително сложни задачи, отличаващ се с висока производителност, интелигентност, плавност и разбиране.",
  "claude-opus-4-20250514.description": "Claude Opus 4 е най-мощният модел на Anthropic за изключително сложни задачи, отличаващ се с висока производителност, интелигентност, плавност и разбиране.",
  "claude-opus-4-5-20251101.description": "Claude Opus 4.5 е флагманският модел на Anthropic, комбиниращ изключителна интелигентност с мащабируема производителност, идеален за сложни задачи, изискващи най-висококачествени отговори и разсъждение.",
  "claude-opus-4-6.description": "Claude Opus 4.6 е най-интелигентният модел на Anthropic за изграждане на агенти и програмиране.",
  "claude-sonnet-4-20250514-thinking.description": "Claude Sonnet 4 Thinking може да генерира почти мигновени отговори или разширено стъпково мислене с видим процес.",
  "claude-sonnet-4-20250514.description": "Claude Sonnet 4 може да генерира почти мигновени отговори или разширено поетапно мислене с видим процес.",
  "claude-sonnet-4-5-20250929.description": "Claude Sonnet 4.5 е най-интелигентният модел на Anthropic до момента.",
  "codegeex-4.description": "CodeGeeX-4 е мощен AI асистент за програмиране, който поддържа многоезични въпроси и допълване на код, повишавайки продуктивността на разработчиците.",
  "codegeex4-all-9b.description": "CodeGeeX4-ALL-9B е многоезичен модел за генериране на код, който поддържа допълване и създаване на код, интерпретиране, уеб търсене, извикване на функции и въпроси на ниво хранилище. Подходящ е за широк спектър от софтуерни сценарии и е водещ модел под 10 милиарда параметри.",
  "codegemma.description": "CodeGemma е лек модел за разнообразни програмни задачи, позволяващ бърза итерация и интеграция.",
  "codegemma:2b.description": "CodeGemma е лек модел за разнообразни програмни задачи, позволяващ бърза итерация и интеграция.",
  "codellama.description": "Code Llama е голям езиков модел, фокусиран върху генериране и обсъждане на код, с широка езикова поддръжка за работни процеси на разработчици.",
  "codellama/CodeLlama-34b-Instruct-hf.description": "Code Llama е голям езиков модел, фокусиран върху генериране и обсъждане на код, с широка езикова поддръжка за работни процеси на разработчици.",
  "codellama:13b.description": "Code Llama е голям езиков модел, фокусиран върху генериране и обсъждане на код, с широка езикова поддръжка за работни процеси на разработчици.",
  "codellama:34b.description": "Code Llama е голям езиков модел, фокусиран върху генериране и обсъждане на код, с широка езикова поддръжка за работни процеси на разработчици.",
  "codellama:70b.description": "Code Llama е голям езиков модел, фокусиран върху генериране и обсъждане на код, с широка езикова поддръжка за работни процеси на разработчици.",
  "codeqwen.description": "CodeQwen1.5 е голям езиков модел, обучен върху обширни данни от код, създаден за сложни програмни задачи.",
  "codestral-latest.description": "Codestral е нашият най-усъвършенстван модел за програмиране; версия 2 (януари 2025) е насочена към задачи с ниска латентност и висока честота като FIM, корекция на код и генериране на тестове.",
  "codestral.description": "Codestral е първият модел за програмиране на Mistral AI, осигуряващ силна поддръжка за генериране на код.",
  "codex-mini-latest.description": "codex-mini-latest е фино настроен o4-mini модел за Codex CLI. За директна употреба чрез API се препоръчва gpt-4.1.",
  "cogito-2.1:671b.description": "Cogito v2.1 671B е отворен модел от САЩ, свободен за търговска употреба, с производителност, съпоставима с водещите модели, по-висока ефективност при разсъждение с токени, 128k контекст и силни общи способности.",
  "cogview-4.description": "CogView-4 е първият отворен модел на Zhipu за преобразуване на текст в изображение, който може да генерира китайски знаци. Подобрява семантичното разбиране, качеството на изображенията и рендирането на китайски/английски текст, поддържа двуезични подкани с произволна дължина и може да генерира изображения с всякаква резолюция в зададени граници.",
  "cohere-command-r-plus.description": "Command R+ е усъвършенстван модел, оптимизиран за RAG, създаден за корпоративни натоварвания.",
  "cohere-command-r.description": "Command R е мащабируем генеративен модел, проектиран за RAG и използване на инструменти, позволяващ продукционен AI.",
  "cohere/Cohere-command-r-plus.description": "Command R+ е усъвършенстван модел, оптимизиран за RAG, създаден за корпоративни натоварвания.",
  "cohere/Cohere-command-r.description": "Command R е мащабируем генеративен модел, проектиран за RAG и използване на инструменти, позволяващ продукционен AI.",
  "cohere/command-a.description": "Command A е най-мощният модел на Cohere досега, отличаващ се в използване на инструменти, агенти, RAG и многоезични сценарии. Има 256K контекст, работи само с два GPU и осигурява 150% по-висока пропускателност от Command R+ 08-2024.",
  "cohere/command-r-plus.description": "Command R+ е най-новият LLM на Cohere, оптимизиран за чат и дълъг контекст, с цел изключителна производителност, за да могат компаниите да преминат от прототипи към продукция.",
  "cohere/command-r.description": "Command R е оптимизиран за чат и задачи с дълъг контекст, позициониран като „мащабируем“ модел, който балансира висока производителност и точност, за да могат компаниите да преминат от прототипи към продукция.",
  "cohere/embed-v4.0.description": "Модел, който класифицира или преобразува текст, изображения или смесено съдържание в ембединг представяния.",
  "comfyui/flux-dev.description": "FLUX.1 Dev е висококачествен модел за преобразуване на текст в изображение (10–50 стъпки), идеален за премиум творчески и артистични резултати.",
  "comfyui/flux-kontext-dev.description": "FLUX.1 Kontext-dev е модел за редактиране на изображения, който поддържа редакции, водени от текст, включително локални промени и трансфер на стил.",
  "comfyui/flux-krea-dev.description": "FLUX.1 Krea-dev е модел за преобразуване на текст в изображение с вградени филтри за безопасност, съвместно разработен с Krea.",
  "comfyui/flux-schnell.description": "FLUX.1 Schnell е ултра-бърз модел за преобразуване на текст в изображение, който генерира висококачествени изображения за 1–4 стъпки, идеален за реално време и бързо прототипиране.",
  "comfyui/stable-diffusion-15.description": "Stable Diffusion 1.5 е класически модел 512x512 за преобразуване на текст в изображение, идеален за бързо прототипиране и творчески експерименти.",
  "comfyui/stable-diffusion-35-inclclip.description": "Stable Diffusion 3.5 с вградени CLIP/T5 енкодери не изисква външни файлове, подходящ за модели като sd3.5_medium_incl_clips с по-ниска консумация на ресурси.",
  "comfyui/stable-diffusion-35.description": "Stable Diffusion 3.5 е модел от ново поколение за преобразуване на текст в изображение с варианти Large и Medium. Изисква външни CLIP енкодери и осигурява отлично качество на изображенията и съответствие с подкани.",
  "comfyui/stable-diffusion-custom-refiner.description": "Персонализиран SDXL модел за преобразуване на изображение в изображение. Използвайте custom_sd_lobe.safetensors като име на файл; ако имате VAE, използвайте custom_sd_vae_lobe.safetensors. Поставете файловете в съответните папки на Comfy.",
  "comfyui/stable-diffusion-custom.description": "Персонализиран SD модел за преобразуване на текст в изображение. Използвайте custom_sd_lobe.safetensors като име на файл; ако имате VAE, използвайте custom_sd_vae_lobe.safetensors. Поставете файловете в съответните папки на Comfy.",
  "comfyui/stable-diffusion-refiner.description": "SDXL модел за преобразуване на изображение в изображение, който извършва висококачествени трансформации от входни изображения, поддържайки трансфер на стил, възстановяване и творчески вариации.",
  "comfyui/stable-diffusion-xl.description": "SDXL е модел за преобразуване на текст в изображение, поддържащ висока резолюция 1024x1024 с по-добро качество и детайлност на изображенията.",
  "command-a-03-2025.description": "Command A е най-способният ни модел досега, отличаващ се в използването на инструменти, агенти, RAG и многоезични сценарии. Разполага с контекстен прозорец от 256K, работи само с два GPU и осигурява 150% по-висока пропускателна способност от Command R+ 08-2024.",
  "command-light-nightly.description": "За да съкратим времето между основните версии, предлагаме нощни билдове на Command. За серията command-light това е command-light-nightly. Това е най-новата, най-експериментална (и потенциално нестабилна) версия, която се обновява редовно без предизвестие, затова не се препоръчва за продукционна употреба.",
  "command-light.description": "По-малък и по-бърз вариант на Command, който е почти толкова способен, но с по-висока скорост.",
  "command-nightly.description": "За да съкратим времето между основните версии, предлагаме нощни билдове на Command. За серията Command това е command-nightly. Това е най-новата, най-експериментална (и потенциално нестабилна) версия, която се обновява редовно без предизвестие, затова не се препоръчва за продукционна употреба.",
  "command-r-03-2024.description": "Command R е чат модел, следващ инструкции, с по-високо качество, по-голяма надеждност и по-дълъг контекстен прозорец от предишните модели. Поддържа сложни работни потоци като генериране на код, RAG, използване на инструменти и агенти.",
  "command-r-08-2024.description": "command-r-08-2024 е обновен модел Command R, пуснат през август 2024 г.",
  "command-r-plus-04-2024.description": "command-r-plus е псевдоним на command-r-plus-04-2024, така че използването на command-r-plus в API-то сочи към този модел.",
  "command-r-plus-08-2024.description": "Command R+ е чат модел, следващ инструкции, с по-високо качество, по-голяма надеждност и по-дълъг контекстен прозорец от предишните модели. Най-подходящ е за сложни RAG работни потоци и многоетапно използване на инструменти.",
  "command-r-plus.description": "Command R+ е високопроизводителен LLM, създаден за реални бизнес сценарии и сложни приложения.",
  "command-r.description": "Command R е LLM, оптимизиран за чат и задачи с дълъг контекст, идеален за динамично взаимодействие и управление на знания.",
  "command-r7b-12-2024.description": "command-r7b-12-2024 е малка, ефективна актуализация, пусната през декември 2024 г. Отличава се в RAG, използване на инструменти и задачи с агенти, изискващи сложно, многоетапно разсъждение.",
  "command.description": "Чат модел, следващ инструкции, който осигурява по-високо качество и надеждност при езикови задачи, с по-дълъг контекстен прозорец от базовите ни генеративни модели.",
  "computer-use-preview.description": "computer-use-preview е специализиран модел за инструмента „computer use“, обучен да разбира и изпълнява задачи, свързани с компютри.",
  "dall-e-2.description": "Второ поколение DALL·E модел с по-реалистично и точно генериране на изображения и 4× по-висока резолюция от първото поколение.",
  "dall-e-3.description": "Най-новият модел DALL·E, пуснат през ноември 2023 г., поддържа по-реалистично и точно генериране на изображения с по-силни детайли.",
  "databricks/dbrx-instruct.description": "DBRX Instruct предлага изключително надеждно следване на инструкции в различни индустрии.",
  "deepseek-ai/DeepSeek-OCR.description": "DeepSeek-OCR е визионно-езиков модел от DeepSeek AI, фокусиран върху OCR и „контекстуална оптична компресия“. Изследва компресиране на контекст от изображения, ефективно обработва документи и ги преобразува в структуриран текст (напр. Markdown). Прецизно разпознава текст в изображения, подходящ за дигитализация на документи, извличане на текст и структурирана обработка.",
  "deepseek-ai/DeepSeek-R1-0528-Qwen3-8B.description": "DeepSeek-R1-0528-Qwen3-8B дестилира chain-of-thought от DeepSeek-R1-0528 в Qwen3 8B Base. Постига SOTA сред отворените модели, надминавайки Qwen3 8B с 10% на AIME 2024 и съвпада с производителността на Qwen3-235B-thinking. Отличава се в математическо разсъждение, програмиране и логически тестове. Споделя архитектурата на Qwen3-8B, но използва токенизатора на DeepSeek-R1-0528.",
  "deepseek-ai/DeepSeek-R1-0528.description": "DeepSeek R1 използва допълнителни изчисления и алгоритмични оптимизации след обучение, за да задълбочи разсъждението. Представя се силно в бенчмаркове по математика, програмиране и логика, доближавайки се до водещи модели като o3 и Gemini 2.5 Pro.",
  "deepseek-ai/DeepSeek-R1-Distill-Llama-70B.description": "Дестилираните модели DeepSeek-R1 използват RL и cold-start данни за подобряване на разсъждението и поставят нови бенчмарк стандарти за отворени модели с много задачи.",
  "deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B.description": "Дестилираните модели DeepSeek-R1 използват RL и cold-start данни за подобряване на разсъждението и поставят нови бенчмарк стандарти за отворени модели с много задачи.",
  "deepseek-ai/DeepSeek-R1-Distill-Qwen-14B.description": "Дестилираните модели DeepSeek-R1 използват RL и cold-start данни за подобряване на разсъждението и поставят нови бенчмарк стандарти за отворени модели с много задачи.",
  "deepseek-ai/DeepSeek-R1-Distill-Qwen-32B.description": "DeepSeek-R1-Distill-Qwen-32B е дестилиран от Qwen2.5-32B и фино настроен върху 800K подбрани проби от DeepSeek-R1. Отличава се в математика, програмиране и разсъждение, постигайки силни резултати на AIME 2024, MATH-500 (94.3% точност) и GPQA Diamond.",
  "deepseek-ai/DeepSeek-R1-Distill-Qwen-7B.description": "DeepSeek-R1-Distill-Qwen-7B е дестилиран от Qwen2.5-Math-7B и фино настроен върху 800K подбрани проби от DeepSeek-R1. Представя се силно с 92.8% на MATH-500, 55.5% на AIME 2024 и рейтинг 1189 в CodeForces за 7B модел.",
  "deepseek-ai/DeepSeek-R1.description": "DeepSeek-R1 подобрява разсъждението с RL и cold-start данни, поставяйки нови бенчмарк стандарти за отворени модели с много задачи и надминава OpenAI-o1-mini.",
  "deepseek-ai/DeepSeek-V2.5.description": "DeepSeek-V2.5 надгражда DeepSeek-V2-Chat и DeepSeek-Coder-V2-Instruct, комбинирайки общи и кодови способности. Подобрява писането и следването на инструкции за по-добро съответствие с предпочитанията и показва значителни подобрения в AlpacaEval 2.0, ArenaHard, AlignBench и MT-Bench.",
  "deepseek-ai/DeepSeek-V3.1-Terminus.description": "DeepSeek-V3.1-Terminus е обновен модел V3.1, позициониран като хибриден агентен LLM. Отстранява докладвани от потребители проблеми и подобрява стабилността, езиковата последователност и намалява смесените китайски/английски и аномални символи. Интегрира режими на мислене и немислене с шаблони за чат за гъвкаво превключване. Подобрява и производителността на Code Agent и Search Agent за по-надеждно използване на инструменти и многоетапни задачи.",
  "deepseek-ai/DeepSeek-V3.1.description": "DeepSeek V3.1 използва хибридна архитектура за разсъждение и поддържа както мислещ, така и немислещ режим.",
  "deepseek-ai/DeepSeek-V3.2-Exp.description": "DeepSeek-V3.2-Exp е експериментална версия V3.2, която служи като мост към следващата архитектура. Добавя DeepSeek Sparse Attention (DSA) върху V3.1-Terminus за подобряване на ефективността при обучение и извеждане с дълъг контекст, с оптимизации за използване на инструменти, разбиране на дълги документи и многoетапно разсъждение. Идеален е за изследване на по-висока ефективност при разсъждение с големи контекстуални бюджети.",
  "deepseek-ai/DeepSeek-V3.description": "DeepSeek-V3 е MoE модел с 671 милиарда параметъра, използващ MLA и DeepSeekMoE с балансирано натоварване без загуби за ефективно обучение и извеждане. Предварително обучен върху 14.8 трилиона висококачествени токени със SFT и RL, той превъзхожда други отворени модели и се доближава до водещите затворени модели.",
  "deepseek-ai/deepseek-llm-67b-chat.description": "DeepSeek LLM Chat (67B) е иновативен модел, предлагащ дълбоко езиково разбиране и интеракция.",
  "deepseek-ai/deepseek-v3.1-terminus.description": "DeepSeek V3.1 е модел за разсъждение от ново поколение с по-силни способности за сложни разсъждения и верига от мисли за задълбочени аналитични задачи.",
  "deepseek-ai/deepseek-v3.1.description": "DeepSeek V3.1 е модел за разсъждение от ново поколение с по-силни способности за сложни разсъждения и верига от мисли за задълбочени аналитични задачи.",
  "deepseek-ai/deepseek-vl2.description": "DeepSeek-VL2 е MoE модел за визия и език, базиран на DeepSeekMoE-27B със слаба активация, постигайки висока производителност с едва 4.5 милиарда активни параметъра. Отличава се в визуални въпроси и отговори, OCR, разбиране на документи/таблици/графики и визуално привързване.",
  "deepseek-coder-33B-instruct.description": "DeepSeek Coder 33B е езиков модел за програмиране, обучен върху 2 трилиона токени (87% код, 13% китайски/английски текст). Въвежда 16K контекстен прозорец и задачи за попълване в средата, осигурявайки допълване на код на ниво проект и попълване на фрагменти.",
  "deepseek-coder-v2.description": "DeepSeek Coder V2 е отворен MoE модел за програмиране, който се представя на ниво GPT-4 Turbo.",
  "deepseek-coder-v2:236b.description": "DeepSeek Coder V2 е отворен MoE модел за програмиране, който се представя на ниво GPT-4 Turbo.",
  "deepseek-ocr.description": "DeepSeek-OCR е визионно-езиков модел от DeepSeek AI, фокусиран върху OCR и „контекстуална оптична компресия“. Изследва компресиране на контекстуална информация от изображения, ефективно обработва документи и ги преобразува в структурирани текстови формати като Markdown. Прецизно разпознава текст в изображения, което го прави идеален за дигитализация на документи, извличане на текст и структурирана обработка.",
  "deepseek-r1-0528.description": "Пълен модел с 685 милиарда параметъра, пуснат на 28.05.2025. DeepSeek-R1 използва мащабно подсилено обучение след предварителното обучение, значително подобрявайки разсъждението с минимални етикетирани данни и се представя силно в математика, програмиране и езиково разсъждение.",
  "deepseek-r1-250528.description": "DeepSeek R1 250528 е пълният модел за разсъждение на DeepSeek-R1, предназначен за трудни математически и логически задачи.",
  "deepseek-r1-70b-fast-online.description": "DeepSeek R1 70B бързо издание с търсене в реално време в уеб, осигуряващо по-бързи отговори при запазване на производителността.",
  "deepseek-r1-70b-online.description": "DeepSeek R1 70B стандартно издание с търсене в реално време в уеб, подходящо за актуални чат и текстови задачи.",
  "deepseek-r1-distill-llama-70b.description": "DeepSeek R1 Distill Llama 70B комбинира разсъждението на R1 с екосистемата на Llama.",
  "deepseek-r1-distill-llama-8b.description": "DeepSeek-R1-Distill-Llama-8B е дистилиран от Llama-3.1-8B с използване на изходи от DeepSeek R1.",
  "deepseek-r1-distill-llama.description": "deepseek-r1-distill-llama е дистилиран от DeepSeek-R1 върху Llama.",
  "deepseek-r1-distill-qianfan-70b.description": "DeepSeek R1 Distill Qianfan 70B е дистилиран модел на R1, базиран на Qianfan-70B с висока стойност.",
  "deepseek-r1-distill-qianfan-8b.description": "DeepSeek R1 Distill Qianfan 8B е дистилиран модел на R1, базиран на Qianfan-8B за малки и средни приложения.",
  "deepseek-r1-distill-qianfan-llama-70b.description": "DeepSeek R1 Distill Qianfan Llama 70B е дистилиран модел на R1, базиран на Llama-70B.",
  "deepseek-r1-distill-qwen-1.5b.description": "DeepSeek R1 Distill Qwen 1.5B е ултралек дистилиран модел за среди с много ниски ресурси.",
  "deepseek-r1-distill-qwen-14b.description": "DeepSeek R1 Distill Qwen 14B е среден по размер дистилиран модел за многосценарийно внедряване.",
  "deepseek-r1-distill-qwen-32b.description": "DeepSeek R1 Distill Qwen 32B е дистилиран модел на R1, базиран на Qwen-32B, балансиращ производителност и разходи.",
  "deepseek-r1-distill-qwen-7b.description": "DeepSeek R1 Distill Qwen 7B е лек дистилиран модел за edge и частни корпоративни среди.",
  "deepseek-r1-distill-qwen.description": "deepseek-r1-distill-qwen е дистилиран от DeepSeek-R1 върху Qwen.",
  "deepseek-r1-fast-online.description": "Пълна бърза версия на DeepSeek R1 с търсене в реално време в уеб, комбинираща възможности от мащаб 671B и по-бърз отговор.",
  "deepseek-r1-online.description": "Пълна версия на DeepSeek R1 с 671 милиарда параметъра и търсене в реално време в уеб, предлагаща по-силно разбиране и генериране.",
  "deepseek-r1.description": "DeepSeek-R1 използва данни от студен старт преди подсиленото обучение и се представя наравно с OpenAI-o1 в математика, програмиране и разсъждение.",
  "deepseek-v2.description": "DeepSeek V2 е ефективен MoE модел за икономична обработка.",
  "deepseek-v2:236b.description": "DeepSeek V2 236B е модел на DeepSeek, фокусиран върху програмиране, с висока производителност при генериране на код.",
  "deepseek-v3-0324.description": "DeepSeek-V3-0324 е MoE модел с 671 милиарда параметъра, с изключителни способности в програмиране, технически задачи, разбиране на контекст и обработка на дълги текстове.",
  "deepseek-v3.1-terminus.description": "DeepSeek-V3.1-Terminus е оптимизиран за терминални устройства LLM от DeepSeek.",
  "deepseek-v3.1-think-250821.description": "DeepSeek V3.1 Think 250821 е модел за дълбоко разсъждение, съответстващ на версията Terminus, създаден за високопроизводително разсъждение.",
  "deepseek-v3.1.description": "DeepSeek-V3.1 е нов хибриден модел за разсъждение от DeepSeek, поддържащ както мислещ, така и немислещ режим и предлагащ по-висока ефективност на мисленето от DeepSeek-R1-0528. Оптимизациите след обучение значително подобряват използването на инструменти от агенти и изпълнението на задачи. Поддържа 128k контекстен прозорец и до 64k изходни токена.",
  "deepseek-v3.1:671b.description": "DeepSeek V3.1 е модел за разсъждение от ново поколение с подобрени способности за сложни разсъждения и верига от мисли, подходящ за задачи, изискващи задълбочен анализ.",
  "deepseek-v3.2-exp.description": "deepseek-v3.2-exp въвежда разредено внимание за подобряване на ефективността при обучение и извеждане върху дълги текстове, на по-ниска цена от deepseek-v3.1.",
  "deepseek-v3.2-think.description": "DeepSeek V3.2 Think е пълен модел за дълбоко мислене с по-силно дълговерижно разсъждение.",
  "deepseek-v3.2.description": "DeepSeek-V3.2 е първият хибриден модел за логическо мислене от DeepSeek, който интегрира мисленето в използването на инструменти. Използва ефективна архитектура за намаляване на изчислителните ресурси, мащабно обучение с подсилване за повишаване на способностите и синтетични задачи в голям мащаб за по-добра обобщаемост. Комбинацията от тези три елемента постига производителност, сравнима с GPT-5-High, със значително по-кратки изходни текстове, което намалява изчислителното натоварване и времето за изчакване на потребителя.",
  "deepseek-v3.description": "DeepSeek-V3 е мощен MoE модел с общо 671 милиарда параметъра и 37 милиарда активни на токен.",
  "deepseek-vl2-small.description": "DeepSeek VL2 Small е лек мултимодален вариант за среди с ограничени ресурси и висока едновременност.",
  "deepseek-vl2.description": "DeepSeek VL2 е мултимодален модел за разбиране на изображения и текст и прецизни визуални въпроси и отговори.",
  "deepseek/deepseek-chat-v3-0324.description": "DeepSeek V3 е MoE модел с 685 милиарда параметъра и най-новата итерация от водещата чат серия на DeepSeek.\n\nНадгражда [DeepSeek V3](/deepseek/deepseek-chat-v3) и се представя отлично в различни задачи.",
  "deepseek/deepseek-chat-v3-0324:free.description": "DeepSeek V3 е MoE модел с 685 милиарда параметъра и най-новата итерация от водещата чат серия на DeepSeek.\n\nНадгражда [DeepSeek V3](/deepseek/deepseek-chat-v3) и се представя отлично в различни задачи.",
  "deepseek/deepseek-chat-v3.1.description": "DeepSeek-V3.1 е хибриден модел за разсъждение с дълъг контекст от DeepSeek, поддържащ смесени режими на мислене/без мислене и интеграция с инструменти.",
  "deepseek/deepseek-chat.description": "DeepSeek-V3 е високоефективен хибриден модел за разсъждение от DeepSeek, предназначен за сложни задачи и интеграция с инструменти.",
  "deepseek/deepseek-math-v2.description": "DeepSeek Math V2 е модел, който постига значителни пробиви в способностите за математическо разсъждение. Основната му иновация е в механизма за обучение чрез „самопроверка“ и е достигнал ниво на златен медал в няколко от най-престижните математически състезания.",
  "deepseek/deepseek-r1-0528.description": "DeepSeek R1 0528 е обновен вариант, фокусиран върху отворен достъп и по-дълбоко разсъждение.",
  "deepseek/deepseek-r1-0528:free.description": "DeepSeek-R1 значително подобрява разсъждението с минимално етикетирани данни и извежда верига от мисли преди крайния отговор за повишаване на точността.",
  "deepseek/deepseek-r1-distill-llama-70b.description": "DeepSeek R1 Distill Llama 70B е дестилиран LLM, базиран на Llama 3.3 70B, фино настроен с изходи от DeepSeek R1 за постигане на конкурентна производителност спрямо водещите модели.",
  "deepseek/deepseek-r1-distill-llama-8b.description": "DeepSeek R1 Distill Llama 8B е дестилиран LLM, базиран на Llama-3.1-8B-Instruct, обучен с изходи от DeepSeek R1.",
  "deepseek/deepseek-r1-distill-qwen-14b.description": "DeepSeek R1 Distill Qwen 14B е дестилиран LLM, базиран на Qwen 2.5 14B, обучен с изходи от DeepSeek R1. Надминава OpenAI o1-mini в множество бенчмаркове, постигайки водещи резултати сред плътните модели. Основни резултати:\nAIME 2024 pass@1: 69.7\nMATH-500 pass@1: 93.9\nCodeForces рейтинг: 1481\nФиното настройване с изходи от DeepSeek R1 осигурява конкурентна производителност спрямо по-големи модели.",
  "deepseek/deepseek-r1-distill-qwen-32b.description": "DeepSeek R1 Distill Qwen 32B е дестилиран LLM, базиран на Qwen 2.5 32B, обучен с изходи от DeepSeek R1. Надминава OpenAI o1-mini в множество бенчмаркове, постигайки водещи резултати сред плътните модели. Основни резултати:\nAIME 2024 pass@1: 72.6\nMATH-500 pass@1: 94.3\nCodeForces рейтинг: 1691\nФиното настройване с изходи от DeepSeek R1 осигурява конкурентна производителност спрямо по-големи модели.",
  "deepseek/deepseek-r1.description": "DeepSeek R1 е обновен до DeepSeek-R1-0528. С повече изчислителна мощ и алгоритмични оптимизации след обучение, значително подобрява дълбочината и способността за разсъждение. Представя се отлично в бенчмаркове по математика, програмиране и логика, доближавайки се до водещи модели като o3 и Gemini 2.5 Pro.",
  "deepseek/deepseek-r1/community.description": "DeepSeek R1 е най-новият модел с отворен код, пуснат от екипа на DeepSeek, с много силна производителност в разсъждението, особено в математика, програмиране и логически задачи, сравним с OpenAI o1.",
  "deepseek/deepseek-r1:free.description": "DeepSeek-R1 значително подобрява разсъждението с минимално етикетирани данни и извежда верига от мисли преди крайния отговор за повишаване на точността.",
  "deepseek/deepseek-reasoner.description": "DeepSeek-V3 Thinking (reasoner) е експериментален модел за разсъждение от DeepSeek, подходящ за задачи с висока сложност.",
  "deepseek/deepseek-v3.1-base.description": "DeepSeek V3.1 Base е подобрена версия на модела DeepSeek V3.",
  "deepseek/deepseek-v3.description": "Бърз универсален LLM с подобрено разсъждение.",
  "deepseek/deepseek-v3/community.description": "DeepSeek-V3 постига значителен пробив в скоростта на разсъждение спрямо предишни модели. Класира се на първо място сред моделите с отворен код и съперничи на най-напредналите затворени модели. DeepSeek-V3 използва Multi-Head Latent Attention (MLA) и архитектурата DeepSeekMoE, и двете напълно валидирани в DeepSeek-V2. Въвежда и беззагубна помощна стратегия за балансиране на натоварването и цел за обучение с предсказване на множество токени за по-силна производителност.",
  "deepseek_r1.description": "DeepSeek-R1 е модел за разсъждение, управляван от обучение чрез подсилване, който адресира проблеми с повторения и четимост. Преди RL използва начални данни за допълнително подобряване на разсъждението. Сравнява се с OpenAI-o1 в задачи по математика, програмиране и логика, с внимателно проектирано обучение за подобрени резултати.",
  "deepseek_r1_distill_llama_70b.description": "DeepSeek-R1-Distill-Llama-70B е дестилиран от Llama-3.3-70B-Instruct. Като част от серията DeepSeek-R1, е фино настроен с примери, генерирани от DeepSeek-R1, и се представя силно в математика, програмиране и разсъждение.",
  "deepseek_r1_distill_qwen_14b.description": "DeepSeek-R1-Distill-Qwen-14B е дестилиран от Qwen2.5-14B и фино настроен с 800K подбрани примера, генерирани от DeepSeek-R1, осигуряващ силно разсъждение.",
  "deepseek_r1_distill_qwen_32b.description": "DeepSeek-R1-Distill-Qwen-32B е дестилиран от Qwen2.5-32B и фино настроен с 800K подбрани примера, генерирани от DeepSeek-R1, отличаващ се в математика, програмиране и разсъждение.",
  "devstral-2:123b.description": "Devstral 2 123B се отличава с използването на инструменти за изследване на кодови бази, редактиране на множество файлове и поддръжка на агенти за софтуерно инженерство.",
  "doubao-1.5-lite-32k.description": "Doubao-1.5-lite е нов лек модел с изключително бърз отговор, предоставящ първокласно качество и ниска латентност.",
  "doubao-1.5-pro-256k.description": "Doubao-1.5-pro-256k е цялостен ъпгрейд на Doubao-1.5-Pro, подобряващ общата производителност с 10%. Поддържа контекстен прозорец от 256k и до 12k изходни токена, осигурявайки по-висока производителност, по-голям прозорец и отлична стойност за по-широки приложения.",
  "doubao-1.5-pro-32k.description": "Doubao-1.5-pro е флагмански модел от ново поколение с цялостни подобрения, отличаващ се в знания, програмиране и разсъждение.",
  "doubao-1.5-thinking-pro-m.description": "Doubao-1.5 е нов дълбок разсъждаващ модел (версия m включва родно мултимодално дълбоко разсъждение), който се отличава в математика, програмиране, научно разсъждение и общи задачи като творческо писане. Достига или доближава водещи резултати в бенчмаркове като AIME 2024, Codeforces и GPQA. Поддържа контекстен прозорец от 128k и 16k изход.",
  "doubao-1.5-thinking-pro.description": "Doubao-1.5 е нов дълбок разсъждаващ модел, който се отличава в математика, програмиране, научно разсъждение и общи задачи като творческо писане. Достига или доближава водещи резултати в бенчмаркове като AIME 2024, Codeforces и GPQA. Поддържа контекстен прозорец от 128k и 16k изход.",
  "doubao-1.5-thinking-vision-pro.description": "Нов визуален дълбок разсъждаващ модел със засилено мултимодално разбиране и разсъждение, постигайки SOTA резултати в 37 от 59 публични бенчмарка.",
  "doubao-1.5-ui-tars.description": "Doubao-1.5-UI-TARS е роден агентен модел, фокусиран върху графичен интерфейс, който безпроблемно взаимодейства с интерфейси чрез човешко възприятие, разсъждение и действие.",
  "doubao-1.5-vision-lite.description": "Doubao-1.5-vision-lite е подобрен мултимодален модел, който поддържа изображения с всякаква резолюция и екстремни съотношения, подобрявайки визуалното разсъждение, разпознаването на документи, разбиране на детайли и следване на инструкции. Поддържа контекстен прозорец от 128k и до 16k изходни токена.",
  "doubao-1.5-vision-pro-32k.description": "Doubao-1.5-vision-pro е подобрен мултимодален модел, който поддържа изображения с всякаква резолюция и екстремни съотношения, подобрявайки визуалното разсъждение, разпознаването на документи, разбиране на детайли и следване на инструкции.",
  "doubao-1.5-vision-pro.description": "Doubao-1.5-vision-pro е подобрен мултимодален модел, който поддържа изображения с всякаква резолюция и екстремни съотношения, подобрявайки визуалното разсъждение, разпознаването на документи, разбиране на детайли и следване на инструкции.",
  "doubao-lite-128k.description": "Изключително бърз отговор с по-добра стойност, предлагащ по-гъвкави възможности в различни сценарии. Поддържа разсъждение и фина настройка с контекстен прозорец от 128k.",
  "doubao-lite-32k.description": "Изключително бърз отговор с по-добра стойност, предлагащ по-гъвкави възможности в различни сценарии. Поддържа разсъждение и фина настройка с контекстен прозорец от 32k.",
  "doubao-lite-4k.description": "Изключително бърз отговор с по-добра стойност, предлагащ по-гъвкави възможности в различни сценарии. Поддържа разсъждение и фина настройка с контекстен прозорец от 4k.",
  "doubao-pro-256k.description": "Най-добре представящият се флагмански модел за сложни задачи, с отлични резултати в справочни въпроси, обобщение, създаване, класификация на текст и ролеви игри. Поддържа разсъждение и фина настройка с контекстен прозорец от 256k.",
  "doubao-pro-32k.description": "Най-добре представящият се флагмански модел за сложни задачи, с отлични резултати в справочни въпроси, обобщение, създаване, класификация на текст и ролеви игри. Поддържа разсъждение и фина настройка с контекстен прозорец от 32k.",
  "doubao-seed-1.6-flash.description": "Doubao-Seed-1.6-flash е изключително бърз мултимодален дълбок разсъждаващ модел с TPOT до 10ms. Поддържа текст и визия, надминава предишния lite модел в разбиране на текст и съответства на конкурентни pro модели във визия. Поддържа контекстен прозорец от 256k и до 16k изходни токена.",
  "doubao-seed-1.6-lite.description": "Doubao-Seed-1.6-lite е нов мултимодален дълбок разсъждаващ модел с регулируемо усилие на разсъждение (Минимално, Ниско, Средно, Високо), осигуряващ по-добра стойност и силен избор за обичайни задачи, с контекстен прозорец до 256k.",
  "doubao-seed-1.6-thinking.description": "Doubao-Seed-1.6 значително засилва разсъждението, допълнително подобрявайки основните способности в програмиране, математика и логическо мислене спрямо Doubao-1.5-thinking-pro, като добавя и разбиране на визия. Поддържа контекстен прозорец от 256k и до 16k изходни токена.",
  "doubao-seed-1.6-vision.description": "Doubao-Seed-1.6-vision е визуален дълбок разсъждаващ модел, който осигурява по-силно мултимодално разбиране и разсъждение за образование, преглед на изображения, инспекция/сигурност и AI търсене с въпроси и отговори. Поддържа контекстен прозорец от 256k и до 64k изходни токена.",
  "doubao-seed-1.6.description": "Doubao-Seed-1.6 е нов мултимодален дълбок разсъждаващ модел с режими auto, thinking и non-thinking. В non-thinking режим значително превъзхожда Doubao-1.5-pro/250115. Поддържа контекстен прозорец от 256k и до 16k изходни токена.",
  "doubao-seed-1.8.description": "Doubao-Seed-1.8 притежава по-силно мултимодално разбиране и агентни способности, поддържа вход от текст/изображение/видео и кеширане на контекст, като осигурява отлична производителност при сложни задачи.",
  "doubao-seed-code.description": "Doubao-Seed-Code е дълбоко оптимизиран за агентно програмиране, поддържа мултимодални входове (текст/изображение/видео) и контекстен прозорец от 256k, съвместим е с Anthropic API и е подходящ за програмиране, разбиране на визия и работни потоци с агенти.",
  "doubao-seededit-3-0-i2i-250628.description": "Моделът за изображения на Doubao от ByteDance Seed поддържа вход от текст и изображения с високо контролируемо, висококачествено генериране на изображения. Поддържа редактиране на изображения, водено от текст, с размери на изхода между 512 и 1536 по дългата страна.",
  "doubao-seedream-3-0-t2i-250415.description": "Seedream 3.0 е модел за генериране на изображения от ByteDance Seed, поддържащ вход от текст и изображения с високо контролируемо, висококачествено генериране на изображения. Генерира изображения от текстови подсказки.",
  "doubao-seedream-4-0-250828.description": "Seedream 4.0 е модел за генериране на изображения от ByteDance Seed, поддържащ вход от текст и изображения с високо контролируемо, висококачествено генериране на изображения. Генерира изображения от текстови подсказки.",
  "doubao-vision-lite-32k.description": "Doubao-vision е мултимодален модел от Doubao със силно разбиране и разсъждение върху изображения, както и точно следване на инструкции. Представя се добре при извличане на текст от изображения и задачи за разсъждение, базирани на изображения, позволявайки по-сложни и широки визуални сценарии с въпроси и отговори.",
  "doubao-vision-pro-32k.description": "Doubao-vision е мултимодален модел от Doubao със силно разбиране и разсъждение върху изображения, както и точно следване на инструкции. Представя се добре при извличане на текст от изображения и задачи за разсъждение, базирани на изображения, позволявайки по-сложни и широки визуални сценарии с въпроси и отговори.",
  "emohaa.description": "Emohaa е модел за психично здраве с професионални консултантски способности, който помага на потребителите да разберат емоционални проблеми.",
  "ernie-4.5-0.3b.description": "ERNIE 4.5 0.3B е лек модел с отворен код за локално и персонализирано внедряване.",
  "ernie-4.5-21b-a3b.description": "ERNIE 4.5 21B A3B е модел с отворен код с голям брой параметри и по-силни способности за разбиране и генериране.",
  "ernie-4.5-300b-a47b.description": "ERNIE 4.5 300B A47B е ултра-голям MoE модел на Baidu ERNIE с отлични способности за разсъждение.",
  "ernie-4.5-8k-preview.description": "ERNIE 4.5 8K Preview е модел за предварителен преглед с 8K контекст за оценка на ERNIE 4.5.",
  "ernie-4.5-turbo-128k-preview.description": "Предварителен преглед на ERNIE 4.5 Turbo 128K с възможности на ниво издание, подходящ за интеграция и тестване.",
  "ernie-4.5-turbo-128k.description": "ERNIE 4.5 Turbo 128K е високопроизводителен общ модел с търсачна поддръжка и извикване на инструменти за QA, програмиране и агентски сценарии.",
  "ernie-4.5-turbo-32k.description": "ERNIE 4.5 Turbo 32K е версия със средна дължина на контекста за QA, извличане от бази знания и многозавойни диалози.",
  "ernie-4.5-turbo-latest.description": "Най-новият ERNIE 4.5 Turbo с оптимизирана цялостна производителност, идеален за основен продукционен модел.",
  "ernie-4.5-turbo-vl-32k-preview.description": "ERNIE 4.5 Turbo VL 32K Preview е мултимодален предварителен модел с 32K контекст за оценка на способността за разбиране на дълъг визуален контекст.",
  "ernie-4.5-turbo-vl-32k.description": "ERNIE 4.5 Turbo VL 32K е мултимодална версия със средно-дълъг контекст за комбинирано разбиране на дълги документи и изображения.",
  "ernie-4.5-turbo-vl-latest.description": "ERNIE 4.5 Turbo VL Latest е най-новата мултимодална версия с подобрено разбиране и разсъждение върху изображения и текст.",
  "ernie-4.5-turbo-vl-preview.description": "ERNIE 4.5 Turbo VL Preview е мултимодален предварителен модел за разбиране и генериране на изображения и текст, подходящ за визуални QA и разбиране на съдържание.",
  "ernie-4.5-turbo-vl.description": "ERNIE 4.5 Turbo VL е зрял мултимодален модел за продукционно разбиране и разпознаване на изображения и текст.",
  "ernie-4.5-vl-28b-a3b.description": "ERNIE 4.5 VL 28B A3B е мултимодален модел с отворен код за разбиране и разсъждение върху изображения и текст.",
  "ernie-5.0-thinking-latest.description": "Wenxin 5.0 Thinking е флагмански модел с пълна модалност, обединяващ текст, изображение, аудио и видео. Осигурява значителни подобрения за сложни QA, творчество и агентски сценарии.",
  "ernie-5.0-thinking-preview.description": "Wenxin 5.0 Thinking Preview е флагмански модел с пълна модалност, обединяващ текст, изображение, аудио и видео. Осигурява значителни подобрения за сложни QA, творчество и агентски сценарии.",
  "ernie-char-8k.description": "ERNIE Character 8K е модел за диалог с персонажи, предназначен за изграждане на IP персонажи и дългосрочен разговорен спътник.",
  "ernie-char-fiction-8k-preview.description": "ERNIE Character Fiction 8K Preview е предварителен модел за създаване на персонажи и сюжет, предназначен за оценка и тестване на функции.",
  "ernie-char-fiction-8k.description": "ERNIE Character Fiction 8K е модел за персонажи, предназначен за романи и създаване на сюжет, подходящ за генериране на дълги истории.",
  "ernie-irag-edit.description": "ERNIE iRAG Edit е модел за редактиране на изображения, поддържащ изтриване, прерисуване и генериране на варианти.",
  "ernie-lite-pro-128k.description": "ERNIE Lite Pro 128K е лек високопроизводителен модел за сценарии, чувствителни към латентност и разходи.",
  "ernie-novel-8k.description": "ERNIE Novel 8K е създаден за дълги романи и IP сюжети с многоперсонажни наративи.",
  "ernie-speed-pro-128k.description": "ERNIE Speed Pro 128K е модел с висока едновременност и висока стойност за мащабни онлайн услуги и корпоративни приложения.",
  "ernie-x1-turbo-32k.description": "ERNIE X1 Turbo 32K е бърз мислещ модел с 32K контекст за сложни разсъждения и многозавойни разговори.",
  "ernie-x1.1-preview.description": "ERNIE X1.1 Preview е предварителен модел за мислене, предназначен за оценка и тестване.",
  "fal-ai/flux-kontext/dev.description": "FLUX.1 модел, фокусиран върху редактиране на изображения, поддържащ вход от текст и изображения.",
  "fal-ai/flux-pro/kontext.description": "FLUX.1 Kontext [pro] приема текст и референтни изображения като вход, позволявайки целенасочени локални редакции и сложни глобални трансформации на сцени.",
  "fal-ai/flux/krea.description": "Flux Krea [dev] е модел за генериране на изображения с естетично предпочитание към по-реалистични и естествени изображения.",
  "fal-ai/flux/schnell.description": "FLUX.1 [schnell] е модел за генериране на изображения с 12 милиарда параметъра, създаден за бърз и висококачествен изход.",
  "fal-ai/hunyuan-image/v3.description": "Мощен роден мултимодален модел за генериране на изображения.",
  "fal-ai/imagen4/preview.description": "Модел за висококачествено генериране на изображения от Google.",
  "fal-ai/nano-banana.description": "Nano Banana е най-новият, най-бърз и най-ефективен роден мултимодален модел на Google, позволяващ генериране и редактиране на изображения чрез разговор.",
  "flux-1-schnell.description": "Модел за преобразуване на текст в изображение с 12 милиарда параметъра от Black Forest Labs, използващ латентна дифузионна дестилация за генериране на висококачествени изображения в 1–4 стъпки. Съперничи на затворени алтернативи и е пуснат под лиценз Apache-2.0 за лична, изследователска и търговска употреба.",
  "flux-dev.description": "FLUX.1 [dev] е дестилиран модел с отворени тегла за нетърговска употреба. Запазва почти професионално качество на изображенията и следване на инструкции, като същевременно работи по-ефективно и използва ресурсите по-добре от стандартни модели със същия размер.",
  "flux-kontext-max.description": "Съвременно генериране и редактиране на изображения с контекст, комбиниращо текст и изображения за прецизни и последователни резултати.",
  "flux-kontext-pro.description": "Съвременно генериране и редактиране на изображения с контекст, комбиниращо текст и изображения за прецизни и последователни резултати.",
  "flux-merged.description": "FLUX.1-merged комбинира дълбоките характеристики, изследвани в „DEV“, с високоскоростните предимства на „Schnell“, разширявайки границите на производителността и разширявайки приложенията.",
  "flux-pro-1.1-ultra.description": "Генериране на изображения с ултра висока резолюция и изход от 4MP, създаващ ясни изображения за 10 секунди.",
  "flux-pro-1.1.description": "Подобрен професионален модел за генериране на изображения с отлично качество и прецизно следване на подсказки.",
  "flux-pro.description": "Висококласен търговски модел за генериране на изображения с несравнимо качество и разнообразие на изхода.",
  "flux-schnell.description": "FLUX.1 [schnell] е най-усъвършенстваният отворен модел с малко стъпки, надминаващ подобни конкуренти и дори силни недестилирани модели като Midjourney v6.0 и DALL-E 3 (HD). Фино настроен е да запази разнообразието от предварително обучение, значително подобрявайки визуалното качество, следването на инструкции, вариациите в размер/съотношение, обработката на шрифтове и разнообразието на изхода.",
  "flux.1-schnell.description": "FLUX.1-schnell е високопроизводителен модел за генериране на изображения с бърз изход в различни стилове.",
  "gemini-1.0-pro-001.description": "Gemini 1.0 Pro 001 (Tuning) осигурява стабилна и настройваема производителност за комплексни задачи.",
  "gemini-1.0-pro-002.description": "Gemini 1.0 Pro 002 (Tuning) предлага силна мултимодална поддръжка за комплексни задачи.",
  "gemini-1.0-pro-latest.description": "Gemini 1.0 Pro е високопроизводителен AI модел на Google, проектиран за мащабиране на широк спектър от задачи.",
  "gemini-1.5-flash-001.description": "Gemini 1.5 Flash 001 е ефективен мултимодален модел за мащабиране на приложения.",
  "gemini-1.5-flash-002.description": "Gemini 1.5 Flash 002 е ефективен мултимодален модел, създаден за широко внедряване.",
  "gemini-1.5-flash-8b-exp-0924.description": "Gemini 1.5 Flash 8B 0924 е най-новият експериментален модел с значителни подобрения в текстови и мултимодални случаи на употреба.",
  "gemini-1.5-flash-8b-latest.description": "Gemini 1.5 Flash 8B е ефективен мултимодален модел, създаден за широко внедряване.",
  "gemini-1.5-flash-8b.description": "Gemini 1.5 Flash 8B е ефективен мултимодален модел за мащабиране на приложения.",
  "gemini-1.5-flash-exp-0827.description": "Gemini 1.5 Flash 0827 предлага оптимизирана мултимодална обработка за комплексни задачи.",
  "gemini-1.5-flash-latest.description": "Gemini 1.5 Flash е най-новият мултимодален AI модел на Google с бърза обработка, поддържащ текстови, визуални и видео входове за ефективно мащабиране на задачи.",
  "gemini-1.5-pro-001.description": "Gemini 1.5 Pro 001 е мащабируемо мултимодално AI решение за комплексни задачи.",
  "gemini-1.5-pro-002.description": "Gemini 1.5 Pro 002 е най-новият модел, готов за продукция, с по-високо качество на изхода, особено при математика, дълъг контекст и визуални задачи.",
  "gemini-1.5-pro-exp-0801.description": "Gemini 1.5 Pro 0801 осигурява силна мултимодална обработка с по-голяма гъвкавост за разработка на приложения.",
  "gemini-1.5-pro-exp-0827.description": "Gemini 1.5 Pro 0827 прилага последните оптимизации за по-ефективна мултимодална обработка.",
  "gemini-1.5-pro-latest.description": "Gemini 1.5 Pro поддържа до 2 милиона токена, идеален среден по размер мултимодален модел за комплексни задачи.",
  "gemini-2.0-flash-001.description": "Gemini 2.0 Flash предлага функции от ново поколение, включително изключителна скорост, вградена употреба на инструменти, мултимодално генериране и контекстен прозорец от 1 милион токена.",
  "gemini-2.0-flash-exp-image-generation.description": "Експериментален модел Gemini 2.0 Flash с поддръжка за генериране на изображения.",
  "gemini-2.0-flash-lite-001.description": "Вариант на Gemini 2.0 Flash, оптимизиран за ниска цена и ниска латентност.",
  "gemini-2.0-flash-lite.description": "Вариант на Gemini 2.0 Flash, оптимизиран за ниска цена и ниска латентност.",
  "gemini-2.0-flash.description": "Gemini 2.0 Flash предлага функции от ново поколение, включително изключителна скорост, вградена употреба на инструменти, мултимодално генериране и контекстен прозорец от 1 милион токена.",
  "gemini-2.5-flash-image.description": "Nano Banana е най-новият, най-бърз и най-ефективен роден мултимодален модел на Google, позволяващ разговорно генериране и редактиране на изображения.",
  "gemini-2.5-flash-image:image.description": "Nano Banana е най-новият, най-бърз и най-ефективен роден мултимодален модел на Google, позволяващ разговорно генериране и редактиране на изображения.",
  "gemini-2.5-flash-lite-preview-06-17.description": "Gemini 2.5 Flash-Lite Preview е най-малкият и най-изгоден модел на Google, проектиран за мащабна употреба.",
  "gemini-2.5-flash-lite-preview-09-2025.description": "Предварителна версия (25 септември 2025 г.) на Gemini 2.5 Flash-Lite",
  "gemini-2.5-flash-lite.description": "Gemini 2.5 Flash-Lite е най-малкият и най-изгоден модел на Google, проектиран за мащабна употреба.",
  "gemini-2.5-flash-preview-04-17.description": "Gemini 2.5 Flash Preview е най-изгодният модел на Google с пълни възможности.",
  "gemini-2.5-flash-preview-09-2025.description": "Предварителна версия (25 септември 2025 г.) на Gemini 2.5 Flash",
  "gemini-2.5-flash.description": "Gemini 2.5 Flash е най-изгодният модел на Google с пълни възможности.",
  "gemini-2.5-pro-preview-03-25.description": "Gemini 2.5 Pro Preview е най-усъвършенстваният модел за разсъждение на Google, способен да разсъждава върху код, математика и STEM проблеми и да анализира големи набори от данни, кодови бази и документи с дълъг контекст.",
  "gemini-2.5-pro-preview-05-06.description": "Gemini 2.5 Pro Preview е най-усъвършенстваният модел за разсъждение на Google, способен да разсъждава върху код, математика и STEM проблеми и да анализира големи набори от данни, кодови бази и документи с дълъг контекст.",
  "gemini-2.5-pro-preview-06-05.description": "Gemini 2.5 Pro Preview е най-усъвършенстваният модел за разсъждение на Google, способен да разсъждава върху код, математика и STEM проблеми и да анализира големи набори от данни, кодови бази и документи с дълъг контекст.",
  "gemini-2.5-pro.description": "Gemini 2.5 Pro е най-усъвършенстваният модел за разсъждение на Google, способен да разсъждава върху код, математика и STEM проблеми и да анализира големи набори от данни, кодови бази и документи с дълъг контекст.",
  "gemini-3-flash-preview.description": "Gemini 3 Flash е най-интелигентният модел, създаден за скорост, съчетаващ авангардна интелигентност с отлично търсене и обоснованост.",
  "gemini-3-pro-image-preview.description": "Gemini 3 Pro Image（Nano Banana Pro）е модел на Google за генериране на изображения, който също така поддържа мултимодален диалог.",
  "gemini-3-pro-preview.description": "Gemini 3 Pro е най-мощният агентен и „vibe-coding“ модел на Google, който предлага по-богати визуализации и по-дълбоко взаимодействие, базирано на съвременно логическо мислене.",
  "gemini-flash-latest.description": "Най-новата версия на Gemini Flash",
  "gemini-flash-lite-latest.description": "Най-новата версия на Gemini Flash-Lite",
  "gemini-pro-latest.description": "Най-новата версия на Gemini Pro",
  "gemma-7b-it.description": "Gemma 7B е икономически ефективен за малки до средни задачи.",
  "gemma2-9b-it.description": "Gemma 2 9B е оптимизиран за специфични задачи и интеграция с инструменти.",
  "gemma2.description": "Gemma 2 е ефективният модел на Google, обхващащ приложения от малки приложения до сложна обработка на данни.",
  "gemma2:27b.description": "Gemma 2 е ефективният модел на Google, обхващащ приложения от малки приложения до сложна обработка на данни.",
  "gemma2:2b.description": "Gemma 2 е ефективният модел на Google, обхващащ приложения от малки приложения до сложна обработка на данни.",
  "generalv3.5.description": "Spark Max е най-пълнофункционалната версия, поддържаща уеб търсене и множество вградени плъгини. Напълно оптимизираните основни възможности, системни роли и извикване на функции осигуряват отлична производителност в сложни приложения.",
  "generalv3.description": "Spark Pro е високопроизводителен LLM, оптимизиран за професионални области като математика, програмиране, здравеопазване и образование. Поддържа уеб търсене и вградени плъгини като прогноза за времето и дата. Осигурява силна производителност и ефективност при сложни въпроси, езиково разбиране и напреднало текстово създаване, което го прави идеален за професионални приложения.",
  "glm-4-0520.description": "GLM-4-0520 е най-новата версия на модела, проектирана за изключително сложни и разнообразни задачи с отлична производителност.",
  "glm-4-7.description": "GLM-4.7 е най-новият флагмански модел на Zhipu AI. Той подобрява способностите за програмиране, дългосрочно планиране на задачи и сътрудничество с инструменти в сценарии за агентно програмиране, постигайки водещи резултати сред отворените модели в множество публични тестове. Общите способности са подобрени, с по-кратки и естествени отговори и по-завладяващо писане. При сложни агентни задачи следването на инструкции е по-силно при използване на инструменти, а естетиката на интерфейса и ефективността при изпълнение на дългосрочни задачи са допълнително подобрени.",
  "glm-4-9b-chat.description": "GLM-4-9B-Chat се представя силно в семантика, математика, логика, програмиране и знания. Поддържа също така уеб браузване, изпълнение на код, извикване на персонализирани инструменти и логическо мислене върху дълги текстове, с поддръжка на 26 езика, включително японски, корейски и немски.",
  "glm-4-air-250414.description": "GLM-4-Air е високостойностен вариант с производителност, близка до GLM-4, висока скорост и по-ниска цена.",
  "glm-4-air.description": "GLM-4-Air е високостойностен вариант с производителност, близка до GLM-4, висока скорост и по-ниска цена.",
  "glm-4-airx.description": "GLM-4-AirX е по-ефективен вариант на GLM-4-Air с до 2.6 пъти по-бързо логическо мислене.",
  "glm-4-alltools.description": "GLM-4-AllTools е универсален агентен модел, оптимизиран за сложно планиране на инструкции и използване на инструменти като уеб браузване, обяснение на код и генериране на текст, подходящ за многозадачно изпълнение.",
  "glm-4-flash-250414.description": "GLM-4-Flash е идеален за прости задачи: най-бърз и безплатен.",
  "glm-4-flash.description": "GLM-4-Flash е идеален за прости задачи: най-бърз и безплатен.",
  "glm-4-flashx.description": "GLM-4-FlashX е подобрена версия на Flash с ултра-бързо логическо мислене.",
  "glm-4-long.description": "GLM-4-Long поддържа ултра-дълги входове за задачи, изискващи памет и обработка на мащабни документи.",
  "glm-4-plus.description": "GLM-4-Plus е флагман с висока интелигентност, силен при работа с дълги текстове и сложни задачи, с подобрена цялостна производителност.",
  "glm-4.1v-thinking-flash.description": "GLM-4.1V-Thinking е най-силният известен ~10B VLM, покриващ SOTA задачи като разбиране на видео, QA по изображения, решаване на задачи, OCR, четене на документи и графики, GUI агенти, фронтенд програмиране и обоснованост. Надминава дори 8 пъти по-големия Qwen2.5-VL-72B в много задачи. С усъвършенствано RL, използва верижно мислене за подобрена точност и богатство, превъзхождайки традиционните модели без мислене както по резултати, така и по обяснимост.",
  "glm-4.1v-thinking-flashx.description": "GLM-4.1V-Thinking е най-силният известен ~10B VLM, покриващ SOTA задачи като разбиране на видео, QA по изображения, решаване на задачи, OCR, четене на документи и графики, GUI агенти, фронтенд програмиране и обоснованост. Надминава дори 8 пъти по-големия Qwen2.5-VL-72B в много задачи. С усъвършенствано RL, използва верижно мислене за подобрена точност и богатство, превъзхождайки традиционните модели без мислене както по резултати, така и по обяснимост.",
  "glm-4.5-air.description": "GLM-4.5 лек вариант, който балансира производителност и цена, с гъвкави хибридни режими на мислене.",
  "glm-4.5-airx.description": "GLM-4.5-Air бърз вариант с по-бързи отговори за мащабни и високоскоростни приложения.",
  "glm-4.5-x.description": "GLM-4.5 бърз вариант, осигуряващ силна производителност със скорост на генериране до 100 токена/секунда.",
  "glm-4.5.description": "Флагманският модел на Zhipu с превключваем режим на мислене, осигуряващ SOTA производителност с отворен код и до 128K контекст.",
  "glm-4.5v.description": "Следващото поколение MoE визуален логически модел на Zhipu с 106 милиарда общи параметъра и 12 милиарда активни, постигащ SOTA сред отворените мултимодални модели със сходен размер в задачи с изображения, видео, документи и GUI.",
  "glm-4.6.description": "Най-новият флагмански модел на Zhipu GLM-4.6 (355B) напълно надминава предшествениците си в напреднало програмиране, обработка на дълги текстове, логическо мислене и агентни способности. Особено се доближава до Claude Sonnet 4 по програмиране, превръщайки се в най-добрия кодиращ модел в Китай.",
  "glm-4.7-flash.description": "GLM-4.7-Flash, като SOTA модел от 30B ниво, предлага нов избор, който балансира производителност и ефективност. Подобрява програмирането, дългосрочното планиране и сътрудничеството с инструменти в агентни сценарии, постигайки водещи резултати сред отворените модели със същия размер в актуалните класации.",
  "glm-4.7-flashx.description": "GLM-4.7-Flash, като SOTA модел от 30B ниво, предлага нов избор, който балансира производителност и ефективност. Подобрява програмирането, дългосрочното планиране и сътрудничеството с инструменти в агентни сценарии, постигайки водещи резултати сред отворените модели със същия размер в актуалните класации.",
  "glm-4.7.description": "GLM-4.7 е най-новият флагмански модел на Zhipu, подобрен за сценарии с агентно програмиране с по-добри способности за кодиране, дългосрочно планиране на задачи и сътрудничество с инструменти. Постига водеща производителност сред отворените модели в множество публични бенчмаркове. Общите способности са подобрени с по-кратки и естествени отговори и по-завладяващо писане. При сложни агентни задачи следването на инструкции при извикване на инструменти е по-силно, а естетиката на интерфейса и ефективността при изпълнение на дългосрочни задачи в Artifacts и Agentic Coding са допълнително подобрени.",
  "glm-4.description": "GLM-4 е по-старият флагман, пуснат през януари 2024 г., сега заменен от по-силния GLM-4-0520.",
  "glm-4v-flash.description": "GLM-4V-Flash се фокусира върху ефективно разбиране на единични изображения за бързи анализи като обработка в реално време или на партиди.",
  "glm-4v-plus-0111.description": "GLM-4V-Plus разбира видео и множество изображения, подходящ за мултимодални задачи.",
  "glm-4v-plus.description": "GLM-4V-Plus разбира видео и множество изображения, подходящ за мултимодални задачи.",
  "glm-4v.description": "GLM-4V осигурява силно разбиране на изображения и логическо мислене в различни визуални задачи.",
  "glm-z1-air.description": "Модел за логическо мислене със силни способности за дълбоко разсъждение при сложни задачи.",
  "glm-z1-airx.description": "Ултра-бързо логическо мислене с високо качество на разсъжденията.",
  "glm-z1-flash.description": "Серията GLM-Z1 осигурява силно логическо мислене при сложни задачи, отличавайки се в логика, математика и програмиране.",
  "glm-z1-flashx.description": "Бърз и икономичен: Flash-усилен с ултра-бързо логическо мислене и по-висока едновременност.",
  "glm-zero-preview.description": "GLM-Zero-Preview осигурява силно логическо мислене при сложни задачи, отличавайки се в логика, математика и програмиране.",
  "global.anthropic.claude-opus-4-5-20251101-v1:0.description": "Claude Opus 4.5 е флагманският модел на Anthropic, съчетаващ изключителна интелигентност и мащабируема производителност за комплексни задачи, изискващи отговори и разсъждения с най-високо качество.",
  "google/gemini-2.0-flash-001.description": "Gemini 2.0 Flash предоставя възможности от ново поколение, включително отлична скорост, вградена употреба на инструменти, мултимодално генериране и контекстен прозорец от 1 милион токена.",
  "google/gemini-2.0-flash-lite-001.description": "Gemini 2.0 Flash Lite е олекотен вариант на Gemini с изключено мислене по подразбиране за подобрена латентност и разходи, но може да бъде активирано чрез параметри.",
  "google/gemini-2.0-flash-lite.description": "Gemini 2.0 Flash Lite предлага функции от ново поколение, включително изключителна скорост, вградена употреба на инструменти, мултимодално генериране и контекстен прозорец от 1 милион токена.",
  "google/gemini-2.0-flash.description": "Gemini 2.0 Flash е високопроизводителен модел на Google за разширени мултимодални задачи с разсъждение.",
  "google/gemini-2.5-flash-image-free.description": "Безплатен слой на Gemini 2.5 Flash Image с ограничен капацитет за мултимодално генериране.",
  "google/gemini-2.5-flash-image-preview.description": "Експериментален модел Gemini 2.5 Flash с поддръжка за генериране на изображения.",
  "google/gemini-2.5-flash-image.description": "Gemini 2.5 Flash Image (Nano Banana) е модел на Google за генериране на изображения с поддръжка на мултимодален разговор.",
  "google/gemini-2.5-flash-lite.description": "Gemini 2.5 Flash Lite е олекотен вариант на Gemini 2.5, оптимизиран за ниска латентност и разходи, подходящ за сценарии с висок трафик.",
  "google/gemini-2.5-flash-preview.description": "Gemini 2.5 Flash е най-усъвършенстваният водещ модел на Google, създаден за напреднало разсъждение, програмиране, математика и научни задачи. Включва вградено „мислене“ за по-точни отговори и по-фино обработване на контекста.\n\nЗабележка: Моделът има два варианта — с мислене и без мислене. Ценообразуването на изхода се различава значително в зависимост от това дали мисленето е активирано. Ако изберете стандартния вариант (без суфикса “:thinking”), моделът изрично ще избягва генериране на мисловни токени.\n\nЗа да използвате мислене и да получавате мисловни токени, трябва да изберете варианта “:thinking”, който има по-висока цена за изхода.\n\nGemini 2.5 Flash може също да бъде конфигуриран чрез параметъра “max reasoning tokens”, както е документирано (https://openrouter.ai/docs/use-cases/reasoning-tokens#max-tokens-for-reasoning).",
  "google/gemini-2.5-flash-preview:thinking.description": "Gemini 2.5 Flash е най-усъвършенстваният водещ модел на Google, създаден за напреднало разсъждение, програмиране, математика и научни задачи. Включва вградено „мислене“ за по-точни отговори и по-фино обработване на контекста.\n\nЗабележка: Моделът има два варианта — с мислене и без мислене. Ценообразуването на изхода се различава значително в зависимост от това дали мисленето е активирано. Ако изберете стандартния вариант (без суфикса “:thinking”), моделът изрично ще избягва генериране на мисловни токени.\n\nЗа да използвате мислене и да получавате мисловни токени, трябва да изберете варианта “:thinking”, който има по-висока цена за изхода.\n\nGemini 2.5 Flash може също да бъде конфигуриран чрез параметъра “max reasoning tokens”, както е документирано (https://openrouter.ai/docs/use-cases/reasoning-tokens#max-tokens-for-reasoning).",
  "google/gemini-2.5-flash.description": "Gemini 2.5 Flash (Lite/Pro/Flash) е фамилия от модели на Google, обхващаща от ниска латентност до високопроизводително разсъждение.",
  "google/gemini-2.5-pro-free.description": "Безплатен слой на Gemini 2.5 Pro с ограничен капацитет за мултимодален дълъг контекст, подходящ за тестове и леки работни потоци.",
  "google/gemini-2.5-pro-preview.description": "Gemini 2.5 Pro Preview е най-усъвършенстваният мисловен модел на Google за разсъждение върху сложни проблеми в програмирането, математиката и STEM, както и за анализ на големи набори от данни, кодови бази и документи с дълъг контекст.",
  "google/gemini-2.5-pro.description": "Gemini 2.5 Pro е водещият модел на Google за разсъждение с поддръжка на дълъг контекст за сложни задачи.",
  "google/gemini-3-pro-image-preview-free.description": "Безплатен слой на Gemini 3 Pro Image с ограничен капацитет за мултимодално генериране.",
  "google/gemini-3-pro-image-preview.description": "Gemini 3 Pro Image (Nano Banana Pro) е модел на Google за генериране на изображения с поддръжка на мултимодален разговор.",
  "google/gemini-3-pro-preview-free.description": "Gemini 3 Pro Preview Free предлага същото мултимодално разбиране и разсъждение като стандартната версия, но с квотни и честотни ограничения, което го прави подходящ за тестове и нискочестотна употреба.",
  "google/gemini-3-pro-preview.description": "Gemini 3 Pro е модел от ново поколение за мултимодално разсъждение от фамилията Gemini, който разбира текст, аудио, изображения и видео и се справя със сложни задачи и големи кодови бази.",
  "google/gemini-embedding-001.description": "Модел за вграждане от най-ново поколение с висока производителност при задачи на английски, многоезични и кодови задачи.",
  "google/gemini-flash-1.5.description": "Gemini 1.5 Flash осигурява оптимизирана мултимодална обработка за широк спектър от сложни задачи.",
  "google/gemini-pro-1.5.description": "Gemini 1.5 Pro съчетава най-новите оптимизации за по-ефективна обработка на мултимодални данни.",
  "google/gemma-2-27b-it.description": "Gemma 2 27B е универсален LLM с висока производителност в множество сценарии.",
  "google/gemma-2-27b.description": "Gemma 2 е ефективна фамилия модели на Google за приложения от малки приложения до сложна обработка на данни.",
  "google/gemma-2-2b-it.description": "Разширен малък езиков модел, проектиран за edge приложения.",
  "google/gemma-2-9b-it.description": "Gemma 2 9B, разработен от Google, предлага ефективно следване на инструкции и стабилни общи възможности.",
  "google/gemma-2-9b-it:free.description": "Gemma 2 е олекотена фамилия модели с отворен код на Google за текст.",
  "google/gemma-2-9b.description": "Gemma 2 е ефективна фамилия модели на Google за приложения от малки приложения до сложна обработка на данни.",
  "google/gemma-2b-it.description": "Gemma Instruct (2B) осигурява базова обработка на инструкции за олекотени приложения.",
  "google/gemma-3-12b-it.description": "Gemma 3 12B е езиков модел с отворен код от Google, който поставя нов стандарт за ефективност и производителност.",
  "google/gemma-3-27b-it.description": "Gemma 3 27B е езиков модел с отворен код от Google, който поставя нов стандарт за ефективност и производителност.",
  "google/text-embedding-005.description": "Модел за вграждане на текст, фокусиран върху английски език, оптимизиран за задачи с код и английски език.",
  "google/text-multilingual-embedding-002.description": "Многоезичен модел за вграждане на текст, оптимизиран за задачи с кръстосан езиков обхват на много езици.",
  "gpt-3.5-turbo-0125.description": "GPT 3.5 Turbo за генериране и разбиране на текст; в момента сочи към gpt-3.5-turbo-0125.",
  "gpt-3.5-turbo-1106.description": "GPT 3.5 Turbo за генериране и разбиране на текст; в момента сочи към gpt-3.5-turbo-0125.",
  "gpt-3.5-turbo-instruct.description": "GPT 3.5 Turbo за задачи с генериране и разбиране на текст, оптимизиран за следване на инструкции.",
  "gpt-3.5-turbo.description": "GPT 3.5 Turbo за генериране и разбиране на текст; в момента сочи към gpt-3.5-turbo-0125.",
  "gpt-35-turbo-16k.description": "GPT-3.5 Turbo 16k е модел за генериране на текст с висока капацитетност за сложни задачи.",
  "gpt-35-turbo.description": "GPT-3.5 Turbo е ефективният модел на OpenAI за чат и генериране на текст, поддържащ паралелно извикване на функции.",
  "gpt-4-0125-preview.description": "Най-новият GPT-4 Turbo добавя възможности за визуално разпознаване. Визуалните заявки поддържат JSON режим и извикване на функции. Това е рентабилен мултимодален модел, който балансира точността и ефективността за приложения в реално време.",
  "gpt-4-0613.description": "GPT-4 предлага по-голям контекстов прозорец за обработка на по-дълги входове, подходящ за обобщаване на широка информация и анализ на данни.",
  "gpt-4-1106-preview.description": "Най-новият GPT-4 Turbo добавя възможности за визуално разпознаване. Визуалните заявки поддържат JSON режим и извикване на функции. Това е рентабилен мултимодален модел, който балансира точността и ефективността за приложения в реално време.",
  "gpt-4-32k-0613.description": "GPT-4 предлага по-голям контекстов прозорец за обработка на по-дълги входове в сценарии, изискващи интеграция на широка информация и анализ на данни.",
  "gpt-4-32k.description": "GPT-4 предлага по-голям контекстов прозорец за обработка на по-дълги входове в сценарии, изискващи интеграция на широка информация и анализ на данни.",
  "gpt-4-turbo-2024-04-09.description": "Най-новият GPT-4 Turbo добавя възможности за визуално разпознаване. Визуалните заявки поддържат JSON режим и извикване на функции. Това е рентабилен мултимодален модел, който балансира точността и ефективността за приложения в реално време.",
  "gpt-4-turbo-preview.description": "Най-новият GPT-4 Turbo добавя възможности за визуално разпознаване. Визуалните заявки поддържат JSON режим и извикване на функции. Това е рентабилен мултимодален модел, който балансира точността и ефективността за приложения в реално време.",
  "gpt-4-turbo.description": "Най-новият GPT-4 Turbo добавя възможности за визуално разпознаване. Визуалните заявки поддържат JSON режим и извикване на функции. Това е рентабилен мултимодален модел, който балансира точността и ефективността за приложения в реално време.",
  "gpt-4-vision-preview.description": "Предварителен преглед на GPT-4 Vision, създаден за задачи по анализ и обработка на изображения.",
  "gpt-4.1-mini.description": "GPT-4.1 mini балансира интелигентност, скорост и цена, което го прави привлекателен за множество приложения.",
  "gpt-4.1-nano.description": "GPT-4.1 nano е най-бързият и най-рентабилен модел от серията GPT-4.1.",
  "gpt-4.1.description": "GPT-4.1 е водещият ни модел за сложни задачи и решаване на проблеми в различни области.",
  "gpt-4.5-preview.description": "GPT-4.5-preview е най-новият универсален модел с дълбоки познания за света и по-добро разбиране на намеренията, силен в творчески задачи и планиране на агенти. Границата на знанията му е октомври 2023 г.",
  "gpt-4.description": "GPT-4 предлага по-голям контекстов прозорец за обработка на по-дълги входове, подходящ за обобщаване на широка информация и анализ на данни.",
  "gpt-4o-2024-05-13.description": "ChatGPT-4o е динамичен модел, актуализиран в реално време, който съчетава силно разбиране и генериране за мащабни приложения като клиентска поддръжка, образование и техническа помощ.",
  "gpt-4o-2024-08-06.description": "ChatGPT-4o е динамичен модел, актуализиран в реално време. Съчетава силно езиково разбиране и генериране за мащабни приложения като клиентска поддръжка, образование и техническа помощ.",
  "gpt-4o-2024-11-20.description": "ChatGPT-4o е динамичен модел, актуализиран в реално време, който съчетава силно разбиране и генериране за мащабни приложения като клиентска поддръжка, образование и техническа помощ.",
  "gpt-4o-audio-preview.description": "Предварителен преглед на GPT-4o Audio модел с аудио вход и изход.",
  "gpt-4o-mini-audio-preview.description": "GPT-4o mini Audio модел с аудио вход и изход.",
  "gpt-4o-mini-realtime-preview.description": "GPT-4o-mini вариант в реално време с аудио и текстов вход/изход в реално време.",
  "gpt-4o-mini-search-preview.description": "GPT-4o mini Search Preview е обучен да разбира и изпълнява заявки за уеб търсене чрез Chat Completions API. Уеб търсенето се таксува на извикване на инструмент в допълнение към разходите за токени.",
  "gpt-4o-mini-transcribe.description": "GPT-4o Mini Transcribe е модел за преобразуване на реч в текст, който транскрибира аудио с помощта на GPT-4o, подобрявайки точността на думите, идентификацията на езика и прецизността спрямо оригиналния модел Whisper.",
  "gpt-4o-mini-tts.description": "GPT-4o mini TTS е модел за преобразуване на текст в реч, базиран на GPT-4o mini, който преобразува текст в естествено звучаща реч с максимум 2000 токена вход.",
  "gpt-4o-mini.description": "GPT-4o mini е най-новият модел на OpenAI след GPT-4 Omni, поддържащ вход от текст и изображение с текстов изход. Това е най-усъвършенстваният им малък модел, значително по-евтин от последните водещи модели и над 60% по-евтин от GPT-3.5 Turbo, като същевременно поддържа водеща интелигентност (82% MMLU).",
  "gpt-4o-realtime-preview-2024-10-01.description": "GPT-4o вариант в реално време с аудио и текстов вход/изход в реално време.",
  "gpt-4o-realtime-preview-2025-06-03.description": "GPT-4o вариант в реално време с аудио и текстов вход/изход в реално време.",
  "gpt-4o-realtime-preview.description": "GPT-4o вариант в реално време с аудио и текстов вход/изход в реално време.",
  "gpt-4o-search-preview.description": "GPT-4o Search Preview е обучен да разбира и изпълнява заявки за уеб търсене чрез Chat Completions API. Уеб търсенето се таксува на извикване на инструмент в допълнение към разходите за токени.",
  "gpt-4o-transcribe.description": "GPT-4o Transcribe е модел за преобразуване на реч в текст, който транскрибира аудио с помощта на GPT-4o, подобрявайки точността на думите, идентификацията на езика и прецизността спрямо оригиналния модел Whisper.",
  "gpt-4o.description": "ChatGPT-4o е динамичен модел, актуализиран в реално време, който съчетава силно разбиране и генериране за мащабни приложения като клиентска поддръжка, образование и техническа помощ.",
  "gpt-5-chat-latest.description": "Моделът GPT-5, използван в ChatGPT, съчетава силно разбиране и генериране за разговорни приложения.",
  "gpt-5-chat.description": "GPT-5 Chat е предварителен модел, оптимизиран за разговорни сценарии. Поддържа вход от текст и изображения, изход само текст, подходящ за чатботове и разговорен ИИ.",
  "gpt-5-codex.description": "GPT-5 Codex е вариант на GPT-5, оптимизиран за агентски задачи по програмиране в среди, подобни на Codex.",
  "gpt-5-mini.description": "По-бърз и по-икономичен вариант на GPT-5 за добре дефинирани задачи, осигуряващ по-бързи отговори при запазено качество.",
  "gpt-5-nano.description": "Най-бързият и най-рентабилен вариант на GPT-5, идеален за приложения, чувствителни към закъснение и разходи.",
  "gpt-5-pro.description": "GPT-5 Pro използва повече изчислителна мощ за по-дълбоко мислене и последователно предоставя по-добри отговори.",
  "gpt-5.1-chat-latest.description": "GPT-5.1 Chat: вариантът на GPT-5.1 за ChatGPT, създаден за чат сценарии.",
  "gpt-5.1-codex-mini.description": "GPT-5.1 Codex mini: по-малък и по-евтин вариант на Codex, оптимизиран за агентски задачи по програмиране.",
  "gpt-5.1-codex.description": "GPT-5.1 Codex: вариант на GPT-5.1, оптимизиран за агентски задачи по програмиране, за сложни кодови/агентски работни потоци в Responses API.",
  "gpt-5.1.description": "GPT-5.1 — водещ модел, оптимизиран за програмиране и агентски задачи с конфигурируемо усилие за разсъждение и по-дълъг контекст.",
  "gpt-5.2-chat-latest.description": "GPT-5.2 Chat е вариантът на ChatGPT (chat-latest) с най-новите подобрения в разговорите.",
  "gpt-5.2-pro.description": "GPT-5.2 pro: по-интелигентен и прецизен вариант на GPT-5.2 (само чрез Responses API), подходящ за трудни задачи и дълги многоетапни разсъждения.",
  "gpt-5.2.description": "GPT-5.2 е водещ модел за програмиране и агентски работни потоци с по-силно разсъждение и производителност при дълъг контекст.",
  "gpt-5.description": "Най-добрият модел за междудисциплинарно програмиране и агентски задачи. GPT-5 прави скок в точността, скоростта, разсъждението, осъзнаването на контекста, структурираното мислене и решаването на проблеми.",
  "gpt-audio.description": "GPT Audio е универсален чат модел за вход/изход на аудио, поддържан в Chat Completions API.",
  "gpt-image-1-mini.description": "По-евтин вариант на GPT Image 1 с роден вход от текст и изображения и изход на изображения.",
  "gpt-image-1.5.description": "Подобрен модел GPT Image 1 с 4× по-бързо генериране, по-прецизно редактиране и подобрено рендиране на текст.",
  "gpt-image-1.description": "Роден мултимодален модел за генериране на изображения в ChatGPT.",
  "gpt-oss-120b.description": "Изисква кандидатстване за достъп. GPT-OSS-120B е отворен голям езиков модел от OpenAI със силни възможности за генериране на текст.",
  "gpt-oss-20b.description": "Изисква кандидатстване за достъп. GPT-OSS-20B е отворен езиков модел със среден размер от OpenAI с ефективно генериране на текст.",
  "gpt-oss:120b.description": "GPT-OSS 120B е големият отворен езиков модел на OpenAI, използващ MXFP4 квантизация и позициониран като водещ модел. Изисква среди с множество GPU или висок клас работни станции и осигурява отлично представяне при сложни логически задачи, генериране на код и многоезична обработка, с усъвършенствано извикване на функции и интеграция с инструменти.",
  "gpt-oss:20b.description": "GPT-OSS 20B е отворен езиков модел на OpenAI, използващ MXFP4 квантизация, подходящ за потребителски GPU от висок клас или Apple Silicon Mac. Представя се добре при генериране на диалози, програмиране и логически задачи, поддържа извикване на функции и използване на инструменти.",
  "gpt-realtime.description": "Общ модел в реално време, поддържащ текстов и аудио вход/изход в реално време, както и вход от изображения.",
  "grok-2-image-1212.description": "Нашият най-нов модел за генериране на изображения създава живи, реалистични изображения от текстови подсказки и се отличава в маркетинг, социални мрежи и развлекателни приложения.",
  "grok-2-vision-1212.description": "Подобрена точност, следване на инструкции и многоезични възможности.",
  "grok-3-mini.description": "Олекотен модел, който обмисля преди да отговори. Бърз и интелигентен при логически задачи, които не изискват дълбоки познания, с достъп до сурови логически следи.",
  "grok-3.description": "Водещ модел, който се отличава в корпоративни приложения като извличане на данни, програмиране и обобщаване, с дълбоки познания във финанси, здравеопазване, право и наука.",
  "grok-4-0709.description": "Grok 4 на xAI с мощни логически способности.",
  "grok-4-1-fast-non-reasoning.description": "Модерен мултимодален модел, оптимизиран за високоефективна употреба на агентски инструменти.",
  "grok-4-1-fast-reasoning.description": "Модерен мултимодален модел, оптимизиран за високоефективна употреба на агентски инструменти.",
  "grok-4-fast-non-reasoning.description": "С гордост представяме Grok 4 Fast – нашият най-нов напредък в икономичните логически модели.",
  "grok-4-fast-reasoning.description": "С гордост представяме Grok 4 Fast – нашият най-нов напредък в икономичните логически модели.",
  "grok-4.description": "Нашият най-нов и най-мощен водещ модел, който се отличава в обработка на естествен език, математика и логика – идеален универсален модел.",
  "grok-code-fast-1.description": "С гордост представяме grok-code-fast-1 – бърз и икономичен логически модел, който се отличава в агентско програмиране.",
  "groq/compound-mini.description": "Compound-mini е композитна AI система, задвижвана от публично достъпни модели, поддържани в GroqCloud, която интелигентно и селективно използва инструменти за отговаряне на потребителски запитвания.",
  "groq/compound.description": "Compound е композитна AI система, задвижвана от множество публично достъпни модели, поддържани в GroqCloud, която интелигентно и селективно използва инструменти за отговаряне на потребителски запитвания.",
  "gryphe/mythomax-l2-13b.description": "MythoMax L2 13B е креативен и интелигентен езиков модел, създаден чрез обединяване на няколко водещи модела.",
  "hunyuan-a13b.description": "Първият хибриден логически модел на Hunyuan, надграден от hunyuan-standard-256K (общо 80B, 13B активни). По подразбиране използва бавно мислене и поддържа превключване между бързо/бавно чрез параметри или префикс /no_think. Общите възможности са подобрени спрямо предишното поколение, особено в математика, наука, разбиране на дълги текстове и агентски задачи.",
  "hunyuan-code.description": "Най-новият модел за генериране на код, обучен с 200B висококачествен код и шест месеца SFT; контекстът е разширен до 8K. Води в автоматизирани тестове за пет езика и в човешки оценки по десет критерия.",
  "hunyuan-functioncall.description": "Най-новият MoE модел FunctionCall, обучен с висококачествени данни за извикване на функции, с прозорец на контекста от 32K и водещи резултати в бенчмаркове по различни измерения.",
  "hunyuan-large-longcontext.description": "Отличава се при задачи с дълги документи като обобщаване и въпроси/отговори, като същевременно се справя с общо генериране. Силен в анализ и генериране на дълги текстове със сложно и детайлно съдържание.",
  "hunyuan-large-vision.description": "Модел за разбиране на изображения и текст, обучен от Hunyuan Large. Поддържа вход от множество изображения + текст при всякаква резолюция и подобрява многоезичното визуално разбиране.",
  "hunyuan-large.description": "Hunyuan-large има ~389B общи параметри и ~52B активни – най-големият и най-мощен отворен MoE модел с трансформър архитектура.",
  "hunyuan-lite-vision.description": "Най-новият 7B мултимодален модел с прозорец на контекста от 32K, поддържащ китайско/английски мултимодален чат, разпознаване на обекти, разбиране на таблици в документи и мултимодална математика, превъзхождащ други 7B модели в множество бенчмаркове.",
  "hunyuan-lite.description": "Надграден до MoE архитектура с прозорец на контекста от 256K, водещ много отворени модели в NLP, програмиране, математика и индустриални бенчмаркове.",
  "hunyuan-pro.description": "MoE модел с трилион параметри и 32K контекст, водещ в бенчмаркове, силен при сложни инструкции и логика, напреднала математика, извикване на функции и оптимизиран за многоезичен превод, финанси, право и медицина.",
  "hunyuan-role.description": "Най-новият модел за ролеви игри, официално фино настроен върху ролеви датасети, осигуряващ по-силна базова производителност за ролеви сценарии.",
  "hunyuan-standard-256K.description": "Използва подобрено маршрутизиране за намаляване на натоварването и срив на експерти. Постига 99.9% точност при търсене на игла в купа сено в дълъг контекст. MOE-256K допълнително разширява дължината и качеството на контекста.",
  "hunyuan-standard-vision.description": "Най-новият мултимодален модел с многоезични отговори и балансирани способности на китайски и английски.",
  "hunyuan-standard.description": "Използва подобрено маршрутизиране за намаляване на натоварването и срив на експерти. Постига 99.9% точност при търсене на игла в купа сено в дълъг контекст. MOE-32K предлага силна стойност при работа с дълги входове.",
  "hunyuan-t1-20250321.description": "Изгражда балансирани способности в изкуства и STEM с добро улавяне на информация от дълги текстове. Поддържа логически отговори за задачи по математика, логика, наука и програмиране на различни нива на трудност.",
  "hunyuan-t1-20250403.description": "Подобрява генерирането на код на ниво проекти и качеството на писане, засилва разбирането на теми в многоходови разговори и следване на инструкции, подобрява разбиране на думи и намалява смесването на опростен/традиционен китайски и китайски/английски изход.",
  "hunyuan-t1-20250529.description": "Подобрява креативното писане и композиция, засилва фронтенд програмиране, математика и логическо мислене, и подобрява следването на инструкции.",
  "hunyuan-t1-20250711.description": "Значително подобрява трудна математика, логика и програмиране, повишава стабилността на изхода и засилва способностите за работа с дълги текстове.",
  "hunyuan-t1-latest.description": "Значително подобрява модела с бавно мислене при трудна математика, сложна логика, трудни задачи по програмиране, следване на инструкции и качество на креативното писане.",
  "hunyuan-t1-vision-20250619.description": "Най-новият мултимодален модел t1-vision с дълбоко логическо мислене и вградена верига на мисълта, значително подобрен спрямо предишната версия по подразбиране.",
  "hunyuan-t1-vision-20250916.description": "Най-новият модел t1-vision с дълбоко логическо мислене и големи подобрения във VQA, визуално привързване, OCR, диаграми, решаване на заснети задачи и създаване на съдържание от изображения, както и по-силна поддръжка на английски и езици с ограничени ресурси.",
  "hunyuan-turbo-20241223.description": "Тази версия подобрява мащабирането на инструкции за по-добра генерализация, значително подобрява логическото мислене в математика/код/логика, засилва разбирането на думи и повишава качеството на писане.",
  "hunyuan-turbo-latest.description": "Общи подобрения в NLP разбирането, писането, чата, въпросите и отговорите, превода и специализираните области; по-човешки отговори, по-добро изясняване на неясни намерения, подобрен синтактичен анализ, по-високо творческо качество и интерактивност, както и по-силни многозавойни разговори.",
  "hunyuan-turbo-vision.description": "Флагмански модел от ново поколение за визия и език с нова MoE архитектура, с широки подобрения в разпознаването, създаването на съдържание, въпроси и отговори по знания и аналитично мислене.",
  "hunyuan-turbo.description": "Преглед на следващото поколение LLM на Hunyuan с нова MoE архитектура, осигуряваща по-бързо разсъждение и по-силни резултати от hunyuan-pro.",
  "hunyuan-turbos-20250313.description": "Унифицира стила на решаване на математически задачи и засилва многозавойните въпроси и отговори в математиката. Стилът на писане е усъвършенстван, за да намали изкуствения тон и да добави изтънченост.",
  "hunyuan-turbos-20250416.description": "Подобрен базов модел за предварително обучение за по-добро разбиране и следване на инструкции; подобрено съгласуване в математика, код, логика и наука; подобрено качество на писане, разбиране, точност на превода и въпроси и отговори по знания; засилени способности на агентите, особено при многозавойно разбиране.",
  "hunyuan-turbos-20250604.description": "Подобрен базов модел за предварително обучение с по-добро писане и четене с разбиране, значителни подобрения в кода и STEM, както и по-добро следване на сложни инструкции.",
  "hunyuan-turbos-20250926.description": "Подобрено качество на предварителните данни и стратегията за последващо обучение, подобряваща агентите, английския език/езиците с ограничени ресурси, следването на инструкции, кода и STEM възможностите.",
  "hunyuan-turbos-latest.description": "Най-новият флагмански модел Hunyuan TurboS с по-силно разсъждение и по-добро цялостно изживяване.",
  "hunyuan-turbos-longtext-128k-20250325.description": "Изключителен при задачи с дълги документи като обобщение и въпроси и отговори, като същевременно се справя с общо генериране. Силен при анализ и генериране на дълги текстове за сложни и детайлни съдържания.",
  "hunyuan-turbos-role-plus.description": "Най-новият модел за ролеви игри, официално фино настроен върху ролеви набори от данни, осигуряващ по-силна базова производителност за ролеви сценарии.",
  "hunyuan-turbos-vision-20250619.description": "Най-новият флагмански модел TurboS за визия и език с големи подобрения при задачи с изображения и текст като разпознаване на обекти, въпроси и отговори по знания, копирайтинг и решаване на задачи по снимки.",
  "hunyuan-turbos-vision.description": "Флагмански модел от ново поколение за визия и език, базиран на най-новия TurboS, фокусиран върху задачи с разбиране на изображения и текст като разпознаване на обекти, въпроси и отговори по знания, копирайтинг и решаване на задачи по снимки.",
  "hunyuan-vision-1.5-instruct.description": "Модел за бързо мислене, генериращ текст от изображения, базиран на текстовия TurboS. В сравнение с предишната версия, има значителни подобрения в основното разпознаване и анализ на изображения.",
  "hunyuan-vision.description": "Най-новият мултимодален модел, поддържащ вход от изображения и текст за генериране на текст.",
  "image-01-live.description": "Модел за генериране на изображения с фини детайли, поддържащ преобразуване от текст към изображение и контролируеми стилови настройки.",
  "image-01.description": "Нов модел за генериране на изображения с фини детайли, поддържащ преобразуване от текст към изображение и от изображение към изображение.",
  "imagen-4.0-fast-generate-001.description": "Бързата версия от четвъртото поколение модели Imagen за преобразуване от текст към изображение.",
  "imagen-4.0-generate-001.description": "Четвърто поколение модели Imagen за преобразуване от текст към изображение.",
  "imagen-4.0-generate-preview-06-06.description": "Семейство модели от четвърто поколение Imagen за преобразуване от текст към изображение.",
  "imagen-4.0-ultra-generate-001.description": "Ultra версията от четвъртото поколение модели Imagen за преобразуване от текст към изображение.",
  "imagen-4.0-ultra-generate-preview-06-06.description": "Ultra вариант от четвъртото поколение модели Imagen за преобразуване от текст към изображение.",
  "inception/mercury-coder-small.description": "Mercury Coder Small е идеален за генериране на код, отстраняване на грешки и рефакториране с минимално закъснение.",
  "inclusionAI/Ling-flash-2.0.description": "Ling-flash-2.0 е третият модел от архитектурата Ling 2.0, разработен от екипа Bailing на Ant Group. Това е MoE модел със 100 милиарда общи параметри, от които само 6.1 милиарда са активни на токен (4.8 милиарда без вграждане). Въпреки леката си конфигурация, той съперничи или надминава плътни модели с 40 милиарда параметри и дори по-големи MoE модели в множество бенчмаркове, като постига висока ефективност чрез архитектура и стратегия на обучение.",
  "inclusionAI/Ling-mini-2.0.description": "Ling-mini-2.0 е малък, високоефективен MoE LLM с 16 милиарда общи параметри и само 1.4 милиарда активни на токен (789 милиона без вграждане), осигуряващ изключително бързо генериране. Благодарение на ефективния MoE дизайн и голям обем висококачествени обучителни данни, той постига водеща производителност, сравнима с плътни модели под 10 милиарда и по-големи MoE модели.",
  "inclusionAI/Ring-flash-2.0.description": "Ring-flash-2.0 е високоефективен мислещ модел, оптимизиран от базовия Ling-flash-2.0. Използва MoE архитектура със 100 милиарда общи параметри и само 6.1 милиарда активни при всяка инференция. Алгоритъмът icepop стабилизира обучението с подсилване (RL) за MoE модели, позволявайки допълнителни подобрения в сложното разсъждение. Постига значителни пробиви в трудни бенчмаркове (математически състезания, генериране на код, логическо мислене), надминавайки водещи плътни модели под 40 милиарда и съперничейки на по-големи отворени и затворени MoE модели за разсъждение. Също така се представя добре в творческо писане, а ефективната му архитектура осигурява бърза инференция с по-ниски разходи за внедряване при висока едновременност.",
  "inclusionai/ling-1t.description": "Ling-1T е MoE модел на inclusionAI с 1 трилион параметри, оптимизиран за задачи с висока интензивност на разсъждение и работа с голям контекст.",
  "inclusionai/ling-flash-2.0.description": "Ling-flash-2.0 е MoE модел на inclusionAI, оптимизиран за ефективност и производителност при разсъждение, подходящ за средни до големи задачи.",
  "inclusionai/ling-mini-2.0.description": "Ling-mini-2.0 е лек MoE модел на inclusionAI, който значително намалява разходите, като същевременно запазва способността за разсъждение.",
  "inclusionai/ming-flash-omini-preview.description": "Ming-flash-omni Preview е мултимодален модел на inclusionAI, поддържащ вход от реч, изображение и видео, с подобрено визуализиране на изображения и разпознаване на реч.",
  "inclusionai/ring-1t.description": "Ring-1T е MoE модел на inclusionAI с трилион параметри, предназначен за мащабни задачи по разсъждение и научни изследвания.",
  "inclusionai/ring-flash-2.0.description": "Ring-flash-2.0 е вариант на модела Ring от inclusionAI за сценарии с висока пропускателна способност, с акцент върху скоростта и ефективността на разходите.",
  "inclusionai/ring-mini-2.0.description": "Ring-mini-2.0 е лек MoE модел на inclusionAI с висока пропускателна способност, създаден за едновременна работа.",
  "internlm/internlm2_5-7b-chat.description": "InternLM2.5-7B-Chat е отворен модел за чат, базиран на архитектурата InternLM2. Моделът с 7B параметри е фокусиран върху генериране на диалог с поддръжка на китайски/английски, използвайки съвременно обучение за плавен и интелигентен разговор. Подходящ е за различни сценарии като клиентска поддръжка и лични асистенти.",
  "internlm2.5-latest.description": "Наследени модели, които все още се поддържат с отлична и стабилна производителност след множество итерации. Предлагат се във варианти 7B и 20B, поддържат 1M контекст и по-силно следване на инструкции и използване на инструменти. По подразбиране използва последната серия InternLM2.5 (в момента internlm2.5-20b-chat).",
  "internlm3-latest.description": "Нашата най-нова серия модели с отлична производителност при разсъждение, водеща сред отворените модели в своя клас. По подразбиране използва последната серия InternLM3 (в момента internlm3-8b-instruct).",
  "internvl2.5-38b-mpo.description": "InternVL2.5 38B MPO е мултимодален предварително обучен модел за комплексно визуално-текстово разсъждение.",
  "internvl2.5-latest.description": "InternVL2.5 все още се поддържа с висока и стабилна производителност. По подразбиране използва последната серия InternVL2.5 (в момента internvl2.5-78b).",
  "internvl3-14b.description": "InternVL3 14B е среден по размер мултимодален модел, балансиращ между производителност и разходи.",
  "internvl3-1b.description": "InternVL3 1B е лек мултимодален модел за внедряване при ограничени ресурси.",
  "internvl3-38b.description": "InternVL3 38B е голям отворен мултимодален модел за високоточна визуално-текстова интерпретация.",
  "internvl3-latest.description": "Нашият най-нов мултимодален модел с по-силно визуално-текстово разбиране и разбиране на дълги визуални последователности, сравним с водещите затворени модели. По подразбиране използва последната серия InternVL (в момента internvl3-78b).",
  "irag-1.0.description": "ERNIE iRAG е модел за генериране, подсилен с извличане на изображения, предназначен за търсене на изображения, визуално-текстово извличане и създаване на съдържание.",
  "jamba-large.description": "Нашият най-мощен и напреднал модел, създаден за комплексни корпоративни задачи с изключителна производителност.",
  "jamba-mini.description": "Най-ефективният модел в своя клас, балансиращ скорост и качество с малък отпечатък.",
  "meta.llama3-8b-instruct-v1:0.description": "Meta Llama 3 е отворен LLM, предназначен за разработчици, изследователи и предприятия, създаден да им помага да изграждат, експериментират и отговорно мащабират идеи за генеративен ИИ. Като част от основата за глобални иновации в общността, той е подходящ за среди с ограничени изчислителни ресурси, крайни устройства и по-бързо обучение.",
  "meta/Llama-3.2-11B-Vision-Instruct.description": "Силен визуален анализ на изображения с висока резолюция, подходящ за приложения за визуално разбиране.",
  "meta/Llama-3.2-90B-Vision-Instruct.description": "Разширен визуален анализ за приложения с агенти за визуално разбиране.",
  "meta/Llama-3.3-70B-Instruct.description": "Llama 3.3 е най-усъвършенстваният многоезичен отворен модел Llama, предлагащ производителност, близка до 405B, на много ниска цена. Базиран е на трансформър архитектура и е подобрен чрез SFT и RLHF за полезност и безопасност. Версията, настроена за инструкции, е оптимизирана за многоезичен чат и надминава много отворени и затворени модели в индустриалните бенчмаркове. Край на знанията: декември 2023.",
  "meta/Meta-Llama-3-70B-Instruct.description": "Мощен модел с 70 милиарда параметъра, отличаващ се с логическо мислене, програмиране и широк спектър от езикови задачи.",
  "meta/Meta-Llama-3-8B-Instruct.description": "Универсален модел с 8 милиарда параметъра, оптимизиран за чат и генериране на текст.",
  "meta/Meta-Llama-3.1-405B-Instruct.description": "Llama 3.1, настроен за инструкции, е текстов модел, оптимизиран за многоезичен чат, с висока производителност в индустриалните бенчмаркове сред отворени и затворени модели.",
  "meta/Meta-Llama-3.1-70B-Instruct.description": "Llama 3.1, настроен за инструкции, е текстов модел, оптимизиран за многоезичен чат, с висока производителност в индустриалните бенчмаркове сред отворени и затворени модели.",
  "meta/Meta-Llama-3.1-8B-Instruct.description": "Llama 3.1, настроен за инструкции, е текстов модел, оптимизиран за многоезичен чат, с висока производителност в индустриалните бенчмаркове сред отворени и затворени модели.",
  "meta/llama-3-70b.description": "Отворен модел с 70 милиарда параметъра, фино настроен от Meta за следване на инструкции, предоставян от Groq на LPU хардуер за бързо и ефективно изпълнение.",
  "meta/llama-3-8b.description": "Отворен модел с 8 милиарда параметъра, фино настроен от Meta за следване на инструкции, предоставян от Groq на LPU хардуер за бързо и ефективно изпълнение.",
  "meta/llama-3.1-405b-instruct.description": "Разширен LLM, поддържащ генериране на синтетични данни, дистилация на знания и логическо мислене за чатботи, програмиране и специализирани задачи.",
  "meta/llama-3.1-70b-instruct.description": "Създаден за сложни диалози с отлично разбиране на контекста, логическо мислене и генериране на текст.",
  "meta/llama-3.1-70b.description": "Обновен Meta Llama 3 70B Instruct с 128K контекст, многоезична поддръжка и подобрено логическо мислене.",
  "meta/llama-3.1-8b-instruct.description": "Модерен модел с високо ниво на езиково разбиране, логическо мислене и генериране на текст.",
  "meta/llama-3.1-8b.description": "Llama 3.1 8B поддържа 128K контекстен прозорец, идеален за чат в реално време и анализ на данни, като предлага значителни икономии спрямо по-големите модели. Предоставян от Groq на LPU хардуер за бързо и ефективно изпълнение.",
  "meta/llama-3.2-11b-vision-instruct.description": "Модерен модел за визуално-езикови задачи, отличаващ се с висококачествено логическо мислене върху изображения.",
  "meta/llama-3.2-11b.description": "Модел, настроен за инструкции, за визуален анализ (вход: текст + изображение, изход: текст), оптимизиран за визуално разпознаване, логическо мислене върху изображения, надписи и общи въпроси за изображения.",
  "meta/llama-3.2-1b-instruct.description": "Модерен малък езиков модел с високо ниво на разбиране, логическо мислене и генериране на текст.",
  "meta/llama-3.2-1b.description": "Само текстов модел за използване на устройства, подходящ за многоезично локално извличане, обобщаване и пренаписване.",
  "meta/llama-3.2-3b-instruct.description": "Модерен малък езиков модел с високо ниво на разбиране, логическо мислене и генериране на текст.",
  "meta/llama-3.2-3b.description": "Само текстов модел, фино настроен за използване на устройства, като многоезично локално извличане, обобщаване и пренаписване.",
  "meta/llama-3.2-90b-vision-instruct.description": "Модерен модел за визуално-езикови задачи, отличаващ се с висококачествено логическо мислене върху изображения.",
  "meta/llama-3.2-90b.description": "Модел, настроен за инструкции, за визуален анализ (вход: текст + изображение, изход: текст), оптимизиран за визуално разпознаване, логическо мислене върху изображения, надписи и общи въпроси за изображения.",
  "meta/llama-3.3-70b-instruct.description": "Разширен LLM, силен в логическо мислене, математика, здрав разум и извикване на функции.",
  "meta/llama-3.3-70b.description": "Перфектен баланс между производителност и ефективност. Създаден за високоефективен разговорен ИИ в създаване на съдържание, корпоративни приложения и изследвания, с високо ниво на езиково разбиране за обобщаване, класификация, анализ на настроения и генериране на код.",
  "meta/llama-4-maverick.description": "Семейството Llama 4 е нативен мултимодален AI модел, поддържащ текстови и мултимодални преживявания, използващ MoE за водещо разбиране на текст и изображения. Llama 4 Maverick е модел с 17B параметъра и 128 експерта, предоставян от DeepInfra.",
  "meta/llama-4-scout.description": "Семейството Llama 4 е нативен мултимодален AI модел, поддържащ текстови и мултимодални преживявания, използващ MoE за водещо разбиране на текст и изображения. Llama 4 Scout е модел с 17B параметъра и 16 експерта, предоставян от DeepInfra.",
  "mistralai/Mistral-7B-v0.1.description": "Mistral 7B е компактен, но високоефективен модел, подходящ за партидна обработка и прости задачи като класификация и генериране на текст, с добро логическо разсъждение.",
  "mistralai/Mixtral-8x22B-Instruct-v0.1.description": "Mixtral-8x22B Instruct (141B) е много голям езиков модел, предназначен за тежки натоварвания.",
  "mistralai/Mixtral-8x7B-Instruct-v0.1.description": "Mixtral-8x7B Instruct (46.7B) предлага висока производителност за обработка на данни в голям мащаб.",
  "mistralai/Mixtral-8x7B-v0.1.description": "Mixtral 8x7B е разреден MoE модел, който ускорява извеждането и е подходящ за многоезични задачи и генериране на код.",
  "mistralai/mistral-nemo.description": "Mistral Nemo е модел с 7.3B параметъра с поддръжка на много езици и силна производителност при програмиране.",
  "mixtral-8x7b-32768.description": "Mixtral 8x7B осигурява устойчиво на грешки паралелно изчисление за сложни задачи.",
  "mixtral.description": "Mixtral е MoE модел на Mistral AI с отворени тегла, поддържащ генериране на код и езиково разбиране.",
  "mixtral:8x22b.description": "Mixtral е MoE модел на Mistral AI с отворени тегла, поддържащ генериране на код и езиково разбиране.",
  "moonshot-v1-128k-vision-preview.description": "Моделите Kimi vision (включително moonshot-v1-8k-vision-preview/moonshot-v1-32k-vision-preview/moonshot-v1-128k-vision-preview) разбират съдържание на изображения като текст, цветове и форми на обекти.",
  "moonshot-v1-128k.description": "Moonshot V1 128K предлага изключително дълъг контекст за генериране на много дълги текстове, обработвайки до 128 000 токена за научни, академични и документи с голям обем.",
  "moonshot-v1-32k-vision-preview.description": "Моделите Kimi vision (включително moonshot-v1-8k-vision-preview/moonshot-v1-32k-vision-preview/moonshot-v1-128k-vision-preview) разбират съдържание на изображения като текст, цветове и форми на обекти.",
  "moonshot-v1-32k.description": "Moonshot V1 32K поддържа 32 768 токена за средно дълъг контекст, идеален за дълги документи и сложни диалози в създаване на съдържание, отчети и чат системи.",
  "moonshot-v1-8k-vision-preview.description": "Моделите Kimi vision (включително moonshot-v1-8k-vision-preview/moonshot-v1-32k-vision-preview/moonshot-v1-128k-vision-preview) разбират съдържание на изображения като текст, цветове и форми на обекти.",
  "moonshot-v1-8k.description": "Moonshot V1 8K е оптимизиран за генериране на кратки текстове с висока ефективност, обработвайки 8 192 токена за кратки чатове, бележки и бързо съдържание.",
  "moonshot-v1-auto.description": "Moonshot V1 Auto избира подходящия модел въз основа на текущата употреба на токени в контекста.",
  "moonshotai/Kimi-Dev-72B.description": "Kimi-Dev-72B е отворен кодов езиков модел, оптимизиран с мащабно подсилващо обучение за създаване на стабилни, готови за продукция корекции. Постига 60.4% в SWE-bench Verified, поставяйки нов рекорд сред отворените модели за автоматизирани задачи като отстраняване на грешки и преглед на код.",
  "moonshotai/Kimi-K2-Instruct-0905.description": "Kimi K2-Instruct-0905 е най-новият и най-мощен модел от серията Kimi K2. Това е MoE модел от най-висок клас с 1T общо и 32B активни параметъра. Основни характеристики включват по-силна агентна интелигентност при програмиране, значителни подобрения в бенчмаркове и реални задачи, както и подобрена естетика и използваемост на фронтенд кода.",
  "moonshotai/Kimi-K2-Thinking.description": "Kimi K2 Thinking е най-новият и най-мощен отворен модел за мислене. Значително разширява дълбочината на многoстъпковото разсъждение и поддържа стабилна употреба на инструменти в 200–300 последователни извиквания, поставяйки нови рекорди в Humanity's Last Exam (HLE), BrowseComp и други бенчмаркове. Отличава се в програмиране, математика, логика и агентни сценарии. Изграден върху MoE архитектура с ~1T параметри, поддържа 256K контекстен прозорец и извикване на инструменти.",
  "moonshotai/kimi-k2-0711.description": "Kimi K2 0711 е instruct вариант от серията Kimi, подходящ за висококачествен код и използване на инструменти.",
  "moonshotai/kimi-k2-0905.description": "Kimi K2 0905 е актуализация, която разширява контекста и логическата производителност с оптимизации за програмиране.",
  "moonshotai/kimi-k2-instruct-0905.description": "Моделът kimi-k2-0905-preview поддържа 256K контекстен прозорец, с по-силно агентно програмиране, по-изпипан и практичен фронтенд код и по-добро разбиране на контекста.",
  "moonshotai/kimi-k2-thinking-turbo.description": "Kimi K2 Thinking Turbo е високоскоростна версия на Kimi K2 Thinking, значително намаляваща латентността, като запазва дълбокото разсъждение.",
  "moonshotai/kimi-k2-thinking.description": "Kimi K2 Thinking е модел за разсъждение на Moonshot, оптимизиран за задачи, изискващи дълбоко мислене, с общи агентни способности.",
  "moonshotai/kimi-k2.description": "Kimi K2 е голям MoE модел от Moonshot AI с 1T общи параметри и 32B активни при всяко преминаване, оптимизиран за агентни способности, включително напреднало използване на инструменти, разсъждение и синтез на код.",
  "morph/morph-v3-fast.description": "Morph предоставя специализиран модел за прилагане на промени в кода, предложени от водещи модели (напр. Claude или GPT-4o), към съществуващите ви файлове със скорост над 4500 токена/сек. Това е последната стъпка в AI работния процес за програмиране и поддържа 16k входни/изходни токена.",
  "morph/morph-v3-large.description": "Morph предоставя специализиран модел за прилагане на промени в кода, предложени от водещи модели (напр. Claude или GPT-4o), към съществуващите ви файлове със скорост над 2500 токена/сек. Това е последната стъпка в AI работния процес за програмиране и поддържа 16k входни/изходни токена.",
  "nousresearch/hermes-2-pro-llama-3-8b.description": "Hermes 2 Pro Llama 3 8B е обновена версия на Nous Hermes 2 с най-новите вътрешно разработени набори от данни.",
  "nvidia/Llama-3.1-Nemotron-70B-Instruct-HF.description": "Llama 3.1 Nemotron 70B е персонализиран LLM от NVIDIA, създаден за подобряване на полезността. Представя се отлично в Arena Hard, AlpacaEval 2 LC и GPT-4-Turbo MT-Bench, заемайки първо място и в трите автоматични бенчмарка към 1 октомври 2024 г. Обучен е от Llama-3.1-70B-Instruct с помощта на RLHF (REINFORCE), Llama-3.1-Nemotron-70B-Reward и HelpSteer2-Preference подсказки.",
  "nvidia/llama-3.1-nemotron-51b-instruct.description": "Отличителен езиков модел, предлагащ изключителна точност и ефективност.",
  "nvidia/llama-3.1-nemotron-70b-instruct.description": "Llama-3.1-Nemotron-70B-Instruct е персонализиран модел на NVIDIA, създаден за подобряване на полезността на отговорите от LLM.",
  "openai/o3-mini.description": "o3-mini е най-новият малък модел за разсъждение на OpenAI, който предлага по-висока интелигентност при същите разходи и закъснение като o1-mini.",
  "openai/o3.description": "OpenAI o3 е най-мощният модел за разсъждение, поставящ нови стандарти в програмирането, математиката, науката и визуалното възприятие. Отличава се при сложни, многопластови заявки и е особено силен в анализа на изображения, графики и диаграми.",
  "openai/o4-mini-high.description": "o4-mini high е модел от висок клас за разсъждение, оптимизиран за бърза и ефективна логика с отлична производителност в програмиране и визуални задачи.",
  "openai/o4-mini.description": "OpenAI o4-mini е малък, ефективен модел за разсъждение, подходящ за сценарии с ниско закъснение.",
  "openai/text-embedding-3-large.description": "Най-способният embedding модел на OpenAI за задачи на английски и други езици.",
  "openai/text-embedding-3-small.description": "Подобрена, високопроизводителна версия на embedding модела ada от OpenAI.",
  "openai/text-embedding-ada-002.description": "Наследен embedding модел за текст от OpenAI.",
  "openrouter/auto.description": "Въз основа на дължината на контекста, темата и сложността, заявката ви се насочва към Llama 3 70B Instruct, Claude 3.5 Sonnet (със самомодерация) или GPT-4o.",
  "perplexity/sonar-pro.description": "Водещият продукт на Perplexity с търсене в реално време, поддържащ сложни заявки и последващи въпроси.",
  "perplexity/sonar-reasoning-pro.description": "Разширен модел, фокусиран върху разсъждение, който генерира chain-of-thought (CoT) с подобрено търсене, включително множество заявки на заявка.",
  "perplexity/sonar-reasoning.description": "Модел, фокусиран върху разсъждение, който генерира chain-of-thought (CoT) с подробни обяснения, базирани на търсене.",
  "perplexity/sonar.description": "Олекотен продукт на Perplexity с търсене в реално време, по-бърз и по-евтин от Sonar Pro.",
  "phi3.description": "Phi-3 е лек отворен модел на Microsoft за ефективна интеграция и мащабно разсъждение.",
  "phi3:14b.description": "Phi-3 е лек отворен модел на Microsoft за ефективна интеграция и мащабно разсъждение.",
  "pixtral-12b-2409.description": "Pixtral е силен в разбирането на графики/изображения, въпроси и отговори по документи, мултимодално разсъждение и следване на инструкции. Обработва изображения в оригинална резолюция/съотношение и поддържа множество изображения в контекст от 128K.",
  "pixtral-large-latest.description": "Pixtral Large е мултимодален отворен модел с 124 милиарда параметъра, базиран на Mistral Large 2 – вторият в нашето мултимодално семейство с водещо разбиране на изображения.",
  "pro-128k.description": "Spark Pro 128K предлага много голям контекст, обработващ до 128K, идеален за дълги документи, изискващи пълен анализ и логическа последователност, с плавна логика и разнообразна поддръжка на цитиране в сложни дискусии.",
  "pro-deepseek-r1.description": "Модел за специализирани корпоративни услуги с включена паралелна обработка.",
  "pro-deepseek-v3.description": "Модел за специализирани корпоративни услуги с включена паралелна обработка.",
  "qianfan-70b.description": "Qianfan 70B е голям китайски модел за висококачествено генериране и сложно разсъждение.",
  "qianfan-8b.description": "Qianfan 8B е среден по размер общ модел, балансиращ разходи и качество за генериране на текст и въпроси/отговори.",
  "qianfan-agent-intent-32k.description": "Qianfan Agent Intent 32K е насочен към разпознаване на намерения и координация на агенти с поддръжка на дълъг контекст.",
  "qianfan-agent-lite-8k.description": "Qianfan Agent Lite 8K е лек агент модел за нискобюджетни многозавойни диалози и работни потоци.",
  "qianfan-check-vl.description": "Qianfan Check VL е мултимодален модел за преглед на съдържание, съвместимост между изображение и текст и задачи по разпознаване.",
  "qianfan-composition.description": "Qianfan Composition е мултимодален модел за създаване, разбиране и генериране на смесено изображение и текст.",
  "qianfan-engcard-vl.description": "Qianfan EngCard VL е мултимодален модел за разпознаване, фокусиран върху английски езикови сценарии.",
  "qianfan-lightning-128b-a19b.description": "Qianfan Lightning 128B A19B е високопроизводителен китайски общ модел за сложни въпроси и мащабно разсъждение.",
  "qianfan-llama-vl-8b.description": "Qianfan Llama VL 8B е мултимодален модел, базиран на Llama, за общо разбиране на изображения и текст.",
  "qianfan-multipicocr.description": "Qianfan MultiPicOCR е OCR модел за множество изображения, откриващ и разпознаващ текст в различни изображения.",
  "qianfan-qi-vl.description": "Qianfan QI VL е мултимодален модел за въпроси и отговори с точна извличане и отговори в сложни сценарии с изображения и текст.",
  "qianfan-singlepicocr.description": "Qianfan SinglePicOCR е OCR модел за едно изображение с висока точност при разпознаване на символи.",
  "qianfan-vl-70b.description": "Qianfan VL 70B е голям мултимодален езиков модел за сложно разбиране на изображения и текст.",
  "qianfan-vl-8b.description": "Qianfan VL 8B е лек мултимодален езиков модел за ежедневни въпроси и анализ на изображения и текст.",
  "qvq-72b-preview.description": "QVQ-72B-Preview е експериментален изследователски модел от Qwen, фокусиран върху подобрено визуално разсъждение.",
  "qvq-max.description": "Моделът за визуално разсъждение Qwen QVQ поддържа вход от изображения и изход с chain-of-thought, с по-силна производителност в математика, програмиране, визуален анализ, творчество и общи задачи.",
  "qvq-plus.description": "Модел за визуално разсъждение с вход от изображения и изход с chain-of-thought. Серията qvq-plus следва qvq-max и предлага по-бързо разсъждение с по-добър баланс между качество и цена.",
  "qwen-3-32b.description": "Qwen 3 32B: силен в многоезични и програмистки задачи, подходящ за средномащабна продукция.",
  "qwen-coder-plus.description": "Модел за програмиране от серията Qwen.",
  "qwen-coder-turbo-latest.description": "Модел за програмиране от серията Qwen.",
  "qwen-coder-turbo.description": "Модел за програмиране от серията Qwen.",
  "qwen-flash.description": "Най-бързият и най-евтин модел от Qwen, идеален за прости задачи.",
  "qwen-image-edit.description": "Qwen Image Edit е модел за редактиране на изображения, който променя изображения въз основа на входни изображения и текстови подсказки, позволявайки прецизни корекции и творчески трансформации.",
  "qwen-image.description": "Qwen-Image е универсален модел за генериране на изображения, поддържащ множество художествени стилове и силно рендиране на сложен текст, особено на китайски и английски. Поддържа многострочни оформления, текст на ниво абзац и фини детайли за сложни текстово-визуални оформления.",
  "qwen-long.description": "Изключително голям модел от Qwen с дълъг контекст и чат в сценарии с дълги и многодокументни взаимодействия.",
  "qwen-math-plus-latest.description": "Qwen Math е езиков модел, специализиран в решаване на математически задачи.",
  "qwen-math-plus.description": "Qwen Math е езиков модел, специализиран в решаване на математически задачи.",
  "qwen-math-turbo-latest.description": "Qwen Math е езиков модел, специализиран в решаване на математически задачи.",
  "qwen-math-turbo.description": "Qwen Math е езиков модел, специализиран в решаване на математически задачи.",
  "qwen-max.description": "Изключително голям модел от серията Qwen с мащаб от стотици милиарди параметри, поддържащ китайски, английски и други езици; API моделът зад текущите продукти Qwen2.5.",
  "qwen-omni-turbo.description": "Моделите Qwen-Omni поддържат мултимодални входове (видео, аудио, изображения, текст) и изходи в аудио и текстов формат.",
  "qwen-plus.description": "Подобрен изключително голям модел от серията Qwen, поддържащ китайски, английски и други езици.",
  "qwen-turbo.description": "Qwen Turbo вече няма да се актуализира; заменете го с Qwen Flash. Изключително голям модел от серията Qwen, поддържащ китайски, английски и други езици.",
  "qwen-vl-chat-v1.description": "Qwen VL поддържа гъвкави взаимодействия, включително вход от множество изображения, многозавойни въпроси и творчески задачи.",
  "qwen-vl-max-latest.description": "Изключително голям мултимодален модел от серията Qwen. В сравнение с подобрената версия, допълнително подобрява визуалното разсъждение и следването на инструкции за по-силно възприятие и когниция.",
  "qwen-vl-max.description": "Изключително голям мултимодален модел от серията Qwen. В сравнение с подобрената версия, допълнително подобрява визуалното разсъждение и следването на инструкции за по-силно визуално възприятие и когниция.",
  "qwen-vl-ocr.description": "Qwen OCR е модел за извличане на текст от документи, таблици, изображения от изпити и ръкописен текст. Поддържа китайски, английски, френски, японски, корейски, немски, руски, италиански, виетнамски и арабски.",
  "qwen-vl-plus-latest.description": "Подобрен голям мултимодален модел от серията Qwen с значителни подобрения в детайлите и разпознаването на текст, поддържащ резолюция над 1 мегапиксел и произволни съотношения.",
  "qwen-vl-plus.description": "Подобрен голям мултимодален модел от серията Qwen с значителни подобрения в детайлите и разпознаването на текст, поддържащ резолюция над 1 мегапиксел и произволни съотношения.",
  "qwen-vl-v1.description": "Предварително обучен модел, инициализиран от Qwen-7B с добавен визуален модул и вход за изображения с резолюция 448.",
  "qwen/qwen3-coder-plus.description": "Qwen3-Coder-Plus е модел от серията Qwen, оптимизиран за по-сложно използване на инструменти и дълготрайни сесии.",
  "qwen/qwen3-coder.description": "Qwen3-Coder е част от семейството за генериране на код Qwen3, силен в разбирането и създаването на код от дълги документи.",
  "qwen/qwen3-max-preview.description": "Qwen3 Max (преглед) е вариантът Max за напреднало разсъждение и интеграция с инструменти.",
  "qwen/qwen3-max.description": "Qwen3 Max е висококласният модел за разсъждение от серията Qwen3, предназначен за многоезично разсъждение и интеграция с инструменти.",
  "qwen/qwen3-vl-plus.description": "Qwen3 VL-Plus е подобрен визуален вариант на Qwen3 с усъвършенствано мултимодално разсъждение и обработка на видео.",
  "qwen2.5-14b-instruct-1m.description": "Qwen2.5 отворен код, модел с 72B параметъра.",
  "qwen2.5-14b-instruct.description": "Qwen2.5 отворен код, модел с 14B параметъра.",
  "qwen2.5-32b-instruct.description": "Qwen2.5 отворен код, модел с 32B параметъра.",
  "qwen2.5-72b-instruct.description": "Qwen2.5 отворен код, модел с 72B параметъра.",
  "qwen2.5-7b-instruct.description": "Qwen2.5 7B Instruct е зрял модел с отворен код за чат и генериране в различни сценарии.",
  "qwen2.5-coder-1.5b-instruct.description": "Модел за програмиране Qwen с отворен код.",
  "qwen2.5-coder-14b-instruct.description": "Модел за програмиране Qwen с отворен код.",
  "qwen2.5-coder-32b-instruct.description": "Модел за програмиране Qwen с отворен код.",
  "qwen2.5-coder-7b-instruct.description": "Модел за програмиране Qwen с отворен код.",
  "qwen2.5-coder-instruct.description": "Qwen2.5-Coder е най-новият модел, фокусиран върху програмиране, от семейството Qwen (преди CodeQwen).",
  "qwen2.5-instruct.description": "Qwen2.5 е най-новата серия LLM модели от Qwen, включваща базови и инструкторски модели от 0.5B до 72B параметъра.",
  "qwen2.5-math-1.5b-instruct.description": "Qwen-Math предлага силни способности за решаване на математически задачи.",
  "qwen2.5-math-72b-instruct.description": "Qwen-Math предлага силни способности за решаване на математически задачи.",
  "qwen2.5-math-7b-instruct.description": "Qwen-Math предлага силни способности за решаване на математически задачи.",
  "qwen2.5-omni-7b.description": "Моделите Qwen-Omni поддържат мултимодални входове (видео, аудио, изображения, текст) и извеждат аудио и текст.",
  "qwen2.5-vl-32b-instruct.description": "Qwen2.5 VL 32B Instruct е мултимодален модел с отворен код, подходящ за частно внедряване и използване в различни сценарии.",
  "qwen2.5-vl-72b-instruct.description": "Подобрен следване на инструкции, математика, решаване на задачи и програмиране, с по-силно разпознаване на обекти. Поддържа точно локализиране на визуални елементи във всички формати, разбиране на дълги видеа (до 10 минути) с прецизно времево маркиране, разбиране на последователност и скорост, както и агенти, които могат да управляват ОС или мобилни устройства чрез парсинг и локализация. Силен в извличането на ключова информация и изход в JSON формат. Това е най-мощната версия от серията с 72B параметъра.",
  "qwen2.5-vl-7b-instruct.description": "Qwen2.5 VL 7B Instruct е лек мултимодален модел, балансиращ между разходи за внедряване и способности за разпознаване.",
  "qwen2.5-vl-instruct.description": "Qwen2.5-VL е най-новият модел за визия и език от семейството Qwen.",
  "qwen2.5.description": "Qwen2.5 е следващото поколение голям езиков модел на Alibaba с висока производителност в различни приложения.",
  "qwen2.5:0.5b.description": "Qwen2.5 е следващото поколение голям езиков модел на Alibaba с висока производителност в различни приложения.",
  "qwen2.5:1.5b.description": "Qwen2.5 е следващото поколение голям езиков модел на Alibaba с висока производителност в различни приложения.",
  "qwen2.5:72b.description": "Qwen2.5 е следващото поколение голям езиков модел на Alibaba с висока производителност в различни приложения.",
  "qwen2.description": "Qwen2 е следващото поколение голям езиков модел на Alibaba с висока производителност в различни приложения.",
  "qwen2:0.5b.description": "Qwen2 е следващото поколение голям езиков модел на Alibaba с висока производителност в различни приложения.",
  "qwen2:1.5b.description": "Qwen2 е следващото поколение голям езиков модел на Alibaba с висока производителност в различни приложения.",
  "qwen2:72b.description": "Qwen2 е следващото поколение голям езиков модел на Alibaba с висока производителност в различни приложения.",
  "qwen3-0.6b.description": "Qwen3 0.6B е начален модел за базово разсъждение и силно ограничени среди.",
  "qwen3-1.7b.description": "Qwen3 1.7B е ултралек модел за внедряване на устройства и крайни точки.",
  "qwen3-14b.description": "Qwen3 14B е среден по размер модел за многоезични въпроси и отговори и генериране на текст.",
  "qwen3-235b-a22b-instruct-2507.description": "Qwen3 235B A22B Instruct 2507 е водещ модел с инструкции за широк спектър от задачи по генериране и разсъждение.",
  "qwen3-235b-a22b-thinking-2507.description": "Qwen3 235B A22B Thinking 2507 е ултраголям модел за дълбоко разсъждение.",
  "qwen3-30b-a3b-instruct-2507.description": "Qwen3 30B A3B Instruct 2507 е средно-голям модел с инструкции за висококачествено генериране и въпроси и отговори.",
  "qwen3-30b-a3b-thinking-2507.description": "Qwen3 30B A3B Thinking 2507 е средно-голям модел за разсъждение, балансиращ точност и разходи.",
  "qwen3-30b-a3b.description": "Qwen3 30B A3B е средно-голям универсален модел, балансиращ между цена и качество.",
  "qwen3-32b.description": "Qwen3 32B е подходящ за общи задачи, изискващи по-дълбоко разбиране.",
  "qwen3-4b.description": "Qwen3 4B е подходящ за малки до средни приложения и локално извеждане.",
  "qwen3-8b.description": "Qwen3 8B е лек модел с гъвкаво внедряване за натоварвания с висока едновременност.",
  "qwen3-coder-30b-a3b-instruct.description": "Модел за програмиране Qwen с отворен код. Най-новият qwen3-coder-30b-a3b-instruct е базиран на Qwen3 и предлага силни способности за програмиране чрез агенти, използване на инструменти и взаимодействие със среди за автономно програмиране, с отлично представяне при код и стабилни общи възможности.",
  "qwen3-coder-480b-a35b-instruct.description": "Qwen3 Coder 480B A35B Instruct е водещ модел за програмиране с поддръжка на много езици и разбиране на сложен код.",
  "qwen3-coder-flash.description": "Модел за програмиране Qwen. Най-новата серия Qwen3-Coder е базирана на Qwen3 и предлага силни способности за програмиране чрез агенти, използване на инструменти и взаимодействие със среди за автономно програмиране, с отлично представяне при код и стабилни общи възможности.",
  "qwen3-coder-plus.description": "Модел за програмиране Qwen. Най-новата серия Qwen3-Coder е базирана на Qwen3 и предлага силни способности за програмиране чрез агенти, използване на инструменти и взаимодействие със среди за автономно програмиране, с отлично представяне при код и стабилни общи възможности.",
  "qwen3-coder:480b.description": "Високопроизводителен модел на Alibaba с дълъг контекст за задачи с агенти и програмиране.",
  "qwen3-max-preview.description": "Най-добре представящият се модел Qwen за сложни, многоетапни задачи. Прегледната версия поддържа разсъждение.",
  "qwen3-max.description": "Моделите Qwen3 Max предлагат значителни подобрения спрямо серията 2.5 в общите способности, разбиране на китайски/английски, следване на сложни инструкции, субективни отворени задачи, многоезичност и използване на инструменти, с по-малко халюцинации. Най-новият qwen3-max подобрява програмирането чрез агенти и използването на инструменти спрямо qwen3-max-preview. Тази версия достига водещи резултати в индустрията и е насочена към по-сложни нужди на агентите.",
  "stable-diffusion-3.5-large.description": "stable-diffusion-3.5-large е текст-към-изображение модел MMDiT с 800 милиона параметъра, предлагащ отлично качество и съответствие с подадените инструкции, поддържащ изображения с резолюция 1 мегапиксел и ефективна работа на потребителски хардуер.",
  "stable-diffusion-v1.5.description": "stable-diffusion-v1.5 е инициализиран от контролна точка v1.2 и фино настроен за 595 хиляди стъпки върху „laion-aesthetics v2 5+“ при резолюция 512x512, като намалява влиянието на текстовото условие с 10% за подобрено семплиране без класификатор.",
  "stable-diffusion-xl-base-1.0.description": "Модел с отворен код за генериране на изображения от текст от Stability AI, предлагащ водещо в индустрията творческо качество. Притежава силно разбиране на инструкции и поддържа обратни дефиниции на подканите за прецизно генериране.",
  "stable-diffusion-xl.description": "stable-diffusion-xl предлага значителни подобрения спрямо v1.5 и съответства на водещите отворени модели за генериране на изображения от текст. Подобренията включват 3 пъти по-голям UNet гръбнак, модул за прецизиране за по-добро качество на изображенията и по-ефективни техники на обучение.",
  "step-1-128k.description": "Баланс между производителност и разходи за общи сценарии.",
  "step-1-256k.description": "Обработка на изключително дълъг контекст, идеална за анализ на дълги документи.",
  "step-1-32k.description": "Поддържа разговори със средна дължина за широк спектър от приложения.",
  "step-1-8k.description": "Малък модел, подходящ за леки задачи.",
  "step-1-flash.description": "Модел с висока скорост, подходящ за чат в реално време.",
  "step-1.5v-mini.description": "Силни възможности за разбиране на видео съдържание.",
  "step-1o-turbo-vision.description": "Силно визуално разбиране, надминаващо 1o в математика и програмиране. По-малък от 1o с по-бърз изход.",
  "step-1o-vision-32k.description": "Силно визуално разбиране с по-добра визуална производителност от серията Step-1V.",
  "step-1v-32k.description": "Поддържа визуални входове за по-богато мултимодално взаимодействие.",
  "step-1v-8k.description": "Малък визуален модел за основни задачи с изображения и текст.",
  "step-1x-edit.description": "Този модел е фокусиран върху редактиране на изображения, модифицирайки и подобрявайки изображения въз основа на предоставени от потребителя изображения и текст. Поддържа множество входни формати, включително текстови описания и примерни изображения, и генерира редакции, съответстващи на намеренията на потребителя.",
  "step-1x-medium.description": "Този модел предлага силно генериране на изображения от текстови подканва. С вградена поддръжка на китайски език, той по-добре разбира китайски описания, улавя тяхната семантика и ги преобразува във визуални характеристики за по-точно генериране. Създава изображения с висока резолюция и качество и поддържа известна степен на трансфер на стил.",
  "step-2-16k-exp.description": "Експериментална версия на Step-2 с най-нови функции и текущи актуализации. Не се препоръчва за продукционна употреба.",
  "step-2-16k.description": "Поддържа взаимодействия с голям контекст за сложни диалози.",
  "step-2-mini.description": "Изграден върху следващото поколение вътрешна архитектура MFA attention, предоставяйки резултати, подобни на Step-1, при значително по-ниска цена, с по-висока пропускателна способност и по-бърза латентност. Обработва общи задачи със силни способности за програмиране.",
  "step-2x-large.description": "Модел от ново поколение StepFun за генериране на изображения, създаващ висококачествени изображения от текстови подканва. Осигурява по-реалистична текстура и по-добро визуализиране на китайски/английски текст.",
  "step-3.description": "Този модел притежава силно визуално възприятие и сложна логика, точно обработва междудомейново знание, анализ между математика и визия и широк спектър от ежедневни визуални задачи.",
  "step-r1-v-mini.description": "Модел за логическо разсъждение със силно визуално разбиране, който може да обработва изображения и текст, след което да генерира текст след дълбоко разсъждение. Отличава се във визуално разсъждение и предоставя водещи резултати в математика, програмиране и текстово разсъждение, с контекстен прозорец от 100K.",
  "stepfun-ai/step3.description": "Step3 е авангарден мултимодален модел за разсъждение от StepFun, изграден върху MoE архитектура с общо 321B и 38B активни параметъра. Дизайнът от край до край минимизира разходите за декодиране, като същевременно осигурява водещо разсъждение между визия и език. С MFA и AFD дизайн, остава ефективен както на флагмански, така и на нискобюджетни ускорители. Предобучен с над 20T текстови токени и 4T токени от изображения и текст на множество езици. Постига водеща производителност сред отворените модели в математика, код и мултимодални бенчмаркове.",
  "taichu_llm.description": "Обучен върху масивни висококачествени данни, с по-силно разбиране на текст, създаване на съдържание и разговорно въпроси-отговори.",
  "taichu_o1.description": "taichu_o1 е модел от ново поколение за разсъждение, използващ мултимодално взаимодействие и обучение чрез подсилване за постигане на човешкоподобна верига на мисълта, поддържащ симулация на сложни решения и разкриващ логически пътища, като същевременно поддържа висока точност – подходящ за стратегически анализ и дълбоко мислене.",
  "taichu_vl.description": "Комбинира визуално разбиране, трансфер на знания и логическа атрибуция, отличавайки се в задачи с въпроси и отговори между изображения и текст.",
  "tencent/Hunyuan-A13B-Instruct.description": "Hunyuan-A13B-Instruct използва общо 80B параметъра с 13B активни, за да съответства на по-големи модели. Поддържа хибридно бързо/бавнопотоцово разсъждение, стабилно разбиране на дълги текстове и водещи способности на агенти в BFCL-v3 и τ-Bench. GQA и мулти-квантови формати позволяват ефективно извеждане.",
  "tencent/Hunyuan-MT-7B.description": "Моделът за превод Hunyuan включва Hunyuan-MT-7B и ансамбъла Hunyuan-MT-Chimera. Hunyuan-MT-7B е лек модел с 7B параметъра, поддържащ 33 езика плюс 5 китайски малцинствени езика. В WMT25 заема първо място в 30 от 31 езикови двойки. Tencent Hunyuan използва пълен тренировъчен процес от предобучение до SFT, превод чрез RL и ансамблово RL, постигайки водеща производителност за своя размер с ефективно и лесно внедряване.",
  "text-embedding-3-large.description": "Най-способният модел за вграждане за задачи на английски и други езици.",
  "text-embedding-3-small.description": "Ефективен, икономичен модел от ново поколение за вграждане, подходящ за извличане и RAG сценарии.",
  "thudm/glm-4-32b.description": "GLM-4-32B-0414 е двуезичен (китайски/английски) модел с отворени тегла и 32B параметъра, оптимизиран за генериране на код, извикване на функции и агентни задачи. Предобучен върху 15T висококачествени и логически наситени данни и допълнително усъвършенстван чрез подравняване с човешки предпочитания, отхвърляне на проби и RL. Отличава се в сложно разсъждение, генериране на артефакти и структурирани изходи, достигайки нивото на GPT-4o и DeepSeek-V3-0324 в множество бенчмаркове.",
  "thudm/glm-4-32b:free.description": "GLM-4-32B-0414 е двуезичен (китайски/английски) модел с отворени тегла и 32B параметъра, оптимизиран за генериране на код, извикване на функции и агентни задачи. Предобучен върху 15T висококачествени и логически наситени данни и допълнително усъвършенстван чрез подравняване с човешки предпочитания, отхвърляне на проби и RL. Отличава се в сложно разсъждение, генериране на артефакти и структурирани изходи, достигайки нивото на GPT-4o и DeepSeek-V3-0324 в множество бенчмаркове.",
  "thudm/glm-4-9b-chat.description": "Отворената версия на най-новия предобучен модел GLM-4 от Zhipu AI.",
  "thudm/glm-z1-32b.description": "GLM-Z1-32B-0414 е подобрен вариант на GLM-4-32B, създаден за дълбоко математическо, логическо и кодово разсъждение. Използва разширено RL (специфично за задачи и общо предпочитание по двойки), за да подобри сложни многоетапни задачи. В сравнение с GLM-4-32B, Z1 значително подобрява структурираното разсъждение и способностите в формални домейни.\n\nПоддържа принудително „мислене“ чрез инженеринг на подканите, подобрена кохерентност за дълги изходи и е оптимизиран за агентни работни потоци с дълъг контекст (чрез YaRN), извикване на JSON инструменти и фино семплиране за стабилно разсъждение. Идеален за случаи, изискващи внимателни многоетапни или формални изводи.",
  "xai/grok-3-mini-fast.description": "Лек модел на xAI, който обмисля преди да отговори – идеален за прости или логически задачи без необходимост от задълбочени познания в конкретна област. Налични са сурови следи от разсъждения. Бързият вариант работи върху по-бърза инфраструктура за значително по-бързи отговори, но с по-висока цена на токен.",
  "xai/grok-3-mini.description": "Лек модел на xAI, който обмисля преди да отговори – идеален за прости или логически задачи без необходимост от задълбочени познания в конкретна област. Налични са сурови следи от разсъждения.",
  "xai/grok-3.description": "Флагманският модел на xAI се отличава в корпоративни приложения като извличане на данни, програмиране и обобщаване, с дълбоки познания в области като финанси, здравеопазване, право и наука.",
  "xai/grok-4.description": "Най-новият флагмански модел на xAI с ненадмината производителност в естествен език, математика и разсъждение – идеален универсален модел.",
  "yi-large-fc.description": "Изграден върху yi-large с подобрено извикване на инструменти, подходящ за агенти и работни потоци.",
  "yi-large-preview.description": "Ранна версия; препоръчва се използването на по-новия yi-large.",
  "yi-large-rag.description": "Разширена услуга, базирана на yi-large, която комбинира извличане и генериране за прецизни отговори с търсене в реално време в интернет.",
  "yi-large-turbo.description": "Изключителна стойност и производителност, настроен за силен баланс между качество, скорост и цена.",
  "yi-large.description": "Нов модел със 100 милиарда параметъра с отлични възможности за въпроси и отговори и генериране на текст.",
  "yi-lightning-lite.description": "Олекотена версия; препоръчва се използването на yi-lightning.",
  "yi-lightning.description": "Най-нов високопроизводителен модел с по-бързо извеждане и висококачествени резултати.",
  "yi-medium-200k.description": "Модел с дълъг контекст от 200K, предназначен за дълбоко разбиране и генериране на дълги текстове.",
  "yi-medium.description": "Настроен модел със среден размер с балансирани възможности и стойност, оптимизиран за следване на инструкции.",
  "yi-spark.description": "Компактен и бърз модел с подсилени възможности в математика и програмиране.",
  "yi-vision-v2.description": "Визуален модел за сложни задачи със силно разбиране и анализ на множество изображения.",
  "yi-vision.description": "Визуален модел за сложни задачи със силно разбиране и анализ на изображения.",
  "z-ai/glm-4.5-air.description": "GLM 4.5 Air е олекотен вариант на GLM 4.5 за сценарии, чувствителни към разходи, като същевременно запазва силни способности за разсъждение.",
  "z-ai/glm-4.5.description": "GLM 4.5 е флагманският модел на Z.AI с хибридно разсъждение, оптимизиран за инженерни и задачи с дълъг контекст.",
  "z-ai/glm-4.6.description": "GLM 4.6 е флагманският модел на Z.AI с разширен контекст и подобрени възможности за програмиране.",
  "zai-org/GLM-4.5-Air.description": "GLM-4.5-Air е базов модел за агентни приложения с архитектура Mixture-of-Experts. Оптимизиран е за използване на инструменти, уеб браузване, софтуерно инженерство и фронтенд програмиране, и се интегрира с кодови агенти като Claude Code и Roo Code. Използва хибридно разсъждение за справяне както със сложни, така и с ежедневни задачи.",
  "zai-org/GLM-4.5.description": "GLM-4.5 е базов модел, създаден за агентни приложения с архитектура Mixture-of-Experts. Дълбоко оптимизиран за използване на инструменти, уеб браузване, софтуерно инженерство и фронтенд програмиране, и се интегрира с кодови агенти като Claude Code и Roo Code. Използва хибридно разсъждение за справяне както със сложни, така и с ежедневни задачи.",
  "zai-org/GLM-4.5V.description": "GLM-4.5V е най-новият визуален езиков модел (VLM) на Zhipu AI, изграден върху флагманския текстов модел GLM-4.5-Air (106B общо, 12B активни) с MoE архитектура за висока производителност при по-ниска цена. Следва пътя на GLM-4.1V-Thinking и добавя 3D-RoPE за подобрено пространствено разсъждение в 3D. Оптимизиран чрез предварително обучение, SFT и RL, обработва изображения, видео и дълги документи и е сред водещите отворени модели в 41 публични мултимодални бенчмарка. Режимът Thinking позволява на потребителите да балансират между скорост и дълбочина.",
  "zai-org/GLM-4.6.description": "В сравнение с GLM-4.5, GLM-4.6 разширява контекста от 128K до 200K за по-сложни агентни задачи. Постига по-високи резултати в кодови бенчмаркове и показва по-добра реална производителност в приложения като Claude Code, Cline, Roo Code и Kilo Code, включително по-добро генериране на фронтенд страници. Разсъждението е подобрено и се поддържа използване на инструменти по време на разсъждение, което засилва цялостните възможности. По-добре се интегрира в агентни рамки, подобрява инструментите/търсещите агенти и има по-предпочитан от хора стил на писане и естественост в ролевите сценарии.",
  "zai/glm-4.5-air.description": "GLM-4.5 и GLM-4.5-Air са най-новите ни флагмани за агентни приложения, и двата използват MoE. GLM-4.5 има 355B общо и 32B активни параметри на стъпка; GLM-4.5-Air е по-лек с 106B общо и 12B активни.",
  "zai/glm-4.5.description": "Серията GLM-4.5 е проектирана за агенти. Флагманският GLM-4.5 комбинира разсъждение, програмиране и агентни умения с 355B общи параметри (32B активни) и предлага два режима на работа като хибридна система за разсъждение.",
  "zai/glm-4.5v.description": "GLM-4.5V надгражда GLM-4.5-Air, наследявайки доказани техники от GLM-4.1V-Thinking и мащабира с мощна MoE архитектура с 106 милиарда параметъра.",
  "zenmux/auto.description": "ZenMux автоматично избира най-добрия модел по стойност и производителност от поддържаните опции според вашата заявка."
}
