{
  "01-ai/yi-1.5-34b-chat.description": "Най-новият отворен модел на 01.AI с фино настройване и 34 милиарда параметъра, поддържащ множество сценарии за диалог, обучен с висококачествени данни и съобразен с човешките предпочитания.",
  "01-ai/yi-1.5-9b-chat.description": "Най-новият отворен модел на 01.AI с фино настройване и 9 милиарда параметъра, поддържащ множество сценарии за диалог, обучен с висококачествени данни и съобразен с човешките предпочитания.",
  "360/deepseek-r1.description": "DeepSeek-R1, внедрен от 360, използва мащабно подсилващо обучение в етапа след предварителното обучение, значително подобрявайки логическото мислене с минимално количество етикетирани данни. Сравнява се с OpenAI o1 при задачи по математика, програмиране и езиково разсъждение.",
  "360gpt-pro-trans.description": "Модел, специализиран в превод, дълбоко фино настроен за водещо качество на превода.",
  "360gpt-pro.description": "360GPT Pro е основен AI модел на 360 с ефективна обработка на текст за разнообразни NLP сценарии, поддържащ разбиране на дълги текстове и многократен диалог.",
  "360gpt-turbo-responsibility-8k.description": "360GPT Turbo Responsibility 8K поставя акцент върху семантичната безопасност и отговорността при чувствително съдържание, осигурявайки точни и надеждни потребителски преживявания.",
  "360gpt-turbo.description": "360GPT Turbo предлага мощни изчислителни и диалогови възможности с отлично семантично разбиране и ефективност на генериране, идеален за предприятия и разработчици.",
  "360gpt2-o1.description": "360gpt2-o1 изгражда верига на мисълта чрез дървовидно търсене с механизъм за рефлексия и обучение чрез подсилване, позволявайки саморефлексия и самокорекция.",
  "360gpt2-pro.description": "360GPT2 Pro е усъвършенстван NLP модел от 360 с отлични възможности за генериране и разбиране на текст, особено при творчески задачи, справяйки се със сложни трансформации и ролеви игри.",
  "360zhinao2-o1.description": "360zhinao2-o1 изгражда верига на мисълта чрез дървовидно търсене с механизъм за рефлексия и обучение чрез подсилване, позволявайки саморефлексия и самокорекция.",
  "4.0Ultra.description": "Spark Ultra е най-мощният модел от серията Spark, подобряващ разбирането и обобщаването на текст, както и уеб търсенето. Това е цялостно решение за повишаване на продуктивността на работното място и точността на отговорите, позиционирайки го като водещ интелигентен продукт.",
  "AnimeSharp.description": "AnimeSharp (известен още като \"4x-AnimeSharp\") е отворен модел за супер-резолюция, базиран на ESRGAN от Kim2091, фокусиран върху увеличаване и изостряне на изображения в аниме стил. Преименуван е от \"4x-TextSharpV1\" през февруари 2022 г., първоначално предназначен и за текстови изображения, но силно оптимизиран за аниме съдържание.",
  "Baichuan2-Turbo.description": "Използва разширение чрез търсене, за да свърже модела с домейн и уеб знания. Поддържа качване на PDF/Word файлове и въвеждане на URL адреси за навременно, цялостно извличане и професионални, точни резултати.",
  "Baichuan3-Turbo-128k.description": "С ултра-дълъг контекст от 128K, оптимизиран за чести бизнес сценарии с големи подобрения и висока стойност. В сравнение с Baichuan2, създаването на съдържание се подобрява с 20%, въпросите и отговорите с 17%, а ролевите игри с 40%. Общата производителност надвишава тази на GPT-3.5.",
  "Baichuan3-Turbo.description": "Оптимизиран за чести бизнес сценарии с големи подобрения и висока стойност. В сравнение с Baichuan2, създаването на съдържание се подобрява с 20%, въпросите и отговорите с 17%, а ролевите игри с 40%. Общата производителност надвишава тази на GPT-3.5.",
  "Baichuan4-Air.description": "Водещ модел в Китай, надминаващ основни чуждестранни модели при китайски задачи като знания, дълги текстове и творческо генериране. Също така предлага водещи в индустрията мултимодални възможности с отлични резултати на авторитетни бенчмаркове.",
  "Baichuan4-Turbo.description": "Водещ модел в Китай, надминаващ основни чуждестранни модели при китайски задачи като знания, дълги текстове и творческо генериране. Също така предлага водещи в индустрията мултимодални възможности с отлични резултати на авторитетни бенчмаркове.",
  "Baichuan4.description": "Водещо вътрешно представяне, надминаващо водещи чуждестранни модели при китайски задачи като енциклопедични знания, дълги текстове и творческо генериране. Също така предлага водещи в индустрията мултимодални възможности и силни резултати на бенчмаркове.",
  "ByteDance-Seed/Seed-OSS-36B-Instruct.description": "Seed-OSS е семейство от отворени LLM модели от ByteDance Seed, проектирани за силна обработка на дълъг контекст, логическо мислене, агентни и общи способности. Seed-OSS-36B-Instruct е 36B модел, настроен за инструкции, с вграден ултра-дълъг контекст за обработка на големи документи или кодови бази. Оптимизиран е за логическо мислене, генериране на код и агентни задачи (използване на инструменти), като същевременно запазва силни общи способности. Ключова характеристика е \"Бюджет за мислене\", позволяващ гъвкава дължина на разсъждение за подобрена ефективност.",
  "DeepSeek-R1-Distill-Llama-70B.description": "DeepSeek R1, по-големият и по-интелигентен модел от серията DeepSeek, е дистилиран в архитектурата Llama 70B. Бенчмаркове и човешки оценки показват, че е по-умен от базовия Llama 70B, особено при задачи по математика и точност на фактите.",
  "DeepSeek-R1-Distill-Qwen-1.5B.description": "Дистилиран модел DeepSeek-R1, базиран на Qwen2.5-Math-1.5B. Подсилващо обучение и cold-start данни оптимизират логическата производителност, поставяйки нови мултизадачни бенчмаркове за отворени модели.",
  "DeepSeek-R1-Distill-Qwen-14B.description": "Моделите DeepSeek-R1-Distill са фино настроени от отворени модели с помощта на примерни данни, генерирани от DeepSeek-R1.",
  "DeepSeek-R1-Distill-Qwen-32B.description": "Моделите DeepSeek-R1-Distill са фино настроени от отворени модели с помощта на примерни данни, генерирани от DeepSeek-R1.",
  "DeepSeek-R1-Distill-Qwen-7B.description": "Дистилиран модел DeepSeek-R1, базиран на Qwen2.5-Math-7B. Подсилващо обучение и cold-start данни оптимизират логическата производителност, поставяйки нови мултизадачни бенчмаркове за отворени модели.",
  "DeepSeek-R1.description": "DeepSeek-R1 прилага мащабно подсилващо обучение в етапа след предварителното обучение, значително подобрявайки логическото мислене с много малко етикетирани данни. Сравнява се с продукционния модел OpenAI o1 при задачи по математика, програмиране и езиково разсъждение.",
  "DeepSeek-V3-1.description": "DeepSeek V3.1 е следващо поколение модел за логическо мислене с подобрено сложно разсъждение и верига на мисълта, подходящ за задачи с дълбок анализ.",
  "DeepSeek-V3-Fast.description": "Доставчик: sophnet. DeepSeek V3 Fast е високоскоростната версия на DeepSeek V3 0324, с пълна прецизност (без квантизация), по-силен при програмиране и математика и по-бързи отговори.",
  "DeepSeek-V3.1-Fast.description": "DeepSeek V3.1 Fast е високоскоростният вариант на DeepSeek V3.1. Хибриден режим на мислене: чрез шаблони за чат, един модел поддържа както мислещ, така и немислещ режим. По-умно използване на инструменти: оптимизации след обучение подобряват производителността при задачи с инструменти и агенти.",
  "DeepSeek-V3.1-Think.description": "Режим на мислене на DeepSeek-V3.1: нов хибриден модел за разсъждение с мислещ и немислещ режим, по-ефективен от DeepSeek-R1-0528. Оптимизациите след обучение значително подобряват използването на инструменти от агенти и производителността при агентни задачи.",
  "DeepSeek-V3.description": "DeepSeek-V3 е MoE модел, разработен от DeepSeek. Надминава други отворени модели като Qwen2.5-72B и Llama-3.1-405B в много бенчмаркове и е конкурентен с водещи затворени модели като GPT-4o и Claude 3.5 Sonnet.",
  "Doubao-lite-128k.description": "Doubao-lite предлага изключително бързи отговори и по-добра стойност, с гъвкави опции за различни сценарии. Поддържа 128K контекст за извеждане и фина настройка.",
  "Doubao-lite-32k.description": "Doubao-lite предлага изключително бързи отговори и по-добра стойност, с гъвкави опции за различни сценарии. Поддържа 32K контекст за извеждане и фина настройка.",
  "Doubao-lite-4k.description": "Doubao-lite предлага изключително бързи отговори и по-добра стойност, с гъвкави опции за различни сценарии. Поддържа 4K контекст за извеждане и фина настройка.",
  "Doubao-pro-128k.description": "Водещ флагмански модел с най-добра производителност за сложни задачи, отличен в отговори с препратки, обобщения, създаване на съдържание, класификация и ролеви игри. Поддържа 128K контекст за извеждане и фина настройка.",
  "Doubao-pro-32k.description": "Водещ флагмански модел с най-добра производителност за сложни задачи, отличен в отговори с препратки, обобщения, създаване на съдържание, класификация и ролеви игри. Поддържа 32K контекст за извеждане и фина настройка.",
  "Doubao-pro-4k.description": "Водещ флагмански модел с най-добра производителност за сложни задачи, отличен в отговори с препратки, обобщения, създаване на съдържание, класификация и ролеви игри. Поддържа 4K контекст за извеждане и фина настройка.",
  "DreamO.description": "DreamO е модел с отворен код за персонализирано генериране на изображения, разработен съвместно от ByteDance и Пекинския университет. Използва унифицирана архитектура за поддръжка на многозадачно генериране на изображения. Прилага ефективно композиционно моделиране за създаване на висококачествени, персонализирани изображения въз основа на зададени от потребителя характеристики като идентичност, обект, стил, фон и други условия.",
  "ERNIE-3.5-128K.description": "Флагмански LLM модел на Baidu, обучен върху мащабни китайски и английски корпуси, с отлични общи способности за чат, създаване на съдържание и използване на плъгини. Поддържа автоматична интеграция с Baidu Search плъгин за предоставяне на актуални отговори.",
  "ERNIE-3.5-8K-Preview.description": "Флагмански LLM модел на Baidu, обучен върху мащабни китайски и английски корпуси, с отлични общи способности за чат, създаване на съдържание и използване на плъгини. Поддържа автоматична интеграция с Baidu Search плъгин за предоставяне на актуални отговори.",
  "ERNIE-3.5-8K.description": "Флагмански LLM модел на Baidu, обучен върху мащабни китайски и английски корпуси, с отлични общи способности за чат, създаване на съдържание и използване на плъгини. Поддържа автоматична интеграция с Baidu Search плъгин за предоставяне на актуални отговори.",
  "ERNIE-4.0-8K-Latest.description": "Флагмански ултра-голям LLM модел на Baidu с цялостни подобрения спрямо ERNIE 3.5, подходящ за сложни задачи в различни области. Поддържа интеграция с Baidu Search плъгин за предоставяне на актуални отговори.",
  "ERNIE-4.0-8K-Preview.description": "Флагмански ултра-голям LLM модел на Baidu с цялостни подобрения спрямо ERNIE 3.5, подходящ за сложни задачи в различни области. Поддържа интеграция с Baidu Search плъгин за предоставяне на актуални отговори.",
  "ERNIE-4.0-Turbo-8K-Latest.description": "Флагмански ултра-голям LLM модел на Baidu с отлична цялостна производителност за сложни задачи и интеграция с Baidu Search плъгин за предоставяне на актуални отговори. Надминава ERNIE 4.0.",
  "ERNIE-4.0-Turbo-8K-Preview.description": "Флагмански ултра-голям LLM модел на Baidu с отлична цялостна производителност за сложни задачи и интеграция с Baidu Search плъгин за предоставяне на актуални отговори. Надминава ERNIE 4.0.",
  "ERNIE-Character-8K.description": "Вертикално-ориентиран LLM модел на Baidu за игрови NPC, клиентско обслужване и ролеви игри, с по-ясна консистентност на персонажа, по-добро следване на инструкции и по-силно логическо мислене.",
  "ERNIE-Lite-Pro-128K.description": "Олекотен LLM модел на Baidu, балансиращ между качество и производителност при извеждане, по-добър от ERNIE Lite и подходящ за устройства с ограничени ресурси.",
  "ERNIE-Speed-128K.description": "Най-новият високопроизводителен LLM модел на Baidu (2024), с отлични общи способности, подходящ за фина настройка за специфични сценарии и с изключителна логическа производителност.",
  "ERNIE-Speed-Pro-128K.description": "Най-новият високопроизводителен LLM модел на Baidu (2024), с отлични общи способности, по-добър от ERNIE Speed, подходящ за фина настройка и с изключителна логическа производителност.",
  "FLUX-1.1-pro.description": "FLUX.1.1 Pro",
  "FLUX.1-Kontext-dev.description": "FLUX.1-Kontext-dev е мултимодален модел за генериране и редактиране на изображения от Black Forest Labs, базиран на архитектура Rectified Flow Transformer с 12B параметъра. Фокусира се върху генериране, реконструкция, подобрение и редакция на изображения според зададен контекст. Комбинира контролираната генерация на дифузионни модели с контекстното моделиране на Transformer, поддържайки висококачествени резултати за задачи като inpainting, outpainting и реконструкция на визуални сцени.",
  "FLUX.1-Kontext-pro.description": "FLUX.1 Kontext [pro]",
  "FLUX.1-dev.description": "FLUX.1-dev е мултимодален езиков модел с отворен код (MLLM) от Black Forest Labs, оптимизиран за задачи с изображения и текст, комбиниращ разбиране и генериране на изображения/текст. Изграден върху напреднали LLM модели (като Mistral-7B), използва внимателно проектиран визуален енкодер и многоетапна настройка с инструкции за постигане на мултимодална координация и логическо мислене при сложни задачи.",
  "Gryphe/MythoMax-L2-13b.description": "MythoMax-L2 (13B) е иновативен модел за разнообразни области и сложни задачи.",
  "HelloMeme.description": "HelloMeme е AI инструмент, който генерира мемета, GIF-ове или кратки видеа от предоставени изображения или движения. Не изисква умения за рисуване или програмиране — само референтно изображение — за създаване на забавно, атрактивно и стилово консистентно съдържание.",
  "HiDream-I1-Full.description": "HiDream-E1-Full е мултимодален модел за редактиране на изображения с отворен код от HiDream.ai, базиран на напреднала архитектура Diffusion Transformer и силно езиково разбиране (вграден LLaMA 3.1-8B-Instruct). Поддържа генериране на изображения чрез естествен език, трансфер на стил, локални редакции и прерисуване, с отлично разбиране и изпълнение на връзката между изображение и текст.",
  "HunyuanDiT-v1.2-Diffusers-Distilled.description": "hunyuandit-v1.2-distilled е олекотен модел за преобразуване на текст в изображение, оптимизиран чрез дистилация за бързо генериране на висококачествени изображения, особено подходящ за среди с ограничени ресурси и реално време.",
  "InstantCharacter.description": "InstantCharacter е модел за персонализирано генериране на персонажи без нужда от настройка, пуснат от Tencent AI през 2025 г., насочен към висок реализъм и консистентност на персонажа в различни сценарии. Може да моделира персонаж от едно референтно изображение и гъвкаво да го прехвърля между стилове, действия и фонове.",
  "InternVL2-8B.description": "InternVL2-8B е мощен модел за визия и език, поддържащ мултимодална обработка на изображения и текст, с точно разпознаване на съдържание и генериране на съответни описания или отговори.",
  "InternVL2.5-26B.description": "InternVL2.5-26B е мощен модел за визия и език, поддържащ мултимодална обработка на изображения и текст, с точно разпознаване на съдържание и генериране на съответни описания или отговори.",
  "Kolors.description": "Kolors е модел за преобразуване на текст в изображение, разработен от екипа на Kuaishou Kolors. Обучен с милиарди параметри, той има значителни предимства във визуалното качество, разбиране на китайски семантики и визуализиране на текст.",
  "Kwai-Kolors/Kolors.description": "Kolors е мащабен латентен дифузионен модел за преобразуване на текст в изображение от екипа на Kuaishou Kolors. Обучен върху милиарди двойки текст-изображение, той се отличава с високо визуално качество, точност при сложни семантики и визуализиране на китайски/английски текст, с отлично разбиране и генериране на китайско съдържание.",
  "Kwaipilot/KAT-Dev.description": "KAT-Dev (32B) е модел с отворен код за задачи в софтуерното инженерство. Постига 62.4% успеваемост в SWE-Bench Verified, класирайки се на 5-то място сред отворените модели. Оптимизиран чрез междинно обучение, SFT и RL за допълване на код, отстраняване на грешки и преглед на код.",
  "Llama-3.2-11B-Vision-Instruct.description": "Силен визуален анализ на изображения с висока резолюция, подходящ за приложения за визуално разбиране.",
  "Llama-3.2-90B-Vision-Instruct\t.description": "Разширено визуално разсъждение за приложения с агенти за визуално разбиране.",
  "Meta-Llama-3-3-70B-Instruct.description": "Llama 3.3 70B е универсален трансформерен модел за чат и генериране на текст.",
  "Meta-Llama-3.1-405B-Instruct.description": "Llama 3.1 е текстов модел, обучен с инструкции, оптимизиран за многоезичен чат, с отлични резултати на водещи индустриални бенчмаркове сред отворени и затворени модели.",
  "Meta-Llama-3.1-70B-Instruct.description": "Llama 3.1 е текстов модел, обучен с инструкции, оптимизиран за многоезичен чат, с отлични резултати на водещи индустриални бенчмаркове сред отворени и затворени модели.",
  "Meta-Llama-3.1-8B-Instruct.description": "Llama 3.1 е текстов модел, обучен с инструкции, оптимизиран за многоезичен чат, с отлични резултати на водещи индустриални бенчмаркове сред отворени и затворени модели.",
  "Meta-Llama-3.2-1B-Instruct.description": "Модерен малък езиков модел с отлично езиково разбиране, логическо мислене и генериране на текст.",
  "Meta-Llama-3.2-3B-Instruct.description": "Модерен малък езиков модел с отлично езиково разбиране, логическо мислене и генериране на текст.",
  "Meta-Llama-3.3-70B-Instruct.description": "Llama 3.3 е най-усъвършенстваният многоезичен отворен модел от серията Llama, предлагащ производителност, близка до 405B, на много по-ниска цена. Базиран е на трансформерна архитектура и подобрен чрез SFT и RLHF за полезност и безопасност. Версията, обучена с инструкции, е оптимизирана за многоезичен чат и надминава много отворени и затворени модели на индустриални бенчмаркове. Граница на знанието: декември 2023 г.",
  "Meta-Llama-4-Maverick-17B-128E-Instruct-FP8.description": "Llama 4 Maverick е голям MoE модел с ефективна активация на експерти за силна логическа производителност.",
  "MiniMax-M1.description": "Нов вътрешен модел за разсъждение с 80K верига на мисълта и 1M вход, предлагащ производителност, сравнима с водещите глобални модели.",
  "MiniMax-M2-Stable.description": "Създаден за ефективно програмиране и агентски работни потоци, с по-висока едновременност за търговска употреба.",
  "MiniMax-M2.1-Lightning.description": "Мощни многоезични програмни възможности за цялостно подобрено програмиране. По-бързо, по-ефективно.",
  "MiniMax-M2.1.description": "Мощни многоезични програмни възможности за цялостно подобрено програмиране",
  "MiniMax-M2.description": "Създаден за ефективно кодиране и агентски работни потоци",
  "MiniMax-Text-01.description": "MiniMax-01 въвежда мащабно линейно внимание отвъд класическите трансформери, с 456B параметри и 45.9B активирани на преминаване. Постига водеща производителност и поддържа до 4M токена контекст (32× GPT-4o, 20× Claude-3.5-Sonnet).",
  "MiniMaxAI/MiniMax-M1-80k.description": "MiniMax-M1 е отворен модел с голям мащаб и хибридно внимание, с общо 456B параметри и ~45.9B активни на токен. Поддържа нативно 1M контекст и използва Flash Attention за 75% по-малко FLOPs при генериране на 100K токена спрямо DeepSeek R1. С MoE архитектура, CISPO и хибридно обучение с внимание и RL, постига водеща производителност при дълги входове и реални задачи по софтуерно инженерство.",
  "MiniMaxAI/MiniMax-M2.description": "MiniMax-M2 преосмисля ефективността на агентите. Това е компактен, бърз и икономичен MoE модел с 230B общо и 10B активни параметри, създаден за водещи задачи по програмиране и агенти, като същевременно запазва силен общ интелект. Със само 10B активни параметри, съперничи на много по-големи модели, което го прави идеален за приложения с висока ефективност.",
  "Moonshot-Kimi-K2-Instruct.description": "1T общи параметри с 32B активни. Сред немислещите модели е водещ в гранични знания, математика и програмиране, и по-силен в общи агентски задачи. Оптимизиран за агентски натоварвания, може да предприема действия, а не само да отговаря на въпроси. Най-подходящ за импровизационен, общ чат и агентски преживявания като модел на рефлексно ниво без дълго мислене.",
  "NousResearch/Nous-Hermes-2-Mixtral-8x7B-DPO.description": "Nous Hermes 2 - Mixtral 8x7B-DPO (46.7B) е високоточен модел с инструкции за сложни изчисления.",
  "OmniConsistency.description": "OmniConsistency подобрява стиловата последователност и обобщението при задачи от изображение към изображение чрез въвеждане на мащабни дифузионни трансформери (DiTs) и сдвоени стилизирани данни, избягвайки влошаване на стила.",
  "Phi-3-medium-128k-instruct.description": "Същият модел Phi-3-medium с по-голям контекстен прозорец за RAG или few-shot подканвания.",
  "Phi-3-medium-4k-instruct.description": "Модел с 14B параметри с по-високо качество от Phi-3-mini, фокусиран върху данни с високо качество и интензивно разсъждение.",
  "Phi-3-mini-128k-instruct.description": "Същият модел Phi-3-mini с по-голям контекстен прозорец за RAG или few-shot подканвания.",
  "Phi-3-mini-4k-instruct.description": "Най-малкият член на семейството Phi-3, оптимизиран за качество и ниска латентност.",
  "Phi-3-small-128k-instruct.description": "Същият модел Phi-3-small с по-голям контекстен прозорец за RAG или few-shot подканвания.",
  "Phi-3-small-8k-instruct.description": "Модел с 7B параметри с по-високо качество от Phi-3-mini, фокусиран върху данни с високо качество и интензивно разсъждение.",
  "Phi-3.5-mini-instruct.description": "Актуализирана версия на модела Phi-3-mini.",
  "Phi-3.5-vision-instrust.description": "Актуализирана версия на модела Phi-3-vision.",
  "Pro/Qwen/Qwen2-7B-Instruct.description": "Qwen2-7B-Instruct е 7B модел с инструкции от серията Qwen2. Използва трансформерна архитектура със SwiGLU, QKV bias и групирано внимание, и обработва големи входове. Постига отлични резултати в езиково разбиране, генериране, многоезични задачи, програмиране, математика и разсъждение, надминавайки повечето отворени модели и конкурирайки се със затворени.",
  "Pro/Qwen/Qwen2.5-7B-Instruct.description": "Qwen2.5-7B-Instruct е част от най-новата серия LLM на Alibaba Cloud. Моделът с 7B параметри носи значителни подобрения в програмирането и математиката, поддържа над 29 езика и подобрява следването на инструкции, разбирането на структурирани данни и генерирането на структурирани изходи (особено JSON).",
  "Pro/Qwen/Qwen2.5-Coder-7B-Instruct.description": "Qwen2.5-Coder-7B-Instruct е най-новият LLM на Alibaba Cloud, фокусиран върху програмиране. Изграден върху Qwen2.5 и обучен с 5.5T токена, значително подобрява генерирането на код, разсъждението и поправката, като същевременно запазва силни математически и общи способности, осигурявайки стабилна основа за кодови агенти.",
  "Pro/Qwen/Qwen2.5-VL-7B-Instruct.description": "Qwen2.5-VL е нов модел за визия и език от серията Qwen с мощно визуално разбиране. Анализира текст, графики и оформления в изображения, разбира дълги видеа и събития, поддържа разсъждение и използване на инструменти, обвързване на обекти във формати, и структурирани изходи. Подобрява динамичната резолюция и обучението с честота на кадрите за видео разбиране и повишава ефективността на визуалния енкодер.",
  "Pro/THUDM/GLM-4.1V-9B-Thinking.description": "GLM-4.1V-9B-Thinking е отворен VLM модел, разработен от Zhipu AI и лабораторията KEG на университета Цинхуа, създаден за сложна мултимодална когниция. Базиран на GLM-4-9B-0414, той добавя верижно разсъждение (chain-of-thought) и обучение чрез подсилване (RL), което значително подобрява между-модалното разсъждение и стабилността.",
  "Pro/THUDM/glm-4-9b-chat.description": "GLM-4-9B-Chat е отворен GLM-4 модел от Zhipu AI. Демонстрира високи резултати в семантика, математика, логическо мислене, програмиране и знания. Освен многозавойни разговори, поддържа уеб сърфиране, изпълнение на код, извикване на персонализирани инструменти и разсъждение върху дълги текстове. Поддържа 26 езика (включително китайски, английски, японски, корейски, немски). Представя се отлично в AlignBench-v2, MT-Bench, MMLU и C-Eval и поддържа до 128K контекст за академични и бизнес приложения.",
  "Pro/deepseek-ai/DeepSeek-R1-Distill-Qwen-7B.description": "DeepSeek-R1-Distill-Qwen-7B е дестилиран от Qwen2.5-Math-7B и фино настроен с 800K подбрани проби от DeepSeek-R1. Постига отлични резултати: 92.8% на MATH-500, 55.5% на AIME 2024 и рейтинг 1189 в CodeForces за 7B модел.",
  "Pro/deepseek-ai/DeepSeek-R1.description": "DeepSeek-R1 е модел за разсъждение, базиран на обучение чрез подсилване (RL), който намалява повторенията и подобрява четимостта. Използва cold-start данни преди RL, за да засили разсъждението, съпоставя се с OpenAI-o1 при задачи по математика, код и логика и подобрява общите резултати чрез внимателно обучение.",
  "Pro/deepseek-ai/DeepSeek-V3.1-Terminus.description": "DeepSeek-V3.1-Terminus е обновен модел от серията V3.1, позициониран като хибриден агентен LLM. Отстранява докладвани от потребители проблеми и подобрява стабилността, езиковата последователност и намалява смесването на китайски/английски и аномални символи. Интегрира режими с и без разсъждение с шаблони за чат за гъвкаво превключване. Подобрява и производителността на Code Agent и Search Agent за по-надеждно използване на инструменти и многoетапни задачи.",
  "Pro/deepseek-ai/DeepSeek-V3.2-Exp.description": "DeepSeek-V3.2-Exp е експериментална версия от серията V3.2, която служи като мост към следващата архитектура. Добавя DeepSeek Sparse Attention (DSA) върху V3.1-Terminus за по-ефективно обучение и инференция при дълъг контекст, с оптимизации за използване на инструменти, разбиране на дълги документи и многoетапно разсъждение. Идеален за изследване на по-висока ефективност при разсъждение с голям контекстов бюджет.",
  "Pro/deepseek-ai/DeepSeek-V3.description": "DeepSeek-V3 е MoE модел с 671 милиарда параметъра, използващ MLA и DeepSeekMoE с балансирано натоварване без загуби за ефективно обучение и инференция. Предварително обучен върху 14.8T висококачествени токени и допълнително настроен с SFT и RL, той надминава други отворени модели и се доближава до водещите затворени решения.",
  "Pro/moonshotai/Kimi-K2-Instruct-0905.description": "Kimi K2-Instruct-0905 е най-новият и най-мощен модел от серията Kimi K2. Това е MoE модел от най-висок клас с 1T общо и 32B активни параметъра. Основните му предимства включват по-силна агентна интелигентност при програмиране с значителни подобрения в бенчмаркове и реални задачи, както и подобрена естетика и използваемост на фронтенд кода.",
  "Pro/moonshotai/Kimi-K2-Thinking.description": "Kimi K2 Thinking Turbo е ускорен вариант, оптимизиран за скорост на разсъждение и пропускателна способност, като запазва многoетапното разсъждение и използване на инструменти от K2 Thinking. Това е MoE модел с ~1T общи параметри, роден 256K контекст и стабилно мащабируемо извикване на инструменти за производствени сценарии с по-строги изисквания за латентност и едновременност.",
  "Pro/zai-org/glm-4.7.description": "GLM-4.7 е новото флагманско поколение модел на Zhipu с общ брой параметри 355 милиарда и 32 милиарда активни параметри. Той предлага цялостен ъпгрейд в области като обща диалогова комуникация, логическо разсъждение и способности на интелигентни агенти. GLM-4.7 подобрява Interleaved Thinking (преплетено мислене) и въвежда Preserved Thinking (запазено мислене) и Turn-level Thinking (мислене на ниво ход), осигурявайки по-дълбоко и последователно разсъждение.",
  "QwQ-32B-Preview.description": "Qwen QwQ е експериментален изследователски модел, фокусиран върху подобряване на разсъждението.",
  "Qwen/QVQ-72B-Preview.description": "QVQ-72B-Preview е изследователски модел от Qwen, насочен към визуално разсъждение, със силни страни в разбирането на сложни сцени и визуални математически задачи.",
  "Qwen/QwQ-32B-Preview.description": "Qwen QwQ е експериментален изследователски модел, фокусиран върху подобрено AI разсъждение.",
  "Qwen/QwQ-32B.description": "QwQ е модел за разсъждение от семейството Qwen. В сравнение със стандартните модели, настроени по инструкции, той добавя мисловни и логически способности, които значително подобряват представянето при трудни задачи. QwQ-32B е среден по размер модел, съпоставим с водещи модели за разсъждение като DeepSeek-R1 и o1-mini. Използва RoPE, SwiGLU, RMSNorm и QKV bias в вниманието, с 64 слоя и 40 Q глави (8 KV в GQA).",
  "Qwen/Qwen-Image-Edit-2509.description": "Qwen-Image-Edit-2509 е най-новата версия за редактиране на изображения от екипа на Qwen. Базиран на 20B модела Qwen-Image, той разширява силното текстово рендиране към редактиране на изображения за прецизни текстови промени. Използва двуканална архитектура – входовете се подават към Qwen2.5-VL за семантичен контрол и към VAE енкодер за контрол на външния вид, което позволява редакции както на семантично, така и на визуално ниво. Поддържа локални редакции (добавяне/премахване/промяна) и по-високо ниво на семантични промени като създаване на IP и трансфер на стил, като същевременно запазва смисъла. Постига SOTA резултати в множество бенчмаркове.",
  "Qwen/Qwen-Image.description": "Qwen-Image е базов модел за генериране на изображения с 20B параметъра от екипа на Qwen. Постига значителен напредък в рендиране на сложен текст и прецизно редактиране на изображения, особено за висококачествен китайски/английски текст. Поддържа многострочни и параграфни оформления с последователна типография. Освен текстово рендиране, поддържа широк спектър от стилове – от фотореалистични до аниме, както и напреднало редактиране като трансфер на стил, добавяне/премахване на обекти, подобряване на детайли, редактиране на текст и контрол на позата, с цел да бъде цялостна основа за визуално творчество.",
  "Qwen/Qwen2-72B-Instruct.description": "Qwen 2 Instruct (72B) предоставя прецизно следване на инструкции за корпоративни натоварвания.",
  "Qwen/Qwen2-7B-Instruct.description": "Qwen2-7B-Instruct е 7B модел от серията Qwen2, обучен за следване на инструкции, използващ Transformer, SwiGLU, QKV bias и групирано внимание при заявки. Обработва големи входни данни и се представя отлично в задачи по разбиране, генериране, многоезичност, програмиране, математика и логическо мислене, надминавайки повечето отворени модели и превъзхождайки Qwen1.5-7B-Chat в множество оценки.",
  "Qwen/Qwen2-VL-72B-Instruct.description": "Qwen2-VL е най-новият модел от серията Qwen-VL, постигайки водещи резултати в задачи по компютърно зрение като MathVista, DocVQA, RealWorldQA и MTVQA. Разбира видеа с продължителност над 20 минути за видео QA, диалог и създаване на съдържание. Поддържа сложна логика и вземане на решения, интегрирайки се с устройства/роботи за действия, водени от визуална информация. Освен английски и китайски, чете текст на много езици, включително повечето европейски, японски, корейски, арабски и виетнамски.",
  "Qwen/Qwen2.5-14B-Instruct.description": "Qwen2.5-14B-Instruct е част от най-новата серия LLM на Alibaba Cloud. Моделът с 14B параметри предлага значителни подобрения в програмирането и математиката, поддържа над 29 езика и подобрява следването на инструкции, разбирането на структурирани данни и генерирането на структурирани изходи (особено JSON).",
  "Qwen/Qwen2.5-32B-Instruct.description": "Qwen2.5-32B-Instruct е част от най-новата серия LLM на Alibaba Cloud. Моделът с 32B параметри предлага значителни подобрения в програмирането и математиката, поддържа над 29 езика и подобрява следването на инструкции, разбирането на структурирани данни и генерирането на структурирани изходи (особено JSON).",
  "Qwen/Qwen2.5-72B-Instruct-128K.description": "Qwen2.5-72B-Instruct е част от най-новата серия LLM на Alibaba Cloud. Моделът с 72B параметри подобрява програмирането и математиката, поддържа до 128K вход и над 8K изход, предлага над 29 езика и подобрява следването на инструкции и структурирания изход (особено JSON).",
  "Qwen/Qwen2.5-72B-Instruct-Turbo.description": "Qwen2.5 е ново семейство LLM, оптимизирано за задачи със стил на инструкции.",
  "Qwen/Qwen2.5-72B-Instruct.description": "Qwen2.5-72B-Instruct е част от най-новата серия LLM на Alibaba Cloud. Моделът с 72B параметри предлага значителни подобрения в програмирането и математиката, поддържа над 29 езика и подобрява следването на инструкции, разбирането на структурирани данни и генерирането на структурирани изходи (особено JSON).",
  "Qwen/Qwen2.5-7B-Instruct-Turbo.description": "Qwen2.5 е ново семейство LLM, оптимизирано за задачи със стил на инструкции.",
  "Qwen/Qwen2.5-7B-Instruct.description": "Qwen2.5-7B-Instruct е част от най-новата серия LLM на Alibaba Cloud. Моделът с 7B параметри предлага значителни подобрения в програмирането и математиката, поддържа над 29 езика и подобрява следването на инструкции, разбирането на структурирани данни и генерирането на структурирани изходи (особено JSON).",
  "Qwen/Qwen2.5-Coder-32B-Instruct.description": "Qwen2.5 Coder 32B Instruct е най-новият LLM на Alibaba Cloud, фокусиран върху програмиране. Изграден върху Qwen2.5 и обучен с 5.5T токена, той значително подобрява генерирането на код, логическото мислене и поправката на грешки, като същевременно запазва силни математически и общи способности, предоставяйки стабилна основа за агенти за програмиране.",
  "Qwen/Qwen2.5-Coder-7B-Instruct.description": "Qwen2.5-Coder-7B-Instruct е най-новият LLM на Alibaba Cloud, фокусиран върху програмиране. Изграден върху Qwen2.5 и обучен с 5.5T токена, той значително подобрява генерирането на код, логическото мислене и поправката на грешки, като същевременно запазва силни математически и общи способности, предоставяйки стабилна основа за агенти за програмиране.",
  "Qwen/Qwen2.5-VL-32B-Instruct.description": "Qwen2.5-VL-32B-Instruct е мултимодален модел от екипа на Qwen. Разпознава често срещани обекти и анализира текст, диаграми, икони, графики и оформления. Като визуален агент, може да разсъждава и динамично да управлява инструменти, включително използване на компютър и телефон. Прецизно локализира обекти и генерира структурирани изходи за фактури и таблици. В сравнение с Qwen2-VL, RL допълнително подобрява математиката и решаването на проблеми, с по-предпочитани от хората отговори.",
  "Qwen/Qwen2.5-VL-72B-Instruct.description": "Qwen2.5-VL е модел за визия и език от серията Qwen2.5 с основни подобрения: по-силно визуално разбиране за обекти, текст, диаграми и оформления; разсъждение като визуален агент с динамично използване на инструменти; разбиране на видеа над 1 час и улавяне на ключови събития; прецизно позициониране на обекти чрез кутии или точки; и структурирани изходи за сканирани данни като фактури и таблици.",
  "Qwen/Qwen3-14B.description": "Qwen3 е следващо поколение модел Tongyi Qwen с основни подобрения в логическото мислене, общите способности, агентните възможности и многоезичната производителност, като поддържа превключване между режими на мислене.",
  "Qwen/Qwen3-235B-A22B-Instruct-2507.description": "Qwen3-235B-A22B-Instruct-2507 е водещ MoE модел от серията Qwen3 с общо 235B и 22B активни параметри. Това е актуализирана версия без мислене, фокусирана върху подобряване на следването на инструкции, логическото мислене, разбирането на текст, математика, наука, програмиране и използване на инструменти. Разширява също така многоезичните знания и се съобразява по-добре с предпочитанията на потребителите при субективни отворени задачи.",
  "Qwen/Qwen3-235B-A22B-Thinking-2507.description": "Qwen3-235B-A22B-Thinking-2507 е модел от серията Qwen3, фокусиран върху сложни логически задачи. Използва MoE архитектура с общо 235B и ~22B активни параметри на токен за повишена ефективност. Като специализиран мислещ модел, показва значителни подобрения в логика, математика, наука, програмиране и академични оценки, достигайки водещи резултати сред отворените мислещи модели. Подобрява също следването на инструкции, използването на инструменти и генерирането на текст, като нативно поддържа 256K контекст за дълбоко разсъждение и дълги документи.",
  "Qwen/Qwen3-235B-A22B.description": "Qwen3 е следващо поколение модел Tongyi Qwen с основни подобрения в логическото мислене, общите способности, агентните възможности и многоезичната производителност, като поддържа превключване между режими на мислене.",
  "Qwen/Qwen3-30B-A3B-Instruct-2507.description": "Qwen3-30B-A3B-Instruct-2507 е актуализираната немислеща версия на Qwen3-30B-A3B. Това е MoE модел с общо 30.5B и 3.3B активни параметри. Значително подобрява следването на инструкции, логическото мислене, разбирането на текст, математика, наука, програмиране и използване на инструменти, разширява многоезичните знания и се съобразява по-добре с предпочитанията на потребителите при субективни отворени задачи. Поддържа 256K контекст. Този модел е само немислещ и няма да генерира тагове `<think></think>`.",
  "Qwen/Qwen3-30B-A3B-Thinking-2507.description": "Qwen3-30B-A3B-Thinking-2507 е най-новият мислещ модел от серията Qwen3. Това е MoE модел с общо 30.5B и 3.3B активни параметри, фокусиран върху сложни задачи. Показва значителни подобрения в логика, математика, наука, програмиране и академични оценки, и подобрява следването на инструкции, използването на инструменти, генерирането на текст и съобразяването с предпочитания. Нативно поддържа 256K контекст и може да се разшири до 1M токена. Тази версия е проектирана за мислещ режим с детайлно стъпково разсъждение и силни агентни възможности.",
  "Qwen/Qwen3-30B-A3B.description": "Qwen3 е следващо поколение модел Tongyi Qwen с основни подобрения в логическото мислене, общите способности, агентните възможности и многоезичната производителност, като поддържа превключване между режими на мислене.",
  "Qwen/Qwen3-32B.description": "Qwen3 е следващо поколение модел Tongyi Qwen с основни подобрения в логическото мислене, общите способности, агентните възможности и многоезичната производителност, като поддържа превключване между режими на мислене.",
  "Qwen/Qwen3-8B.description": "Qwen3 е следващо поколение модел Tongyi Qwen с основни подобрения в логическото мислене, общите способности, агентните възможности и многоезичната производителност, като поддържа превключване между режими на мислене.",
  "Qwen/Qwen3-Coder-30B-A3B-Instruct.description": "Qwen3-Coder-30B-A3B-Instruct е модел за програмиране от серията Qwen3, разработен от екипа на Qwen. Той е оптимизиран за висока производителност и ефективност, като същевременно подобрява възможностите за работа с код. Демонстрира силни предимства при агентно програмиране, автоматизирани операции в браузър и използване на инструменти сред отворените модели. Поддържа нативно контекст от 256K токена и може да се разшири до 1M токена за разбиране на цели кодови бази. Използва се за агентно програмиране в платформи като Qwen Code и CLINE с посветен формат за извикване на функции.",
  "Qwen/Qwen3-Coder-480B-A35B-Instruct.description": "Qwen3-Coder-480B-A35B-Instruct е най-агентният модел за програмиране на Alibaba до момента. Това е MoE модел с общо 480 милиарда параметъра и 35 милиарда активни, осигуряващ баланс между ефективност и производителност. Поддържа нативно контекст от 256K токена и може да се разшири до 1M токена чрез YaRN, което позволява работа с големи кодови бази. Създаден е за агентни работни потоци при програмиране и може да взаимодейства с инструменти и среди за решаване на сложни задачи. Постига водещи резултати сред отворените модели в бенчмаркове за програмиране и агенти, сравними с Claude Sonnet 4.",
  "Qwen/Qwen3-Next-80B-A3B-Instruct.description": "Qwen3-Next-80B-A3B-Instruct е базов модел от ново поколение, използващ архитектурата Qwen3-Next за изключителна ефективност при обучение и инференция. Комбинира хибридно внимание (Gated DeltaNet + Gated Attention), силно разреден MoE и оптимизации за стабилност при обучение. С общо 80 милиарда параметъра, но само ~3 милиарда активни при инференция, значително намалява изчислителните ресурси и осигурява над 10 пъти по-висока пропускателност спрямо Qwen3-32B при контексти над 32K. Тази версия, настроена за инструкции, е насочена към общи задачи (без режим на мислене). Представя се наравно с Qwen3-235B в някои бенчмаркове и показва силни предимства при задачи с ултра-дълъг контекст.",
  "Qwen/Qwen3-Next-80B-A3B-Thinking.description": "Qwen3-Next-80B-A3B-Thinking е базов модел от ново поколение, предназначен за сложни разсъждения. Използва архитектурата Qwen3-Next с хибридно внимание (Gated DeltaNet + Gated Attention) и силно разреден MoE за изключителна ефективност при обучение и инференция. С общо 80 милиарда параметъра и ~3 милиарда активни при инференция, намалява изчислителните разходи и осигурява над 10 пъти по-висока пропускателност спрямо Qwen3-32B при контексти над 32K. Тази версия „Thinking“ е насочена към многoетапни задачи като доказателства, синтез на код, логически анализ и планиране, като генерира структурирана верига от мисли. Надминава Qwen3-32B-Thinking и побеждава Gemini-2.5-Flash-Thinking в няколко бенчмарка.",
  "Qwen/Qwen3-Omni-30B-A3B-Captioner.description": "Qwen3-Omni-30B-A3B-Captioner е VLM модел от серията Qwen3, създаден за висококачествени, детайлни и точни описания на изображения. Използва MoE архитектура с 30 милиарда параметъра за дълбоко разбиране на изображения и генериране на плавни описания, като се отличава в улавянето на детайли, разбиране на сцени, разпознаване на обекти и логически връзки.",
  "Qwen/Qwen3-Omni-30B-A3B-Instruct.description": "Qwen3-Omni-30B-A3B-Instruct е MoE модел от серията Qwen3 с общо 30 милиарда и 3 милиарда активни параметъра, осигуряващ висока производителност при ниска цена на инференция. Обучен е върху висококачествени многоезични данни от различни източници и поддържа пълноформатни входове (текст, изображения, аудио, видео), както и кросмодално разбиране и генериране.",
  "Qwen/Qwen3-Omni-30B-A3B-Thinking.description": "Qwen3-Omni-30B-A3B-Thinking е основният компонент „Мислител“ на Qwen3-Omni. Обработва мултимодални входове (текст, аудио, изображения, видео) и извършва сложни разсъждения чрез верига от мисли, обединявайки входовете в споделено представяне за дълбоко кросмодално разбиране. Това е MoE модел с 30 милиарда общи и 3 милиарда активни параметъра, балансиращ силни разсъждения и изчислителна ефективност.",
  "Qwen/Qwen3-VL-235B-A22B-Instruct.description": "Qwen3-VL-235B-A22B-Instruct е голям модел от серията Qwen3-VL, настроен за инструкции и изграден върху MoE архитектура, осигуряващ отлично мултимодално разбиране и генериране. Поддържа нативно контекст от 256K токена и е подходящ за високонагружени производствени мултимодални услуги.",
  "Qwen/Qwen3-VL-235B-A22B-Thinking.description": "Qwen3-VL-235B-A22B-Thinking е водещата версия за разсъждение на Qwen3-VL, оптимизирана за сложни мултимодални разсъждения, дълъг контекст и взаимодействие с агенти в корпоративни сценарии.",
  "Qwen/Qwen3-VL-30B-A3B-Instruct.description": "Qwen3-VL-30B-A3B-Instruct е настроен за инструкции модел от серията Qwen3-VL с високо ниво на разбиране и генериране на визия и език. Поддържа нативно контекст от 256K токена за мултимодален чат и генериране, базирано на изображения.",
  "Qwen/Qwen3-VL-30B-A3B-Thinking.description": "Qwen3-VL-30B-A3B-Thinking е версия с подобрени разсъждения на Qwen3-VL, оптимизирана за мултимодални разсъждения, преобразуване на изображения в код и сложно визуално разбиране. Поддържа контекст от 256K токена с по-силна способност за верига от мисли.",
  "Qwen/Qwen3-VL-32B-Instruct.description": "Qwen3-VL-32B-Instruct е модел за визия и език от екипа на Qwen с водещи резултати в множество VL бенчмаркове. Поддържа изображения с мегапикселова резолюция и предлага силно визуално разбиране, многоезичен OCR, прецизно визуално позициониране и визуален диалог. Обработва сложни мултимодални задачи и поддържа извикване на инструменти и допълване на префикси.",
  "Qwen/Qwen3-VL-32B-Thinking.description": "Qwen3-VL-32B-Thinking е оптимизиран за сложно визуално разсъждение. Включва вграден режим на мислене, който генерира междинни стъпки на разсъждение преди отговорите, подобрявайки логиката на многоетапни задачи, планиране и сложни разсъждения. Поддържа изображения с мегапикселова резолюция, силно визуално разбиране, многоезичен OCR, прецизно позициониране, визуален диалог, извикване на инструменти и допълване на префикси.",
  "Qwen/Qwen3-VL-8B-Instruct.description": "Qwen3-VL-8B-Instruct е модел за визия и език от серията Qwen3, изграден върху Qwen3-8B-Instruct и обучен върху големи обеми от данни с изображения и текст. Отличава се с общо визуално разбиране, диалог, фокусиран върху визията, и многоезично разпознаване на текст в изображения. Подходящ е за визуални въпроси и отговори, описания, следване на мултимодални инструкции и използване на инструменти.",
  "Qwen/Qwen3-VL-8B-Thinking.description": "Qwen3-VL-8B-Thinking е визуалната версия за разсъждение на Qwen3, оптимизирана за сложно многоетапно разсъждение. Генерира верига от мисли преди отговорите за подобрена точност, идеална за задълбочени визуални въпроси и отговори и детайлен анализ на изображения.",
  "Qwen2-72B-Instruct.description": "Qwen2 е най-новата версия от серията Qwen, поддържаща контекстен прозорец от 128k. В сравнение с най-добрите отворени модели днес, Qwen2-72B значително превъзхожда водещите модели в разбирането на естествен език, знания, програмиране, математика и многоезични възможности.",
  "Qwen2-7B-Instruct.description": "Qwen2 е най-новата версия от серията Qwen, която превъзхожда най-добрите отворени модели със сходен или дори по-голям размер. Qwen2 7B показва значителни предимства в множество бенчмаркове, особено в програмиране и разбиране на китайски език.",
  "Qwen2-VL-72B.description": "Qwen2-VL-72B е мощен модел за визия и език, поддържащ мултимодална обработка на изображения и текст, като точно разпознава съдържанието на изображения и генерира съответни описания или отговори.",
  "Qwen2.5-14B-Instruct.description": "Qwen2.5-14B-Instruct е LLM с 14 милиарда параметъра и висока производителност, оптимизиран за китайски и многоезични сценарии, поддържащ интелигентни въпроси и отговори и генериране на съдържание.",
  "Qwen2.5-32B-Instruct.description": "Qwen2.5-32B-Instruct е LLM с 32 милиарда параметъра и балансирана производителност, оптимизиран за китайски и многоезични сценарии, поддържащ интелигентни въпроси и отговори и генериране на съдържание.",
  "Qwen2.5-72B-Instruct.description": "LLM за китайски и английски език, настроен за език, програмиране, математика и логическо разсъждение.",
  "Qwen2.5-7B-Instruct.description": "Qwen2.5-7B-Instruct е LLM с 7 милиарда параметъра, който поддържа извикване на функции и безпроблемна интеграция с външни системи, значително подобрявайки гъвкавостта и разширяемостта. Оптимизиран е за китайски и многоезични сценарии, поддържащ интелигентни въпроси и отговори и генериране на съдържание.",
  "Qwen2.5-Coder-14B-Instruct.description": "Qwen2.5-Coder-14B-Instruct е мащабен предварително обучен модел за програмиране с отлични способности за разбиране и генериране на код. Ефективно се справя с широк спектър от програмни задачи, идеален за интелигентно програмиране, автоматично генериране на скриптове и въпроси и отговори, свързани с програмиране.",
  "Qwen2.5-Coder-32B-Instruct.description": "Разширен LLM за генериране на код, логическо разсъждение и отстраняване на грешки на основните програмни езици.",
  "Qwen3-235B-A22B-Instruct-2507-FP8.description": "Qwen3 235B A22B Instruct 2507 е оптимизиран за напреднало разсъждение и следване на инструкции, използвайки MoE за ефективно мащабиране на разсъждението.",
  "Qwen3-235B.description": "Qwen3-235B-A22B е MoE модел, който въвежда хибриден режим на разсъждение, позволяващ на потребителите да превключват безпроблемно между мислещ и немислещ режим. Поддържа разбиране и разсъждение на 119 езика и диалекта и има силни възможности за извикване на инструменти, конкурирайки се с водещи модели като DeepSeek R1, OpenAI o1, o3-mini, Grok 3 и Google Gemini 2.5 Pro в бенчмаркове за общи способности, програмиране и математика, многоезичност и логическо разсъждение.",
  "Qwen3-32B.description": "Qwen3-32B е плътен модел, който въвежда хибриден режим на разсъждение, позволяващ на потребителите да превключват между мислещ и немислещ режим. С архитектурни подобрения, повече данни и по-добро обучение, той се представя наравно с Qwen2.5-72B.",
  "SenseChat-128K.description": "Базов модел V4 с контекст от 128K, силен в разбиране и генериране на дълги текстове.",
  "SenseChat-32K.description": "Базов модел V4 с контекст от 32K, гъвкав за различни сценарии.",
  "SenseChat-5-1202.description": "Най-новата версия, базирана на V5.5, с значителни подобрения в основни знания по китайски/английски, чат, STEM, хуманитарни науки, писане, математика/логика и контрол на дължината.",
  "SenseChat-5-Cantonese.description": "Проектиран за диалектни навици, жаргон и местни знания в Хонконг; надминава GPT-4 в разбирането на кантонски и съперничи на GPT-4 Turbo в знания, логика, математика и програмиране.",
  "SenseChat-5-beta.description": "Някои показатели надвишават тези на SenseChat-5-1202.",
  "SenseChat-5.description": "Най-новият V5.5 с контекст от 128K; значителни подобрения в математическо разсъждение, чат на английски, следване на инструкции и разбиране на дълги текстове, сравним с GPT-4o.",
  "SenseChat-Character-Pro.description": "Разширен модел за чат с персонажи с контекст от 32K, подобрени възможности и поддръжка на китайски/английски.",
  "SenseChat-Character.description": "Стандартен модел за чат с персонажи с контекст от 8K и висока скорост на отговор.",
  "SenseChat-Turbo-1202.description": "Най-новият лек модел, достигащ над 90% от възможностите на пълния модел с значително по-ниска цена за инференция.",
  "SenseChat-Turbo.description": "Подходящ за бързи въпроси и отговори и сценарии за фина настройка на модели.",
  "SenseChat-Vision.description": "Най-новият V5.5 с вход от множество изображения и широки основни подобрения в разпознаване на атрибути, пространствени отношения, действия/събития, разбиране на сцени, разпознаване на емоции, логическо разсъждение и разбиране/генериране на текст.",
  "SenseChat.description": "Базов модел V4 с контекст от 4K и силни общи възможности.",
  "SenseNova-V6-5-Pro.description": "Със значителни подобрения в мултимодалните, езиковите и логическите данни, както и с оптимизация на стратегията за обучение, новият модел значително подобрява мултимодалното разсъждение и следването на обобщени инструкции, поддържа контекстен прозорец до 128k и се отличава в задачи по OCR и разпознаване на културен и туристически IP.",
  "SenseNova-V6-5-Turbo.description": "Със значителни подобрения в мултимодалните, езиковите и логическите данни, както и с оптимизация на стратегията за обучение, новият модел значително подобрява мултимодалното разсъждение и следването на обобщени инструкции, поддържа контекстен прозорец до 128k и се отличава в задачи по OCR и разпознаване на културен и туристически IP.",
  "SenseNova-V6-Pro.description": "Нативно обединява изображение, текст и видео, преодолявайки традиционните мултимодални ограничения; заема водещи позиции в OpenCompass и SuperCLUE.",
  "SenseNova-V6-Reasoner.description": "Комбинира дълбоко разсъждение чрез зрение и език, поддържа бавно мислене и пълна верига на мисълта.",
  "SenseNova-V6-Turbo.description": "Нативно обединява изображение, текст и видео, преодолявайки традиционните мултимодални ограничения. Води в основните мултимодални и езикови възможности и заема челни позиции в множество оценки.",
  "Skylark2-lite-8k.description": "Модел от второ поколение Skylark. Skylark2-lite осигурява бързи отговори за реалновремеви, чувствителни към разходите сценарии с по-ниски изисквания за точност, с контекстен прозорец от 8K.",
  "Skylark2-pro-32k.description": "Модел от второ поколение Skylark. Skylark2-pro предлага по-висока точност за сложни задачи по генериране на текст като професионално копирайтинг, писане на романи и висококачествен превод, с контекстен прозорец от 32K.",
  "Skylark2-pro-4k.description": "Модел от второ поколение Skylark. Skylark2-pro предлага по-висока точност за сложни задачи по генериране на текст като професионално копирайтинг, писане на романи и висококачествен превод, с контекстен прозорец от 4K.",
  "Skylark2-pro-character-4k.description": "Модел от второ поколение Skylark. Skylark2-pro-character се отличава в ролеви игри и чат, съчетавайки подканите с отличителни стилове на персонажи и естествен диалог за чатботи, виртуални асистенти и обслужване на клиенти, с бързи отговори.",
  "Skylark2-pro-turbo-8k.description": "Модел от второ поколение Skylark. Skylark2-pro-turbo-8k предлага по-бърза инференция на по-ниска цена с контекстен прозорец от 8K.",
  "THUDM/GLM-4-32B-0414.description": "GLM-4-32B-0414 е следващо поколение отворен GLM модел с 32 милиарда параметъра, сравним по производителност с OpenAI GPT и сериите DeepSeek V3/R1.",
  "THUDM/GLM-4-9B-0414.description": "GLM-4-9B-0414 е 9-милиарден GLM модел, който наследява технологиите на GLM-4-32B, като същевременно предлага по-леко внедряване. Представя се добре в генериране на код, уеб дизайн, създаване на SVG и писане, базирано на търсене.",
  "THUDM/GLM-4.1V-9B-Thinking.description": "GLM-4.1V-9B-Thinking е отворен VLM модел от Zhipu AI и лабораторията KEG на Цинхуа, създаден за сложна мултимодална когниция. Изграден върху GLM-4-9B-0414, добавя верижно разсъждение и подсилено обучение (RL), значително подобрявайки между-модалното разсъждение и стабилността.",
  "THUDM/GLM-Z1-32B-0414.description": "GLM-Z1-32B-0414 е модел за дълбоко разсъждение, изграден от GLM-4-32B-0414 с данни за студен старт и разширено подсилено обучение, допълнително обучен върху математика, код и логика. Значително подобрява способността за решаване на сложни задачи спрямо базовия модел.",
  "THUDM/GLM-Z1-9B-0414.description": "GLM-Z1-9B-0414 е компактен GLM модел с 9 милиарда параметъра, който запазва силните страни на отворения код, като същевременно предлага впечатляващи възможности. Представя се отлично в математическо разсъждение и общи задачи, водещ в своя клас сред отворените модели.",
  "THUDM/GLM-Z1-Rumination-32B-0414.description": "GLM-Z1-Rumination-32B е модел за дълбоко разсъждение с възможности за „размисъл“ (сравним с OpenAI Deep Research). За разлика от типичните модели за дълбоко мислене, той отделя повече време за обмисляне, за да решава по-отворени и сложни проблеми.",
  "THUDM/glm-4-9b-chat.description": "GLM-4-9B-Chat е отвореният GLM-4 модел от Zhipu AI. Представя се силно в семантика, математика, разсъждение, код и знания. Освен многозавойни чатове, поддържа уеб браузване, изпълнение на код, извикване на персонализирани инструменти и разсъждение върху дълги текстове. Поддържа 26 езика (включително китайски, английски, японски, корейски, немски). Представя се добре в AlignBench-v2, MT-Bench, MMLU и C-Eval и поддържа до 128K контекст за академична и бизнес употреба.",
  "Tongyi-Zhiwen/QwenLong-L1-32B.description": "QwenLong-L1-32B е първият модел за разсъждение с дълъг контекст (LRM), обучен с подсилено обучение, оптимизиран за разсъждение върху дълги текстове. Неговото прогресивно разширяване на контекста чрез RL позволява стабилен преход от кратък към дълъг контекст. Надминава OpenAI-o3-mini и Qwen3-235B-A22B в седем бенчмарка за въпроси и отговори върху документи с дълъг контекст, съперничи на Claude-3.7-Sonnet-Thinking. Особено силен е в математика, логика и многозвенно разсъждение.",
  "Yi-34B-Chat.description": "Yi-1.5-34B запазва силните езикови способности на серията, като използва инкрементално обучение върху 500 милиарда висококачествени токена, за да подобри значително логиката в математиката и програмирането.",
  "abab5.5-chat.description": "Създаден за продуктивни сценарии с обработка на сложни задачи и ефективно генериране на текст за професионална употреба.",
  "abab5.5s-chat.description": "Проектиран за чат с китайски персонажи, осигуряващ висококачествен диалог на китайски език за различни приложения.",
  "abab6.5g-chat.description": "Проектиран за многоезичен чат с персонажи, поддържащ висококачествено генериране на диалог на английски и други езици.",
  "abab6.5s-chat.description": "Подходящ за широк спектър от NLP задачи, включително генериране на текст и диалогови системи.",
  "abab6.5t-chat.description": "Оптимизиран за чат с китайски персонажи, осигуряващ плавен диалог, съобразен с китайските езикови навици.",
  "accounts/fireworks/models/deepseek-r1.description": "DeepSeek-R1 е модерен LLM, оптимизиран с обучение чрез подсилване и cold-start данни, осигуряващ отлично представяне при логическо разсъждение, математика и програмиране.",
  "accounts/fireworks/models/deepseek-v3.description": "Мощен езиков модел от тип Mixture-of-Experts (MoE) от DeepSeek с общо 671 милиарда параметъра и 37 милиарда активни параметъра на токен.",
  "accounts/fireworks/models/llama-v3-70b-instruct.description": "Meta разработи и пусна серията Meta Llama 3 LLM, която включва предварително обучени и фино настроени за инструкции модели за генериране на текст с размери 8B и 70B. Моделите Llama 3, фино настроени за инструкции, са оптимизирани за разговорна употреба и надминават много от съществуващите отворени чат модели по общи индустриални показатели.",
  "accounts/fireworks/models/llama-v3-8b-instruct-hf.description": "Моделите Meta Llama 3, фино настроени за инструкции, са оптимизирани за разговорна употреба и надминават много от съществуващите отворени чат модели по общи индустриални показатели. Llama 3 8B Instruct (HF версия) е оригиналната FP16 версия на Llama 3 8B Instruct, като се очаква резултатите да съвпадат с официалната имплементация на Hugging Face.",
  "accounts/fireworks/models/llama-v3-8b-instruct.description": "Meta разработи и пусна серията Meta Llama 3 LLM — колекция от предварително обучени и фино настроени за инструкции модели за генериране на текст с размери 8B и 70B. Моделите Llama 3, фино настроени за инструкции, са оптимизирани за разговорна употреба и надминават много от съществуващите отворени чат модели по общи индустриални показатели.",
  "accounts/fireworks/models/llama-v3p1-405b-instruct.description": "Meta Llama 3.1 е многоезично LLM семейство с предварително обучени и фино настроени за инструкции модели за генериране с размери 8B, 70B и 405B. Моделите, фино настроени за текстови инструкции, са оптимизирани за многоезичен диалог и надминават много от съществуващите отворени и затворени чат модели по общи индустриални показатели. 405B е най-способният модел в семейството Llama 3.1, използващ FP8 извод, който точно съвпада с референтната имплементация.",
  "accounts/fireworks/models/llama-v3p1-70b-instruct.description": "Meta Llama 3.1 е многоезично LLM семейство с предварително обучени и фино настроени за инструкции модели за генериране с размери 8B, 70B и 405B. Моделите, фино настроени за текстови инструкции, са оптимизирани за многоезичен диалог и надминават много от съществуващите отворени и затворени чат модели по общи индустриални показатели.",
  "accounts/fireworks/models/llama-v3p1-8b-instruct.description": "Meta Llama 3.1 е многоезично LLM семейство с предварително обучени и фино настроени за инструкции модели за генериране с размери 8B, 70B и 405B. Моделите, фино настроени за текстови инструкции, са оптимизирани за многоезичен диалог и надминават много от съществуващите отворени и затворени чат модели по общи индустриални показатели.",
  "accounts/fireworks/models/llama-v3p2-11b-vision-instruct.description": "Фино настроен за инструкции модел за визуално разсъждение от Meta с 11 милиарда параметъра, оптимизиран за визуално разпознаване, логическо разсъждение по изображения, надписи и въпроси и отговори, свързани с изображения. Разбира визуални данни като диаграми и графики и свързва визията и езика чрез генериране на текстови описания на детайли от изображенията.",
  "accounts/fireworks/models/llama-v3p2-3b-instruct.description": "Llama 3.2 3B Instruct е лек многоезичен модел от Meta, проектиран за ефективна работа с предимства по отношение на латентност и разходи спрямо по-големите модели. Типични случаи на употреба включват пренаписване на заявки/подсказки и помощ при писане.",
  "accounts/fireworks/models/llama-v3p2-90b-vision-instruct.description": "Фино настроен за инструкции модел за визуално разсъждение от Meta с 90 милиарда параметъра, оптимизиран за визуално разпознаване, логическо разсъждение по изображения, надписи и въпроси и отговори, свързани с изображения. Разбира визуални данни като диаграми и графики и свързва визията и езика чрез генериране на текстови описания на детайли от изображенията. Забележка: този модел се предоставя експериментално като безсървърен модел. За производствена употреба имайте предвид, че Fireworks може да прекрати разполагането без предизвестие.",
  "accounts/fireworks/models/llama-v3p3-70b-instruct.description": "Llama 3.3 70B Instruct е декемврийската актуализация на Llama 3.1 70B. Подобрява използването на инструменти, поддръжката на многоезичен текст, математиката и програмирането спрямо изданието от юли 2024 г. Достига водещо в индустрията представяне при логическо разсъждение, математика и следване на инструкции, като предлага производителност, сравнима с 3.1 405B, но със значителни предимства по отношение на скорост и разходи.",
  "accounts/fireworks/models/mistral-small-24b-instruct-2501.description": "Модел с 24 милиарда параметъра и водещи възможности, сравними с по-големи модели.",
  "accounts/fireworks/models/mixtral-8x22b-instruct.description": "Mixtral MoE 8x22B Instruct v0.1 е фино настроената за инструкции версия на Mixtral MoE 8x22B v0.1, с активиран API за завършване на чат.",
  "accounts/fireworks/models/mixtral-8x7b-instruct.description": "Mixtral MoE 8x7B Instruct е фино настроената за инструкции версия на Mixtral MoE 8x7B, с активиран API за завършване на чат.",
  "accounts/fireworks/models/mythomax-l2-13b.description": "Подобрена версия на MythoMix, вероятно по-усъвършенствана форма, обединяваща MythoLogic-L2 и Huginn с експериментална техника за сливане на тензори. Уникалната ѝ природа я прави отлична за разказване на истории и ролеви игри.",
  "accounts/fireworks/models/phi-3-vision-128k-instruct.description": "Phi-3-Vision-128K-Instruct е лек, модерен отворен мултимодален модел, изграден от синтетични данни и подбрани публични уеб набори от данни, фокусиран върху висококачествени текстови и визуални данни, изискващи логическо разсъждение. Принадлежи към семейството Phi-3, с мултимодална версия, поддържаща контекст с дължина 128K токена. Моделът преминава през задълбочено подобрение, включително фино обучение под надзор и директна оптимизация на предпочитанията, за да осигури точно следване на инструкции и силни мерки за безопасност.",
  "accounts/fireworks/models/qwen-qwq-32b-preview.description": "Моделът Qwen QwQ се фокусира върху напредъка в логическото разсъждение на ИИ, демонстрирайки, че отворените модели могат да съперничат на затворените водещи модели. QwQ-32B-Preview е експериментално издание, което съвпада с o1 и надминава GPT-4o и Claude 3.5 Sonnet по логическо разсъждение и анализ в GPQA, AIME, MATH-500 и LiveCodeBench. Забележка: този модел се предоставя експериментално като безсървърен модел. За производствена употреба имайте предвид, че Fireworks може да прекрати разполагането без предизвестие.",
  "accounts/fireworks/models/qwen2-vl-72b-instruct.description": "Моделът Qwen-VL с 72 милиарда параметъра е най-новата итерация на Alibaba, отразяваща почти година иновации.",
  "accounts/fireworks/models/qwen2p5-72b-instruct.description": "Qwen2.5 е серия LLM само с декодер, разработена от екипа на Qwen и Alibaba Cloud, предлагаща размери 0.5B, 1.5B, 3B, 7B, 14B, 32B и 72B, с базови и фино настроени за инструкции варианти.",
  "accounts/fireworks/models/qwen2p5-coder-32b-instruct.description": "Qwen2.5-Coder е най-новият LLM от Qwen, проектиран за програмиране (преди CodeQwen). Забележка: този модел се предоставя експериментално като безсървърен модел. За производствена употреба имайте предвид, че Fireworks може да прекрати разполагането без предизвестие.",
  "accounts/yi-01-ai/models/yi-large.description": "Yi-Large е LLM от най-висок клас, който се нарежда непосредствено под GPT-4, Gemini 1.5 Pro и Claude 3 Opus в класацията LMSYS. Отличава се с многоезични възможности, особено на испански, китайски, японски, немски и френски. Yi-Large е също така удобен за разработчици, използвайки същата API схема като OpenAI за лесна интеграция.",
  "ai21-jamba-1.5-large.description": "Многоезичен модел с 398 милиарда параметъра (94 милиарда активни), с прозорец на контекста от 256 хиляди токена, поддръжка на извикване на функции, структурирани изходи и обосновано генериране.",
  "ai21-jamba-1.5-mini.description": "Многоезичен модел с 52 милиарда параметъра (12 милиарда активни), с прозорец на контекста от 256 хиляди токена, поддръжка на извикване на функции, структурирани изходи и обосновано генериране.",
  "ai21-labs/AI21-Jamba-1.5-Large.description": "Многоезичен модел с 398 милиарда параметъра (94 милиарда активни), с прозорец на контекста от 256 хиляди токена, поддръжка на извикване на функции, структурирани изходи и обосновано генериране.",
  "ai21-labs/AI21-Jamba-1.5-Mini.description": "Многоезичен модел с 52 милиарда параметъра (12 милиарда активни), с прозорец на контекста от 256 хиляди токена, поддръжка на извикване на функции, структурирани изходи и обосновано генериране.",
  "alibaba/qwen-3-14b.description": "Qwen3 е най-новото поколение от серията Qwen, предлагащо пълен набор от плътни и MoE модели. Обучен върху обширни данни, той постига пробиви в логическото мислене, следване на инструкции, агентни способности и многоезична поддръжка.",
  "alibaba/qwen-3-235b.description": "Qwen3 е най-новото поколение от серията Qwen, предлагащо пълен набор от плътни и MoE модели. Обучен върху обширни данни, той постига пробиви в логическото мислене, следване на инструкции, агентни способности и многоезична поддръжка.",
  "alibaba/qwen-3-30b.description": "Qwen3 е най-новото поколение от серията Qwen, предлагащо пълен набор от плътни и MoE модели. Обучен върху обширни данни, той постига пробиви в логическото мислене, следване на инструкции, агентни способности и многоезична поддръжка.",
  "alibaba/qwen-3-32b.description": "Qwen3 е най-новото поколение от серията Qwen, предлагащо пълен набор от плътни и MoE модели. Обучен върху обширни данни, той постига пробиви в логическото мислене, следване на инструкции, агентни способности и многоезична поддръжка.",
  "alibaba/qwen3-coder.description": "Qwen3-Coder-480B-A35B-Instruct е най-агентният кодов модел на Qwen, с отлични резултати при агентно програмиране, използване на браузър и други основни задачи, съпоставим с Claude Sonnet.",
  "amazon/nova-lite.description": "Многофункционален модел с изключително ниска цена и много бърза обработка на изображения, видео и текст.",
  "amazon/nova-micro.description": "Само текстов модел с ултраниска латентност и много ниска цена.",
  "amazon/nova-pro.description": "Многофункционален модел с отличен баланс между точност, скорост и цена за широк спектър от задачи.",
  "amazon/titan-embed-text-v2.description": "Amazon Titan Text Embeddings V2 е лек и ефективен многоезичен embedding модел, поддържащ 1024, 512 и 256 измерения.",
  "anthropic.claude-3-5-sonnet-20240620-v1:0.description": "Claude 3.5 Sonnet поставя нов стандарт в индустрията, надминавайки конкурентите и Claude 3 Opus в широки оценки, като същевременно запазва средно ниво на скорост и цена.",
  "anthropic.claude-3-5-sonnet-20241022-v2:0.description": "Claude 3.5 Sonnet поставя нов стандарт в индустрията, надминавайки конкурентите и Claude 3 Opus в широки оценки, като същевременно запазва средно ниво на скорост и цена.",
  "anthropic.claude-3-haiku-20240307-v1:0.description": "Claude 3 Haiku е най-бързият и най-компактен модел на Anthropic, осигуряващ почти мигновени отговори на прости заявки. Поддържа вход от изображения и прозорец на контекста от 200 хиляди токена.",
  "anthropic.claude-3-opus-20240229-v1:0.description": "Claude 3 Opus е най-мощният AI модел на Anthropic с водеща производителност при сложни задачи. Обработва отворени заявки и нови сценарии с изключителна плавност и човешко разбиране, поддържа вход от изображения и прозорец на контекста от 200 хиляди токена.",
  "anthropic.claude-3-sonnet-20240229-v1:0.description": "Claude 3 Sonnet балансира интелигентност и скорост за корпоративни натоварвания, предлага висока стойност при по-ниска цена. Поддържа вход от изображения и прозорец на контекста от 200 хиляди токена.",
  "anthropic.claude-instant-v1.description": "Бърз, икономичен и способен модел за ежедневен чат, анализ на текст, обобщение и въпроси по документи.",
  "anthropic.claude-v2.description": "Много способен модел за задачи от сложен диалог и творческо генериране до точно следване на инструкции.",
  "anthropic.claude-v2:1.description": "Обновен Claude 2 с удвоен прозорец на контекста и подобрена надеждност, по-ниска честота на халюцинации и по-точни отговори, базирани на доказателства, за дълги документи и RAG.",
  "anthropic/claude-3-haiku.description": "Claude 3 Haiku е най-бързият модел на Anthropic, проектиран за корпоративни натоварвания с по-дълги заявки. Бързо анализира големи документи като тримесечни отчети, договори или правни случаи на половин цена спрямо конкурентите.",
  "anthropic/claude-3-opus.description": "Claude 3 Opus е най-интелигентният модел на Anthropic с водеща производителност при сложни задачи, обработва отворени заявки и нови сценарии с изключителна плавност и човешко разбиране.",
  "anthropic/claude-3.5-haiku.description": "Claude 3.5 Haiku предлага подобрена скорост, точност при програмиране и използване на инструменти, подходящ за сценарии с високи изисквания към скорост и взаимодействие с инструменти.",
  "anthropic/claude-3.5-sonnet.description": "Claude 3.5 Sonnet е бърз и ефективен модел от семейството Sonnet, с подобрена производителност при програмиране и логическо мислене. Някои версии постепенно се заменят от Sonnet 3.7 и по-нови.",
  "anthropic/claude-3.7-sonnet.description": "Claude 3.7 Sonnet е подобрен модел от серията Sonnet с по-силно логическо мислене и програмиране, подходящ за сложни корпоративни задачи.",
  "anthropic/claude-haiku-4.5.description": "Claude Haiku 4.5 е високопроизводителен и бърз модел на Anthropic, осигуряващ много ниска латентност при запазване на висока точност.",
  "anthropic/claude-opus-4.1.description": "Opus 4.1 е висок клас модел на Anthropic, оптимизиран за програмиране, сложно логическо мислене и дълготрайни задачи.",
  "anthropic/claude-opus-4.5.description": "Claude Opus 4.5 е флагманският модел на Anthropic, съчетаващ върхова интелигентност с мащабируема производителност за сложни задачи с високо качество на разсъждение.",
  "anthropic/claude-opus-4.description": "Opus 4 е флагманският модел на Anthropic, проектиран за сложни задачи и корпоративни приложения.",
  "anthropic/claude-sonnet-4.5.description": "Claude Sonnet 4.5 е най-новият хибриден модел за логическо мислене на Anthropic, оптимизиран за сложни разсъждения и програмиране.",
  "anthropic/claude-sonnet-4.description": "Claude Sonnet 4 е хибриден модел за логическо мислене на Anthropic с комбинирани способности за мислене и бързи отговори.",
  "ascend-tribe/pangu-pro-moe.description": "Pangu-Pro-MoE 72B-A16B е разреден LLM с общо 72 милиарда и 16 милиарда активни параметри, базиран на групирана MoE (MoGE) архитектура. Групира експерти при избора и ограничава токените да активират равен брой експерти на група, което балансира натоварването и подобрява ефективността на внедряване върху Ascend.",
  "aya.description": "Aya 23 е многоезичен модел на Cohere, поддържащ 23 езика за разнообразни приложения.",
  "aya:35b.description": "Aya 23 е многоезичен модел на Cohere, поддържащ 23 езика за разнообразни приложения.",
  "azure-DeepSeek-R1-0528.description": "Разположен от Microsoft; DeepSeek R1 е надграден до DeepSeek-R1-0528. Актуализацията увеличава изчислителната мощ и оптимизациите след обучение, значително подобрявайки дълбочината на разсъждение и извеждането. Представя се отлично в тестове по математика, програмиране и логика, доближавайки се до водещи модели като O3 и Gemini 2.5 Pro.",
  "baichuan-m2-32b.description": "Baichuan M2 32B е MoE модел от Baichuan Intelligence със силни способности за разсъждение.",
  "baichuan/baichuan2-13b-chat.description": "Baichuan-13B е отворен, търговски използваем LLM с 13 милиарда параметри от Baichuan, постигайки водещи резултати за своя размер в авторитетни китайски и английски тестове.",
  "baidu/ERNIE-4.5-300B-A47B.description": "ERNIE-4.5-300B-A47B е MoE LLM на Baidu с общо 300 милиарда параметри и 47 милиарда активни на токен, балансирайки висока производителност и изчислителна ефективност. Като основен модел от серията ERNIE 4.5, той се отличава в разбиране, генериране, разсъждение и програмиране. Използва мултимодален хетерогенен MoE метод за предварително обучение с комбинирано текстово и визуално обучение за повишаване на цялостните способности, особено при следване на инструкции и световни знания.",
  "baidu/ernie-5.0-thinking-preview.description": "ERNIE 5.0 Thinking Preview е следващото поколение нативен мултимодален модел на Baidu, силен в мултимодално разбиране, следване на инструкции, създаване, фактологични въпроси и отговори и използване на инструменти.",
  "black-forest-labs/flux-1.1-pro.description": "FLUX 1.1 Pro е по-бърза, подобрена версия на FLUX Pro с отлично качество на изображенията и спазване на подканите.",
  "black-forest-labs/flux-dev.description": "FLUX Dev е развойната версия на FLUX за нетърговска употреба.",
  "black-forest-labs/flux-pro.description": "FLUX Pro е професионалният модел FLUX за висококачествено генериране на изображения.",
  "black-forest-labs/flux-schnell.description": "FLUX Schnell е бърз модел за генериране на изображения, оптимизиран за скорост.",
  "c4ai-aya-expanse-32b.description": "Aya Expanse е високопроизводителен многоезичен модел с 32 милиарда параметри, използващ обучение по инструкции, арбитраж на данни, обучение по предпочитания и сливане на модели, за да се конкурира с едноезични модели. Поддържа 23 езика.",
  "c4ai-aya-expanse-8b.description": "Aya Expanse е високопроизводителен многоезичен модел с 8 милиарда параметри, използващ обучение по инструкции, арбитраж на данни, обучение по предпочитания и сливане на модели, за да се конкурира с едноезични модели. Поддържа 23 езика.",
  "c4ai-aya-vision-32b.description": "Aya Vision е авангарден мултимодален модел, който се представя отлично в ключови езикови, текстови и визуални тестове. Поддържа 23 езика. Тази версия с 32 милиарда параметри е фокусирана върху най-високо ниво на многоезична производителност.",
  "c4ai-aya-vision-8b.description": "Aya Vision е авангарден мултимодален модел, който се представя отлично в ключови езикови, текстови и визуални тестове. Тази версия с 8 милиарда параметри е фокусирана върху ниска латентност и силна производителност.",
  "charglm-3.description": "CharGLM-3 е създаден за ролеви игри и емоционално общуване, поддържа ултра-дълга многозавойна памет и персонализиран диалог.",
  "charglm-4.description": "CharGLM-4 е създаден за ролеви игри и емоционално общуване, поддържа ултра-дълга многозавойна памет и персонализиран диалог.",
  "chatgpt-4o-latest.description": "ChatGPT-4o е динамичен модел, актуализиран в реално време, комбиниращ силно разбиране и генериране за мащабни приложения като клиентска поддръжка, образование и техническа помощ.",
  "claude-2.0.description": "Claude 2 предлага ключови подобрения за предприятия, включително водещ контекст от 200 000 токена, намалени халюцинации, системни подканвания и нова тестова функция: използване на инструменти.",
  "claude-2.1.description": "Claude 2 предлага ключови подобрения за предприятия, включително водещ контекст от 200 000 токена, намалени халюцинации, системни подканвания и нова тестова функция: използване на инструменти.",
  "claude-3-5-haiku-20241022.description": "Claude 3.5 Haiku е най-бързият модел от ново поколение на Anthropic. В сравнение с Claude 3 Haiku, той показва подобрение в различни умения и надминава предишния най-голям модел Claude 3 Opus в много интелигентни бенчмаркове.",
  "claude-3-5-haiku-latest.description": "Claude 3.5 Haiku осигурява бързи отговори за леки задачи.",
  "claude-3-7-sonnet-20250219.description": "Claude 3.7 Sonnet е най-интелигентният модел на Anthropic и първият хибриден модел за разсъждение на пазара. Той може да генерира почти мигновени отговори или разширено поетапно разсъждение, което потребителите могат да проследят. Sonnet е особено силен в програмиране, анализ на данни, визуални задачи и задачи за агенти.",
  "claude-3-7-sonnet-latest.description": "Claude 3.7 Sonnet е най-новият и най-способен модел на Anthropic за силно сложни задачи, отличаващ се с производителност, интелигентност, плавност и разбиране.",
  "claude-3-haiku-20240307.description": "Claude 3 Haiku е най-бързият и най-компактен модел на Anthropic, проектиран за почти мигновени отговори с бърза и точна производителност.",
  "claude-3-opus-20240229.description": "Claude 3 Opus е най-мощният модел на Anthropic за силно сложни задачи, отличаващ се с производителност, интелигентност, плавност и разбиране.",
  "claude-3-sonnet-20240229.description": "Claude 3 Sonnet балансира интелигентност и скорост за корпоративни натоварвания, осигурявайки висока полезност на по-ниска цена и надеждно мащабно внедряване.",
  "claude-haiku-4-5-20251001.description": "Claude Haiku 4.5 е най-бързият и най-интелигентен Haiku модел на Anthropic, с мълниеносна скорост и разширено разсъждение.",
  "claude-opus-4-1-20250805-thinking.description": "Claude Opus 4.1 Thinking е усъвършенстван вариант, който може да разкрие процеса си на разсъждение.",
  "claude-opus-4-1-20250805.description": "Claude Opus 4.1 е най-новият и най-способен модел на Anthropic за силно сложни задачи, отличаващ се с производителност, интелигентност, плавност и разбиране.",
  "claude-opus-4-20250514.description": "Claude Opus 4 е най-мощният модел на Anthropic за силно комплексни задачи, отличаващ се с висока производителност, интелигентност, плавност и разбиране.",
  "claude-opus-4-5-20251101.description": "Claude Opus 4.5 е флагманският модел на Anthropic, комбиниращ изключителна интелигентност с мащабируема производителност, идеален за сложни задачи, изискващи най-висококачествени отговори и разсъждение.",
  "claude-sonnet-4-20250514-thinking.description": "Claude Sonnet 4 Thinking може да генерира почти мигновени отговори или разширено стъпково мислене с видим процес.",
  "claude-sonnet-4-20250514.description": "Claude Sonnet 4 може да генерира почти мигновени отговори или разширено поетапно мислене с видим процес.",
  "claude-sonnet-4-5-20250929.description": "Claude Sonnet 4.5 е най-интелигентният модел на Anthropic досега.",
  "codegeex-4.description": "CodeGeeX-4 е мощен AI асистент за програмиране, който поддържа многоезични въпроси и допълване на код, повишавайки продуктивността на разработчиците.",
  "codegeex4-all-9b.description": "CodeGeeX4-ALL-9B е многоезичен модел за генериране на код, който поддържа допълване и създаване на код, интерпретиране, уеб търсене, извикване на функции и въпроси на ниво хранилище. Подходящ е за широк спектър от софтуерни сценарии и е водещ модел под 10 милиарда параметри.",
  "codegemma.description": "CodeGemma е лек модел за разнообразни програмни задачи, позволяващ бърза итерация и интеграция.",
  "codegemma:2b.description": "CodeGemma е лек модел за разнообразни програмни задачи, позволяващ бърза итерация и интеграция.",
  "codellama.description": "Code Llama е голям езиков модел, фокусиран върху генериране и обсъждане на код, с широка езикова поддръжка за работни процеси на разработчици.",
  "codellama/CodeLlama-34b-Instruct-hf.description": "Code Llama е голям езиков модел, фокусиран върху генериране и обсъждане на код, с широка езикова поддръжка за работни процеси на разработчици.",
  "codellama:13b.description": "Code Llama е голям езиков модел, фокусиран върху генериране и обсъждане на код, с широка езикова поддръжка за работни процеси на разработчици.",
  "codellama:34b.description": "Code Llama е голям езиков модел, фокусиран върху генериране и обсъждане на код, с широка езикова поддръжка за работни процеси на разработчици.",
  "codellama:70b.description": "Code Llama е голям езиков модел, фокусиран върху генериране и обсъждане на код, с широка езикова поддръжка за работни процеси на разработчици.",
  "codeqwen.description": "CodeQwen1.5 е голям езиков модел, обучен върху обширни данни от код, създаден за сложни програмни задачи.",
  "codestral-latest.description": "Codestral е нашият най-усъвършенстван модел за програмиране; версия 2 (януари 2025) е насочена към задачи с ниска латентност и висока честота като FIM, корекция на код и генериране на тестове.",
  "codestral.description": "Codestral е първият модел за програмиране на Mistral AI, осигуряващ силна поддръжка за генериране на код.",
  "codex-mini-latest.description": "codex-mini-latest е фино настроен o4-mini модел за Codex CLI. За директна употреба чрез API се препоръчва gpt-4.1.",
  "cogito-2.1:671b.description": "Cogito v2.1 671B е отворен модел от САЩ, свободен за търговска употреба, с производителност, съпоставима с водещите модели, по-висока ефективност при разсъждение с токени, 128k контекст и силни общи способности.",
  "cogview-4.description": "CogView-4 е първият отворен модел на Zhipu за преобразуване на текст в изображение, който може да генерира китайски знаци. Подобрява семантичното разбиране, качеството на изображенията и рендирането на китайски/английски текст, поддържа двуезични подкани с произволна дължина и може да генерира изображения с всякаква резолюция в зададени граници.",
  "cohere-command-r-plus.description": "Command R+ е усъвършенстван модел, оптимизиран за RAG, създаден за корпоративни натоварвания.",
  "cohere-command-r.description": "Command R е мащабируем генеративен модел, проектиран за RAG и използване на инструменти, позволяващ продукционен AI.",
  "cohere/Cohere-command-r-plus.description": "Command R+ е усъвършенстван модел, оптимизиран за RAG, създаден за корпоративни натоварвания.",
  "cohere/Cohere-command-r.description": "Command R е мащабируем генеративен модел, проектиран за RAG и използване на инструменти, позволяващ продукционен AI.",
  "cohere/command-a.description": "Command A е най-мощният модел на Cohere досега, отличаващ се в използване на инструменти, агенти, RAG и многоезични сценарии. Има 256K контекст, работи само с два GPU и осигурява 150% по-висока пропускателност от Command R+ 08-2024.",
  "cohere/command-r-plus.description": "Command R+ е най-новият LLM на Cohere, оптимизиран за чат и дълъг контекст, с цел изключителна производителност, за да могат компаниите да преминат от прототипи към продукция.",
  "cohere/command-r.description": "Command R е оптимизиран за чат и задачи с дълъг контекст, позициониран като „мащабируем“ модел, който балансира висока производителност и точност, за да могат компаниите да преминат от прототипи към продукция.",
  "cohere/embed-v4.0.description": "Модел, който класифицира или преобразува текст, изображения или смесено съдържание в ембединг представяния.",
  "comfyui/flux-dev.description": "FLUX.1 Dev е висококачествен модел за преобразуване на текст в изображение (10–50 стъпки), идеален за премиум творчески и артистични резултати.",
  "comfyui/flux-kontext-dev.description": "FLUX.1 Kontext-dev е модел за редактиране на изображения, който поддържа редакции, водени от текст, включително локални промени и трансфер на стил.",
  "comfyui/flux-krea-dev.description": "FLUX.1 Krea-dev е модел за преобразуване на текст в изображение с вградени филтри за безопасност, съвместно разработен с Krea.",
  "comfyui/flux-schnell.description": "FLUX.1 Schnell е ултра-бърз модел за преобразуване на текст в изображение, който генерира висококачествени изображения за 1–4 стъпки, идеален за реално време и бързо прототипиране.",
  "comfyui/stable-diffusion-15.description": "Stable Diffusion 1.5 е класически модел 512x512 за преобразуване на текст в изображение, идеален за бързо прототипиране и творчески експерименти.",
  "comfyui/stable-diffusion-35-inclclip.description": "Stable Diffusion 3.5 с вградени CLIP/T5 енкодери не изисква външни файлове, подходящ за модели като sd3.5_medium_incl_clips с по-ниска консумация на ресурси.",
  "comfyui/stable-diffusion-35.description": "Stable Diffusion 3.5 е модел от ново поколение за преобразуване на текст в изображение с варианти Large и Medium. Изисква външни CLIP енкодери и осигурява отлично качество на изображенията и съответствие с подкани.",
  "comfyui/stable-diffusion-custom-refiner.description": "Персонализиран SDXL модел за преобразуване на изображение в изображение. Използвайте custom_sd_lobe.safetensors като име на файл; ако имате VAE, използвайте custom_sd_vae_lobe.safetensors. Поставете файловете в съответните папки на Comfy.",
  "comfyui/stable-diffusion-custom.description": "Персонализиран SD модел за преобразуване на текст в изображение. Използвайте custom_sd_lobe.safetensors като име на файл; ако имате VAE, използвайте custom_sd_vae_lobe.safetensors. Поставете файловете в съответните папки на Comfy.",
  "comfyui/stable-diffusion-refiner.description": "SDXL модел за преобразуване на изображение в изображение, който извършва висококачествени трансформации от входни изображения, поддържайки трансфер на стил, възстановяване и творчески вариации.",
  "comfyui/stable-diffusion-xl.description": "SDXL е модел за преобразуване на текст в изображение, поддържащ висока резолюция 1024x1024 с по-добро качество и детайлност на изображенията.",
  "command-a-03-2025.description": "Command A е най-способният ни модел досега, отличаващ се в използването на инструменти, агенти, RAG и многоезични сценарии. Разполага с контекстен прозорец от 256K, работи само с два GPU и осигурява 150% по-висока пропускателна способност от Command R+ 08-2024.",
  "command-light-nightly.description": "За да съкратим времето между основните версии, предлагаме нощни билдове на Command. За серията command-light това е command-light-nightly. Това е най-новата, най-експериментална (и потенциално нестабилна) версия, която се обновява редовно без предизвестие, затова не се препоръчва за продукционна употреба.",
  "command-light.description": "По-малък и по-бърз вариант на Command, който е почти толкова способен, но с по-висока скорост.",
  "command-nightly.description": "За да съкратим времето между основните версии, предлагаме нощни билдове на Command. За серията Command това е command-nightly. Това е най-новата, най-експериментална (и потенциално нестабилна) версия, която се обновява редовно без предизвестие, затова не се препоръчва за продукционна употреба.",
  "command-r-03-2024.description": "Command R е чат модел, следващ инструкции, с по-високо качество, по-голяма надеждност и по-дълъг контекстен прозорец от предишните модели. Поддържа сложни работни потоци като генериране на код, RAG, използване на инструменти и агенти.",
  "command-r-08-2024.description": "command-r-08-2024 е обновен модел Command R, пуснат през август 2024 г.",
  "command-r-plus-04-2024.description": "command-r-plus е псевдоним на command-r-plus-04-2024, така че използването на command-r-plus в API-то сочи към този модел.",
  "command-r-plus-08-2024.description": "Command R+ е чат модел, следващ инструкции, с по-високо качество, по-голяма надеждност и по-дълъг контекстен прозорец от предишните модели. Най-подходящ е за сложни RAG работни потоци и многоетапно използване на инструменти.",
  "command-r-plus.description": "Command R+ е високопроизводителен LLM, създаден за реални бизнес сценарии и сложни приложения.",
  "command-r.description": "Command R е LLM, оптимизиран за чат и задачи с дълъг контекст, идеален за динамично взаимодействие и управление на знания.",
  "command-r7b-12-2024.description": "command-r7b-12-2024 е малка, ефективна актуализация, пусната през декември 2024 г. Отличава се в RAG, използване на инструменти и задачи с агенти, изискващи сложно, многоетапно разсъждение.",
  "command.description": "Чат модел, следващ инструкции, който осигурява по-високо качество и надеждност при езикови задачи, с по-дълъг контекстен прозорец от базовите ни генеративни модели.",
  "computer-use-preview.description": "computer-use-preview е специализиран модел за инструмента „computer use“, обучен да разбира и изпълнява задачи, свързани с компютри.",
  "dall-e-2.description": "Второ поколение DALL·E модел с по-реалистично и точно генериране на изображения и 4× по-висока резолюция от първото поколение.",
  "dall-e-3.description": "Най-новият модел DALL·E, пуснат през ноември 2023 г., поддържа по-реалистично и точно генериране на изображения с по-силни детайли.",
  "databricks/dbrx-instruct.description": "DBRX Instruct предлага изключително надеждно следване на инструкции в различни индустрии.",
  "deepseek-ai/DeepSeek-OCR.description": "DeepSeek-OCR е визионно-езиков модел от DeepSeek AI, фокусиран върху OCR и „контекстуална оптична компресия“. Изследва компресиране на контекст от изображения, ефективно обработва документи и ги преобразува в структуриран текст (напр. Markdown). Прецизно разпознава текст в изображения, подходящ за дигитализация на документи, извличане на текст и структурирана обработка.",
  "deepseek-ai/DeepSeek-R1-0528-Qwen3-8B.description": "DeepSeek-R1-0528-Qwen3-8B дестилира chain-of-thought от DeepSeek-R1-0528 в Qwen3 8B Base. Постига SOTA сред отворените модели, надминавайки Qwen3 8B с 10% на AIME 2024 и съвпада с производителността на Qwen3-235B-thinking. Отличава се в математическо разсъждение, програмиране и логически тестове. Споделя архитектурата на Qwen3-8B, но използва токенизатора на DeepSeek-R1-0528.",
  "deepseek-ai/DeepSeek-R1-0528.description": "DeepSeek R1 използва допълнителни изчисления и алгоритмични оптимизации след обучение, за да задълбочи разсъждението. Представя се силно в бенчмаркове по математика, програмиране и логика, доближавайки се до водещи модели като o3 и Gemini 2.5 Pro.",
  "deepseek-ai/DeepSeek-R1-Distill-Llama-70B.description": "Дестилираните модели DeepSeek-R1 използват RL и cold-start данни за подобряване на разсъждението и поставят нови бенчмарк стандарти за отворени модели с много задачи.",
  "deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B.description": "Дестилираните модели DeepSeek-R1 използват RL и cold-start данни за подобряване на разсъждението и поставят нови бенчмарк стандарти за отворени модели с много задачи.",
  "deepseek-ai/DeepSeek-R1-Distill-Qwen-14B.description": "Дестилираните модели DeepSeek-R1 използват RL и cold-start данни за подобряване на разсъждението и поставят нови бенчмарк стандарти за отворени модели с много задачи.",
  "deepseek-ai/DeepSeek-R1-Distill-Qwen-32B.description": "DeepSeek-R1-Distill-Qwen-32B е дестилиран от Qwen2.5-32B и фино настроен върху 800K подбрани проби от DeepSeek-R1. Отличава се в математика, програмиране и разсъждение, постигайки силни резултати на AIME 2024, MATH-500 (94.3% точност) и GPQA Diamond.",
  "deepseek-ai/DeepSeek-R1-Distill-Qwen-7B.description": "DeepSeek-R1-Distill-Qwen-7B е дестилиран от Qwen2.5-Math-7B и фино настроен върху 800K подбрани проби от DeepSeek-R1. Представя се силно с 92.8% на MATH-500, 55.5% на AIME 2024 и рейтинг 1189 в CodeForces за 7B модел.",
  "deepseek-ai/DeepSeek-R1.description": "DeepSeek-R1 подобрява разсъждението с RL и cold-start данни, поставяйки нови бенчмарк стандарти за отворени модели с много задачи и надминава OpenAI-o1-mini.",
  "deepseek-ai/DeepSeek-V2.5.description": "DeepSeek-V2.5 надгражда DeepSeek-V2-Chat и DeepSeek-Coder-V2-Instruct, комбинирайки общи и кодови способности. Подобрява писането и следването на инструкции за по-добро съответствие с предпочитанията и показва значителни подобрения в AlpacaEval 2.0, ArenaHard, AlignBench и MT-Bench.",
  "deepseek-ai/DeepSeek-V3.1-Terminus.description": "DeepSeek-V3.1-Terminus е обновен модел V3.1, позициониран като хибриден агентен LLM. Отстранява докладвани от потребители проблеми и подобрява стабилността, езиковата последователност и намалява смесените китайски/английски и аномални символи. Интегрира режими на мислене и немислене с шаблони за чат за гъвкаво превключване. Подобрява и производителността на Code Agent и Search Agent за по-надеждно използване на инструменти и многоетапни задачи.",
  "deepseek-ai/DeepSeek-V3.1.description": "DeepSeek V3.1 използва хибридна архитектура за разсъждение и поддържа както мислещ, така и немислещ режим.",
  "deepseek-ai/DeepSeek-V3.2-Exp.description": "DeepSeek-V3.2-Exp е експериментална версия V3.2, която служи като мост към следващата архитектура. Добавя DeepSeek Sparse Attention (DSA) върху V3.1-Terminus за подобряване на ефективността при обучение и извеждане с дълъг контекст, с оптимизации за използване на инструменти, разбиране на дълги документи и многoетапно разсъждение. Идеален е за изследване на по-висока ефективност при разсъждение с големи контекстуални бюджети.",
  "deepseek-ai/DeepSeek-V3.description": "DeepSeek-V3 е MoE модел с 671 милиарда параметъра, използващ MLA и DeepSeekMoE с балансирано натоварване без загуби за ефективно обучение и извеждане. Предварително обучен върху 14.8 трилиона висококачествени токени със SFT и RL, той превъзхожда други отворени модели и се доближава до водещите затворени модели.",
  "deepseek-ai/deepseek-llm-67b-chat.description": "DeepSeek LLM Chat (67B) е иновативен модел, предлагащ дълбоко езиково разбиране и интеракция.",
  "deepseek-ai/deepseek-r1.description": "Модел от ново поколение с висока ефективност, силен в разсъждение, математика и програмиране.",
  "deepseek-ai/deepseek-v3.1-terminus.description": "DeepSeek V3.1 е модел за разсъждение от ново поколение с по-силни способности за сложни разсъждения и верига от мисли за задълбочени аналитични задачи.",
  "deepseek-ai/deepseek-v3.1.description": "DeepSeek V3.1 е модел за разсъждение от ново поколение с по-силни способности за сложни разсъждения и верига от мисли за задълбочени аналитични задачи.",
  "deepseek-ai/deepseek-vl2.description": "DeepSeek-VL2 е MoE модел за визия и език, базиран на DeepSeekMoE-27B със слаба активация, постигайки висока производителност с едва 4.5 милиарда активни параметъра. Отличава се в визуални въпроси и отговори, OCR, разбиране на документи/таблици/графики и визуално привързване.",
  "deepseek-chat.description": "Нов модел с отворен код, комбиниращ общи и програмни способности. Съхранява общия диалогов стил на чат модела и силното програмиране на кодовия модел, с по-добро съответствие на предпочитанията. DeepSeek-V2.5 също така подобрява писането и следването на инструкции.",
  "deepseek-coder-33B-instruct.description": "DeepSeek Coder 33B е езиков модел за програмиране, обучен върху 2 трилиона токени (87% код, 13% китайски/английски текст). Въвежда 16K контекстен прозорец и задачи за попълване в средата, осигурявайки допълване на код на ниво проект и попълване на фрагменти.",
  "deepseek-coder-v2.description": "DeepSeek Coder V2 е отворен MoE модел за програмиране, който се представя на ниво GPT-4 Turbo.",
  "deepseek-coder-v2:236b.description": "DeepSeek Coder V2 е отворен MoE модел за програмиране, който се представя на ниво GPT-4 Turbo.",
  "deepseek-ocr.description": "DeepSeek-OCR е визионно-езиков модел от DeepSeek AI, фокусиран върху OCR и „контекстуална оптична компресия“. Изследва компресиране на контекстуална информация от изображения, ефективно обработва документи и ги преобразува в структурирани текстови формати като Markdown. Прецизно разпознава текст в изображения, което го прави идеален за дигитализация на документи, извличане на текст и структурирана обработка.",
  "deepseek-r1-0528.description": "Пълен модел с 685 милиарда параметъра, пуснат на 28.05.2025. DeepSeek-R1 използва мащабно подсилено обучение след предварителното обучение, значително подобрявайки разсъждението с минимални етикетирани данни и се представя силно в математика, програмиране и езиково разсъждение.",
  "deepseek-r1-250528.description": "DeepSeek R1 250528 е пълният модел за разсъждение на DeepSeek-R1, предназначен за трудни математически и логически задачи.",
  "deepseek-r1-70b-fast-online.description": "DeepSeek R1 70B бързо издание с търсене в реално време в уеб, осигуряващо по-бързи отговори при запазване на производителността.",
  "deepseek-r1-70b-online.description": "DeepSeek R1 70B стандартно издание с търсене в реално време в уеб, подходящо за актуални чат и текстови задачи.",
  "deepseek-r1-distill-llama-70b.description": "DeepSeek R1 Distill Llama 70B комбинира разсъждението на R1 с екосистемата на Llama.",
  "deepseek-r1-distill-llama-8b.description": "DeepSeek-R1-Distill-Llama-8B е дистилиран от Llama-3.1-8B с използване на изходи от DeepSeek R1.",
  "deepseek-r1-distill-llama.description": "deepseek-r1-distill-llama е дистилиран от DeepSeek-R1 върху Llama.",
  "deepseek-r1-distill-qianfan-70b.description": "DeepSeek R1 Distill Qianfan 70B е дистилиран модел на R1, базиран на Qianfan-70B с висока стойност.",
  "deepseek-r1-distill-qianfan-8b.description": "DeepSeek R1 Distill Qianfan 8B е дистилиран модел на R1, базиран на Qianfan-8B за малки и средни приложения.",
  "deepseek-r1-distill-qianfan-llama-70b.description": "DeepSeek R1 Distill Qianfan Llama 70B е дистилиран модел на R1, базиран на Llama-70B.",
  "deepseek-r1-distill-qwen-1.5b.description": "DeepSeek R1 Distill Qwen 1.5B е ултралек дистилиран модел за среди с много ниски ресурси.",
  "deepseek-r1-distill-qwen-14b.description": "DeepSeek R1 Distill Qwen 14B е среден по размер дистилиран модел за многосценарийно внедряване.",
  "deepseek-r1-distill-qwen-32b.description": "DeepSeek R1 Distill Qwen 32B е дистилиран модел на R1, базиран на Qwen-32B, балансиращ производителност и разходи.",
  "deepseek-r1-distill-qwen-7b.description": "DeepSeek R1 Distill Qwen 7B е лек дистилиран модел за edge и частни корпоративни среди.",
  "deepseek-r1-distill-qwen.description": "deepseek-r1-distill-qwen е дистилиран от DeepSeek-R1 върху Qwen.",
  "deepseek-r1-fast-online.description": "Пълна бърза версия на DeepSeek R1 с търсене в реално време в уеб, комбинираща възможности от мащаб 671B и по-бърз отговор.",
  "deepseek-r1-online.description": "Пълна версия на DeepSeek R1 с 671 милиарда параметъра и търсене в реално време в уеб, предлагаща по-силно разбиране и генериране.",
  "deepseek-r1.description": "DeepSeek-R1 използва данни от студен старт преди подсиленото обучение и се представя наравно с OpenAI-o1 в математика, програмиране и разсъждение.",
  "deepseek-reasoner.description": "Режимът на мислене DeepSeek V3.2 извежда верига от мисли преди крайния отговор за повишена точност.",
  "deepseek-v2.description": "DeepSeek V2 е ефективен MoE модел за икономична обработка.",
  "deepseek-v2:236b.description": "DeepSeek V2 236B е модел на DeepSeek, фокусиран върху програмиране, с висока производителност при генериране на код.",
  "deepseek-v3-0324.description": "DeepSeek-V3-0324 е MoE модел с 671 милиарда параметъра, с изключителни способности в програмиране, технически задачи, разбиране на контекст и обработка на дълги текстове.",
  "deepseek-v3.1-terminus.description": "DeepSeek-V3.1-Terminus е оптимизиран за терминални устройства LLM от DeepSeek.",
  "deepseek-v3.1-think-250821.description": "DeepSeek V3.1 Think 250821 е модел за дълбоко разсъждение, съответстващ на версията Terminus, създаден за високопроизводително разсъждение.",
  "deepseek-v3.1.description": "DeepSeek-V3.1 е нов хибриден модел за разсъждение от DeepSeek, поддържащ както мислещ, така и немислещ режим и предлагащ по-висока ефективност на мисленето от DeepSeek-R1-0528. Оптимизациите след обучение значително подобряват използването на инструменти от агенти и изпълнението на задачи. Поддържа 128k контекстен прозорец и до 64k изходни токена.",
  "deepseek-v3.1:671b.description": "DeepSeek V3.1 е модел за разсъждение от ново поколение с подобрени способности за сложни разсъждения и верига от мисли, подходящ за задачи, изискващи задълбочен анализ.",
  "deepseek-v3.2-exp.description": "deepseek-v3.2-exp въвежда разредено внимание за подобряване на ефективността при обучение и извеждане върху дълги текстове, на по-ниска цена от deepseek-v3.1.",
  "deepseek-v3.2-think.description": "DeepSeek V3.2 Think е пълен модел за дълбоко мислене с по-силно дълговерижно разсъждение.",
  "deepseek-v3.2.description": "DeepSeek-V3.2 е първият хибриден модел за разсъждение от DeepSeek, който интегрира мислене в използването на инструменти. С ефективна архитектура за пестене на изчислителни ресурси, мащабно подсилено обучение за повишаване на способностите и мащабни синтетични задачи за силна обобщаемост, той постига производителност, сравнима с GPT-5-High. Дължината на изхода е значително намалена, което води до по-ниски изчислителни разходи и по-кратко време за изчакване от страна на потребителя.",
  "deepseek-v3.description": "DeepSeek-V3 е мощен MoE модел с общо 671 милиарда параметъра и 37 милиарда активни на токен.",
  "deepseek-vl2-small.description": "DeepSeek VL2 Small е лек мултимодален вариант за среди с ограничени ресурси и висока едновременност.",
  "deepseek-vl2.description": "DeepSeek VL2 е мултимодален модел за разбиране на изображения и текст и прецизни визуални въпроси и отговори.",
  "deepseek/deepseek-chat-v3-0324.description": "DeepSeek V3 е MoE модел с 685 милиарда параметъра и най-новата итерация от водещата чат серия на DeepSeek.\n\nНадгражда [DeepSeek V3](/deepseek/deepseek-chat-v3) и се представя отлично в различни задачи.",
  "deepseek/deepseek-chat-v3-0324:free.description": "DeepSeek V3 е MoE модел с 685 милиарда параметъра и най-новата итерация от водещата чат серия на DeepSeek.\n\nНадгражда [DeepSeek V3](/deepseek/deepseek-chat-v3) и се представя отлично в различни задачи.",
  "deepseek/deepseek-chat-v3.1.description": "DeepSeek-V3.1 е хибриден модел за разсъждение с дълъг контекст от DeepSeek, поддържащ смесени режими на мислене/без мислене и интеграция с инструменти.",
  "deepseek/deepseek-chat.description": "DeepSeek-V3 е високоефективен хибриден модел за разсъждение от DeepSeek, предназначен за сложни задачи и интеграция с инструменти.",
  "deepseek/deepseek-r1-0528.description": "DeepSeek R1 0528 е обновен вариант, фокусиран върху отворен достъп и по-дълбоко разсъждение.",
  "deepseek/deepseek-r1-0528:free.description": "DeepSeek-R1 значително подобрява разсъждението с минимално етикетирани данни и извежда верига от мисли преди крайния отговор за повишаване на точността.",
  "deepseek/deepseek-r1-distill-llama-70b.description": "DeepSeek R1 Distill Llama 70B е дестилиран LLM, базиран на Llama 3.3 70B, фино настроен с изходи от DeepSeek R1 за постигане на конкурентна производителност спрямо водещите модели.",
  "deepseek/deepseek-r1-distill-llama-8b.description": "DeepSeek R1 Distill Llama 8B е дестилиран LLM, базиран на Llama-3.1-8B-Instruct, обучен с изходи от DeepSeek R1.",
  "deepseek/deepseek-r1-distill-qwen-14b.description": "DeepSeek R1 Distill Qwen 14B е дестилиран LLM, базиран на Qwen 2.5 14B, обучен с изходи от DeepSeek R1. Надминава OpenAI o1-mini в множество бенчмаркове, постигайки водещи резултати сред плътните модели. Основни резултати:\nAIME 2024 pass@1: 69.7\nMATH-500 pass@1: 93.9\nCodeForces рейтинг: 1481\nФиното настройване с изходи от DeepSeek R1 осигурява конкурентна производителност спрямо по-големи модели.",
  "deepseek/deepseek-r1-distill-qwen-32b.description": "DeepSeek R1 Distill Qwen 32B е дестилиран LLM, базиран на Qwen 2.5 32B, обучен с изходи от DeepSeek R1. Надминава OpenAI o1-mini в множество бенчмаркове, постигайки водещи резултати сред плътните модели. Основни резултати:\nAIME 2024 pass@1: 72.6\nMATH-500 pass@1: 94.3\nCodeForces рейтинг: 1691\nФиното настройване с изходи от DeepSeek R1 осигурява конкурентна производителност спрямо по-големи модели.",
  "deepseek/deepseek-r1.description": "DeepSeek R1 е обновен до DeepSeek-R1-0528. С повече изчислителна мощ и алгоритмични оптимизации след обучение, значително подобрява дълбочината и способността за разсъждение. Представя се отлично в бенчмаркове по математика, програмиране и логика, доближавайки се до водещи модели като o3 и Gemini 2.5 Pro.",
  "deepseek/deepseek-r1/community.description": "DeepSeek R1 е най-новият модел с отворен код, пуснат от екипа на DeepSeek, с много силна производителност в разсъждението, особено в математика, програмиране и логически задачи, сравним с OpenAI o1.",
  "deepseek/deepseek-r1:free.description": "DeepSeek-R1 значително подобрява разсъждението с минимално етикетирани данни и извежда верига от мисли преди крайния отговор за повишаване на точността.",
  "deepseek/deepseek-reasoner.description": "DeepSeek-V3 Thinking (reasoner) е експериментален модел за разсъждение от DeepSeek, подходящ за задачи с висока сложност.",
  "deepseek/deepseek-v3.1-base.description": "DeepSeek V3.1 Base е подобрена версия на модела DeepSeek V3.",
  "deepseek/deepseek-v3.description": "Бърз универсален LLM с подобрено разсъждение.",
  "deepseek/deepseek-v3/community.description": "DeepSeek-V3 постига значителен пробив в скоростта на разсъждение спрямо предишни модели. Класира се на първо място сред моделите с отворен код и съперничи на най-напредналите затворени модели. DeepSeek-V3 използва Multi-Head Latent Attention (MLA) и архитектурата DeepSeekMoE, и двете напълно валидирани в DeepSeek-V2. Въвежда и беззагубна помощна стратегия за балансиране на натоварването и цел за обучение с предсказване на множество токени за по-силна производителност.",
  "deepseek_r1.description": "DeepSeek-R1 е модел за разсъждение, управляван от обучение чрез подсилване, който адресира проблеми с повторения и четимост. Преди RL използва начални данни за допълнително подобряване на разсъждението. Сравнява се с OpenAI-o1 в задачи по математика, програмиране и логика, с внимателно проектирано обучение за подобрени резултати.",
  "deepseek_r1_distill_llama_70b.description": "DeepSeek-R1-Distill-Llama-70B е дестилиран от Llama-3.3-70B-Instruct. Като част от серията DeepSeek-R1, е фино настроен с примери, генерирани от DeepSeek-R1, и се представя силно в математика, програмиране и разсъждение.",
  "deepseek_r1_distill_qwen_14b.description": "DeepSeek-R1-Distill-Qwen-14B е дестилиран от Qwen2.5-14B и фино настроен с 800K подбрани примера, генерирани от DeepSeek-R1, осигуряващ силно разсъждение.",
  "deepseek_r1_distill_qwen_32b.description": "DeepSeek-R1-Distill-Qwen-32B е дестилиран от Qwen2.5-32B и фино настроен с 800K подбрани примера, генерирани от DeepSeek-R1, отличаващ се в математика, програмиране и разсъждение.",
  "devstral-2:123b.description": "Devstral 2 123B се отличава с използването на инструменти за изследване на кодови бази, редактиране на множество файлове и поддръжка на агенти за софтуерно инженерство.",
  "doubao-1.5-lite-32k.description": "Doubao-1.5-lite е нов лек модел с изключително бърз отговор, предоставящ първокласно качество и ниска латентност.",
  "doubao-1.5-pro-256k.description": "Doubao-1.5-pro-256k е цялостен ъпгрейд на Doubao-1.5-Pro, подобряващ общата производителност с 10%. Поддържа контекстен прозорец от 256k и до 12k изходни токена, осигурявайки по-висока производителност, по-голям прозорец и отлична стойност за по-широки приложения.",
  "doubao-1.5-pro-32k.description": "Doubao-1.5-pro е флагмански модел от ново поколение с цялостни подобрения, отличаващ се в знания, програмиране и разсъждение.",
  "doubao-1.5-thinking-pro-m.description": "Doubao-1.5 е нов дълбок разсъждаващ модел (версия m включва родно мултимодално дълбоко разсъждение), който се отличава в математика, програмиране, научно разсъждение и общи задачи като творческо писане. Достига или доближава водещи резултати в бенчмаркове като AIME 2024, Codeforces и GPQA. Поддържа контекстен прозорец от 128k и 16k изход.",
  "doubao-1.5-thinking-pro.description": "Doubao-1.5 е нов дълбок разсъждаващ модел, който се отличава в математика, програмиране, научно разсъждение и общи задачи като творческо писане. Достига или доближава водещи резултати в бенчмаркове като AIME 2024, Codeforces и GPQA. Поддържа контекстен прозорец от 128k и 16k изход.",
  "doubao-1.5-thinking-vision-pro.description": "Нов визуален дълбок разсъждаващ модел със засилено мултимодално разбиране и разсъждение, постигайки SOTA резултати в 37 от 59 публични бенчмарка.",
  "doubao-1.5-ui-tars.description": "Doubao-1.5-UI-TARS е роден агентен модел, фокусиран върху графичен интерфейс, който безпроблемно взаимодейства с интерфейси чрез човешко възприятие, разсъждение и действие.",
  "doubao-1.5-vision-lite.description": "Doubao-1.5-vision-lite е подобрен мултимодален модел, който поддържа изображения с всякаква резолюция и екстремни съотношения, подобрявайки визуалното разсъждение, разпознаването на документи, разбиране на детайли и следване на инструкции. Поддържа контекстен прозорец от 128k и до 16k изходни токена.",
  "doubao-1.5-vision-pro-32k.description": "Doubao-1.5-vision-pro е подобрен мултимодален модел, който поддържа изображения с всякаква резолюция и екстремни съотношения, подобрявайки визуалното разсъждение, разпознаването на документи, разбиране на детайли и следване на инструкции.",
  "doubao-1.5-vision-pro.description": "Doubao-1.5-vision-pro е подобрен мултимодален модел, който поддържа изображения с всякаква резолюция и екстремни съотношения, подобрявайки визуалното разсъждение, разпознаването на документи, разбиране на детайли и следване на инструкции.",
  "doubao-lite-128k.description": "Изключително бърз отговор с по-добра стойност, предлагащ по-гъвкави възможности в различни сценарии. Поддържа разсъждение и фина настройка с контекстен прозорец от 128k.",
  "doubao-lite-32k.description": "Изключително бърз отговор с по-добра стойност, предлагащ по-гъвкави възможности в различни сценарии. Поддържа разсъждение и фина настройка с контекстен прозорец от 32k.",
  "doubao-lite-4k.description": "Изключително бърз отговор с по-добра стойност, предлагащ по-гъвкави възможности в различни сценарии. Поддържа разсъждение и фина настройка с контекстен прозорец от 4k.",
  "doubao-pro-256k.description": "Най-добре представящият се флагмански модел за сложни задачи, с отлични резултати в справочни въпроси, обобщение, създаване, класификация на текст и ролеви игри. Поддържа разсъждение и фина настройка с контекстен прозорец от 256k.",
  "doubao-pro-32k.description": "Най-добре представящият се флагмански модел за сложни задачи, с отлични резултати в справочни въпроси, обобщение, създаване, класификация на текст и ролеви игри. Поддържа разсъждение и фина настройка с контекстен прозорец от 32k.",
  "doubao-seed-1.6-flash.description": "Doubao-Seed-1.6-flash е изключително бърз мултимодален дълбок разсъждаващ модел с TPOT до 10ms. Поддържа текст и визия, надминава предишния lite модел в разбиране на текст и съответства на конкурентни pro модели във визия. Поддържа контекстен прозорец от 256k и до 16k изходни токена.",
  "doubao-seed-1.6-lite.description": "Doubao-Seed-1.6-lite е нов мултимодален дълбок разсъждаващ модел с регулируемо усилие на разсъждение (Минимално, Ниско, Средно, Високо), осигуряващ по-добра стойност и силен избор за обичайни задачи, с контекстен прозорец до 256k.",
  "doubao-seed-1.6-thinking.description": "Doubao-Seed-1.6 значително засилва разсъждението, допълнително подобрявайки основните способности в програмиране, математика и логическо мислене спрямо Doubao-1.5-thinking-pro, като добавя и разбиране на визия. Поддържа контекстен прозорец от 256k и до 16k изходни токена.",
  "doubao-seed-1.6-vision.description": "Doubao-Seed-1.6-vision е визуален дълбок разсъждаващ модел, който осигурява по-силно мултимодално разбиране и разсъждение за образование, преглед на изображения, инспекция/сигурност и AI търсене с въпроси и отговори. Поддържа контекстен прозорец от 256k и до 64k изходни токена.",
  "doubao-seed-1.6.description": "Doubao-Seed-1.6 е нов мултимодален дълбок разсъждаващ модел с режими auto, thinking и non-thinking. В non-thinking режим значително превъзхожда Doubao-1.5-pro/250115. Поддържа контекстен прозорец от 256k и до 16k изходни токена.",
  "doubao-seed-1.8.description": "Doubao-Seed-1.8 притежава по-силни мултимодални способности и способности на агент, поддържа вход от текст/изображения/видео и контекстно кеширане, осигурявайки по-добра производителност при сложни задачи.",
  "doubao-seed-code.description": "Doubao-Seed-Code е дълбоко оптимизиран за агентно програмиране, поддържа мултимодални входове (текст/изображение/видео) и контекстен прозорец от 256k, съвместим е с Anthropic API и е подходящ за програмиране, разбиране на визия и работни потоци с агенти.",
  "doubao-seededit-3-0-i2i-250628.description": "Моделът за изображения на Doubao от ByteDance Seed поддържа вход от текст и изображения с високо контролируемо, висококачествено генериране на изображения. Поддържа редактиране на изображения, водено от текст, с размери на изхода между 512 и 1536 по дългата страна.",
  "doubao-seedream-3-0-t2i-250415.description": "Seedream 3.0 е модел за генериране на изображения от ByteDance Seed, поддържащ вход от текст и изображения с високо контролируемо, висококачествено генериране на изображения. Генерира изображения от текстови подсказки.",
  "doubao-seedream-4-0-250828.description": "Seedream 4.0 е модел за генериране на изображения от ByteDance Seed, поддържащ вход от текст и изображения с високо контролируемо, висококачествено генериране на изображения. Генерира изображения от текстови подсказки.",
  "doubao-vision-lite-32k.description": "Doubao-vision е мултимодален модел от Doubao със силно разбиране и разсъждение върху изображения, както и точно следване на инструкции. Представя се добре при извличане на текст от изображения и задачи за разсъждение, базирани на изображения, позволявайки по-сложни и широки визуални сценарии с въпроси и отговори.",
  "doubao-vision-pro-32k.description": "Doubao-vision е мултимодален модел от Doubao със силно разбиране и разсъждение върху изображения, както и точно следване на инструкции. Представя се добре при извличане на текст от изображения и задачи за разсъждение, базирани на изображения, позволявайки по-сложни и широки визуални сценарии с въпроси и отговори.",
  "emohaa.description": "Emohaa е модел за психично здраве с професионални консултантски способности, който помага на потребителите да разберат емоционални проблеми.",
  "ernie-4.5-0.3b.description": "ERNIE 4.5 0.3B е лек модел с отворен код за локално и персонализирано внедряване.",
  "ernie-4.5-21b-a3b.description": "ERNIE 4.5 21B A3B е модел с отворен код с голям брой параметри и по-силни способности за разбиране и генериране.",
  "ernie-4.5-300b-a47b.description": "ERNIE 4.5 300B A47B е ултра-голям MoE модел на Baidu ERNIE с отлични способности за разсъждение.",
  "ernie-4.5-8k-preview.description": "ERNIE 4.5 8K Preview е модел за предварителен преглед с 8K контекст за оценка на ERNIE 4.5.",
  "ernie-4.5-turbo-128k-preview.description": "Предварителен преглед на ERNIE 4.5 Turbo 128K с възможности на ниво издание, подходящ за интеграция и тестване.",
  "ernie-4.5-turbo-128k.description": "ERNIE 4.5 Turbo 128K е високопроизводителен общ модел с търсачна поддръжка и извикване на инструменти за QA, програмиране и агентски сценарии.",
  "ernie-4.5-turbo-32k.description": "ERNIE 4.5 Turbo 32K е версия със средна дължина на контекста за QA, извличане от бази знания и многозавойни диалози.",
  "ernie-4.5-turbo-latest.description": "Най-новият ERNIE 4.5 Turbo с оптимизирана цялостна производителност, идеален за основен продукционен модел.",
  "ernie-4.5-turbo-vl-32k-preview.description": "ERNIE 4.5 Turbo VL 32K Preview е мултимодален предварителен модел с 32K контекст за оценка на способността за разбиране на дълъг визуален контекст.",
  "ernie-4.5-turbo-vl-32k.description": "ERNIE 4.5 Turbo VL 32K е мултимодална версия със средно-дълъг контекст за комбинирано разбиране на дълги документи и изображения.",
  "ernie-4.5-turbo-vl-latest.description": "ERNIE 4.5 Turbo VL Latest е най-новата мултимодална версия с подобрено разбиране и разсъждение върху изображения и текст.",
  "ernie-4.5-turbo-vl-preview.description": "ERNIE 4.5 Turbo VL Preview е мултимодален предварителен модел за разбиране и генериране на изображения и текст, подходящ за визуални QA и разбиране на съдържание.",
  "ernie-4.5-turbo-vl.description": "ERNIE 4.5 Turbo VL е зрял мултимодален модел за продукционно разбиране и разпознаване на изображения и текст.",
  "ernie-4.5-vl-28b-a3b.description": "ERNIE 4.5 VL 28B A3B е мултимодален модел с отворен код за разбиране и разсъждение върху изображения и текст.",
  "ernie-5.0-thinking-latest.description": "Wenxin 5.0 Thinking е флагмански модел с пълна модалност, обединяващ текст, изображение, аудио и видео. Осигурява значителни подобрения за сложни QA, творчество и агентски сценарии.",
  "ernie-5.0-thinking-preview.description": "Wenxin 5.0 Thinking Preview е флагмански модел с пълна модалност, обединяващ текст, изображение, аудио и видео. Осигурява значителни подобрения за сложни QA, творчество и агентски сценарии.",
  "ernie-char-8k.description": "ERNIE Character 8K е модел за диалог с персонажи, предназначен за изграждане на IP персонажи и дългосрочен разговорен спътник.",
  "ernie-char-fiction-8k-preview.description": "ERNIE Character Fiction 8K Preview е предварителен модел за създаване на персонажи и сюжет, предназначен за оценка и тестване на функции.",
  "ernie-char-fiction-8k.description": "ERNIE Character Fiction 8K е модел за персонажи, предназначен за романи и създаване на сюжет, подходящ за генериране на дълги истории.",
  "ernie-irag-edit.description": "ERNIE iRAG Edit е модел за редактиране на изображения, поддържащ изтриване, прерисуване и генериране на варианти.",
  "ernie-lite-8k.description": "ERNIE Lite 8K е лек общ модел за чувствителни към разходите ежедневни QA и генериране на съдържание.",
  "ernie-lite-pro-128k.description": "ERNIE Lite Pro 128K е лек високопроизводителен модел за сценарии, чувствителни към латентност и разходи.",
  "ernie-novel-8k.description": "ERNIE Novel 8K е създаден за дълги романи и IP сюжети с многоперсонажни наративи.",
  "ernie-speed-128k.description": "ERNIE Speed 128K е модел без такси за I/O, предназначен за разбиране на дълги текстове и мащабни тестове.",
  "ernie-speed-8k.description": "ERNIE Speed 8K е безплатен, бърз модел за ежедневен чат и леки текстови задачи.",
  "ernie-speed-pro-128k.description": "ERNIE Speed Pro 128K е модел с висока едновременност и висока стойност за мащабни онлайн услуги и корпоративни приложения.",
  "ernie-tiny-8k.description": "ERNIE Tiny 8K е ултралек модел за прости QA, класификация и нискоразходно извеждане.",
  "ernie-x1-turbo-32k.description": "ERNIE X1 Turbo 32K е бърз мислещ модел с 32K контекст за сложни разсъждения и многозавойни разговори.",
  "ernie-x1.1-preview.description": "ERNIE X1.1 Preview е предварителен модел за мислене, предназначен за оценка и тестване.",
  "meta.llama3-8b-instruct-v1:0.description": "Meta Llama 3 е отворен LLM, предназначен за разработчици, изследователи и предприятия, създаден да им помага да изграждат, експериментират и отговорно мащабират идеи за генеративен ИИ. Като част от основата за глобални иновации в общността, той е подходящ за среди с ограничени изчислителни ресурси, крайни устройства и по-бързо обучение.",
  "meta/Llama-3.2-11B-Vision-Instruct.description": "Силен визуален анализ на изображения с висока резолюция, подходящ за приложения за визуално разбиране.",
  "meta/Llama-3.2-90B-Vision-Instruct.description": "Разширен визуален анализ за приложения с агенти за визуално разбиране.",
  "meta/Llama-3.3-70B-Instruct.description": "Llama 3.3 е най-усъвършенстваният многоезичен отворен модел Llama, предлагащ производителност, близка до 405B, на много ниска цена. Базиран е на трансформър архитектура и е подобрен чрез SFT и RLHF за полезност и безопасност. Версията, настроена за инструкции, е оптимизирана за многоезичен чат и надминава много отворени и затворени модели в индустриалните бенчмаркове. Край на знанията: декември 2023.",
  "meta/Meta-Llama-3-70B-Instruct.description": "Мощен модел с 70 милиарда параметъра, отличаващ се с логическо мислене, програмиране и широк спектър от езикови задачи.",
  "meta/Meta-Llama-3-8B-Instruct.description": "Универсален модел с 8 милиарда параметъра, оптимизиран за чат и генериране на текст.",
  "meta/Meta-Llama-3.1-405B-Instruct.description": "Llama 3.1, настроен за инструкции, е текстов модел, оптимизиран за многоезичен чат, с висока производителност в индустриалните бенчмаркове сред отворени и затворени модели.",
  "meta/Meta-Llama-3.1-70B-Instruct.description": "Llama 3.1, настроен за инструкции, е текстов модел, оптимизиран за многоезичен чат, с висока производителност в индустриалните бенчмаркове сред отворени и затворени модели.",
  "meta/Meta-Llama-3.1-8B-Instruct.description": "Llama 3.1, настроен за инструкции, е текстов модел, оптимизиран за многоезичен чат, с висока производителност в индустриалните бенчмаркове сред отворени и затворени модели.",
  "meta/llama-3-70b.description": "Отворен модел с 70 милиарда параметъра, фино настроен от Meta за следване на инструкции, предоставян от Groq на LPU хардуер за бързо и ефективно изпълнение.",
  "meta/llama-3-8b.description": "Отворен модел с 8 милиарда параметъра, фино настроен от Meta за следване на инструкции, предоставян от Groq на LPU хардуер за бързо и ефективно изпълнение.",
  "meta/llama-3.1-405b-instruct.description": "Разширен LLM, поддържащ генериране на синтетични данни, дистилация на знания и логическо мислене за чатботи, програмиране и специализирани задачи.",
  "meta/llama-3.1-70b-instruct.description": "Създаден за сложни диалози с отлично разбиране на контекста, логическо мислене и генериране на текст.",
  "meta/llama-3.1-70b.description": "Обновен Meta Llama 3 70B Instruct с 128K контекст, многоезична поддръжка и подобрено логическо мислене.",
  "meta/llama-3.1-8b-instruct.description": "Модерен модел с високо ниво на езиково разбиране, логическо мислене и генериране на текст.",
  "meta/llama-3.1-8b.description": "Llama 3.1 8B поддържа 128K контекстен прозорец, идеален за чат в реално време и анализ на данни, като предлага значителни икономии спрямо по-големите модели. Предоставян от Groq на LPU хардуер за бързо и ефективно изпълнение.",
  "meta/llama-3.2-11b-vision-instruct.description": "Модерен модел за визуално-езикови задачи, отличаващ се с висококачествено логическо мислене върху изображения.",
  "meta/llama-3.2-11b.description": "Модел, настроен за инструкции, за визуален анализ (вход: текст + изображение, изход: текст), оптимизиран за визуално разпознаване, логическо мислене върху изображения, надписи и общи въпроси за изображения.",
  "meta/llama-3.2-1b-instruct.description": "Модерен малък езиков модел с високо ниво на разбиране, логическо мислене и генериране на текст.",
  "meta/llama-3.2-1b.description": "Само текстов модел за използване на устройства, подходящ за многоезично локално извличане, обобщаване и пренаписване.",
  "meta/llama-3.2-3b-instruct.description": "Модерен малък езиков модел с високо ниво на разбиране, логическо мислене и генериране на текст.",
  "meta/llama-3.2-3b.description": "Само текстов модел, фино настроен за използване на устройства, като многоезично локално извличане, обобщаване и пренаписване.",
  "meta/llama-3.2-90b-vision-instruct.description": "Модерен модел за визуално-езикови задачи, отличаващ се с висококачествено логическо мислене върху изображения.",
  "meta/llama-3.2-90b.description": "Модел, настроен за инструкции, за визуален анализ (вход: текст + изображение, изход: текст), оптимизиран за визуално разпознаване, логическо мислене върху изображения, надписи и общи въпроси за изображения.",
  "meta/llama-3.3-70b-instruct.description": "Разширен LLM, силен в логическо мислене, математика, здрав разум и извикване на функции.",
  "meta/llama-3.3-70b.description": "Перфектен баланс между производителност и ефективност. Създаден за високоефективен разговорен ИИ в създаване на съдържание, корпоративни приложения и изследвания, с високо ниво на езиково разбиране за обобщаване, класификация, анализ на настроения и генериране на код.",
  "meta/llama-4-maverick.description": "Семейството Llama 4 е нативен мултимодален AI модел, поддържащ текстови и мултимодални преживявания, използващ MoE за водещо разбиране на текст и изображения. Llama 4 Maverick е модел с 17B параметъра и 128 експерта, предоставян от DeepInfra.",
  "meta/llama-4-scout.description": "Семейството Llama 4 е нативен мултимодален AI модел, поддържащ текстови и мултимодални преживявания, използващ MoE за водещо разбиране на текст и изображения. Llama 4 Scout е модел с 17B параметъра и 16 експерта, предоставян от DeepInfra.",
  "mistralai/Mistral-7B-v0.1.description": "Mistral 7B е компактен, но високоефективен модел, подходящ за партидна обработка и прости задачи като класификация и генериране на текст, с добро логическо разсъждение.",
  "mistralai/Mixtral-8x22B-Instruct-v0.1.description": "Mixtral-8x22B Instruct (141B) е много голям езиков модел, предназначен за тежки натоварвания.",
  "mistralai/Mixtral-8x7B-Instruct-v0.1.description": "Mixtral-8x7B Instruct (46.7B) предлага висока производителност за обработка на данни в голям мащаб.",
  "mistralai/Mixtral-8x7B-v0.1.description": "Mixtral 8x7B е разреден MoE модел, който ускорява извеждането и е подходящ за многоезични задачи и генериране на код.",
  "mistralai/mistral-nemo.description": "Mistral Nemo е модел с 7.3B параметъра с поддръжка на много езици и силна производителност при програмиране.",
  "mixtral-8x7b-32768.description": "Mixtral 8x7B осигурява устойчиво на грешки паралелно изчисление за сложни задачи.",
  "mixtral.description": "Mixtral е MoE модел на Mistral AI с отворени тегла, поддържащ генериране на код и езиково разбиране.",
  "mixtral:8x22b.description": "Mixtral е MoE модел на Mistral AI с отворени тегла, поддържащ генериране на код и езиково разбиране.",
  "moonshot-v1-128k-vision-preview.description": "Моделите Kimi vision (включително moonshot-v1-8k-vision-preview/moonshot-v1-32k-vision-preview/moonshot-v1-128k-vision-preview) разбират съдържание на изображения като текст, цветове и форми на обекти.",
  "moonshot-v1-128k.description": "Moonshot V1 128K предлага изключително дълъг контекст за генериране на много дълги текстове, обработвайки до 128 000 токена за научни, академични и документи с голям обем.",
  "moonshot-v1-32k-vision-preview.description": "Моделите Kimi vision (включително moonshot-v1-8k-vision-preview/moonshot-v1-32k-vision-preview/moonshot-v1-128k-vision-preview) разбират съдържание на изображения като текст, цветове и форми на обекти.",
  "moonshot-v1-32k.description": "Moonshot V1 32K поддържа 32 768 токена за средно дълъг контекст, идеален за дълги документи и сложни диалози в създаване на съдържание, отчети и чат системи.",
  "moonshot-v1-8k-vision-preview.description": "Моделите Kimi vision (включително moonshot-v1-8k-vision-preview/moonshot-v1-32k-vision-preview/moonshot-v1-128k-vision-preview) разбират съдържание на изображения като текст, цветове и форми на обекти.",
  "moonshot-v1-8k.description": "Moonshot V1 8K е оптимизиран за генериране на кратки текстове с висока ефективност, обработвайки 8 192 токена за кратки чатове, бележки и бързо съдържание.",
  "moonshot-v1-auto.description": "Moonshot V1 Auto избира подходящия модел въз основа на текущата употреба на токени в контекста.",
  "moonshotai/Kimi-Dev-72B.description": "Kimi-Dev-72B е отворен кодов езиков модел, оптимизиран с мащабно подсилващо обучение за създаване на стабилни, готови за продукция корекции. Постига 60.4% в SWE-bench Verified, поставяйки нов рекорд сред отворените модели за автоматизирани задачи като отстраняване на грешки и преглед на код.",
  "moonshotai/Kimi-K2-Instruct-0905.description": "Kimi K2-Instruct-0905 е най-новият и най-мощен модел от серията Kimi K2. Това е MoE модел от най-висок клас с 1T общо и 32B активни параметъра. Основни характеристики включват по-силна агентна интелигентност при програмиране, значителни подобрения в бенчмаркове и реални задачи, както и подобрена естетика и използваемост на фронтенд кода.",
  "moonshotai/Kimi-K2-Thinking.description": "Kimi K2 Thinking е най-новият и най-мощен отворен модел за мислене. Значително разширява дълбочината на многoстъпковото разсъждение и поддържа стабилна употреба на инструменти в 200–300 последователни извиквания, поставяйки нови рекорди в Humanity's Last Exam (HLE), BrowseComp и други бенчмаркове. Отличава се в програмиране, математика, логика и агентни сценарии. Изграден върху MoE архитектура с ~1T параметри, поддържа 256K контекстен прозорец и извикване на инструменти.",
  "moonshotai/kimi-k2-0711.description": "Kimi K2 0711 е instruct вариант от серията Kimi, подходящ за висококачествен код и използване на инструменти.",
  "moonshotai/kimi-k2-0905.description": "Kimi K2 0905 е актуализация, която разширява контекста и логическата производителност с оптимизации за програмиране.",
  "moonshotai/kimi-k2-instruct-0905.description": "Моделът kimi-k2-0905-preview поддържа 256K контекстен прозорец, с по-силно агентно програмиране, по-изпипан и практичен фронтенд код и по-добро разбиране на контекста.",
  "moonshotai/kimi-k2-thinking-turbo.description": "Kimi K2 Thinking Turbo е високоскоростна версия на Kimi K2 Thinking, значително намаляваща латентността, като запазва дълбокото разсъждение.",
  "moonshotai/kimi-k2-thinking.description": "Kimi K2 Thinking е модел за разсъждение на Moonshot, оптимизиран за задачи, изискващи дълбоко мислене, с общи агентни способности.",
  "moonshotai/kimi-k2.description": "Kimi K2 е голям MoE модел от Moonshot AI с 1T общи параметри и 32B активни при всяко преминаване, оптимизиран за агентни способности, включително напреднало използване на инструменти, разсъждение и синтез на код.",
  "morph/morph-v3-fast.description": "Morph предоставя специализиран модел за прилагане на промени в кода, предложени от водещи модели (напр. Claude или GPT-4o), към съществуващите ви файлове със скорост над 4500 токена/сек. Това е последната стъпка в AI работния процес за програмиране и поддържа 16k входни/изходни токена.",
  "morph/morph-v3-large.description": "Morph предоставя специализиран модел за прилагане на промени в кода, предложени от водещи модели (напр. Claude или GPT-4o), към съществуващите ви файлове със скорост над 2500 токена/сек. Това е последната стъпка в AI работния процес за програмиране и поддържа 16k входни/изходни токена.",
  "nousresearch/hermes-2-pro-llama-3-8b.description": "Hermes 2 Pro Llama 3 8B е обновена версия на Nous Hermes 2 с най-новите вътрешно разработени набори от данни.",
  "nvidia/Llama-3.1-Nemotron-70B-Instruct-HF.description": "Llama 3.1 Nemotron 70B е персонализиран LLM от NVIDIA, създаден за подобряване на полезността. Представя се отлично в Arena Hard, AlpacaEval 2 LC и GPT-4-Turbo MT-Bench, заемайки първо място и в трите автоматични бенчмарка към 1 октомври 2024 г. Обучен е от Llama-3.1-70B-Instruct с помощта на RLHF (REINFORCE), Llama-3.1-Nemotron-70B-Reward и HelpSteer2-Preference подсказки.",
  "nvidia/llama-3.1-nemotron-51b-instruct.description": "Отличителен езиков модел, предлагащ изключителна точност и ефективност.",
  "nvidia/llama-3.1-nemotron-70b-instruct.description": "Llama-3.1-Nemotron-70B-Instruct е персонализиран модел на NVIDIA, създаден за подобряване на полезността на отговорите от LLM.",
  "openai/o3-mini.description": "o3-mini е най-новият малък модел за разсъждение на OpenAI, който предлага по-висока интелигентност при същите разходи и закъснение като o1-mini.",
  "openai/o3.description": "OpenAI o3 е най-мощният модел за разсъждение, поставящ нови стандарти в програмирането, математиката, науката и визуалното възприятие. Отличава се при сложни, многопластови заявки и е особено силен в анализа на изображения, графики и диаграми.",
  "openai/o4-mini-high.description": "o4-mini high е модел от висок клас за разсъждение, оптимизиран за бърза и ефективна логика с отлична производителност в програмиране и визуални задачи.",
  "openai/o4-mini.description": "OpenAI o4-mini е малък, ефективен модел за разсъждение, подходящ за сценарии с ниско закъснение.",
  "openai/text-embedding-3-large.description": "Най-способният embedding модел на OpenAI за задачи на английски и други езици.",
  "openai/text-embedding-3-small.description": "Подобрена, високопроизводителна версия на embedding модела ada от OpenAI.",
  "openai/text-embedding-ada-002.description": "Наследен embedding модел за текст от OpenAI.",
  "openrouter/auto.description": "Въз основа на дължината на контекста, темата и сложността, заявката ви се насочва към Llama 3 70B Instruct, Claude 3.5 Sonnet (със самомодерация) или GPT-4o.",
  "perplexity/sonar-pro.description": "Водещият продукт на Perplexity с търсене в реално време, поддържащ сложни заявки и последващи въпроси.",
  "perplexity/sonar-reasoning-pro.description": "Разширен модел, фокусиран върху разсъждение, който генерира chain-of-thought (CoT) с подобрено търсене, включително множество заявки на заявка.",
  "perplexity/sonar-reasoning.description": "Модел, фокусиран върху разсъждение, който генерира chain-of-thought (CoT) с подробни обяснения, базирани на търсене.",
  "perplexity/sonar.description": "Олекотен продукт на Perplexity с търсене в реално време, по-бърз и по-евтин от Sonar Pro.",
  "phi3.description": "Phi-3 е лек отворен модел на Microsoft за ефективна интеграция и мащабно разсъждение.",
  "phi3:14b.description": "Phi-3 е лек отворен модел на Microsoft за ефективна интеграция и мащабно разсъждение.",
  "pixtral-12b-2409.description": "Pixtral е силен в разбирането на графики/изображения, въпроси и отговори по документи, мултимодално разсъждение и следване на инструкции. Обработва изображения в оригинална резолюция/съотношение и поддържа множество изображения в контекст от 128K.",
  "pixtral-large-latest.description": "Pixtral Large е мултимодален отворен модел с 124 милиарда параметъра, базиран на Mistral Large 2 – вторият в нашето мултимодално семейство с водещо разбиране на изображения.",
  "pro-128k.description": "Spark Pro 128K предлага много голям контекст, обработващ до 128K, идеален за дълги документи, изискващи пълен анализ и логическа последователност, с плавна логика и разнообразна поддръжка на цитиране в сложни дискусии.",
  "pro-deepseek-r1.description": "Модел за специализирани корпоративни услуги с включена паралелна обработка.",
  "pro-deepseek-v3.description": "Модел за специализирани корпоративни услуги с включена паралелна обработка.",
  "qianfan-70b.description": "Qianfan 70B е голям китайски модел за висококачествено генериране и сложно разсъждение.",
  "qianfan-8b.description": "Qianfan 8B е среден по размер общ модел, балансиращ разходи и качество за генериране на текст и въпроси/отговори.",
  "qianfan-agent-intent-32k.description": "Qianfan Agent Intent 32K е насочен към разпознаване на намерения и координация на агенти с поддръжка на дълъг контекст.",
  "qianfan-agent-lite-8k.description": "Qianfan Agent Lite 8K е лек агент модел за нискобюджетни многозавойни диалози и работни потоци.",
  "qianfan-agent-speed-32k.description": "Qianfan Agent Speed 32K е модел с висока пропускателна способност за мащабни, многозадачни агентни приложения.",
  "qianfan-agent-speed-8k.description": "Qianfan Agent Speed 8K е модел с висока едновременност за кратки до средни разговори и бърз отговор.",
  "qianfan-check-vl.description": "Qianfan Check VL е мултимодален модел за преглед на съдържание, съвместимост между изображение и текст и задачи по разпознаване.",
  "qianfan-composition.description": "Qianfan Composition е мултимодален модел за създаване, разбиране и генериране на смесено изображение и текст.",
  "qianfan-engcard-vl.description": "Qianfan EngCard VL е мултимодален модел за разпознаване, фокусиран върху английски езикови сценарии.",
  "qianfan-lightning-128b-a19b.description": "Qianfan Lightning 128B A19B е високопроизводителен китайски общ модел за сложни въпроси и мащабно разсъждение.",
  "qianfan-llama-vl-8b.description": "Qianfan Llama VL 8B е мултимодален модел, базиран на Llama, за общо разбиране на изображения и текст.",
  "qianfan-multipicocr.description": "Qianfan MultiPicOCR е OCR модел за множество изображения, откриващ и разпознаващ текст в различни изображения.",
  "qianfan-qi-vl.description": "Qianfan QI VL е мултимодален модел за въпроси и отговори с точна извличане и отговори в сложни сценарии с изображения и текст.",
  "qianfan-singlepicocr.description": "Qianfan SinglePicOCR е OCR модел за едно изображение с висока точност при разпознаване на символи.",
  "qianfan-vl-70b.description": "Qianfan VL 70B е голям мултимодален езиков модел за сложно разбиране на изображения и текст.",
  "qianfan-vl-8b.description": "Qianfan VL 8B е лек мултимодален езиков модел за ежедневни въпроси и анализ на изображения и текст.",
  "qvq-72b-preview.description": "QVQ-72B-Preview е експериментален изследователски модел от Qwen, фокусиран върху подобрено визуално разсъждение.",
  "qvq-max.description": "Моделът за визуално разсъждение Qwen QVQ поддържа вход от изображения и изход с chain-of-thought, с по-силна производителност в математика, програмиране, визуален анализ, творчество и общи задачи.",
  "qvq-plus.description": "Модел за визуално разсъждение с вход от изображения и изход с chain-of-thought. Серията qvq-plus следва qvq-max и предлага по-бързо разсъждение с по-добър баланс между качество и цена.",
  "qwen-3-32b.description": "Qwen 3 32B: силен в многоезични и програмистки задачи, подходящ за средномащабна продукция.",
  "qwen-coder-plus.description": "Модел за програмиране от серията Qwen.",
  "qwen-coder-turbo-latest.description": "Модел за програмиране от серията Qwen.",
  "qwen-coder-turbo.description": "Модел за програмиране от серията Qwen.",
  "qwen-flash.description": "Най-бързият и най-евтин модел от Qwen, идеален за прости задачи.",
  "qwen-image-edit.description": "Qwen Image Edit е модел за редактиране на изображения, който променя изображения въз основа на входни изображения и текстови подсказки, позволявайки прецизни корекции и творчески трансформации.",
  "qwen-image.description": "Qwen-Image е универсален модел за генериране на изображения, поддържащ множество художествени стилове и силно рендиране на сложен текст, особено на китайски и английски. Поддържа многострочни оформления, текст на ниво абзац и фини детайли за сложни текстово-визуални оформления.",
  "qwen-long.description": "Изключително голям модел от Qwen с дълъг контекст и чат в сценарии с дълги и многодокументни взаимодействия.",
  "qwen-math-plus-latest.description": "Qwen Math е езиков модел, специализиран в решаване на математически задачи.",
  "qwen-math-plus.description": "Qwen Math е езиков модел, специализиран в решаване на математически задачи.",
  "qwen-math-turbo-latest.description": "Qwen Math е езиков модел, специализиран в решаване на математически задачи.",
  "qwen-math-turbo.description": "Qwen Math е езиков модел, специализиран в решаване на математически задачи.",
  "qwen-max.description": "Изключително голям модел от серията Qwen с мащаб от стотици милиарди параметри, поддържащ китайски, английски и други езици; API моделът зад текущите продукти Qwen2.5.",
  "qwen-omni-turbo.description": "Моделите Qwen-Omni поддържат мултимодални входове (видео, аудио, изображения, текст) и изходи в аудио и текстов формат.",
  "qwen-plus.description": "Подобрен изключително голям модел от серията Qwen, поддържащ китайски, английски и други езици.",
  "qwen-turbo.description": "Qwen Turbo вече няма да се актуализира; заменете го с Qwen Flash. Изключително голям модел от серията Qwen, поддържащ китайски, английски и други езици.",
  "qwen-vl-chat-v1.description": "Qwen VL поддържа гъвкави взаимодействия, включително вход от множество изображения, многозавойни въпроси и творчески задачи.",
  "qwen-vl-max-latest.description": "Изключително голям мултимодален модел от серията Qwen. В сравнение с подобрената версия, допълнително подобрява визуалното разсъждение и следването на инструкции за по-силно възприятие и когниция.",
  "qwen-vl-max.description": "Изключително голям мултимодален модел от серията Qwen. В сравнение с подобрената версия, допълнително подобрява визуалното разсъждение и следването на инструкции за по-силно визуално възприятие и когниция.",
  "qwen-vl-ocr.description": "Qwen OCR е модел за извличане на текст от документи, таблици, изображения от изпити и ръкописен текст. Поддържа китайски, английски, френски, японски, корейски, немски, руски, италиански, виетнамски и арабски.",
  "qwen-vl-plus-latest.description": "Подобрен голям мултимодален модел от серията Qwen с значителни подобрения в детайлите и разпознаването на текст, поддържащ резолюция над 1 мегапиксел и произволни съотношения.",
  "qwen-vl-plus.description": "Подобрен голям мултимодален модел от серията Qwen с значителни подобрения в детайлите и разпознаването на текст, поддържащ резолюция над 1 мегапиксел и произволни съотношения.",
  "qwen-vl-v1.description": "Предварително обучен модел, инициализиран от Qwen-7B с добавен визуален модул и вход за изображения с резолюция 448.",
  "qwen/qwen3-coder-plus.description": "Qwen3-Coder-Plus е модел от серията Qwen, оптимизиран за по-сложно използване на инструменти и дълготрайни сесии.",
  "qwen/qwen3-coder.description": "Qwen3-Coder е част от семейството за генериране на код Qwen3, силен в разбирането и създаването на код от дълги документи.",
  "qwen/qwen3-max-preview.description": "Qwen3 Max (преглед) е вариантът Max за напреднало разсъждение и интеграция с инструменти.",
  "qwen/qwen3-max.description": "Qwen3 Max е висококласният модел за разсъждение от серията Qwen3, предназначен за многоезично разсъждение и интеграция с инструменти.",
  "qwen/qwen3-vl-plus.description": "Qwen3 VL-Plus е подобрен визуален вариант на Qwen3 с усъвършенствано мултимодално разсъждение и обработка на видео.",
  "qwen2.5-14b-instruct-1m.description": "Qwen2.5 отворен код, модел с 72B параметъра.",
  "qwen2.5-14b-instruct.description": "Qwen2.5 отворен код, модел с 14B параметъра.",
  "qwen2.5-32b-instruct.description": "Qwen2.5 отворен код, модел с 32B параметъра.",
  "qwen2.5-72b-instruct.description": "Qwen2.5 отворен код, модел с 72B параметъра.",
  "qwen2.5-7b-instruct.description": "Qwen2.5 7B Instruct е зрял модел с отворен код за чат и генериране в различни сценарии.",
  "qwen2.5-coder-1.5b-instruct.description": "Модел за програмиране Qwen с отворен код.",
  "qwen2.5-coder-14b-instruct.description": "Модел за програмиране Qwen с отворен код.",
  "qwen2.5-coder-32b-instruct.description": "Модел за програмиране Qwen с отворен код.",
  "qwen2.5-coder-7b-instruct.description": "Модел за програмиране Qwen с отворен код.",
  "qwen2.5-coder-instruct.description": "Qwen2.5-Coder е най-новият модел, фокусиран върху програмиране, от семейството Qwen (преди CodeQwen).",
  "qwen2.5-instruct.description": "Qwen2.5 е най-новата серия LLM модели от Qwen, включваща базови и инструкторски модели от 0.5B до 72B параметъра.",
  "qwen2.5-math-1.5b-instruct.description": "Qwen-Math предлага силни способности за решаване на математически задачи.",
  "qwen2.5-math-72b-instruct.description": "Qwen-Math предлага силни способности за решаване на математически задачи.",
  "qwen2.5-math-7b-instruct.description": "Qwen-Math предлага силни способности за решаване на математически задачи.",
  "qwen2.5-omni-7b.description": "Моделите Qwen-Omni поддържат мултимодални входове (видео, аудио, изображения, текст) и извеждат аудио и текст.",
  "qwen2.5-vl-32b-instruct.description": "Qwen2.5 VL 32B Instruct е мултимодален модел с отворен код, подходящ за частно внедряване и използване в различни сценарии.",
  "qwen2.5-vl-72b-instruct.description": "Подобрен следване на инструкции, математика, решаване на задачи и програмиране, с по-силно разпознаване на обекти. Поддържа точно локализиране на визуални елементи във всички формати, разбиране на дълги видеа (до 10 минути) с прецизно времево маркиране, разбиране на последователност и скорост, както и агенти, които могат да управляват ОС или мобилни устройства чрез парсинг и локализация. Силен в извличането на ключова информация и изход в JSON формат. Това е най-мощната версия от серията с 72B параметъра.",
  "qwen2.5-vl-7b-instruct.description": "Qwen2.5 VL 7B Instruct е лек мултимодален модел, балансиращ между разходи за внедряване и способности за разпознаване.",
  "qwen2.5-vl-instruct.description": "Qwen2.5-VL е най-новият модел за визия и език от семейството Qwen.",
  "qwen2.5.description": "Qwen2.5 е следващото поколение голям езиков модел на Alibaba с висока производителност в различни приложения.",
  "qwen2.5:0.5b.description": "Qwen2.5 е следващото поколение голям езиков модел на Alibaba с висока производителност в различни приложения.",
  "qwen2.5:1.5b.description": "Qwen2.5 е следващото поколение голям езиков модел на Alibaba с висока производителност в различни приложения.",
  "qwen2.5:72b.description": "Qwen2.5 е следващото поколение голям езиков модел на Alibaba с висока производителност в различни приложения.",
  "qwen2.description": "Qwen2 е следващото поколение голям езиков модел на Alibaba с висока производителност в различни приложения.",
  "qwen2:0.5b.description": "Qwen2 е следващото поколение голям езиков модел на Alibaba с висока производителност в различни приложения.",
  "qwen2:1.5b.description": "Qwen2 е следващото поколение голям езиков модел на Alibaba с висока производителност в различни приложения.",
  "qwen2:72b.description": "Qwen2 е следващото поколение голям езиков модел на Alibaba с висока производителност в различни приложения.",
  "qwen3-0.6b.description": "Qwen3 0.6B е начален модел за базово разсъждение и силно ограничени среди.",
  "qwen3-1.7b.description": "Qwen3 1.7B е ултралек модел за внедряване на устройства и крайни точки.",
  "qwen3-14b.description": "Qwen3 14B е среден по размер модел за многоезични въпроси и отговори и генериране на текст.",
  "qwen3-235b-a22b-instruct-2507.description": "Qwen3 235B A22B Instruct 2507 е водещ модел с инструкции за широк спектър от задачи по генериране и разсъждение.",
  "qwen3-235b-a22b-thinking-2507.description": "Qwen3 235B A22B Thinking 2507 е ултраголям модел за дълбоко разсъждение.",
  "qwen3-235b-a22b.description": "Qwen3 235B A22B е универсален голям модел за сложни задачи.",
  "qwen3-30b-a3b-instruct-2507.description": "Qwen3 30B A3B Instruct 2507 е средно-голям модел с инструкции за висококачествено генериране и въпроси и отговори.",
  "qwen3-30b-a3b-thinking-2507.description": "Qwen3 30B A3B Thinking 2507 е средно-голям модел за разсъждение, балансиращ точност и разходи.",
  "qwen3-30b-a3b.description": "Qwen3 30B A3B е средно-голям универсален модел, балансиращ между цена и качество.",
  "qwen3-32b.description": "Qwen3 32B е подходящ за общи задачи, изискващи по-дълбоко разбиране.",
  "qwen3-4b.description": "Qwen3 4B е подходящ за малки до средни приложения и локално извеждане.",
  "qwen3-8b.description": "Qwen3 8B е лек модел с гъвкаво внедряване за натоварвания с висока едновременност.",
  "qwen3-coder-30b-a3b-instruct.description": "Модел за програмиране Qwen с отворен код. Най-новият qwen3-coder-30b-a3b-instruct е базиран на Qwen3 и предлага силни способности за програмиране чрез агенти, използване на инструменти и взаимодействие със среди за автономно програмиране, с отлично представяне при код и стабилни общи възможности.",
  "qwen3-coder-480b-a35b-instruct.description": "Qwen3 Coder 480B A35B Instruct е водещ модел за програмиране с поддръжка на много езици и разбиране на сложен код.",
  "qwen3-coder-flash.description": "Модел за програмиране Qwen. Най-новата серия Qwen3-Coder е базирана на Qwen3 и предлага силни способности за програмиране чрез агенти, използване на инструменти и взаимодействие със среди за автономно програмиране, с отлично представяне при код и стабилни общи възможности.",
  "qwen3-coder-plus.description": "Модел за програмиране Qwen. Най-новата серия Qwen3-Coder е базирана на Qwen3 и предлага силни способности за програмиране чрез агенти, използване на инструменти и взаимодействие със среди за автономно програмиране, с отлично представяне при код и стабилни общи възможности.",
  "qwen3-coder:480b.description": "Високопроизводителен модел на Alibaba с дълъг контекст за задачи с агенти и програмиране.",
  "qwen3-max-preview.description": "Най-добре представящият се модел Qwen за сложни, многоетапни задачи. Прегледната версия поддържа разсъждение.",
  "qwen3-max.description": "Моделите Qwen3 Max предлагат значителни подобрения спрямо серията 2.5 в общите способности, разбиране на китайски/английски, следване на сложни инструкции, субективни отворени задачи, многоезичност и използване на инструменти, с по-малко халюцинации. Най-новият qwen3-max подобрява програмирането чрез агенти и използването на инструменти спрямо qwen3-max-preview. Тази версия достига водещи резултати в индустрията и е насочена към по-сложни нужди на агентите.",
  "stable-diffusion-3.5-large.description": "stable-diffusion-3.5-large е текст-към-изображение модел MMDiT с 800 милиона параметъра, предлагащ отлично качество и съответствие с подадените инструкции, поддържащ изображения с резолюция 1 мегапиксел и ефективна работа на потребителски хардуер.",
  "stable-diffusion-v1.5.description": "stable-diffusion-v1.5 е инициализиран от контролна точка v1.2 и фино настроен за 595 хиляди стъпки върху „laion-aesthetics v2 5+“ при резолюция 512x512, като намалява влиянието на текстовото условие с 10% за подобрено семплиране без класификатор.",
  "stable-diffusion-xl-base-1.0.description": "Модел с отворен код за генериране на изображения от текст от Stability AI, предлагащ водещо в индустрията творческо качество. Притежава силно разбиране на инструкции и поддържа обратни дефиниции на подканите за прецизно генериране.",
  "stable-diffusion-xl.description": "stable-diffusion-xl предлага значителни подобрения спрямо v1.5 и съответства на водещите отворени модели за генериране на изображения от текст. Подобренията включват 3 пъти по-голям UNet гръбнак, модул за прецизиране за по-добро качество на изображенията и по-ефективни техники на обучение.",
  "step-1-128k.description": "Баланс между производителност и разходи за общи сценарии.",
  "step-1-256k.description": "Обработка на изключително дълъг контекст, идеална за анализ на дълги документи.",
  "step-1-32k.description": "Поддържа разговори със средна дължина за широк спектър от приложения.",
  "step-1-8k.description": "Малък модел, подходящ за леки задачи.",
  "step-1-flash.description": "Модел с висока скорост, подходящ за чат в реално време.",
  "step-1.5v-mini.description": "Силни възможности за разбиране на видео съдържание.",
  "step-1o-turbo-vision.description": "Силно визуално разбиране, надминаващо 1o в математика и програмиране. По-малък от 1o с по-бърз изход.",
  "step-1o-vision-32k.description": "Силно визуално разбиране с по-добра визуална производителност от серията Step-1V.",
  "step-1v-32k.description": "Поддържа визуални входове за по-богато мултимодално взаимодействие.",
  "step-1v-8k.description": "Малък визуален модел за основни задачи с изображения и текст.",
  "step-1x-edit.description": "Този модел е фокусиран върху редактиране на изображения, модифицирайки и подобрявайки изображения въз основа на предоставени от потребителя изображения и текст. Поддържа множество входни формати, включително текстови описания и примерни изображения, и генерира редакции, съответстващи на намеренията на потребителя.",
  "step-1x-medium.description": "Този модел предлага силно генериране на изображения от текстови подканва. С вградена поддръжка на китайски език, той по-добре разбира китайски описания, улавя тяхната семантика и ги преобразува във визуални характеристики за по-точно генериране. Създава изображения с висока резолюция и качество и поддържа известна степен на трансфер на стил.",
  "step-2-16k-exp.description": "Експериментална версия на Step-2 с най-нови функции и текущи актуализации. Не се препоръчва за продукционна употреба.",
  "step-2-16k.description": "Поддържа взаимодействия с голям контекст за сложни диалози.",
  "step-2-mini.description": "Изграден върху следващото поколение вътрешна архитектура MFA attention, предоставяйки резултати, подобни на Step-1, при значително по-ниска цена, с по-висока пропускателна способност и по-бърза латентност. Обработва общи задачи със силни способности за програмиране.",
  "step-2x-large.description": "Модел от ново поколение StepFun за генериране на изображения, създаващ висококачествени изображения от текстови подканва. Осигурява по-реалистична текстура и по-добро визуализиране на китайски/английски текст.",
  "step-3.description": "Този модел притежава силно визуално възприятие и сложна логика, точно обработва междудомейново знание, анализ между математика и визия и широк спектър от ежедневни визуални задачи.",
  "step-r1-v-mini.description": "Модел за логическо разсъждение със силно визуално разбиране, който може да обработва изображения и текст, след което да генерира текст след дълбоко разсъждение. Отличава се във визуално разсъждение и предоставя водещи резултати в математика, програмиране и текстово разсъждение, с контекстен прозорец от 100K.",
  "stepfun-ai/step3.description": "Step3 е авангарден мултимодален модел за разсъждение от StepFun, изграден върху MoE архитектура с общо 321B и 38B активни параметъра. Дизайнът от край до край минимизира разходите за декодиране, като същевременно осигурява водещо разсъждение между визия и език. С MFA и AFD дизайн, остава ефективен както на флагмански, така и на нискобюджетни ускорители. Предобучен с над 20T текстови токени и 4T токени от изображения и текст на множество езици. Постига водеща производителност сред отворените модели в математика, код и мултимодални бенчмаркове.",
  "taichu_llm.description": "Обучен върху масивни висококачествени данни, с по-силно разбиране на текст, създаване на съдържание и разговорно въпроси-отговори.",
  "taichu_o1.description": "taichu_o1 е модел от ново поколение за разсъждение, използващ мултимодално взаимодействие и обучение чрез подсилване за постигане на човешкоподобна верига на мисълта, поддържащ симулация на сложни решения и разкриващ логически пътища, като същевременно поддържа висока точност – подходящ за стратегически анализ и дълбоко мислене.",
  "taichu_vl.description": "Комбинира визуално разбиране, трансфер на знания и логическа атрибуция, отличавайки се в задачи с въпроси и отговори между изображения и текст.",
  "tencent/Hunyuan-A13B-Instruct.description": "Hunyuan-A13B-Instruct използва общо 80B параметъра с 13B активни, за да съответства на по-големи модели. Поддържа хибридно бързо/бавнопотоцово разсъждение, стабилно разбиране на дълги текстове и водещи способности на агенти в BFCL-v3 и τ-Bench. GQA и мулти-квантови формати позволяват ефективно извеждане.",
  "tencent/Hunyuan-MT-7B.description": "Моделът за превод Hunyuan включва Hunyuan-MT-7B и ансамбъла Hunyuan-MT-Chimera. Hunyuan-MT-7B е лек модел с 7B параметъра, поддържащ 33 езика плюс 5 китайски малцинствени езика. В WMT25 заема първо място в 30 от 31 езикови двойки. Tencent Hunyuan използва пълен тренировъчен процес от предобучение до SFT, превод чрез RL и ансамблово RL, постигайки водеща производителност за своя размер с ефективно и лесно внедряване.",
  "text-embedding-3-large.description": "Най-способният модел за вграждане за задачи на английски и други езици.",
  "text-embedding-3-small.description": "Ефективен, икономичен модел от ново поколение за вграждане, подходящ за извличане и RAG сценарии.",
  "thudm/glm-4-32b.description": "GLM-4-32B-0414 е двуезичен (китайски/английски) модел с отворени тегла и 32B параметъра, оптимизиран за генериране на код, извикване на функции и агентни задачи. Предобучен върху 15T висококачествени и логически наситени данни и допълнително усъвършенстван чрез подравняване с човешки предпочитания, отхвърляне на проби и RL. Отличава се в сложно разсъждение, генериране на артефакти и структурирани изходи, достигайки нивото на GPT-4o и DeepSeek-V3-0324 в множество бенчмаркове.",
  "thudm/glm-4-32b:free.description": "GLM-4-32B-0414 е двуезичен (китайски/английски) модел с отворени тегла и 32B параметъра, оптимизиран за генериране на код, извикване на функции и агентни задачи. Предобучен върху 15T висококачествени и логически наситени данни и допълнително усъвършенстван чрез подравняване с човешки предпочитания, отхвърляне на проби и RL. Отличава се в сложно разсъждение, генериране на артефакти и структурирани изходи, достигайки нивото на GPT-4o и DeepSeek-V3-0324 в множество бенчмаркове.",
  "thudm/glm-4-9b-chat.description": "Отворената версия на най-новия предобучен модел GLM-4 от Zhipu AI.",
  "thudm/glm-z1-32b.description": "GLM-Z1-32B-0414 е подобрен вариант на GLM-4-32B, създаден за дълбоко математическо, логическо и кодово разсъждение. Използва разширено RL (специфично за задачи и общо предпочитание по двойки), за да подобри сложни многоетапни задачи. В сравнение с GLM-4-32B, Z1 значително подобрява структурираното разсъждение и способностите в формални домейни.\n\nПоддържа принудително „мислене“ чрез инженеринг на подканите, подобрена кохерентност за дълги изходи и е оптимизиран за агентни работни потоци с дълъг контекст (чрез YaRN), извикване на JSON инструменти и фино семплиране за стабилно разсъждение. Идеален за случаи, изискващи внимателни многоетапни или формални изводи.",
  "xai/grok-3-mini-fast.description": "Лек модел на xAI, който обмисля преди да отговори – идеален за прости или логически задачи без необходимост от задълбочени познания в конкретна област. Налични са сурови следи от разсъждения. Бързият вариант работи върху по-бърза инфраструктура за значително по-бързи отговори, но с по-висока цена на токен.",
  "xai/grok-3-mini.description": "Лек модел на xAI, който обмисля преди да отговори – идеален за прости или логически задачи без необходимост от задълбочени познания в конкретна област. Налични са сурови следи от разсъждения.",
  "xai/grok-3.description": "Флагманският модел на xAI се отличава в корпоративни приложения като извличане на данни, програмиране и обобщаване, с дълбоки познания в области като финанси, здравеопазване, право и наука.",
  "xai/grok-4.description": "Най-новият флагмански модел на xAI с ненадмината производителност в естествен език, математика и разсъждение – идеален универсален модел.",
  "yi-large-fc.description": "Изграден върху yi-large с подобрено извикване на инструменти, подходящ за агенти и работни потоци.",
  "yi-large-preview.description": "Ранна версия; препоръчва се използването на по-новия yi-large.",
  "yi-large-rag.description": "Разширена услуга, базирана на yi-large, която комбинира извличане и генериране за прецизни отговори с търсене в реално време в интернет.",
  "yi-large-turbo.description": "Изключителна стойност и производителност, настроен за силен баланс между качество, скорост и цена.",
  "yi-large.description": "Нов модел със 100 милиарда параметъра с отлични възможности за въпроси и отговори и генериране на текст.",
  "yi-lightning-lite.description": "Олекотена версия; препоръчва се използването на yi-lightning.",
  "yi-lightning.description": "Най-нов високопроизводителен модел с по-бързо извеждане и висококачествени резултати.",
  "yi-medium-200k.description": "Модел с дълъг контекст от 200K, предназначен за дълбоко разбиране и генериране на дълги текстове.",
  "yi-medium.description": "Настроен модел със среден размер с балансирани възможности и стойност, оптимизиран за следване на инструкции.",
  "yi-spark.description": "Компактен и бърз модел с подсилени възможности в математика и програмиране.",
  "yi-vision-v2.description": "Визуален модел за сложни задачи със силно разбиране и анализ на множество изображения.",
  "yi-vision.description": "Визуален модел за сложни задачи със силно разбиране и анализ на изображения.",
  "z-ai/glm-4.5-air.description": "GLM 4.5 Air е олекотен вариант на GLM 4.5 за сценарии, чувствителни към разходи, като същевременно запазва силни способности за разсъждение.",
  "z-ai/glm-4.5.description": "GLM 4.5 е флагманският модел на Z.AI с хибридно разсъждение, оптимизиран за инженерни и задачи с дълъг контекст.",
  "z-ai/glm-4.6.description": "GLM 4.6 е флагманският модел на Z.AI с разширен контекст и подобрени възможности за програмиране.",
  "zai-glm-4.6.description": "Показва отлични резултати при задачи с програмиране и разсъждение, поддържа стрийминг и извикване на инструменти, подходящ за агентно програмиране и сложни логически задачи.",
  "zai-org/GLM-4.5-Air.description": "GLM-4.5-Air е базов модел за агентни приложения с архитектура Mixture-of-Experts. Оптимизиран е за използване на инструменти, уеб браузване, софтуерно инженерство и фронтенд програмиране, и се интегрира с кодови агенти като Claude Code и Roo Code. Използва хибридно разсъждение за справяне както със сложни, така и с ежедневни задачи.",
  "zai-org/GLM-4.5.description": "GLM-4.5 е базов модел, създаден за агентни приложения с архитектура Mixture-of-Experts. Дълбоко оптимизиран за използване на инструменти, уеб браузване, софтуерно инженерство и фронтенд програмиране, и се интегрира с кодови агенти като Claude Code и Roo Code. Използва хибридно разсъждение за справяне както със сложни, така и с ежедневни задачи.",
  "zai-org/GLM-4.5V.description": "GLM-4.5V е най-новият визуален езиков модел (VLM) на Zhipu AI, изграден върху флагманския текстов модел GLM-4.5-Air (106B общо, 12B активни) с MoE архитектура за висока производителност при по-ниска цена. Следва пътя на GLM-4.1V-Thinking и добавя 3D-RoPE за подобрено пространствено разсъждение в 3D. Оптимизиран чрез предварително обучение, SFT и RL, обработва изображения, видео и дълги документи и е сред водещите отворени модели в 41 публични мултимодални бенчмарка. Режимът Thinking позволява на потребителите да балансират между скорост и дълбочина.",
  "zai-org/GLM-4.6.description": "В сравнение с GLM-4.5, GLM-4.6 разширява контекста от 128K до 200K за по-сложни агентни задачи. Постига по-високи резултати в кодови бенчмаркове и показва по-добра реална производителност в приложения като Claude Code, Cline, Roo Code и Kilo Code, включително по-добро генериране на фронтенд страници. Разсъждението е подобрено и се поддържа използване на инструменти по време на разсъждение, което засилва цялостните възможности. По-добре се интегрира в агентни рамки, подобрява инструментите/търсещите агенти и има по-предпочитан от хора стил на писане и естественост в ролевите сценарии.",
  "zai/glm-4.5-air.description": "GLM-4.5 и GLM-4.5-Air са най-новите ни флагмани за агентни приложения, и двата използват MoE. GLM-4.5 има 355B общо и 32B активни параметри на стъпка; GLM-4.5-Air е по-лек с 106B общо и 12B активни.",
  "zai/glm-4.5.description": "Серията GLM-4.5 е проектирана за агенти. Флагманският GLM-4.5 комбинира разсъждение, програмиране и агентни умения с 355B общи параметри (32B активни) и предлага два режима на работа като хибридна система за разсъждение.",
  "zai/glm-4.5v.description": "GLM-4.5V надгражда GLM-4.5-Air, наследявайки доказани техники от GLM-4.1V-Thinking и мащабира с мощна MoE архитектура с 106 милиарда параметъра.",
  "zenmux/auto.description": "ZenMux автоматично избира най-добрия модел по стойност и производителност от поддържаните опции според вашата заявка."
}
