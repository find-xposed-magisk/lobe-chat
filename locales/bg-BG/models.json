{
  "01-ai/yi-1.5-34b-chat.description": "Най-новият отворен модел на 01.AI с фино настройване и 34 милиарда параметъра, поддържащ множество сценарии за диалог, обучен с висококачествени данни и съобразен с човешките предпочитания.",
  "01-ai/yi-1.5-9b-chat.description": "Най-новият отворен модел на 01.AI с фино настройване и 9 милиарда параметъра, поддържащ множество сценарии за диалог, обучен с висококачествени данни и съобразен с човешките предпочитания.",
  "360/deepseek-r1.description": "DeepSeek-R1, внедрен от 360, използва мащабно подсилващо обучение след предварителното обучение, значително подобрявайки логическото мислене с минимално количество етикетирани данни. Сравним е с OpenAI o1 при задачи по математика, програмиране и езиково разсъждение.",
  "360gpt-pro-trans.description": "Модел, специализиран в превод, фино настроен за водещо качество на превода.",
  "360gpt-pro.description": "360GPT Pro е основен AI модел на 360 с ефективна обработка на текст за разнообразни NLP сценарии, поддържащ разбиране на дълги текстове и многозавойни диалози.",
  "360gpt-turbo-responsibility-8k.description": "360GPT Turbo Responsibility 8K акцентира върху семантичната безопасност и отговорността при чувствително съдържание, осигурявайки точни и надеждни потребителски преживявания.",
  "360gpt-turbo.description": "360GPT Turbo предлага мощни изчислителни и диалогови възможности с отлично семантично разбиране и ефективност на генериране – идеален за предприятия и разработчици.",
  "360gpt2-o1.description": "360gpt2-o1 изгражда верига на мисълта чрез дървовидно търсене с механизъм за рефлексия и обучение чрез подсилване, позволявайки саморефлексия и самокорекция.",
  "360gpt2-pro.description": "360GPT2 Pro е усъвършенстван NLP модел от 360 с отлични възможности за генериране и разбиране на текст, особено при творчески задачи, сложни трансформации и ролеви игри.",
  "360zhinao2-o1.description": "360zhinao2-o1 изгражда верига на мисълта чрез дървовидно търсене с механизъм за рефлексия и обучение чрез подсилване, позволявайки саморефлексия и самокорекция.",
  "4.0Ultra.description": "Spark Ultra е най-мощният модел от серията Spark, подобряващ разбирането и обобщаването на текст, както и уеб търсенето. Това е цялостно решение за повишаване на продуктивността на работното място и точността на отговорите, позиционирайки го като водещ интелигентен продукт.",
  "AnimeSharp.description": "AnimeSharp (известен още като „4x-AnimeSharp“) е отворен модел за суперрезолюция, базиран на ESRGAN от Kim2091, фокусиран върху увеличаване и изостряне на изображения в аниме стил. Преименуван е от „4x-TextSharpV1“ през февруари 2022 г., първоначално предназначен и за текстови изображения, но силно оптимизиран за аниме съдържание.",
  "Baichuan2-Turbo.description": "Използва разширение чрез търсене, за да свърже модела с домейн и уеб знания. Поддържа качване на PDF/Word файлове и въвеждане на URL адреси за навременно, цялостно извличане и професионални, точни резултати.",
  "Baichuan3-Turbo-128k.description": "С ултра-дълъг контекст от 128K, оптимизиран за чести бизнес сценарии с големи подобрения и висока стойност. В сравнение с Baichuan2, създаването на съдържание се подобрява с 20%, отговорите на въпроси – със 17%, а ролевите игри – с 40%. Общата производителност надвишава тази на GPT-3.5.",
  "Baichuan3-Turbo.description": "Оптимизиран за чести бизнес сценарии с големи подобрения и висока стойност. В сравнение с Baichuan2, създаването на съдържание се подобрява с 20%, отговорите на въпроси – със 17%, а ролевите игри – с 40%. Общата производителност надвишава тази на GPT-3.5.",
  "Baichuan4-Air.description": "Водещ модел в Китай, надминаващ основни чуждестранни модели при китайски задачи като знания, дълги текстове и творческо генериране. Също така предлага водещи в индустрията мултимодални възможности с отлични резултати в авторитетни тестове.",
  "Baichuan4-Turbo.description": "Водещ модел в Китай, надминаващ основни чуждестранни модели при китайски задачи като знания, дълги текстове и творческо генериране. Също така предлага водещи в индустрията мултимодални възможности с отлични резултати в авторитетни тестове.",
  "Baichuan4.description": "Водещо вътрешно представяне, надминаващо водещи чуждестранни модели при китайски задачи като енциклопедични знания, дълги текстове и творческо генериране. Осигурява и водещи мултимодални възможности с отлични резултати в тестове.",
  "ByteDance-Seed/Seed-OSS-36B-Instruct.description": "Seed-OSS е семейство от отворени LLM модели от ByteDance Seed, проектирани за силна обработка на дълъг контекст, логическо мислене, агентни и общи способности. Seed-OSS-36B-Instruct е 36B модел, настроен за инструкции, с вграден ултра-дълъг контекст за обработка на големи документи или кодови бази. Оптимизиран е за логическо мислене, генериране на код и агентни задачи (използване на инструменти), като същевременно запазва силни общи способности. Ключова характеристика е „Бюджет за мислене“, позволяващ гъвкава дължина на разсъжденията за по-добра ефективност.",
  "DeepSeek-R1-Distill-Llama-70B.description": "DeepSeek R1, по-големият и по-интелигентен модел от серията DeepSeek, е дистилиран в архитектурата Llama 70B. Тестове и човешки оценки показват, че е по-умен от базовия Llama 70B, особено при задачи по математика и точност на фактите.",
  "DeepSeek-R1-Distill-Qwen-1.5B.description": "Дистилиран модел DeepSeek-R1, базиран на Qwen2.5-Math-1.5B. Подсилващо обучение и cold-start данни оптимизират логическата производителност, поставяйки нови мултизадачни стандарти за отворени модели.",
  "DeepSeek-R1-Distill-Qwen-14B.description": "Моделите DeepSeek-R1-Distill са фино настроени от отворени модели с помощта на примерни данни, генерирани от DeepSeek-R1.",
  "DeepSeek-R1-Distill-Qwen-32B.description": "Моделите DeepSeek-R1-Distill са фино настроени от отворени модели с помощта на примерни данни, генерирани от DeepSeek-R1.",
  "DeepSeek-R1-Distill-Qwen-7B.description": "Дистилиран модел DeepSeek-R1, базиран на Qwen2.5-Math-7B. Подсилващо обучение и cold-start данни оптимизират логическата производителност, поставяйки нови мултизадачни стандарти за отворени модели.",
  "DeepSeek-R1.description": "DeepSeek-R1 прилага мащабно подсилващо обучение след предварителното обучение, значително подобрявайки логическото мислене с много малко етикетирани данни. Сравним е с OpenAI o1 при задачи по математика, програмиране и езиково разсъждение.",
  "DeepSeek-V3-1.description": "DeepSeek V3.1 е следващо поколение модел за логическо мислене с подобрено сложно разсъждение и верига на мисълта, подходящ за задачи с дълбок анализ.",
  "DeepSeek-V3-Fast.description": "Доставчик: sophnet. DeepSeek V3 Fast е високоскоростната версия на DeepSeek V3 0324, с пълна прецизност (без квантизация), по-силен при код и математика и по-бързи отговори.",
  "DeepSeek-V3.1-Fast.description": "DeepSeek V3.1 Fast е високоскоростният вариант на DeepSeek V3.1. Хибриден режим на мислене: чрез шаблони за чат, един модел поддържа както мислещ, така и немислещ режим. По-умно използване на инструменти: следобучение подобрява производителността при инструментални и агентни задачи.",
  "DeepSeek-V3.1-Think.description": "Режим на мислене на DeepSeek-V3.1: нов хибриден модел за разсъждение с мислещ и немислещ режим, по-ефективен от DeepSeek-R1-0528. Оптимизациите след обучението значително подобряват използването на инструменти и производителността при агентни задачи.",
  "DeepSeek-V3.description": "DeepSeek-V3 е MoE модел, разработен от DeepSeek. Надминава други отворени модели като Qwen2.5-72B и Llama-3.1-405B в много тестове и е конкурентен с водещи затворени модели като GPT-4o и Claude 3.5 Sonnet.",
  "amazon/titan-embed-text-v2.description": "Amazon Titan Text Embeddings V2 е лек и ефективен многоезичен модел за вграждане, поддържащ размерности 1024, 512 и 256.",
  "gemini-flash-latest.description": "Последно издание на Gemini Flash",
  "gemini-flash-lite-latest.description": "Последно издание на Gemini Flash-Lite",
  "gemini-pro-latest.description": "Последно издание на Gemini Pro",
  "meta/Llama-3.2-90B-Vision-Instruct.description": "Разширено визуално разсъждение за приложения с агенти за визуално разбиране.",
  "meta/Llama-3.3-70B-Instruct.description": "Llama 3.3 е най-усъвършенстваният многоезичен модел с отворен код от серията Llama, предлагащ производителност, близка до 405B, на много ниска цена. Базиран е на трансформър архитектура и е подобрен чрез SFT и RLHF за полезност и безопасност. Версията, настроена за инструкции, е оптимизирана за многоезичен чат и надминава много отворени и затворени модели в индустриалните бенчмаркове. Граница на знанията: декември 2023 г.",
  "meta/Meta-Llama-3-70B-Instruct.description": "Мощен модел с 70 милиарда параметъра, който се отличава в разсъждение, програмиране и широк спектър от езикови задачи.",
  "meta/Meta-Llama-3-8B-Instruct.description": "Универсален модел с 8 милиарда параметъра, оптимизиран за чат и генериране на текст.",
  "meta/Meta-Llama-3.1-405B-Instruct.description": "Llama 3.1, настроен за инструкции, е текстов модел, оптимизиран за многоезичен чат, с висока производителност в общи индустриални бенчмаркове сред отворени и затворени модели.",
  "meta/Meta-Llama-3.1-70B-Instruct.description": "Llama 3.1, настроен за инструкции, е текстов модел, оптимизиран за многоезичен чат, с висока производителност в общи индустриални бенчмаркове сред отворени и затворени модели.",
  "meta/Meta-Llama-3.1-8B-Instruct.description": "Llama 3.1, настроен за инструкции, е текстов модел, оптимизиран за многоезичен чат, с висока производителност в общи индустриални бенчмаркове сред отворени и затворени модели.",
  "meta/llama-3-70b.description": "Модел с отворен код и 70 милиарда параметъра, фино настроен от Meta за следване на инструкции, предоставян от Groq на LPU хардуер за бързо и ефективно извеждане.",
  "meta/llama-3-8b.description": "Модел с отворен код и 8 милиарда параметъра, фино настроен от Meta за следване на инструкции, предоставян от Groq на LPU хардуер за бързо и ефективно извеждане.",
  "meta/llama-3.1-405b-instruct.description": "Разширен езиков модел, поддържащ генериране на синтетични данни, дестилация на знания и разсъждение за чатботи, програмиране и специализирани задачи.",
  "meta/llama-3.1-70b-instruct.description": "Създаден за сложни диалози с отлично разбиране на контекста, разсъждение и генериране на текст.",
  "meta/llama-3.1-70b.description": "Обновен Meta Llama 3 70B Instruct с 128K контекст, многоезична поддръжка и подобрено разсъждение.",
  "meta/llama-3.1-8b-instruct.description": "Модерен модел с високо ниво на езиково разбиране, разсъждение и генериране на текст.",
  "meta/llama-3.1-8b.description": "Llama 3.1 8B поддържа контекстен прозорец от 128K, идеален за чат в реално време и анализ на данни, като предлага значителни икономии спрямо по-големите модели. Предоставян от Groq на LPU хардуер за бързо и ефективно извеждане.",
  "meta/llama-3.2-11b-vision-instruct.description": "Модел от ново поколение за визуално-езикови задачи, който се отличава с висококачествено разсъждение по изображения.",
  "meta/llama-3.2-11b.description": "Модел, настроен за инструкции, за разсъждение по изображения (вход: текст + изображение, изход: текст), оптимизиран за визуално разпознаване, разсъждение по изображения, надписи и общи въпроси по изображения.",
  "meta/llama-3.2-1b-instruct.description": "Модерен малък езиков модел с високо ниво на разбиране, разсъждение и генериране на текст.",
  "meta/llama-3.2-1b.description": "Само текстов модел за използване на устройства, подходящ за многоезично локално извличане, обобщаване и пренаписване.",
  "meta/llama-3.2-3b-instruct.description": "Модерен малък езиков модел с високо ниво на разбиране, разсъждение и генериране на текст.",
  "meta/llama-3.2-3b.description": "Само текстов модел, фино настроен за използване на устройства, като многоезично локално извличане, обобщаване и пренаписване.",
  "meta/llama-3.2-90b-vision-instruct.description": "Модел от ново поколение за визуално-езикови задачи, който се отличава с висококачествено разсъждение по изображения.",
  "meta/llama-3.2-90b.description": "Модел, настроен за инструкции, за разсъждение по изображения (вход: текст + изображение, изход: текст), оптимизиран за визуално разпознаване, разсъждение по изображения, надписи и общи въпроси по изображения.",
  "meta/llama-3.3-70b-instruct.description": "Разширен езиков модел с високи способности за разсъждение, математика, здрав разум и извикване на функции.",
  "meta/llama-3.3-70b.description": "Идеален баланс между производителност и ефективност. Създаден за високоефективен разговорен ИИ в създаване на съдържание, корпоративни приложения и изследвания, с високо езиково разбиране за обобщаване, класификация, анализ на настроения и генериране на код.",
  "meta/llama-4-maverick.description": "Семейството Llama 4 е роден мултимодален ИИ модел, поддържащ текстови и мултимодални преживявания, използващ MoE за водещо разбиране на текст и изображения. Llama 4 Maverick е модел с 17 милиарда параметъра и 128 експерта, предоставян от DeepInfra.",
  "meta/llama-4-scout.description": "Семейството Llama 4 е роден мултимодален ИИ модел, поддържащ текстови и мултимодални преживявания, използващ MoE за водещо разбиране на текст и изображения. Llama 4 Scout е модел с 17 милиарда параметъра и 16 експерта, предоставян от DeepInfra."
}
