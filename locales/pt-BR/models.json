{
  "01-ai/yi-1.5-34b-chat.description": "O modelo open-source mais recente da 01.AI, ajustado com 34 bilhões de parâmetros. Suporta múltiplos cenários de diálogo, treinado com dados de alta qualidade e alinhado às preferências humanas.",
  "01-ai/yi-1.5-9b-chat.description": "O modelo open-source mais recente da 01.AI, ajustado com 9 bilhões de parâmetros. Suporta múltiplos cenários de diálogo, treinado com dados de alta qualidade e alinhado às preferências humanas.",
  "360/deepseek-r1.description": "O DeepSeek-R1 implantado pela 360 utiliza aprendizado por reforço em larga escala no pós-treinamento para melhorar significativamente o raciocínio com poucos rótulos. Alcança desempenho comparável ao OpenAI o1 em tarefas de matemática, programação e raciocínio em linguagem natural.",
  "360gpt-pro-trans.description": "Modelo especializado em tradução, profundamente ajustado para oferecer qualidade de tradução de ponta.",
  "360gpt-pro.description": "O 360GPT Pro é um modelo central da 360 AI com processamento de texto eficiente para diversos cenários de PLN, com suporte à compreensão de textos longos e diálogos de múltiplas interações.",
  "360gpt-turbo-responsibility-8k.description": "O 360GPT Turbo Responsibility 8K enfatiza a segurança semântica e a responsabilidade em aplicações sensíveis a conteúdo, garantindo experiências precisas e robustas para o usuário.",
  "360gpt-turbo.description": "O 360GPT Turbo oferece forte capacidade de computação e chat com excelente compreensão semântica e eficiência de geração, ideal para empresas e desenvolvedores.",
  "360gpt2-o1.description": "O 360gpt2-o1 constrói cadeias de raciocínio por meio de busca em árvore com mecanismo de reflexão e treinamento por reforço, permitindo autorreflexão e autocorreção.",
  "360gpt2-pro.description": "O 360GPT2 Pro é um modelo avançado de PLN da 360 com excelente geração e compreensão de texto, especialmente para tarefas criativas, transformações complexas e simulações de papéis.",
  "360zhinao2-o1.description": "O 360zhinao2-o1 constrói cadeias de raciocínio por meio de busca em árvore com mecanismo de reflexão e treinamento por reforço, permitindo autorreflexão e autocorreção.",
  "4.0Ultra.description": "O Spark Ultra é o modelo mais poderoso da série Spark, aprimorando a compreensão e a sumarização de texto, além de melhorar a busca na web. É uma solução completa para aumentar a produtividade no trabalho e fornecer respostas precisas, posicionando-se como um produto inteligente de destaque.",
  "AnimeSharp.description": "AnimeSharp (também conhecido como \"4x-AnimeSharp\") é um modelo open-source de super-resolução baseado no ESRGAN de Kim2091, focado em ampliar e aprimorar imagens no estilo anime. Foi renomeado de \"4x-TextSharpV1\" em fevereiro de 2022, originalmente também voltado para imagens de texto, mas fortemente otimizado para conteúdo de anime.",
  "Baichuan2-Turbo.description": "Utiliza aumento por busca para conectar o modelo ao conhecimento de domínio e da web. Suporta upload de arquivos PDF/Word e entrada de URLs para recuperação abrangente e atualizada, com saídas profissionais e precisas.",
  "Baichuan3-Turbo-128k.description": "Com uma janela de contexto ultra longa de 128K, é otimizado para cenários empresariais de alta frequência, com ganhos significativos e alto valor. Em comparação com o Baichuan2, a criação de conteúdo melhora em 20%, perguntas e respostas em 17% e simulação de papéis em 40%. O desempenho geral supera o GPT-3.5.",
  "Baichuan3-Turbo.description": "Otimizado para cenários empresariais de alta frequência, com ganhos significativos e alto valor. Em comparação com o Baichuan2, a criação de conteúdo melhora em 20%, perguntas e respostas em 17% e simulação de papéis em 40%. O desempenho geral supera o GPT-3.5.",
  "Baichuan4-Air.description": "Modelo de alto desempenho na China, superando modelos internacionais em tarefas em chinês como conhecimento, textos longos e geração criativa. Também possui capacidades multimodais líderes do setor com resultados fortes em benchmarks reconhecidos.",
  "Baichuan4-Turbo.description": "Modelo de alto desempenho na China, superando modelos internacionais em tarefas em chinês como conhecimento, textos longos e geração criativa. Também possui capacidades multimodais líderes do setor com resultados fortes em benchmarks reconhecidos.",
  "Baichuan4.description": "Desempenho doméstico de ponta, superando modelos internacionais líderes em tarefas em chinês como conhecimento enciclopédico, textos longos e geração criativa. Também oferece capacidades multimodais líderes do setor e resultados sólidos em benchmarks.",
  "ByteDance-Seed/Seed-OSS-36B-Instruct.description": "Seed-OSS é uma família de LLMs open-source da ByteDance Seed, projetada para lidar com contextos longos, raciocínio, agentes e habilidades gerais. O Seed-OSS-36B-Instruct é um modelo de 36B ajustado por instruções com suporte nativo a contextos ultra longos, ideal para processar grandes documentos ou bases de código. É otimizado para raciocínio, geração de código e tarefas de agente (uso de ferramentas), mantendo forte capacidade geral. Um recurso-chave é o \"Orçamento de Pensamento\", que permite flexibilidade no comprimento do raciocínio para melhorar a eficiência.",
  "DeepSeek-R1-Distill-Llama-70B.description": "DeepSeek R1, o modelo maior e mais inteligente da suíte DeepSeek, foi destilado na arquitetura Llama 70B. Benchmarks e avaliações humanas mostram que é mais inteligente que o Llama 70B base, especialmente em tarefas de matemática e precisão factual.",
  "DeepSeek-R1-Distill-Qwen-1.5B.description": "Modelo destilado do DeepSeek-R1 baseado no Qwen2.5-Math-1.5B. Aprendizado por reforço e dados de inicialização a frio otimizam o desempenho em raciocínio, estabelecendo novos benchmarks multitarefa para modelos open-source.",
  "DeepSeek-R1-Distill-Qwen-14B.description": "Os modelos DeepSeek-R1-Distill são ajustados a partir de modelos open-source usando dados de amostra gerados pelo DeepSeek-R1.",
  "DeepSeek-R1-Distill-Qwen-32B.description": "Os modelos DeepSeek-R1-Distill são ajustados a partir de modelos open-source usando dados de amostra gerados pelo DeepSeek-R1.",
  "DeepSeek-R1-Distill-Qwen-7B.description": "Modelo destilado do DeepSeek-R1 baseado no Qwen2.5-Math-7B. Aprendizado por reforço e dados de inicialização a frio otimizam o desempenho em raciocínio, estabelecendo novos benchmarks multitarefa para modelos open-source.",
  "DeepSeek-R1.description": "O DeepSeek-R1 aplica aprendizado por reforço em larga escala durante o pós-treinamento, aumentando significativamente o raciocínio com muito poucos dados rotulados. Alcança desempenho comparável ao modelo de produção OpenAI o1 em tarefas de matemática, código e raciocínio em linguagem natural.",
  "DeepSeek-V3-1.description": "O DeepSeek V3.1 é um modelo de raciocínio de próxima geração com raciocínio complexo aprimorado e cadeia de pensamento, adequado para tarefas de análise profunda.",
  "DeepSeek-V3-Fast.description": "Fornecedor: sophnet. O DeepSeek V3 Fast é a versão de alta TPS do DeepSeek V3 0324, com precisão total (não quantizado), respostas mais rápidas e desempenho superior em código e matemática.",
  "DeepSeek-V3.1-Fast.description": "O DeepSeek V3.1 Fast é a variante rápida de alta TPS do DeepSeek V3.1. Modo de pensamento híbrido: via templates de chat, um único modelo suporta modos com e sem raciocínio. Uso de ferramentas mais inteligente: o pós-treinamento melhora o desempenho em tarefas de agente e uso de ferramentas.",
  "DeepSeek-V3.1-Think.description": "Modo de pensamento do DeepSeek-V3.1: um novo modelo híbrido de raciocínio com modos de pensamento e não pensamento, mais eficiente que o DeepSeek-R1-0528. Otimizações no pós-treinamento melhoram significativamente o uso de ferramentas de agente e o desempenho em tarefas de agente.",
  "DeepSeek-V3.description": "O DeepSeek-V3 é um modelo MoE desenvolvido pela DeepSeek. Supera outros modelos open-source como Qwen2.5-72B e Llama-3.1-405B em muitos benchmarks e é competitivo com modelos fechados líderes como GPT-4o e Claude 3.5 Sonnet.",
  "Doubao-lite-128k.description": "O Doubao-lite oferece respostas ultra rápidas e melhor custo-benefício, com opções flexíveis para diversos cenários. Suporta contexto de 128K para inferência e ajuste fino.",
  "Doubao-lite-32k.description": "O Doubao-lite oferece respostas ultra rápidas e melhor custo-benefício, com opções flexíveis para diversos cenários. Suporta contexto de 32K para inferência e ajuste fino.",
  "Doubao-lite-4k.description": "O Doubao-lite oferece respostas ultra rápidas e melhor custo-benefício, com opções flexíveis para diversos cenários. Suporta contexto de 4K para inferência e ajuste fino.",
  "Doubao-pro-128k.description": "Modelo carro-chefe de melhor desempenho para tarefas complexas, com excelência em perguntas e respostas com referência, sumarização, criação, classificação e simulação de papéis. Suporta contexto de 128K para inferência e ajuste fino.",
  "Doubao-pro-32k.description": "Modelo carro-chefe de melhor desempenho para tarefas complexas, com excelência em perguntas e respostas com referência, sumarização, criação, classificação e simulação de papéis. Suporta contexto de 32K para inferência e ajuste fino.",
  "Doubao-pro-4k.description": "Modelo carro-chefe de melhor desempenho para tarefas complexas, com excelência em perguntas e respostas com referência, sumarização, criação, classificação e simulação de papéis. Suporta contexto de 4K para inferência e ajuste fino.",
  "DreamO.description": "DreamO é um modelo open-source de personalização de imagens desenvolvido em conjunto pela ByteDance e pela Universidade de Pequim, utilizando uma arquitetura unificada para suportar geração de imagens multitarefa. Emprega modelagem composicional eficiente para gerar imagens altamente consistentes e personalizadas com base em identidade, tema, estilo, fundo e outras condições especificadas pelo usuário.",
  "ERNIE-3.5-128K.description": "Modelo LLM de grande escala da Baidu, treinado com vastos corpora em chinês/inglês, com forte capacidade geral para conversas, criação e uso de plugins; suporta integração automática com o plugin de busca Baidu para respostas atualizadas.",
  "ERNIE-3.5-8K-Preview.description": "Modelo LLM de grande escala da Baidu, treinado com vastos corpora em chinês/inglês, com forte capacidade geral para conversas, criação e uso de plugins; suporta integração automática com o plugin de busca Baidu para respostas atualizadas.",
  "ERNIE-3.5-8K.description": "Modelo LLM de grande escala da Baidu, treinado com vastos corpora em chinês/inglês, com forte capacidade geral para conversas, criação e uso de plugins; suporta integração automática com o plugin de busca Baidu para respostas atualizadas.",
  "ERNIE-4.0-8K-Latest.description": "Modelo LLM ultra-avançado da Baidu com melhorias abrangentes em relação ao ERNIE 3.5, adequado para tarefas complexas em diversos domínios; suporta integração com o plugin de busca Baidu para respostas atualizadas.",
  "ERNIE-4.0-8K-Preview.description": "Modelo LLM ultra-avançado da Baidu com melhorias abrangentes em relação ao ERNIE 3.5, adequado para tarefas complexas em diversos domínios; suporta integração com o plugin de busca Baidu para respostas atualizadas.",
  "ERNIE-4.0-Turbo-8K-Latest.description": "Modelo LLM ultra-avançado da Baidu com desempenho geral robusto para tarefas complexas, com integração ao plugin de busca Baidu para respostas atualizadas. Supera o ERNIE 4.0.",
  "ERNIE-4.0-Turbo-8K-Preview.description": "Modelo LLM ultra-avançado da Baidu com desempenho geral robusto para tarefas complexas, com integração ao plugin de busca Baidu para respostas atualizadas. Supera o ERNIE 4.0.",
  "ERNIE-Character-8K.description": "Modelo LLM da Baidu voltado para domínios específicos como NPCs de jogos, atendimento ao cliente e interpretação de personagens, com maior consistência de persona, melhor seguimento de instruções e raciocínio aprimorado.",
  "ERNIE-Lite-Pro-128K.description": "Modelo LLM leve da Baidu que equilibra qualidade e desempenho de inferência, superior ao ERNIE Lite e adequado para aceleradores de baixo custo computacional.",
  "ERNIE-Speed-128K.description": "Modelo LLM de alto desempenho mais recente da Baidu (2024), com forte capacidade geral, ideal como base para ajustes finos em cenários específicos, com excelente desempenho em raciocínio.",
  "ERNIE-Speed-Pro-128K.description": "Modelo LLM de alto desempenho mais recente da Baidu (2024), com forte capacidade geral, superior ao ERNIE Speed, ideal como base para ajustes finos com excelente desempenho em raciocínio.",
  "FLUX-1.1-pro.description": "FLUX.1.1 Pro",
  "FLUX.1-Kontext-dev.description": "FLUX.1-Kontext-dev é um modelo multimodal de geração e edição de imagens do Black Forest Labs baseado em uma arquitetura Rectified Flow Transformer com 12 bilhões de parâmetros. Foca na geração, reconstrução, aprimoramento ou edição de imagens sob condições contextuais específicas. Combina os pontos fortes da geração controlável dos modelos de difusão com o modelamento de contexto dos Transformers, oferecendo saídas de alta qualidade para tarefas como inpainting, outpainting e reconstrução de cenas visuais.",
  "FLUX.1-Kontext-pro.description": "FLUX.1 Kontext [pro]",
  "FLUX.1-dev.description": "FLUX.1-dev é um modelo de linguagem multimodal de código aberto (MLLM) do Black Forest Labs, otimizado para tarefas de imagem e texto, combinando compreensão e geração de imagem/texto. Baseado em LLMs avançados (como Mistral-7B), utiliza um codificador visual cuidadosamente projetado e ajuste de instruções em múltiplas etapas para permitir coordenação multimodal e raciocínio em tarefas complexas.",
  "Gryphe/MythoMax-L2-13b.description": "MythoMax-L2 (13B) é um modelo inovador para diversos domínios e tarefas complexas.",
  "HelloMeme.description": "HelloMeme é uma ferramenta de IA que gera memes, GIFs ou vídeos curtos a partir de imagens ou movimentos fornecidos. Não requer habilidades de desenho ou programação—basta uma imagem de referência para criar conteúdo divertido, atrativo e estilisticamente consistente.",
  "HiDream-I1-Full.description": "HiDream-E1-Full é um modelo de edição de imagem multimodal de código aberto da HiDream.ai, baseado em uma arquitetura Diffusion Transformer avançada e forte compreensão de linguagem (com LLaMA 3.1-8B-Instruct embutido). Suporta geração de imagens guiada por linguagem natural, transferência de estilo, edições locais e repintura, com excelente compreensão e execução imagem-texto.",
  "HunyuanDiT-v1.2-Diffusers-Distilled.description": "hunyuandit-v1.2-distilled é um modelo leve de texto para imagem otimizado via destilação para gerar imagens de alta qualidade rapidamente, especialmente adequado para ambientes com poucos recursos e geração em tempo real.",
  "InstantCharacter.description": "InstantCharacter é um modelo de geração de personagens personalizados sem necessidade de ajuste, lançado pela Tencent AI em 2025, com foco em geração de personagens de alta fidelidade e consistência entre cenários. Pode modelar um personagem a partir de uma única imagem de referência e transferi-lo com flexibilidade entre estilos, ações e cenários.",
  "InternVL2-8B.description": "InternVL2-8B é um poderoso modelo visão-linguagem que suporta processamento multimodal de imagem e texto, reconhecendo com precisão o conteúdo visual e gerando descrições ou respostas relevantes.",
  "InternVL2.5-26B.description": "InternVL2.5-26B é um poderoso modelo visão-linguagem que suporta processamento multimodal de imagem e texto, reconhecendo com precisão o conteúdo visual e gerando descrições ou respostas relevantes.",
  "Kolors.description": "Kolors é um modelo de texto para imagem desenvolvido pela equipe Kolors da Kuaishou. Treinado com bilhões de parâmetros, apresenta vantagens notáveis em qualidade visual, compreensão semântica do chinês e renderização de texto.",
  "Kwai-Kolors/Kolors.description": "Kolors é um modelo de texto para imagem de difusão latente em larga escala da equipe Kolors da Kuaishou. Treinado com bilhões de pares texto-imagem, destaca-se em qualidade visual, precisão semântica complexa e renderização de texto em chinês/inglês, com forte compreensão e geração de conteúdo em chinês.",
  "Kwaipilot/KAT-Dev.description": "KAT-Dev (32B) é um modelo de código aberto com 32 bilhões de parâmetros para tarefas de engenharia de software. Alcança uma taxa de resolução de 62,4% no SWE-Bench Verified, ocupando o 5º lugar entre os modelos abertos. É otimizado por meio de mid-training, SFT e RL para preenchimento de código, correção de bugs e revisão de código.",
  "Llama-3.2-11B-Vision-Instruct.description": "Raciocínio visual avançado em imagens de alta resolução, adequado para aplicações de compreensão visual.",
  "Llama-3.2-90B-Vision-Instruct\t.description": "Raciocínio visual avançado para aplicações de agentes com compreensão visual.",
  "Meta-Llama-3-3-70B-Instruct.description": "Llama 3.3 70B é um modelo Transformer versátil para tarefas de conversa e geração.",
  "Meta-Llama-3.1-405B-Instruct.description": "Modelo de texto ajustado por instruções Llama 3.1, otimizado para conversas multilíngues, com desempenho destacado em benchmarks da indústria entre modelos abertos e fechados.",
  "Meta-Llama-3.1-70B-Instruct.description": "Modelo de texto ajustado por instruções Llama 3.1, otimizado para conversas multilíngues, com desempenho destacado em benchmarks da indústria entre modelos abertos e fechados.",
  "Meta-Llama-3.1-8B-Instruct.description": "Modelo de texto ajustado por instruções Llama 3.1, otimizado para conversas multilíngues, com desempenho destacado em benchmarks da indústria entre modelos abertos e fechados.",
  "Meta-Llama-3.2-1B-Instruct.description": "Modelo de linguagem pequeno e de ponta com forte compreensão linguística, excelente raciocínio e geração de texto.",
  "Meta-Llama-3.2-3B-Instruct.description": "Modelo de linguagem pequeno e de ponta com forte compreensão linguística, excelente raciocínio e geração de texto.",
  "Meta-Llama-3.3-70B-Instruct.description": "Llama 3.3 é o modelo Llama multilíngue de código aberto mais avançado, oferecendo desempenho próximo ao de modelos de 405B a um custo muito baixo. Baseado em Transformer e aprimorado com SFT e RLHF para utilidade e segurança. A versão ajustada por instruções é otimizada para conversas multilíngues e supera muitos modelos abertos e fechados em benchmarks da indústria. Data de corte do conhecimento: dezembro de 2023.",
  "Meta-Llama-4-Maverick-17B-128E-Instruct-FP8.description": "Llama 4 Maverick é um modelo MoE de grande porte com ativação eficiente de especialistas para desempenho robusto em raciocínio.",
  "MiniMax-M1.description": "Um novo modelo de raciocínio interno com 80 mil cadeias de pensamento e 1 milhão de tokens de entrada, oferecendo desempenho comparável aos principais modelos globais.",
  "MiniMax-M2-Stable.description": "Projetado para fluxos de trabalho de codificação e agentes eficientes, com maior concorrência para uso comercial.",
  "MiniMax-M2.description": "Projetado para fluxos de trabalho de codificação e agentes eficientes.",
  "MiniMax-Text-01.description": "O MiniMax-01 introduz atenção linear em larga escala além dos Transformers clássicos, com 456 bilhões de parâmetros e 45,9 bilhões ativados por passagem. Alcança desempenho de ponta e suporta até 4 milhões de tokens de contexto (32× GPT-4o, 20× Claude-3.5-Sonnet).",
  "MiniMaxAI/MiniMax-M1-80k.description": "MiniMax-M1 é um modelo de raciocínio com pesos abertos, atenção híbrida em larga escala, com 456 bilhões de parâmetros totais e ~45,9 bilhões ativos por token. Suporta nativamente 1 milhão de tokens de contexto e utiliza Flash Attention para reduzir FLOPs em 75% na geração de 100 mil tokens em comparação com o DeepSeek R1. Com arquitetura MoE, CISPO e treinamento com atenção híbrida via RL, atinge desempenho líder em raciocínio com entradas longas e tarefas reais de engenharia de software.",
  "MiniMaxAI/MiniMax-M2.description": "MiniMax-M2 redefine a eficiência de agentes. É um modelo MoE compacto, rápido e econômico com 230 bilhões de parâmetros totais e 10 bilhões ativos, projetado para tarefas de codificação e agentes de alto nível, mantendo forte inteligência geral. Com apenas 10 bilhões de parâmetros ativos, rivaliza com modelos muito maiores, sendo ideal para aplicações de alta eficiência.",
  "Moonshot-Kimi-K2-Instruct.description": "1 trilhão de parâmetros totais com 32 bilhões ativos. Entre os modelos sem modo de pensamento, é de ponta em conhecimento avançado, matemática e codificação, com desempenho superior em tarefas gerais de agentes. Otimizado para cargas de trabalho de agentes, pode agir, não apenas responder perguntas. Ideal para conversas improvisadas, bate-papo geral e experiências com agentes como um modelo de reflexo, sem pensamento prolongado.",
  "NousResearch/Nous-Hermes-2-Mixtral-8x7B-DPO.description": "Nous Hermes 2 - Mixtral 8x7B-DPO (46,7B) é um modelo de instrução de alta precisão para cálculos complexos.",
  "OmniConsistency.description": "OmniConsistency melhora a consistência de estilo e a generalização em tarefas de imagem para imagem ao introduzir Diffusion Transformers (DiTs) em larga escala e dados estilizados pareados, evitando a degradação de estilo.",
  "Phi-3-medium-128k-instruct.description": "O mesmo modelo Phi-3-medium com uma janela de contexto maior para RAG ou prompts de poucos exemplos.",
  "Phi-3-medium-4k-instruct.description": "Um modelo com 14 bilhões de parâmetros e qualidade superior ao Phi-3-mini, focado em dados de alta qualidade e raciocínio intensivo.",
  "Phi-3-mini-128k-instruct.description": "O mesmo modelo Phi-3-mini com uma janela de contexto maior para RAG ou prompts de poucos exemplos.",
  "Phi-3-mini-4k-instruct.description": "O menor membro da família Phi-3, otimizado para qualidade e baixa latência.",
  "Phi-3-small-128k-instruct.description": "O mesmo modelo Phi-3-small com uma janela de contexto maior para RAG ou prompts de poucos exemplos.",
  "Phi-3-small-8k-instruct.description": "Um modelo com 7 bilhões de parâmetros e qualidade superior ao Phi-3-mini, focado em dados de alta qualidade e raciocínio intensivo.",
  "Phi-3.5-mini-instruct.description": "Uma versão atualizada do modelo Phi-3-mini.",
  "Phi-3.5-vision-instrust.description": "Uma versão atualizada do modelo Phi-3-vision.",
  "Pro/Qwen/Qwen2-7B-Instruct.description": "Qwen2-7B-Instruct é um LLM de 7 bilhões de parâmetros ajustado para instruções da série Qwen2. Utiliza arquitetura Transformer com SwiGLU, viés QKV na atenção e atenção com consultas agrupadas, lidando com entradas grandes. Apresenta forte desempenho em compreensão de linguagem, geração, tarefas multilíngues, codificação, matemática e raciocínio, superando a maioria dos modelos abertos e competindo com modelos proprietários. Supera o Qwen1.5-7B-Chat em vários benchmarks.",
  "Pro/Qwen/Qwen2.5-7B-Instruct.description": "Qwen2.5-7B-Instruct faz parte da mais recente série de LLMs da Alibaba Cloud. O modelo de 7 bilhões traz ganhos notáveis em codificação e matemática, suporta mais de 29 idiomas e melhora o seguimento de instruções, compreensão de dados estruturados e geração de saídas estruturadas (especialmente JSON).",
  "Pro/Qwen/Qwen2.5-Coder-7B-Instruct.description": "Qwen2.5-Coder-7B-Instruct é o mais recente LLM da Alibaba Cloud focado em código. Baseado no Qwen2.5 e treinado com 5,5 trilhões de tokens, melhora significativamente a geração, raciocínio e correção de código, mantendo pontos fortes em matemática e capacidades gerais, oferecendo uma base sólida para agentes de codificação.",
  "Pro/Qwen/Qwen2.5-VL-7B-Instruct.description": "Qwen2.5-VL é um novo modelo de linguagem e visão da série Qwen com forte compreensão visual. Analisa texto, gráficos e layouts em imagens, entende vídeos longos e eventos, suporta raciocínio e uso de ferramentas, ancoragem de objetos em múltiplos formatos e saídas estruturadas. Melhora a resolução dinâmica e o treinamento com taxa de quadros para compreensão de vídeo e aumenta a eficiência do codificador visual.",
  "Pro/THUDM/GLM-4.1V-9B-Thinking.description": "GLM-4.1V-9B-Thinking é um modelo VLM de código aberto da Zhipu AI e do Laboratório KEG da Universidade Tsinghua, projetado para cognição multimodal complexa. Baseado no GLM-4-9B-0414, adiciona raciocínio em cadeia e aprendizado por reforço (RL) para melhorar significativamente o raciocínio entre modalidades e a estabilidade.",
  "Pro/THUDM/glm-4-9b-chat.description": "GLM-4-9B-Chat é o modelo GLM-4 de código aberto da Zhipu AI. Apresenta forte desempenho em semântica, matemática, raciocínio, código e conhecimento. Além de bate-papo com múltiplas interações, suporta navegação na web, execução de código, chamadas de ferramentas personalizadas e raciocínio com textos longos. Suporta 26 idiomas (incluindo chinês, inglês, japonês, coreano e alemão). Apresenta bom desempenho nos benchmarks AlignBench-v2, MT-Bench, MMLU e C-Eval, e suporta até 128 mil tokens de contexto para uso acadêmico e empresarial.",
  "Pro/deepseek-ai/DeepSeek-R1-Distill-Qwen-7B.description": "DeepSeek-R1-Distill-Qwen-7B é destilado do Qwen2.5-Math-7B e ajustado com 800 mil amostras curadas do DeepSeek-R1. Apresenta desempenho forte, com 92,8% no MATH-500, 55,5% no AIME 2024 e uma pontuação de 1189 no CodeForces para um modelo de 7B.",
  "Pro/deepseek-ai/DeepSeek-R1.description": "DeepSeek-R1 é um modelo de raciocínio orientado por RL que reduz repetições e melhora a legibilidade. Utiliza dados de início a frio antes do RL para impulsionar ainda mais o raciocínio, iguala o OpenAI-o1 em tarefas de matemática, código e raciocínio, e melhora os resultados gerais por meio de treinamento cuidadoso.",
  "Pro/deepseek-ai/DeepSeek-V3.1-Terminus.description": "DeepSeek-V3.1-Terminus é uma versão atualizada do modelo V3.1, posicionado como um LLM híbrido para agentes. Corrige problemas relatados por usuários e melhora a estabilidade, consistência linguística e reduz caracteres anormais e mistura de chinês/inglês. Integra modos de pensamento e não-pensamento com templates de chat para alternância flexível. Também melhora o desempenho dos agentes de código e de busca para uso mais confiável de ferramentas e tarefas em múltiplas etapas.",
  "Pro/deepseek-ai/DeepSeek-V3.2-Exp.description": "DeepSeek-V3.2-Exp é uma versão experimental da série V3.2 que faz a ponte para a próxima arquitetura. Adiciona DeepSeek Sparse Attention (DSA) sobre o V3.1-Terminus para melhorar o treinamento e a inferência com contexto longo, com otimizações para uso de ferramentas, compreensão de documentos longos e raciocínio em múltiplas etapas. Ideal para explorar maior eficiência de raciocínio com orçamentos de contexto amplos.",
  "Pro/deepseek-ai/DeepSeek-V3.description": "DeepSeek-V3 é um modelo MoE com 671 bilhões de parâmetros, utilizando MLA e DeepSeekMoE com balanceamento de carga sem perdas para inferência e treinamento eficientes. Pré-treinado com 14,8 trilhões de tokens de alta qualidade e ajustado com SFT e RL, supera outros modelos abertos e se aproxima dos modelos fechados líderes.",
  "Pro/moonshotai/Kimi-K2-Instruct-0905.description": "Kimi K2-Instruct-0905 é o mais novo e poderoso modelo Kimi K2. Trata-se de um modelo MoE de alto nível com 1 trilhão de parâmetros totais e 32 bilhões de parâmetros ativos. Seus principais recursos incluem inteligência de codificação agentica aprimorada, com ganhos significativos em benchmarks e tarefas reais de agentes, além de melhorias na estética e usabilidade da codificação de frontend.",
  "Pro/moonshotai/Kimi-K2-Thinking.description": "Kimi K2 Thinking Turbo é a variante Turbo otimizada para velocidade de raciocínio e rendimento, mantendo o raciocínio em múltiplas etapas e o uso de ferramentas do K2 Thinking. É um modelo MoE com aproximadamente 1 trilhão de parâmetros totais, contexto nativo de 256K e chamadas de ferramentas em larga escala estáveis para cenários de produção com exigências mais rigorosas de latência e concorrência.",
  "QwQ-32B-Preview.description": "Qwen QwQ é um modelo de pesquisa experimental focado em aprimorar o raciocínio.",
  "Qwen/QVQ-72B-Preview.description": "QVQ-72B-Preview é um modelo de pesquisa da Qwen focado em raciocínio visual, com pontos fortes em compreensão de cenas complexas e problemas visuais de matemática.",
  "Qwen/QwQ-32B-Preview.description": "Qwen QwQ é um modelo de pesquisa experimental focado em aprimorar o raciocínio da IA.",
  "Qwen/QwQ-32B.description": "QwQ é um modelo de raciocínio da família Qwen. Em comparação com modelos padrão ajustados por instrução, ele adiciona capacidades de pensamento e raciocínio que aumentam significativamente o desempenho em tarefas subsequentes, especialmente em problemas difíceis. O QwQ-32B é um modelo de raciocínio de porte médio competitivo com os principais modelos de raciocínio como DeepSeek-R1 e o1-mini. Utiliza RoPE, SwiGLU, RMSNorm e viés QKV na atenção, com 64 camadas e 40 cabeças de atenção Q (8 KV em GQA).",
  "Qwen/Qwen-Image-Edit-2509.description": "Qwen-Image-Edit-2509 é a versão mais recente de edição de imagens da Qwen-Image, desenvolvida pela equipe Qwen. Baseado no modelo Qwen-Image de 20B, ele estende a renderização de texto de alta qualidade para edição de imagens com precisão textual. Utiliza uma arquitetura de controle duplo, enviando entradas para o Qwen2.5-VL para controle semântico e para um codificador VAE para controle de aparência, permitindo edições tanto no nível semântico quanto visual. Suporta edições locais (adicionar/remover/modificar) e edições semânticas de alto nível como criação de IP e transferência de estilo, preservando o significado. Alcança resultados SOTA em diversos benchmarks.",
  "Qwen/Qwen-Image.description": "Qwen-Image é um modelo base de geração de imagens com 20 bilhões de parâmetros da equipe Qwen. Apresenta avanços significativos na renderização de texto complexo e edição precisa de imagens, especialmente para textos em chinês/inglês de alta fidelidade. Suporta layouts de múltiplas linhas e parágrafos mantendo a coerência tipográfica. Além da renderização de texto, oferece uma ampla gama de estilos, desde fotorrealismo até anime, e edições avançadas como transferência de estilo, adição/remoção de objetos, aprimoramento de detalhes, edição de texto e controle de pose, visando ser uma base abrangente para criação visual.",
  "Qwen/Qwen2-72B-Instruct.description": "Qwen 2 Instruct (72B) oferece seguimento preciso de instruções para cargas de trabalho empresariais.",
  "Qwen/Qwen2-7B-Instruct.description": "Qwen2-7B-Instruct é um modelo ajustado por instruções com 7 bilhões de parâmetros da série Qwen2, utilizando Transformer, SwiGLU, viés QKV e atenção com consulta agrupada. Lida com entradas grandes e apresenta desempenho sólido em benchmarks de compreensão, geração, multilinguismo, programação, matemática e raciocínio, superando a maioria dos modelos abertos e ultrapassando o Qwen1.5-7B-Chat em várias avaliações.",
  "Qwen/Qwen2-VL-72B-Instruct.description": "Qwen2-VL é o modelo mais recente da linha Qwen-VL, alcançando SOTA em benchmarks de visão como MathVista, DocVQA, RealWorldQA e MTVQA. Consegue compreender vídeos com mais de 20 minutos para perguntas sobre vídeos, diálogos e criação de conteúdo. Também oferece raciocínio complexo e tomada de decisão, integrando-se a dispositivos/robôs para ações guiadas por visão. Além do inglês e chinês, consegue ler textos em diversos idiomas, incluindo a maioria das línguas europeias, japonês, coreano, árabe e vietnamita.",
  "Qwen/Qwen2.5-14B-Instruct.description": "Qwen2.5-14B-Instruct faz parte da mais recente série de LLMs da Alibaba Cloud. O modelo de 14 bilhões de parâmetros apresenta ganhos notáveis em programação e matemática, suporta mais de 29 idiomas e melhora o seguimento de instruções, compreensão de dados estruturados e geração de saídas estruturadas (especialmente JSON).",
  "Qwen/Qwen2.5-32B-Instruct.description": "Qwen2.5-32B-Instruct faz parte da mais recente série de LLMs da Alibaba Cloud. O modelo de 32 bilhões de parâmetros apresenta ganhos notáveis em programação e matemática, suporta mais de 29 idiomas e melhora o seguimento de instruções, compreensão de dados estruturados e geração de saídas estruturadas (especialmente JSON).",
  "Qwen/Qwen2.5-72B-Instruct-128K.description": "Qwen2.5-72B-Instruct faz parte da mais recente série de LLMs da Alibaba Cloud. O modelo de 72 bilhões de parâmetros melhora a programação e a matemática, suporta até 128K de entrada e mais de 8K de saída, oferece suporte a mais de 29 idiomas e aprimora o seguimento de instruções e a geração de saídas estruturadas (especialmente JSON).",
  "Qwen/Qwen2.5-72B-Instruct-Turbo.description": "Qwen2.5 é uma nova família de LLMs otimizada para tarefas baseadas em instruções.",
  "Qwen/Qwen2.5-72B-Instruct.description": "Qwen2.5-72B-Instruct faz parte da mais recente série de LLMs da Alibaba Cloud. O modelo de 72 bilhões de parâmetros apresenta ganhos notáveis em programação e matemática, suporta mais de 29 idiomas e melhora o seguimento de instruções, compreensão de dados estruturados e geração de saídas estruturadas (especialmente JSON).",
  "Qwen/Qwen2.5-7B-Instruct-Turbo.description": "Qwen2.5 é uma nova família de LLMs otimizada para tarefas baseadas em instruções.",
  "Qwen/Qwen2.5-7B-Instruct.description": "Qwen2.5-7B-Instruct faz parte da mais recente série de LLMs da Alibaba Cloud. O modelo de 7 bilhões de parâmetros apresenta ganhos notáveis em programação e matemática, suporta mais de 29 idiomas e melhora o seguimento de instruções, compreensão de dados estruturados e geração de saídas estruturadas (especialmente JSON).",
  "Qwen/Qwen2.5-Coder-32B-Instruct.description": "Qwen2.5 Coder 32B Instruct é o mais recente LLM da Alibaba Cloud focado em código. Baseado no Qwen2.5 e treinado com 5,5 trilhões de tokens, melhora significativamente a geração, raciocínio e correção de código, mantendo pontos fortes em matemática e tarefas gerais, oferecendo uma base sólida para agentes de programação.",
  "Qwen/Qwen2.5-Coder-7B-Instruct.description": "Qwen2.5-Coder-7B-Instruct é o mais recente LLM da Alibaba Cloud focado em código. Baseado no Qwen2.5 e treinado com 5,5 trilhões de tokens, melhora significativamente a geração, raciocínio e correção de código, mantendo pontos fortes em matemática e tarefas gerais, oferecendo uma base sólida para agentes de programação.",
  "Qwen/Qwen2.5-VL-32B-Instruct.description": "Qwen2.5-VL-32B-Instruct é um modelo multimodal da equipe Qwen. Reconhece objetos comuns e analisa texto, gráficos, ícones, imagens e layouts. Como agente visual, pode raciocinar e controlar ferramentas dinamicamente, incluindo uso de computador e celular. Localiza objetos com precisão e gera saídas estruturadas para faturas e tabelas. Em comparação com o Qwen2-VL, o RL melhora ainda mais a matemática e a resolução de problemas, com respostas mais alinhadas às preferências humanas.",
  "Qwen/Qwen2.5-VL-72B-Instruct.description": "Qwen2.5-VL é o modelo de visão e linguagem da série Qwen2.5 com grandes melhorias: compreensão visual mais forte para objetos, texto, gráficos e layouts; raciocínio como agente visual com uso dinâmico de ferramentas; compreensão de vídeos com mais de 1 hora e captura de eventos-chave; localização precisa de objetos via caixas ou pontos; e saídas estruturadas para dados digitalizados como faturas e tabelas.",
  "Qwen/Qwen3-14B.description": "Qwen3 é um modelo Tongyi Qwen de nova geração com avanços significativos em raciocínio, capacidade geral, habilidades de agente e desempenho multilíngue, além de suportar a alternância entre modos de pensamento.",
  "Qwen/Qwen3-235B-A22B-Instruct-2507.description": "Qwen3-235B-A22B-Instruct-2507 é o modelo MoE carro-chefe da série Qwen3, com 235 bilhões de parâmetros totais e 22 bilhões ativos. Esta versão não-pensante foi atualizada com foco em seguir instruções, raciocínio lógico, compreensão de texto, matemática, ciências, programação e uso de ferramentas. Também amplia o conhecimento multilíngue de cauda longa e se alinha melhor às preferências dos usuários em tarefas subjetivas e abertas.",
  "Qwen/Qwen3-235B-A22B-Thinking-2507.description": "Qwen3-235B-A22B-Thinking-2507 é um modelo Qwen3 voltado para raciocínio complexo e desafiador. Utiliza uma arquitetura MoE com 235 bilhões de parâmetros totais e cerca de 22 bilhões ativos por token, otimizando a eficiência. Como modelo dedicado ao pensamento, apresenta grandes avanços em lógica, matemática, ciências, programação e benchmarks acadêmicos, atingindo desempenho de ponta em raciocínio aberto. Também melhora a execução de instruções, uso de ferramentas e geração de texto, com suporte nativo a contexto de 256K para raciocínio profundo e documentos longos.",
  "Qwen/Qwen3-235B-A22B.description": "Qwen3 é um modelo Tongyi Qwen de nova geração com avanços significativos em raciocínio, capacidade geral, habilidades de agente e desempenho multilíngue, além de suportar a alternância entre modos de pensamento.",
  "Qwen/Qwen3-30B-A3B-Instruct-2507.description": "Qwen3-30B-A3B-Instruct-2507 é a versão não-pensante atualizada do Qwen3-30B-A3B. É um modelo MoE com 30,5 bilhões de parâmetros totais e 3,3 bilhões ativos. Apresenta melhorias significativas em seguir instruções, raciocínio lógico, compreensão de texto, matemática, ciências, programação e uso de ferramentas, além de expandir o conhecimento multilíngue de cauda longa e alinhar-se melhor às preferências dos usuários em tarefas abertas e subjetivas. Suporta contexto de 256K. Este modelo é exclusivamente não-pensante e não gera tags `<think></think>`.",
  "Qwen/Qwen3-30B-A3B-Thinking-2507.description": "Qwen3-30B-A3B-Thinking-2507 é o mais recente modelo de pensamento da série Qwen3. É um modelo MoE com 30,5 bilhões de parâmetros totais e 3,3 bilhões ativos, focado em tarefas complexas. Apresenta avanços significativos em lógica, matemática, ciências, programação e benchmarks acadêmicos, além de melhorias em seguir instruções, uso de ferramentas, geração de texto e alinhamento com preferências. Suporta nativamente contexto de 256K e pode ser estendido para até 1 milhão de tokens. Esta versão é projetada para modo de pensamento, com raciocínio detalhado passo a passo e fortes capacidades de agente.",
  "Qwen/Qwen3-30B-A3B.description": "Qwen3 é um modelo Tongyi Qwen de nova geração com avanços significativos em raciocínio, capacidade geral, habilidades de agente e desempenho multilíngue, além de suportar a alternância entre modos de pensamento.",
  "Qwen/Qwen3-32B.description": "Qwen3 é um modelo Tongyi Qwen de nova geração com avanços significativos em raciocínio, capacidade geral, habilidades de agente e desempenho multilíngue, além de suportar a alternância entre modos de pensamento.",
  "Qwen/Qwen3-8B.description": "Qwen3 é um modelo Tongyi Qwen de nova geração com avanços significativos em raciocínio, capacidade geral, habilidades de agente e desempenho multilíngue, além de suportar a alternância entre modos de pensamento.",
  "Qwen/Qwen3-Coder-30B-A3B-Instruct.description": "Qwen3-Coder-30B-A3B-Instruct é um modelo de código da série Qwen3 desenvolvido pela equipe Qwen. Foi otimizado para alto desempenho e eficiência, com foco em capacidades de programação. Apresenta vantagens notáveis em codificação agente, operações automatizadas de navegador e uso de ferramentas entre os modelos abertos. Suporta nativamente contexto de 256K e pode ser estendido para 1 milhão de tokens para compreensão em nível de base de código. Alimenta codificação agente em plataformas como Qwen Code e CLINE com um formato dedicado de chamada de funções.",
  "Qwen/Qwen3-Coder-480B-A35B-Instruct.description": "Qwen3-Coder-480B-A35B-Instruct é o modelo de código mais avançado da Alibaba até o momento. É um modelo MoE com 480 bilhões de parâmetros totais e 35 bilhões ativos, equilibrando eficiência e desempenho. Suporta nativamente contexto de 256K e pode ser estendido para 1 milhão de tokens via YaRN, permitindo lidar com grandes bases de código. Projetado para fluxos de trabalho de codificação agente, pode interagir com ferramentas e ambientes para resolver tarefas complexas de programação. Alcança resultados de ponta entre os modelos abertos em benchmarks de codificação e agentes, comparável a modelos líderes como Claude Sonnet 4.",
  "Qwen/Qwen3-Next-80B-A3B-Instruct.description": "Qwen3-Next-80B-A3B-Instruct é um modelo base de nova geração que utiliza a arquitetura Qwen3-Next para eficiência extrema em treinamento e inferência. Combina atenção híbrida (Gated DeltaNet + Gated Attention), MoE altamente esparso e otimizações de estabilidade de treinamento. Com 80 bilhões de parâmetros totais, mas cerca de 3 bilhões ativos na inferência, reduz o custo computacional e entrega mais de 10 vezes o throughput do Qwen3-32B em contextos acima de 32K. Esta versão ajustada para instruções é voltada para tarefas gerais (sem modo de pensamento). Apresenta desempenho comparável ao Qwen3-235B em alguns benchmarks e vantagens em tarefas com contexto ultra-longo.",
  "Qwen/Qwen3-Next-80B-A3B-Thinking.description": "Qwen3-Next-80B-A3B-Thinking é um modelo base de nova geração voltado para raciocínio complexo. Utiliza a arquitetura Qwen3-Next com atenção híbrida (Gated DeltaNet + Gated Attention) e MoE altamente esparso para eficiência extrema em treinamento e inferência. Com 80 bilhões de parâmetros totais e cerca de 3 bilhões ativos na inferência, reduz o custo computacional e entrega mais de 10 vezes o throughput do Qwen3-32B em contextos acima de 32K. Esta versão de pensamento é voltada para tarefas de múltiplas etapas como provas, síntese de código, análise lógica e planejamento, gerando cadeias de raciocínio estruturadas. Supera o Qwen3-32B-Thinking e o Gemini-2.5-Flash-Thinking em vários benchmarks.",
  "Qwen/Qwen3-Omni-30B-A3B-Captioner.description": "Qwen3-Omni-30B-A3B-Captioner é um modelo VLM da série Qwen3 desenvolvido para gerar legendas de imagem de alta qualidade, detalhadas e precisas. Utiliza uma arquitetura MoE com 30 bilhões de parâmetros para compreender profundamente imagens e produzir descrições fluentes, destacando-se na captura de detalhes, compreensão de cenas, reconhecimento de objetos e raciocínio relacional.",
  "Qwen/Qwen3-Omni-30B-A3B-Instruct.description": "Qwen3-Omni-30B-A3B-Instruct é um modelo MoE da série Qwen3 com 30 bilhões de parâmetros totais e 3 bilhões ativos, oferecendo alto desempenho com menor custo de inferência. Treinado com dados multilíngues de alta qualidade e múltiplas fontes, suporta entradas multimodais completas (texto, imagens, áudio, vídeo) e compreensão e geração entre modalidades.",
  "Qwen/Qwen3-Omni-30B-A3B-Thinking.description": "Qwen3-Omni-30B-A3B-Thinking é o componente central \"pensante\" do Qwen3-Omni. Processa entradas multimodais (texto, áudio, imagens, vídeo) e realiza raciocínio complexo em cadeia, unificando as entradas em uma representação compartilhada para compreensão profunda entre modalidades. É um modelo MoE com 30 bilhões de parâmetros totais e 3 bilhões ativos, equilibrando raciocínio avançado e eficiência computacional.",
  "Qwen/Qwen3-VL-235B-A22B-Instruct.description": "Qwen3-VL-235B-A22B-Instruct é um modelo Qwen3-VL ajustado para instruções, baseado em MoE, que oferece excelente compreensão e geração multimodal. Suporta nativamente contexto de 256K e é adequado para serviços multimodais de produção com alta concorrência.",
  "Qwen/Qwen3-VL-235B-A22B-Thinking.description": "Qwen3-VL-235B-A22B-Thinking é a versão de pensamento carro-chefe do Qwen3-VL, otimizada para raciocínio multimodal complexo, raciocínio com contexto longo e interação com agentes em cenários corporativos.",
  "Qwen/Qwen3-VL-30B-A3B-Instruct.description": "Qwen3-VL-30B-A3B-Instruct é o modelo Qwen3-VL ajustado para instruções, com forte compreensão e geração visão-linguagem. Suporta nativamente contexto de 256K para chat multimodal e geração condicionada por imagem.",
  "Qwen/Qwen3-VL-30B-A3B-Thinking.description": "Qwen3-VL-30B-A3B-Thinking é a versão aprimorada para raciocínio do Qwen3-VL, otimizada para raciocínio multimodal, conversão de imagem para código e compreensão visual complexa. Suporta contexto de 256K com maior capacidade de raciocínio em cadeia.",
  "Qwen/Qwen3-VL-32B-Instruct.description": "Qwen3-VL-32B-Instruct é um modelo visão-linguagem da equipe Qwen com resultados SOTA em vários benchmarks VL. Suporta imagens em resolução megapixel e oferece forte compreensão visual, OCR multilíngue, ancoragem visual detalhada e diálogo visual. Lida com tarefas multimodais complexas e suporta chamadas de ferramentas e preenchimento de prefixo.",
  "Qwen/Qwen3-VL-32B-Thinking.description": "Qwen3-VL-32B-Thinking é otimizado para raciocínio visual complexo. Inclui um modo de pensamento embutido que gera etapas intermediárias de raciocínio antes das respostas, aprimorando lógica em múltiplas etapas, planejamento e raciocínio complexo. Suporta imagens em megapixel, forte compreensão visual, OCR multilíngue, ancoragem detalhada, diálogo visual, chamadas de ferramentas e preenchimento de prefixo.",
  "Qwen/Qwen3-VL-8B-Instruct.description": "Qwen3-VL-8B-Instruct é um modelo visão-linguagem baseado no Qwen3-8B-Instruct e treinado com grandes volumes de dados imagem-texto. Destaca-se em compreensão visual geral, diálogo centrado em visão e reconhecimento de texto multilíngue em imagens, sendo adequado para QA visual, legendagem, seguimento de instruções multimodais e uso de ferramentas.",
  "Qwen/Qwen3-VL-8B-Thinking.description": "Qwen3-VL-8B-Thinking é a versão visual pensante do Qwen3, otimizada para raciocínio complexo em múltiplas etapas. Gera uma cadeia de pensamento antes das respostas para melhorar a precisão, sendo ideal para QA visual profundo e análise detalhada de imagens.",
  "Qwen2-72B-Instruct.description": "Qwen2 é a versão mais recente da série Qwen, com suporte a uma janela de contexto de 128k. Em comparação com os melhores modelos abertos atuais, o Qwen2-72B supera significativamente os principais modelos em compreensão de linguagem natural, conhecimento, programação, matemática e capacidades multilíngues.",
  "Qwen2-7B-Instruct.description": "Qwen2 é a versão mais recente da série Qwen, superando os melhores modelos abertos de tamanho semelhante e até mesmo modelos maiores. O Qwen2 7B apresenta vantagens significativas em diversos benchmarks, especialmente em programação e compreensão do chinês.",
  "Qwen2-VL-72B.description": "Qwen2-VL-72B é um poderoso modelo de linguagem e visão que oferece suporte ao processamento multimodal de imagem e texto, reconhecendo com precisão o conteúdo visual e gerando descrições ou respostas relevantes.",
  "Qwen2.5-14B-Instruct.description": "Qwen2.5-14B-Instruct é um modelo de linguagem com 14 bilhões de parâmetros e alto desempenho, otimizado para cenários em chinês e multilíngues, com suporte a perguntas e respostas inteligentes e geração de conteúdo.",
  "Qwen2.5-32B-Instruct.description": "Qwen2.5-32B-Instruct é um modelo de linguagem com 32 bilhões de parâmetros e desempenho equilibrado, otimizado para cenários em chinês e multilíngues, com suporte a perguntas e respostas inteligentes e geração de conteúdo.",
  "Qwen2.5-72B-Instruct.description": "Modelo de linguagem para chinês e inglês, ajustado para linguagem, programação, matemática e raciocínio.",
  "Qwen2.5-7B-Instruct.description": "Qwen2.5-7B-Instruct é um modelo de linguagem com 7 bilhões de parâmetros que oferece suporte a chamadas de função e integração fluida com sistemas externos, aumentando significativamente a flexibilidade e a extensibilidade. É otimizado para cenários em chinês e multilíngues, com suporte a perguntas e respostas inteligentes e geração de conteúdo.",
  "Qwen2.5-Coder-14B-Instruct.description": "Qwen2.5-Coder-14B-Instruct é um modelo de instrução para programação em larga escala, com forte capacidade de compreensão e geração de código. Ele lida eficientemente com uma ampla gama de tarefas de programação, sendo ideal para codificação inteligente, geração automatizada de scripts e perguntas e respostas sobre programação.",
  "Qwen2.5-Coder-32B-Instruct.description": "Modelo avançado de linguagem para geração de código, raciocínio e correção de bugs em diversas linguagens de programação.",
  "Qwen3-235B-A22B-Instruct-2507-FP8.description": "Qwen3 235B A22B Instruct 2507 é otimizado para raciocínio avançado e seguimento de instruções, utilizando MoE para manter a eficiência em escala.",
  "Qwen3-235B.description": "Qwen3-235B-A22B é um modelo MoE que introduz um modo híbrido de raciocínio, permitindo alternância fluida entre pensamento e não pensamento. Ele oferece compreensão e raciocínio em 119 idiomas e dialetos, com forte capacidade de uso de ferramentas, competindo com modelos como DeepSeek R1, OpenAI o1, o3-mini, Grok 3 e Google Gemini 2.5 Pro em benchmarks de habilidades gerais, programação, matemática, multilinguismo e raciocínio baseado em conhecimento.",
  "Qwen3-32B.description": "Qwen3-32B é um modelo denso que introduz um modo híbrido de raciocínio, permitindo alternância entre pensamento e não pensamento. Com melhorias na arquitetura, mais dados e melhor treinamento, seu desempenho é comparável ao Qwen2.5-72B.",
  "SenseChat-128K.description": "Base V4 com janela de contexto de 128K, excelente em compreensão e geração de textos longos.",
  "SenseChat-32K.description": "Base V4 com janela de contexto de 32K, flexível para diversos cenários.",
  "SenseChat-5-1202.description": "Versão mais recente baseada no V5.5, com avanços significativos em fundamentos de chinês/inglês, conversação, conhecimento em STEM, humanidades, redação, matemática/lógica e controle de comprimento.",
  "SenseChat-5-Cantonese.description": "Projetado para os hábitos de diálogo de Hong Kong, gírias e conhecimento local; supera o GPT-4 em compreensão do cantonês e rivaliza com o GPT-4 Turbo em conhecimento, raciocínio, matemática e programação.",
  "SenseChat-5-beta.description": "Alguns desempenhos superam o SenseChat-5-1202.",
  "SenseChat-5.description": "Versão mais recente V5.5 com contexto de 128K; grandes avanços em raciocínio matemático, conversação em inglês, seguimento de instruções e compreensão de textos longos, comparável ao GPT-4o.",
  "SenseChat-Character-Pro.description": "Modelo avançado de conversação com personagens, com contexto de 32K, capacidade aprimorada e suporte a chinês/inglês.",
  "SenseChat-Character.description": "Modelo padrão de conversação com personagens, com contexto de 8K e alta velocidade de resposta.",
  "SenseChat-Turbo-1202.description": "Modelo leve mais recente, alcançando mais de 90% da capacidade do modelo completo com custo de inferência significativamente menor.",
  "SenseChat-Turbo.description": "Adequado para perguntas e respostas rápidas e cenários de ajuste fino de modelos.",
  "SenseChat-Vision.description": "Versão mais recente V5.5 com entrada de múltiplas imagens e amplas melhorias em reconhecimento de atributos, relações espaciais, detecção de ações/eventos, compreensão de cenas, reconhecimento de emoções, raciocínio de senso comum e compreensão/geração de texto.",
  "SenseChat.description": "Base V4 com contexto de 4K e forte capacidade geral.",
  "SenseNova-V6-5-Pro.description": "Com atualizações abrangentes em dados multimodais, linguísticos e de raciocínio, além de otimização da estratégia de treinamento, o novo modelo melhora significativamente o raciocínio multimodal e o seguimento de instruções generalizadas, com suporte a janela de contexto de até 128k, destacando-se em tarefas de OCR e reconhecimento de IPs de turismo cultural.",
  "SenseNova-V6-5-Turbo.description": "Com atualizações abrangentes em dados multimodais, linguísticos e de raciocínio, além de otimização da estratégia de treinamento, o novo modelo melhora significativamente o raciocínio multimodal e o seguimento de instruções generalizadas, com suporte a janela de contexto de até 128k, destacando-se em tarefas de OCR e reconhecimento de IPs de turismo cultural.",
  "SenseNova-V6-Pro.description": "Unifica nativamente imagem, texto e vídeo, rompendo barreiras tradicionais entre modalidades; lidera rankings como OpenCompass e SuperCLUE.",
  "SenseNova-V6-Reasoner.description": "Combina raciocínio profundo em visão e linguagem, com suporte a pensamento lento e cadeia completa de raciocínio.",
  "SenseNova-V6-Turbo.description": "Unifica nativamente imagem, texto e vídeo, rompendo barreiras tradicionais entre modalidades. Lidera em capacidades centrais multimodais e linguísticas, com classificação de alto nível em diversas avaliações.",
  "Skylark2-lite-8k.description": "Segunda geração do modelo Skylark. O Skylark2-lite oferece respostas rápidas para cenários em tempo real e sensíveis a custo, com menor necessidade de precisão e janela de contexto de 8K.",
  "Skylark2-pro-32k.description": "Segunda geração do modelo Skylark. O Skylark2-pro oferece maior precisão para geração de textos complexos, como redação profissional, escrita de romances e tradução de alta qualidade, com janela de contexto de 32K.",
  "Skylark2-pro-4k.description": "Segunda geração do modelo Skylark. O Skylark2-pro oferece maior precisão para geração de textos complexos, como redação profissional, escrita de romances e tradução de alta qualidade, com janela de contexto de 4K.",
  "Skylark2-pro-character-4k.description": "Segunda geração do modelo Skylark. O Skylark2-pro-character se destaca em interpretação de papéis e conversação, combinando prompts com estilos de persona distintos e diálogo natural para chatbots, assistentes virtuais e atendimento ao cliente, com respostas rápidas.",
  "Skylark2-pro-turbo-8k.description": "Segunda geração do modelo Skylark. O Skylark2-pro-turbo-8k oferece inferência mais rápida com menor custo e janela de contexto de 8K.",
  "THUDM/GLM-4-32B-0414.description": "GLM-4-32B-0414 é um modelo GLM de próxima geração com 32 bilhões de parâmetros, com desempenho comparável ao OpenAI GPT e à série DeepSeek V3/R1.",
  "THUDM/GLM-4-9B-0414.description": "GLM-4-9B-0414 é um modelo GLM com 9 bilhões de parâmetros que herda as técnicas do GLM-4-32B, oferecendo implantação mais leve. Apresenta bom desempenho em geração de código, design web, geração de SVG e redação baseada em busca.",
  "THUDM/GLM-4.1V-9B-Thinking.description": "GLM-4.1V-9B-Thinking é um modelo VLM de código aberto da Zhipu AI e do Laboratório KEG da Universidade Tsinghua, projetado para cognição multimodal complexa. Baseado no GLM-4-9B-0414, adiciona raciocínio em cadeia e aprendizado por reforço para melhorar significativamente o raciocínio entre modalidades e a estabilidade.",
  "THUDM/GLM-Z1-32B-0414.description": "GLM-Z1-32B-0414 é um modelo de raciocínio profundo baseado no GLM-4-32B-0414, com dados de inicialização a frio e aprendizado por reforço expandido, treinado adicionalmente em matemática, código e lógica. Melhora significativamente a capacidade matemática e a resolução de tarefas complexas em relação ao modelo base.",
  "THUDM/GLM-Z1-9B-0414.description": "GLM-Z1-9B-0414 é um modelo GLM compacto com 9 bilhões de parâmetros que mantém as vantagens do código aberto e oferece capacidade impressionante. Apresenta forte desempenho em raciocínio matemático e tarefas gerais, liderando sua categoria de tamanho entre os modelos abertos.",
  "THUDM/GLM-Z1-Rumination-32B-0414.description": "GLM-Z1-Rumination-32B-0414 é um modelo de raciocínio profundo com capacidade de ruminação (avaliado em comparação com o OpenAI Deep Research). Diferente dos modelos de pensamento profundo típicos, ele dedica mais tempo à deliberação para resolver problemas mais abertos e complexos.",
  "THUDM/glm-4-9b-chat.description": "GLM-4-9B-Chat é o modelo GLM-4 de código aberto da Zhipu AI. Apresenta forte desempenho em semântica, matemática, raciocínio, código e conhecimento. Além de conversas multi-turno, oferece suporte a navegação na web, execução de código, chamadas de ferramentas personalizadas e raciocínio com textos longos. Suporta 26 idiomas (incluindo chinês, inglês, japonês, coreano e alemão). Apresenta bom desempenho em benchmarks como AlignBench-v2, MT-Bench, MMLU e C-Eval, com suporte a contexto de até 128K para uso acadêmico e empresarial.",
  "Tongyi-Zhiwen/QwenLong-L1-32B.description": "QwenLong-L1-32B é o primeiro modelo de raciocínio de longo contexto (LRM) treinado com aprendizado por reforço, otimizado para raciocínio em textos longos. Seu RL com expansão progressiva de contexto permite uma transição estável de contextos curtos para longos. Supera o OpenAI-o3-mini e o Qwen3-235B-A22B em sete benchmarks de QA com documentos de longo contexto, rivalizando com o Claude-3.7-Sonnet-Thinking. É especialmente forte em matemática, lógica e raciocínio multi-hop.",
  "Yi-34B-Chat.description": "Yi-1.5-34B mantém as fortes habilidades linguísticas gerais da série, utilizando treinamento incremental com 500 bilhões de tokens de alta qualidade para melhorar significativamente lógica matemática e programação.",
  "abab5.5-chat.description": "Projetado para cenários de produtividade, com capacidade de lidar com tarefas complexas e geração eficiente de texto para uso profissional.",
  "abab5.5s-chat.description": "Projetado para conversas com personas em chinês, oferecendo diálogos de alta qualidade em chinês para diversas aplicações.",
  "abab6.5g-chat.description": "Projetado para conversas com personas multilíngues, com suporte à geração de diálogos de alta qualidade em inglês e outros idiomas.",
  "abab6.5s-chat.description": "Adequado para uma ampla gama de tarefas de PLN, incluindo geração de texto e sistemas de diálogo.",
  "abab6.5t-chat.description": "Otimizado para conversas com personas em chinês, oferecendo diálogos fluentes que se adequam aos hábitos de expressão do idioma.",
  "accounts/fireworks/models/deepseek-r1.description": "DeepSeek-R1 é um modelo de linguagem de última geração otimizado com aprendizado por reforço e dados de início a frio, oferecendo excelente desempenho em raciocínio, matemática e programação.",
  "accounts/fireworks/models/deepseek-v3.description": "Um poderoso modelo de linguagem Mixture-of-Experts (MoE) da DeepSeek com 671 bilhões de parâmetros totais e 37 bilhões de parâmetros ativos por token.",
  "accounts/fireworks/models/llama-v3-70b-instruct.description": "A Meta desenvolveu e lançou a série de modelos LLM Meta Llama 3, que inclui modelos de geração de texto pré-treinados e ajustados por instrução com 8B e 70B parâmetros. Os modelos Llama 3 ajustados por instrução são otimizados para uso conversacional e superam muitos modelos de chat abertos existentes em benchmarks amplamente utilizados na indústria.",
  "accounts/fireworks/models/llama-v3-8b-instruct-hf.description": "Os modelos Llama 3 da Meta ajustados por instrução são otimizados para uso conversacional e superam muitos modelos de chat abertos existentes em benchmarks amplamente utilizados na indústria. O Llama 3 8B Instruct (versão HF) é a versão original em FP16 do Llama 3 8B Instruct, com resultados esperados equivalentes à implementação oficial do Hugging Face.",
  "accounts/fireworks/models/llama-v3-8b-instruct.description": "A Meta desenvolveu e lançou a série de modelos LLM Meta Llama 3, uma coleção de modelos de geração de texto pré-treinados e ajustados por instrução com 8B e 70B parâmetros. Os modelos Llama 3 ajustados por instrução são otimizados para uso conversacional e superam muitos modelos de chat abertos existentes em benchmarks amplamente utilizados na indústria.",
  "accounts/fireworks/models/llama-v3p1-405b-instruct.description": "O Meta Llama 3.1 é uma família de modelos LLM multilíngues com modelos de geração pré-treinados e ajustados por instrução nos tamanhos 8B, 70B e 405B. Os modelos de texto ajustados por instrução são otimizados para diálogos multilíngues e superam muitos modelos de chat abertos e fechados em benchmarks amplamente utilizados na indústria. O modelo 405B é o mais avançado da família Llama 3.1, utilizando inferência em FP8 que se aproxima da implementação de referência.",
  "accounts/fireworks/models/llama-v3p1-70b-instruct.description": "O Meta Llama 3.1 é uma família de modelos LLM multilíngues com modelos de geração pré-treinados e ajustados por instrução nos tamanhos 8B, 70B e 405B. Os modelos de texto ajustados por instrução são otimizados para diálogos multilíngues e superam muitos modelos de chat abertos e fechados em benchmarks amplamente utilizados na indústria.",
  "accounts/fireworks/models/llama-v3p1-8b-instruct.description": "O Meta Llama 3.1 é uma família de modelos LLM multilíngues com modelos de geração pré-treinados e ajustados por instrução nos tamanhos 8B, 70B e 405B. Os modelos de texto ajustados por instrução são otimizados para diálogos multilíngues e superam muitos modelos de chat abertos e fechados em benchmarks amplamente utilizados na indústria.",
  "accounts/fireworks/models/llama-v3p2-11b-vision-instruct.description": "Um modelo de raciocínio visual ajustado por instrução da Meta com 11 bilhões de parâmetros, otimizado para reconhecimento visual, raciocínio com imagens, legendagem e perguntas e respostas relacionadas a imagens. Ele compreende dados visuais como gráficos e tabelas e conecta visão e linguagem ao gerar descrições textuais de detalhes visuais.",
  "accounts/fireworks/models/llama-v3p2-3b-instruct.description": "O Llama 3.2 3B Instruct é um modelo multilíngue leve da Meta, projetado para execução eficiente com vantagens significativas de latência e custo em relação a modelos maiores. Casos de uso típicos incluem reescrita de consultas/prompts e assistência na escrita.",
  "accounts/fireworks/models/llama-v3p2-90b-vision-instruct.description": "Um modelo de raciocínio visual ajustado por instrução da Meta com 90 bilhões de parâmetros, otimizado para reconhecimento visual, raciocínio com imagens, legendagem e perguntas e respostas relacionadas a imagens. Ele compreende dados visuais como gráficos e tabelas e conecta visão e linguagem ao gerar descrições textuais de detalhes visuais. Observação: este modelo é atualmente fornecido de forma experimental como um modelo serverless. Para uso em produção, observe que a Fireworks pode descontinuar a implantação sem aviso prévio.",
  "accounts/fireworks/models/llama-v3p3-70b-instruct.description": "O Llama 3.3 70B Instruct é a atualização de dezembro do Llama 3.1 70B. Ele melhora o uso de ferramentas, suporte a texto multilíngue, matemática e programação em relação à versão de julho de 2024. Alcança desempenho líder da indústria em raciocínio, matemática e seguimento de instruções, oferecendo desempenho comparável ao 3.1 405B com vantagens significativas de velocidade e custo.",
  "accounts/fireworks/models/mistral-small-24b-instruct-2501.description": "Um modelo com 24 bilhões de parâmetros com capacidade de ponta comparável a modelos maiores.",
  "accounts/fireworks/models/mixtral-8x22b-instruct.description": "Mixtral MoE 8x22B Instruct v0.1 é a versão ajustada por instrução do Mixtral MoE 8x22B v0.1, com a API de conclusão de chat ativada.",
  "accounts/fireworks/models/mixtral-8x7b-instruct.description": "Mixtral MoE 8x7B Instruct é a versão ajustada por instrução do Mixtral MoE 8x7B, com a API de conclusão de chat ativada.",
  "accounts/fireworks/models/mythomax-l2-13b.description": "Uma variante aprimorada do MythoMix, possivelmente sua forma mais refinada, combinando MythoLogic-L2 e Huginn com uma técnica altamente experimental de fusão de tensores. Sua natureza única o torna excelente para contar histórias e interpretação de papéis.",
  "accounts/fireworks/models/phi-3-vision-128k-instruct.description": "Phi-3-Vision-128K-Instruct é um modelo multimodal leve e de última geração construído a partir de dados sintéticos e conjuntos de dados públicos selecionados da web, com foco em dados de texto e visão de alta qualidade e intensivos em raciocínio. Pertence à família Phi-3, com uma versão multimodal que suporta um contexto de 128K tokens. O modelo passa por aprimoramentos rigorosos, incluindo ajuste supervisionado e otimização direta de preferências, para garantir seguimento preciso de instruções e fortes medidas de segurança.",
  "accounts/fireworks/models/qwen-qwq-32b-preview.description": "O modelo Qwen QwQ foca no avanço do raciocínio em IA, demonstrando que modelos abertos podem rivalizar com modelos fechados de ponta em raciocínio. QwQ-32B-Preview é uma versão experimental que iguala o o1 e supera o GPT-4o e Claude 3.5 Sonnet em raciocínio e análise nos benchmarks GPQA, AIME, MATH-500 e LiveCodeBench. Observação: este modelo é atualmente fornecido de forma experimental como um modelo serverless. Para uso em produção, observe que a Fireworks pode descontinuar a implantação sem aviso prévio.",
  "accounts/fireworks/models/qwen2-vl-72b-instruct.description": "O modelo Qwen-VL 72B é a iteração mais recente da Alibaba, refletindo quase um ano de inovação.",
  "accounts/fireworks/models/qwen2p5-72b-instruct.description": "Qwen2.5 é uma série de modelos LLM apenas com decodificador desenvolvida pela equipe Qwen e Alibaba Cloud, oferecendo tamanhos de 0.5B, 1.5B, 3B, 7B, 14B, 32B e 72B, com variantes base e ajustadas por instrução.",
  "accounts/fireworks/models/qwen2p5-coder-32b-instruct.description": "Qwen2.5-Coder é o mais recente modelo LLM da Qwen projetado para programação (anteriormente CodeQwen). Observação: este modelo é atualmente fornecido de forma experimental como um modelo serverless. Para uso em produção, observe que a Fireworks pode descontinuar a implantação sem aviso prévio.",
  "accounts/yi-01-ai/models/yi-large.description": "Yi-Large é um modelo LLM de alto nível que ocupa posição logo abaixo do GPT-4, Gemini 1.5 Pro e Claude 3 Opus no ranking LMSYS. Ele se destaca em capacidade multilíngue, especialmente em espanhol, chinês, japonês, alemão e francês. Yi-Large também é amigável para desenvolvedores, utilizando o mesmo esquema de API do OpenAI para fácil integração.",
  "ai21-jamba-1.5-large.description": "Um modelo multilíngue com 398 bilhões de parâmetros (94B ativos), janela de contexto de 256K, chamadas de função, saída estruturada e geração fundamentada.",
  "ai21-jamba-1.5-mini.description": "Um modelo multilíngue com 52 bilhões de parâmetros (12B ativos), janela de contexto de 256K, chamadas de função, saída estruturada e geração fundamentada.",
  "ai21-labs/AI21-Jamba-1.5-Large.description": "Um modelo multilíngue com 398 bilhões de parâmetros (94B ativos), janela de contexto de 256K, chamadas de função, saída estruturada e geração fundamentada.",
  "ai21-labs/AI21-Jamba-1.5-Mini.description": "Um modelo multilíngue com 52 bilhões de parâmetros (12B ativos), janela de contexto de 256K, chamadas de função, saída estruturada e geração fundamentada.",
  "alibaba/qwen-3-14b.description": "Qwen3 é a geração mais recente da série Qwen, oferecendo um conjunto abrangente de modelos densos e MoE. Baseado em treinamento extensivo, traz avanços em raciocínio, seguimento de instruções, capacidades de agente e suporte multilíngue.",
  "alibaba/qwen-3-235b.description": "Qwen3 é a geração mais recente da série Qwen, oferecendo um conjunto abrangente de modelos densos e MoE. Baseado em treinamento extensivo, traz avanços em raciocínio, seguimento de instruções, capacidades de agente e suporte multilíngue.",
  "alibaba/qwen-3-30b.description": "Qwen3 é a geração mais recente da série Qwen, oferecendo um conjunto abrangente de modelos densos e MoE. Baseado em treinamento extensivo, traz avanços em raciocínio, seguimento de instruções, capacidades de agente e suporte multilíngue.",
  "alibaba/qwen-3-32b.description": "Qwen3 é a geração mais recente da série Qwen, oferecendo um conjunto abrangente de modelos densos e MoE. Baseado em treinamento extensivo, traz avanços em raciocínio, seguimento de instruções, capacidades de agente e suporte multilíngue.",
  "alibaba/qwen3-coder.description": "Qwen3-Coder-480B-A35B-Instruct é o modelo de código mais agente da Qwen, com excelente desempenho em programação autônoma, uso de navegador por agentes e outras tarefas centrais de codificação, alcançando resultados comparáveis ao nível do Claude Sonnet.",
  "amazon/nova-lite.description": "Um modelo multimodal de baixíssimo custo com processamento extremamente rápido de entradas de imagem, vídeo e texto.",
  "amazon/nova-micro.description": "Um modelo apenas de texto que oferece latência ultrabaixa a um custo muito reduzido.",
  "amazon/nova-pro.description": "Um modelo multimodal altamente capaz com o melhor equilíbrio entre precisão, velocidade e custo para uma ampla gama de tarefas.",
  "amazon/titan-embed-text-v2.description": "Amazon Titan Text Embeddings V2 é um modelo de embeddings multilíngue leve e eficiente, com suporte para dimensões de 1024, 512 e 256.",
  "anthropic.claude-3-5-sonnet-20240620-v1:0.description": "Claude 3.5 Sonnet eleva o padrão da indústria, superando concorrentes e o Claude 3 Opus em avaliações amplas, mantendo velocidade e custo intermediários.",
  "anthropic.claude-3-5-sonnet-20241022-v2:0.description": "Claude 3.5 Sonnet eleva o padrão da indústria, superando concorrentes e o Claude 3 Opus em avaliações amplas, mantendo velocidade e custo intermediários.",
  "anthropic.claude-3-haiku-20240307-v1:0.description": "Claude 3 Haiku é o modelo mais rápido e compacto da Anthropic, oferecendo respostas quase instantâneas para consultas simples. Proporciona experiências de IA naturais e fluídas, com suporte a entrada de imagem e janela de contexto de 200 mil tokens.",
  "anthropic.claude-3-opus-20240229-v1:0.description": "Claude 3 Opus é o modelo de IA mais poderoso da Anthropic, com desempenho de ponta em tarefas altamente complexas. Lida com prompts abertos e cenários inéditos com fluência excepcional e compreensão semelhante à humana, além de suportar entrada de imagem com janela de contexto de 200 mil tokens.",
  "anthropic.claude-3-sonnet-20240229-v1:0.description": "Claude 3 Sonnet equilibra inteligência e velocidade para cargas de trabalho corporativas, oferecendo alto valor a um custo reduzido. Foi projetado como um modelo confiável para implantações de IA em escala e suporta entrada de imagem com janela de contexto de 200 mil tokens.",
  "anthropic.claude-instant-v1.description": "Um modelo rápido, econômico e ainda assim capaz para conversas cotidianas, análise de texto, resumo e perguntas e respostas sobre documentos.",
  "anthropic.claude-v2.description": "Um modelo altamente capaz para tarefas que vão de diálogos complexos e geração criativa até seguimento detalhado de instruções.",
  "anthropic.claude-v2:1.description": "Uma versão atualizada do Claude 2 com o dobro da janela de contexto e melhorias em confiabilidade, taxa de alucinação e precisão baseada em evidências para documentos longos e RAG.",
  "anthropic/claude-3-haiku.description": "Claude 3 Haiku é o modelo mais rápido da Anthropic, projetado para cargas de trabalho corporativas com prompts longos. Analisa rapidamente documentos extensos como relatórios trimestrais, contratos ou casos jurídicos a metade do custo de modelos similares.",
  "anthropic/claude-3-opus.description": "Claude 3 Opus é o modelo mais inteligente da Anthropic, com desempenho líder de mercado em tarefas altamente complexas, lidando com prompts abertos e cenários inéditos com fluência excepcional e compreensão semelhante à humana.",
  "anthropic/claude-3.5-haiku.description": "Claude 3.5 Haiku apresenta velocidade aprimorada, maior precisão em codificação e uso de ferramentas, ideal para cenários com exigências elevadas de velocidade e interação com ferramentas.",
  "anthropic/claude-3.5-sonnet.description": "Claude 3.5 Sonnet é o modelo rápido e eficiente da família Sonnet, oferecendo melhor desempenho em codificação e raciocínio, com algumas versões sendo gradualmente substituídas pelo Sonnet 3.7 e posteriores.",
  "anthropic/claude-3.7-sonnet.description": "Claude 3.7 Sonnet é um modelo Sonnet aprimorado com raciocínio e codificação mais robustos, adequado para tarefas complexas em nível corporativo.",
  "anthropic/claude-haiku-4.5.description": "Claude Haiku 4.5 é o modelo rápido de alto desempenho da Anthropic, oferecendo latência muito baixa com alta precisão.",
  "anthropic/claude-opus-4.1.description": "Opus 4.1 é o modelo de ponta da Anthropic, otimizado para programação, raciocínio complexo e tarefas de longa duração.",
  "anthropic/claude-opus-4.5.description": "Claude Opus 4.5 é o modelo principal da Anthropic, combinando inteligência de alto nível com desempenho escalável para tarefas complexas e raciocínio de alta qualidade.",
  "anthropic/claude-opus-4.description": "Opus 4 é o modelo principal da Anthropic, projetado para tarefas complexas e aplicações corporativas.",
  "anthropic/claude-sonnet-4.5.description": "Claude Sonnet 4.5 é o mais recente modelo híbrido de raciocínio da Anthropic, otimizado para raciocínio complexo e codificação.",
  "anthropic/claude-sonnet-4.description": "Claude Sonnet 4 é o modelo híbrido de raciocínio da Anthropic com capacidade mista de pensamento e não-pensamento.",
  "ascend-tribe/pangu-pro-moe.description": "Pangu-Pro-MoE 72B-A16B é um LLM esparso com 72 bilhões de parâmetros totais e 16 bilhões ativos, baseado em uma arquitetura MoE agrupada (MoGE). Ele agrupa especialistas durante a seleção e limita os tokens a ativar especialistas iguais por grupo, equilibrando a carga e melhorando a eficiência de implantação no Ascend.",
  "aya.description": "Aya 23 é o modelo multilíngue da Cohere com suporte a 23 idiomas para diversos casos de uso.",
  "aya:35b.description": "Aya 23 é o modelo multilíngue da Cohere com suporte a 23 idiomas para diversos casos de uso.",
  "azure-DeepSeek-R1-0528.description": "Implantado pela Microsoft; o DeepSeek R1 foi atualizado para DeepSeek-R1-0528. A atualização aumenta o poder computacional e otimizações no algoritmo pós-treinamento, melhorando significativamente a profundidade de raciocínio e inferência. Apresenta ótimo desempenho em benchmarks de matemática, programação e lógica geral, aproximando-se de modelos líderes como o O3 e Gemini 2.5 Pro.",
  "baichuan-m2-32b.description": "Baichuan M2 32B é um modelo MoE da Baichuan Intelligence com forte capacidade de raciocínio.",
  "baichuan/baichuan2-13b-chat.description": "Baichuan-13B é um LLM de 13 bilhões de parâmetros de código aberto e uso comercial da Baichuan, alcançando resultados de ponta para seu tamanho em benchmarks autoritativos em chinês e inglês.",
  "baidu/ERNIE-4.5-300B-A47B.description": "ERNIE-4.5-300B-A47B é um LLM MoE da Baidu com 300 bilhões de parâmetros totais e 47 bilhões ativos por token, equilibrando desempenho robusto e eficiência computacional. Como modelo central do ERNIE 4.5, destaca-se em compreensão, geração, raciocínio e programação. Utiliza pré-treinamento multimodal heterogêneo com treinamento conjunto texto-visão para aumentar a capacidade geral, especialmente em seguir instruções e conhecimento de mundo.",
  "baidu/ernie-5.0-thinking-preview.description": "ERNIE 5.0 Thinking Preview é o modelo ERNIE multimodal nativo de próxima geração da Baidu, com forte compreensão multimodal, seguimento de instruções, criação, perguntas e respostas factuais e uso de ferramentas.",
  "black-forest-labs/flux-1.1-pro.description": "FLUX 1.1 Pro é uma versão mais rápida e aprimorada do FLUX Pro, com excelente qualidade de imagem e aderência ao prompt.",
  "black-forest-labs/flux-dev.description": "FLUX Dev é a versão de desenvolvimento do FLUX para uso não comercial.",
  "black-forest-labs/flux-pro.description": "FLUX Pro é o modelo profissional do FLUX para geração de imagens de alta qualidade.",
  "black-forest-labs/flux-schnell.description": "FLUX Schnell é um modelo de geração de imagens rápido, otimizado para velocidade.",
  "c4ai-aya-expanse-32b.description": "Aya Expanse é um modelo multilíngue de alto desempenho com 32 bilhões de parâmetros que utiliza ajuste por instrução, arbitragem de dados, treinamento por preferência e fusão de modelos para rivalizar com modelos monolíngues. Suporta 23 idiomas.",
  "c4ai-aya-expanse-8b.description": "Aya Expanse é um modelo multilíngue de alto desempenho com 8 bilhões de parâmetros que utiliza ajuste por instrução, arbitragem de dados, treinamento por preferência e fusão de modelos para rivalizar com modelos monolíngues. Suporta 23 idiomas.",
  "c4ai-aya-vision-32b.description": "Aya Vision é um modelo multimodal de última geração com forte desempenho em benchmarks de linguagem, texto e visão. Suporta 23 idiomas. Esta versão de 32B foca em desempenho multilíngue de alto nível.",
  "c4ai-aya-vision-8b.description": "Aya Vision é um modelo multimodal de última geração com forte desempenho em benchmarks de linguagem, texto e visão. Esta versão de 8B foca em baixa latência e desempenho robusto.",
  "charglm-3.description": "CharGLM-3 foi desenvolvido para simulação de papéis e companhia emocional, com suporte a memória de múltiplas interações de longo prazo e diálogo personalizado.",
  "charglm-4.description": "CharGLM-4 foi desenvolvido para simulação de papéis e companhia emocional, com suporte a memória de múltiplas interações de longo prazo e diálogo personalizado.",
  "chatgpt-4o-latest.description": "ChatGPT-4o é um modelo dinâmico atualizado em tempo real, combinando forte compreensão e geração para casos de uso em larga escala como suporte ao cliente, educação e suporte técnico.",
  "claude-2.0.description": "Claude 2 oferece melhorias importantes para empresas, incluindo um contexto líder de 200 mil tokens, menos alucinações, prompts de sistema e um novo recurso de teste: chamadas de ferramentas.",
  "claude-2.1.description": "Claude 2 oferece melhorias importantes para empresas, incluindo um contexto líder de 200 mil tokens, menos alucinações, prompts de sistema e um novo recurso de teste: chamadas de ferramentas.",
  "claude-3-5-haiku-20241022.description": "Claude 3.5 Haiku é o modelo de próxima geração mais rápido da Anthropic, com melhorias em diversas habilidades e superando o modelo principal anterior, Claude 3 Opus, em muitos benchmarks.",
  "claude-3-5-haiku-latest.description": "Claude 3.5 Haiku oferece respostas rápidas para tarefas leves.",
  "claude-3-7-sonnet-20250219.description": "Claude Sonnet 3.7 é o modelo mais inteligente da Anthropic e o primeiro modelo híbrido de raciocínio do mercado, oferecendo respostas quase instantâneas ou pensamento estendido com controle refinado.",
  "claude-3-7-sonnet-latest.description": "Claude 3.7 Sonnet é o modelo mais recente e avançado da Anthropic para tarefas altamente complexas, com excelência em desempenho, inteligência, fluência e compreensão.",
  "claude-3-haiku-20240307.description": "Claude 3 Haiku é o modelo mais rápido e compacto da Anthropic, projetado para respostas quase instantâneas com desempenho rápido e preciso.",
  "claude-3-opus-20240229.description": "Claude 3 Opus é o modelo mais poderoso da Anthropic para tarefas altamente complexas, com excelência em desempenho, inteligência, fluência e compreensão.",
  "claude-3-sonnet-20240229.description": "Claude 3 Sonnet equilibra inteligência e velocidade para cargas de trabalho empresariais, oferecendo alta utilidade com menor custo e implantação confiável em larga escala.",
  "claude-haiku-4-5-20251001.description": "Claude Haiku 4.5 é o modelo Haiku mais rápido e inteligente da Anthropic, com velocidade relâmpago e pensamento estendido.",
  "claude-opus-4-1-20250805-thinking.description": "Claude Opus 4.1 Thinking é uma variante avançada que pode revelar seu processo de raciocínio.",
  "claude-opus-4-1-20250805.description": "Claude Opus 4.1 é o modelo mais recente e avançado da Anthropic para tarefas altamente complexas, com excelência em desempenho, inteligência, fluência e compreensão.",
  "claude-opus-4-20250514.description": "Claude Opus 4 é o modelo mais poderoso da Anthropic para tarefas altamente complexas, com excelência em desempenho, inteligência, fluência e compreensão.",
  "claude-opus-4-5-20251101.description": "Claude Opus 4.5 é o modelo principal da Anthropic, combinando inteligência excepcional com desempenho escalável, ideal para tarefas complexas que exigem respostas e raciocínio da mais alta qualidade.",
  "claude-sonnet-4-20250514-thinking.description": "Claude Sonnet 4 Thinking pode produzir respostas quase instantâneas ou pensamento passo a passo estendido com processo visível.",
  "claude-sonnet-4-20250514.description": "Claude Sonnet 4 é o modelo mais inteligente da Anthropic até o momento, oferecendo respostas quase instantâneas ou pensamento passo a passo estendido com controle refinado para usuários de API.",
  "claude-sonnet-4-5-20250929.description": "Claude Sonnet 4.5 é o modelo mais inteligente da Anthropic até o momento.",
  "meta.llama3-8b-instruct-v1:0.description": "O Meta Llama 3 é um modelo de linguagem aberto para desenvolvedores, pesquisadores e empresas, projetado para ajudá-los a construir, experimentar e escalar ideias de IA generativa de forma responsável. Como parte da base para a inovação da comunidade global, é ideal para ambientes com recursos computacionais limitados, dispositivos de borda e tempos de treinamento mais rápidos.",
  "mistral-large-latest.description": "Mistral Large é o modelo principal, com excelente desempenho em tarefas multilíngues, raciocínio complexo e geração de código — ideal para aplicações de alto nível.",
  "mistral-large.description": "Mixtral Large é o modelo principal da Mistral, combinando geração de código, matemática e raciocínio com uma janela de contexto de 128K.",
  "mistral-medium-latest.description": "Mistral Medium 3 oferece desempenho de ponta com custo 8× menor e facilita a implantação em ambientes corporativos.",
  "mistral-nemo-instruct.description": "Mistral-Nemo-Instruct-2407 é a versão ajustada por instruções do Mistral-Nemo-Base-2407.",
  "mistral-nemo.description": "Mistral Nemo é um modelo de alta eficiência com 12B parâmetros, desenvolvido pela Mistral AI e NVIDIA.",
  "mistral-small-latest.description": "Mistral Small é uma opção econômica, rápida e confiável para tradução, sumarização e análise de sentimento.",
  "mistral-small.description": "Mistral Small é adequado para qualquer tarefa baseada em linguagem que exija alta eficiência e baixa latência.",
  "mistral.description": "Mistral é o modelo de 7B da Mistral AI, adequado para diversas tarefas linguísticas.",
  "mistral/codestral-embed.description": "Modelo de embedding de código para indexação de bases de código e repositórios, ideal para assistentes de programação.",
  "mistral/codestral.description": "Mistral Codestral 25.01 é um modelo de programação de última geração, otimizado para baixa latência e uso frequente. Suporta mais de 80 linguagens e se destaca em FIM, correção de código e geração de testes.",
  "mistral/devstral-small.description": "Devstral é um LLM com comportamento agente voltado para tarefas de engenharia de software, sendo uma excelente escolha para agentes desenvolvedores.",
  "mistral/magistral-medium.description": "Raciocínio complexo apoiado por compreensão profunda, com lógica transparente que pode ser acompanhada e verificada. Mantém raciocínio de alta fidelidade entre idiomas, mesmo durante a tarefa.",
  "mistral/magistral-small.description": "Raciocínio complexo apoiado por compreensão profunda, com lógica transparente que pode ser acompanhada e verificada. Mantém raciocínio de alta fidelidade entre idiomas, mesmo durante a tarefa.",
  "mistral/ministral-3b.description": "Modelo compacto e eficiente para tarefas locais, como assistentes e análises no dispositivo, com desempenho de baixa latência.",
  "mistral/ministral-8b.description": "Modelo mais potente com inferência rápida e eficiente em memória, ideal para fluxos de trabalho complexos e aplicações exigentes em edge.",
  "mistral/mistral-embed.description": "Modelo geral de embedding de texto para busca semântica, similaridade, agrupamento e fluxos de RAG.",
  "mistral/mistral-large.description": "Mistral Large é ideal para tarefas complexas que exigem raciocínio avançado ou especialização — geração de texto sintético, código, RAG ou agentes.",
  "mistral/mistral-small.description": "Mistral Small é ideal para tarefas simples e em lote, como classificação, suporte ao cliente ou geração de texto, com ótimo desempenho a um preço acessível.",
  "mistral/mixtral-8x22b-instruct.description": "Modelo Instruct 8x22B. O 8x22B é um modelo MoE aberto disponibilizado pela Mistral.",
  "mistral/pixtral-12b.description": "Modelo de 12B com compreensão de imagens e texto.",
  "mistral/pixtral-large.description": "Pixtral Large é o segundo modelo da nossa família multimodal com compreensão de imagem em nível de fronteira. Lida com documentos, gráficos e imagens naturais, mantendo a liderança em compreensão textual do Mistral Large 2.",
  "mistralai/Mistral-7B-Instruct-v0.1.description": "Mistral (7B) Instruct é conhecido por seu forte desempenho em diversas tarefas linguísticas.",
  "mistralai/Mistral-7B-Instruct-v0.2.description": "Mistral (7B) Instruct v0.2 melhora o manuseio de instruções e a precisão dos resultados.",
  "mistralai/Mistral-7B-Instruct-v0.3.description": "Mistral (7B) Instruct v0.3 oferece computação eficiente e forte compreensão linguística para diversos casos de uso.",
  "mistralai/Mistral-7B-v0.1.description": "Mistral 7B é compacto, mas de alto desempenho, ideal para processamento em lote e tarefas simples como classificação e geração de texto, com raciocínio sólido.",
  "mistralai/Mixtral-8x22B-Instruct-v0.1.description": "Mixtral-8x22B Instruct (141B) é um LLM muito grande para cargas de trabalho pesadas.",
  "mistralai/Mixtral-8x7B-Instruct-v0.1.description": "Mixtral-8x7B Instruct (46.7B) oferece alta capacidade para processamento de dados em larga escala.",
  "mistralai/Mixtral-8x7B-v0.1.description": "Mixtral 8x7B é um modelo MoE esparso que acelera a inferência, adequado para tarefas multilíngues e geração de código.",
  "mistralai/mistral-nemo.description": "Mistral Nemo é um modelo de 7.3B com suporte multilíngue e forte desempenho em programação.",
  "mixtral-8x7b-32768.description": "Mixtral 8x7B oferece computação paralela tolerante a falhas para tarefas complexas.",
  "mixtral.description": "Mixtral é o modelo MoE da Mistral AI com pesos abertos, com suporte à geração de código e compreensão de linguagem.",
  "mixtral:8x22b.description": "Mixtral é o modelo MoE da Mistral AI com pesos abertos, com suporte à geração de código e compreensão de linguagem.",
  "moonshot-v1-128k-vision-preview.description": "Os modelos de visão Kimi (incluindo moonshot-v1-8k-vision-preview/moonshot-v1-32k-vision-preview/moonshot-v1-128k-vision-preview) compreendem conteúdo de imagem como texto, cores e formas de objetos.",
  "moonshot-v1-128k.description": "Moonshot V1 128K oferece contexto ultra-longo para geração de texto muito extensa, lidando com até 128.000 tokens para pesquisa, uso acadêmico e documentos longos.",
  "moonshot-v1-32k-vision-preview.description": "Os modelos de visão Kimi (incluindo moonshot-v1-8k-vision-preview/moonshot-v1-32k-vision-preview/moonshot-v1-128k-vision-preview) compreendem conteúdo de imagem como texto, cores e formas de objetos.",
  "moonshot-v1-32k.description": "Moonshot V1 32K suporta 32.768 tokens para contexto de comprimento médio, ideal para documentos longos e diálogos complexos em criação de conteúdo, relatórios e sistemas de chat.",
  "moonshot-v1-8k-vision-preview.description": "Os modelos de visão Kimi (incluindo moonshot-v1-8k-vision-preview/moonshot-v1-32k-vision-preview/moonshot-v1-128k-vision-preview) compreendem conteúdo de imagem como texto, cores e formas de objetos.",
  "moonshot-v1-8k.description": "Moonshot V1 8K é otimizado para geração de texto curta com desempenho eficiente, lidando com 8.192 tokens para conversas rápidas, anotações e conteúdo breve.",
  "moonshot-v1-auto.description": "Moonshot V1 Auto seleciona o modelo apropriado com base no uso atual de tokens de contexto.",
  "openai/gpt-4.1-nano.description": "GPT-4.1 Nano é uma opção de custo ultrabaixo e baixa latência para conversas curtas de alta frequência ou tarefas de classificação.",
  "openai/gpt-4.1.description": "A série GPT-4.1 oferece janelas de contexto maiores e capacidades aprimoradas de engenharia e raciocínio.",
  "openai/gpt-4o-mini.description": "GPT-4o-mini é uma variante rápida e compacta do GPT-4o para uso multimodal com baixa latência.",
  "openai/gpt-4o.description": "A família GPT-4o é o modelo Omni da OpenAI com entrada de texto + imagem e saída em texto.",
  "openai/gpt-5-chat.description": "GPT-5 Chat é uma variante do GPT-5 otimizada para conversas com menor latência e melhor interatividade.",
  "openai/gpt-5-codex.description": "GPT-5-Codex é uma variante do GPT-5 ainda mais otimizada para programação e fluxos de trabalho de código em larga escala.",
  "openai/gpt-5-mini.description": "GPT-5 Mini é uma variante menor do GPT-5 para cenários de baixo custo e baixa latência.",
  "openai/gpt-5-nano.description": "GPT-5 Nano é a variante ultracompacta para cenários com restrições rigorosas de custo e latência.",
  "openai/gpt-5-pro.description": "GPT-5 Pro é o modelo principal da OpenAI, oferecendo raciocínio avançado, geração de código e recursos de nível corporativo, com roteamento em tempo de execução e políticas de segurança mais rigorosas.",
  "openai/gpt-5.1-chat.description": "GPT-5.1 Chat é o membro leve da família GPT-5.1, otimizado para conversas de baixa latência, mantendo forte raciocínio e execução de instruções.",
  "openai/gpt-5.1-codex-mini.description": "GPT-5.1-Codex-Mini é uma versão menor e mais rápida do GPT-5.1-Codex, ideal para cenários de programação sensíveis a latência e custo.",
  "openai/gpt-5.1-codex.description": "GPT-5.1-Codex é uma variante do GPT-5.1 otimizada para engenharia de software e fluxos de trabalho de programação, adequada para grandes refatorações, depuração complexa e tarefas autônomas prolongadas.",
  "openai/gpt-5.1.description": "GPT-5.1 é o modelo principal mais recente da série GPT-5, com melhorias significativas em raciocínio geral, seguimento de instruções e naturalidade em conversas, adequado para tarefas amplas.",
  "openai/gpt-5.description": "GPT-5 é o modelo de alto desempenho da OpenAI para uma ampla gama de tarefas de produção e pesquisa.",
  "openai/gpt-oss-120b.description": "Um modelo de linguagem de uso geral altamente capaz, com raciocínio forte e controlável.",
  "openai/gpt-oss-20b.description": "Um modelo de linguagem compacto com pesos abertos, otimizado para baixa latência e ambientes com recursos limitados, incluindo implantações locais e na borda.",
  "openai/o1-mini.description": "o1-mini é um modelo de raciocínio rápido e econômico, projetado para programação, matemática e ciência. Possui contexto de 128K e corte de conhecimento em outubro de 2023.",
  "openai/o1-preview.description": "o1 é o novo modelo de raciocínio da OpenAI para tarefas complexas que exigem conhecimento amplo. Possui contexto de 128K e corte de conhecimento em outubro de 2023.",
  "openai/o1.description": "OpenAI o1 é um modelo de raciocínio principal desenvolvido para problemas complexos que exigem pensamento profundo, oferecendo raciocínio sólido e maior precisão em tarefas de múltiplas etapas.",
  "openai/o3-mini-high.description": "o3-mini (raciocínio avançado) oferece inteligência superior com os mesmos custos e metas de latência do o1-mini.",
  "openai/o3-mini.description": "o3-mini é o mais recente modelo de raciocínio compacto da OpenAI, oferecendo inteligência superior com os mesmos custos e metas de latência do o1-mini.",
  "openai/o3.description": "OpenAI o3 é o modelo de raciocínio mais poderoso, estabelecendo um novo estado da arte em programação, matemática, ciência e percepção visual. Destaca-se em consultas complexas e multifacetadas, com forte capacidade de análise de imagens, gráficos e diagramas.",
  "openai/o4-mini-high.description": "o4-mini com raciocínio avançado, otimizado para raciocínio rápido e eficiente com desempenho sólido em programação e visão computacional.",
  "openai/o4-mini.description": "OpenAI o4-mini é um modelo de raciocínio pequeno e eficiente para cenários de baixa latência.",
  "openai/text-embedding-3-large.description": "O modelo de embedding mais avançado da OpenAI para tarefas em inglês e outros idiomas.",
  "openai/text-embedding-3-small.description": "Variante aprimorada e de alto desempenho do modelo de embedding ada da OpenAI.",
  "openai/text-embedding-ada-002.description": "Modelo de embedding de texto legado da OpenAI.",
  "openrouter/auto.description": "Com base no comprimento do contexto, tópico e complexidade, sua solicitação é roteada para Llama 3 70B Instruct, Claude 3.5 Sonnet (auto-moderado) ou GPT-4o.",
  "perplexity/sonar-pro.description": "Produto principal da Perplexity com base em busca, oferecendo suporte a consultas avançadas e seguimentos.",
  "perplexity/sonar-reasoning-pro.description": "Modelo avançado com foco em raciocínio que gera cadeia de pensamento (CoT) com busca aprimorada, incluindo múltiplas consultas por solicitação.",
  "perplexity/sonar-reasoning.description": "Modelo com foco em raciocínio que gera cadeia de pensamento (CoT) com explicações detalhadas baseadas em busca.",
  "perplexity/sonar.description": "Produto leve da Perplexity com base em busca, mais rápido e econômico que o Sonar Pro.",
  "phi3.description": "Phi-3 é o modelo leve e aberto da Microsoft para integração eficiente e raciocínio em larga escala.",
  "phi3:14b.description": "Phi-3 é o modelo leve e aberto da Microsoft para integração eficiente e raciocínio em larga escala.",
  "pixtral-12b-2409.description": "Pixtral é forte em compreensão de gráficos/imagens, perguntas e respostas em documentos, raciocínio multimodal e seguimento de instruções. Processa imagens em resolução/aspecto nativos e lida com qualquer número de imagens dentro de uma janela de contexto de 128K.",
  "pixtral-large-latest.description": "Pixtral Large é um modelo multimodal aberto com 124 bilhões de parâmetros baseado no Mistral Large 2, o segundo da nossa família multimodal com compreensão de imagem de ponta.",
  "pro-128k.description": "Spark Pro 128K oferece uma capacidade de contexto muito grande, lidando com até 128K de contexto, ideal para documentos longos que exigem análise de texto completo e coerência de longo alcance, com lógica fluida e suporte a citações diversas em discussões complexas.",
  "pro-deepseek-r1.description": "Modelo de serviço dedicado para empresas com concorrência agrupada.",
  "pro-deepseek-v3.description": "Modelo de serviço dedicado para empresas com concorrência agrupada.",
  "qianfan-70b.description": "Qianfan 70B é um modelo chinês de grande porte para geração de alta qualidade e raciocínio complexo.",
  "qianfan-8b.description": "Qianfan 8B é um modelo geral de porte médio que equilibra custo e qualidade para geração de texto e perguntas e respostas.",
  "qianfan-agent-intent-32k.description": "Qianfan Agent Intent 32K é voltado para reconhecimento de intenção e orquestração de agentes com suporte a contexto longo.",
  "qianfan-agent-lite-8k.description": "Qianfan Agent Lite 8K é um modelo de agente leve para diálogos de múltiplas voltas e fluxos de trabalho de baixo custo.",
  "qianfan-agent-speed-32k.description": "Qianfan Agent Speed 32K é um modelo de agente de alta vazão para aplicativos de agentes multitarefa em larga escala.",
  "qianfan-agent-speed-8k.description": "Qianfan Agent Speed 8K é um modelo de agente de alta concorrência para conversas curtas a médias e respostas rápidas.",
  "qianfan-check-vl.description": "Qianfan Check VL é um modelo de revisão de conteúdo multimodal para conformidade e reconhecimento de imagem-texto.",
  "qianfan-composition.description": "Qianfan Composition é um modelo de criação multimodal para compreensão e geração mista de imagem e texto.",
  "qianfan-engcard-vl.description": "Qianfan EngCard VL é um modelo de reconhecimento multimodal focado em cenários em inglês.",
  "qianfan-lightning-128b-a19b.description": "Qianfan Lightning 128B A19B é um modelo chinês de alto desempenho para perguntas e respostas complexas e raciocínio em larga escala.",
  "qianfan-llama-vl-8b.description": "Qianfan Llama VL 8B é um modelo multimodal baseado em Llama para compreensão geral de imagem e texto.",
  "qianfan-multipicocr.description": "Qianfan MultiPicOCR é um modelo de OCR para múltiplas imagens, detectando e reconhecendo texto em várias imagens.",
  "qianfan-qi-vl.description": "Qianfan QI VL é um modelo de perguntas e respostas multimodal para recuperação precisa e respostas em cenários complexos de imagem e texto.",
  "qianfan-singlepicocr.description": "Qianfan SinglePicOCR é um modelo de OCR para imagem única com reconhecimento de caracteres de alta precisão.",
  "qianfan-vl-70b.description": "Qianfan VL 70B é um grande modelo de linguagem visual para compreensão complexa de imagem e texto.",
  "qianfan-vl-8b.description": "Qianfan VL 8B é um modelo leve de linguagem visual para perguntas e respostas e análise de imagem e texto no dia a dia.",
  "qwen/qwen3-30b-a3b.description": "Qwen3 é a mais recente geração de modelos LLM da série Qwen, com arquiteturas densas e MoE, destacando-se em raciocínio, suporte multilíngue e tarefas avançadas de agentes. Sua capacidade única de alternar entre um modo de pensamento para raciocínio complexo e um modo sem pensamento para conversas eficientes garante desempenho versátil e de alta qualidade.\n\nQwen3 supera significativamente modelos anteriores como QwQ e Qwen2.5, oferecendo excelente desempenho em matemática, programação, raciocínio lógico, escrita criativa e conversas interativas. A variante Qwen3-30B-A3B possui 30,5 bilhões de parâmetros (3,3 bilhões ativos), 48 camadas, 128 especialistas (8 ativos por tarefa) e suporta até 131 mil tokens de contexto com YaRN, estabelecendo um novo padrão para modelos abertos.",
  "qwen/qwen3-30b-a3b:free.description": "Qwen3 é a mais recente geração de modelos LLM da série Qwen, com arquiteturas densas e MoE, destacando-se em raciocínio, suporte multilíngue e tarefas avançadas de agentes. Sua capacidade única de alternar entre um modo de pensamento para raciocínio complexo e um modo sem pensamento para conversas eficientes garante desempenho versátil e de alta qualidade.\n\nQwen3 supera significativamente modelos anteriores como QwQ e Qwen2.5, oferecendo excelente desempenho em matemática, programação, raciocínio lógico, escrita criativa e conversas interativas. A variante Qwen3-30B-A3B possui 30,5 bilhões de parâmetros (3,3 bilhões ativos), 48 camadas, 128 especialistas (8 ativos por tarefa) e suporta até 131 mil tokens de contexto com YaRN, estabelecendo um novo padrão para modelos abertos.",
  "qwen/qwen3-32b.description": "Qwen3-32B é um modelo LLM denso com 32,8 bilhões de parâmetros, otimizado para raciocínio complexo e conversas eficientes. Alterna entre um modo de pensamento para matemática, programação e lógica, e um modo sem pensamento para conversas gerais mais rápidas. Apresenta forte desempenho em seguir instruções, uso de ferramentas por agentes e escrita criativa em mais de 100 idiomas e dialetos. Suporta nativamente 32 mil tokens de contexto e escala até 131 mil com YaRN.",
  "qwen/qwen3-32b:free.description": "Qwen3-32B é um modelo LLM denso com 32,8 bilhões de parâmetros, otimizado para raciocínio complexo e conversas eficientes. Alterna entre um modo de pensamento para matemática, programação e lógica, e um modo sem pensamento para conversas gerais mais rápidas. Apresenta forte desempenho em seguir instruções, uso de ferramentas por agentes e escrita criativa em mais de 100 idiomas e dialetos. Suporta nativamente 32 mil tokens de contexto e escala até 131 mil com YaRN.",
  "qwen/qwen3-8b:free.description": "Qwen3-8B é um modelo LLM denso com 8,2 bilhões de parâmetros, projetado para tarefas com alto grau de raciocínio e conversas eficientes. Alterna entre um modo de pensamento para matemática, programação e lógica, e um modo sem pensamento para conversas gerais. Ajustado para seguir instruções, integração com agentes e escrita criativa em mais de 100 idiomas e dialetos. Suporta nativamente 32 mil tokens de contexto e escala até 131 mil com YaRN.",
  "qwen/qwen3-coder-plus.description": "Qwen3-Coder-Plus é um modelo da série Qwen voltado para programação, otimizado para uso de ferramentas mais complexas e sessões prolongadas.",
  "qwen/qwen3-coder.description": "Qwen3-Coder é a família de modelos de geração de código da série Qwen3, com forte capacidade de compreensão e geração de código em documentos longos.",
  "qwen/qwen3-max-preview.description": "Qwen3 Max (prévia) é a variante Max para raciocínio avançado e integração com ferramentas.",
  "qwen/qwen3-max.description": "Qwen3 Max é o modelo de raciocínio de alto desempenho da série Qwen3, voltado para raciocínio multilíngue e integração com ferramentas.",
  "qwen/qwen3-vl-plus.description": "Qwen3 VL-Plus é a variante da série Qwen3 com aprimoramento visual, oferecendo raciocínio multimodal avançado e processamento de vídeo.",
  "qwen2.5-14b-instruct-1m.description": "Qwen2.5 modelo open-source com 72 bilhões de parâmetros.",
  "qwen2.5-14b-instruct.description": "Qwen2.5 modelo open-source com 14 bilhões de parâmetros.",
  "qwen2.5-32b-instruct.description": "Qwen2.5 modelo open-source com 32 bilhões de parâmetros.",
  "qwen2.5-72b-instruct.description": "Qwen2.5 modelo open-source com 72 bilhões de parâmetros.",
  "qwen2.5-7b-instruct.description": "Qwen2.5 7B Instruct é um modelo open-source maduro para geração e conversas em múltiplos cenários.",
  "qwen2.5-coder-1.5b-instruct.description": "Modelo de código Qwen open-source.",
  "qwen2.5-coder-14b-instruct.description": "Modelo de código Qwen open-source.",
  "qwen2.5-coder-32b-instruct.description": "Modelo de código Qwen open-source.",
  "qwen2.5-coder-7b-instruct.description": "Modelo de código Qwen open-source.",
  "qwen2.5-coder-instruct.description": "Qwen2.5-Coder é o mais recente modelo LLM focado em código da família Qwen (anteriormente CodeQwen).",
  "qwen2.5-instruct.description": "Qwen2.5 é a mais recente série de modelos LLM da Qwen, com modelos base e ajustados por instrução variando de 0,5B a 72B parâmetros.",
  "qwen2.5-math-1.5b-instruct.description": "Qwen-Math oferece forte capacidade de resolução de problemas matemáticos.",
  "qwen2.5-math-72b-instruct.description": "Qwen-Math oferece forte capacidade de resolução de problemas matemáticos.",
  "qwen2.5-math-7b-instruct.description": "Qwen-Math oferece forte capacidade de resolução de problemas matemáticos.",
  "qwen2.5-omni-7b.description": "Modelos Qwen-Omni suportam entradas multimodais (vídeo, áudio, imagens, texto) e geram saídas em áudio e texto.",
  "qwen2.5-vl-32b-instruct.description": "Qwen2.5 VL 32B Instruct é um modelo multimodal open-source adequado para implantação privada e uso em múltiplos cenários.",
  "qwen2.5-vl-72b-instruct.description": "Melhorias em seguir instruções, matemática, resolução de problemas e programação, com reconhecimento geral de objetos mais robusto. Suporta localização precisa de elementos visuais em diversos formatos, compreensão de vídeos longos (até 10 minutos) com temporização de eventos em nível de segundo, ordenação temporal e compreensão de velocidade, além de agentes que podem controlar sistemas operacionais ou dispositivos móveis via análise e localização. Forte extração de informações-chave e saída em JSON. Esta é a versão 72B, a mais poderosa da série.",
  "qwen2.5-vl-7b-instruct.description": "Qwen2.5 VL 7B Instruct é um modelo multimodal leve que equilibra custo de implantação e capacidade de reconhecimento.",
  "qwen2.5-vl-instruct.description": "Qwen2.5-VL é o mais recente modelo de linguagem e visão da família Qwen.",
  "qwen2.5.description": "Qwen2.5 é o modelo de linguagem de próxima geração da Alibaba, com desempenho robusto em diversos casos de uso.",
  "qwen2.5:0.5b.description": "Qwen2.5 é o modelo de linguagem de próxima geração da Alibaba, com desempenho robusto em diversos casos de uso.",
  "qwen2.5:1.5b.description": "Qwen2.5 é o modelo de linguagem de próxima geração da Alibaba, com desempenho robusto em diversos casos de uso.",
  "qwen2.5:72b.description": "Qwen2.5 é o modelo de linguagem de próxima geração da Alibaba, com desempenho robusto em diversos casos de uso.",
  "qwen2.description": "Qwen2 é o modelo de linguagem de próxima geração da Alibaba, com desempenho robusto em diversos casos de uso.",
  "qwen2:0.5b.description": "Qwen2 é o modelo de linguagem de próxima geração da Alibaba, com desempenho robusto em diversos casos de uso.",
  "qwen2:1.5b.description": "Qwen2 é o modelo de linguagem de próxima geração da Alibaba, com desempenho robusto em diversos casos de uso.",
  "qwen2:72b.description": "Qwen2 é o modelo de linguagem de próxima geração da Alibaba, com desempenho robusto em diversos casos de uso.",
  "qwen3-0.6b.description": "Qwen3 0.6B é um modelo de entrada para raciocínio simples e ambientes altamente restritos.",
  "qwen3-1.7b.description": "Qwen3 1.7B é um modelo ultraleve para implantação em dispositivos e borda.",
  "qwen3-14b.description": "Qwen3 14B é um modelo de porte médio para perguntas e respostas multilíngues e geração de texto.",
  "qwen3-235b-a22b-instruct-2507.description": "Qwen3 235B A22B Instruct 2507 é um modelo de instrução de ponta para uma ampla gama de tarefas de geração e raciocínio.",
  "qwen3-235b-a22b-thinking-2507.description": "Qwen3 235B A22B Thinking 2507 é um modelo de raciocínio ultra grande para tarefas complexas.",
  "qwen3-235b-a22b.description": "Qwen3 235B A22B é um modelo geral de grande porte para tarefas complexas.",
  "qwen3-30b-a3b-instruct-2507.description": "Qwen3 30B A3B Instruct 2507 é um modelo de instrução de porte médio-grande para geração de alta qualidade e perguntas e respostas.",
  "qwen3-30b-a3b-thinking-2507.description": "Qwen3 30B A3B Thinking 2507 é um modelo de raciocínio de porte médio-grande que equilibra precisão e custo.",
  "qwen3-30b-a3b.description": "Qwen3 30B A3B é um modelo geral de porte médio-grande que equilibra custo e qualidade.",
  "qwen3-32b.description": "Qwen3 32B é adequado para tarefas gerais que exigem maior capacidade de compreensão.",
  "qwen3-4b.description": "Qwen3 4B é adequado para aplicativos de pequeno a médio porte e inferência local.",
  "qwen3-8b.description": "Qwen3 8B é um modelo leve com implantação flexível para cargas de trabalho com alta concorrência.",
  "stable-diffusion-3.5-large.description": "stable-diffusion-3.5-large é um modelo MMDiT de texto para imagem com 800 milhões de parâmetros, oferecendo excelente qualidade e alinhamento com prompts, suportando imagens de 1 megapixel e execução eficiente em hardwares de consumo.",
  "stable-diffusion-v1.5.description": "stable-diffusion-v1.5 é inicializado a partir do checkpoint v1.2 e ajustado por 595 mil etapas no conjunto \"laion-aesthetics v2 5+\" com resolução de 512x512, reduzindo o condicionamento de texto em 10% para melhorar a amostragem com orientação livre de classificadores.",
  "stable-diffusion-xl-base-1.0.description": "Um modelo de texto para imagem de código aberto da Stability AI com geração criativa de imagens líder na indústria. Possui forte compreensão de instruções e suporta definições de prompt reverso para geração precisa.",
  "stable-diffusion-xl.description": "stable-diffusion-xl traz melhorias significativas em relação à versão v1.5 e alcança resultados comparáveis aos melhores modelos abertos de texto para imagem. As melhorias incluem um backbone UNet 3x maior, um módulo de refinamento para melhor qualidade de imagem e técnicas de treinamento mais eficientes.",
  "step-1-128k.description": "Equilibra desempenho e custo para cenários gerais.",
  "step-1-256k.description": "Manipulação de contexto extra longo, ideal para análise de documentos extensos.",
  "step-1-32k.description": "Suporta conversas de comprimento médio para uma ampla gama de cenários.",
  "step-1-8k.description": "Modelo pequeno adequado para tarefas leves.",
  "step-1-flash.description": "Modelo de alta velocidade adequado para chat em tempo real.",
  "step-1.5v-mini.description": "Capacidades robustas de compreensão de vídeo.",
  "step-1o-turbo-vision.description": "Compreensão de imagem avançada, superando o 1o em matemática e programação. Menor que o 1o e com saída mais rápida.",
  "step-1o-vision-32k.description": "Compreensão de imagem avançada com desempenho visual superior à série Step-1V.",
  "step-1v-32k.description": "Suporta entradas visuais para interações multimodais mais ricas.",
  "step-1v-8k.description": "Modelo visual pequeno para tarefas básicas de imagem e texto.",
  "step-1x-edit.description": "Este modelo foca em edição de imagens, modificando e aprimorando imagens com base em imagens e textos fornecidos pelo usuário. Suporta múltiplos formatos de entrada, incluindo descrições textuais e imagens de exemplo, gerando edições alinhadas à intenção do usuário.",
  "step-1x-medium.description": "Este modelo oferece geração de imagens robusta a partir de prompts de texto. Com suporte nativo ao chinês, compreende melhor descrições nesse idioma, capturando sua semântica e convertendo-as em recursos visuais para uma geração mais precisa. Produz imagens de alta resolução e qualidade, com suporte a certo grau de transferência de estilo.",
  "step-2-16k-exp.description": "Versão experimental do Step-2 com os recursos mais recentes e atualizações contínuas. Não recomendado para produção.",
  "step-2-16k.description": "Suporta interações com contexto amplo para diálogos complexos.",
  "step-2-mini.description": "Baseado na arquitetura de atenção MFA de próxima geração, oferece resultados semelhantes ao Step-1 com custo muito menor, maior rendimento e menor latência. Lida com tarefas gerais com forte capacidade de programação.",
  "step-2x-large.description": "Modelo de imagem StepFun de nova geração focado em geração de imagens, produzindo imagens de alta qualidade a partir de prompts de texto. Oferece texturas mais realistas e melhor renderização de texto em chinês/inglês.",
  "step-3.description": "Este modelo possui forte percepção visual e raciocínio complexo, lidando com precisão com compreensão de conhecimento entre domínios, análise cruzada de matemática e visão, e uma ampla gama de tarefas visuais do cotidiano.",
  "step-r1-v-mini.description": "Modelo de raciocínio com forte compreensão de imagem que pode processar imagens e textos, gerando texto após raciocínio profundo. Destaca-se em raciocínio visual e oferece desempenho de ponta em matemática, programação e raciocínio textual, com janela de contexto de 100K.",
  "stepfun-ai/step3.description": "Step3 é um modelo de raciocínio multimodal de ponta da StepFun, baseado em arquitetura MoE com 321B de parâmetros totais e 38B ativos. Seu design de ponta a ponta minimiza o custo de decodificação enquanto entrega raciocínio visão-linguagem de alto nível. Com design MFA e AFD, mantém eficiência tanto em aceleradores topo de linha quanto de entrada. Pré-treinado com mais de 20T de tokens de texto e 4T de tokens imagem-texto em vários idiomas. Alcança desempenho líder entre modelos abertos em benchmarks de matemática, código e multimodalidade.",
  "taichu_llm.description": "Treinado com dados massivos de alta qualidade, com melhor compreensão de texto, criação de conteúdo e perguntas e respostas conversacionais.",
  "taichu_o1.description": "taichu_o1 é um modelo de raciocínio de próxima geração que utiliza interação multimodal e aprendizado por reforço para alcançar raciocínio em cadeia semelhante ao humano, suportando simulação de decisões complexas e expondo caminhos de raciocínio com alta precisão, ideal para análise estratégica e pensamento profundo.",
  "taichu_vl.description": "Combina compreensão de imagem, transferência de conhecimento e atribuição lógica, destacando-se em perguntas e respostas imagem-texto.",
  "tencent/Hunyuan-A13B-Instruct.description": "Hunyuan-A13B-Instruct utiliza 80B de parâmetros totais com 13B ativos para igualar modelos maiores. Suporta raciocínio híbrido rápido/lento, compreensão estável de textos longos e desempenho líder em agentes nos benchmarks BFCL-v3 e τ-Bench. Formatos GQA e multi-quant permitem inferência eficiente.",
  "tencent/Hunyuan-MT-7B.description": "O Modelo de Tradução Hunyuan inclui o Hunyuan-MT-7B e o conjunto Hunyuan-MT-Chimera. O Hunyuan-MT-7B é um modelo leve de tradução com 7B de parâmetros, suportando 33 idiomas e 5 línguas minoritárias chinesas. No WMT25, obteve 30 primeiros lugares em 31 pares de idiomas. A Hunyuan da Tencent utiliza um pipeline completo de pré-treinamento, SFT, RL de tradução e RL em conjunto, alcançando desempenho líder em seu porte com implantação eficiente e fácil.",
  "text-embedding-3-large.description": "O modelo de embedding mais avançado para tarefas em inglês e outros idiomas.",
  "text-embedding-3-small.description": "Modelo de embedding de próxima geração eficiente e econômico para recuperação e cenários RAG.",
  "thudm/glm-4-32b.description": "GLM-4-32B-0414 é um modelo bilíngue (chinês/inglês) de 32B com pesos abertos, otimizado para geração de código, chamadas de função e tarefas de agente. Pré-treinado com 15T de dados de alta qualidade e foco em raciocínio, refinado com alinhamento de preferências humanas, amostragem de rejeição e RL. Destaca-se em raciocínio complexo, geração de artefatos e saída estruturada, alcançando desempenho comparável ao GPT-4o e DeepSeek-V3-0324 em múltiplos benchmarks.",
  "thudm/glm-4-32b:free.description": "GLM-4-32B-0414 é um modelo bilíngue (chinês/inglês) de 32B com pesos abertos, otimizado para geração de código, chamadas de função e tarefas de agente. Pré-treinado com 15T de dados de alta qualidade e foco em raciocínio, refinado com alinhamento de preferências humanas, amostragem de rejeição e RL. Destaca-se em raciocínio complexo, geração de artefatos e saída estruturada, alcançando desempenho comparável ao GPT-4o e DeepSeek-V3-0324 em múltiplos benchmarks.",
  "thudm/glm-4-9b-chat.description": "Versão de código aberto do mais recente modelo pré-treinado GLM-4 da Zhipu AI.",
  "thudm/glm-z1-32b.description": "GLM-Z1-32B-0414 é uma variante de raciocínio aprimorada do GLM-4-32B, projetada para resolução de problemas focados em matemática, lógica e código. Aplica RL expandido (preferência pareada específica e geral) para melhorar tarefas complexas de múltiplas etapas. Em comparação com o GLM-4-32B, o Z1 melhora significativamente o raciocínio estruturado e a capacidade em domínios formais.\n\nSuporta etapas de “pensamento” via engenharia de prompt, melhora a coerência em saídas longas e é otimizado para fluxos de trabalho de agentes com contexto longo (via YaRN), chamadas de ferramentas JSON e amostragem refinada para raciocínio estável. Ideal para casos que exigem derivações formais ou de múltiplas etapas cuidadosas.",
  "thudm/glm-z1-rumination-32b.description": "GLM Z1 Rumination 32B é um modelo de raciocínio profundo da série GLM-4-Z1, otimizado para tarefas abertas e complexas que exigem pensamento prolongado. Baseado no glm-4-32b-0414, adiciona estágios extras de RL e alinhamento em múltiplas fases, introduzindo uma capacidade de “ruminação” que simula processamento cognitivo estendido. Isso inclui raciocínio iterativo, análise em múltiplos saltos e fluxos de trabalho com ferramentas como busca, recuperação e síntese com consciência de citação.\n\nDestaca-se em redação científica, análise comparativa e perguntas e respostas complexas. Suporta chamadas de função para primitivas de busca/navegação (`search`, `click`, `open`, `finish`) em pipelines de agentes. O comportamento de ruminação é controlado por laços de múltiplas rodadas com modelagem de recompensa baseada em regras e mecanismos de decisão atrasada, testado em frameworks de pesquisa profunda como o stack interno de alinhamento da OpenAI. Esta variante prioriza profundidade em vez de velocidade.",
  "zai-org/GLM-4.5-Air.description": "GLM-4.5-Air é um modelo base para aplicações com agentes, utilizando uma arquitetura Mixture-of-Experts. Ele é otimizado para uso de ferramentas, navegação na web, engenharia de software e codificação frontend, e integra-se com agentes de código como Claude Code e Roo Code. Utiliza raciocínio híbrido para lidar tanto com cenários complexos quanto com situações do dia a dia.",
  "zai-org/GLM-4.5.description": "GLM-4.5 é um modelo base desenvolvido para aplicações com agentes, utilizando uma arquitetura Mixture-of-Experts. É profundamente otimizado para uso de ferramentas, navegação na web, engenharia de software e codificação frontend, e integra-se com agentes de código como Claude Code e Roo Code. Utiliza raciocínio híbrido para lidar com raciocínios complexos e situações cotidianas.",
  "zai-org/GLM-4.5V.description": "GLM-4.5V é o mais recente VLM da Zhipu AI, baseado no modelo de texto principal GLM-4.5-Air (106B no total, 12B ativos), com uma arquitetura MoE que oferece alto desempenho a um custo reduzido. Segue a linha de desenvolvimento do GLM-4.1V-Thinking e adiciona 3D-RoPE para melhorar o raciocínio espacial em 3D. Otimizado por meio de pré-treinamento, SFT e RL, lida com imagens, vídeos e documentos longos, e está entre os melhores modelos abertos em 41 benchmarks multimodais públicos. Um modo de alternância de raciocínio permite ao usuário equilibrar velocidade e profundidade.",
  "zai-org/GLM-4.6.description": "Comparado ao GLM-4.5, o GLM-4.6 expande o contexto de 128K para 200K para tarefas de agentes mais complexas. Apresenta pontuações mais altas em benchmarks de código e desempenho superior em aplicações reais como Claude Code, Cline, Roo Code e Kilo Code, incluindo melhor geração de páginas frontend. O raciocínio foi aprimorado e o uso de ferramentas é suportado durante o processo, fortalecendo a capacidade geral. Integra-se melhor a frameworks de agentes, melhora agentes de busca/ferramentas e apresenta estilo de escrita mais natural e preferido por humanos, além de maior naturalidade em simulações de papéis.",
  "zai/glm-4.5-air.description": "GLM-4.5 e GLM-4.5-Air são nossos modelos principais mais recentes para aplicações com agentes, ambos utilizando MoE. O GLM-4.5 possui 355B no total e 32B ativos por passagem; o GLM-4.5-Air é mais enxuto, com 106B no total e 12B ativos.",
  "zai/glm-4.5.description": "A série GLM-4.5 foi projetada para agentes. O modelo principal GLM-4.5 combina raciocínio, codificação e habilidades de agente com 355B de parâmetros totais (32B ativos) e oferece modos de operação duplos como um sistema de raciocínio híbrido.",
  "zai/glm-4.5v.description": "GLM-4.5V é baseado no GLM-4.5-Air, herdando técnicas comprovadas do GLM-4.1V-Thinking e escalando com uma robusta arquitetura MoE de 106B parâmetros.",
  "zenmux/auto.description": "O roteamento automático do ZenMux seleciona o modelo com melhor desempenho e custo-benefício entre as opções suportadas, com base na sua solicitação."
}
