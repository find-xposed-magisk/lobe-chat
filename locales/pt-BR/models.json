{
  "01-ai/yi-1.5-34b-chat.description": "O modelo open-source mais recente da 01.AI, ajustado com 34 bilhões de parâmetros. Suporta múltiplos cenários de diálogo, treinado com dados de alta qualidade e alinhado às preferências humanas.",
  "01-ai/yi-1.5-9b-chat.description": "O modelo open-source mais recente da 01.AI, ajustado com 9 bilhões de parâmetros. Suporta múltiplos cenários de diálogo, treinado com dados de alta qualidade e alinhado às preferências humanas.",
  "360/deepseek-r1.description": "O DeepSeek-R1 implantado pela 360 utiliza aprendizado por reforço em larga escala no pós-treinamento para melhorar significativamente o raciocínio com poucos rótulos. Alcança desempenho comparável ao OpenAI o1 em tarefas de matemática, programação e raciocínio em linguagem natural.",
  "360gpt-pro-trans.description": "Modelo especializado em tradução, profundamente ajustado para oferecer qualidade de tradução de ponta.",
  "360gpt-pro.description": "O 360GPT Pro é um modelo central da 360 AI com processamento de texto eficiente para diversos cenários de PLN, com suporte à compreensão de textos longos e diálogos de múltiplas interações.",
  "360gpt-turbo-responsibility-8k.description": "O 360GPT Turbo Responsibility 8K enfatiza a segurança semântica e a responsabilidade em aplicações sensíveis a conteúdo, garantindo experiências precisas e robustas para o usuário.",
  "360gpt-turbo.description": "O 360GPT Turbo oferece forte capacidade de computação e chat com excelente compreensão semântica e eficiência de geração, ideal para empresas e desenvolvedores.",
  "360gpt2-o1.description": "O 360gpt2-o1 constrói cadeias de raciocínio por meio de busca em árvore com mecanismo de reflexão e treinamento por reforço, permitindo autorreflexão e autocorreção.",
  "360gpt2-pro.description": "O 360GPT2 Pro é um modelo avançado de PLN da 360 com excelente geração e compreensão de texto, especialmente para tarefas criativas, transformações complexas e simulações de papéis.",
  "360zhinao2-o1.description": "O 360zhinao2-o1 constrói cadeias de raciocínio por meio de busca em árvore com mecanismo de reflexão e treinamento por reforço, permitindo autorreflexão e autocorreção.",
  "4.0Ultra.description": "O Spark Ultra é o modelo mais poderoso da série Spark, aprimorando a compreensão e a sumarização de texto, além de melhorar a busca na web. É uma solução completa para aumentar a produtividade no trabalho e fornecer respostas precisas, posicionando-se como um produto inteligente de destaque.",
  "AnimeSharp.description": "AnimeSharp (também conhecido como \"4x-AnimeSharp\") é um modelo open-source de super-resolução baseado no ESRGAN de Kim2091, focado em ampliar e aprimorar imagens no estilo anime. Foi renomeado de \"4x-TextSharpV1\" em fevereiro de 2022, originalmente também voltado para imagens de texto, mas fortemente otimizado para conteúdo de anime.",
  "Baichuan2-Turbo.description": "Utiliza aumento por busca para conectar o modelo ao conhecimento de domínio e da web. Suporta upload de arquivos PDF/Word e entrada de URLs para recuperação abrangente e atualizada, com saídas profissionais e precisas.",
  "Baichuan3-Turbo-128k.description": "Com uma janela de contexto ultra longa de 128K, é otimizado para cenários empresariais de alta frequência, com ganhos significativos e alto valor. Em comparação com o Baichuan2, a criação de conteúdo melhora em 20%, perguntas e respostas em 17% e simulação de papéis em 40%. O desempenho geral supera o GPT-3.5.",
  "Baichuan3-Turbo.description": "Otimizado para cenários empresariais de alta frequência, com ganhos significativos e alto valor. Em comparação com o Baichuan2, a criação de conteúdo melhora em 20%, perguntas e respostas em 17% e simulação de papéis em 40%. O desempenho geral supera o GPT-3.5.",
  "Baichuan4-Air.description": "Modelo de alto desempenho na China, superando modelos internacionais em tarefas em chinês como conhecimento, textos longos e geração criativa. Também possui capacidades multimodais líderes do setor com resultados fortes em benchmarks reconhecidos.",
  "Baichuan4-Turbo.description": "Modelo de alto desempenho na China, superando modelos internacionais em tarefas em chinês como conhecimento, textos longos e geração criativa. Também possui capacidades multimodais líderes do setor com resultados fortes em benchmarks reconhecidos.",
  "Baichuan4.description": "Desempenho doméstico de ponta, superando modelos internacionais líderes em tarefas em chinês como conhecimento enciclopédico, textos longos e geração criativa. Também oferece capacidades multimodais líderes do setor e resultados sólidos em benchmarks.",
  "ByteDance-Seed/Seed-OSS-36B-Instruct.description": "Seed-OSS é uma família de LLMs open-source da ByteDance Seed, projetada para lidar com contextos longos, raciocínio, agentes e habilidades gerais. O Seed-OSS-36B-Instruct é um modelo de 36B ajustado por instruções com suporte nativo a contextos ultra longos, ideal para processar grandes documentos ou bases de código. É otimizado para raciocínio, geração de código e tarefas de agente (uso de ferramentas), mantendo forte capacidade geral. Um recurso-chave é o \"Orçamento de Pensamento\", que permite flexibilidade no comprimento do raciocínio para melhorar a eficiência.",
  "DeepSeek-R1-Distill-Llama-70B.description": "DeepSeek R1, o modelo maior e mais inteligente da suíte DeepSeek, foi destilado na arquitetura Llama 70B. Benchmarks e avaliações humanas mostram que é mais inteligente que o Llama 70B base, especialmente em tarefas de matemática e precisão factual.",
  "DeepSeek-R1-Distill-Qwen-1.5B.description": "Modelo destilado do DeepSeek-R1 baseado no Qwen2.5-Math-1.5B. Aprendizado por reforço e dados de inicialização a frio otimizam o desempenho em raciocínio, estabelecendo novos benchmarks multitarefa para modelos open-source.",
  "DeepSeek-R1-Distill-Qwen-14B.description": "Os modelos DeepSeek-R1-Distill são ajustados a partir de modelos open-source usando dados de amostra gerados pelo DeepSeek-R1.",
  "DeepSeek-R1-Distill-Qwen-32B.description": "Os modelos DeepSeek-R1-Distill são ajustados a partir de modelos open-source usando dados de amostra gerados pelo DeepSeek-R1.",
  "DeepSeek-R1-Distill-Qwen-7B.description": "Modelo destilado do DeepSeek-R1 baseado no Qwen2.5-Math-7B. Aprendizado por reforço e dados de inicialização a frio otimizam o desempenho em raciocínio, estabelecendo novos benchmarks multitarefa para modelos open-source.",
  "DeepSeek-R1.description": "O DeepSeek-R1 aplica aprendizado por reforço em larga escala durante o pós-treinamento, aumentando significativamente o raciocínio com muito poucos dados rotulados. Alcança desempenho comparável ao modelo de produção OpenAI o1 em tarefas de matemática, código e raciocínio em linguagem natural.",
  "DeepSeek-V3-1.description": "O DeepSeek V3.1 é um modelo de raciocínio de próxima geração com raciocínio complexo aprimorado e cadeia de pensamento, adequado para tarefas de análise profunda.",
  "DeepSeek-V3-Fast.description": "Fornecedor: sophnet. O DeepSeek V3 Fast é a versão de alta TPS do DeepSeek V3 0324, com precisão total (não quantizado), respostas mais rápidas e desempenho superior em código e matemática.",
  "DeepSeek-V3.1-Fast.description": "O DeepSeek V3.1 Fast é a variante rápida de alta TPS do DeepSeek V3.1. Modo de pensamento híbrido: via templates de chat, um único modelo suporta modos com e sem raciocínio. Uso de ferramentas mais inteligente: o pós-treinamento melhora o desempenho em tarefas de agente e uso de ferramentas.",
  "DeepSeek-V3.1-Think.description": "Modo de pensamento do DeepSeek-V3.1: um novo modelo híbrido de raciocínio com modos de pensamento e não pensamento, mais eficiente que o DeepSeek-R1-0528. Otimizações no pós-treinamento melhoram significativamente o uso de ferramentas de agente e o desempenho em tarefas de agente.",
  "DeepSeek-V3.description": "O DeepSeek-V3 é um modelo MoE desenvolvido pela DeepSeek. Supera outros modelos open-source como Qwen2.5-72B e Llama-3.1-405B em muitos benchmarks e é competitivo com modelos fechados líderes como GPT-4o e Claude 3.5 Sonnet.",
  "Doubao-lite-128k.description": "O Doubao-lite oferece respostas ultra rápidas e melhor custo-benefício, com opções flexíveis para diversos cenários. Suporta contexto de 128K para inferência e ajuste fino.",
  "Doubao-lite-32k.description": "O Doubao-lite oferece respostas ultra rápidas e melhor custo-benefício, com opções flexíveis para diversos cenários. Suporta contexto de 32K para inferência e ajuste fino.",
  "Doubao-lite-4k.description": "O Doubao-lite oferece respostas ultra rápidas e melhor custo-benefício, com opções flexíveis para diversos cenários. Suporta contexto de 4K para inferência e ajuste fino.",
  "Doubao-pro-128k.description": "Modelo carro-chefe de melhor desempenho para tarefas complexas, com excelência em perguntas e respostas com referência, sumarização, criação, classificação e simulação de papéis. Suporta contexto de 128K para inferência e ajuste fino.",
  "Doubao-pro-32k.description": "Modelo carro-chefe de melhor desempenho para tarefas complexas, com excelência em perguntas e respostas com referência, sumarização, criação, classificação e simulação de papéis. Suporta contexto de 32K para inferência e ajuste fino.",
  "Doubao-pro-4k.description": "Modelo carro-chefe de melhor desempenho para tarefas complexas, com excelência em perguntas e respostas com referência, sumarização, criação, classificação e simulação de papéis. Suporta contexto de 4K para inferência e ajuste fino.",
  "DreamO.description": "DreamO é um modelo open-source de personalização de imagens desenvolvido em conjunto pela ByteDance e pela Universidade de Pequim, utilizando uma arquitetura unificada para suportar geração de imagens multitarefa. Emprega modelagem composicional eficiente para gerar imagens altamente consistentes e personalizadas com base em identidade, tema, estilo, fundo e outras condições especificadas pelo usuário.",
  "ERNIE-3.5-128K.description": "Modelo LLM de grande escala da Baidu, treinado com vastos corpora em chinês/inglês, com forte capacidade geral para conversas, criação e uso de plugins; suporta integração automática com o plugin de busca Baidu para respostas atualizadas.",
  "ERNIE-3.5-8K-Preview.description": "Modelo LLM de grande escala da Baidu, treinado com vastos corpora em chinês/inglês, com forte capacidade geral para conversas, criação e uso de plugins; suporta integração automática com o plugin de busca Baidu para respostas atualizadas.",
  "ERNIE-3.5-8K.description": "Modelo LLM de grande escala da Baidu, treinado com vastos corpora em chinês/inglês, com forte capacidade geral para conversas, criação e uso de plugins; suporta integração automática com o plugin de busca Baidu para respostas atualizadas.",
  "ERNIE-4.0-8K-Latest.description": "Modelo LLM ultra-avançado da Baidu com melhorias abrangentes em relação ao ERNIE 3.5, adequado para tarefas complexas em diversos domínios; suporta integração com o plugin de busca Baidu para respostas atualizadas.",
  "ERNIE-4.0-8K-Preview.description": "Modelo LLM ultra-avançado da Baidu com melhorias abrangentes em relação ao ERNIE 3.5, adequado para tarefas complexas em diversos domínios; suporta integração com o plugin de busca Baidu para respostas atualizadas.",
  "ERNIE-4.0-Turbo-8K-Latest.description": "Modelo LLM ultra-avançado da Baidu com desempenho geral robusto para tarefas complexas, com integração ao plugin de busca Baidu para respostas atualizadas. Supera o ERNIE 4.0.",
  "ERNIE-4.0-Turbo-8K-Preview.description": "Modelo LLM ultra-avançado da Baidu com desempenho geral robusto para tarefas complexas, com integração ao plugin de busca Baidu para respostas atualizadas. Supera o ERNIE 4.0.",
  "ERNIE-Character-8K.description": "Modelo LLM da Baidu voltado para domínios específicos como NPCs de jogos, atendimento ao cliente e interpretação de personagens, com maior consistência de persona, melhor seguimento de instruções e raciocínio aprimorado.",
  "ERNIE-Lite-Pro-128K.description": "Modelo LLM leve da Baidu que equilibra qualidade e desempenho de inferência, superior ao ERNIE Lite e adequado para aceleradores de baixo custo computacional.",
  "ERNIE-Speed-128K.description": "Modelo LLM de alto desempenho mais recente da Baidu (2024), com forte capacidade geral, ideal como base para ajustes finos em cenários específicos, com excelente desempenho em raciocínio.",
  "ERNIE-Speed-Pro-128K.description": "Modelo LLM de alto desempenho mais recente da Baidu (2024), com forte capacidade geral, superior ao ERNIE Speed, ideal como base para ajustes finos com excelente desempenho em raciocínio.",
  "FLUX-1.1-pro.description": "FLUX.1.1 Pro",
  "FLUX.1-Kontext-dev.description": "FLUX.1-Kontext-dev é um modelo multimodal de geração e edição de imagens do Black Forest Labs baseado em uma arquitetura Rectified Flow Transformer com 12 bilhões de parâmetros. Foca na geração, reconstrução, aprimoramento ou edição de imagens sob condições contextuais específicas. Combina os pontos fortes da geração controlável dos modelos de difusão com o modelamento de contexto dos Transformers, oferecendo saídas de alta qualidade para tarefas como inpainting, outpainting e reconstrução de cenas visuais.",
  "FLUX.1-Kontext-pro.description": "FLUX.1 Kontext [pro]",
  "FLUX.1-dev.description": "FLUX.1-dev é um modelo de linguagem multimodal de código aberto (MLLM) do Black Forest Labs, otimizado para tarefas de imagem e texto, combinando compreensão e geração de imagem/texto. Baseado em LLMs avançados (como Mistral-7B), utiliza um codificador visual cuidadosamente projetado e ajuste de instruções em múltiplas etapas para permitir coordenação multimodal e raciocínio em tarefas complexas.",
  "Gryphe/MythoMax-L2-13b.description": "MythoMax-L2 (13B) é um modelo inovador para diversos domínios e tarefas complexas.",
  "HelloMeme.description": "HelloMeme é uma ferramenta de IA que gera memes, GIFs ou vídeos curtos a partir de imagens ou movimentos fornecidos. Não requer habilidades de desenho ou programação—basta uma imagem de referência para criar conteúdo divertido, atrativo e estilisticamente consistente.",
  "HiDream-I1-Full.description": "HiDream-E1-Full é um modelo de edição de imagem multimodal de código aberto da HiDream.ai, baseado em uma arquitetura Diffusion Transformer avançada e forte compreensão de linguagem (com LLaMA 3.1-8B-Instruct embutido). Suporta geração de imagens guiada por linguagem natural, transferência de estilo, edições locais e repintura, com excelente compreensão e execução imagem-texto.",
  "HunyuanDiT-v1.2-Diffusers-Distilled.description": "hunyuandit-v1.2-distilled é um modelo leve de texto para imagem otimizado via destilação para gerar imagens de alta qualidade rapidamente, especialmente adequado para ambientes com poucos recursos e geração em tempo real.",
  "InstantCharacter.description": "InstantCharacter é um modelo de geração de personagens personalizados sem necessidade de ajuste, lançado pela Tencent AI em 2025, com foco em geração de personagens de alta fidelidade e consistência entre cenários. Pode modelar um personagem a partir de uma única imagem de referência e transferi-lo com flexibilidade entre estilos, ações e cenários.",
  "InternVL2-8B.description": "InternVL2-8B é um poderoso modelo visão-linguagem que suporta processamento multimodal de imagem e texto, reconhecendo com precisão o conteúdo visual e gerando descrições ou respostas relevantes.",
  "InternVL2.5-26B.description": "InternVL2.5-26B é um poderoso modelo visão-linguagem que suporta processamento multimodal de imagem e texto, reconhecendo com precisão o conteúdo visual e gerando descrições ou respostas relevantes.",
  "Kolors.description": "Kolors é um modelo de texto para imagem desenvolvido pela equipe Kolors da Kuaishou. Treinado com bilhões de parâmetros, apresenta vantagens notáveis em qualidade visual, compreensão semântica do chinês e renderização de texto.",
  "Kwai-Kolors/Kolors.description": "Kolors é um modelo de texto para imagem de difusão latente em larga escala da equipe Kolors da Kuaishou. Treinado com bilhões de pares texto-imagem, destaca-se em qualidade visual, precisão semântica complexa e renderização de texto em chinês/inglês, com forte compreensão e geração de conteúdo em chinês.",
  "Kwaipilot/KAT-Dev.description": "KAT-Dev (32B) é um modelo de código aberto com 32 bilhões de parâmetros para tarefas de engenharia de software. Alcança uma taxa de resolução de 62,4% no SWE-Bench Verified, ocupando o 5º lugar entre os modelos abertos. É otimizado por meio de mid-training, SFT e RL para preenchimento de código, correção de bugs e revisão de código.",
  "Llama-3.2-11B-Vision-Instruct.description": "Raciocínio visual avançado em imagens de alta resolução, adequado para aplicações de compreensão visual.",
  "Llama-3.2-90B-Vision-Instruct\t.description": "Raciocínio visual avançado para aplicações de agentes com compreensão visual.",
  "Meta-Llama-3-3-70B-Instruct.description": "Llama 3.3 70B é um modelo Transformer versátil para tarefas de conversa e geração.",
  "Meta-Llama-3.1-405B-Instruct.description": "Modelo de texto ajustado por instruções Llama 3.1, otimizado para conversas multilíngues, com desempenho destacado em benchmarks da indústria entre modelos abertos e fechados.",
  "Meta-Llama-3.1-70B-Instruct.description": "Modelo de texto ajustado por instruções Llama 3.1, otimizado para conversas multilíngues, com desempenho destacado em benchmarks da indústria entre modelos abertos e fechados.",
  "Meta-Llama-3.1-8B-Instruct.description": "Modelo de texto ajustado por instruções Llama 3.1, otimizado para conversas multilíngues, com desempenho destacado em benchmarks da indústria entre modelos abertos e fechados.",
  "Meta-Llama-3.2-1B-Instruct.description": "Modelo de linguagem pequeno e de ponta com forte compreensão linguística, excelente raciocínio e geração de texto.",
  "Meta-Llama-3.2-3B-Instruct.description": "Modelo de linguagem pequeno e de ponta com forte compreensão linguística, excelente raciocínio e geração de texto.",
  "Meta-Llama-3.3-70B-Instruct.description": "Llama 3.3 é o modelo Llama multilíngue de código aberto mais avançado, oferecendo desempenho próximo ao de modelos de 405B a um custo muito baixo. Baseado em Transformer e aprimorado com SFT e RLHF para utilidade e segurança. A versão ajustada por instruções é otimizada para conversas multilíngues e supera muitos modelos abertos e fechados em benchmarks da indústria. Data de corte do conhecimento: dezembro de 2023.",
  "Meta-Llama-4-Maverick-17B-128E-Instruct-FP8.description": "Llama 4 Maverick é um modelo MoE de grande porte com ativação eficiente de especialistas para desempenho robusto em raciocínio.",
  "MiniMax-M1.description": "Um novo modelo de raciocínio interno com 80 mil cadeias de pensamento e 1 milhão de tokens de entrada, oferecendo desempenho comparável aos principais modelos globais.",
  "MiniMax-M2-Stable.description": "Projetado para fluxos de trabalho de codificação e agentes eficientes, com maior concorrência para uso comercial.",
  "MiniMax-M2.1-Lightning.description": "Poderosas capacidades de programação multilíngue, experiência de codificação totalmente aprimorada. Mais rápido e eficiente.",
  "MiniMax-M2.1.description": "MiniMax-M2.1 é o principal modelo open-source da MiniMax, focado em resolver tarefas complexas do mundo real. Seus principais pontos fortes são as capacidades de programação multilíngue e a habilidade de atuar como um Agente para resolver tarefas complexas.",
  "MiniMax-M2.description": "Desenvolvido especificamente para codificação eficiente e fluxos de trabalho com agentes",
  "MiniMax-Text-01.description": "O MiniMax-01 introduz atenção linear em larga escala além dos Transformers clássicos, com 456 bilhões de parâmetros e 45,9 bilhões ativados por passagem. Alcança desempenho de ponta e suporta até 4 milhões de tokens de contexto (32× GPT-4o, 20× Claude-3.5-Sonnet).",
  "MiniMaxAI/MiniMax-M1-80k.description": "MiniMax-M1 é um modelo de raciocínio com pesos abertos, atenção híbrida em larga escala, com 456 bilhões de parâmetros totais e ~45,9 bilhões ativos por token. Suporta nativamente 1 milhão de tokens de contexto e utiliza Flash Attention para reduzir FLOPs em 75% na geração de 100 mil tokens em comparação com o DeepSeek R1. Com arquitetura MoE, CISPO e treinamento com atenção híbrida via RL, atinge desempenho líder em raciocínio com entradas longas e tarefas reais de engenharia de software.",
  "MiniMaxAI/MiniMax-M2.description": "MiniMax-M2 redefine a eficiência de agentes. É um modelo MoE compacto, rápido e econômico com 230 bilhões de parâmetros totais e 10 bilhões ativos, projetado para tarefas de codificação e agentes de alto nível, mantendo forte inteligência geral. Com apenas 10 bilhões de parâmetros ativos, rivaliza com modelos muito maiores, sendo ideal para aplicações de alta eficiência.",
  "Moonshot-Kimi-K2-Instruct.description": "1 trilhão de parâmetros totais com 32 bilhões ativos. Entre os modelos sem modo de pensamento, é de ponta em conhecimento avançado, matemática e codificação, com desempenho superior em tarefas gerais de agentes. Otimizado para cargas de trabalho de agentes, pode agir, não apenas responder perguntas. Ideal para conversas improvisadas, bate-papo geral e experiências com agentes como um modelo de reflexo, sem pensamento prolongado.",
  "NousResearch/Nous-Hermes-2-Mixtral-8x7B-DPO.description": "Nous Hermes 2 - Mixtral 8x7B-DPO (46,7B) é um modelo de instrução de alta precisão para cálculos complexos.",
  "OmniConsistency.description": "OmniConsistency melhora a consistência de estilo e a generalização em tarefas de imagem para imagem ao introduzir Diffusion Transformers (DiTs) em larga escala e dados estilizados pareados, evitando a degradação de estilo.",
  "PaddlePaddle/PaddleOCR-VL-1.5.description": "PaddleOCR-VL-1.5 é uma versão aprimorada da série PaddleOCR-VL, alcançando 94,5% de precisão no benchmark de análise de documentos OmniDocBench v1.5, superando modelos grandes generalistas e modelos especializados em análise de documentos. Inova ao oferecer suporte à localização de caixas delimitadoras irregulares para elementos de documentos, lidando de forma eficaz com imagens escaneadas, inclinadas e capturadas de tela.",
  "Phi-3-medium-128k-instruct.description": "O mesmo modelo Phi-3-medium com uma janela de contexto maior para RAG ou prompts de poucos exemplos.",
  "Phi-3-medium-4k-instruct.description": "Um modelo com 14 bilhões de parâmetros e qualidade superior ao Phi-3-mini, focado em dados de alta qualidade e raciocínio intensivo.",
  "Phi-3-mini-128k-instruct.description": "O mesmo modelo Phi-3-mini com uma janela de contexto maior para RAG ou prompts de poucos exemplos.",
  "Phi-3-mini-4k-instruct.description": "O menor membro da família Phi-3, otimizado para qualidade e baixa latência.",
  "Phi-3-small-128k-instruct.description": "O mesmo modelo Phi-3-small com uma janela de contexto maior para RAG ou prompts de poucos exemplos.",
  "Phi-3-small-8k-instruct.description": "Um modelo com 7 bilhões de parâmetros e qualidade superior ao Phi-3-mini, focado em dados de alta qualidade e raciocínio intensivo.",
  "Phi-3.5-mini-instruct.description": "Uma versão atualizada do modelo Phi-3-mini.",
  "Phi-3.5-vision-instrust.description": "Uma versão atualizada do modelo Phi-3-vision.",
  "Pro/MiniMaxAI/MiniMax-M2.1.description": "MiniMax-M2.1 é um modelo de linguagem de código aberto otimizado para capacidades de agentes, com excelência em programação, uso de ferramentas, seguimento de instruções e planejamento de longo prazo. O modelo oferece suporte ao desenvolvimento de software multilíngue e à execução de fluxos de trabalho complexos em várias etapas, alcançando uma pontuação de 74,0 no SWE-bench Verified e superando o Claude Sonnet 4.5 em cenários multilíngues.",
  "Pro/Qwen/Qwen2-7B-Instruct.description": "Qwen2-7B-Instruct é um LLM de 7 bilhões de parâmetros ajustado para instruções da série Qwen2. Utiliza arquitetura Transformer com SwiGLU, viés QKV na atenção e atenção com consultas agrupadas, lidando com entradas grandes. Apresenta forte desempenho em compreensão de linguagem, geração, tarefas multilíngues, codificação, matemática e raciocínio, superando a maioria dos modelos abertos e competindo com modelos proprietários. Supera o Qwen1.5-7B-Chat em vários benchmarks.",
  "Pro/Qwen/Qwen2.5-7B-Instruct.description": "Qwen2.5-7B-Instruct faz parte da mais recente série de LLMs da Alibaba Cloud. O modelo de 7 bilhões traz ganhos notáveis em codificação e matemática, suporta mais de 29 idiomas e melhora o seguimento de instruções, compreensão de dados estruturados e geração de saídas estruturadas (especialmente JSON).",
  "Pro/Qwen/Qwen2.5-Coder-7B-Instruct.description": "Qwen2.5-Coder-7B-Instruct é o mais recente LLM da Alibaba Cloud focado em código. Baseado no Qwen2.5 e treinado com 5,5 trilhões de tokens, melhora significativamente a geração, raciocínio e correção de código, mantendo pontos fortes em matemática e capacidades gerais, oferecendo uma base sólida para agentes de codificação.",
  "Pro/Qwen/Qwen2.5-VL-7B-Instruct.description": "Qwen2.5-VL é um novo modelo de linguagem e visão da série Qwen com forte compreensão visual. Analisa texto, gráficos e layouts em imagens, entende vídeos longos e eventos, suporta raciocínio e uso de ferramentas, ancoragem de objetos em múltiplos formatos e saídas estruturadas. Melhora a resolução dinâmica e o treinamento com taxa de quadros para compreensão de vídeo e aumenta a eficiência do codificador visual.",
  "Pro/THUDM/GLM-4.1V-9B-Thinking.description": "GLM-4.1V-9B-Thinking é um modelo VLM de código aberto da Zhipu AI e do Laboratório KEG da Universidade Tsinghua, projetado para cognição multimodal complexa. Baseado no GLM-4-9B-0414, adiciona raciocínio em cadeia e aprendizado por reforço (RL) para melhorar significativamente o raciocínio entre modalidades e a estabilidade.",
  "Pro/THUDM/glm-4-9b-chat.description": "GLM-4-9B-Chat é o modelo GLM-4 de código aberto da Zhipu AI. Apresenta forte desempenho em semântica, matemática, raciocínio, código e conhecimento. Além de bate-papo com múltiplas interações, suporta navegação na web, execução de código, chamadas de ferramentas personalizadas e raciocínio com textos longos. Suporta 26 idiomas (incluindo chinês, inglês, japonês, coreano e alemão). Apresenta bom desempenho nos benchmarks AlignBench-v2, MT-Bench, MMLU e C-Eval, e suporta até 128 mil tokens de contexto para uso acadêmico e empresarial.",
  "Pro/deepseek-ai/DeepSeek-R1-Distill-Qwen-7B.description": "DeepSeek-R1-Distill-Qwen-7B é destilado do Qwen2.5-Math-7B e ajustado com 800 mil amostras curadas do DeepSeek-R1. Apresenta desempenho forte, com 92,8% no MATH-500, 55,5% no AIME 2024 e uma pontuação de 1189 no CodeForces para um modelo de 7B.",
  "Pro/deepseek-ai/DeepSeek-R1.description": "DeepSeek-R1 é um modelo de raciocínio orientado por RL que reduz repetições e melhora a legibilidade. Utiliza dados de início a frio antes do RL para impulsionar ainda mais o raciocínio, iguala o OpenAI-o1 em tarefas de matemática, código e raciocínio, e melhora os resultados gerais por meio de treinamento cuidadoso.",
  "Pro/deepseek-ai/DeepSeek-V3.1-Terminus.description": "DeepSeek-V3.1-Terminus é uma versão atualizada do modelo V3.1, posicionado como um LLM híbrido para agentes. Corrige problemas relatados por usuários e melhora a estabilidade, consistência linguística e reduz caracteres anormais e mistura de chinês/inglês. Integra modos de pensamento e não-pensamento com templates de chat para alternância flexível. Também melhora o desempenho dos agentes de código e de busca para uso mais confiável de ferramentas e tarefas em múltiplas etapas.",
  "Pro/deepseek-ai/DeepSeek-V3.2-Exp.description": "DeepSeek-V3.2-Exp é uma versão experimental da série V3.2 que faz a ponte para a próxima arquitetura. Adiciona DeepSeek Sparse Attention (DSA) sobre o V3.1-Terminus para melhorar o treinamento e a inferência com contexto longo, com otimizações para uso de ferramentas, compreensão de documentos longos e raciocínio em múltiplas etapas. Ideal para explorar maior eficiência de raciocínio com orçamentos de contexto amplos.",
  "Pro/deepseek-ai/DeepSeek-V3.description": "DeepSeek-V3 é um modelo MoE com 671 bilhões de parâmetros, utilizando MLA e DeepSeekMoE com balanceamento de carga sem perdas para inferência e treinamento eficientes. Pré-treinado com 14,8 trilhões de tokens de alta qualidade e ajustado com SFT e RL, supera outros modelos abertos e se aproxima dos modelos fechados líderes.",
  "Pro/moonshotai/Kimi-K2-Instruct-0905.description": "Kimi K2-Instruct-0905 é o mais novo e poderoso modelo Kimi K2. Trata-se de um modelo MoE de alto nível com 1 trilhão de parâmetros totais e 32 bilhões de parâmetros ativos. Seus principais recursos incluem inteligência de codificação agentica aprimorada, com ganhos significativos em benchmarks e tarefas reais de agentes, além de melhorias na estética e usabilidade da codificação de frontend.",
  "Pro/moonshotai/Kimi-K2-Thinking.description": "Kimi K2 Thinking Turbo é a variante Turbo otimizada para velocidade de raciocínio e rendimento, mantendo o raciocínio em múltiplas etapas e o uso de ferramentas do K2 Thinking. É um modelo MoE com aproximadamente 1 trilhão de parâmetros totais, contexto nativo de 256K e chamadas de ferramentas em larga escala estáveis para cenários de produção com exigências mais rigorosas de latência e concorrência.",
  "Pro/moonshotai/Kimi-K2.5.description": "Kimi K2.5 é um modelo agente multimodal nativo open-source, baseado no Kimi-K2-Base, treinado com aproximadamente 1,5 trilhão de tokens mistos de visão e texto. O modelo adota uma arquitetura MoE com 1 trilhão de parâmetros totais e 32 bilhões de parâmetros ativos, suportando uma janela de contexto de 256K, integrando perfeitamente capacidades de compreensão visual e linguística.",
  "Pro/zai-org/glm-4.7.description": "GLM-4.7 é o modelo carro-chefe de nova geração da Zhipu, com 355 bilhões de parâmetros totais e 32 bilhões de parâmetros ativos, totalmente aprimorado em diálogo geral, raciocínio e capacidades de agente. O GLM-4.7 aprimora o Pensamento Intercalado e introduz o Pensamento Preservado e o Pensamento por Turno.",
  "QwQ-32B-Preview.description": "Qwen QwQ é um modelo de pesquisa experimental focado em aprimorar o raciocínio.",
  "Qwen/QVQ-72B-Preview.description": "QVQ-72B-Preview é um modelo de pesquisa da Qwen focado em raciocínio visual, com pontos fortes em compreensão de cenas complexas e problemas visuais de matemática.",
  "Qwen/QwQ-32B-Preview.description": "Qwen QwQ é um modelo de pesquisa experimental focado em aprimorar o raciocínio da IA.",
  "Qwen/QwQ-32B.description": "QwQ é um modelo de raciocínio da família Qwen. Em comparação com modelos padrão ajustados por instrução, ele adiciona capacidades de pensamento e raciocínio que aumentam significativamente o desempenho em tarefas subsequentes, especialmente em problemas difíceis. O QwQ-32B é um modelo de raciocínio de porte médio competitivo com os principais modelos de raciocínio como DeepSeek-R1 e o1-mini. Utiliza RoPE, SwiGLU, RMSNorm e viés QKV na atenção, com 64 camadas e 40 cabeças de atenção Q (8 KV em GQA).",
  "Qwen/Qwen-Image-Edit-2509.description": "Qwen-Image-Edit-2509 é a versão mais recente de edição de imagens da Qwen-Image, desenvolvida pela equipe Qwen. Baseado no modelo Qwen-Image de 20B, ele estende a renderização de texto de alta qualidade para edição de imagens com precisão textual. Utiliza uma arquitetura de controle duplo, enviando entradas para o Qwen2.5-VL para controle semântico e para um codificador VAE para controle de aparência, permitindo edições tanto no nível semântico quanto visual. Suporta edições locais (adicionar/remover/modificar) e edições semânticas de alto nível como criação de IP e transferência de estilo, preservando o significado. Alcança resultados SOTA em diversos benchmarks.",
  "Qwen/Qwen-Image.description": "Qwen-Image é um modelo base de geração de imagens com 20 bilhões de parâmetros da equipe Qwen. Apresenta avanços significativos na renderização de texto complexo e edição precisa de imagens, especialmente para textos em chinês/inglês de alta fidelidade. Suporta layouts de múltiplas linhas e parágrafos mantendo a coerência tipográfica. Além da renderização de texto, oferece uma ampla gama de estilos, desde fotorrealismo até anime, e edições avançadas como transferência de estilo, adição/remoção de objetos, aprimoramento de detalhes, edição de texto e controle de pose, visando ser uma base abrangente para criação visual.",
  "Qwen/Qwen2-72B-Instruct.description": "Qwen 2 Instruct (72B) oferece seguimento preciso de instruções para cargas de trabalho empresariais.",
  "Qwen/Qwen2-7B-Instruct.description": "Qwen2-7B-Instruct é um modelo ajustado por instruções com 7 bilhões de parâmetros da série Qwen2, utilizando Transformer, SwiGLU, viés QKV e atenção com consulta agrupada. Lida com entradas grandes e apresenta desempenho sólido em benchmarks de compreensão, geração, multilinguismo, programação, matemática e raciocínio, superando a maioria dos modelos abertos e ultrapassando o Qwen1.5-7B-Chat em várias avaliações.",
  "Qwen/Qwen2-VL-72B-Instruct.description": "Qwen2-VL é o modelo mais recente da linha Qwen-VL, alcançando SOTA em benchmarks de visão como MathVista, DocVQA, RealWorldQA e MTVQA. Consegue compreender vídeos com mais de 20 minutos para perguntas sobre vídeos, diálogos e criação de conteúdo. Também oferece raciocínio complexo e tomada de decisão, integrando-se a dispositivos/robôs para ações guiadas por visão. Além do inglês e chinês, consegue ler textos em diversos idiomas, incluindo a maioria das línguas europeias, japonês, coreano, árabe e vietnamita.",
  "Qwen/Qwen2.5-14B-Instruct.description": "Qwen2.5-14B-Instruct faz parte da mais recente série de LLMs da Alibaba Cloud. O modelo de 14 bilhões de parâmetros apresenta ganhos notáveis em programação e matemática, suporta mais de 29 idiomas e melhora o seguimento de instruções, compreensão de dados estruturados e geração de saídas estruturadas (especialmente JSON).",
  "Qwen/Qwen2.5-32B-Instruct.description": "Qwen2.5-32B-Instruct faz parte da mais recente série de LLMs da Alibaba Cloud. O modelo de 32 bilhões de parâmetros apresenta ganhos notáveis em programação e matemática, suporta mais de 29 idiomas e melhora o seguimento de instruções, compreensão de dados estruturados e geração de saídas estruturadas (especialmente JSON).",
  "Qwen/Qwen2.5-72B-Instruct-128K.description": "Qwen2.5-72B-Instruct faz parte da mais recente série de LLMs da Alibaba Cloud. O modelo de 72 bilhões de parâmetros melhora a programação e a matemática, suporta até 128K de entrada e mais de 8K de saída, oferece suporte a mais de 29 idiomas e aprimora o seguimento de instruções e a geração de saídas estruturadas (especialmente JSON).",
  "Qwen/Qwen2.5-72B-Instruct-Turbo.description": "Qwen2.5 é uma nova família de LLMs otimizada para tarefas baseadas em instruções.",
  "Qwen/Qwen2.5-72B-Instruct.description": "Qwen2.5-72B-Instruct faz parte da mais recente série de LLMs da Alibaba Cloud. O modelo de 72 bilhões de parâmetros apresenta ganhos notáveis em programação e matemática, suporta mais de 29 idiomas e melhora o seguimento de instruções, compreensão de dados estruturados e geração de saídas estruturadas (especialmente JSON).",
  "Qwen/Qwen2.5-7B-Instruct-Turbo.description": "Qwen2.5 é uma nova família de LLMs otimizada para tarefas baseadas em instruções.",
  "Qwen/Qwen2.5-7B-Instruct.description": "Qwen2.5-7B-Instruct faz parte da mais recente série de LLMs da Alibaba Cloud. O modelo de 7 bilhões de parâmetros apresenta ganhos notáveis em programação e matemática, suporta mais de 29 idiomas e melhora o seguimento de instruções, compreensão de dados estruturados e geração de saídas estruturadas (especialmente JSON).",
  "Qwen/Qwen2.5-Coder-32B-Instruct.description": "Qwen2.5 Coder 32B Instruct é o mais recente LLM da Alibaba Cloud focado em código. Baseado no Qwen2.5 e treinado com 5,5 trilhões de tokens, melhora significativamente a geração, raciocínio e correção de código, mantendo pontos fortes em matemática e tarefas gerais, oferecendo uma base sólida para agentes de programação.",
  "Qwen/Qwen2.5-Coder-7B-Instruct.description": "Qwen2.5-Coder-7B-Instruct é o mais recente LLM da Alibaba Cloud focado em código. Baseado no Qwen2.5 e treinado com 5,5 trilhões de tokens, melhora significativamente a geração, raciocínio e correção de código, mantendo pontos fortes em matemática e tarefas gerais, oferecendo uma base sólida para agentes de programação.",
  "Qwen/Qwen2.5-VL-32B-Instruct.description": "Qwen2.5-VL-32B-Instruct é um modelo multimodal da equipe Qwen. Reconhece objetos comuns e analisa texto, gráficos, ícones, imagens e layouts. Como agente visual, pode raciocinar e controlar ferramentas dinamicamente, incluindo uso de computador e celular. Localiza objetos com precisão e gera saídas estruturadas para faturas e tabelas. Em comparação com o Qwen2-VL, o RL melhora ainda mais a matemática e a resolução de problemas, com respostas mais alinhadas às preferências humanas.",
  "Qwen/Qwen2.5-VL-72B-Instruct.description": "Qwen2.5-VL é o modelo de visão e linguagem da série Qwen2.5 com grandes melhorias: compreensão visual mais forte para objetos, texto, gráficos e layouts; raciocínio como agente visual com uso dinâmico de ferramentas; compreensão de vídeos com mais de 1 hora e captura de eventos-chave; localização precisa de objetos via caixas ou pontos; e saídas estruturadas para dados digitalizados como faturas e tabelas.",
  "Qwen/Qwen3-14B.description": "Qwen3 é um modelo Tongyi Qwen de nova geração com avanços significativos em raciocínio, capacidade geral, habilidades de agente e desempenho multilíngue, além de suportar a alternância entre modos de pensamento.",
  "Qwen/Qwen3-235B-A22B-Instruct-2507.description": "Qwen3-235B-A22B-Instruct-2507 é o modelo MoE carro-chefe da série Qwen3, com 235 bilhões de parâmetros totais e 22 bilhões ativos. Esta versão não-pensante foi atualizada com foco em seguir instruções, raciocínio lógico, compreensão de texto, matemática, ciências, programação e uso de ferramentas. Também amplia o conhecimento multilíngue de cauda longa e se alinha melhor às preferências dos usuários em tarefas subjetivas e abertas.",
  "Qwen/Qwen3-235B-A22B-Thinking-2507.description": "Qwen3-235B-A22B-Thinking-2507 é um modelo Qwen3 voltado para raciocínio complexo e desafiador. Utiliza uma arquitetura MoE com 235 bilhões de parâmetros totais e cerca de 22 bilhões ativos por token, otimizando a eficiência. Como modelo dedicado ao pensamento, apresenta grandes avanços em lógica, matemática, ciências, programação e benchmarks acadêmicos, atingindo desempenho de ponta em raciocínio aberto. Também melhora a execução de instruções, uso de ferramentas e geração de texto, com suporte nativo a contexto de 256K para raciocínio profundo e documentos longos.",
  "Qwen/Qwen3-235B-A22B.description": "Qwen3 é um modelo Tongyi Qwen de nova geração com avanços significativos em raciocínio, capacidade geral, habilidades de agente e desempenho multilíngue, além de suportar a alternância entre modos de pensamento.",
  "Qwen/Qwen3-30B-A3B-Instruct-2507.description": "Qwen3-30B-A3B-Instruct-2507 é a versão não-pensante atualizada do Qwen3-30B-A3B. É um modelo MoE com 30,5 bilhões de parâmetros totais e 3,3 bilhões ativos. Apresenta melhorias significativas em seguir instruções, raciocínio lógico, compreensão de texto, matemática, ciências, programação e uso de ferramentas, além de expandir o conhecimento multilíngue de cauda longa e alinhar-se melhor às preferências dos usuários em tarefas abertas e subjetivas. Suporta contexto de 256K. Este modelo é exclusivamente não-pensante e não gera tags `<think></think>`.",
  "Qwen/Qwen3-30B-A3B-Thinking-2507.description": "Qwen3-30B-A3B-Thinking-2507 é o mais recente modelo de pensamento da série Qwen3. É um modelo MoE com 30,5 bilhões de parâmetros totais e 3,3 bilhões ativos, focado em tarefas complexas. Apresenta avanços significativos em lógica, matemática, ciências, programação e benchmarks acadêmicos, além de melhorias em seguir instruções, uso de ferramentas, geração de texto e alinhamento com preferências. Suporta nativamente contexto de 256K e pode ser estendido para até 1 milhão de tokens. Esta versão é projetada para modo de pensamento, com raciocínio detalhado passo a passo e fortes capacidades de agente.",
  "Qwen/Qwen3-30B-A3B.description": "Qwen3 é um modelo Tongyi Qwen de nova geração com avanços significativos em raciocínio, capacidade geral, habilidades de agente e desempenho multilíngue, além de suportar a alternância entre modos de pensamento.",
  "Qwen/Qwen3-32B.description": "Qwen3 é um modelo Tongyi Qwen de nova geração com avanços significativos em raciocínio, capacidade geral, habilidades de agente e desempenho multilíngue, além de suportar a alternância entre modos de pensamento.",
  "Qwen/Qwen3-8B.description": "Qwen3 é um modelo Tongyi Qwen de nova geração com avanços significativos em raciocínio, capacidade geral, habilidades de agente e desempenho multilíngue, além de suportar a alternância entre modos de pensamento.",
  "Qwen/Qwen3-Coder-30B-A3B-Instruct.description": "Qwen3-Coder-30B-A3B-Instruct é um modelo de código da série Qwen3 desenvolvido pela equipe Qwen. Foi otimizado para alto desempenho e eficiência, com foco em capacidades de programação. Apresenta vantagens notáveis em codificação agente, operações automatizadas de navegador e uso de ferramentas entre os modelos abertos. Suporta nativamente contexto de 256K e pode ser estendido para 1 milhão de tokens para compreensão em nível de base de código. Alimenta codificação agente em plataformas como Qwen Code e CLINE com um formato dedicado de chamada de funções.",
  "Qwen/Qwen3-Coder-480B-A35B-Instruct.description": "Qwen3-Coder-480B-A35B-Instruct é o modelo de código mais avançado da Alibaba até o momento. É um modelo MoE com 480 bilhões de parâmetros totais e 35 bilhões ativos, equilibrando eficiência e desempenho. Suporta nativamente contexto de 256K e pode ser estendido para 1 milhão de tokens via YaRN, permitindo lidar com grandes bases de código. Projetado para fluxos de trabalho de codificação agente, pode interagir com ferramentas e ambientes para resolver tarefas complexas de programação. Alcança resultados de ponta entre os modelos abertos em benchmarks de codificação e agentes, comparável a modelos líderes como Claude Sonnet 4.",
  "Qwen/Qwen3-Next-80B-A3B-Instruct.description": "Qwen3-Next-80B-A3B-Instruct é um modelo base de nova geração que utiliza a arquitetura Qwen3-Next para eficiência extrema em treinamento e inferência. Combina atenção híbrida (Gated DeltaNet + Gated Attention), MoE altamente esparso e otimizações de estabilidade de treinamento. Com 80 bilhões de parâmetros totais, mas cerca de 3 bilhões ativos na inferência, reduz o custo computacional e entrega mais de 10 vezes o throughput do Qwen3-32B em contextos acima de 32K. Esta versão ajustada para instruções é voltada para tarefas gerais (sem modo de pensamento). Apresenta desempenho comparável ao Qwen3-235B em alguns benchmarks e vantagens em tarefas com contexto ultra-longo.",
  "Qwen/Qwen3-Next-80B-A3B-Thinking.description": "Qwen3-Next-80B-A3B-Thinking é um modelo base de nova geração voltado para raciocínio complexo. Utiliza a arquitetura Qwen3-Next com atenção híbrida (Gated DeltaNet + Gated Attention) e MoE altamente esparso para eficiência extrema em treinamento e inferência. Com 80 bilhões de parâmetros totais e cerca de 3 bilhões ativos na inferência, reduz o custo computacional e entrega mais de 10 vezes o throughput do Qwen3-32B em contextos acima de 32K. Esta versão de pensamento é voltada para tarefas de múltiplas etapas como provas, síntese de código, análise lógica e planejamento, gerando cadeias de raciocínio estruturadas. Supera o Qwen3-32B-Thinking e o Gemini-2.5-Flash-Thinking em vários benchmarks.",
  "Qwen/Qwen3-Omni-30B-A3B-Captioner.description": "Qwen3-Omni-30B-A3B-Captioner é um modelo VLM da série Qwen3 desenvolvido para gerar legendas de imagem de alta qualidade, detalhadas e precisas. Utiliza uma arquitetura MoE com 30 bilhões de parâmetros para compreender profundamente imagens e produzir descrições fluentes, destacando-se na captura de detalhes, compreensão de cenas, reconhecimento de objetos e raciocínio relacional.",
  "Qwen/Qwen3-Omni-30B-A3B-Instruct.description": "Qwen3-Omni-30B-A3B-Instruct é um modelo MoE da série Qwen3 com 30 bilhões de parâmetros totais e 3 bilhões ativos, oferecendo alto desempenho com menor custo de inferência. Treinado com dados multilíngues de alta qualidade e múltiplas fontes, suporta entradas multimodais completas (texto, imagens, áudio, vídeo) e compreensão e geração entre modalidades.",
  "Qwen/Qwen3-Omni-30B-A3B-Thinking.description": "Qwen3-Omni-30B-A3B-Thinking é o componente central \"pensante\" do Qwen3-Omni. Processa entradas multimodais (texto, áudio, imagens, vídeo) e realiza raciocínio complexo em cadeia, unificando as entradas em uma representação compartilhada para compreensão profunda entre modalidades. É um modelo MoE com 30 bilhões de parâmetros totais e 3 bilhões ativos, equilibrando raciocínio avançado e eficiência computacional.",
  "Qwen/Qwen3-VL-235B-A22B-Instruct.description": "Qwen3-VL-235B-A22B-Instruct é um modelo Qwen3-VL ajustado para instruções, baseado em MoE, que oferece excelente compreensão e geração multimodal. Suporta nativamente contexto de 256K e é adequado para serviços multimodais de produção com alta concorrência.",
  "Qwen/Qwen3-VL-235B-A22B-Thinking.description": "Qwen3-VL-235B-A22B-Thinking é a versão de pensamento carro-chefe do Qwen3-VL, otimizada para raciocínio multimodal complexo, raciocínio com contexto longo e interação com agentes em cenários corporativos.",
  "Qwen/Qwen3-VL-30B-A3B-Instruct.description": "Qwen3-VL-30B-A3B-Instruct é o modelo Qwen3-VL ajustado para instruções, com forte compreensão e geração visão-linguagem. Suporta nativamente contexto de 256K para chat multimodal e geração condicionada por imagem.",
  "Qwen/Qwen3-VL-30B-A3B-Thinking.description": "Qwen3-VL-30B-A3B-Thinking é a versão aprimorada para raciocínio do Qwen3-VL, otimizada para raciocínio multimodal, conversão de imagem para código e compreensão visual complexa. Suporta contexto de 256K com maior capacidade de raciocínio em cadeia.",
  "Qwen/Qwen3-VL-32B-Instruct.description": "Qwen3-VL-32B-Instruct é um modelo visão-linguagem da equipe Qwen com resultados SOTA em vários benchmarks VL. Suporta imagens em resolução megapixel e oferece forte compreensão visual, OCR multilíngue, ancoragem visual detalhada e diálogo visual. Lida com tarefas multimodais complexas e suporta chamadas de ferramentas e preenchimento de prefixo.",
  "Qwen/Qwen3-VL-32B-Thinking.description": "Qwen3-VL-32B-Thinking é otimizado para raciocínio visual complexo. Inclui um modo de pensamento embutido que gera etapas intermediárias de raciocínio antes das respostas, aprimorando lógica em múltiplas etapas, planejamento e raciocínio complexo. Suporta imagens em megapixel, forte compreensão visual, OCR multilíngue, ancoragem detalhada, diálogo visual, chamadas de ferramentas e preenchimento de prefixo.",
  "Qwen/Qwen3-VL-8B-Instruct.description": "Qwen3-VL-8B-Instruct é um modelo visão-linguagem baseado no Qwen3-8B-Instruct e treinado com grandes volumes de dados imagem-texto. Destaca-se em compreensão visual geral, diálogo centrado em visão e reconhecimento de texto multilíngue em imagens, sendo adequado para QA visual, legendagem, seguimento de instruções multimodais e uso de ferramentas.",
  "Qwen/Qwen3-VL-8B-Thinking.description": "Qwen3-VL-8B-Thinking é a versão visual pensante do Qwen3, otimizada para raciocínio complexo em múltiplas etapas. Gera uma cadeia de pensamento antes das respostas para melhorar a precisão, sendo ideal para QA visual profundo e análise detalhada de imagens.",
  "Qwen2-72B-Instruct.description": "Qwen2 é a versão mais recente da série Qwen, com suporte a uma janela de contexto de 128k. Em comparação com os melhores modelos abertos atuais, o Qwen2-72B supera significativamente os principais modelos em compreensão de linguagem natural, conhecimento, programação, matemática e capacidades multilíngues.",
  "Qwen2-7B-Instruct.description": "Qwen2 é a versão mais recente da série Qwen, superando os melhores modelos abertos de tamanho semelhante e até mesmo modelos maiores. O Qwen2 7B apresenta vantagens significativas em diversos benchmarks, especialmente em programação e compreensão do chinês.",
  "Qwen2-VL-72B.description": "Qwen2-VL-72B é um poderoso modelo de linguagem e visão que oferece suporte ao processamento multimodal de imagem e texto, reconhecendo com precisão o conteúdo visual e gerando descrições ou respostas relevantes.",
  "Qwen2.5-14B-Instruct.description": "Qwen2.5-14B-Instruct é um modelo de linguagem com 14 bilhões de parâmetros e alto desempenho, otimizado para cenários em chinês e multilíngues, com suporte a perguntas e respostas inteligentes e geração de conteúdo.",
  "Qwen2.5-32B-Instruct.description": "Qwen2.5-32B-Instruct é um modelo de linguagem com 32 bilhões de parâmetros e desempenho equilibrado, otimizado para cenários em chinês e multilíngues, com suporte a perguntas e respostas inteligentes e geração de conteúdo.",
  "Qwen2.5-72B-Instruct.description": "Modelo de linguagem para chinês e inglês, ajustado para linguagem, programação, matemática e raciocínio.",
  "Qwen2.5-7B-Instruct.description": "Qwen2.5-7B-Instruct é um modelo de linguagem com 7 bilhões de parâmetros que oferece suporte a chamadas de função e integração fluida com sistemas externos, aumentando significativamente a flexibilidade e a extensibilidade. É otimizado para cenários em chinês e multilíngues, com suporte a perguntas e respostas inteligentes e geração de conteúdo.",
  "Qwen2.5-Coder-14B-Instruct.description": "Qwen2.5-Coder-14B-Instruct é um modelo de instrução para programação em larga escala, com forte capacidade de compreensão e geração de código. Ele lida eficientemente com uma ampla gama de tarefas de programação, sendo ideal para codificação inteligente, geração automatizada de scripts e perguntas e respostas sobre programação.",
  "Qwen2.5-Coder-32B-Instruct.description": "Modelo avançado de linguagem para geração de código, raciocínio e correção de bugs em diversas linguagens de programação.",
  "Qwen3-235B-A22B-Instruct-2507-FP8.description": "Qwen3 235B A22B Instruct 2507 é otimizado para raciocínio avançado e seguimento de instruções, utilizando MoE para manter a eficiência em escala.",
  "Qwen3-235B.description": "Qwen3-235B-A22B é um modelo MoE que introduz um modo híbrido de raciocínio, permitindo alternância fluida entre pensamento e não pensamento. Ele oferece compreensão e raciocínio em 119 idiomas e dialetos, com forte capacidade de uso de ferramentas, competindo com modelos como DeepSeek R1, OpenAI o1, o3-mini, Grok 3 e Google Gemini 2.5 Pro em benchmarks de habilidades gerais, programação, matemática, multilinguismo e raciocínio baseado em conhecimento.",
  "Qwen3-32B.description": "Qwen3-32B é um modelo denso que introduz um modo híbrido de raciocínio, permitindo alternância entre pensamento e não pensamento. Com melhorias na arquitetura, mais dados e melhor treinamento, seu desempenho é comparável ao Qwen2.5-72B.",
  "SenseChat-128K.description": "Base V4 com janela de contexto de 128K, excelente em compreensão e geração de textos longos.",
  "SenseChat-32K.description": "Base V4 com janela de contexto de 32K, flexível para diversos cenários.",
  "SenseChat-5-1202.description": "Versão mais recente baseada no V5.5, com avanços significativos em fundamentos de chinês/inglês, conversação, conhecimento em STEM, humanidades, redação, matemática/lógica e controle de comprimento.",
  "SenseChat-5-Cantonese.description": "Projetado para os hábitos de diálogo de Hong Kong, gírias e conhecimento local; supera o GPT-4 em compreensão do cantonês e rivaliza com o GPT-4 Turbo em conhecimento, raciocínio, matemática e programação.",
  "SenseChat-5-beta.description": "Alguns desempenhos superam o SenseChat-5-1202.",
  "SenseChat-5.description": "Versão mais recente V5.5 com contexto de 128K; grandes avanços em raciocínio matemático, conversação em inglês, seguimento de instruções e compreensão de textos longos, comparável ao GPT-4o.",
  "SenseChat-Character-Pro.description": "Modelo avançado de conversação com personagens, com contexto de 32K, capacidade aprimorada e suporte a chinês/inglês.",
  "SenseChat-Character.description": "Modelo padrão de conversação com personagens, com contexto de 8K e alta velocidade de resposta.",
  "SenseChat-Turbo-1202.description": "Modelo leve mais recente, alcançando mais de 90% da capacidade do modelo completo com custo de inferência significativamente menor.",
  "SenseChat-Turbo.description": "Adequado para perguntas e respostas rápidas e cenários de ajuste fino de modelos.",
  "SenseChat-Vision.description": "Versão mais recente V5.5 com entrada de múltiplas imagens e amplas melhorias em reconhecimento de atributos, relações espaciais, detecção de ações/eventos, compreensão de cenas, reconhecimento de emoções, raciocínio de senso comum e compreensão/geração de texto.",
  "SenseChat.description": "Base V4 com contexto de 4K e forte capacidade geral.",
  "SenseNova-V6-5-Pro.description": "Com atualizações abrangentes em dados multimodais, linguísticos e de raciocínio, além de otimização da estratégia de treinamento, o novo modelo melhora significativamente o raciocínio multimodal e o seguimento de instruções generalizadas, com suporte a janela de contexto de até 128k, destacando-se em tarefas de OCR e reconhecimento de IPs de turismo cultural.",
  "SenseNova-V6-5-Turbo.description": "Com atualizações abrangentes em dados multimodais, linguísticos e de raciocínio, além de otimização da estratégia de treinamento, o novo modelo melhora significativamente o raciocínio multimodal e o seguimento de instruções generalizadas, com suporte a janela de contexto de até 128k, destacando-se em tarefas de OCR e reconhecimento de IPs de turismo cultural.",
  "SenseNova-V6-Pro.description": "Unifica nativamente imagem, texto e vídeo, rompendo barreiras tradicionais entre modalidades; lidera rankings como OpenCompass e SuperCLUE.",
  "SenseNova-V6-Reasoner.description": "Combina raciocínio profundo em visão e linguagem, com suporte a pensamento lento e cadeia completa de raciocínio.",
  "SenseNova-V6-Turbo.description": "Unifica nativamente imagem, texto e vídeo, rompendo barreiras tradicionais entre modalidades. Lidera em capacidades centrais multimodais e linguísticas, com classificação de alto nível em diversas avaliações.",
  "Skylark2-lite-8k.description": "Segunda geração do modelo Skylark. O Skylark2-lite oferece respostas rápidas para cenários em tempo real e sensíveis a custo, com menor necessidade de precisão e janela de contexto de 8K.",
  "Skylark2-pro-32k.description": "Segunda geração do modelo Skylark. O Skylark2-pro oferece maior precisão para geração de textos complexos, como redação profissional, escrita de romances e tradução de alta qualidade, com janela de contexto de 32K.",
  "Skylark2-pro-4k.description": "Segunda geração do modelo Skylark. O Skylark2-pro oferece maior precisão para geração de textos complexos, como redação profissional, escrita de romances e tradução de alta qualidade, com janela de contexto de 4K.",
  "Skylark2-pro-character-4k.description": "Segunda geração do modelo Skylark. O Skylark2-pro-character se destaca em interpretação de papéis e conversação, combinando prompts com estilos de persona distintos e diálogo natural para chatbots, assistentes virtuais e atendimento ao cliente, com respostas rápidas.",
  "Skylark2-pro-turbo-8k.description": "Segunda geração do modelo Skylark. O Skylark2-pro-turbo-8k oferece inferência mais rápida com menor custo e janela de contexto de 8K.",
  "THUDM/GLM-4-32B-0414.description": "GLM-4-32B-0414 é um modelo GLM de próxima geração com 32 bilhões de parâmetros, com desempenho comparável ao OpenAI GPT e à série DeepSeek V3/R1.",
  "THUDM/GLM-4-9B-0414.description": "GLM-4-9B-0414 é um modelo GLM com 9 bilhões de parâmetros que herda as técnicas do GLM-4-32B, oferecendo implantação mais leve. Apresenta bom desempenho em geração de código, design web, geração de SVG e redação baseada em busca.",
  "THUDM/GLM-4.1V-9B-Thinking.description": "GLM-4.1V-9B-Thinking é um modelo VLM de código aberto da Zhipu AI e do Laboratório KEG da Universidade Tsinghua, projetado para cognição multimodal complexa. Baseado no GLM-4-9B-0414, adiciona raciocínio em cadeia e aprendizado por reforço para melhorar significativamente o raciocínio entre modalidades e a estabilidade.",
  "THUDM/GLM-Z1-32B-0414.description": "GLM-Z1-32B-0414 é um modelo de raciocínio profundo baseado no GLM-4-32B-0414, com dados de inicialização a frio e aprendizado por reforço expandido, treinado adicionalmente em matemática, código e lógica. Melhora significativamente a capacidade matemática e a resolução de tarefas complexas em relação ao modelo base.",
  "THUDM/GLM-Z1-9B-0414.description": "GLM-Z1-9B-0414 é um modelo GLM compacto com 9 bilhões de parâmetros que mantém as vantagens do código aberto e oferece capacidade impressionante. Apresenta forte desempenho em raciocínio matemático e tarefas gerais, liderando sua categoria de tamanho entre os modelos abertos.",
  "THUDM/GLM-Z1-Rumination-32B-0414.description": "GLM-Z1-Rumination-32B-0414 é um modelo de raciocínio profundo com capacidade de ruminação (avaliado em comparação com o OpenAI Deep Research). Diferente dos modelos de pensamento profundo típicos, ele dedica mais tempo à deliberação para resolver problemas mais abertos e complexos.",
  "THUDM/glm-4-9b-chat.description": "GLM-4-9B-Chat é o modelo GLM-4 de código aberto da Zhipu AI. Apresenta forte desempenho em semântica, matemática, raciocínio, código e conhecimento. Além de conversas multi-turno, oferece suporte a navegação na web, execução de código, chamadas de ferramentas personalizadas e raciocínio com textos longos. Suporta 26 idiomas (incluindo chinês, inglês, japonês, coreano e alemão). Apresenta bom desempenho em benchmarks como AlignBench-v2, MT-Bench, MMLU e C-Eval, com suporte a contexto de até 128K para uso acadêmico e empresarial.",
  "Tongyi-Zhiwen/QwenLong-L1-32B.description": "QwenLong-L1-32B é o primeiro modelo de raciocínio de longo contexto (LRM) treinado com aprendizado por reforço, otimizado para raciocínio em textos longos. Seu RL com expansão progressiva de contexto permite uma transição estável de contextos curtos para longos. Supera o OpenAI-o3-mini e o Qwen3-235B-A22B em sete benchmarks de QA com documentos de longo contexto, rivalizando com o Claude-3.7-Sonnet-Thinking. É especialmente forte em matemática, lógica e raciocínio multi-hop.",
  "Yi-34B-Chat.description": "Yi-1.5-34B mantém as fortes habilidades linguísticas gerais da série, utilizando treinamento incremental com 500 bilhões de tokens de alta qualidade para melhorar significativamente lógica matemática e programação.",
  "abab5.5-chat.description": "Projetado para cenários de produtividade, com capacidade de lidar com tarefas complexas e geração eficiente de texto para uso profissional.",
  "abab5.5s-chat.description": "Projetado para conversas com personas em chinês, oferecendo diálogos de alta qualidade em chinês para diversas aplicações.",
  "abab6.5g-chat.description": "Projetado para conversas com personas multilíngues, com suporte à geração de diálogos de alta qualidade em inglês e outros idiomas.",
  "abab6.5s-chat.description": "Adequado para uma ampla gama de tarefas de PLN, incluindo geração de texto e sistemas de diálogo.",
  "abab6.5t-chat.description": "Otimizado para conversas com personas em chinês, oferecendo diálogos fluentes que se adequam aos hábitos de expressão do idioma.",
  "accounts/fireworks/models/deepseek-r1.description": "DeepSeek-R1 é um modelo de linguagem de última geração otimizado com aprendizado por reforço e dados de início a frio, oferecendo excelente desempenho em raciocínio, matemática e programação.",
  "accounts/fireworks/models/deepseek-v3.description": "Um poderoso modelo de linguagem Mixture-of-Experts (MoE) da DeepSeek com 671 bilhões de parâmetros totais e 37 bilhões de parâmetros ativos por token.",
  "accounts/fireworks/models/llama-v3-70b-instruct.description": "A Meta desenvolveu e lançou a série de modelos LLM Meta Llama 3, que inclui modelos de geração de texto pré-treinados e ajustados por instrução com 8B e 70B parâmetros. Os modelos Llama 3 ajustados por instrução são otimizados para uso conversacional e superam muitos modelos de chat abertos existentes em benchmarks amplamente utilizados na indústria.",
  "accounts/fireworks/models/llama-v3-8b-instruct-hf.description": "Os modelos Llama 3 da Meta ajustados por instrução são otimizados para uso conversacional e superam muitos modelos de chat abertos existentes em benchmarks amplamente utilizados na indústria. O Llama 3 8B Instruct (versão HF) é a versão original em FP16 do Llama 3 8B Instruct, com resultados esperados equivalentes à implementação oficial do Hugging Face.",
  "accounts/fireworks/models/llama-v3-8b-instruct.description": "A Meta desenvolveu e lançou a série de modelos LLM Meta Llama 3, uma coleção de modelos de geração de texto pré-treinados e ajustados por instrução com 8B e 70B parâmetros. Os modelos Llama 3 ajustados por instrução são otimizados para uso conversacional e superam muitos modelos de chat abertos existentes em benchmarks amplamente utilizados na indústria.",
  "accounts/fireworks/models/llama-v3p1-405b-instruct.description": "O Meta Llama 3.1 é uma família de modelos LLM multilíngues com modelos de geração pré-treinados e ajustados por instrução nos tamanhos 8B, 70B e 405B. Os modelos de texto ajustados por instrução são otimizados para diálogos multilíngues e superam muitos modelos de chat abertos e fechados em benchmarks amplamente utilizados na indústria. O modelo 405B é o mais avançado da família Llama 3.1, utilizando inferência em FP8 que se aproxima da implementação de referência.",
  "accounts/fireworks/models/llama-v3p1-70b-instruct.description": "O Meta Llama 3.1 é uma família de modelos LLM multilíngues com modelos de geração pré-treinados e ajustados por instrução nos tamanhos 8B, 70B e 405B. Os modelos de texto ajustados por instrução são otimizados para diálogos multilíngues e superam muitos modelos de chat abertos e fechados em benchmarks amplamente utilizados na indústria.",
  "accounts/fireworks/models/llama-v3p1-8b-instruct.description": "O Meta Llama 3.1 é uma família de modelos LLM multilíngues com modelos de geração pré-treinados e ajustados por instrução nos tamanhos 8B, 70B e 405B. Os modelos de texto ajustados por instrução são otimizados para diálogos multilíngues e superam muitos modelos de chat abertos e fechados em benchmarks amplamente utilizados na indústria.",
  "accounts/fireworks/models/llama-v3p2-11b-vision-instruct.description": "Um modelo de raciocínio visual ajustado por instrução da Meta com 11 bilhões de parâmetros, otimizado para reconhecimento visual, raciocínio com imagens, legendagem e perguntas e respostas relacionadas a imagens. Ele compreende dados visuais como gráficos e tabelas e conecta visão e linguagem ao gerar descrições textuais de detalhes visuais.",
  "accounts/fireworks/models/llama-v3p2-3b-instruct.description": "O Llama 3.2 3B Instruct é um modelo multilíngue leve da Meta, projetado para execução eficiente com vantagens significativas de latência e custo em relação a modelos maiores. Casos de uso típicos incluem reescrita de consultas/prompts e assistência na escrita.",
  "accounts/fireworks/models/llama-v3p2-90b-vision-instruct.description": "Um modelo de raciocínio visual ajustado por instrução da Meta com 90 bilhões de parâmetros, otimizado para reconhecimento visual, raciocínio com imagens, legendagem e perguntas e respostas relacionadas a imagens. Ele compreende dados visuais como gráficos e tabelas e conecta visão e linguagem ao gerar descrições textuais de detalhes visuais. Observação: este modelo é atualmente fornecido de forma experimental como um modelo serverless. Para uso em produção, observe que a Fireworks pode descontinuar a implantação sem aviso prévio.",
  "accounts/fireworks/models/llama-v3p3-70b-instruct.description": "O Llama 3.3 70B Instruct é a atualização de dezembro do Llama 3.1 70B. Ele melhora o uso de ferramentas, suporte a texto multilíngue, matemática e programação em relação à versão de julho de 2024. Alcança desempenho líder da indústria em raciocínio, matemática e seguimento de instruções, oferecendo desempenho comparável ao 3.1 405B com vantagens significativas de velocidade e custo.",
  "accounts/fireworks/models/mistral-small-24b-instruct-2501.description": "Um modelo com 24 bilhões de parâmetros com capacidade de ponta comparável a modelos maiores.",
  "accounts/fireworks/models/mixtral-8x22b-instruct.description": "Mixtral MoE 8x22B Instruct v0.1 é a versão ajustada por instrução do Mixtral MoE 8x22B v0.1, com a API de conclusão de chat ativada.",
  "accounts/fireworks/models/mixtral-8x7b-instruct.description": "Mixtral MoE 8x7B Instruct é a versão ajustada por instrução do Mixtral MoE 8x7B, com a API de conclusão de chat ativada.",
  "accounts/fireworks/models/mythomax-l2-13b.description": "Uma variante aprimorada do MythoMix, possivelmente sua forma mais refinada, combinando MythoLogic-L2 e Huginn com uma técnica altamente experimental de fusão de tensores. Sua natureza única o torna excelente para contar histórias e interpretação de papéis.",
  "accounts/fireworks/models/phi-3-vision-128k-instruct.description": "Phi-3-Vision-128K-Instruct é um modelo multimodal leve e de última geração construído a partir de dados sintéticos e conjuntos de dados públicos selecionados da web, com foco em dados de texto e visão de alta qualidade e intensivos em raciocínio. Pertence à família Phi-3, com uma versão multimodal que suporta um contexto de 128K tokens. O modelo passa por aprimoramentos rigorosos, incluindo ajuste supervisionado e otimização direta de preferências, para garantir seguimento preciso de instruções e fortes medidas de segurança.",
  "accounts/fireworks/models/qwen-qwq-32b-preview.description": "O modelo Qwen QwQ foca no avanço do raciocínio em IA, demonstrando que modelos abertos podem rivalizar com modelos fechados de ponta em raciocínio. QwQ-32B-Preview é uma versão experimental que iguala o o1 e supera o GPT-4o e Claude 3.5 Sonnet em raciocínio e análise nos benchmarks GPQA, AIME, MATH-500 e LiveCodeBench. Observação: este modelo é atualmente fornecido de forma experimental como um modelo serverless. Para uso em produção, observe que a Fireworks pode descontinuar a implantação sem aviso prévio.",
  "accounts/fireworks/models/qwen2-vl-72b-instruct.description": "O modelo Qwen-VL 72B é a iteração mais recente da Alibaba, refletindo quase um ano de inovação.",
  "accounts/fireworks/models/qwen2p5-72b-instruct.description": "Qwen2.5 é uma série de modelos LLM apenas com decodificador desenvolvida pela equipe Qwen e Alibaba Cloud, oferecendo tamanhos de 0.5B, 1.5B, 3B, 7B, 14B, 32B e 72B, com variantes base e ajustadas por instrução.",
  "accounts/fireworks/models/qwen2p5-coder-32b-instruct.description": "Qwen2.5-Coder é o mais recente modelo LLM da Qwen projetado para programação (anteriormente CodeQwen). Observação: este modelo é atualmente fornecido de forma experimental como um modelo serverless. Para uso em produção, observe que a Fireworks pode descontinuar a implantação sem aviso prévio.",
  "accounts/yi-01-ai/models/yi-large.description": "Yi-Large é um modelo LLM de alto nível que ocupa posição logo abaixo do GPT-4, Gemini 1.5 Pro e Claude 3 Opus no ranking LMSYS. Ele se destaca em capacidade multilíngue, especialmente em espanhol, chinês, japonês, alemão e francês. Yi-Large também é amigável para desenvolvedores, utilizando o mesmo esquema de API do OpenAI para fácil integração.",
  "ai21-jamba-1.5-large.description": "Um modelo multilíngue com 398 bilhões de parâmetros (94B ativos), janela de contexto de 256K, chamadas de função, saída estruturada e geração fundamentada.",
  "ai21-jamba-1.5-mini.description": "Um modelo multilíngue com 52 bilhões de parâmetros (12B ativos), janela de contexto de 256K, chamadas de função, saída estruturada e geração fundamentada.",
  "ai21-labs/AI21-Jamba-1.5-Large.description": "Um modelo multilíngue com 398 bilhões de parâmetros (94B ativos), janela de contexto de 256K, chamadas de função, saída estruturada e geração fundamentada.",
  "ai21-labs/AI21-Jamba-1.5-Mini.description": "Um modelo multilíngue com 52 bilhões de parâmetros (12B ativos), janela de contexto de 256K, chamadas de função, saída estruturada e geração fundamentada.",
  "alibaba/qwen-3-14b.description": "Qwen3 é a geração mais recente da série Qwen, oferecendo um conjunto abrangente de modelos densos e MoE. Baseado em treinamento extensivo, traz avanços em raciocínio, seguimento de instruções, capacidades de agente e suporte multilíngue.",
  "alibaba/qwen-3-235b.description": "Qwen3 é a geração mais recente da série Qwen, oferecendo um conjunto abrangente de modelos densos e MoE. Baseado em treinamento extensivo, traz avanços em raciocínio, seguimento de instruções, capacidades de agente e suporte multilíngue.",
  "alibaba/qwen-3-30b.description": "Qwen3 é a geração mais recente da série Qwen, oferecendo um conjunto abrangente de modelos densos e MoE. Baseado em treinamento extensivo, traz avanços em raciocínio, seguimento de instruções, capacidades de agente e suporte multilíngue.",
  "alibaba/qwen-3-32b.description": "Qwen3 é a geração mais recente da série Qwen, oferecendo um conjunto abrangente de modelos densos e MoE. Baseado em treinamento extensivo, traz avanços em raciocínio, seguimento de instruções, capacidades de agente e suporte multilíngue.",
  "alibaba/qwen3-coder.description": "Qwen3-Coder-480B-A35B-Instruct é o modelo de código mais agente da Qwen, com excelente desempenho em programação autônoma, uso de navegador por agentes e outras tarefas centrais de codificação, alcançando resultados comparáveis ao nível do Claude Sonnet.",
  "amazon/nova-lite.description": "Um modelo multimodal de baixíssimo custo com processamento extremamente rápido de entradas de imagem, vídeo e texto.",
  "amazon/nova-micro.description": "Um modelo apenas de texto que oferece latência ultrabaixa a um custo muito reduzido.",
  "amazon/nova-pro.description": "Um modelo multimodal altamente capaz com o melhor equilíbrio entre precisão, velocidade e custo para uma ampla gama de tarefas.",
  "amazon/titan-embed-text-v2.description": "Amazon Titan Text Embeddings V2 é um modelo de embeddings multilíngue leve e eficiente, com suporte para dimensões de 1024, 512 e 256.",
  "anthropic.claude-3-5-sonnet-20240620-v1:0.description": "Claude 3.5 Sonnet eleva o padrão da indústria, superando concorrentes e o Claude 3 Opus em avaliações amplas, mantendo velocidade e custo intermediários.",
  "anthropic.claude-3-5-sonnet-20241022-v2:0.description": "Claude 3.5 Sonnet eleva o padrão da indústria, superando concorrentes e o Claude 3 Opus em avaliações amplas, mantendo velocidade e custo intermediários.",
  "anthropic.claude-3-haiku-20240307-v1:0.description": "Claude 3 Haiku é o modelo mais rápido e compacto da Anthropic, oferecendo respostas quase instantâneas para consultas simples. Proporciona experiências de IA naturais e fluídas, com suporte a entrada de imagem e janela de contexto de 200 mil tokens.",
  "anthropic.claude-3-opus-20240229-v1:0.description": "Claude 3 Opus é o modelo de IA mais poderoso da Anthropic, com desempenho de ponta em tarefas altamente complexas. Lida com prompts abertos e cenários inéditos com fluência excepcional e compreensão semelhante à humana, além de suportar entrada de imagem com janela de contexto de 200 mil tokens.",
  "anthropic.claude-3-sonnet-20240229-v1:0.description": "Claude 3 Sonnet equilibra inteligência e velocidade para cargas de trabalho corporativas, oferecendo alto valor a um custo reduzido. Foi projetado como um modelo confiável para implantações de IA em escala e suporta entrada de imagem com janela de contexto de 200 mil tokens.",
  "anthropic.claude-instant-v1.description": "Um modelo rápido, econômico e ainda assim capaz para conversas cotidianas, análise de texto, resumo e perguntas e respostas sobre documentos.",
  "anthropic.claude-v2.description": "Um modelo altamente capaz para tarefas que vão de diálogos complexos e geração criativa até seguimento detalhado de instruções.",
  "anthropic.claude-v2:1.description": "Uma versão atualizada do Claude 2 com o dobro da janela de contexto e melhorias em confiabilidade, taxa de alucinação e precisão baseada em evidências para documentos longos e RAG.",
  "anthropic/claude-3-haiku.description": "Claude 3 Haiku é o modelo mais rápido da Anthropic, projetado para cargas de trabalho corporativas com prompts longos. Analisa rapidamente documentos extensos como relatórios trimestrais, contratos ou casos jurídicos a metade do custo de modelos similares.",
  "anthropic/claude-3-opus.description": "Claude 3 Opus é o modelo mais inteligente da Anthropic, com desempenho líder de mercado em tarefas altamente complexas, lidando com prompts abertos e cenários inéditos com fluência excepcional e compreensão semelhante à humana.",
  "anthropic/claude-3.5-haiku.description": "Claude 3.5 Haiku apresenta velocidade aprimorada, maior precisão em codificação e uso de ferramentas, ideal para cenários com exigências elevadas de velocidade e interação com ferramentas.",
  "anthropic/claude-3.5-sonnet.description": "Claude 3.5 Sonnet é o modelo rápido e eficiente da família Sonnet, oferecendo melhor desempenho em codificação e raciocínio, com algumas versões sendo gradualmente substituídas pelo Sonnet 3.7 e posteriores.",
  "anthropic/claude-3.7-sonnet.description": "Claude 3.7 Sonnet é um modelo Sonnet aprimorado com raciocínio e codificação mais robustos, adequado para tarefas complexas em nível corporativo.",
  "anthropic/claude-haiku-4.5.description": "Claude Haiku 4.5 é o modelo rápido de alto desempenho da Anthropic, oferecendo latência muito baixa com alta precisão.",
  "anthropic/claude-opus-4.1.description": "Opus 4.1 é o modelo de ponta da Anthropic, otimizado para programação, raciocínio complexo e tarefas de longa duração.",
  "anthropic/claude-opus-4.5.description": "Claude Opus 4.5 é o modelo principal da Anthropic, combinando inteligência de alto nível com desempenho escalável para tarefas complexas e raciocínio de alta qualidade.",
  "anthropic/claude-opus-4.description": "Opus 4 é o modelo principal da Anthropic, projetado para tarefas complexas e aplicações corporativas.",
  "anthropic/claude-sonnet-4.5.description": "Claude Sonnet 4.5 é o mais recente modelo híbrido de raciocínio da Anthropic, otimizado para raciocínio complexo e codificação.",
  "anthropic/claude-sonnet-4.description": "Claude Sonnet 4 é o modelo híbrido de raciocínio da Anthropic com capacidade mista de pensamento e não-pensamento.",
  "ascend-tribe/pangu-pro-moe.description": "Pangu-Pro-MoE 72B-A16B é um LLM esparso com 72 bilhões de parâmetros totais e 16 bilhões ativos, baseado em uma arquitetura MoE agrupada (MoGE). Ele agrupa especialistas durante a seleção e limita os tokens a ativar especialistas iguais por grupo, equilibrando a carga e melhorando a eficiência de implantação no Ascend.",
  "aya.description": "Aya 23 é o modelo multilíngue da Cohere com suporte a 23 idiomas para diversos casos de uso.",
  "aya:35b.description": "Aya 23 é o modelo multilíngue da Cohere com suporte a 23 idiomas para diversos casos de uso.",
  "azure-DeepSeek-R1-0528.description": "Implantado pela Microsoft; o DeepSeek R1 foi atualizado para DeepSeek-R1-0528. A atualização aumenta o poder computacional e otimizações no algoritmo pós-treinamento, melhorando significativamente a profundidade de raciocínio e inferência. Apresenta ótimo desempenho em benchmarks de matemática, programação e lógica geral, aproximando-se de modelos líderes como o O3 e Gemini 2.5 Pro.",
  "baichuan-m2-32b.description": "Baichuan M2 32B é um modelo MoE da Baichuan Intelligence com forte capacidade de raciocínio.",
  "baichuan/baichuan2-13b-chat.description": "Baichuan-13B é um LLM de 13 bilhões de parâmetros de código aberto e uso comercial da Baichuan, alcançando resultados de ponta para seu tamanho em benchmarks autoritativos em chinês e inglês.",
  "baidu/ERNIE-4.5-300B-A47B.description": "ERNIE-4.5-300B-A47B é um LLM MoE da Baidu com 300 bilhões de parâmetros totais e 47 bilhões ativos por token, equilibrando desempenho robusto e eficiência computacional. Como modelo central do ERNIE 4.5, destaca-se em compreensão, geração, raciocínio e programação. Utiliza pré-treinamento multimodal heterogêneo com treinamento conjunto texto-visão para aumentar a capacidade geral, especialmente em seguir instruções e conhecimento de mundo.",
  "baidu/ernie-5.0-thinking-preview.description": "ERNIE 5.0 Thinking Preview é o modelo ERNIE multimodal nativo de próxima geração da Baidu, com forte compreensão multimodal, seguimento de instruções, criação, perguntas e respostas factuais e uso de ferramentas.",
  "black-forest-labs/flux-1.1-pro.description": "FLUX 1.1 Pro é uma versão mais rápida e aprimorada do FLUX Pro, com excelente qualidade de imagem e aderência ao prompt.",
  "black-forest-labs/flux-dev.description": "FLUX Dev é a versão de desenvolvimento do FLUX para uso não comercial.",
  "black-forest-labs/flux-pro.description": "FLUX Pro é o modelo profissional do FLUX para geração de imagens de alta qualidade.",
  "black-forest-labs/flux-schnell.description": "FLUX Schnell é um modelo de geração de imagens rápido, otimizado para velocidade.",
  "c4ai-aya-expanse-32b.description": "Aya Expanse é um modelo multilíngue de alto desempenho com 32 bilhões de parâmetros que utiliza ajuste por instrução, arbitragem de dados, treinamento por preferência e fusão de modelos para rivalizar com modelos monolíngues. Suporta 23 idiomas.",
  "c4ai-aya-expanse-8b.description": "Aya Expanse é um modelo multilíngue de alto desempenho com 8 bilhões de parâmetros que utiliza ajuste por instrução, arbitragem de dados, treinamento por preferência e fusão de modelos para rivalizar com modelos monolíngues. Suporta 23 idiomas.",
  "c4ai-aya-vision-32b.description": "Aya Vision é um modelo multimodal de última geração com forte desempenho em benchmarks de linguagem, texto e visão. Suporta 23 idiomas. Esta versão de 32B foca em desempenho multilíngue de alto nível.",
  "c4ai-aya-vision-8b.description": "Aya Vision é um modelo multimodal de última geração com forte desempenho em benchmarks de linguagem, texto e visão. Esta versão de 8B foca em baixa latência e desempenho robusto.",
  "charglm-3.description": "CharGLM-3 foi desenvolvido para simulação de papéis e companhia emocional, com suporte a memória de múltiplas interações de longo prazo e diálogo personalizado.",
  "charglm-4.description": "CharGLM-4 foi desenvolvido para simulação de papéis e companhia emocional, com suporte a memória de múltiplas interações de longo prazo e diálogo personalizado.",
  "chatgpt-4o-latest.description": "ChatGPT-4o é um modelo dinâmico atualizado em tempo real, combinando forte compreensão e geração para casos de uso em larga escala como suporte ao cliente, educação e suporte técnico.",
  "claude-2.0.description": "Claude 2 oferece melhorias importantes para empresas, incluindo um contexto líder de 200 mil tokens, menos alucinações, prompts de sistema e um novo recurso de teste: chamadas de ferramentas.",
  "claude-2.1.description": "Claude 2 oferece melhorias importantes para empresas, incluindo um contexto líder de 200 mil tokens, menos alucinações, prompts de sistema e um novo recurso de teste: chamadas de ferramentas.",
  "claude-3-5-haiku-20241022.description": "Claude 3.5 Haiku é o modelo de nova geração mais rápido da Anthropic. Em comparação com o Claude 3 Haiku, apresenta melhorias em diversas habilidades e supera o maior modelo anterior, o Claude 3 Opus, em muitos testes de inteligência.",
  "claude-3-5-haiku-latest.description": "Claude 3.5 Haiku oferece respostas rápidas para tarefas leves.",
  "claude-3-7-sonnet-20250219.description": "Claude 3.7 Sonnet é o modelo mais inteligente da Anthropic e o primeiro modelo híbrido de raciocínio do mercado. Ele pode gerar respostas quase instantâneas ou realizar raciocínios detalhados passo a passo que os usuários podem acompanhar. O Sonnet se destaca especialmente em programação, ciência de dados, visão computacional e tarefas de agentes.",
  "claude-3-7-sonnet-latest.description": "Claude 3.7 Sonnet é o modelo mais recente e avançado da Anthropic para tarefas altamente complexas, com excelência em desempenho, inteligência, fluência e compreensão.",
  "claude-3-haiku-20240307.description": "Claude 3 Haiku é o modelo mais rápido e compacto da Anthropic, projetado para respostas quase instantâneas com desempenho rápido e preciso.",
  "claude-3-opus-20240229.description": "Claude 3 Opus é o modelo mais poderoso da Anthropic para tarefas altamente complexas, com excelência em desempenho, inteligência, fluência e compreensão.",
  "claude-3-sonnet-20240229.description": "Claude 3 Sonnet equilibra inteligência e velocidade para cargas de trabalho empresariais, oferecendo alta utilidade com menor custo e implantação confiável em larga escala.",
  "claude-haiku-4-5-20251001.description": "Claude Haiku 4.5 é o modelo Haiku mais rápido e inteligente da Anthropic, com velocidade relâmpago e raciocínio avançado.",
  "claude-opus-4-1-20250805-thinking.description": "Claude Opus 4.1 Thinking é uma variante avançada que pode revelar seu processo de raciocínio.",
  "claude-opus-4-1-20250805.description": "Claude Opus 4.1 é o modelo mais recente e avançado da Anthropic para tarefas altamente complexas, com excelência em desempenho, inteligência, fluência e compreensão.",
  "claude-opus-4-20250514.description": "Claude Opus 4 é o modelo mais poderoso da Anthropic para tarefas altamente complexas, com destaque em desempenho, inteligência, fluência e compreensão.",
  "claude-opus-4-5-20251101.description": "Claude Opus 4.5 é o modelo principal da Anthropic, combinando inteligência excepcional com desempenho escalável, ideal para tarefas complexas que exigem respostas e raciocínio da mais alta qualidade.",
  "claude-opus-4-6.description": "Claude Opus 4.6 é o modelo mais inteligente da Anthropic para desenvolvimento de agentes e programação.",
  "claude-sonnet-4-20250514-thinking.description": "Claude Sonnet 4 Thinking pode produzir respostas quase instantâneas ou pensamento passo a passo estendido com processo visível.",
  "claude-sonnet-4-20250514.description": "Claude Sonnet 4 pode gerar respostas quase instantâneas ou realizar raciocínios detalhados passo a passo com processo visível.",
  "claude-sonnet-4-5-20250929.description": "Claude Sonnet 4.5 é o modelo mais inteligente da Anthropic até o momento.",
  "codegeex-4.description": "CodeGeeX-4 é um assistente de codificação com IA poderoso que oferece suporte a perguntas e respostas multilíngues e autocompletar código para aumentar a produtividade dos desenvolvedores.",
  "codegeex4-all-9b.description": "CodeGeeX4-ALL-9B é um modelo de geração de código multilíngue que oferece suporte a autocompletar e geração de código, interpretação de código, busca na web, chamadas de função e perguntas e respostas em nível de repositório, cobrindo uma ampla gama de cenários de desenvolvimento de software. É um modelo de código de alto nível com menos de 10 bilhões de parâmetros.",
  "codegemma.description": "CodeGemma é um modelo leve para tarefas variadas de programação, permitindo iteração rápida e fácil integração.",
  "codegemma:2b.description": "CodeGemma é um modelo leve para tarefas variadas de programação, permitindo iteração rápida e fácil integração.",
  "codellama.description": "Code Llama é um modelo de linguagem grande (LLM) focado em geração e discussão de código, com amplo suporte a linguagens para fluxos de trabalho de desenvolvedores.",
  "codellama/CodeLlama-34b-Instruct-hf.description": "Code Llama é um modelo de linguagem grande (LLM) focado em geração e discussão de código, com amplo suporte a linguagens para fluxos de trabalho de desenvolvedores.",
  "codellama:13b.description": "Code Llama é um modelo de linguagem grande (LLM) focado em geração e discussão de código, com amplo suporte a linguagens para fluxos de trabalho de desenvolvedores.",
  "codellama:34b.description": "Code Llama é um modelo de linguagem grande (LLM) focado em geração e discussão de código, com amplo suporte a linguagens para fluxos de trabalho de desenvolvedores.",
  "codellama:70b.description": "Code Llama é um modelo de linguagem grande (LLM) focado em geração e discussão de código, com amplo suporte a linguagens para fluxos de trabalho de desenvolvedores.",
  "codeqwen.description": "CodeQwen1.5 é um modelo de linguagem grande treinado com uma ampla base de dados de código, projetado para tarefas complexas de programação.",
  "codestral-latest.description": "Codestral é nosso modelo de codificação mais avançado; a versão v2 (jan 2025) é voltada para tarefas de baixa latência e alta frequência como FIM, correção de código e geração de testes.",
  "codestral.description": "Codestral é o primeiro modelo de código da Mistral AI, oferecendo suporte robusto à geração de código.",
  "codex-mini-latest.description": "codex-mini-latest é um modelo o4-mini ajustado para o Codex CLI. Para uso direto via API, recomendamos começar com o gpt-4.1.",
  "cogito-2.1:671b.description": "Cogito v2.1 671B é um modelo de linguagem grande de código aberto dos EUA, gratuito para uso comercial, com desempenho comparável aos melhores modelos, maior eficiência de raciocínio por token, contexto longo de 128k e capacidade geral robusta.",
  "cogview-4.description": "CogView-4 é o primeiro modelo de texto para imagem de código aberto da Zhipu que pode gerar caracteres chineses. Ele melhora a compreensão semântica, a qualidade da imagem e a renderização de texto em chinês/inglês, suporta prompts bilíngues de qualquer comprimento e pode gerar imagens em qualquer resolução dentro de faixas especificadas.",
  "cohere-command-r-plus.description": "Command R+ é um modelo avançado otimizado para RAG, desenvolvido para cargas de trabalho empresariais.",
  "cohere-command-r.description": "Command R é um modelo generativo escalável projetado para uso com RAG e ferramentas, permitindo IA em nível de produção.",
  "cohere/Cohere-command-r-plus.description": "Command R+ é um modelo avançado otimizado para RAG, desenvolvido para cargas de trabalho empresariais.",
  "cohere/Cohere-command-r.description": "Command R é um modelo generativo escalável projetado para uso com RAG e ferramentas, permitindo IA em nível de produção.",
  "cohere/command-a.description": "Command A é o modelo mais poderoso da Cohere até o momento, com excelência no uso de ferramentas, agentes, RAG e casos de uso multilíngues. Possui janela de contexto de 256K, roda em apenas duas GPUs e oferece 150% mais rendimento que o Command R+ 08-2024.",
  "cohere/command-r-plus.description": "Command R+ é o mais recente LLM da Cohere, otimizado para chat e contexto longo, visando desempenho excepcional para que empresas avancem de protótipos para produção.",
  "cohere/command-r.description": "Command R é otimizado para tarefas de chat e contexto longo, posicionado como um modelo “escalável” que equilibra alto desempenho e precisão, permitindo que empresas avancem de protótipos para produção.",
  "cohere/embed-v4.0.description": "Um modelo que classifica ou converte texto, imagens ou conteúdo misto em embeddings.",
  "comfyui/flux-dev.description": "FLUX.1 Dev é um modelo de texto para imagem de alta qualidade (10–50 etapas), ideal para resultados criativos e artísticos premium.",
  "comfyui/flux-kontext-dev.description": "FLUX.1 Kontext-dev é um modelo de edição de imagem que permite edições guiadas por texto, incluindo edições locais e transferência de estilo.",
  "comfyui/flux-krea-dev.description": "FLUX.1 Krea-dev é um modelo de texto para imagem com filtros de segurança integrados, co-desenvolvido com a Krea.",
  "comfyui/flux-schnell.description": "FLUX.1 Schnell é um modelo de texto para imagem ultrarrápido que gera imagens de alta qualidade em 1–4 etapas, ideal para uso em tempo real e prototipagem rápida.",
  "comfyui/stable-diffusion-15.description": "Stable Diffusion 1.5 é um modelo clássico de texto para imagem 512x512, ideal para prototipagem rápida e experimentos criativos.",
  "comfyui/stable-diffusion-35-inclclip.description": "Stable Diffusion 3.5 com codificadores CLIP/T5 integrados, não requer arquivos de codificador externos, adequado para modelos como sd3.5_medium_incl_clips com menor uso de recursos.",
  "comfyui/stable-diffusion-35.description": "Stable Diffusion 3.5 é um modelo de texto para imagem de nova geração com variantes Large e Medium. Requer arquivos de codificador CLIP externos e oferece excelente qualidade de imagem e aderência ao prompt.",
  "comfyui/stable-diffusion-custom-refiner.description": "Modelo personalizado SDXL de imagem para imagem. Use custom_sd_lobe.safetensors como nome do arquivo do modelo; se tiver um VAE, use custom_sd_vae_lobe.safetensors. Coloque os arquivos do modelo nas pastas exigidas pelo Comfy.",
  "comfyui/stable-diffusion-custom.description": "Modelo personalizado SD de texto para imagem. Use custom_sd_lobe.safetensors como nome do arquivo do modelo; se tiver um VAE, use custom_sd_vae_lobe.safetensors. Coloque os arquivos do modelo nas pastas exigidas pelo Comfy.",
  "comfyui/stable-diffusion-refiner.description": "Modelo SDXL de imagem para imagem que realiza transformações de alta qualidade a partir de imagens de entrada, com suporte a transferência de estilo, restauração e variações criativas.",
  "comfyui/stable-diffusion-xl.description": "SDXL é um modelo de texto para imagem que suporta geração em alta resolução 1024x1024 com melhor qualidade de imagem e detalhes.",
  "command-a-03-2025.description": "O Command A é o nosso modelo mais avançado até o momento, com excelente desempenho no uso de ferramentas, agentes, RAG e cenários multilíngues. Possui uma janela de contexto de 256K, opera com apenas duas GPUs e oferece 150% mais rendimento do que o Command R+ 08-2024.",
  "command-light-nightly.description": "Para reduzir o intervalo entre grandes lançamentos, oferecemos versões noturnas do Command. Na série command-light, essa versão é chamada de command-light-nightly. É a versão mais recente e experimental (e potencialmente instável), atualizada regularmente sem aviso prévio, portanto não é recomendada para ambientes de produção.",
  "command-light.description": "Uma variante menor e mais rápida do Command, quase tão capaz quanto, mas com maior velocidade.",
  "command-nightly.description": "Para reduzir o intervalo entre grandes lançamentos, oferecemos versões noturnas do Command. Na série Command, essa versão é chamada de command-nightly. É a versão mais recente e experimental (e potencialmente instável), atualizada regularmente sem aviso prévio, portanto não é recomendada para ambientes de produção.",
  "command-r-03-2024.description": "O Command R é um modelo de chat que segue instruções, com maior qualidade, confiabilidade e uma janela de contexto mais longa do que os modelos anteriores. Suporta fluxos de trabalho complexos como geração de código, RAG, uso de ferramentas e agentes.",
  "command-r-08-2024.description": "command-r-08-2024 é uma versão atualizada do modelo Command R, lançada em agosto de 2024.",
  "command-r-plus-04-2024.description": "command-r-plus é um alias de command-r-plus-04-2024, portanto, ao usar command-r-plus na API, você estará acessando esse modelo.",
  "command-r-plus-08-2024.description": "O Command R+ é um modelo de chat que segue instruções, com maior qualidade, confiabilidade e uma janela de contexto mais longa do que os modelos anteriores. É ideal para fluxos de trabalho RAG complexos e uso de ferramentas em múltiplas etapas.",
  "command-r-plus.description": "O Command R+ é um LLM de alto desempenho projetado para cenários empresariais reais e aplicativos complexos.",
  "command-r.description": "O Command R é um LLM otimizado para chat e tarefas com contexto longo, ideal para interações dinâmicas e gestão de conhecimento.",
  "command-r7b-12-2024.description": "command-r7b-12-2024 é uma atualização pequena e eficiente lançada em dezembro de 2024. Destaca-se em tarefas de RAG, uso de ferramentas e agentes que exigem raciocínio complexo em múltiplas etapas.",
  "command.description": "Um modelo de chat que segue instruções, oferecendo maior qualidade e confiabilidade em tarefas de linguagem, com uma janela de contexto mais longa do que nossos modelos generativos básicos.",
  "computer-use-preview.description": "computer-use-preview é um modelo especializado para a ferramenta \"uso de computador\", treinado para compreender e executar tarefas relacionadas ao uso de computadores.",
  "dall-e-2.description": "Modelo DALL·E de segunda geração com geração de imagens mais realista e precisa, e resolução 4× maior que a da primeira geração.",
  "dall-e-3.description": "O modelo DALL·E mais recente, lançado em novembro de 2023, oferece geração de imagens mais realista e precisa, com maior riqueza de detalhes.",
  "databricks/dbrx-instruct.description": "O DBRX Instruct oferece manuseio de instruções altamente confiável em diversos setores.",
  "deepseek-ai/DeepSeek-OCR.description": "O DeepSeek-OCR é um modelo de visão e linguagem da DeepSeek AI focado em OCR e \"compressão óptica contextual\". Explora a compressão de contexto a partir de imagens, processa documentos de forma eficiente e os converte em texto estruturado (por exemplo, Markdown). Reconhece texto em imagens com precisão, sendo ideal para digitalização de documentos, extração de texto e processamento estruturado.",
  "deepseek-ai/DeepSeek-R1-0528-Qwen3-8B.description": "O DeepSeek-R1-0528-Qwen3-8B destila o raciocínio em cadeia do DeepSeek-R1-0528 no Qwen3 8B Base. Alcança SOTA entre modelos abertos, superando o Qwen3 8B em 10% no AIME 2024 e igualando o desempenho do Qwen3-235B-thinking. Destaca-se em raciocínio matemático, programação e benchmarks de lógica geral. Compartilha a arquitetura do Qwen3-8B, mas usa o tokenizador do DeepSeek-R1-0528.",
  "deepseek-ai/DeepSeek-R1-0528.description": "O DeepSeek R1 aproveita maior capacidade computacional e otimizações algorítmicas pós-treinamento para aprofundar o raciocínio. Apresenta desempenho sólido em benchmarks de matemática, programação e lógica geral, aproximando-se de líderes como o o3 e o Gemini 2.5 Pro.",
  "deepseek-ai/DeepSeek-R1-Distill-Llama-70B.description": "Os modelos destilados DeepSeek-R1 utilizam aprendizado por reforço (RL) e dados de inicialização a frio para melhorar o raciocínio e estabelecer novos benchmarks multitarefa entre modelos abertos.",
  "deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B.description": "Os modelos destilados DeepSeek-R1 utilizam aprendizado por reforço (RL) e dados de inicialização a frio para melhorar o raciocínio e estabelecer novos benchmarks multitarefa entre modelos abertos.",
  "deepseek-ai/DeepSeek-R1-Distill-Qwen-14B.description": "Os modelos destilados DeepSeek-R1 utilizam aprendizado por reforço (RL) e dados de inicialização a frio para melhorar o raciocínio e estabelecer novos benchmarks multitarefa entre modelos abertos.",
  "deepseek-ai/DeepSeek-R1-Distill-Qwen-32B.description": "O DeepSeek-R1-Distill-Qwen-32B é destilado do Qwen2.5-32B e ajustado com 800 mil amostras curadas do DeepSeek-R1. Destaca-se em matemática, programação e raciocínio, com resultados expressivos no AIME 2024, MATH-500 (94,3% de acurácia) e GPQA Diamond.",
  "deepseek-ai/DeepSeek-R1-Distill-Qwen-7B.description": "O DeepSeek-R1-Distill-Qwen-7B é destilado do Qwen2.5-Math-7B e ajustado com 800 mil amostras curadas do DeepSeek-R1. Apresenta desempenho sólido, com 92,8% no MATH-500, 55,5% no AIME 2024 e pontuação 1189 no CodeForces para um modelo de 7B.",
  "deepseek-ai/DeepSeek-R1.description": "O DeepSeek-R1 melhora o raciocínio com dados de inicialização a frio e aprendizado por reforço, estabelecendo novos benchmarks multitarefa entre modelos abertos e superando o OpenAI-o1-mini.",
  "deepseek-ai/DeepSeek-V2.5.description": "O DeepSeek-V2.5 aprimora os modelos DeepSeek-V2-Chat e DeepSeek-Coder-V2-Instruct, combinando habilidades gerais e de programação. Melhora a escrita e o seguimento de instruções para melhor alinhamento de preferências, com ganhos significativos no AlpacaEval 2.0, ArenaHard, AlignBench e MT-Bench.",
  "deepseek-ai/DeepSeek-V3.1-Terminus.description": "O DeepSeek-V3.1-Terminus é uma versão atualizada do modelo V3.1, posicionado como um LLM híbrido com foco em agentes. Corrige problemas relatados por usuários e melhora a estabilidade, consistência linguística e reduz caracteres anômalos e mistura de idiomas. Integra modos de pensamento e não-pensamento com templates de chat para alternância flexível. Também aprimora o desempenho dos agentes de código e busca para uso mais confiável de ferramentas e tarefas em múltiplas etapas.",
  "deepseek-ai/DeepSeek-V3.1.description": "O DeepSeek V3.1 utiliza uma arquitetura de raciocínio híbrida e suporta modos de pensamento e não-pensamento.",
  "deepseek-ai/DeepSeek-V3.2-Exp.description": "O DeepSeek-V3.2-Exp é uma versão experimental do V3.2 que faz a ponte para a próxima arquitetura. Adiciona DeepSeek Sparse Attention (DSA) sobre o V3.1-Terminus para melhorar o treinamento e inferência em contextos longos, com otimizações para uso de ferramentas, compreensão de documentos longos e raciocínio em múltiplas etapas. Ideal para explorar maior eficiência de raciocínio com grandes orçamentos de contexto.",
  "deepseek-ai/DeepSeek-V3.description": "O DeepSeek-V3 é um modelo MoE com 671 bilhões de parâmetros, utilizando MLA e DeepSeekMoE com balanceamento de carga sem perdas para treinamento e inferência eficientes. Pré-treinado com 14,8 trilhões de tokens de alta qualidade, com SFT e RL, supera outros modelos abertos e se aproxima dos modelos fechados líderes.",
  "deepseek-ai/deepseek-llm-67b-chat.description": "O DeepSeek LLM Chat (67B) é um modelo inovador que oferece compreensão profunda da linguagem e interação.",
  "deepseek-ai/deepseek-v3.1-terminus.description": "O DeepSeek V3.1 é um modelo de raciocínio de nova geração com raciocínio complexo mais forte e cadeia de pensamento para tarefas de análise profunda.",
  "deepseek-ai/deepseek-v3.1.description": "O DeepSeek V3.1 é um modelo de raciocínio de nova geração com raciocínio complexo mais forte e cadeia de pensamento para tarefas de análise profunda.",
  "deepseek-ai/deepseek-vl2.description": "O DeepSeek-VL2 é um modelo de visão e linguagem MoE baseado no DeepSeekMoE-27B com ativação esparsa, alcançando alto desempenho com apenas 4,5B de parâmetros ativos. Destaca-se em QA visual, OCR, compreensão de documentos/tabelas/gráficos e ancoragem visual.",
  "deepseek-chat.description": "Um novo modelo de código aberto que combina habilidades gerais e de programação. Ele mantém o diálogo geral do modelo de chat e a forte capacidade de codificação do modelo de programador, com melhor alinhamento de preferências. O DeepSeek-V2.5 também aprimora a escrita e o seguimento de instruções.",
  "deepseek-coder-33B-instruct.description": "O DeepSeek Coder 33B é um modelo de linguagem para código treinado com 2 trilhões de tokens (87% código, 13% texto em chinês/inglês). Introduz uma janela de contexto de 16K e tarefas de preenchimento intermediário, oferecendo preenchimento de código em nível de projeto e inserção de trechos.",
  "deepseek-coder-v2.description": "O DeepSeek Coder V2 é um modelo de código MoE open-source com forte desempenho em tarefas de programação, comparável ao GPT-4 Turbo.",
  "deepseek-coder-v2:236b.description": "O DeepSeek Coder V2 é um modelo de código MoE open-source com forte desempenho em tarefas de programação, comparável ao GPT-4 Turbo.",
  "deepseek-ocr.description": "O DeepSeek-OCR é um modelo de visão e linguagem da DeepSeek AI focado em OCR e \"compressão óptica contextual\". Explora a compressão de informações contextuais a partir de imagens, processa documentos de forma eficiente e os converte em formatos de texto estruturado como Markdown. Reconhece texto em imagens com precisão, sendo ideal para digitalização de documentos, extração de texto e processamento estruturado.",
  "deepseek-r1-0528.description": "Modelo completo de 685B lançado em 28/05/2025. O DeepSeek-R1 utiliza RL em larga escala no pós-treinamento, melhorando significativamente o raciocínio com dados rotulados mínimos, com forte desempenho em matemática, programação e raciocínio em linguagem natural.",
  "deepseek-r1-250528.description": "O DeepSeek R1 250528 é o modelo completo de raciocínio DeepSeek-R1 para tarefas difíceis de matemática e lógica.",
  "deepseek-r1-70b-fast-online.description": "Edição rápida do DeepSeek R1 70B com busca em tempo real na web, oferecendo respostas mais rápidas sem comprometer o desempenho.",
  "deepseek-r1-70b-online.description": "Edição padrão do DeepSeek R1 70B com busca em tempo real na web, ideal para chat e tarefas de texto atualizadas.",
  "deepseek-r1-distill-llama-70b.description": "O DeepSeek R1 Distill Llama 70B combina o raciocínio do R1 com o ecossistema Llama.",
  "deepseek-r1-distill-llama-8b.description": "O DeepSeek-R1-Distill-Llama-8B é destilado do Llama-3.1-8B usando saídas do DeepSeek R1.",
  "deepseek-r1-distill-llama.description": "deepseek-r1-distill-llama é destilado do DeepSeek-R1 sobre o Llama.",
  "deepseek-r1-distill-qianfan-70b.description": "O DeepSeek R1 Distill Qianfan 70B é uma destilação do R1 baseada no Qianfan-70B com alto valor.",
  "deepseek-r1-distill-qianfan-8b.description": "O DeepSeek R1 Distill Qianfan 8B é uma destilação do R1 baseada no Qianfan-8B para aplicativos de pequeno e médio porte.",
  "deepseek-r1-distill-qianfan-llama-70b.description": "O DeepSeek R1 Distill Qianfan Llama 70B é uma destilação do R1 baseada no Llama-70B.",
  "deepseek-r1-distill-qwen-1.5b.description": "O DeepSeek R1 Distill Qwen 1.5B é um modelo de destilação ultraleve para ambientes com recursos muito limitados.",
  "deepseek-r1-distill-qwen-14b.description": "O DeepSeek R1 Distill Qwen 14B é um modelo de destilação de porte médio para implantação em múltiplos cenários.",
  "deepseek-r1-distill-qwen-32b.description": "O DeepSeek R1 Distill Qwen 32B é uma destilação do R1 baseada no Qwen-32B, equilibrando desempenho e custo.",
  "deepseek-r1-distill-qwen-7b.description": "O DeepSeek R1 Distill Qwen 7B é um modelo de destilação leve para ambientes de borda e empresas privadas.",
  "deepseek-r1-distill-qwen.description": "deepseek-r1-distill-qwen é destilado do DeepSeek-R1 sobre o Qwen.",
  "deepseek-r1-fast-online.description": "Versão completa e rápida do DeepSeek R1 com busca em tempo real na web, combinando capacidade de 671B com respostas mais ágeis.",
  "deepseek-r1-online.description": "Versão completa do DeepSeek R1 com 671B de parâmetros e busca em tempo real na web, oferecendo compreensão e geração mais robustas.",
  "deepseek-r1.description": "O DeepSeek-R1 usa dados de inicialização a frio antes do RL e apresenta desempenho comparável ao OpenAI-o1 em matemática, programação e raciocínio.",
  "deepseek-reasoner.description": "O modo de raciocínio DeepSeek V3.2 gera uma cadeia de pensamento antes da resposta final para melhorar a precisão.",
  "deepseek-v2.description": "O DeepSeek V2 é um modelo MoE eficiente para processamento econômico.",
  "deepseek-v2:236b.description": "O DeepSeek V2 236B é o modelo da DeepSeek focado em código com forte geração de código.",
  "deepseek-v3-0324.description": "O DeepSeek-V3-0324 é um modelo MoE com 671B de parâmetros, com destaque em programação, capacidade técnica, compreensão de contexto e manipulação de textos longos.",
  "deepseek-v3.1-terminus.description": "DeepSeek-V3.1-Terminus é um modelo LLM otimizado para terminais da DeepSeek, desenvolvido especialmente para dispositivos de terminal.",
  "deepseek-v3.1-think-250821.description": "DeepSeek V3.1 Think 250821 é o modelo de raciocínio profundo correspondente à versão Terminus, projetado para desempenho elevado em tarefas de raciocínio.",
  "deepseek-v3.1.description": "DeepSeek-V3.1 é um novo modelo híbrido de raciocínio da DeepSeek, que suporta modos com e sem raciocínio, oferecendo maior eficiência de pensamento em comparação ao DeepSeek-R1-0528. Otimizações pós-treinamento melhoram significativamente o uso de ferramentas por agentes e o desempenho em tarefas. Suporta uma janela de contexto de 128k e até 64k tokens de saída.",
  "deepseek-v3.1:671b.description": "DeepSeek V3.1 é um modelo de raciocínio de nova geração com melhorias em raciocínio complexo e cadeia de pensamento, ideal para tarefas que exigem análise profunda.",
  "deepseek-v3.2-exp.description": "deepseek-v3.2-exp introduz atenção esparsa para melhorar a eficiência de treinamento e inferência em textos longos, com custo inferior ao deepseek-v3.1.",
  "deepseek-v3.2-think.description": "DeepSeek V3.2 Think é um modelo completo de raciocínio profundo com raciocínio em cadeias longas mais robusto.",
  "deepseek-v3.2.description": "DeepSeek-V3.2 é o primeiro modelo de raciocínio híbrido da DeepSeek que integra pensamento ao uso de ferramentas. Utiliza uma arquitetura eficiente para economizar computação, aprendizado por reforço em larga escala para ampliar capacidades e dados sintéticos em grande escala para fortalecer a generalização. A combinação desses três elementos atinge desempenho comparável ao GPT-5-High, com comprimento de saída significativamente reduzido, diminuindo notavelmente a sobrecarga computacional e o tempo de espera do usuário.",
  "deepseek-v3.description": "DeepSeek-V3 é um poderoso modelo MoE com 671 bilhões de parâmetros totais e 37 bilhões ativos por token.",
  "deepseek-vl2-small.description": "DeepSeek VL2 Small é uma versão multimodal leve, ideal para ambientes com recursos limitados e alta concorrência.",
  "deepseek-vl2.description": "DeepSeek VL2 é um modelo multimodal para compreensão de imagem-texto e perguntas e respostas visuais detalhadas.",
  "deepseek/deepseek-chat-v3-0324.description": "DeepSeek V3 é um modelo MoE com 685 bilhões de parâmetros e a mais recente iteração da série de chat principal da DeepSeek.\n\nBaseado no [DeepSeek V3](/deepseek/deepseek-chat-v3), apresenta excelente desempenho em diversas tarefas.",
  "deepseek/deepseek-chat-v3-0324:free.description": "DeepSeek V3 é um modelo MoE com 685 bilhões de parâmetros e a mais recente iteração da série de chat principal da DeepSeek.\n\nBaseado no [DeepSeek V3](/deepseek/deepseek-chat-v3), apresenta excelente desempenho em diversas tarefas.",
  "deepseek/deepseek-chat-v3.1.description": "DeepSeek-V3.1 é o modelo híbrido de raciocínio com longo contexto da DeepSeek, com suporte a modos mistos de pensamento/não pensamento e integração com ferramentas.",
  "deepseek/deepseek-chat.description": "DeepSeek-V3 é o modelo híbrido de raciocínio de alto desempenho da DeepSeek para tarefas complexas e integração com ferramentas.",
  "deepseek/deepseek-math-v2.description": "DeepSeek Math V2 é um modelo que alcançou avanços significativos em capacidades de raciocínio matemático. Sua principal inovação está no mecanismo de treinamento de \"autoverificação\", tendo conquistado níveis de medalha de ouro em diversas competições de matemática de alto nível.",
  "deepseek/deepseek-r1-0528.description": "DeepSeek R1 0528 é uma variante atualizada com foco em disponibilidade aberta e raciocínio mais profundo.",
  "deepseek/deepseek-r1-0528:free.description": "DeepSeek-R1 melhora significativamente o raciocínio com dados rotulados mínimos e gera uma cadeia de pensamento antes da resposta final para aumentar a precisão.",
  "deepseek/deepseek-r1-distill-llama-70b.description": "DeepSeek R1 Distill Llama 70B é um LLM destilado baseado no Llama 3.3 70B, ajustado com saídas do DeepSeek R1 para alcançar desempenho competitivo com modelos de ponta.",
  "deepseek/deepseek-r1-distill-llama-8b.description": "DeepSeek R1 Distill Llama 8B é um LLM destilado baseado no Llama-3.1-8B-Instruct, treinado com saídas do DeepSeek R1.",
  "deepseek/deepseek-r1-distill-qwen-14b.description": "DeepSeek R1 Distill Qwen 14B é um LLM destilado baseado no Qwen 2.5 14B, treinado com saídas do DeepSeek R1. Supera o OpenAI o1-mini em vários benchmarks, alcançando resultados de ponta entre modelos densos. Destaques de benchmark:\nAIME 2024 pass@1: 69.7\nMATH-500 pass@1: 93.9\nCodeForces Rating: 1481\nO ajuste fino com saídas do DeepSeek R1 oferece desempenho competitivo com modelos de ponta maiores.",
  "deepseek/deepseek-r1-distill-qwen-32b.description": "DeepSeek R1 Distill Qwen 32B é um LLM destilado baseado no Qwen 2.5 32B, treinado com saídas do DeepSeek R1. Supera o OpenAI o1-mini em vários benchmarks, alcançando resultados de ponta entre modelos densos. Destaques de benchmark:\nAIME 2024 pass@1: 72.6\nMATH-500 pass@1: 94.3\nCodeForces Rating: 1691\nO ajuste fino com saídas do DeepSeek R1 oferece desempenho competitivo com modelos de ponta maiores.",
  "deepseek/deepseek-r1.description": "DeepSeek R1 foi atualizado para DeepSeek-R1-0528. Com mais capacidade computacional e otimizações algorítmicas pós-treinamento, melhora significativamente a profundidade e capacidade de raciocínio. Apresenta forte desempenho em benchmarks de matemática, programação e lógica geral, aproximando-se de líderes como o o3 e Gemini 2.5 Pro.",
  "deepseek/deepseek-r1/community.description": "DeepSeek R1 é o mais recente modelo de código aberto lançado pela equipe DeepSeek, com desempenho de raciocínio muito forte, especialmente em matemática, programação e tarefas de lógica, comparável ao OpenAI o1.",
  "deepseek/deepseek-r1:free.description": "DeepSeek-R1 melhora significativamente o raciocínio com dados rotulados mínimos e gera uma cadeia de pensamento antes da resposta final para aumentar a precisão.",
  "deepseek/deepseek-reasoner.description": "DeepSeek-V3 Thinking (reasoner) é o modelo experimental de raciocínio da DeepSeek, adequado para tarefas de alta complexidade.",
  "deepseek/deepseek-v3.1-base.description": "DeepSeek V3.1 Base é uma versão aprimorada do modelo DeepSeek V3.",
  "deepseek/deepseek-v3.description": "Um LLM rápido e de uso geral com raciocínio aprimorado.",
  "deepseek/deepseek-v3/community.description": "DeepSeek-V3 representa um grande avanço na velocidade de raciocínio em relação aos modelos anteriores. Classifica-se em primeiro lugar entre os modelos de código aberto e rivaliza com os modelos fechados mais avançados. Adota Multi-Head Latent Attention (MLA) e a arquitetura DeepSeekMoE, ambas validadas no DeepSeek-V2. Também introduz uma estratégia auxiliar sem perdas para balanceamento de carga e um objetivo de treinamento com previsão de múltiplos tokens para desempenho superior.",
  "deepseek_r1.description": "DeepSeek-R1 é um modelo de raciocínio orientado por aprendizado por reforço que resolve problemas de repetição e legibilidade. Antes do RL, utiliza dados de início a frio para melhorar ainda mais o desempenho de raciocínio. Alcança desempenho comparável ao OpenAI-o1 em tarefas de matemática, programação e raciocínio, com treinamento cuidadosamente projetado para melhorar os resultados gerais.",
  "deepseek_r1_distill_llama_70b.description": "DeepSeek-R1-Distill-Llama-70B é destilado do Llama-3.3-70B-Instruct. Como parte da série DeepSeek-R1, é ajustado com amostras geradas pelo DeepSeek-R1 e apresenta forte desempenho em matemática, programação e raciocínio.",
  "deepseek_r1_distill_qwen_14b.description": "DeepSeek-R1-Distill-Qwen-14B é destilado do Qwen2.5-14B e ajustado com 800 mil amostras selecionadas geradas pelo DeepSeek-R1, oferecendo raciocínio robusto.",
  "deepseek_r1_distill_qwen_32b.description": "DeepSeek-R1-Distill-Qwen-32B é destilado do Qwen2.5-32B e ajustado com 800 mil amostras selecionadas geradas pelo DeepSeek-R1, destacando-se em matemática, programação e raciocínio.",
  "devstral-2:123b.description": "O Devstral 2 123B se destaca no uso de ferramentas para explorar bases de código, editar múltiplos arquivos e oferecer suporte a agentes de engenharia de software.",
  "doubao-1.5-lite-32k.description": "O Doubao-1.5-lite é um novo modelo leve com resposta ultrarrápida, oferecendo qualidade e latência de alto nível.",
  "doubao-1.5-pro-256k.description": "O Doubao-1.5-pro-256k é uma atualização abrangente do Doubao-1.5-Pro, com melhoria de 10% no desempenho geral. Suporta uma janela de contexto de 256k e até 12k tokens de saída, oferecendo maior desempenho, janela expandida e excelente custo-benefício para casos de uso mais amplos.",
  "doubao-1.5-pro-32k.description": "O Doubao-1.5-pro é um modelo carro-chefe de nova geração com melhorias em todas as áreas, destacando-se em conhecimento, programação e raciocínio.",
  "doubao-1.5-thinking-pro-m.description": "O Doubao-1.5 é um novo modelo de raciocínio profundo (a versão m inclui raciocínio multimodal nativo) que se destaca em matemática, programação, raciocínio científico e tarefas gerais como escrita criativa. Alcança ou se aproxima dos melhores resultados em benchmarks como AIME 2024, Codeforces e GPQA. Suporta uma janela de contexto de 128k e saída de até 16k tokens.",
  "doubao-1.5-thinking-pro.description": "O Doubao-1.5 é um novo modelo de raciocínio profundo que se destaca em matemática, programação, raciocínio científico e tarefas gerais como escrita criativa. Alcança ou se aproxima dos melhores resultados em benchmarks como AIME 2024, Codeforces e GPQA. Suporta uma janela de contexto de 128k e saída de até 16k tokens.",
  "doubao-1.5-thinking-vision-pro.description": "Um novo modelo visual de raciocínio profundo com compreensão e raciocínio multimodal aprimorados, alcançando resultados SOTA em 37 de 59 benchmarks públicos.",
  "doubao-1.5-ui-tars.description": "O Doubao-1.5-UI-TARS é um modelo de agente com foco nativo em interfaces gráficas, interagindo perfeitamente com interfaces por meio de percepção, raciocínio e ação semelhantes às humanas.",
  "doubao-1.5-vision-lite.description": "O Doubao-1.5-vision-lite é um modelo multimodal aprimorado que suporta imagens em qualquer resolução e proporções extremas, melhorando o raciocínio visual, reconhecimento de documentos, compreensão de detalhes e seguimento de instruções. Suporta uma janela de contexto de 128k e até 16k tokens de saída.",
  "doubao-1.5-vision-pro-32k.description": "O Doubao-1.5-vision-pro é um modelo multimodal aprimorado que suporta imagens em qualquer resolução e proporções extremas, melhorando o raciocínio visual, reconhecimento de documentos, compreensão de detalhes e seguimento de instruções.",
  "doubao-1.5-vision-pro.description": "O Doubao-1.5-vision-pro é um modelo multimodal aprimorado que suporta imagens em qualquer resolução e proporções extremas, melhorando o raciocínio visual, reconhecimento de documentos, compreensão de detalhes e seguimento de instruções.",
  "doubao-lite-128k.description": "Resposta ultrarrápida com melhor custo-benefício, oferecendo mais flexibilidade em diversos cenários. Suporta raciocínio e ajuste fino com janela de contexto de 128k.",
  "doubao-lite-32k.description": "Resposta ultrarrápida com melhor custo-benefício, oferecendo mais flexibilidade em diversos cenários. Suporta raciocínio e ajuste fino com janela de contexto de 32k.",
  "doubao-lite-4k.description": "Resposta ultrarrápida com melhor custo-benefício, oferecendo mais flexibilidade em diversos cenários. Suporta raciocínio e ajuste fino com janela de contexto de 4k.",
  "doubao-pro-256k.description": "O modelo carro-chefe com melhor desempenho para tarefas complexas, com excelentes resultados em QA com referência, sumarização, criação, classificação de texto e simulação de papéis. Suporta raciocínio e ajuste fino com janela de contexto de 256k.",
  "doubao-pro-32k.description": "O modelo carro-chefe com melhor desempenho para tarefas complexas, com excelentes resultados em QA com referência, sumarização, criação, classificação de texto e simulação de papéis. Suporta raciocínio e ajuste fino com janela de contexto de 32k.",
  "doubao-seed-1.6-flash.description": "O Doubao-Seed-1.6-flash é um modelo multimodal de raciocínio profundo ultrarrápido com TPOT de até 10ms. Suporta entrada de texto e imagem, supera o modelo lite anterior em compreensão de texto e se equipara aos modelos pro concorrentes em visão. Suporta janela de contexto de 256k e até 16k tokens de saída.",
  "doubao-seed-1.6-lite.description": "O Doubao-Seed-1.6-lite é um novo modelo multimodal de raciocínio profundo com esforço de raciocínio ajustável (Mínimo, Baixo, Médio, Alto), oferecendo melhor custo-benefício e sendo uma escolha sólida para tarefas comuns, com janela de contexto de até 256k.",
  "doubao-seed-1.6-thinking.description": "O Doubao-Seed-1.6-thinking fortalece significativamente o raciocínio, melhorando ainda mais as habilidades centrais em programação, matemática e raciocínio lógico em relação ao Doubao-1.5-thinking-pro, além de adicionar compreensão visual. Suporta janela de contexto de 256k e até 16k tokens de saída.",
  "doubao-seed-1.6-vision.description": "O Doubao-Seed-1.6-vision é um modelo visual de raciocínio profundo que oferece compreensão e raciocínio multimodal mais robustos para educação, revisão de imagens, inspeção/segurança e perguntas e respostas com busca por IA. Suporta janela de contexto de 256k e até 64k tokens de saída.",
  "doubao-seed-1.6.description": "O Doubao-Seed-1.6 é um novo modelo multimodal de raciocínio profundo com modos automático, com raciocínio e sem raciocínio. No modo sem raciocínio, supera significativamente o Doubao-1.5-pro/250115. Suporta janela de contexto de 256k e até 16k tokens de saída.",
  "doubao-seed-1.8.description": "Doubao-Seed-1.8 possui compreensão multimodal e capacidades de agente mais robustas, com suporte a entrada de texto/imagem/vídeo e cache de contexto, oferecendo desempenho excelente em tarefas complexas.",
  "doubao-seed-code.description": "O Doubao-Seed-Code é profundamente otimizado para programação com agentes, suporta entradas multimodais (texto/imagem/vídeo) e janela de contexto de 256k, é compatível com a API da Anthropic e adequado para fluxos de trabalho de programação, compreensão visual e agentes.",
  "doubao-seededit-3-0-i2i-250628.description": "O modelo de imagem Doubao da ByteDance Seed suporta entradas de texto e imagem com geração de imagem altamente controlável e de alta qualidade. Suporta edição de imagem guiada por texto, com tamanhos de saída entre 512 e 1536 no lado mais longo.",
  "doubao-seedream-3-0-t2i-250415.description": "O Seedream 3.0 é um modelo de geração de imagem da ByteDance Seed, que suporta entradas de texto e imagem com geração de imagem altamente controlável e de alta qualidade. Gera imagens a partir de comandos de texto.",
  "doubao-seedream-4-0-250828.description": "O Seedream 4.0 é um modelo de geração de imagem da ByteDance Seed, que suporta entradas de texto e imagem com geração de imagem altamente controlável e de alta qualidade. Gera imagens a partir de comandos de texto.",
  "doubao-vision-lite-32k.description": "O Doubao-vision é um modelo multimodal da Doubao com forte compreensão e raciocínio de imagens, além de seguir instruções com precisão. Tem bom desempenho em tarefas de extração imagem-texto e raciocínio baseado em imagem, permitindo cenários de QA visual mais complexos e amplos.",
  "doubao-vision-pro-32k.description": "O Doubao-vision é um modelo multimodal da Doubao com forte compreensão e raciocínio de imagens, além de seguir instruções com precisão. Tem bom desempenho em tarefas de extração imagem-texto e raciocínio baseado em imagem, permitindo cenários de QA visual mais complexos e amplos.",
  "emohaa.description": "O Emohaa é um modelo voltado para saúde mental com habilidades profissionais de aconselhamento para ajudar os usuários a compreender questões emocionais.",
  "ernie-4.5-0.3b.description": "ERNIE 4.5 0.3B é um modelo leve de código aberto para implantação local e personalizada.",
  "ernie-4.5-21b-a3b.description": "ERNIE 4.5 21B A3B é um modelo de código aberto com grande número de parâmetros, com melhor compreensão e geração.",
  "ernie-4.5-300b-a47b.description": "ERNIE 4.5 300B A47B é o modelo MoE ultra-grande da Baidu ERNIE, com excelente capacidade de raciocínio.",
  "ernie-4.5-8k-preview.description": "ERNIE 4.5 8K Preview é um modelo de pré-visualização com contexto de 8K para avaliação do ERNIE 4.5.",
  "ernie-4.5-turbo-128k-preview.description": "Pré-visualização do ERNIE 4.5 Turbo 128K com capacidades de nível de lançamento, ideal para integração e testes canário.",
  "ernie-4.5-turbo-128k.description": "ERNIE 4.5 Turbo 128K é um modelo geral de alto desempenho com aumento por busca e uso de ferramentas para perguntas e respostas, programação e cenários com agentes.",
  "ernie-4.5-turbo-32k.description": "ERNIE 4.5 Turbo 32K é uma versão com contexto médio para perguntas e respostas, recuperação de base de conhecimento e diálogos de múltiplas interações.",
  "ernie-4.5-turbo-latest.description": "Última versão do ERNIE 4.5 Turbo com desempenho geral otimizado, ideal como modelo principal de produção.",
  "ernie-4.5-turbo-vl-32k-preview.description": "Pré-visualização multimodal do ERNIE 4.5 Turbo VL 32K para avaliação da capacidade de visão em contexto longo.",
  "ernie-4.5-turbo-vl-32k.description": "ERNIE 4.5 Turbo VL 32K é uma versão multimodal de contexto médio-longo para compreensão combinada de documentos longos e imagens.",
  "ernie-4.5-turbo-vl-latest.description": "ERNIE 4.5 Turbo VL Latest é a versão multimodal mais recente com melhor compreensão e raciocínio entre imagem e texto.",
  "ernie-4.5-turbo-vl-preview.description": "Pré-visualização do ERNIE 4.5 Turbo VL, modelo multimodal para compreensão e geração de imagem-texto, ideal para perguntas visuais e compreensão de conteúdo.",
  "ernie-4.5-turbo-vl.description": "ERNIE 4.5 Turbo VL é um modelo multimodal maduro para compreensão e reconhecimento de imagem-texto em produção.",
  "ernie-4.5-vl-28b-a3b.description": "ERNIE 4.5 VL 28B A3B é um modelo multimodal de código aberto para compreensão e raciocínio de imagem-texto.",
  "ernie-5.0-thinking-latest.description": "Wenxin 5.0 Thinking é um modelo nativo multimodal de ponta com modelagem unificada de texto, imagem, áudio e vídeo. Oferece amplas melhorias de capacidade para perguntas e respostas complexas, criação e cenários com agentes.",
  "ernie-5.0-thinking-preview.description": "Pré-visualização do Wenxin 5.0 Thinking, modelo nativo multimodal de ponta com modelagem unificada de texto, imagem, áudio e vídeo. Oferece amplas melhorias de capacidade para perguntas e respostas complexas, criação e cenários com agentes.",
  "ernie-char-8k.description": "ERNIE Character 8K é um modelo de diálogo com personalidade para construção de personagens IP e conversas de companhia de longo prazo.",
  "ernie-char-fiction-8k-preview.description": "Pré-visualização do ERNIE Character Fiction 8K, modelo para criação de personagens e enredos, voltado para avaliação e testes de recursos.",
  "ernie-char-fiction-8k.description": "ERNIE Character Fiction 8K é um modelo de personagem para romances e criação de enredos, adequado para geração de histórias longas.",
  "ernie-irag-edit.description": "ERNIE iRAG Edit é um modelo de edição de imagem que suporta apagar, repintar e gerar variantes.",
  "ernie-lite-pro-128k.description": "ERNIE Lite Pro 128K é um modelo leve de alto desempenho para cenários sensíveis à latência e ao custo.",
  "ernie-novel-8k.description": "ERNIE Novel 8K é projetado para romances longos e enredos de IP com narrativas de múltiplos personagens.",
  "ernie-speed-pro-128k.description": "ERNIE Speed Pro 128K é um modelo de alto valor e alta concorrência para serviços online em larga escala e aplicativos corporativos.",
  "ernie-x1-turbo-32k.description": "ERNIE X1 Turbo 32K é um modelo de raciocínio rápido com contexto de 32K para raciocínio complexo e bate-papo de múltiplas interações.",
  "ernie-x1.1-preview.description": "Pré-visualização do modelo de raciocínio ERNIE X1.1 para avaliação e testes.",
  "fal-ai/bytedance/seedream/v4.description": "Seedream 4.0 é um modelo de geração de imagens da ByteDance Seed, que aceita entradas de texto e imagem, com geração de imagens altamente controlável e de alta qualidade. Ele gera imagens a partir de comandos de texto.",
  "fal-ai/flux-kontext/dev.description": "Modelo FLUX.1 focado em edição de imagens, com suporte a entradas de texto e imagem.",
  "fal-ai/flux-pro/kontext.description": "FLUX.1 Kontext [pro] aceita texto e imagens de referência como entrada, permitindo edições locais direcionadas e transformações complexas de cena.",
  "fal-ai/flux/krea.description": "Flux Krea [dev] é um modelo de geração de imagens com viés estético para imagens mais realistas e naturais.",
  "fal-ai/flux/schnell.description": "FLUX.1 [schnell] é um modelo de geração de imagens com 12 bilhões de parâmetros, projetado para saída rápida e de alta qualidade.",
  "fal-ai/hunyuan-image/v3.description": "Um poderoso modelo multimodal nativo de geração de imagens.",
  "fal-ai/imagen4/preview.description": "Modelo de geração de imagens de alta qualidade do Google.",
  "fal-ai/nano-banana.description": "Nano Banana é o modelo multimodal nativo mais novo, rápido e eficiente do Google, permitindo geração e edição de imagens por meio de conversas.",
  "fal-ai/qwen-image-edit.description": "Um modelo profissional de edição de imagens da equipe Qwen que permite edições semânticas e visuais, edita com precisão textos em chinês e inglês, e possibilita edições de alta qualidade como transferência de estilo e rotação de objetos.",
  "fal-ai/qwen-image.description": "Um poderoso modelo de geração de imagens da equipe Qwen, com renderização impressionante de texto em chinês e estilos visuais diversos.",
  "flux-1-schnell.description": "Modelo de texto para imagem com 12 bilhões de parâmetros da Black Forest Labs, usando difusão adversarial latente para gerar imagens de alta qualidade em 1 a 4 etapas. Rivaliza com alternativas fechadas e é lançado sob licença Apache-2.0 para uso pessoal, acadêmico e comercial.",
  "flux-dev.description": "FLUX.1 [dev] é um modelo destilado de código aberto para uso não comercial. Mantém qualidade de imagem próxima à profissional e seguimento de instruções, com execução mais eficiente e melhor uso de recursos do que modelos padrão do mesmo tamanho.",
  "flux-kontext-max.description": "Geração e edição de imagens contextuais de última geração, combinando texto e imagens para resultados precisos e coerentes.",
  "flux-kontext-pro.description": "Geração e edição de imagens contextuais de última geração, combinando texto e imagens para resultados precisos e coerentes.",
  "flux-merged.description": "FLUX.1-merged combina os recursos profundos explorados no \"DEV\" com as vantagens de alta velocidade do \"Schnell\", ampliando os limites de desempenho e expandindo as aplicações.",
  "flux-pro-1.1-ultra.description": "Geração de imagens em ultra-alta resolução com saída de 4MP, produzindo imagens nítidas em 10 segundos.",
  "flux-pro-1.1.description": "Modelo profissional de geração de imagens atualizado, com excelente qualidade e aderência precisa aos comandos.",
  "flux-pro.description": "Modelo comercial de geração de imagens de alto nível, com qualidade incomparável e saídas diversas.",
  "flux-schnell.description": "FLUX.1 [schnell] é o modelo de código aberto mais avançado com poucas etapas, superando concorrentes similares e até modelos não destilados como Midjourney v6.0 e DALL-E 3 (HD). É ajustado para preservar a diversidade do pré-treinamento, melhorando significativamente a qualidade visual, seguimento de instruções, variação de tamanho/aspecto, manipulação de fontes e diversidade de saída.",
  "flux.1-schnell.description": "FLUX.1-schnell é um modelo de geração de imagens de alto desempenho para saídas rápidas e com múltiplos estilos.",
  "gemini-1.0-pro-001.description": "Gemini 1.0 Pro 001 (Tuning) oferece desempenho estável e ajustável para tarefas complexas.",
  "gemini-1.0-pro-002.description": "Gemini 1.0 Pro 002 (Tuning) oferece suporte multimodal robusto para tarefas complexas.",
  "gemini-1.0-pro-latest.description": "Gemini 1.0 Pro é o modelo de IA de alto desempenho do Google, projetado para escalabilidade em tarefas amplas.",
  "gemini-1.5-flash-001.description": "Gemini 1.5 Flash 001 é um modelo multimodal eficiente para escalabilidade em aplicações amplas.",
  "gemini-1.5-flash-002.description": "Gemini 1.5 Flash 002 é um modelo multimodal eficiente, projetado para implantação em larga escala.",
  "gemini-1.5-flash-8b-exp-0924.description": "Gemini 1.5 Flash 8B 0924 é o modelo experimental mais recente, com avanços notáveis em casos de uso de texto e multimodais.",
  "gemini-1.5-flash-8b-latest.description": "Gemini 1.5 Flash 8B é um modelo multimodal eficiente, projetado para implantação em larga escala.",
  "gemini-1.5-flash-8b.description": "Gemini 1.5 Flash 8B é um modelo multimodal eficiente para escalabilidade em aplicações amplas.",
  "gemini-1.5-flash-exp-0827.description": "Gemini 1.5 Flash 0827 oferece processamento multimodal otimizado para tarefas complexas.",
  "gemini-1.5-flash-latest.description": "Gemini 1.5 Flash é o modelo multimodal mais recente do Google, com processamento rápido e suporte a entradas de texto, imagem e vídeo para escalabilidade eficiente em tarefas.",
  "gemini-1.5-pro-001.description": "Gemini 1.5 Pro 001 é uma solução de IA multimodal escalável para tarefas complexas.",
  "gemini-1.5-pro-002.description": "Gemini 1.5 Pro 002 é o modelo mais recente pronto para produção, com saída de maior qualidade, especialmente em matemática, contexto longo e tarefas visuais.",
  "gemini-1.5-pro-exp-0801.description": "Gemini 1.5 Pro 0801 oferece processamento multimodal robusto com maior flexibilidade para desenvolvimento de aplicativos.",
  "gemini-1.5-pro-exp-0827.description": "Gemini 1.5 Pro 0827 aplica as otimizações mais recentes para processamento multimodal mais eficiente.",
  "gemini-1.5-pro-latest.description": "Gemini 1.5 Pro suporta até 2 milhões de tokens, sendo um modelo multimodal de porte médio ideal para tarefas complexas.",
  "gemini-2.0-flash-001.description": "Gemini 2.0 Flash oferece recursos de próxima geração, incluindo velocidade excepcional, uso nativo de ferramentas, geração multimodal e janela de contexto de 1 milhão de tokens.",
  "gemini-2.0-flash-exp-image-generation.description": "Modelo experimental Gemini 2.0 Flash com suporte à geração de imagens.",
  "gemini-2.0-flash-lite-001.description": "Uma variante do Gemini 2.0 Flash otimizada para eficiência de custo e baixa latência.",
  "gemini-2.0-flash-lite.description": "Uma variante do Gemini 2.0 Flash otimizada para eficiência de custo e baixa latência.",
  "gemini-2.0-flash.description": "Gemini 2.0 Flash oferece recursos de próxima geração, incluindo velocidade excepcional, uso nativo de ferramentas, geração multimodal e janela de contexto de 1 milhão de tokens.",
  "gemini-2.5-flash-image.description": "Nano Banana é o modelo multimodal nativo mais novo, rápido e eficiente do Google, permitindo geração e edição de imagens por meio de conversas.",
  "gemini-2.5-flash-image:image.description": "Nano Banana é o modelo multimodal nativo mais novo, rápido e eficiente do Google, permitindo geração e edição de imagens por meio de conversas.",
  "gemini-2.5-flash-lite-preview-06-17.description": "Gemini 2.5 Flash-Lite Preview é o menor e mais econômico modelo do Google, projetado para uso em larga escala.",
  "gemini-2.5-flash-lite-preview-09-2025.description": "Versão de prévia (25 de setembro de 2025) do Gemini 2.5 Flash-Lite",
  "gemini-2.5-flash-lite.description": "Gemini 2.5 Flash-Lite é o menor e mais econômico modelo do Google, projetado para uso em larga escala.",
  "gemini-2.5-flash-preview-04-17.description": "Gemini 2.5 Flash Preview é o modelo com melhor custo-benefício do Google, com capacidades completas.",
  "gemini-2.5-flash-preview-09-2025.description": "Versão de prévia (25 de setembro de 2025) do Gemini 2.5 Flash",
  "gemini-2.5-flash.description": "Gemini 2.5 Flash é o modelo com melhor custo-benefício do Google, com capacidades completas.",
  "gemini-2.5-pro-preview-03-25.description": "Gemini 2.5 Pro Preview é o modelo de raciocínio mais avançado do Google, capaz de raciocinar sobre código, matemática e problemas STEM, além de analisar grandes conjuntos de dados, bases de código e documentos com contexto longo.",
  "gemini-2.5-pro-preview-05-06.description": "Gemini 2.5 Pro Preview é o modelo de raciocínio mais avançado do Google, capaz de raciocinar sobre código, matemática e problemas STEM, além de analisar grandes conjuntos de dados, bases de código e documentos com contexto longo.",
  "gemini-2.5-pro-preview-06-05.description": "Gemini 2.5 Pro Preview é o modelo de raciocínio mais avançado do Google, capaz de raciocinar sobre código, matemática e problemas STEM, além de analisar grandes conjuntos de dados, bases de código e documentos com contexto longo.",
  "gemini-2.5-pro.description": "Gemini 2.5 Pro é o modelo de raciocínio mais avançado do Google, capaz de raciocinar sobre código, matemática e problemas STEM, além de analisar grandes conjuntos de dados, bases de código e documentos com contexto longo.",
  "gemini-3-flash-preview.description": "Gemini 3 Flash é o modelo mais inteligente desenvolvido para velocidade, combinando inteligência de ponta com excelente fundamentação em buscas.",
  "gemini-3-pro-image-preview.description": "Gemini 3 Pro Image (Nano Banana Pro) é o modelo de geração de imagens do Google, com suporte a conversas multimodais.",
  "gemini-3-pro-image-preview:image.description": "Gemini 3 Pro Image (Nano Banana Pro) é o modelo de geração de imagens do Google e também oferece suporte a chat multimodal.",
  "gemini-3-pro-preview.description": "Gemini 3 Pro é o agente mais poderoso do Google, com capacidades de codificação emocional e visuais aprimoradas, além de raciocínio de última geração.",
  "gemini-flash-latest.description": "Última versão do Gemini Flash",
  "gemini-flash-lite-latest.description": "Última versão do Gemini Flash-Lite",
  "gemini-pro-latest.description": "Última versão do Gemini Pro",
  "gemma-7b-it.description": "Gemma 7B é uma opção econômica para tarefas de pequena a média escala.",
  "gemma2-9b-it.description": "Gemma 2 9B é otimizado para tarefas específicas e integração com ferramentas.",
  "gemma2.description": "Gemma 2 é o modelo eficiente do Google, cobrindo desde aplicativos simples até processamento de dados complexos.",
  "gemma2:27b.description": "Gemma 2 é o modelo eficiente do Google, cobrindo desde aplicativos simples até processamento de dados complexos.",
  "gemma2:2b.description": "Gemma 2 é o modelo eficiente do Google, cobrindo desde aplicativos simples até processamento de dados complexos.",
  "generalv3.5.description": "Spark Max é a versão mais completa, com suporte a busca na web e diversos plugins integrados. Suas capacidades otimizadas, papéis de sistema e chamadas de função oferecem desempenho excelente em cenários de aplicação complexos.",
  "generalv3.description": "Spark Pro é um LLM de alto desempenho otimizado para domínios profissionais, com foco em matemática, programação, saúde e educação. Inclui busca na web e plugins integrados como clima e data. Oferece desempenho forte e eficiente em perguntas e respostas complexas, compreensão de linguagem e criação avançada de texto, sendo ideal para usos profissionais.",
  "glm-4-0520.description": "GLM-4-0520 é a versão mais recente do modelo, projetado para tarefas altamente complexas e diversas, com desempenho excelente.",
  "glm-4-7.description": "GLM-4.7 é o modelo carro-chefe mais recente da Zhipu AI. O GLM-4.7 aprimora as capacidades de programação, planejamento de tarefas de longo prazo e colaboração com ferramentas para cenários de Programação Agente, alcançando desempenho líder entre modelos de código aberto em diversos benchmarks públicos. As capacidades gerais foram aprimoradas, com respostas mais concisas e naturais, e escrita mais envolvente. Em tarefas complexas de agentes, o seguimento de instruções durante chamadas de ferramentas é mais forte, e a estética do front-end de Artifacts e Programação Agente, bem como a eficiência na conclusão de tarefas de longo prazo, foram ainda mais aprimoradas. • Capacidades de programação mais fortes: Melhorias significativas em codificação multilíngue e desempenho de agentes em terminal; o GLM-4.7 agora implementa mecanismos de \"pensar antes de agir\" em frameworks como Claude Code, Kilo Code, TRAE, Cline e Roo Code, com desempenho mais estável em tarefas complexas. • Melhoria na estética do front-end: O GLM-4.7 apresenta avanços significativos na qualidade de geração de front-end, sendo capaz de criar sites, apresentações e cartazes com melhor apelo visual. • Capacidades aprimoradas de chamada de ferramentas: O GLM-4.7 melhora a habilidade de chamar ferramentas, com pontuação de 67 na avaliação BrowseComp e 84,7 na avaliação τ²-Bench de chamadas interativas, superando o Claude Sonnet 4.5 como o novo SOTA de código aberto. • Melhoria no raciocínio: Habilidades matemáticas e de raciocínio significativamente aprimoradas, com pontuação de 42,8% no benchmark HLE (\"Última Prova da Humanidade\"), uma melhoria de 41% em relação ao GLM-4.6, superando o GPT-5.1. • Aprimoramento geral: As conversas com o GLM-4.7 são mais concisas, inteligentes e humanas; a escrita e a simulação de papéis são mais literárias e imersivas.",
  "glm-4-9b-chat.description": "GLM-4-9B-Chat tem desempenho forte em semântica, matemática, raciocínio, código e conhecimento. Também oferece navegação na web, execução de código, chamadas de ferramentas personalizadas e raciocínio com textos longos, com suporte a 26 idiomas, incluindo japonês, coreano e alemão.",
  "glm-4-air-250414.description": "GLM-4-Air é uma opção de alto valor com desempenho próximo ao GLM-4, velocidade rápida e menor custo.",
  "glm-4-air.description": "GLM-4-Air é uma opção de alto valor com desempenho próximo ao GLM-4, velocidade rápida e menor custo.",
  "glm-4-airx.description": "GLM-4-AirX é uma variante mais eficiente do GLM-4-Air, com raciocínio até 2,6x mais rápido.",
  "glm-4-alltools.description": "GLM-4-AllTools é um modelo de agente versátil otimizado para planejamento de instruções complexas e uso de ferramentas como navegação na web, explicação de código e geração de texto, adequado para execução multitarefa.",
  "glm-4-flash-250414.description": "GLM-4-Flash é ideal para tarefas simples: o mais rápido e gratuito.",
  "glm-4-flash.description": "GLM-4-Flash é ideal para tarefas simples: o mais rápido e gratuito.",
  "glm-4-flashx.description": "GLM-4-FlashX é uma versão aprimorada do Flash com raciocínio ultrarrápido.",
  "glm-4-long.description": "GLM-4-Long oferece suporte a entradas ultralongas para tarefas de memória e processamento de documentos em larga escala.",
  "glm-4-plus.description": "GLM-4-Plus é um modelo carro-chefe de alta inteligência com forte capacidade para textos longos e tarefas complexas, além de desempenho geral aprimorado.",
  "glm-4.1v-thinking-flash.description": "GLM-4.1V-Thinking é o modelo VLM de ~10B mais forte conhecido, cobrindo tarefas SOTA como compreensão de vídeo, perguntas visuais, resolução de problemas, OCR, leitura de documentos e gráficos, agentes de interface gráfica, codificação frontend e grounding. Supera até o Qwen2.5-VL-72B, 8x maior, em muitas tarefas. Com RL avançado, usa raciocínio em cadeia para melhorar precisão e riqueza, superando modelos tradicionais sem raciocínio em resultados e explicabilidade.",
  "glm-4.1v-thinking-flashx.description": "GLM-4.1V-Thinking é o modelo VLM de ~10B mais forte conhecido, cobrindo tarefas SOTA como compreensão de vídeo, perguntas visuais, resolução de problemas, OCR, leitura de documentos e gráficos, agentes de interface gráfica, codificação frontend e grounding. Supera até o Qwen2.5-VL-72B, 8x maior, em muitas tarefas. Com RL avançado, usa raciocínio em cadeia para melhorar precisão e riqueza, superando modelos tradicionais sem raciocínio em resultados e explicabilidade.",
  "glm-4.5-air.description": "Edição leve do GLM-4.5 que equilibra desempenho e custo, com modos de raciocínio híbrido flexíveis.",
  "glm-4.5-airx.description": "Edição rápida do GLM-4.5-Air com respostas mais ágeis para uso em larga escala e alta velocidade.",
  "glm-4.5-x.description": "Edição rápida do GLM-4.5, com desempenho robusto e velocidade de geração de até 100 tokens/segundo.",
  "glm-4.5.description": "Modelo principal da Zhipu com modo de raciocínio alternável, oferecendo SOTA de código aberto e suporte a contexto de até 128K tokens.",
  "glm-4.5v.description": "Modelo de raciocínio visual de próxima geração da Zhipu com arquitetura MoE, totalizando 106B parâmetros (12B ativos), atingindo SOTA entre modelos multimodais de código aberto de tamanho semelhante em tarefas de imagem, vídeo, documentos e interfaces gráficas.",
  "glm-4.6.description": "GLM-4.6 (355B), o mais recente modelo carro-chefe da Zhipu, supera totalmente seus antecessores em codificação avançada, processamento de textos longos, raciocínio e capacidades de agente. Destaca-se especialmente em programação, alinhando-se ao Claude Sonnet 4, tornando-se o principal modelo de codificação da China.",
  "glm-4.7-flash.description": "GLM-4.7-Flash, como um modelo SOTA de 30B, oferece uma nova opção que equilibra desempenho e eficiência. Aprimora as capacidades de programação, planejamento de tarefas de longo prazo e colaboração com ferramentas para cenários de Programação Agente, alcançando desempenho líder entre modelos de código aberto do mesmo porte em diversos benchmarks atuais. Na execução de tarefas complexas de agentes inteligentes, apresenta maior conformidade com instruções durante chamadas de ferramentas, além de melhorar ainda mais a estética do front-end e a eficiência na conclusão de tarefas de longo prazo para Artifacts e Programação Agente.",
  "glm-4.7-flashx.description": "GLM-4.7-Flash, como um modelo SOTA de 30B, oferece uma nova opção que equilibra desempenho e eficiência. Aprimora as capacidades de programação, planejamento de tarefas de longo prazo e colaboração com ferramentas para cenários de Programação Agente, alcançando desempenho líder entre modelos de código aberto do mesmo porte em diversos benchmarks atuais. Na execução de tarefas complexas de agentes inteligentes, apresenta maior conformidade com instruções durante chamadas de ferramentas, além de melhorar ainda mais a estética do front-end e a eficiência na conclusão de tarefas de longo prazo para Artifacts e Programação Agente.",
  "glm-4.7.description": "GLM-4.7 é o mais recente modelo carro-chefe da Zhipu, aprimorado para cenários de Codificação Agente com melhorias em capacidades de programação, planejamento de tarefas de longo prazo e colaboração com ferramentas. Alcança desempenho líder entre modelos open-source em diversos benchmarks públicos. Suas capacidades gerais foram aprimoradas com respostas mais concisas e naturais e escrita mais envolvente. Para tarefas complexas de agente, o seguimento de instruções durante chamadas de ferramentas é mais forte, e a estética da interface e a eficiência na conclusão de tarefas de longo prazo em Artifacts e Codificação Agente foram ainda mais otimizadas.",
  "glm-4.description": "GLM-4 é o modelo principal anterior lançado em janeiro de 2024, agora substituído pelo mais forte GLM-4-0520.",
  "glm-4v-flash.description": "GLM-4V-Flash é focado em compreensão eficiente de imagens únicas para cenários de análise rápida, como processamento de imagens em tempo real ou em lote.",
  "glm-4v-plus-0111.description": "GLM-4V-Plus compreende vídeos e múltiplas imagens, adequado para tarefas multimodais.",
  "glm-4v-plus.description": "GLM-4V-Plus compreende vídeos e múltiplas imagens, adequado para tarefas multimodais.",
  "glm-4v.description": "GLM-4V oferece forte compreensão e raciocínio visual em diversas tarefas visuais.",
  "glm-z1-air.description": "Modelo de raciocínio com forte capacidade de inferência para tarefas que exigem dedução profunda.",
  "glm-z1-airx.description": "Raciocínio ultrarrápido com alta qualidade de inferência.",
  "glm-z1-flash.description": "A série GLM-Z1 oferece raciocínio complexo robusto, com destaque em lógica, matemática e programação.",
  "glm-z1-flashx.description": "Rápido e de baixo custo: versão Flash com raciocínio ultrarrápido e maior concorrência.",
  "glm-zero-preview.description": "GLM-Zero-Preview oferece raciocínio complexo robusto, com destaque em lógica, matemática e programação.",
  "global.anthropic.claude-opus-4-5-20251101-v1:0.description": "Claude Opus 4.5 é o modelo principal da Anthropic, combinando inteligência excepcional e desempenho escalável para tarefas complexas que exigem respostas e raciocínio da mais alta qualidade.",
  "google/gemini-2.0-flash-001.description": "Gemini 2.0 Flash oferece capacidades de nova geração, incluindo excelente velocidade, uso nativo de ferramentas, geração multimodal e janela de contexto de 1 milhão de tokens.",
  "google/gemini-2.0-flash-lite-001.description": "Gemini 2.0 Flash Lite é uma variante leve do Gemini com raciocínio desativado por padrão para melhorar latência e custo, podendo ser ativado via parâmetros.",
  "google/gemini-2.0-flash-lite.description": "Gemini 2.0 Flash Lite oferece recursos de nova geração, incluindo velocidade excepcional, uso integrado de ferramentas, geração multimodal e janela de contexto de 1 milhão de tokens.",
  "google/gemini-2.0-flash.description": "Gemini 2.0 Flash é o modelo de raciocínio de alto desempenho do Google para tarefas multimodais estendidas.",
  "google/gemini-2.5-flash-image-free.description": "Camada gratuita do Gemini 2.5 Flash Image com geração multimodal limitada por cota.",
  "google/gemini-2.5-flash-image-preview.description": "Modelo experimental Gemini 2.5 Flash com suporte à geração de imagens.",
  "google/gemini-2.5-flash-image.description": "Gemini 2.5 Flash Image (Nano Banana) é o modelo de geração de imagens do Google com suporte a conversas multimodais.",
  "google/gemini-2.5-flash-lite.description": "Gemini 2.5 Flash Lite é a variante leve do Gemini 2.5, otimizada para latência e custo, ideal para cenários de alto volume.",
  "google/gemini-2.5-flash-preview.description": "Gemini 2.5 Flash é o modelo principal mais avançado do Google, projetado para raciocínio avançado, programação, matemática e ciências. Inclui raciocínio embutido para respostas mais precisas e processamento de contexto refinado.\n\nNota: Este modelo possui duas variantes — com e sem raciocínio. O preço de saída varia significativamente dependendo da ativação do raciocínio.\n\nPara usar o raciocínio e receber tokens de raciocínio, selecione a variante “:thinking”, que possui custo adicional.\n\nO Gemini 2.5 Flash também pode ser configurado via o parâmetro “max reasoning tokens” conforme documentado (https://openrouter.ai/docs/use-cases/reasoning-tokens#max-tokens-for-reasoning).",
  "google/gemini-2.5-flash-preview:thinking.description": "Gemini 2.5 Flash é o modelo principal mais avançado do Google, projetado para raciocínio avançado, programação, matemática e ciências. Inclui raciocínio embutido para respostas mais precisas e processamento de contexto refinado.\n\nNota: Este modelo possui duas variantes — com e sem raciocínio. O preço de saída varia significativamente dependendo da ativação do raciocínio.\n\nPara usar o raciocínio e receber tokens de raciocínio, selecione a variante “:thinking”, que possui custo adicional.\n\nO Gemini 2.5 Flash também pode ser configurado via o parâmetro “max reasoning tokens” conforme documentado (https://openrouter.ai/docs/use-cases/reasoning-tokens#max-tokens-for-reasoning).",
  "google/gemini-2.5-flash.description": "Gemini 2.5 Flash (Lite/Pro/Flash) é a família de modelos do Google que abrange desde baixa latência até raciocínio de alto desempenho.",
  "google/gemini-2.5-pro-free.description": "Camada gratuita do Gemini 2.5 Pro com geração multimodal de contexto longo limitada por cota, ideal para testes e fluxos leves.",
  "google/gemini-2.5-pro-preview.description": "Gemini 2.5 Pro Preview é o modelo de raciocínio mais avançado do Google para resolver problemas complexos em código, matemática e STEM, além de analisar grandes conjuntos de dados, bases de código e documentos com contexto longo.",
  "google/gemini-2.5-pro.description": "Gemini 2.5 Pro é o modelo principal de raciocínio do Google com suporte a contexto longo para tarefas complexas.",
  "google/gemini-3-pro-image-preview-free.description": "Camada gratuita do Gemini 3 Pro Image com geração multimodal limitada por cota.",
  "google/gemini-3-pro-image-preview.description": "Gemini 3 Pro Image (Nano Banana Pro) é o modelo de geração de imagens do Google com suporte a conversas multimodais.",
  "google/gemini-3-pro-preview-free.description": "Gemini 3 Pro Preview Free oferece a mesma compreensão e raciocínio multimodal da versão padrão, mas com limites de cota e taxa, ideal para testes e uso de baixa frequência.",
  "google/gemini-3-pro-preview.description": "Gemini 3 Pro é o modelo de raciocínio multimodal de próxima geração da família Gemini, com compreensão de texto, áudio, imagens e vídeo, capaz de lidar com tarefas complexas e grandes bases de código.",
  "google/gemini-embedding-001.description": "Modelo de embedding de última geração com desempenho robusto em tarefas em inglês, multilíngues e de código.",
  "google/gemini-flash-1.5.description": "Gemini 1.5 Flash oferece processamento multimodal otimizado para uma variedade de tarefas complexas.",
  "google/gemini-pro-1.5.description": "Gemini 1.5 Pro combina as mais recentes otimizações para um processamento mais eficiente de dados multimodais.",
  "google/gemma-2-27b-it.description": "Gemma 2 27B é um modelo de linguagem de uso geral com desempenho sólido em diversos cenários.",
  "google/gemma-2-27b.description": "Gemma 2 é a família de modelos eficientes da Google para casos de uso que vão de aplicativos simples a processamento de dados complexos.",
  "google/gemma-2-2b-it.description": "Um modelo de linguagem pequeno e avançado projetado para aplicações em dispositivos de borda.",
  "google/gemma-2-9b-it.description": "Gemma 2 9B, desenvolvido pela Google, oferece seguimento de instruções eficiente e capacidade geral sólida.",
  "google/gemma-2-9b-it:free.description": "Gemma 2 é a família de modelos de texto open-source e leves da Google.",
  "google/gemma-2-9b.description": "Gemma 2 é a família de modelos eficientes da Google para casos de uso que vão de aplicativos simples a processamento de dados complexos.",
  "google/gemma-2b-it.description": "Gemma Instruct (2B) oferece manipulação básica de instruções para aplicações leves.",
  "google/gemma-3-12b-it.description": "Gemma 3 12B é um modelo de linguagem open-source da Google que estabelece um novo padrão de eficiência e desempenho.",
  "google/gemma-3-27b-it.description": "Gemma 3 27B é um modelo de linguagem open-source da Google que estabelece um novo padrão de eficiência e desempenho.",
  "google/text-embedding-005.description": "Modelo de embedding de texto focado em inglês, otimizado para tarefas de código e linguagem inglesa.",
  "google/text-multilingual-embedding-002.description": "Modelo de embedding de texto multilíngue otimizado para tarefas interlinguísticas em diversos idiomas.",
  "gpt-3.5-turbo-0125.description": "GPT 3.5 Turbo para geração e compreensão de texto; atualmente aponta para gpt-3.5-turbo-0125.",
  "gpt-3.5-turbo-1106.description": "GPT 3.5 Turbo para geração e compreensão de texto; atualmente aponta para gpt-3.5-turbo-0125.",
  "gpt-3.5-turbo-instruct.description": "GPT 3.5 Turbo para tarefas de geração e compreensão de texto, otimizado para seguir instruções.",
  "gpt-3.5-turbo.description": "GPT 3.5 Turbo para geração e compreensão de texto; atualmente aponta para gpt-3.5-turbo-0125.",
  "gpt-35-turbo-16k.description": "GPT-3.5 Turbo 16k é um modelo de geração de texto de alta capacidade para tarefas complexas.",
  "gpt-35-turbo.description": "GPT-3.5 Turbo é o modelo eficiente da OpenAI para chat e geração de texto, com suporte a chamadas de função em paralelo.",
  "gpt-4-0125-preview.description": "O mais recente GPT-4 Turbo adiciona visão. Solicitações visuais suportam modo JSON e chamadas de função. É um modelo multimodal econômico que equilibra precisão e eficiência para aplicações em tempo real.",
  "gpt-4-0613.description": "GPT-4 oferece uma janela de contexto maior para lidar com entradas mais longas, adequado para síntese ampla de informações e análise de dados.",
  "gpt-4-1106-preview.description": "O mais recente GPT-4 Turbo adiciona visão. Solicitações visuais suportam modo JSON e chamadas de função. É um modelo multimodal econômico que equilibra precisão e eficiência para aplicações em tempo real.",
  "gpt-4-32k-0613.description": "GPT-4 oferece uma janela de contexto maior para lidar com entradas mais longas em cenários que exigem integração ampla de informações e análise de dados.",
  "gpt-4-32k.description": "GPT-4 oferece uma janela de contexto maior para lidar com entradas mais longas em cenários que exigem integração ampla de informações e análise de dados.",
  "gpt-4-turbo-2024-04-09.description": "O mais recente GPT-4 Turbo adiciona visão. Solicitações visuais suportam modo JSON e chamadas de função. É um modelo multimodal econômico que equilibra precisão e eficiência para aplicações em tempo real.",
  "gpt-4-turbo-preview.description": "O mais recente GPT-4 Turbo adiciona visão. Solicitações visuais suportam modo JSON e chamadas de função. É um modelo multimodal econômico que equilibra precisão e eficiência para aplicações em tempo real.",
  "gpt-4-turbo.description": "O mais recente GPT-4 Turbo adiciona visão. Solicitações visuais suportam modo JSON e chamadas de função. É um modelo multimodal econômico que equilibra precisão e eficiência para aplicações em tempo real.",
  "gpt-4-vision-preview.description": "Prévia do GPT-4 Vision, projetado para tarefas de análise e processamento de imagens.",
  "gpt-4.1-mini.description": "GPT-4.1 mini equilibra inteligência, velocidade e custo, sendo atraente para diversos casos de uso.",
  "gpt-4.1-nano.description": "GPT-4.1 nano é o modelo GPT-4.1 mais rápido e econômico.",
  "gpt-4.1.description": "GPT-4.1 é nosso modelo carro-chefe para tarefas complexas e resolução de problemas interdisciplinares.",
  "gpt-4.5-preview.description": "GPT-4.5-preview é o mais recente modelo de uso geral com profundo conhecimento de mundo e melhor compreensão de intenções, forte em tarefas criativas e planejamento de agentes. Seu corte de conhecimento é outubro de 2023.",
  "gpt-4.description": "GPT-4 oferece uma janela de contexto maior para lidar com entradas mais longas, adequado para síntese ampla de informações e análise de dados.",
  "gpt-4o-2024-05-13.description": "ChatGPT-4o é um modelo dinâmico atualizado em tempo real, combinando forte compreensão e geração para casos de uso em larga escala como suporte ao cliente, educação e suporte técnico.",
  "gpt-4o-2024-08-06.description": "ChatGPT-4o é um modelo dinâmico atualizado em tempo real. Ele combina forte compreensão e geração de linguagem para casos de uso em larga escala como suporte ao cliente, educação e assistência técnica.",
  "gpt-4o-2024-11-20.description": "ChatGPT-4o é um modelo dinâmico atualizado em tempo real, combinando forte compreensão e geração para casos de uso em larga escala como suporte ao cliente, educação e suporte técnico.",
  "gpt-4o-audio-preview.description": "Modelo de prévia de áudio do GPT-4o com entrada e saída de áudio.",
  "gpt-4o-mini-audio-preview.description": "Modelo de áudio mini do GPT-4o com entrada e saída de áudio.",
  "gpt-4o-mini-realtime-preview.description": "Variante em tempo real do GPT-4o-mini com entrada e saída de texto e áudio em tempo real.",
  "gpt-4o-mini-search-preview.description": "Prévia de busca do GPT-4o mini, treinado para entender e executar consultas de busca na web via API de Conclusões de Chat. A busca na web é cobrada por chamada de ferramenta além dos custos de tokens.",
  "gpt-4o-mini-transcribe.description": "GPT-4o Mini Transcribe é um modelo de transcrição de fala para texto que transcreve áudio com GPT-4o, melhorando a taxa de erro de palavras, identificação de idioma e precisão em relação ao modelo Whisper original.",
  "gpt-4o-mini-tts.description": "GPT-4o mini TTS é um modelo de texto para fala baseado no GPT-4o mini, que converte texto em fala natural com entrada máxima de 2000 tokens.",
  "gpt-4o-mini.description": "GPT-4o mini é o modelo mais recente da OpenAI após o GPT-4 Omni, com suporte a entrada de texto+imagem e saída de texto. É o modelo pequeno mais avançado da empresa, muito mais barato que os modelos de ponta recentes e mais de 60% mais barato que o GPT-3.5 Turbo, mantendo inteligência de alto nível (82% MMLU).",
  "gpt-4o-realtime-preview-2024-10-01.description": "Variante em tempo real do GPT-4o com entrada e saída de áudio e texto em tempo real.",
  "gpt-4o-realtime-preview-2025-06-03.description": "Variante em tempo real do GPT-4o com entrada e saída de áudio e texto em tempo real.",
  "gpt-4o-realtime-preview.description": "Variante em tempo real do GPT-4o com entrada e saída de áudio e texto em tempo real.",
  "gpt-4o-search-preview.description": "GPT-4o Search Preview é treinado para entender e executar buscas na web via a API Chat Completions. A busca na web é cobrada por chamada de ferramenta, além do custo por tokens.",
  "gpt-4o-transcribe.description": "GPT-4o Transcribe é um modelo de transcrição de fala para texto que utiliza o GPT-4o, melhorando a taxa de erro de palavras, identificação de idioma e precisão em relação ao modelo Whisper original.",
  "gpt-4o.description": "ChatGPT-4o é um modelo dinâmico atualizado em tempo real, combinando forte compreensão e geração para casos de uso em larga escala como suporte ao cliente, educação e suporte técnico.",
  "gpt-5-chat-latest.description": "O modelo GPT-5 usado no ChatGPT, combinando forte compreensão e geração para aplicações conversacionais.",
  "gpt-5-chat.description": "GPT-5 Chat é um modelo de prévia otimizado para cenários conversacionais. Suporta entrada de texto e imagem, gera apenas texto e é ideal para chatbots e aplicações de IA conversacional.",
  "gpt-5-codex.description": "GPT-5 Codex é uma variante do GPT-5 otimizada para tarefas de codificação em ambientes semelhantes ao Codex.",
  "gpt-5-mini.description": "Uma variante mais rápida e econômica do GPT-5 para tarefas bem definidas, oferecendo respostas mais ágeis sem comprometer a qualidade.",
  "gpt-5-nano.description": "A variante mais rápida e econômica do GPT-5, ideal para aplicações sensíveis à latência e ao custo.",
  "gpt-5-pro.description": "GPT-5 Pro utiliza mais recursos computacionais para pensar de forma mais profunda e fornecer respostas consistentemente melhores.",
  "gpt-5.1-chat-latest.description": "GPT-5.1 Chat: a variante do ChatGPT baseada no GPT-5.1, desenvolvida para cenários de conversa.",
  "gpt-5.1-codex-mini.description": "GPT-5.1 Codex Mini: uma variante menor e de menor custo do Codex, otimizada para tarefas de codificação com agentes.",
  "gpt-5.1-codex.description": "GPT-5.1 Codex: uma variante do GPT-5.1 otimizada para tarefas de codificação com agentes, voltada para fluxos de trabalho complexos de código/agente na API de Respostas.",
  "gpt-5.1.description": "GPT-5.1 — um modelo principal otimizado para tarefas de codificação e agentes, com esforço de raciocínio configurável e contexto estendido.",
  "gpt-5.2-chat-latest.description": "GPT-5.2 Chat é a variante do ChatGPT (chat-latest) com as melhorias mais recentes em conversação.",
  "gpt-5.2-pro.description": "GPT-5.2 Pro: uma variante mais inteligente e precisa do GPT-5.2 (somente API de Respostas), ideal para problemas difíceis e raciocínio prolongado em múltiplas interações.",
  "gpt-5.2.description": "GPT-5.2 é um modelo principal para fluxos de trabalho de codificação e agentes, com raciocínio mais forte e desempenho aprimorado em contextos longos.",
  "gpt-5.description": "O melhor modelo para tarefas de codificação e agentes em múltiplos domínios. O GPT-5 representa um salto em precisão, velocidade, raciocínio, consciência de contexto, pensamento estruturado e resolução de problemas.",
  "gpt-audio.description": "GPT Audio é um modelo geral de chat com suporte a entrada/saída de áudio, disponível na API Chat Completions.",
  "gpt-image-1-mini.description": "Uma variante de menor custo do GPT Image 1 com entrada nativa de texto e imagem e saída de imagem.",
  "gpt-image-1.5.description": "Uma versão aprimorada do GPT Image 1 com geração 4× mais rápida, edição mais precisa e renderização de texto melhorada.",
  "gpt-image-1.description": "Modelo nativo de geração de imagens multimodal do ChatGPT.",
  "gpt-oss-120b.description": "O acesso requer uma solicitação. GPT-OSS-120B é um modelo de linguagem de código aberto da OpenAI com forte capacidade de geração de texto.",
  "gpt-oss-20b.description": "O acesso requer uma solicitação. GPT-OSS-20B é um modelo de linguagem de médio porte de código aberto da OpenAI com geração de texto eficiente.",
  "gpt-oss:120b.description": "GPT-OSS 120B é o LLM de código aberto de grande porte da OpenAI, utilizando quantização MXFP4 e posicionado como modelo principal. Requer ambientes com múltiplas GPUs ou estações de trabalho de alto desempenho, oferecendo excelente desempenho em raciocínio complexo, geração de código e processamento multilíngue, com chamadas de função avançadas e integração de ferramentas.",
  "gpt-oss:20b.description": "GPT-OSS 20B é um LLM de código aberto da OpenAI com quantização MXFP4, adequado para GPUs de alto desempenho para consumidores ou Macs com Apple Silicon. Apresenta bom desempenho em geração de diálogos, codificação e tarefas de raciocínio, com suporte a chamadas de função e uso de ferramentas.",
  "gpt-realtime.description": "Um modelo geral em tempo real com suporte a entrada/saída de texto e áudio em tempo real, além de entrada de imagem.",
  "grok-2-image-1212.description": "Nosso mais recente modelo de geração de imagens cria imagens vívidas e realistas a partir de prompts, sendo excelente para marketing, redes sociais e entretenimento.",
  "grok-2-vision-1212.description": "Melhoria na precisão, no seguimento de instruções e na capacidade multilíngue.",
  "grok-3-mini.description": "Um modelo leve que pensa antes de responder. É rápido e inteligente para tarefas lógicas que não exigem conhecimento profundo de domínio, com acesso a rastros brutos de raciocínio.",
  "grok-3.description": "Modelo principal que se destaca em casos de uso corporativos como extração de dados, codificação e sumarização, com conhecimento profundo em finanças, saúde, direito e ciência.",
  "grok-4-0709.description": "Grok 4 da xAI com forte capacidade de raciocínio.",
  "grok-4-1-fast-non-reasoning.description": "Modelo multimodal de ponta otimizado para uso de ferramentas por agentes de alto desempenho.",
  "grok-4-1-fast-reasoning.description": "Modelo multimodal de ponta otimizado para uso de ferramentas por agentes de alto desempenho.",
  "grok-4-fast-non-reasoning.description": "Estamos entusiasmados em lançar o Grok 4 Fast, nosso mais recente avanço em modelos de raciocínio com ótimo custo-benefício.",
  "grok-4-fast-reasoning.description": "Estamos entusiasmados em lançar o Grok 4 Fast, nosso mais recente avanço em modelos de raciocínio com ótimo custo-benefício.",
  "grok-4.description": "Nosso modelo principal mais recente e poderoso, excelente em PLN, matemática e raciocínio — um modelo versátil ideal.",
  "grok-code-fast-1.description": "Estamos entusiasmados em lançar o grok-code-fast-1, um modelo de raciocínio rápido e econômico que se destaca em codificação com agentes.",
  "groq/compound-mini.description": "Compound-mini é um sistema de IA composto alimentado por modelos públicos disponíveis no GroqCloud, utilizando ferramentas de forma inteligente e seletiva para responder às perguntas dos usuários.",
  "groq/compound.description": "Compound é um sistema de IA composto alimentado por múltiplos modelos públicos disponíveis no GroqCloud, utilizando ferramentas de forma inteligente e seletiva para responder às perguntas dos usuários.",
  "gryphe/mythomax-l2-13b.description": "MythoMax L2 13B é um modelo de linguagem criativo e inteligente, fundido a partir de diversos modelos de ponta.",
  "hunyuan-a13b.description": "O primeiro modelo de raciocínio híbrido da Hunyuan, atualizado a partir do hunyuan-standard-256K (80B no total, 13B ativos). Opera por padrão em modo de pensamento lento e permite alternância entre rápido/lento via parâmetros ou prefixo /no_think. A capacidade geral foi aprimorada em relação à geração anterior, especialmente em matemática, ciências, compreensão de textos longos e tarefas de agentes.",
  "hunyuan-code.description": "Modelo mais recente de geração de código, treinado com 200B de código de alta qualidade e seis meses de SFT; contexto expandido para 8K. Classificado entre os melhores em benchmarks automatizados para cinco linguagens e em avaliações humanas em dez critérios.",
  "hunyuan-functioncall.description": "Modelo FunctionCall MoE mais recente, treinado com dados de chamadas de função de alta qualidade, com janela de contexto de 32K e resultados líderes em benchmarks em diversas dimensões.",
  "hunyuan-large-longcontext.description": "Excelente em tarefas com documentos longos, como resumo e perguntas e respostas, além de lidar com geração geral. Forte em análise e geração de textos longos e complexos.",
  "hunyuan-large-vision.description": "Modelo de linguagem e visão treinado a partir do Hunyuan Large para compreensão de imagem e texto. Suporta entrada de múltiplas imagens + texto em qualquer resolução e melhora a compreensão visual multilíngue.",
  "hunyuan-large.description": "O hunyuan-large possui ~389B de parâmetros totais e ~52B ativados, sendo o maior e mais poderoso modelo MoE aberto com arquitetura Transformer.",
  "hunyuan-lite-vision.description": "Modelo multimodal mais recente de 7B com janela de contexto de 32K, compatível com chat multimodal em chinês/inglês, reconhecimento de objetos, compreensão de tabelas em documentos e matemática multimodal, superando outros modelos de 7B em vários benchmarks.",
  "hunyuan-lite.description": "Atualizado para uma arquitetura MoE com janela de contexto de 256K, liderando muitos modelos abertos em benchmarks de NLP, código, matemática e indústria.",
  "hunyuan-pro.description": "Modelo MoE com trilhões de parâmetros e contexto longo de 32K, líder em benchmarks, excelente em instruções complexas e raciocínio, matemática avançada, chamadas de função e otimizado para tradução multilíngue, finanças, direito e medicina.",
  "hunyuan-role.description": "Modelo de interpretação de papéis mais recente, ajustado oficialmente com conjuntos de dados específicos, oferecendo desempenho base mais forte para cenários de roleplay.",
  "hunyuan-standard-256K.description": "Utiliza roteamento aprimorado para mitigar desequilíbrio de carga e colapso de especialistas. Alcança 99,9% em 'agulha no palheiro' com contexto longo. O MOE-256K expande ainda mais o comprimento e a qualidade do contexto.",
  "hunyuan-standard-vision.description": "Modelo multimodal mais recente com respostas multilíngues e equilíbrio entre habilidades em chinês e inglês.",
  "hunyuan-standard.description": "Utiliza roteamento aprimorado para mitigar desequilíbrio de carga e colapso de especialistas. Alcança 99,9% em 'agulha no palheiro' com contexto longo. O MOE-32K oferece ótimo custo-benefício ao lidar com entradas extensas.",
  "hunyuan-t1-20250321.description": "Desenvolve capacidades equilibradas em artes e STEM com forte captura de informações em textos longos. Suporta respostas com raciocínio para problemas de matemática, lógica, ciência e programação em diversos níveis de dificuldade.",
  "hunyuan-t1-20250403.description": "Melhora a geração de código em nível de projeto e a qualidade da escrita, fortalece a compreensão de tópicos em múltiplas interações e o seguimento de instruções ToB, aprimora a compreensão lexical e reduz problemas de mistura entre chinês simplificado/tradicional e chinês/inglês.",
  "hunyuan-t1-20250529.description": "Aprimora a escrita criativa e composição, fortalece a programação frontend, raciocínio matemático e lógico, e melhora o seguimento de instruções.",
  "hunyuan-t1-20250711.description": "Melhora significativamente matemática avançada, lógica e programação, aumenta a estabilidade das respostas e aprimora a capacidade com textos longos.",
  "hunyuan-t1-latest.description": "Melhora significativamente o modelo de pensamento lento em matemática avançada, raciocínio complexo, programação difícil, seguimento de instruções e qualidade da escrita criativa.",
  "hunyuan-t1-vision-20250619.description": "Modelo multimodal de raciocínio profundo t1-vision mais recente com cadeia de pensamento nativa longa, significativamente melhorado em relação à versão padrão anterior.",
  "hunyuan-t1-vision-20250916.description": "Modelo de raciocínio profundo t1-vision mais recente com grandes avanços em VQA, ancoragem visual, OCR, gráficos, resolução de problemas fotografados e criação baseada em imagem, além de melhor desempenho em inglês e idiomas de poucos recursos.",
  "hunyuan-turbo-20241223.description": "Esta versão amplia a escalabilidade de instruções para melhor generalização, melhora significativamente o raciocínio em matemática/código/lógica, aprimora a compreensão lexical e eleva a qualidade da escrita.",
  "hunyuan-turbo-latest.description": "Melhorias gerais na experiência em compreensão de NLP, escrita, chat, perguntas e respostas, tradução e domínios; respostas mais humanas, melhor esclarecimento de intenções ambíguas, análise lexical aprimorada, maior criatividade e interatividade, e conversas multi-turno mais robustas.",
  "hunyuan-turbo-vision.description": "Modelo de linguagem e visão de próxima geração com nova arquitetura MoE, com amplas melhorias em reconhecimento, criação de conteúdo, perguntas e respostas baseadas em conhecimento e raciocínio analítico.",
  "hunyuan-turbo.description": "Prévia do LLM de próxima geração da Hunyuan com nova arquitetura MoE, oferecendo raciocínio mais rápido e resultados superiores ao hunyuan-pro.",
  "hunyuan-turbos-20250313.description": "Unifica o estilo de resolução de problemas matemáticos e fortalece perguntas e respostas matemáticas em múltiplas interações. O estilo de escrita foi refinado para reduzir o tom artificial e adicionar sofisticação.",
  "hunyuan-turbos-20250416.description": "Base de pré-treinamento atualizada para melhorar a compreensão e seguimento de instruções; alinhamento aprimora matemática, código, lógica e ciência; melhora a qualidade da escrita, compreensão, precisão de tradução e perguntas e respostas baseadas em conhecimento; fortalece habilidades de agente, especialmente em múltiplas interações.",
  "hunyuan-turbos-20250604.description": "Base de pré-treinamento atualizada com melhorias na escrita e compreensão de leitura, avanços significativos em código e STEM, e melhor seguimento de instruções complexas.",
  "hunyuan-turbos-20250926.description": "Melhoria na qualidade dos dados de pré-treinamento e estratégia de pós-treinamento, aprimorando agentes, idiomas de poucos recursos/inglês, seguimento de instruções, código e capacidades STEM.",
  "hunyuan-turbos-latest.description": "O mais recente modelo principal Hunyuan TurboS com raciocínio mais forte e melhor experiência geral.",
  "hunyuan-turbos-longtext-128k-20250325.description": "Excelente em tarefas com documentos longos, como resumo e perguntas e respostas, além de lidar com geração geral. Forte em análise e geração de textos longos e complexos.",
  "hunyuan-turbos-role-plus.description": "Modelo de interpretação de papéis mais recente, ajustado oficialmente com conjuntos de dados específicos, oferecendo desempenho base mais forte para cenários de roleplay.",
  "hunyuan-turbos-vision-20250619.description": "Modelo principal TurboS de linguagem e visão mais recente com grandes avanços em tarefas imagem-texto como reconhecimento de entidades, perguntas e respostas baseadas em conhecimento, redação publicitária e resolução de problemas com fotos.",
  "hunyuan-turbos-vision.description": "Modelo principal de linguagem e visão de próxima geração baseado no mais recente TurboS, focado em tarefas de compreensão imagem-texto como reconhecimento de entidades, perguntas e respostas baseadas em conhecimento, redação publicitária e resolução de problemas com fotos.",
  "hunyuan-vision-1.5-instruct.description": "Modelo de pensamento rápido para geração de texto a partir de imagem baseado no TurboS textual. Em comparação com a versão anterior, apresenta melhorias significativas em reconhecimento básico de imagem e raciocínio analítico visual.",
  "hunyuan-vision.description": "Modelo multimodal mais recente com suporte a entrada de imagem + texto para geração de texto.",
  "image-01-live.description": "Modelo de geração de imagem com detalhes refinados, suportando geração de imagem a partir de texto e estilos controláveis.",
  "image-01.description": "Novo modelo de geração de imagem com detalhes refinados, suportando geração de imagem a partir de texto e de imagem para imagem.",
  "imagen-4.0-fast-generate-001.description": "Versão rápida da série de modelos de geração de imagem a partir de texto Imagen de quarta geração.",
  "imagen-4.0-generate-001.description": "Série de modelos de geração de imagem a partir de texto Imagen de quarta geração.",
  "imagen-4.0-generate-preview-06-06.description": "Família de modelos de geração de imagem a partir de texto da quarta geração Imagen.",
  "imagen-4.0-ultra-generate-001.description": "Versão Ultra da série de modelos de geração de imagem a partir de texto Imagen de quarta geração.",
  "imagen-4.0-ultra-generate-preview-06-06.description": "Variante Ultra da quarta geração de modelos de geração de imagem a partir de texto Imagen.",
  "inception/mercury-coder-small.description": "Mercury Coder Small é ideal para geração de código, depuração e refatoração com latência mínima.",
  "inclusionAI/Ling-flash-2.0.description": "Ling-flash-2.0 é o terceiro modelo da arquitetura Ling 2.0 da equipe Bailing do Ant Group. É um modelo MoE com 100 bilhões de parâmetros totais, mas apenas 6,1 bilhões ativos por token (4,8 bilhões sem embeddings). Apesar de sua configuração leve, iguala ou supera modelos densos de 40B e MoEs maiores em diversos benchmarks, explorando alta eficiência por meio de arquitetura e estratégia de treinamento.",
  "inclusionAI/Ling-mini-2.0.description": "Ling-mini-2.0 é um LLM MoE pequeno e de alto desempenho com 16 bilhões de parâmetros totais e apenas 1,4 bilhão ativo por token (789 milhões sem embeddings), oferecendo geração muito rápida. Com design MoE eficiente e grandes volumes de dados de treinamento de alta qualidade, atinge desempenho de ponta comparável a modelos densos abaixo de 10B e MoEs maiores.",
  "inclusionAI/Ring-flash-2.0.description": "Ring-flash-2.0 é um modelo de raciocínio de alto desempenho otimizado a partir do Ling-flash-2.0-base. Utiliza arquitetura MoE com 100 bilhões de parâmetros totais e apenas 6,1 bilhões ativos por inferência. Seu algoritmo icepop estabiliza o treinamento por RL em modelos MoE, permitindo avanços contínuos em raciocínio complexo. Alcança grandes conquistas em benchmarks difíceis (competições de matemática, geração de código, raciocínio lógico), superando modelos densos de até 40B e rivalizando com MoEs abertos maiores e modelos fechados de raciocínio. Também se destaca em escrita criativa, e sua arquitetura eficiente proporciona inferência rápida com menor custo de implantação para alta concorrência.",
  "inclusionai/ling-1t.description": "Ling-1T é o modelo MoE de 1 trilhão de parâmetros da inclusionAI, otimizado para tarefas de raciocínio intensivo e cargas de trabalho com contexto extenso.",
  "inclusionai/ling-flash-2.0.description": "Ling-flash-2.0 é o modelo MoE da inclusionAI otimizado para eficiência e desempenho em raciocínio, adequado para tarefas de médio a grande porte.",
  "inclusionai/ling-mini-2.0.description": "Ling-mini-2.0 é o modelo MoE leve da inclusionAI, que reduz significativamente os custos mantendo a capacidade de raciocínio.",
  "inclusionai/ming-flash-omini-preview.description": "Ming-flash-omni Preview é o modelo multimodal da inclusionAI, com suporte a entradas de voz, imagem e vídeo, além de melhorias na renderização de imagens e reconhecimento de fala.",
  "inclusionai/ring-1t.description": "Ring-1T é o modelo MoE de raciocínio com um trilhão de parâmetros da inclusionAI, adequado para tarefas de raciocínio em larga escala e pesquisa.",
  "inclusionai/ring-flash-2.0.description": "Ring-flash-2.0 é uma variante do modelo Ring da inclusionAI para cenários de alto rendimento, com foco em velocidade e eficiência de custo.",
  "inclusionai/ring-mini-2.0.description": "Ring-mini-2.0 é o modelo MoE leve e de alto rendimento da inclusionAI, projetado para alta concorrência.",
  "internlm/internlm2_5-7b-chat.description": "InternLM2.5-7B-Chat é um modelo de chat de código aberto baseado na arquitetura InternLM2. O modelo de 7B é focado em geração de diálogos com suporte a chinês e inglês, utilizando treinamento moderno para conversas fluentes e inteligentes. É adequado para diversos cenários de chat, como atendimento ao cliente e assistentes pessoais.",
  "internlm2.5-latest.description": "Modelos legados ainda mantidos com desempenho excelente e estável após várias iterações. Disponíveis nos tamanhos 7B e 20B, com suporte a contexto de 1 milhão e melhor seguimento de instruções e uso de ferramentas. Padrão para a série InternLM2.5 mais recente (atualmente internlm2.5-20b-chat).",
  "internlm3-latest.description": "Nossa série de modelos mais recente com excelente desempenho em raciocínio, liderando entre os modelos abertos de seu porte. Padrão para a série InternLM3 mais recente (atualmente internlm3-8b-instruct).",
  "internvl2.5-38b-mpo.description": "InternVL2.5 38B MPO é um modelo multimodal pré-treinado para raciocínio complexo entre imagem e texto.",
  "internvl2.5-latest.description": "InternVL2.5 continua sendo mantido com desempenho forte e estável. Padrão para a série InternVL2.5 mais recente (atualmente internvl2.5-78b).",
  "internvl3-14b.description": "InternVL3 14B é um modelo multimodal de porte médio que equilibra desempenho e custo.",
  "internvl3-1b.description": "InternVL3 1B é um modelo multimodal leve para implantação com recursos limitados.",
  "internvl3-38b.description": "InternVL3 38B é um modelo multimodal de código aberto de grande porte para compreensão precisa de imagem e texto.",
  "internvl3-latest.description": "Nosso modelo multimodal mais recente com compreensão aprimorada de imagem e texto e capacidade de lidar com sequências longas de imagens, comparável aos principais modelos fechados. Padrão para a série InternVL mais recente (atualmente internvl3-78b).",
  "irag-1.0.description": "ERNIE iRAG é um modelo de geração aumentada por recuperação de imagens para busca de imagens, recuperação imagem-texto e geração de conteúdo.",
  "jamba-large.description": "Nosso modelo mais poderoso e avançado, projetado para tarefas empresariais complexas com desempenho excepcional.",
  "jamba-mini.description": "O modelo mais eficiente de sua categoria, equilibrando velocidade e qualidade com baixo consumo de recursos.",
  "jina-deepsearch-v1.description": "DeepSearch combina busca na web, leitura e raciocínio para investigações aprofundadas. Pense nele como um agente que assume sua tarefa de pesquisa, realiza buscas amplas com múltiplas iterações e só então produz uma resposta. O processo envolve pesquisa contínua, raciocínio e resolução de problemas sob múltiplas perspectivas, diferindo fundamentalmente dos LLMs padrão que respondem com base em dados pré-treinados ou sistemas RAG tradicionais que dependem de buscas superficiais pontuais.",
  "kimi-k2-0711-preview.description": "kimi-k2 é um modelo base MoE com fortes capacidades de programação e agentes (1T de parâmetros totais, 32B ativos), superando outros modelos abertos populares em benchmarks de raciocínio, programação, matemática e agentes.",
  "kimi-k2-0905-preview.description": "kimi-k2-0905-preview oferece uma janela de contexto de 256k, codificação agente mais robusta, melhor qualidade de código front-end e compreensão de contexto aprimorada.",
  "kimi-k2-instruct.description": "Kimi K2 Instruct é o modelo oficial de raciocínio da Kimi com contexto longo para código, perguntas e respostas e mais.",
  "kimi-k2-thinking-turbo.description": "Variante de raciocínio longo de alta velocidade do K2 com contexto de 256k, raciocínio profundo robusto e saída de 60–100 tokens/segundo.",
  "kimi-k2-thinking.description": "kimi-k2-thinking é o modelo de raciocínio da Moonshot AI com habilidades gerais de agentes e raciocínio. Ele se destaca em raciocínio profundo e pode resolver problemas difíceis com uso de ferramentas em múltiplas etapas.",
  "kimi-k2-turbo-preview.description": "kimi-k2 é um modelo base MoE com fortes capacidades de programação e agentes (1T de parâmetros totais, 32B ativos), superando outros modelos abertos populares em benchmarks de raciocínio, programação, matemática e agentes.",
  "kimi-k2.5.description": "Kimi K2.5 é o modelo Kimi mais avançado, oferecendo SOTA open-source em tarefas de agentes, programação e compreensão visual. Suporta entradas multimodais e modos com ou sem raciocínio.",
  "kimi-k2.description": "Kimi-K2 é um modelo base MoE da Moonshot AI com fortes capacidades de programação e agentes, totalizando 1T de parâmetros com 32B ativos. Em benchmarks de raciocínio geral, programação, matemática e tarefas de agentes, supera outros modelos abertos populares.",
  "kimi-k2:1t.description": "Kimi K2 é um grande modelo MoE LLM da Moonshot AI com 1T de parâmetros totais e 32B ativos por passagem. É otimizado para capacidades de agentes, incluindo uso avançado de ferramentas, raciocínio e síntese de código.",
  "kimi-latest.description": "Kimi Latest usa o modelo Kimi mais recente e pode incluir recursos experimentais. Suporta compreensão de imagens e seleciona automaticamente modelos de cobrança 8k/32k/128k com base no comprimento do contexto.",
  "kuaishou/kat-coder-pro-v1.description": "KAT-Coder-Pro-V1 (gratuito por tempo limitado) foca em compreensão de código e automação para agentes de codificação eficientes.",
  "learnlm-1.5-pro-experimental.description": "LearnLM é um modelo experimental específico para tarefas, treinado com base em princípios da ciência da aprendizagem para seguir instruções do sistema em cenários de ensino/aprendizagem, atuando como um tutor especialista.",
  "learnlm-2.0-flash-experimental.description": "LearnLM é um modelo experimental específico para tarefas, treinado com base em princípios da ciência da aprendizagem para seguir instruções do sistema em cenários de ensino/aprendizagem, atuando como um tutor especialista.",
  "lite.description": "Spark Lite é um LLM leve com latência ultrabaixa e processamento eficiente. É totalmente gratuito e suporta busca em tempo real na web. Suas respostas rápidas funcionam bem em dispositivos com pouca capacidade de computação e para ajuste fino de modelos, oferecendo excelente custo-benefício e uma experiência inteligente, especialmente para perguntas e respostas de conhecimento, geração de conteúdo e cenários de busca.",
  "llama-3.1-70b-versatile.description": "Llama 3.1 70B oferece raciocínio de IA mais robusto para aplicações complexas, com suporte a computação intensiva com alta eficiência e precisão.",
  "llama-3.1-8b-instant.description": "Llama 3.1 8B é um modelo altamente eficiente com geração de texto rápida, ideal para aplicações em larga escala e com bom custo-benefício.",
  "llama-3.1-instruct.description": "O modelo Llama 3.1 ajustado por instruções é otimizado para chat e supera muitos modelos de chat abertos em benchmarks do setor.",
  "llama-3.2-11b-vision-instruct.description": "Raciocínio visual avançado em imagens de alta resolução, ideal para aplicativos de compreensão visual.",
  "llama-3.2-11b-vision-preview.description": "Llama 3.2 foi projetado para tarefas que combinam visão e texto, com excelência em legendagem de imagens e perguntas e respostas visuais, unindo geração de linguagem e raciocínio visual.",
  "llama-3.2-90b-vision-instruct.description": "Raciocínio visual avançado para aplicações de agentes com compreensão visual.",
  "llama-3.2-90b-vision-preview.description": "Llama 3.2 foi projetado para tarefas que combinam visão e texto, com excelência em legendagem de imagens e perguntas e respostas visuais, unindo geração de linguagem e raciocínio visual.",
  "llama-3.2-vision-instruct.description": "O modelo Llama 3.2-Vision ajustado por instruções é otimizado para reconhecimento visual, raciocínio com imagens, legendagem e perguntas e respostas visuais em geral.",
  "llama-3.3-70b-versatile.description": "Meta Llama 3.3 é um LLM multilíngue com 70B de parâmetros (entrada/saída de texto), oferecendo variantes pré-treinadas e ajustadas por instruções. A versão ajustada por instruções é otimizada para diálogos multilíngues e supera muitos modelos de chat abertos e fechados em benchmarks do setor.",
  "llama-3.3-70b.description": "Llama 3.3 70B: um modelo Llama de médio a grande porte que equilibra raciocínio e rendimento.",
  "llama-3.3-instruct.description": "O modelo Llama 3.3 ajustado por instruções é otimizado para chat e supera muitos modelos de chat abertos em benchmarks do setor.",
  "llama3-70b-8192.description": "Meta Llama 3 70B oferece excelente capacidade de lidar com tarefas complexas para projetos exigentes.",
  "llama3-8b-8192.description": "Meta Llama 3 8B oferece desempenho sólido de raciocínio para cenários diversos.",
  "llama3-groq-70b-8192-tool-use-preview.description": "Llama 3 Groq 70B Tool Use oferece chamadas de ferramentas robustas para lidar com tarefas complexas de forma eficiente.",
  "llama3-groq-8b-8192-tool-use-preview.description": "Llama 3 Groq 8B Tool Use é otimizado para uso eficiente de ferramentas com computação paralela rápida.",
  "llama3.1-8b.description": "Llama 3.1 8B: uma variante Llama pequena e de baixa latência para inferência online leve e chat.",
  "llama3.1.description": "Llama 3.1 é o modelo principal da Meta, com escalabilidade de até 405B de parâmetros para diálogos complexos, tradução multilíngue e análise de dados.",
  "llama3.1:405b.description": "Llama 3.1 é o modelo principal da Meta, com escalabilidade de até 405B de parâmetros para diálogos complexos, tradução multilíngue e análise de dados.",
  "llama3.1:70b.description": "Llama 3.1 é o modelo principal da Meta, com escalabilidade de até 405B de parâmetros para diálogos complexos, tradução multilíngue e análise de dados.",
  "llava-v1.5-7b-4096-preview.description": "LLaVA 1.5 7B combina processamento visual para gerar saídas complexas a partir de entradas visuais.",
  "llava.description": "LLaVA é um modelo multimodal que combina um codificador de visão e o Vicuna para compreensão robusta de linguagem e visão.",
  "llava:13b.description": "LLaVA é um modelo multimodal que combina um codificador de visão e o Vicuna para compreensão robusta de linguagem e visão.",
  "llava:34b.description": "LLaVA é um modelo multimodal que combina um codificador de visão e o Vicuna para compreensão robusta de linguagem e visão.",
  "magistral-medium-latest.description": "Magistral Medium 1.2 é um modelo de raciocínio de ponta da Mistral AI (setembro de 2025) com suporte a visão.",
  "magistral-small-2509.description": "Magistral Small 1.2 é um modelo de raciocínio pequeno e de código aberto da Mistral AI (setembro de 2025) com suporte a visão.",
  "mathstral.description": "MathΣtral foi desenvolvido para pesquisa científica e raciocínio matemático, com forte capacidade de cálculo e explicação.",
  "max-32k.description": "Spark Max 32K oferece processamento de contexto ampliado com melhor compreensão e raciocínio lógico, suportando entradas de até 32 mil tokens para leitura de documentos longos e perguntas sobre conhecimento privado.",
  "megrez-3b-instruct.description": "Megrez 3B Instruct é um modelo pequeno e eficiente da Wuwen Xinqiong.",
  "meituan/longcat-flash-chat.description": "Modelo base de código aberto da Meituan, sem raciocínio, otimizado para diálogos e tarefas de agentes, com forte uso de ferramentas e interações complexas de múltiplas etapas.",
  "meta-llama-3-70b-instruct.description": "Um poderoso modelo com 70 bilhões de parâmetros que se destaca em raciocínio, programação e tarefas linguísticas amplas.",
  "meta-llama-3-8b-instruct.description": "Um modelo versátil com 8 bilhões de parâmetros, otimizado para conversas e geração de texto.",
  "meta-llama-3.1-405b-instruct.description": "Modelo de texto ajustado por instruções Llama 3.1, otimizado para conversas multilíngues, com excelente desempenho em benchmarks do setor entre modelos abertos e fechados.",
  "meta-llama-3.1-70b-instruct.description": "Modelo de texto ajustado por instruções Llama 3.1, otimizado para conversas multilíngues, com excelente desempenho em benchmarks do setor entre modelos abertos e fechados.",
  "meta-llama-3.1-8b-instruct.description": "Modelo de texto ajustado por instruções Llama 3.1, otimizado para conversas multilíngues, com excelente desempenho em benchmarks do setor entre modelos abertos e fechados.",
  "meta-llama/Llama-2-13b-chat-hf.description": "LLaMA-2 Chat (13B) oferece forte capacidade linguística e uma experiência sólida de conversa.",
  "meta-llama/Llama-2-70b-hf.description": "LLaMA-2 oferece forte capacidade linguística e uma experiência sólida de interação.",
  "meta-llama/Llama-3-70b-chat-hf.description": "Llama 3 70B Instruct Reference é um modelo de conversa poderoso para diálogos complexos.",
  "meta-llama/Llama-3-8b-chat-hf.description": "Llama 3 8B Instruct Reference oferece suporte multilíngue e amplo conhecimento de domínio.",
  "meta-llama/Llama-3.2-11B-Vision-Instruct-Turbo.description": "LLaMA 3.2 foi projetado para tarefas que combinam visão e texto. Destaca-se em legendagem de imagens e perguntas visuais, unindo geração de linguagem e raciocínio visual.",
  "meta-llama/Llama-3.2-3B-Instruct-Turbo.description": "LLaMA 3.2 foi projetado para tarefas que combinam visão e texto. Destaca-se em legendagem de imagens e perguntas visuais, unindo geração de linguagem e raciocínio visual.",
  "meta-llama/Llama-3.2-90B-Vision-Instruct-Turbo.description": "LLaMA 3.2 foi projetado para tarefas que combinam visão e texto. Destaca-se em legendagem de imagens e perguntas visuais, unindo geração de linguagem e raciocínio visual.",
  "meta-llama/Llama-3.3-70B-Instruct-Turbo.description": "Meta Llama 3.3 é um LLM multilíngue com 70B (entrada/saída de texto), pré-treinado e ajustado por instruções. A versão ajustada por instruções é otimizada para conversas multilíngues e supera muitos modelos abertos e fechados em benchmarks do setor.",
  "meta-llama/Llama-Vision-Free.description": "LLaMA 3.2 foi projetado para tarefas que combinam visão e texto. Destaca-se em legendagem de imagens e perguntas visuais, unindo geração de linguagem e raciocínio visual.",
  "meta-llama/Meta-Llama-3-70B-Instruct-Lite.description": "Llama 3 70B Instruct Lite foi desenvolvido para alto desempenho com baixa latência.",
  "meta-llama/Meta-Llama-3-70B-Instruct-Turbo.description": "Llama 3 70B Instruct Turbo oferece forte compreensão e geração para cargas de trabalho exigentes.",
  "meta-llama/Meta-Llama-3-8B-Instruct-Lite.description": "Llama 3 8B Instruct Lite equilibra desempenho para ambientes com recursos limitados.",
  "meta-llama/Meta-Llama-3-8B-Instruct-Turbo.description": "Llama 3 8B Instruct Turbo é um LLM de alto desempenho para uma ampla gama de casos de uso.",
  "meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo.description": "O modelo Turbo Llama 3.1 405B oferece enorme capacidade de contexto para processamento de grandes volumes de dados e se destaca em aplicações de IA em escala ultra.",
  "meta-llama/Meta-Llama-3.1-405B-Instruct.description": "Llama 3.1 é a principal família de modelos da Meta, com até 405 bilhões de parâmetros para diálogos complexos, tradução multilíngue e análise de dados.",
  "meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo.description": "Llama 3.1 70B é ajustado para aplicações de alta carga; a quantização FP8 oferece computação eficiente e precisão em cenários complexos.",
  "meta-llama/Meta-Llama-3.1-70B.description": "Llama 3.1 é a principal família de modelos da Meta, com até 405 bilhões de parâmetros para diálogos complexos, tradução multilíngue e análise de dados.",
  "meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo.description": "Llama 3.1 8B usa quantização FP8, suporta até 131.072 tokens de contexto e está entre os melhores modelos abertos para tarefas complexas em diversos benchmarks.",
  "meta-llama/llama-3-70b-instruct.description": "Llama 3 70B Instruct é otimizado para diálogos de alta qualidade e tem forte desempenho em avaliações humanas.",
  "meta-llama/llama-3-8b-instruct.description": "Llama 3 8B Instruct é otimizado para diálogos de alta qualidade, superando muitos modelos fechados.",
  "meta-llama/llama-3.1-70b-instruct.description": "A mais recente série Llama 3.1 da Meta, a variante de 70B ajustada por instruções, otimizada para diálogos de alta qualidade. Em avaliações do setor, apresenta desempenho superior a modelos fechados líderes. (Disponível apenas para entidades verificadas corporativamente.)",
  "meta-llama/llama-3.1-8b-instruct.description": "A mais recente série Llama 3.1 da Meta, a variante de 8B ajustada por instruções, é especialmente rápida e eficiente. Em avaliações do setor, apresenta desempenho superior a muitos modelos fechados líderes. (Disponível apenas para entidades verificadas corporativamente.)",
  "meta-llama/llama-3.1-8b-instruct:free.description": "LLaMA 3.1 oferece suporte multilíngue e é um dos principais modelos generativos.",
  "meta-llama/llama-3.2-11b-vision-instruct.description": "LLaMA 3.2 foi projetado para tarefas que combinam visão e texto. Destaca-se em legendagem de imagens e perguntas visuais, unindo geração de linguagem e raciocínio visual.",
  "meta-llama/llama-3.2-3b-instruct.description": "meta-llama/llama-3.2-3b-instruct",
  "meta-llama/llama-3.2-90b-vision-instruct.description": "LLaMA 3.2 foi projetado para tarefas que combinam visão e texto. Destaca-se em legendagem de imagens e perguntas visuais, unindo geração de linguagem e raciocínio visual.",
  "meta-llama/llama-3.3-70b-instruct.description": "Llama 3.3 é o modelo Llama multilíngue de código aberto mais avançado, oferecendo desempenho próximo ao de 405B com custo muito baixo. Baseado em Transformer, aprimorado com SFT e RLHF para utilidade e segurança. A versão ajustada por instruções é otimizada para chat multilíngue e supera muitos modelos abertos e fechados em benchmarks do setor. Corte de conhecimento: dez/2023.",
  "meta-llama/llama-3.3-70b-instruct:free.description": "Llama 3.3 é o modelo Llama multilíngue de código aberto mais avançado, oferecendo desempenho próximo ao de 405B com custo muito baixo. Baseado em Transformer, aprimorado com SFT e RLHF para utilidade e segurança. A versão ajustada por instruções é otimizada para chat multilíngue e supera muitos modelos abertos e fechados em benchmarks do setor. Corte de conhecimento: dez/2023.",
  "meta.llama3-1-405b-instruct-v1:0.description": "Meta Llama 3.1 405B Instruct é o maior e mais poderoso modelo Llama 3.1 Instruct, altamente avançado para raciocínio em diálogos e geração de dados sintéticos, sendo uma base sólida para pré-treinamento ou ajuste fino em domínios específicos. Os LLMs multilíngues Llama 3.1 são modelos de geração pré-treinados e ajustados por instruções nos tamanhos 8B, 70B e 405B (entrada/saída de texto). Os modelos ajustados por instruções são otimizados para diálogos multilíngues e superam muitos modelos de chat abertos disponíveis em benchmarks da indústria. O Llama 3.1 é projetado para uso comercial e de pesquisa em vários idiomas. Os modelos ajustados por instruções são ideais para chat estilo assistente, enquanto os modelos pré-treinados são adequados para tarefas mais amplas de geração de linguagem natural. As saídas do Llama 3.1 também podem ser usadas para melhorar outros modelos, incluindo geração e refinamento de dados sintéticos. O Llama 3.1 é um modelo Transformer autoregressivo com arquitetura otimizada. As versões ajustadas utilizam ajuste supervisionado (SFT) e aprendizado por reforço com feedback humano (RLHF) para alinhar com preferências humanas de utilidade e segurança.",
  "meta.llama3-1-70b-instruct-v1:0.description": "Uma versão atualizada do Meta Llama 3.1 70B Instruct com janela de contexto estendida de 128K, suporte multilíngue e raciocínio aprimorado. Os LLMs multilíngues Llama 3.1 são modelos de geração pré-treinados e ajustados por instruções nos tamanhos 8B, 70B e 405B (entrada/saída de texto). Os modelos ajustados por instruções são otimizados para diálogos multilíngues e superam muitos modelos de chat abertos disponíveis em benchmarks da indústria. O Llama 3.1 é projetado para uso comercial e de pesquisa em vários idiomas. Os modelos ajustados por instruções são ideais para chat estilo assistente, enquanto os modelos pré-treinados são adequados para tarefas mais amplas de geração de linguagem natural. As saídas do Llama 3.1 também podem ser usadas para melhorar outros modelos, incluindo geração e refinamento de dados sintéticos. O Llama 3.1 é um modelo Transformer autoregressivo com arquitetura otimizada. As versões ajustadas utilizam ajuste supervisionado (SFT) e aprendizado por reforço com feedback humano (RLHF) para alinhar com preferências humanas de utilidade e segurança.",
  "meta.llama3-1-8b-instruct-v1:0.description": "Uma versão atualizada do Meta Llama 3.1 8B Instruct com janela de contexto de 128K, suporte multilíngue e raciocínio aprimorado. A família Llama 3.1 inclui modelos de texto ajustados por instruções de 8B, 70B e 405B otimizados para chat multilíngue e desempenho forte em benchmarks. É projetado para uso comercial e de pesquisa em vários idiomas; os modelos ajustados por instruções são ideais para chat estilo assistente, enquanto os modelos pré-treinados são adequados para tarefas mais amplas de geração. As saídas do Llama 3.1 também podem ser usadas para melhorar outros modelos (por exemplo, dados sintéticos e refinamento). É um modelo Transformer autoregressivo, com SFT e RLHF para alinhamento com utilidade e segurança.",
  "meta.llama3-70b-instruct-v1:0.description": "Meta Llama 3 é um LLM aberto para desenvolvedores, pesquisadores e empresas, projetado para ajudá-los a construir, experimentar e escalar ideias de IA generativa de forma responsável. Como parte da base para inovação da comunidade global, é ideal para criação de conteúdo, IA conversacional, compreensão de linguagem, P&D e aplicações empresariais.",
  "meta.llama3-8b-instruct-v1:0.description": "O Meta Llama 3 é um modelo de linguagem aberto para desenvolvedores, pesquisadores e empresas, projetado para ajudá-los a construir, experimentar e escalar ideias de IA generativa de forma responsável. Como parte da base para a inovação da comunidade global, é ideal para ambientes com recursos computacionais limitados, dispositivos de borda e tempos de treinamento mais rápidos.",
  "meta/Llama-3.2-11B-Vision-Instruct.description": "Raciocínio visual avançado em imagens de alta resolução, ideal para aplicativos de compreensão visual.",
  "meta/Llama-3.2-90B-Vision-Instruct.description": "Raciocínio visual avançado para aplicações de agentes com compreensão visual.",
  "meta/Llama-3.3-70B-Instruct.description": "Llama 3.3 é o modelo Llama de código aberto multilíngue mais avançado, oferecendo desempenho próximo ao de modelos de 405B a um custo muito menor. Baseado em Transformer, aprimorado com SFT e RLHF para utilidade e segurança. A versão ajustada por instruções é otimizada para chat multilíngue e supera muitos modelos de chat abertos e fechados em benchmarks da indústria. Corte de conhecimento: dezembro de 2023.",
  "meta/Meta-Llama-3-70B-Instruct.description": "Um modelo poderoso com 70 bilhões de parâmetros que se destaca em raciocínio, programação e tarefas amplas de linguagem.",
  "meta/Meta-Llama-3-8B-Instruct.description": "Um modelo versátil com 8 bilhões de parâmetros, otimizado para chat e geração de texto.",
  "meta/Meta-Llama-3.1-405B-Instruct.description": "Modelo de texto Llama 3.1 ajustado por instruções, otimizado para chat multilíngue, com desempenho forte em benchmarks da indústria entre modelos de chat abertos e fechados.",
  "meta/Meta-Llama-3.1-70B-Instruct.description": "Modelo de texto Llama 3.1 ajustado por instruções, otimizado para chat multilíngue, com desempenho forte em benchmarks da indústria entre modelos de chat abertos e fechados.",
  "meta/Meta-Llama-3.1-8B-Instruct.description": "Modelo de texto Llama 3.1 ajustado por instruções, otimizado para chat multilíngue, com desempenho forte em benchmarks da indústria entre modelos de chat abertos e fechados.",
  "meta/llama-3-70b.description": "Modelo de 70B de código aberto ajustado pela Meta para seguir instruções, servido pela Groq em hardware LPU para inferência rápida e eficiente.",
  "meta/llama-3-8b.description": "Modelo de 8B de código aberto ajustado pela Meta para seguir instruções, servido pela Groq em hardware LPU para inferência rápida e eficiente.",
  "meta/llama-3.1-405b-instruct.description": "Um LLM avançado com suporte à geração de dados sintéticos, destilação de conhecimento e raciocínio para chatbots, programação e tarefas específicas de domínio.",
  "meta/llama-3.1-70b-instruct.description": "Projetado para diálogos complexos com excelente compreensão de contexto, raciocínio e geração de texto.",
  "meta/llama-3.1-70b.description": "Uma versão atualizada do Meta Llama 3 70B Instruct com contexto de 128K, suporte multilíngue e raciocínio aprimorado.",
  "meta/llama-3.1-8b-instruct.description": "Um modelo de ponta com forte compreensão de linguagem, raciocínio e geração de texto.",
  "meta/llama-3.1-8b.description": "Llama 3.1 8B oferece uma janela de contexto de 128K, ideal para chat em tempo real e análise de dados, com economia significativa em relação a modelos maiores. Servido pela Groq em hardware LPU para inferência rápida e eficiente.",
  "meta/llama-3.2-11b-vision-instruct.description": "Um modelo de ponta em visão e linguagem que se destaca em raciocínio de alta qualidade a partir de imagens.",
  "meta/llama-3.2-11b.description": "Modelo de raciocínio visual ajustado por instruções (entrada de texto+imagem, saída de texto), otimizado para reconhecimento visual, raciocínio com imagens, legendagem e perguntas e respostas gerais sobre imagens.",
  "meta/llama-3.2-1b-instruct.description": "Um modelo de linguagem pequeno e avançado com forte compreensão, raciocínio e geração de texto.",
  "meta/llama-3.2-1b.description": "Modelo apenas de texto para uso em dispositivos locais, como recuperação multilíngue, resumo e reescrita.",
  "meta/llama-3.2-3b-instruct.description": "Um modelo de linguagem pequeno e avançado com forte compreensão, raciocínio e geração de texto.",
  "meta/llama-3.2-3b.description": "Modelo apenas de texto ajustado para uso em dispositivos locais, como recuperação multilíngue, resumo e reescrita.",
  "meta/llama-3.2-90b-vision-instruct.description": "Um modelo de ponta em visão e linguagem que se destaca em raciocínio de alta qualidade a partir de imagens.",
  "meta/llama-3.2-90b.description": "Modelo de raciocínio visual ajustado por instruções (entrada de texto+imagem, saída de texto), otimizado para reconhecimento visual, raciocínio com imagens, legendagem e perguntas e respostas gerais sobre imagens.",
  "meta/llama-3.3-70b-instruct.description": "Um LLM avançado com forte desempenho em raciocínio, matemática, senso comum e chamadas de função.",
  "meta/llama-3.3-70b.description": "Um equilíbrio perfeito entre desempenho e eficiência. Criado para IA conversacional de alto desempenho em criação de conteúdo, aplicativos corporativos e pesquisa, com forte compreensão de linguagem para resumo, classificação, sentimento e geração de código.",
  "meta/llama-4-maverick.description": "A família Llama 4 é um conjunto de modelos de IA multimodal nativos que suportam experiências em texto e multimodalidade, utilizando MoE para compreensão avançada de texto e imagem. O Llama 4 Maverick é um modelo de 17B com 128 especialistas, fornecido pela DeepInfra.",
  "meta/llama-4-scout.description": "A família Llama 4 é um conjunto de modelos de IA multimodal nativos que suportam experiências em texto e multimodalidade, utilizando MoE para compreensão avançada de texto e imagem. O Llama 4 Scout é um modelo de 17B com 16 especialistas, fornecido pela DeepInfra.",
  "microsoft/Phi-3-medium-128k-instruct.description": "O mesmo modelo Phi-3-medium com uma janela de contexto maior para RAG ou prompts few-shot.",
  "microsoft/Phi-3-medium-4k-instruct.description": "Modelo com 14 bilhões de parâmetros e qualidade superior ao Phi-3-mini, focado em dados de alta qualidade e raciocínio intensivo.",
  "microsoft/Phi-3-mini-128k-instruct.description": "O mesmo modelo Phi-3-mini com uma janela de contexto maior para RAG ou prompts few-shot.",
  "microsoft/Phi-3-mini-4k-instruct.description": "O menor membro da família Phi-3, otimizado para qualidade e baixa latência.",
  "microsoft/Phi-3-small-128k-instruct.description": "O mesmo modelo Phi-3-small com uma janela de contexto maior para RAG ou prompts few-shot.",
  "microsoft/Phi-3-small-8k-instruct.description": "Modelo com 7 bilhões de parâmetros e qualidade superior ao Phi-3-mini, focado em dados de alta qualidade e raciocínio intensivo.",
  "microsoft/Phi-3.5-mini-instruct.description": "Uma versão atualizada do modelo Phi-3-mini.",
  "microsoft/Phi-3.5-vision-instruct.description": "Uma versão atualizada do modelo Phi-3-vision.",
  "microsoft/WizardLM-2-8x22B.description": "WizardLM 2 é um modelo de linguagem da Microsoft AI que se destaca em diálogos complexos, tarefas multilíngues, raciocínio e assistentes.",
  "microsoft/wizardlm-2-8x22b.description": "WizardLM-2 8x22B é o modelo Wizard mais avançado da Microsoft AI, com desempenho altamente competitivo.",
  "mimo-v2-flash.description": "MiMo-V2-Flash: Um modelo eficiente para raciocínio, programação e fundamentos de agentes.",
  "minicpm-v.description": "MiniCPM-V é o modelo multimodal de próxima geração da OpenBMB, com excelente desempenho em OCR e compreensão multimodal para diversos casos de uso.",
  "minimax-m2.1.description": "MiniMax-M2.1 é a versão mais recente da série MiniMax, otimizada para programação multilíngue e tarefas complexas do mundo real. Como modelo nativo de IA, o MiniMax-M2.1 apresenta melhorias significativas em desempenho, suporte a frameworks de agentes e adaptação a múltiplos cenários, com o objetivo de ajudar empresas e indivíduos a adotarem rapidamente um estilo de vida e trabalho nativo de IA.",
  "minimax-m2.description": "MiniMax M2 é um modelo de linguagem grande e eficiente, construído especificamente para fluxos de trabalho de programação e agentes.",
  "minimax/minimax-m2.1.description": "MiniMax-M2.1 é um modelo de linguagem grande, leve e de ponta, otimizado para programação, fluxos de trabalho com agentes e desenvolvimento moderno de aplicações, oferecendo saídas mais limpas, concisas e com tempos de resposta mais rápidos.",
  "minimax/minimax-m2.description": "MiniMax-M2 é um modelo de alto valor que se destaca em tarefas de programação e agentes em diversos cenários de engenharia.",
  "minimaxai/minimax-m2.description": "MiniMax-M2 é um modelo MoE compacto, rápido e econômico (230B total, 10B ativos), construído para desempenho de ponta em programação e agentes, mantendo forte inteligência geral. Ele se destaca em edições de múltiplos arquivos, ciclos de execução e correção de código, validação de testes e cadeias de ferramentas complexas.",
  "ministral-3b-latest.description": "Ministral 3B é o modelo de ponta da Mistral para uso em borda.",
  "ministral-8b-latest.description": "Ministral 8B é um modelo de borda altamente econômico da Mistral.",
  "mistral-ai/Mistral-Large-2411.description": "Modelo principal da Mistral para tarefas complexas que exigem raciocínio em larga escala ou especialização (geração de texto sintético, geração de código, RAG ou agentes).",
  "mistral-ai/Mistral-Nemo.description": "Mistral Nemo é um LLM de ponta com raciocínio de última geração, conhecimento de mundo e programação, considerando seu tamanho.",
  "mistral-ai/mistral-small-2503.description": "Mistral Small é adequado para qualquer tarefa baseada em linguagem que exija alta eficiência e baixa latência.",
  "mistral-large-instruct.description": "Mistral-Large-Instruct-2407 é um LLM denso avançado com 123B parâmetros e raciocínio, conhecimento e programação de última geração.",
  "mistral-large-latest.description": "Mistral Large é o modelo principal, com excelente desempenho em tarefas multilíngues, raciocínio complexo e geração de código — ideal para aplicações de alto nível.",
  "mistral-large.description": "Mixtral Large é o modelo principal da Mistral, combinando geração de código, matemática e raciocínio com uma janela de contexto de 128K.",
  "mistral-medium-latest.description": "Mistral Medium 3 oferece desempenho de ponta com custo 8× menor e facilita a implantação em ambientes corporativos.",
  "mistral-nemo-instruct.description": "Mistral-Nemo-Instruct-2407 é a versão ajustada por instruções do Mistral-Nemo-Base-2407.",
  "mistral-nemo.description": "Mistral Nemo é um modelo de alta eficiência com 12B parâmetros, desenvolvido pela Mistral AI e NVIDIA.",
  "mistral-small-latest.description": "Mistral Small é uma opção econômica, rápida e confiável para tradução, sumarização e análise de sentimento.",
  "mistral-small.description": "Mistral Small é adequado para qualquer tarefa baseada em linguagem que exija alta eficiência e baixa latência.",
  "mistral.description": "Mistral é o modelo de 7B da Mistral AI, adequado para diversas tarefas linguísticas.",
  "mistral/codestral-embed.description": "Modelo de embedding de código para indexação de bases de código e repositórios, ideal para assistentes de programação.",
  "mistral/codestral.description": "Mistral Codestral 25.01 é um modelo de programação de última geração, otimizado para baixa latência e uso frequente. Suporta mais de 80 linguagens e se destaca em FIM, correção de código e geração de testes.",
  "mistral/devstral-small.description": "Devstral é um LLM com comportamento agente voltado para tarefas de engenharia de software, sendo uma excelente escolha para agentes desenvolvedores.",
  "mistral/magistral-medium.description": "Raciocínio complexo apoiado por compreensão profunda, com lógica transparente que pode ser acompanhada e verificada. Mantém raciocínio de alta fidelidade entre idiomas, mesmo durante a tarefa.",
  "mistral/magistral-small.description": "Raciocínio complexo apoiado por compreensão profunda, com lógica transparente que pode ser acompanhada e verificada. Mantém raciocínio de alta fidelidade entre idiomas, mesmo durante a tarefa.",
  "mistral/ministral-3b.description": "Modelo compacto e eficiente para tarefas locais, como assistentes e análises no dispositivo, com desempenho de baixa latência.",
  "mistral/ministral-8b.description": "Modelo mais potente com inferência rápida e eficiente em memória, ideal para fluxos de trabalho complexos e aplicações exigentes em edge.",
  "mistral/mistral-embed.description": "Modelo geral de embedding de texto para busca semântica, similaridade, agrupamento e fluxos de RAG.",
  "mistral/mistral-large.description": "Mistral Large é ideal para tarefas complexas que exigem raciocínio avançado ou especialização — geração de texto sintético, código, RAG ou agentes.",
  "mistral/mistral-small.description": "Mistral Small é ideal para tarefas simples e em lote, como classificação, suporte ao cliente ou geração de texto, com ótimo desempenho a um preço acessível.",
  "mistral/mixtral-8x22b-instruct.description": "Modelo Instruct 8x22B. O 8x22B é um modelo MoE aberto disponibilizado pela Mistral.",
  "mistral/pixtral-12b.description": "Modelo de 12B com compreensão de imagens e texto.",
  "mistral/pixtral-large.description": "Pixtral Large é o segundo modelo da nossa família multimodal com compreensão de imagem em nível de fronteira. Lida com documentos, gráficos e imagens naturais, mantendo a liderança em compreensão textual do Mistral Large 2.",
  "mistralai/Mistral-7B-Instruct-v0.1.description": "Mistral (7B) Instruct é conhecido por seu forte desempenho em diversas tarefas linguísticas.",
  "mistralai/Mistral-7B-Instruct-v0.2.description": "Mistral (7B) Instruct v0.2 melhora o manuseio de instruções e a precisão dos resultados.",
  "mistralai/Mistral-7B-Instruct-v0.3.description": "Mistral (7B) Instruct v0.3 oferece computação eficiente e forte compreensão linguística para diversos casos de uso.",
  "mistralai/Mistral-7B-v0.1.description": "Mistral 7B é compacto, mas de alto desempenho, ideal para processamento em lote e tarefas simples como classificação e geração de texto, com raciocínio sólido.",
  "mistralai/Mixtral-8x22B-Instruct-v0.1.description": "Mixtral-8x22B Instruct (141B) é um LLM muito grande para cargas de trabalho pesadas.",
  "mistralai/Mixtral-8x7B-Instruct-v0.1.description": "Mixtral-8x7B Instruct (46.7B) oferece alta capacidade para processamento de dados em larga escala.",
  "mistralai/Mixtral-8x7B-v0.1.description": "Mixtral 8x7B é um modelo MoE esparso que acelera a inferência, adequado para tarefas multilíngues e geração de código.",
  "mistralai/mistral-nemo.description": "Mistral Nemo é um modelo de 7.3B com suporte multilíngue e forte desempenho em programação.",
  "mixtral-8x7b-32768.description": "Mixtral 8x7B oferece computação paralela tolerante a falhas para tarefas complexas.",
  "mixtral.description": "Mixtral é o modelo MoE da Mistral AI com pesos abertos, com suporte à geração de código e compreensão de linguagem.",
  "mixtral:8x22b.description": "Mixtral é o modelo MoE da Mistral AI com pesos abertos, com suporte à geração de código e compreensão de linguagem.",
  "moonshot-v1-128k-vision-preview.description": "Os modelos de visão Kimi (incluindo moonshot-v1-8k-vision-preview/moonshot-v1-32k-vision-preview/moonshot-v1-128k-vision-preview) compreendem conteúdo de imagem como texto, cores e formas de objetos.",
  "moonshot-v1-128k.description": "Moonshot V1 128K oferece contexto ultra-longo para geração de texto muito extensa, lidando com até 128.000 tokens para pesquisa, uso acadêmico e documentos longos.",
  "moonshot-v1-32k-vision-preview.description": "Os modelos de visão Kimi (incluindo moonshot-v1-8k-vision-preview/moonshot-v1-32k-vision-preview/moonshot-v1-128k-vision-preview) compreendem conteúdo de imagem como texto, cores e formas de objetos.",
  "moonshot-v1-32k.description": "Moonshot V1 32K suporta 32.768 tokens para contexto de comprimento médio, ideal para documentos longos e diálogos complexos em criação de conteúdo, relatórios e sistemas de chat.",
  "moonshot-v1-8k-vision-preview.description": "Os modelos de visão Kimi (incluindo moonshot-v1-8k-vision-preview/moonshot-v1-32k-vision-preview/moonshot-v1-128k-vision-preview) compreendem conteúdo de imagem como texto, cores e formas de objetos.",
  "moonshot-v1-8k.description": "Moonshot V1 8K é otimizado para geração de texto curta com desempenho eficiente, lidando com 8.192 tokens para conversas rápidas, anotações e conteúdo breve.",
  "moonshot-v1-auto.description": "Moonshot V1 Auto seleciona o modelo apropriado com base no uso atual de tokens de contexto.",
  "moonshotai/Kimi-Dev-72B.description": "Kimi-Dev-72B é um LLM de código open-source otimizado com RL em larga escala para produzir correções robustas e prontas para produção. Alcança 60,4% no SWE-bench Verified, estabelecendo um novo recorde entre modelos abertos para tarefas de engenharia de software automatizada como correção de bugs e revisão de código.",
  "moonshotai/Kimi-K2-Instruct-0905.description": "Kimi K2-Instruct-0905 é a versão mais nova e poderosa do Kimi K2. É um modelo MoE de ponta com 1T total e 32B de parâmetros ativos. Os principais recursos incluem inteligência de programação com agentes mais forte, grandes avanços em benchmarks e tarefas reais de agentes, além de melhorias na estética e usabilidade de código frontend.",
  "moonshotai/Kimi-K2-Thinking.description": "Kimi K2 Thinking é o modelo de raciocínio open-source mais poderoso até o momento. Ele amplia significativamente a profundidade de raciocínio em múltiplas etapas e mantém o uso estável de ferramentas por 200–300 chamadas consecutivas, estabelecendo novos recordes em Humanity's Last Exam (HLE), BrowseComp e outros benchmarks. Destaca-se em programação, matemática, lógica e cenários com agentes. Baseado em arquitetura MoE com ~1T de parâmetros totais, suporta janela de contexto de 256K e chamadas de ferramentas.",
  "moonshotai/kimi-k2-0711.description": "Kimi K2 0711 é a variante instruct da série Kimi, ideal para geração de código de alta qualidade e uso de ferramentas.",
  "moonshotai/kimi-k2-0905.description": "Kimi K2 0905 é uma atualização que amplia o contexto e melhora o desempenho em raciocínio com otimizações para programação.",
  "moonshotai/kimi-k2-instruct-0905.description": "O modelo kimi-k2-0905-preview oferece uma janela de contexto de 256k, com codificação mais autônoma, código frontend mais refinado e prático, e melhor compreensão de contexto.",
  "moonshotai/kimi-k2-thinking-turbo.description": "Kimi K2 Thinking Turbo é a versão de alta velocidade do Kimi K2 Thinking, reduzindo significativamente a latência sem perder profundidade de raciocínio.",
  "moonshotai/kimi-k2-thinking.description": "Kimi K2 Thinking é o modelo de raciocínio da Moonshot otimizado para tarefas de raciocínio profundo, com capacidades gerais de agente.",
  "moonshotai/kimi-k2.description": "Kimi K2 é um modelo MoE de grande porte da Moonshot AI com 1 trilhão de parâmetros totais e 32 bilhões ativos por passagem, otimizado para capacidades de agente, incluindo uso avançado de ferramentas, raciocínio e síntese de código.",
  "morph/morph-v3-fast.description": "Morph oferece um modelo especializado para aplicar alterações de código sugeridas por modelos de ponta (como Claude ou GPT-4o) aos seus arquivos existentes a uma velocidade de 4500+ tokens/seg. É a etapa final em um fluxo de trabalho de codificação com IA e suporta 16k tokens de entrada/saída.",
  "morph/morph-v3-large.description": "Morph oferece um modelo especializado para aplicar alterações de código sugeridas por modelos de ponta (como Claude ou GPT-4o) aos seus arquivos existentes a uma velocidade de 2500+ tokens/seg. É a etapa final em um fluxo de trabalho de codificação com IA e suporta 16k tokens de entrada/saída.",
  "nousresearch/hermes-2-pro-llama-3-8b.description": "Hermes 2 Pro Llama 3 8B é uma versão atualizada do Nous Hermes 2 com os mais recentes conjuntos de dados desenvolvidos internamente.",
  "nvidia/Llama-3.1-Nemotron-70B-Instruct-HF.description": "Llama 3.1 Nemotron 70B é um LLM personalizado da NVIDIA para melhorar a utilidade. Apresenta desempenho superior nos benchmarks Arena Hard, AlpacaEval 2 LC e GPT-4-Turbo MT-Bench, ocupando o 1º lugar em todos os três benchmarks de autoalinhamento em 1º de outubro de 2024. Treinado a partir do Llama-3.1-70B-Instruct usando RLHF (REINFORCE), Llama-3.1-Nemotron-70B-Reward e prompts HelpSteer2-Preference.",
  "nvidia/llama-3.1-nemotron-51b-instruct.description": "Modelo de linguagem distinto com precisão e eficiência excepcionais.",
  "nvidia/llama-3.1-nemotron-70b-instruct.description": "Llama-3.1-Nemotron-70B-Instruct é um modelo personalizado da NVIDIA projetado para melhorar a utilidade das respostas de LLMs.",
  "o1-mini.description": "Menor e mais rápido que o o1-preview, com custo 80% menor, forte em geração de código e tarefas de contexto curto.",
  "o1-preview.description": "Focado em raciocínio avançado e resolução de problemas complexos, incluindo matemática e ciência. Ideal para aplicações que exigem compreensão profunda de contexto e fluxos de trabalho autônomos.",
  "o1-pro.description": "A série o1 é treinada com aprendizado por reforço para pensar antes de responder e lidar com raciocínio complexo. O o1-pro usa mais recursos computacionais para raciocínio mais profundo e respostas consistentemente melhores.",
  "o1.description": "o1 é o novo modelo de raciocínio da OpenAI com entrada de texto+imagem e saída de texto, adequado para tarefas complexas que exigem amplo conhecimento. Possui janela de contexto de 200K e corte de conhecimento em outubro de 2023.",
  "o3-2025-04-16.description": "o3 é o novo modelo de raciocínio da OpenAI com entrada de texto+imagem e saída de texto para tarefas complexas que exigem amplo conhecimento.",
  "o3-deep-research.description": "o3-deep-research é nosso modelo de pesquisa profunda mais avançado para tarefas complexas em múltiplas etapas. Pode buscar na web e acessar seus dados via conectores MCP.",
  "o3-mini.description": "o3-mini é nosso mais novo modelo pequeno de raciocínio, oferecendo maior inteligência com o mesmo custo e latência do o1-mini.",
  "o3-pro-2025-06-10.description": "o3 Pro é o novo modelo de raciocínio da OpenAI com entrada de texto+imagem e saída de texto para tarefas complexas que exigem amplo conhecimento.",
  "o3-pro.description": "o3-pro usa mais recursos computacionais para pensar mais profundamente e fornecer respostas consistentemente melhores; disponível apenas via API de Respostas.",
  "o3.description": "o3 é um modelo versátil e poderoso que estabelece um novo padrão em matemática, ciência, programação e raciocínio visual. Destaca-se em redação técnica, seguimento de instruções e pode analisar texto, código e imagens em problemas de múltiplas etapas.",
  "o4-mini-2025-04-16.description": "o4-mini é um modelo de raciocínio da OpenAI com entrada de texto+imagem e saída de texto, adequado para tarefas complexas que exigem amplo conhecimento, com janela de contexto de 200K.",
  "o4-mini-deep-research.description": "o4-mini-deep-research é um modelo de pesquisa profunda mais rápido e acessível para tarefas complexas em múltiplas etapas. Pode buscar na web e acessar seus dados via conectores MCP.",
  "o4-mini.description": "o4-mini é o mais novo modelo pequeno da série o, otimizado para raciocínio rápido e eficaz com alta eficiência em tarefas de codificação e visão.",
  "open-codestral-mamba.description": "Codestral Mamba é um modelo de linguagem Mamba 2 voltado para geração de código, com suporte a tarefas avançadas de programação e raciocínio.",
  "open-mistral-7b.description": "Mistral 7B é compacto, mas de alto desempenho, ideal para processamento em lote e tarefas simples como classificação e geração de texto, com raciocínio sólido.",
  "open-mistral-nemo.description": "Mistral Nemo é um modelo de 12B co-desenvolvido com a Nvidia, oferecendo desempenho robusto em raciocínio e programação com fácil integração.",
  "open-mixtral-8x22b.description": "Mixtral 8x22B é um modelo MoE de grande porte para tarefas complexas, com raciocínio avançado e alta capacidade de processamento.",
  "open-mixtral-8x7b.description": "Mixtral 8x7B é um modelo MoE esparso que acelera a inferência, adequado para tarefas multilíngues e de geração de código.",
  "openai/gpt-3.5-turbo-instruct.description": "Capacidades semelhantes aos modelos da era GPT-3, compatível com endpoints legados de completions em vez de chat.",
  "openai/gpt-3.5-turbo.description": "O modelo GPT-3.5 mais capaz e econômico da OpenAI, otimizado para chat, mas ainda eficaz em completions clássicos.",
  "openai/gpt-4-turbo.description": "O gpt-4-turbo da OpenAI possui amplo conhecimento geral e expertise em domínios, segue instruções complexas em linguagem natural e resolve problemas difíceis com precisão. O corte de conhecimento é abril de 2023, com janela de contexto de 128k.",
  "openai/gpt-4.1-mini.description": "GPT-4.1 Mini oferece menor latência e melhor custo-benefício para cargas de trabalho de contexto médio.",
  "openai/gpt-4.1-nano.description": "GPT-4.1 Nano é uma opção de custo ultrabaixo e baixa latência para conversas curtas de alta frequência ou tarefas de classificação.",
  "openai/gpt-4.1.description": "A série GPT-4.1 oferece janelas de contexto maiores e capacidades aprimoradas de engenharia e raciocínio.",
  "openai/gpt-4o-mini.description": "GPT-4o-mini é uma variante rápida e compacta do GPT-4o para uso multimodal com baixa latência.",
  "openai/gpt-4o.description": "A família GPT-4o é o modelo Omni da OpenAI com entrada de texto + imagem e saída em texto.",
  "openai/gpt-5-chat.description": "GPT-5 Chat é uma variante do GPT-5 otimizada para conversas com menor latência e melhor interatividade.",
  "openai/gpt-5-codex.description": "GPT-5-Codex é uma variante do GPT-5 ainda mais otimizada para programação e fluxos de trabalho de código em larga escala.",
  "openai/gpt-5-mini.description": "GPT-5 Mini é uma variante menor do GPT-5 para cenários de baixo custo e baixa latência.",
  "openai/gpt-5-nano.description": "GPT-5 Nano é a variante ultracompacta para cenários com restrições rigorosas de custo e latência.",
  "openai/gpt-5-pro.description": "GPT-5 Pro é o modelo principal da OpenAI, oferecendo raciocínio avançado, geração de código e recursos de nível corporativo, com roteamento em tempo de execução e políticas de segurança mais rigorosas.",
  "openai/gpt-5.1-chat.description": "GPT-5.1 Chat é o membro leve da família GPT-5.1, otimizado para conversas de baixa latência, mantendo forte raciocínio e execução de instruções.",
  "openai/gpt-5.1-codex-mini.description": "GPT-5.1-Codex-Mini é uma versão menor e mais rápida do GPT-5.1-Codex, ideal para cenários de programação sensíveis a latência e custo.",
  "openai/gpt-5.1-codex.description": "GPT-5.1-Codex é uma variante do GPT-5.1 otimizada para engenharia de software e fluxos de trabalho de programação, adequada para grandes refatorações, depuração complexa e tarefas autônomas prolongadas.",
  "openai/gpt-5.1.description": "GPT-5.1 é o modelo principal mais recente da série GPT-5, com melhorias significativas em raciocínio geral, seguimento de instruções e naturalidade em conversas, adequado para tarefas amplas.",
  "openai/gpt-5.2-chat.description": "GPT-5.2 Chat é a variante do ChatGPT para experimentar as melhorias mais recentes em conversação.",
  "openai/gpt-5.2-pro.description": "GPT-5.2 Pro: uma variante mais inteligente e precisa do GPT-5.2 (somente API de Respostas), ideal para problemas mais difíceis e raciocínio prolongado em múltiplas interações.",
  "openai/gpt-5.2.description": "GPT-5.2 é um modelo carro-chefe para programação e fluxos de trabalho com agentes, com raciocínio mais avançado e desempenho superior em contextos longos.",
  "openai/gpt-5.description": "GPT-5 é o modelo de alto desempenho da OpenAI para uma ampla gama de tarefas de produção e pesquisa.",
  "openai/gpt-oss-120b.description": "Um modelo de linguagem de uso geral altamente capaz, com raciocínio forte e controlável.",
  "openai/gpt-oss-20b.description": "Um modelo de linguagem compacto com pesos abertos, otimizado para baixa latência e ambientes com recursos limitados, incluindo implantações locais e na borda.",
  "openai/o1-mini.description": "o1-mini é um modelo de raciocínio rápido e econômico, projetado para programação, matemática e ciência. Possui contexto de 128K e corte de conhecimento em outubro de 2023.",
  "openai/o1-preview.description": "o1 é o novo modelo de raciocínio da OpenAI para tarefas complexas que exigem conhecimento amplo. Possui contexto de 128K e corte de conhecimento em outubro de 2023.",
  "openai/o1.description": "OpenAI o1 é um modelo de raciocínio principal desenvolvido para problemas complexos que exigem pensamento profundo, oferecendo raciocínio sólido e maior precisão em tarefas de múltiplas etapas.",
  "openai/o3-mini-high.description": "o3-mini (raciocínio avançado) oferece inteligência superior com os mesmos custos e metas de latência do o1-mini.",
  "openai/o3-mini.description": "o3-mini é o mais recente modelo de raciocínio compacto da OpenAI, oferecendo inteligência superior com os mesmos custos e metas de latência do o1-mini.",
  "openai/o3.description": "OpenAI o3 é o modelo de raciocínio mais poderoso, estabelecendo um novo estado da arte em programação, matemática, ciência e percepção visual. Destaca-se em consultas complexas e multifacetadas, com forte capacidade de análise de imagens, gráficos e diagramas.",
  "openai/o4-mini-high.description": "o4-mini com raciocínio avançado, otimizado para raciocínio rápido e eficiente com desempenho sólido em programação e visão computacional.",
  "openai/o4-mini.description": "OpenAI o4-mini é um modelo de raciocínio pequeno e eficiente para cenários de baixa latência.",
  "openai/text-embedding-3-large.description": "O modelo de embedding mais avançado da OpenAI para tarefas em inglês e outros idiomas.",
  "openai/text-embedding-3-small.description": "Variante aprimorada e de alto desempenho do modelo de embedding ada da OpenAI.",
  "openai/text-embedding-ada-002.description": "Modelo de embedding de texto legado da OpenAI.",
  "openrouter/auto.description": "Com base no comprimento do contexto, tópico e complexidade, sua solicitação é roteada para Llama 3 70B Instruct, Claude 3.5 Sonnet (auto-moderado) ou GPT-4o.",
  "perplexity/sonar-pro.description": "Produto principal da Perplexity com base em busca, oferecendo suporte a consultas avançadas e seguimentos.",
  "perplexity/sonar-reasoning-pro.description": "Modelo avançado com foco em raciocínio que gera cadeia de pensamento (CoT) com busca aprimorada, incluindo múltiplas consultas por solicitação.",
  "perplexity/sonar-reasoning.description": "Modelo com foco em raciocínio que gera cadeia de pensamento (CoT) com explicações detalhadas baseadas em busca.",
  "perplexity/sonar.description": "Produto leve da Perplexity com base em busca, mais rápido e econômico que o Sonar Pro.",
  "phi3.description": "Phi-3 é o modelo leve e aberto da Microsoft para integração eficiente e raciocínio em larga escala.",
  "phi3:14b.description": "Phi-3 é o modelo leve e aberto da Microsoft para integração eficiente e raciocínio em larga escala.",
  "pixtral-12b-2409.description": "Pixtral é forte em compreensão de gráficos/imagens, perguntas e respostas em documentos, raciocínio multimodal e seguimento de instruções. Processa imagens em resolução/aspecto nativos e lida com qualquer número de imagens dentro de uma janela de contexto de 128K.",
  "pixtral-large-latest.description": "Pixtral Large é um modelo multimodal aberto com 124 bilhões de parâmetros baseado no Mistral Large 2, o segundo da nossa família multimodal com compreensão de imagem de ponta.",
  "pro-128k.description": "Spark Pro 128K oferece uma capacidade de contexto muito grande, lidando com até 128K de contexto, ideal para documentos longos que exigem análise de texto completo e coerência de longo alcance, com lógica fluida e suporte a citações diversas em discussões complexas.",
  "pro-deepseek-r1.description": "Modelo de serviço dedicado para empresas com concorrência agrupada.",
  "pro-deepseek-v3.description": "Modelo de serviço dedicado para empresas com concorrência agrupada.",
  "qianfan-70b.description": "Qianfan 70B é um modelo chinês de grande porte para geração de alta qualidade e raciocínio complexo.",
  "qianfan-8b.description": "Qianfan 8B é um modelo geral de porte médio que equilibra custo e qualidade para geração de texto e perguntas e respostas.",
  "qianfan-agent-intent-32k.description": "Qianfan Agent Intent 32K é voltado para reconhecimento de intenção e orquestração de agentes com suporte a contexto longo.",
  "qianfan-agent-lite-8k.description": "Qianfan Agent Lite 8K é um modelo de agente leve para diálogos de múltiplas voltas e fluxos de trabalho de baixo custo.",
  "qianfan-check-vl.description": "Qianfan Check VL é um modelo de revisão de conteúdo multimodal para conformidade e reconhecimento de imagem-texto.",
  "qianfan-composition.description": "Qianfan Composition é um modelo de criação multimodal para compreensão e geração mista de imagem e texto.",
  "qianfan-engcard-vl.description": "Qianfan EngCard VL é um modelo de reconhecimento multimodal focado em cenários em inglês.",
  "qianfan-lightning-128b-a19b.description": "Qianfan Lightning 128B A19B é um modelo chinês de alto desempenho para perguntas e respostas complexas e raciocínio em larga escala.",
  "qianfan-llama-vl-8b.description": "Qianfan Llama VL 8B é um modelo multimodal baseado em Llama para compreensão geral de imagem e texto.",
  "qianfan-multipicocr.description": "Qianfan MultiPicOCR é um modelo de OCR para múltiplas imagens, detectando e reconhecendo texto em várias imagens.",
  "qianfan-qi-vl.description": "Qianfan QI VL é um modelo de perguntas e respostas multimodal para recuperação precisa e respostas em cenários complexos de imagem e texto.",
  "qianfan-singlepicocr.description": "Qianfan SinglePicOCR é um modelo de OCR para imagem única com reconhecimento de caracteres de alta precisão.",
  "qianfan-vl-70b.description": "Qianfan VL 70B é um grande modelo de linguagem visual para compreensão complexa de imagem e texto.",
  "qianfan-vl-8b.description": "Qianfan VL 8B é um modelo leve de linguagem visual para perguntas e respostas e análise de imagem e texto no dia a dia.",
  "qvq-72b-preview.description": "QVQ-72B-Preview é um modelo experimental da Qwen focado em aprimorar o raciocínio visual.",
  "qvq-max.description": "O modelo de raciocínio visual Qwen QVQ aceita entrada visual e gera saídas com cadeia de raciocínio, com desempenho superior em matemática, programação, análise visual, criatividade e tarefas gerais.",
  "qvq-plus.description": "Modelo de raciocínio visual com entrada de imagem e saída com cadeia de raciocínio. A série qvq-plus sucede a qvq-max, oferecendo raciocínio mais rápido com melhor equilíbrio entre qualidade e custo.",
  "qwen-3-32b.description": "Qwen 3 32B: forte em tarefas multilíngues e de programação, adequado para uso em produção de médio porte.",
  "qwen-coder-plus.description": "Modelo de código Qwen.",
  "qwen-coder-turbo-latest.description": "Modelo de código Qwen.",
  "qwen-coder-turbo.description": "Modelo de código Qwen.",
  "qwen-flash.description": "Modelo Qwen mais rápido e de menor custo, ideal para tarefas simples.",
  "qwen-image-edit.description": "Qwen Image Edit é um modelo de imagem para imagem que edita imagens com base em imagens de entrada e comandos de texto, permitindo ajustes precisos e transformações criativas.",
  "qwen-image.description": "Qwen-Image é um modelo geral de geração de imagens que suporta múltiplos estilos artísticos e renderização complexa de texto, especialmente em chinês e inglês. Suporta layouts em várias linhas, texto em nível de parágrafo e detalhes refinados para composições complexas de texto e imagem.",
  "qwen-long.description": "Modelo Qwen ultra-grande com contexto longo e suporte a chat em cenários com múltiplos documentos.",
  "qwen-math-plus-latest.description": "Qwen Math é um modelo de linguagem especializado na resolução de problemas matemáticos.",
  "qwen-math-plus.description": "Qwen Math é um modelo de linguagem especializado na resolução de problemas matemáticos.",
  "qwen-math-turbo-latest.description": "Qwen Math é um modelo de linguagem especializado na resolução de problemas matemáticos.",
  "qwen-math-turbo.description": "Qwen Math é um modelo de linguagem especializado na resolução de problemas matemáticos.",
  "qwen-max.description": "Modelo Qwen ultra-grande com escala de centenas de bilhões, com suporte a chinês, inglês e outros idiomas; é o modelo de API por trás dos produtos Qwen2.5 atuais.",
  "qwen-omni-turbo.description": "Os modelos Qwen-Omni aceitam entradas multimodais (vídeo, áudio, imagens, texto) e geram saídas em áudio e texto.",
  "qwen-plus.description": "Modelo Qwen ultra-grande aprimorado com suporte a chinês, inglês e outros idiomas.",
  "qwen-turbo.description": "Qwen Turbo não será mais atualizado; substitua pelo Qwen Flash. Modelo Qwen ultra-grande com suporte a chinês, inglês e outros idiomas.",
  "qwen-vl-chat-v1.description": "Qwen VL permite interações flexíveis, incluindo entrada com múltiplas imagens, perguntas e respostas em múltiplas etapas e tarefas criativas.",
  "qwen-vl-max-latest.description": "Modelo Qwen de visão e linguagem ultra-grande. Em comparação com a versão aprimorada, melhora ainda mais o raciocínio visual e o seguimento de instruções para percepção e cognição mais fortes.",
  "qwen-vl-max.description": "Modelo Qwen de visão e linguagem ultra-grande. Em comparação com a versão aprimorada, melhora ainda mais o raciocínio visual e o seguimento de instruções para percepção visual e cognição mais fortes.",
  "qwen-vl-ocr.description": "Qwen OCR é um modelo de extração de texto para documentos, tabelas, imagens de exames e escrita manual. Suporta chinês, inglês, francês, japonês, coreano, alemão, russo, italiano, vietnamita e árabe.",
  "qwen-vl-plus-latest.description": "Modelo Qwen de visão e linguagem em larga escala aprimorado, com grandes avanços em reconhecimento de detalhes e texto, suportando resolução acima de um megapixel e proporções arbitrárias.",
  "qwen-vl-plus.description": "Modelo Qwen de visão e linguagem em larga escala aprimorado, com grandes avanços em reconhecimento de detalhes e texto, suportando resolução acima de um megapixel e proporções arbitrárias.",
  "qwen-vl-v1.description": "Modelo pré-treinado inicializado a partir do Qwen-7B com módulo de visão adicionado e entrada de imagem com resolução de 448.",
  "qwen/qwen-2-7b-instruct.description": "Qwen2 é a nova série de LLMs da Qwen. Qwen2 7B é um modelo baseado em transformador que se destaca em compreensão de linguagem, capacidade multilíngue, programação, matemática e raciocínio.",
  "qwen/qwen-2-7b-instruct:free.description": "Qwen2 é uma nova família de modelos de linguagem de grande porte com melhor compreensão e geração.",
  "qwen/qwen-2-vl-72b-instruct.description": "Qwen2-VL é a iteração mais recente do Qwen-VL, atingindo desempenho de ponta em benchmarks de visão como MathVista, DocVQA, RealWorldQA e MTVQA. Compreende mais de 20 minutos de vídeo para perguntas e respostas, diálogos e criação de conteúdo de alta qualidade. Também lida com raciocínio complexo e tomada de decisão, integrando-se a dispositivos móveis e robôs para agir com base em contexto visual e instruções de texto. Além do inglês e chinês, também lê texto em imagens em diversos idiomas, incluindo a maioria das línguas europeias, japonês, coreano, árabe e vietnamita.",
  "qwen/qwen-2.5-72b-instruct.description": "Qwen2.5-72B-Instruct é um dos lançamentos mais recentes de LLMs da Alibaba Cloud. O modelo de 72B traz melhorias notáveis em programação e matemática, suporta mais de 29 idiomas (incluindo chinês e inglês) e melhora significativamente o seguimento de instruções, compreensão de dados estruturados e geração de saídas estruturadas (especialmente JSON).",
  "qwen/qwen2.5-32b-instruct.description": "Qwen2.5-32B-Instruct é um dos lançamentos mais recentes de LLMs da Alibaba Cloud. O modelo de 32B traz melhorias notáveis em programação e matemática, suporta mais de 29 idiomas (incluindo chinês e inglês) e melhora significativamente o seguimento de instruções, compreensão de dados estruturados e geração de saídas estruturadas (especialmente JSON).",
  "qwen/qwen2.5-7b-instruct.description": "Um LLM bilíngue para chinês e inglês com foco em linguagem, programação, matemática e raciocínio.",
  "qwen/qwen2.5-coder-32b-instruct.description": "Um LLM avançado para geração, raciocínio e correção de código em linguagens de programação populares.",
  "qwen/qwen2.5-coder-7b-instruct.description": "Um modelo de código robusto de porte médio com contexto de 32K, excelente em programação multilíngue.",
  "qwen/qwen3-14b.description": "Qwen3-14B é a variante de 14B para raciocínio geral e cenários de chat.",
  "qwen/qwen3-14b:free.description": "Qwen3-14B é um LLM denso com 14,8B de parâmetros, projetado para raciocínio complexo e chat eficiente. Alterna entre modo de pensamento para matemática, programação e lógica, e modo não-pensante para conversas gerais. Ajustado para seguir instruções, usar ferramentas de agentes e escrita criativa em mais de 100 idiomas e dialetos. Suporta nativamente contexto de 32K e escala até 131K com YaRN.",
  "qwen/qwen3-235b-a22b-2507.description": "Qwen3-235B-A22B-Instruct-2507 é a variante Instruct da série Qwen3, equilibrando uso multilíngue com cenários de contexto longo.",
  "qwen/qwen3-235b-a22b-thinking-2507.description": "Qwen3-235B-A22B-Thinking-2507 é a variante de raciocínio da Qwen3, reforçada para tarefas complexas de matemática e raciocínio.",
  "qwen/qwen3-235b-a22b.description": "Qwen3-235B-A22B é um modelo MoE com 235B parâmetros da Qwen, com 22B ativos por passagem. Alterna entre modo de pensamento para raciocínio complexo, matemática e código, e modo não-pensante para chat eficiente. Oferece raciocínio forte, suporte multilíngue (100+ idiomas/dialetos), seguimento avançado de instruções e uso de ferramentas de agentes. Suporta nativamente contexto de 32K e escala até 131K com YaRN.",
  "qwen/qwen3-235b-a22b:free.description": "Qwen3-235B-A22B é um modelo MoE com 235B parâmetros da Qwen, com 22B ativos por passagem. Alterna entre modo de pensamento para raciocínio complexo, matemática e código, e modo não-pensante para chat eficiente. Oferece raciocínio forte, suporte multilíngue (100+ idiomas/dialetos), seguimento avançado de instruções e uso de ferramentas de agentes. Suporta nativamente contexto de 32K e escala até 131K com YaRN.",
  "qwen/qwen3-30b-a3b.description": "Qwen3 é a mais recente geração de modelos LLM da série Qwen, com arquiteturas densas e MoE, destacando-se em raciocínio, suporte multilíngue e tarefas avançadas de agentes. Sua capacidade única de alternar entre um modo de pensamento para raciocínio complexo e um modo sem pensamento para conversas eficientes garante desempenho versátil e de alta qualidade.\n\nQwen3 supera significativamente modelos anteriores como QwQ e Qwen2.5, oferecendo excelente desempenho em matemática, programação, raciocínio lógico, escrita criativa e conversas interativas. A variante Qwen3-30B-A3B possui 30,5 bilhões de parâmetros (3,3 bilhões ativos), 48 camadas, 128 especialistas (8 ativos por tarefa) e suporta até 131 mil tokens de contexto com YaRN, estabelecendo um novo padrão para modelos abertos.",
  "qwen/qwen3-30b-a3b:free.description": "Qwen3 é a mais recente geração de modelos LLM da série Qwen, com arquiteturas densas e MoE, destacando-se em raciocínio, suporte multilíngue e tarefas avançadas de agentes. Sua capacidade única de alternar entre um modo de pensamento para raciocínio complexo e um modo sem pensamento para conversas eficientes garante desempenho versátil e de alta qualidade.\n\nQwen3 supera significativamente modelos anteriores como QwQ e Qwen2.5, oferecendo excelente desempenho em matemática, programação, raciocínio lógico, escrita criativa e conversas interativas. A variante Qwen3-30B-A3B possui 30,5 bilhões de parâmetros (3,3 bilhões ativos), 48 camadas, 128 especialistas (8 ativos por tarefa) e suporta até 131 mil tokens de contexto com YaRN, estabelecendo um novo padrão para modelos abertos.",
  "qwen/qwen3-32b.description": "Qwen3-32B é um modelo LLM denso com 32,8 bilhões de parâmetros, otimizado para raciocínio complexo e conversas eficientes. Alterna entre um modo de pensamento para matemática, programação e lógica, e um modo sem pensamento para conversas gerais mais rápidas. Apresenta forte desempenho em seguir instruções, uso de ferramentas por agentes e escrita criativa em mais de 100 idiomas e dialetos. Suporta nativamente 32 mil tokens de contexto e escala até 131 mil com YaRN.",
  "qwen/qwen3-32b:free.description": "Qwen3-32B é um modelo LLM denso com 32,8 bilhões de parâmetros, otimizado para raciocínio complexo e conversas eficientes. Alterna entre um modo de pensamento para matemática, programação e lógica, e um modo sem pensamento para conversas gerais mais rápidas. Apresenta forte desempenho em seguir instruções, uso de ferramentas por agentes e escrita criativa em mais de 100 idiomas e dialetos. Suporta nativamente 32 mil tokens de contexto e escala até 131 mil com YaRN.",
  "qwen/qwen3-8b:free.description": "Qwen3-8B é um modelo LLM denso com 8,2 bilhões de parâmetros, projetado para tarefas com alto grau de raciocínio e conversas eficientes. Alterna entre um modo de pensamento para matemática, programação e lógica, e um modo sem pensamento para conversas gerais. Ajustado para seguir instruções, integração com agentes e escrita criativa em mais de 100 idiomas e dialetos. Suporta nativamente 32 mil tokens de contexto e escala até 131 mil com YaRN.",
  "qwen/qwen3-coder-plus.description": "Qwen3-Coder-Plus é um modelo da série Qwen voltado para programação, otimizado para uso de ferramentas mais complexas e sessões prolongadas.",
  "qwen/qwen3-coder.description": "Qwen3-Coder é a família de modelos de geração de código da série Qwen3, com forte capacidade de compreensão e geração de código em documentos longos.",
  "qwen/qwen3-max-preview.description": "Qwen3 Max (prévia) é a variante Max para raciocínio avançado e integração com ferramentas.",
  "qwen/qwen3-max.description": "Qwen3 Max é o modelo de raciocínio de alto desempenho da série Qwen3, voltado para raciocínio multilíngue e integração com ferramentas.",
  "qwen/qwen3-vl-plus.description": "Qwen3 VL-Plus é a variante da série Qwen3 com aprimoramento visual, oferecendo raciocínio multimodal avançado e processamento de vídeo.",
  "qwen2.5-14b-instruct-1m.description": "Qwen2.5 modelo open-source com 72 bilhões de parâmetros.",
  "qwen2.5-14b-instruct.description": "Qwen2.5 modelo open-source com 14 bilhões de parâmetros.",
  "qwen2.5-32b-instruct.description": "Qwen2.5 modelo open-source com 32 bilhões de parâmetros.",
  "qwen2.5-72b-instruct.description": "Qwen2.5 modelo open-source com 72 bilhões de parâmetros.",
  "qwen2.5-7b-instruct.description": "Qwen2.5 7B Instruct é um modelo open-source maduro para geração e conversas em múltiplos cenários.",
  "qwen2.5-coder-1.5b-instruct.description": "Modelo de código Qwen open-source.",
  "qwen2.5-coder-14b-instruct.description": "Modelo de código Qwen open-source.",
  "qwen2.5-coder-32b-instruct.description": "Modelo de código Qwen open-source.",
  "qwen2.5-coder-7b-instruct.description": "Modelo de código Qwen open-source.",
  "qwen2.5-coder-instruct.description": "Qwen2.5-Coder é o mais recente modelo LLM focado em código da família Qwen (anteriormente CodeQwen).",
  "qwen2.5-instruct.description": "Qwen2.5 é a mais recente série de modelos LLM da Qwen, com modelos base e ajustados por instrução variando de 0,5B a 72B parâmetros.",
  "qwen2.5-math-1.5b-instruct.description": "Qwen-Math oferece forte capacidade de resolução de problemas matemáticos.",
  "qwen2.5-math-72b-instruct.description": "Qwen-Math oferece forte capacidade de resolução de problemas matemáticos.",
  "qwen2.5-math-7b-instruct.description": "Qwen-Math oferece forte capacidade de resolução de problemas matemáticos.",
  "qwen2.5-omni-7b.description": "Modelos Qwen-Omni suportam entradas multimodais (vídeo, áudio, imagens, texto) e geram saídas em áudio e texto.",
  "qwen2.5-vl-32b-instruct.description": "Qwen2.5 VL 32B Instruct é um modelo multimodal open-source adequado para implantação privada e uso em múltiplos cenários.",
  "qwen2.5-vl-72b-instruct.description": "Melhorias em seguir instruções, matemática, resolução de problemas e programação, com reconhecimento geral de objetos mais robusto. Suporta localização precisa de elementos visuais em diversos formatos, compreensão de vídeos longos (até 10 minutos) com temporização de eventos em nível de segundo, ordenação temporal e compreensão de velocidade, além de agentes que podem controlar sistemas operacionais ou dispositivos móveis via análise e localização. Forte extração de informações-chave e saída em JSON. Esta é a versão 72B, a mais poderosa da série.",
  "qwen2.5-vl-7b-instruct.description": "Qwen2.5 VL 7B Instruct é um modelo multimodal leve que equilibra custo de implantação e capacidade de reconhecimento.",
  "qwen2.5-vl-instruct.description": "Qwen2.5-VL é o mais recente modelo de linguagem e visão da família Qwen.",
  "qwen2.5.description": "Qwen2.5 é o modelo de linguagem de próxima geração da Alibaba, com desempenho robusto em diversos casos de uso.",
  "qwen2.5:0.5b.description": "Qwen2.5 é o modelo de linguagem de próxima geração da Alibaba, com desempenho robusto em diversos casos de uso.",
  "qwen2.5:1.5b.description": "Qwen2.5 é o modelo de linguagem de próxima geração da Alibaba, com desempenho robusto em diversos casos de uso.",
  "qwen2.5:72b.description": "Qwen2.5 é o modelo de linguagem de próxima geração da Alibaba, com desempenho robusto em diversos casos de uso.",
  "qwen2.description": "Qwen2 é o modelo de linguagem de próxima geração da Alibaba, com desempenho robusto em diversos casos de uso.",
  "qwen2:0.5b.description": "Qwen2 é o modelo de linguagem de próxima geração da Alibaba, com desempenho robusto em diversos casos de uso.",
  "qwen2:1.5b.description": "Qwen2 é o modelo de linguagem de próxima geração da Alibaba, com desempenho robusto em diversos casos de uso.",
  "qwen2:72b.description": "Qwen2 é o modelo de linguagem de próxima geração da Alibaba, com desempenho robusto em diversos casos de uso.",
  "qwen3-0.6b.description": "Qwen3 0.6B é um modelo de entrada para raciocínio simples e ambientes altamente restritos.",
  "qwen3-1.7b.description": "Qwen3 1.7B é um modelo ultraleve para implantação em dispositivos e borda.",
  "qwen3-14b.description": "Qwen3 14B é um modelo de porte médio para perguntas e respostas multilíngues e geração de texto.",
  "qwen3-235b-a22b-instruct-2507.description": "Qwen3 235B A22B Instruct 2507 é um modelo de instrução de ponta para uma ampla gama de tarefas de geração e raciocínio.",
  "qwen3-235b-a22b-thinking-2507.description": "Qwen3 235B A22B Thinking 2507 é um modelo de raciocínio ultra grande para tarefas complexas.",
  "qwen3-235b-a22b.description": "Qwen3 é a nova geração do modelo Tongyi Qwen, com grandes avanços em raciocínio, capacidade geral, habilidades de agente e desempenho multilíngue, além de suporte à alternância de modos de raciocínio.",
  "qwen3-30b-a3b-instruct-2507.description": "Qwen3 30B A3B Instruct 2507 é um modelo de instrução de porte médio-grande para geração de alta qualidade e perguntas e respostas.",
  "qwen3-30b-a3b-thinking-2507.description": "Qwen3 30B A3B Thinking 2507 é um modelo de raciocínio de porte médio-grande que equilibra precisão e custo.",
  "qwen3-30b-a3b.description": "Qwen3 30B A3B é um modelo geral de porte médio-grande que equilibra custo e qualidade.",
  "qwen3-32b.description": "Qwen3 32B é adequado para tarefas gerais que exigem maior capacidade de compreensão.",
  "qwen3-4b.description": "Qwen3 4B é adequado para aplicativos de pequeno a médio porte e inferência local.",
  "qwen3-8b.description": "Qwen3 8B é um modelo leve com implantação flexível para cargas de trabalho com alta concorrência.",
  "qwen3-coder-30b-a3b-instruct.description": "Modelo de código Qwen de código aberto. O qwen3-coder-30b-a3b-instruct mais recente é baseado no Qwen3 e oferece fortes habilidades de agente de codificação, uso de ferramentas e interação com o ambiente para programação autônoma, com excelente desempenho de código e sólida capacidade geral.",
  "qwen3-coder-480b-a35b-instruct.description": "Qwen3 Coder 480B A35B Instruct é um modelo de código de ponta para programação multilíngue e compreensão de código complexa.",
  "qwen3-coder-flash.description": "Modelo de código Qwen. A série Qwen3-Coder mais recente é baseada no Qwen3 e oferece fortes habilidades de agente de codificação, uso de ferramentas e interação com o ambiente para programação autônoma, com excelente desempenho de código e sólida capacidade geral.",
  "qwen3-coder-plus.description": "Modelo de código Qwen. A série Qwen3-Coder mais recente é baseada no Qwen3 e oferece fortes habilidades de agente de codificação, uso de ferramentas e interação com o ambiente para programação autônoma, com excelente desempenho de código e sólida capacidade geral.",
  "qwen3-coder:480b.description": "Modelo de alto desempenho da Alibaba com suporte a contexto longo para tarefas de agente e codificação.",
  "qwen3-max-2026-01-23.description": "Os modelos Qwen3 Max apresentam grandes avanços em relação à série 2.5 em capacidade geral, compreensão de chinês/inglês, seguimento de instruções complexas, tarefas subjetivas abertas, habilidade multilíngue e uso de ferramentas, com menos alucinações. A versão mais recente do qwen3-max melhora a programação agente e o uso de ferramentas em relação ao qwen3-max-preview. Este lançamento atinge o SOTA da área e atende a necessidades mais complexas de agentes.",
  "qwen3-max-preview.description": "Modelo Qwen com melhor desempenho para tarefas complexas e de múltiplas etapas. A prévia oferece suporte a raciocínio.",
  "qwen3-max.description": "Os modelos Qwen3 Max apresentam grandes avanços em relação à série 2.5 em capacidade geral, compreensão de chinês/inglês, seguimento de instruções complexas, tarefas subjetivas abertas, capacidade multilíngue e uso de ferramentas, com menos alucinações. O qwen3-max mais recente melhora a programação agente e o uso de ferramentas em relação ao qwen3-max-preview. Esta versão atinge o estado da arte e atende a necessidades mais complexas de agentes.",
  "qwen3-next-80b-a3b-instruct.description": "Modelo Qwen3 de próxima geração, de código aberto e sem raciocínio. Em comparação com a versão anterior (Qwen3-235B-A22B-Instruct-2507), possui melhor compreensão do chinês, raciocínio lógico mais forte e geração de texto aprimorada.",
  "qwen3-next-80b-a3b-thinking.description": "Qwen3 Next 80B A3B Thinking é a versão de raciocínio de ponta para tarefas complexas.",
  "qwen3-omni-flash.description": "Qwen-Omni aceita entradas combinadas de texto, imagens, áudio e vídeo, e gera saídas em texto ou fala. Oferece múltiplos estilos de voz natural, suporte a fala multilíngue e dialetal, e se adapta a casos como redação, reconhecimento visual e assistentes de voz.",
  "qwen3-vl-235b-a22b-instruct.description": "Qwen3 VL 235B A22B Instruct é um modelo multimodal de ponta para compreensão e criação exigentes.",
  "qwen3-vl-235b-a22b-thinking.description": "Qwen3 VL 235B A22B Thinking é a versão de raciocínio de ponta para planejamento e raciocínio multimodal complexos.",
  "qwen3-vl-30b-a3b-instruct.description": "Qwen3 VL 30B A3B Instruct é um modelo multimodal de grande porte que equilibra precisão e desempenho de raciocínio.",
  "qwen3-vl-30b-a3b-thinking.description": "Qwen3 VL 30B A3B Thinking é uma versão de raciocínio profundo para tarefas multimodais complexas.",
  "qwen3-vl-32b-instruct.description": "Qwen3 VL 32B Instruct é um modelo multimodal ajustado por instruções para perguntas e respostas imagem-texto de alta qualidade e criação.",
  "qwen3-vl-32b-thinking.description": "Qwen3 VL 32B Thinking é uma versão multimodal de raciocínio profundo para análise complexa e em cadeia.",
  "qwen3-vl-8b-instruct.description": "Qwen3 VL 8B Instruct é um modelo multimodal leve para perguntas e respostas visuais do dia a dia e integração com aplicativos.",
  "qwen3-vl-8b-thinking.description": "Qwen3 VL 8B Thinking é um modelo multimodal com raciocínio em cadeia para raciocínio visual detalhado.",
  "qwen3-vl-flash.description": "Qwen3 VL Flash: versão leve e de raciocínio rápido para solicitações com baixa latência ou alto volume.",
  "qwen3-vl-plus.description": "Qwen VL é um modelo de geração de texto com compreensão visual. Pode realizar OCR, além de resumir e raciocinar, como extrair atributos de fotos de produtos ou resolver problemas a partir de imagens.",
  "qwen3.description": "Qwen3 é o modelo de linguagem de próxima geração da Alibaba com desempenho robusto em diversos casos de uso.",
  "qwq-32b-preview.description": "QwQ é um modelo de pesquisa experimental da Qwen focado em raciocínio aprimorado.",
  "qwq-32b.description": "QwQ é um modelo de raciocínio da família Qwen. Em comparação com modelos ajustados por instruções padrão, oferece raciocínio e pensamento que aumentam significativamente o desempenho em tarefas complexas. O QwQ-32B é um modelo de raciocínio de porte médio que rivaliza com os principais modelos como DeepSeek-R1 e o1-mini.",
  "qwq-plus.description": "O modelo de raciocínio QwQ treinado com base no Qwen2.5 usa aprendizado por reforço (RL) para melhorar significativamente o raciocínio. Métricas principais em matemática/código (AIME 24/25, LiveCodeBench) e benchmarks gerais (IFEval, LiveBench) atingem o nível completo do DeepSeek-R1.",
  "qwq.description": "QwQ é um modelo de raciocínio da família Qwen. Em comparação com modelos ajustados por instruções padrão, oferece habilidades de pensamento e raciocínio que melhoram significativamente o desempenho em tarefas difíceis. O QwQ-32B é um modelo de porte médio que compete com os principais modelos como DeepSeek-R1 e o1-mini.",
  "qwq_32b.description": "Modelo de raciocínio de porte médio da família Qwen. Em comparação com modelos ajustados por instruções padrão, as habilidades de pensamento e raciocínio do QwQ aumentam significativamente o desempenho em tarefas difíceis.",
  "r1-1776.description": "R1-1776 é uma variante pós-treinada do DeepSeek R1 projetada para fornecer informações factuais sem censura e imparciais.",
  "solar-mini-ja.description": "Solar Mini (Ja) estende o Solar Mini com foco no japonês, mantendo desempenho eficiente e forte em inglês e coreano.",
  "solar-mini.description": "Solar Mini é um LLM compacto que supera o GPT-3.5, com forte capacidade multilíngue suportando inglês e coreano, oferecendo uma solução eficiente e de baixo custo.",
  "solar-pro.description": "Solar Pro é um LLM de alta inteligência da Upstage, focado em seguir instruções em uma única GPU, com pontuações IFEval acima de 80. Atualmente suporta inglês; o lançamento completo está previsto para novembro de 2024 com suporte expandido a idiomas e contexto mais longo.",
  "sonar-deep-research.description": "Deep Research realiza pesquisas abrangentes em nível de especialista e as sintetiza em relatórios acessíveis e acionáveis.",
  "sonar-pro.description": "Produto de busca avançada com fundamentação de pesquisa para consultas complexas e seguimentos.",
  "sonar-reasoning-pro.description": "Produto de busca avançada com fundamentação de pesquisa para consultas complexas e seguimentos.",
  "sonar-reasoning.description": "Produto de busca avançada com fundamentação de pesquisa para consultas complexas e seguimentos.",
  "sonar.description": "Produto leve com fundamentação de busca, mais rápido e barato que o Sonar Pro.",
  "spark-x.description": "Atualizações do X1.5: (1) adiciona modo de pensamento dinâmico controlado pelo campo `thinking`; (2) comprimento de contexto maior com entrada de 64K e saída de 64K; (3) suporte a FunctionCall.",
  "stable-diffusion-3-medium.description": "O mais recente modelo de texto para imagem da Stability AI. Esta versão melhora significativamente a qualidade da imagem, compreensão de texto e diversidade de estilo, interpretando comandos em linguagem natural complexa com mais precisão e gerando imagens mais precisas e diversas.",
  "stable-diffusion-3.5-large-turbo.description": "stable-diffusion-3.5-large-turbo aplica difusão adversarial destilada (ADD) ao stable-diffusion-3.5-large para maior velocidade.",
  "stable-diffusion-3.5-large.description": "stable-diffusion-3.5-large é um modelo MMDiT de texto para imagem com 800 milhões de parâmetros, oferecendo excelente qualidade e alinhamento com prompts, suportando imagens de 1 megapixel e execução eficiente em hardwares de consumo.",
  "stable-diffusion-v1.5.description": "stable-diffusion-v1.5 é inicializado a partir do checkpoint v1.2 e ajustado por 595 mil etapas no conjunto \"laion-aesthetics v2 5+\" com resolução de 512x512, reduzindo o condicionamento de texto em 10% para melhorar a amostragem com orientação livre de classificadores.",
  "stable-diffusion-xl-base-1.0.description": "Um modelo de texto para imagem de código aberto da Stability AI com geração criativa de imagens líder na indústria. Possui forte compreensão de instruções e suporta definições de prompt reverso para geração precisa.",
  "stable-diffusion-xl.description": "stable-diffusion-xl traz melhorias significativas em relação à versão v1.5 e alcança resultados comparáveis aos melhores modelos abertos de texto para imagem. As melhorias incluem um backbone UNet 3x maior, um módulo de refinamento para melhor qualidade de imagem e técnicas de treinamento mais eficientes.",
  "step-1-128k.description": "Equilibra desempenho e custo para cenários gerais.",
  "step-1-256k.description": "Manipulação de contexto extra longo, ideal para análise de documentos extensos.",
  "step-1-32k.description": "Suporta conversas de comprimento médio para uma ampla gama de cenários.",
  "step-1-8k.description": "Modelo pequeno adequado para tarefas leves.",
  "step-1-flash.description": "Modelo de alta velocidade adequado para chat em tempo real.",
  "step-1.5v-mini.description": "Capacidades robustas de compreensão de vídeo.",
  "step-1o-turbo-vision.description": "Compreensão de imagem avançada, superando o 1o em matemática e programação. Menor que o 1o e com saída mais rápida.",
  "step-1o-vision-32k.description": "Compreensão de imagem avançada com desempenho visual superior à série Step-1V.",
  "step-1v-32k.description": "Suporta entradas visuais para interações multimodais mais ricas.",
  "step-1v-8k.description": "Modelo visual pequeno para tarefas básicas de imagem e texto.",
  "step-1x-edit.description": "Este modelo foca em edição de imagens, modificando e aprimorando imagens com base em imagens e textos fornecidos pelo usuário. Suporta múltiplos formatos de entrada, incluindo descrições textuais e imagens de exemplo, gerando edições alinhadas à intenção do usuário.",
  "step-1x-medium.description": "Este modelo oferece geração de imagens robusta a partir de prompts de texto. Com suporte nativo ao chinês, compreende melhor descrições nesse idioma, capturando sua semântica e convertendo-as em recursos visuais para uma geração mais precisa. Produz imagens de alta resolução e qualidade, com suporte a certo grau de transferência de estilo.",
  "step-2-16k-exp.description": "Versão experimental do Step-2 com os recursos mais recentes e atualizações contínuas. Não recomendado para produção.",
  "step-2-16k.description": "Suporta interações com contexto amplo para diálogos complexos.",
  "step-2-mini.description": "Baseado na arquitetura de atenção MFA de próxima geração, oferece resultados semelhantes ao Step-1 com custo muito menor, maior rendimento e menor latência. Lida com tarefas gerais com forte capacidade de programação.",
  "step-2x-large.description": "Modelo de imagem StepFun de nova geração focado em geração de imagens, produzindo imagens de alta qualidade a partir de prompts de texto. Oferece texturas mais realistas e melhor renderização de texto em chinês/inglês.",
  "step-3.description": "Este modelo possui forte percepção visual e raciocínio complexo, lidando com precisão com compreensão de conhecimento entre domínios, análise cruzada de matemática e visão, e uma ampla gama de tarefas visuais do cotidiano.",
  "step-r1-v-mini.description": "Modelo de raciocínio com forte compreensão de imagem que pode processar imagens e textos, gerando texto após raciocínio profundo. Destaca-se em raciocínio visual e oferece desempenho de ponta em matemática, programação e raciocínio textual, com janela de contexto de 100K.",
  "stepfun-ai/step3.description": "Step3 é um modelo de raciocínio multimodal de ponta da StepFun, baseado em arquitetura MoE com 321B de parâmetros totais e 38B ativos. Seu design de ponta a ponta minimiza o custo de decodificação enquanto entrega raciocínio visão-linguagem de alto nível. Com design MFA e AFD, mantém eficiência tanto em aceleradores topo de linha quanto de entrada. Pré-treinado com mais de 20T de tokens de texto e 4T de tokens imagem-texto em vários idiomas. Alcança desempenho líder entre modelos abertos em benchmarks de matemática, código e multimodalidade.",
  "taichu_llm.description": "Treinado com dados massivos de alta qualidade, com melhor compreensão de texto, criação de conteúdo e perguntas e respostas conversacionais.",
  "taichu_o1.description": "taichu_o1 é um modelo de raciocínio de próxima geração que utiliza interação multimodal e aprendizado por reforço para alcançar raciocínio em cadeia semelhante ao humano, suportando simulação de decisões complexas e expondo caminhos de raciocínio com alta precisão, ideal para análise estratégica e pensamento profundo.",
  "taichu_vl.description": "Combina compreensão de imagem, transferência de conhecimento e atribuição lógica, destacando-se em perguntas e respostas imagem-texto.",
  "tencent/Hunyuan-A13B-Instruct.description": "Hunyuan-A13B-Instruct utiliza 80B de parâmetros totais com 13B ativos para igualar modelos maiores. Suporta raciocínio híbrido rápido/lento, compreensão estável de textos longos e desempenho líder em agentes nos benchmarks BFCL-v3 e τ-Bench. Formatos GQA e multi-quant permitem inferência eficiente.",
  "tencent/Hunyuan-MT-7B.description": "O Modelo de Tradução Hunyuan inclui o Hunyuan-MT-7B e o conjunto Hunyuan-MT-Chimera. O Hunyuan-MT-7B é um modelo leve de tradução com 7B de parâmetros, suportando 33 idiomas e 5 línguas minoritárias chinesas. No WMT25, obteve 30 primeiros lugares em 31 pares de idiomas. A Hunyuan da Tencent utiliza um pipeline completo de pré-treinamento, SFT, RL de tradução e RL em conjunto, alcançando desempenho líder em seu porte com implantação eficiente e fácil.",
  "text-embedding-3-large.description": "O modelo de embedding mais avançado para tarefas em inglês e outros idiomas.",
  "text-embedding-3-small.description": "Modelo de embedding de próxima geração eficiente e econômico para recuperação e cenários RAG.",
  "thudm/glm-4-32b.description": "GLM-4-32B-0414 é um modelo bilíngue (chinês/inglês) de 32B com pesos abertos, otimizado para geração de código, chamadas de função e tarefas de agente. Pré-treinado com 15T de dados de alta qualidade e foco em raciocínio, refinado com alinhamento de preferências humanas, amostragem de rejeição e RL. Destaca-se em raciocínio complexo, geração de artefatos e saída estruturada, alcançando desempenho comparável ao GPT-4o e DeepSeek-V3-0324 em múltiplos benchmarks.",
  "thudm/glm-4-32b:free.description": "GLM-4-32B-0414 é um modelo bilíngue (chinês/inglês) de 32B com pesos abertos, otimizado para geração de código, chamadas de função e tarefas de agente. Pré-treinado com 15T de dados de alta qualidade e foco em raciocínio, refinado com alinhamento de preferências humanas, amostragem de rejeição e RL. Destaca-se em raciocínio complexo, geração de artefatos e saída estruturada, alcançando desempenho comparável ao GPT-4o e DeepSeek-V3-0324 em múltiplos benchmarks.",
  "thudm/glm-4-9b-chat.description": "Versão de código aberto do mais recente modelo pré-treinado GLM-4 da Zhipu AI.",
  "thudm/glm-z1-32b.description": "GLM-Z1-32B-0414 é uma variante de raciocínio aprimorada do GLM-4-32B, projetada para resolução de problemas focados em matemática, lógica e código. Aplica RL expandido (preferência pareada específica e geral) para melhorar tarefas complexas de múltiplas etapas. Em comparação com o GLM-4-32B, o Z1 melhora significativamente o raciocínio estruturado e a capacidade em domínios formais.\n\nSuporta etapas de “pensamento” via engenharia de prompt, melhora a coerência em saídas longas e é otimizado para fluxos de trabalho de agentes com contexto longo (via YaRN), chamadas de ferramentas JSON e amostragem refinada para raciocínio estável. Ideal para casos que exigem derivações formais ou de múltiplas etapas cuidadosas.",
  "thudm/glm-z1-rumination-32b.description": "GLM Z1 Rumination 32B é um modelo de raciocínio profundo da série GLM-4-Z1, otimizado para tarefas abertas e complexas que exigem pensamento prolongado. Baseado no glm-4-32b-0414, adiciona estágios extras de RL e alinhamento em múltiplas fases, introduzindo uma capacidade de “ruminação” que simula processamento cognitivo estendido. Isso inclui raciocínio iterativo, análise em múltiplos saltos e fluxos de trabalho com ferramentas como busca, recuperação e síntese com consciência de citação.\n\nDestaca-se em redação científica, análise comparativa e perguntas e respostas complexas. Suporta chamadas de função para primitivas de busca/navegação (`search`, `click`, `open`, `finish`) em pipelines de agentes. O comportamento de ruminação é controlado por laços de múltiplas rodadas com modelagem de recompensa baseada em regras e mecanismos de decisão atrasada, testado em frameworks de pesquisa profunda como o stack interno de alinhamento da OpenAI. Esta variante prioriza profundidade em vez de velocidade.",
  "tngtech/deepseek-r1t-chimera:free.description": "DeepSeek-R1T-Chimera é criado pela fusão do DeepSeek-R1 e DeepSeek-V3 (0324), combinando o raciocínio do R1 com a eficiência de tokens do V3. Baseado no DeepSeek-MoE Transformer e otimizado para geração geral de texto.\n\nFunde pesos pré-treinados para equilibrar raciocínio, eficiência e seguimento de instruções. Lançado sob a licença MIT para uso em pesquisa e comercial.",
  "togethercomputer/StripedHyena-Nous-7B.description": "StripedHyena Nous (7B) oferece maior eficiência computacional por meio de sua arquitetura e estratégia.",
  "tts-1-hd.description": "O mais recente modelo de texto para fala otimizado para qualidade.",
  "tts-1.description": "O mais recente modelo de texto para fala otimizado para velocidade em tempo real.",
  "upstage/SOLAR-10.7B-Instruct-v1.0.description": "Upstage SOLAR Instruct v1 (11B) é ajustado para tarefas de instrução precisas com forte desempenho linguístico.",
  "us.anthropic.claude-3-5-sonnet-20241022-v2:0.description": "Claude 3.5 Sonnet eleva o padrão da indústria, superando concorrentes e o Claude 3 Opus em avaliações amplas, mantendo velocidade e custo intermediários.",
  "us.anthropic.claude-3-7-sonnet-20250219-v1:0.description": "Claude 3.7 Sonnet é o modelo de próxima geração mais rápido da Anthropic. Em comparação com o Claude 3 Haiku, apresenta melhorias em diversas habilidades e supera o modelo principal anterior Claude 3 Opus em muitos benchmarks de inteligência.",
  "us.anthropic.claude-haiku-4-5-20251001-v1:0.description": "Claude Haiku 4.5 é o modelo Haiku mais rápido e inteligente da Anthropic, com velocidade relâmpago e pensamento estendido.",
  "us.anthropic.claude-opus-4-6-v1.description": "Claude Opus 4.6 é o modelo mais inteligente da Anthropic para construção de agentes e programação.",
  "us.anthropic.claude-sonnet-4-5-20250929-v1:0.description": "Claude Sonnet 4.5 é o modelo mais inteligente da Anthropic até hoje.",
  "v0-1.0-md.description": "v0-1.0-md é um modelo legado disponibilizado via API v0.",
  "v0-1.5-lg.description": "v0-1.5-lg é adequado para tarefas avançadas de pensamento ou raciocínio.",
  "v0-1.5-md.description": "v0-1.5-md é adequado para tarefas cotidianas e geração de interfaces.",
  "vercel/v0-1.0-md.description": "Acesse os modelos por trás do v0 para gerar, corrigir e otimizar aplicativos web modernos com raciocínio específico de framework e conhecimento atualizado.",
  "vercel/v0-1.5-md.description": "Acesse os modelos por trás do v0 para gerar, corrigir e otimizar aplicativos web modernos com raciocínio específico de framework e conhecimento atualizado.",
  "volcengine/doubao-seed-code.description": "Doubao-Seed-Code é o LLM da Volcano Engine da ByteDance otimizado para programação agente, com forte desempenho em benchmarks de programação e agentes, com suporte a contexto de 256K.",
  "wan2.2-t2i-flash.description": "Wanxiang 2.2 Speed é o modelo mais recente com melhorias em criatividade, estabilidade e realismo, oferecendo geração rápida e alto valor.",
  "wan2.2-t2i-plus.description": "Wanxiang 2.2 Pro é o modelo mais recente com melhorias em criatividade, estabilidade e realismo, produzindo detalhes mais ricos.",
  "wanx-v1.description": "Modelo base de texto para imagem. Corresponde ao Tongyi Wanxiang 1.0 General.",
  "wanx2.0-t2i-turbo.description": "Excelente em retratos texturizados com velocidade moderada e menor custo. Corresponde ao Tongyi Wanxiang 2.0 Speed.",
  "wanx2.1-t2i-plus.description": "Versão totalmente atualizada com mais detalhes de imagem e velocidade ligeiramente menor. Corresponde ao Tongyi Wanxiang 2.1 Pro.",
  "wanx2.1-t2i-turbo.description": "Versão totalmente atualizada com geração rápida, qualidade geral forte e alto valor. Corresponde ao Tongyi Wanxiang 2.1 Speed.",
  "whisper-1.description": "Modelo geral de reconhecimento de fala com suporte a ASR multilíngue, tradução de fala e identificação de idioma.",
  "wizardlm2.description": "WizardLM 2 é um modelo de linguagem da Microsoft AI que se destaca em diálogos complexos, tarefas multilíngues, raciocínio e assistentes.",
  "wizardlm2:8x22b.description": "WizardLM 2 é um modelo de linguagem da Microsoft AI que se destaca em diálogos complexos, tarefas multilíngues, raciocínio e assistentes.",
  "x-ai/grok-4-fast-non-reasoning.description": "Grok 4 Fast (Sem Raciocínio) é o modelo multimodal de alta vazão e baixo custo da xAI (com suporte a janela de contexto de 2M) para cenários sensíveis à latência e custo que não exigem raciocínio interno. Está ao lado da versão com raciocínio do Grok 4 Fast, e o raciocínio pode ser ativado via parâmetro de API quando necessário. Prompts e respostas podem ser usados pela xAI ou OpenRouter para melhorar modelos futuros.",
  "x-ai/grok-4-fast.description": "Grok 4 Fast é o modelo de alta vazão e baixo custo da xAI (com suporte a janela de contexto de 2M), ideal para casos de uso com alta concorrência e contexto longo.",
  "x-ai/grok-4.1-fast-non-reasoning.description": "Grok 4 Fast (Sem Raciocínio) é o modelo multimodal de alta vazão e baixo custo da xAI (com suporte a janela de contexto de 2M) para cenários sensíveis à latência e custo que não exigem raciocínio interno. Está ao lado da versão com raciocínio do Grok 4 Fast, e o raciocínio pode ser ativado via parâmetro de API quando necessário. Prompts e respostas podem ser usados pela xAI ou OpenRouter para melhorar modelos futuros.",
  "x-ai/grok-4.1-fast.description": "Grok 4 Fast é o modelo de alta vazão e baixo custo da xAI (com suporte a janela de contexto de 2M), ideal para casos de uso com alta concorrência e contexto longo.",
  "x-ai/grok-4.description": "Grok 4 é o modelo de raciocínio de ponta da xAI com forte capacidade de raciocínio e multimodalidade.",
  "x-ai/grok-code-fast-1.description": "Grok Code Fast 1 é o modelo de código rápido da xAI com saída legível e amigável para engenharia.",
  "xai/grok-2-vision.description": "Grok 2 Vision se destaca em tarefas visuais, oferecendo desempenho de ponta em raciocínio visual matemático (MathVista) e perguntas e respostas em documentos (DocVQA). Lida com documentos, gráficos, tabelas, capturas de tela e fotos.",
  "xai/grok-2.description": "Grok 2 é um modelo de fronteira com raciocínio de ponta, forte desempenho em chat, codificação e raciocínio, superando Claude 3.5 Sonnet e GPT-4 Turbo no LMSYS.",
  "xai/grok-3-fast.description": "Modelo de ponta da xAI que se destaca em casos de uso corporativos como extração de dados, codificação e sumarização, com profundo conhecimento em finanças, saúde, direito e ciência. A variante rápida roda em infraestrutura mais ágil para respostas muito mais rápidas com maior custo por token.",
  "xai/grok-3-mini-fast.description": "Modelo leve da xAI que pensa antes de responder, ideal para tarefas simples ou baseadas em lógica sem necessidade de conhecimento profundo. Rastros de raciocínio brutos estão disponíveis. A variante rápida roda em infraestrutura mais ágil para respostas muito mais rápidas com maior custo por token.",
  "xai/grok-3-mini.description": "Modelo leve da xAI que pensa antes de responder, ideal para tarefas simples ou baseadas em lógica sem necessidade de conhecimento profundo. Rastros de raciocínio brutos estão disponíveis.",
  "xai/grok-3.description": "Modelo de ponta da xAI que se destaca em casos de uso corporativos como extração de dados, codificação e sumarização, com profundo conhecimento em finanças, saúde, direito e ciência.",
  "xai/grok-4.description": "O mais novo modelo de ponta da xAI com desempenho incomparável em linguagem natural, matemática e raciocínio — um modelo versátil ideal.",
  "yi-large-fc.description": "Baseado no yi-large com chamadas de ferramentas aprimoradas, adequado para cenários de agentes e fluxos de trabalho.",
  "yi-large-preview.description": "Uma versão inicial; recomenda-se o uso do yi-large (mais recente).",
  "yi-large-rag.description": "Serviço avançado baseado no yi-large, combinando recuperação e geração para respostas precisas com busca em tempo real na web.",
  "yi-large-turbo.description": "Valor e desempenho excepcionais, ajustado para um forte equilíbrio entre qualidade, velocidade e custo.",
  "yi-large.description": "Novo modelo com 100 bilhões de parâmetros com forte desempenho em perguntas e respostas e geração de texto.",
  "yi-lightning-lite.description": "Versão leve; recomenda-se o uso do yi-lightning.",
  "yi-lightning.description": "Modelo de alto desempenho mais recente com inferência mais rápida e saída de alta qualidade.",
  "yi-medium-200k.description": "Modelo de contexto longo com 200K para compreensão e geração profunda de textos longos.",
  "yi-medium.description": "Modelo de porte médio ajustado com capacidade e valor equilibrados, otimizado para seguir instruções.",
  "yi-spark.description": "Modelo compacto e rápido com capacidades reforçadas em matemática e codificação.",
  "yi-vision-v2.description": "Modelo de visão para tarefas complexas com forte compreensão e análise de múltiplas imagens.",
  "yi-vision.description": "Modelo de visão para tarefas complexas com forte compreensão e análise de imagens.",
  "z-ai/glm-4.5-air.description": "GLM 4.5 Air é uma variante leve do GLM 4.5 para cenários sensíveis a custo, mantendo forte raciocínio.",
  "z-ai/glm-4.5.description": "GLM 4.5 é o modelo de ponta da Z.AI com raciocínio híbrido otimizado para engenharia e tarefas com contexto longo.",
  "z-ai/glm-4.6.description": "GLM 4.6 é o modelo de ponta da Z.AI com comprimento de contexto estendido e capacidade de codificação.",
  "z-ai/glm-4.7.description": "GLM-4.7 é o mais novo modelo de ponta da Zhipu, oferecendo capacidades gerais aprimoradas, respostas mais simples e naturais, e uma experiência de escrita mais imersiva.",
  "zai-org/GLM-4.5-Air.description": "GLM-4.5-Air é um modelo base para aplicações com agentes, utilizando uma arquitetura Mixture-of-Experts. Ele é otimizado para uso de ferramentas, navegação na web, engenharia de software e codificação frontend, e integra-se com agentes de código como Claude Code e Roo Code. Utiliza raciocínio híbrido para lidar tanto com cenários complexos quanto com situações do dia a dia.",
  "zai-org/GLM-4.5.description": "GLM-4.5 é um modelo base desenvolvido para aplicações com agentes, utilizando uma arquitetura Mixture-of-Experts. É profundamente otimizado para uso de ferramentas, navegação na web, engenharia de software e codificação frontend, e integra-se com agentes de código como Claude Code e Roo Code. Utiliza raciocínio híbrido para lidar com raciocínios complexos e situações cotidianas.",
  "zai-org/GLM-4.5V.description": "GLM-4.5V é o mais recente VLM da Zhipu AI, baseado no modelo de texto principal GLM-4.5-Air (106B no total, 12B ativos), com uma arquitetura MoE que oferece alto desempenho a um custo reduzido. Segue a linha de desenvolvimento do GLM-4.1V-Thinking e adiciona 3D-RoPE para melhorar o raciocínio espacial em 3D. Otimizado por meio de pré-treinamento, SFT e RL, lida com imagens, vídeos e documentos longos, e está entre os melhores modelos abertos em 41 benchmarks multimodais públicos. Um modo de alternância de raciocínio permite ao usuário equilibrar velocidade e profundidade.",
  "zai-org/GLM-4.6.description": "Comparado ao GLM-4.5, o GLM-4.6 expande o contexto de 128K para 200K para tarefas de agentes mais complexas. Apresenta pontuações mais altas em benchmarks de código e desempenho superior em aplicações reais como Claude Code, Cline, Roo Code e Kilo Code, incluindo melhor geração de páginas frontend. O raciocínio foi aprimorado e o uso de ferramentas é suportado durante o processo, fortalecendo a capacidade geral. Integra-se melhor a frameworks de agentes, melhora agentes de busca/ferramentas e apresenta estilo de escrita mais natural e preferido por humanos, além de maior naturalidade em simulações de papéis.",
  "zai/glm-4.5-air.description": "GLM-4.5 e GLM-4.5-Air são nossos modelos principais mais recentes para aplicações com agentes, ambos utilizando MoE. O GLM-4.5 possui 355B no total e 32B ativos por passagem; o GLM-4.5-Air é mais enxuto, com 106B no total e 12B ativos.",
  "zai/glm-4.5.description": "A série GLM-4.5 foi projetada para agentes. O modelo principal GLM-4.5 combina raciocínio, codificação e habilidades de agente com 355B de parâmetros totais (32B ativos) e oferece modos de operação duplos como um sistema de raciocínio híbrido.",
  "zai/glm-4.5v.description": "GLM-4.5V é baseado no GLM-4.5-Air, herdando técnicas comprovadas do GLM-4.1V-Thinking e escalando com uma robusta arquitetura MoE de 106B parâmetros.",
  "zenmux/auto.description": "O roteamento automático do ZenMux seleciona o modelo com melhor desempenho e custo-benefício entre as opções suportadas, com base na sua solicitação."
}
