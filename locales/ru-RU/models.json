{
  "01-ai/yi-1.5-34b-chat.description": "Последняя открытая модель 01.AI с 34 миллиардами параметров, адаптированная для различных сценариев диалога, обученная на высококачественных данных и согласованная с человеческими предпочтениями.",
  "01-ai/yi-1.5-9b-chat.description": "Последняя открытая модель 01.AI с 9 миллиардами параметров, адаптированная для различных сценариев диалога, обученная на высококачественных данных и согласованная с человеческими предпочтениями.",
  "360/deepseek-r1.description": "DeepSeek-R1, развернутая компанией 360, использует масштабное обучение с подкреплением на этапе дообучения, значительно улучшая логическое мышление при минимальной разметке. Сопоставима с OpenAI o1 в задачах по математике, программированию и языковому рассуждению.",
  "360gpt-pro-trans.description": "Специализированная модель для перевода, глубоко дообученная для достижения передового качества перевода.",
  "360gpt-pro.description": "360GPT Pro — ключевая модель ИИ от 360 с эффективной обработкой текста для различных задач обработки естественного языка, поддерживает понимание длинных текстов и многотуровой диалог.",
  "360gpt-turbo-responsibility-8k.description": "360GPT Turbo Responsibility 8K делает акцент на семантической безопасности и ответственности в чувствительных к контенту приложениях, обеспечивая точный и надежный пользовательский опыт.",
  "360gpt-turbo.description": "360GPT Turbo обеспечивает высокую вычислительную и диалоговую производительность с отличным пониманием семантики и эффективной генерацией, идеально подходит для бизнеса и разработчиков.",
  "360gpt2-o1.description": "360gpt2-o1 формирует цепочку рассуждений с помощью древовидного поиска, механизма рефлексии и обучения с подкреплением, позволяя модели к саморефлексии и самокоррекции.",
  "360gpt2-pro.description": "360GPT2 Pro — продвинутая модель обработки естественного языка от 360 с выдающимися возможностями генерации и понимания текста, особенно в творческих задачах, включая сложные преобразования и ролевые сценарии.",
  "360zhinao2-o1.description": "360zhinao2-o1 формирует цепочку рассуждений с помощью древовидного поиска, механизма рефлексии и обучения с подкреплением, позволяя модели к саморефлексии и самокоррекции.",
  "4.0Ultra.description": "Spark Ultra — самая мощная модель в серии Spark, улучшает понимание текста и его резюмирование, а также расширяет возможности веб-поиска. Это комплексное решение для повышения продуктивности на рабочем месте и точности ответов, позиционирующееся как передовой интеллектуальный продукт.",
  "AnimeSharp.description": "AnimeSharp (также известная как \"4x-AnimeSharp\") — это открытая модель суперразрешения на основе ESRGAN от Kim2091, предназначенная для увеличения и повышения резкости изображений в аниме-стиле. В феврале 2022 года была переименована из \"4x-TextSharpV1\"; изначально также предназначалась для текстовых изображений, но была глубоко оптимизирована под аниме-контент.",
  "Baichuan2-Turbo.description": "Использует расширение поиска для подключения модели к отраслевым и веб-знаниям. Поддерживает загрузку PDF/Word и ввод URL для своевременного, всестороннего поиска и профессионального, точного вывода.",
  "Baichuan3-Turbo-128k.description": "С ультрадлинным контекстным окном на 128K, оптимизирована для частых корпоративных сценариев с существенным приростом ценности. По сравнению с Baichuan2, генерация контента улучшена на 20%, ответы на вопросы — на 17%, ролевые сценарии — на 40%. Общая производительность выше, чем у GPT-3.5.",
  "Baichuan3-Turbo.description": "Оптимизирована для частых корпоративных сценариев с существенным приростом ценности. По сравнению с Baichuan2, генерация контента улучшена на 20%, ответы на вопросы — на 17%, ролевые сценарии — на 40%. Общая производительность выше, чем у GPT-3.5.",
  "Baichuan4-Air.description": "Одна из лучших моделей в Китае, превосходит ведущие зарубежные модели в задачах на китайском языке, таких как энциклопедические знания, длинные тексты и творческая генерация. Также обладает передовыми мультимодальными возможностями с высокими результатами на авторитетных бенчмарках.",
  "Baichuan4-Turbo.description": "Одна из лучших моделей в Китае, превосходит ведущие зарубежные модели в задачах на китайском языке, таких как энциклопедические знания, длинные тексты и творческая генерация. Также обладает передовыми мультимодальными возможностями с высокими результатами на авторитетных бенчмарках.",
  "Baichuan4.description": "Лидер по производительности среди отечественных моделей, превосходит ведущие зарубежные модели в задачах на китайском языке, таких как энциклопедические знания, длинные тексты и творческая генерация. Также предлагает передовые мультимодальные возможности и высокие результаты на бенчмарках.",
  "ByteDance-Seed/Seed-OSS-36B-Instruct.description": "Seed-OSS — семейство открытых LLM от ByteDance Seed, разработанных для обработки длинного контекста, логического мышления, агентных задач и общих способностей. Seed-OSS-36B-Instruct — это модель с 36 миллиардами параметров, адаптированная под инструкции, с нативной поддержкой ультрадлинного контекста для обработки больших документов или кодовых баз. Оптимизирована для логики, генерации кода и агентных задач (использование инструментов), сохраняя при этом общую универсальность. Ключевая особенность — \"Бюджет мышления\", позволяющий гибко управлять длиной рассуждений для повышения эффективности.",
  "DeepSeek-R1-Distill-Llama-70B.description": "DeepSeek R1, более крупная и умная модель из набора DeepSeek, дистиллирована в архитектуру Llama 70B. Бенчмарки и оценки людей показывают, что она умнее базовой Llama 70B, особенно в задачах по математике и точности фактов.",
  "DeepSeek-R1-Distill-Qwen-1.5B.description": "Дистиллированная модель DeepSeek-R1 на основе Qwen2.5-Math-1.5B. Обучение с подкреплением и данные холодного старта оптимизируют производительность в логических задачах, устанавливая новые мультизадачные бенчмарки среди открытых моделей.",
  "DeepSeek-R1-Distill-Qwen-14B.description": "Модели DeepSeek-R1-Distill дообучены на основе открытых моделей с использованием выборок, сгенерированных DeepSeek-R1.",
  "DeepSeek-R1-Distill-Qwen-32B.description": "Модели DeepSeek-R1-Distill дообучены на основе открытых моделей с использованием выборок, сгенерированных DeepSeek-R1.",
  "DeepSeek-R1-Distill-Qwen-7B.description": "Дистиллированная модель DeepSeek-R1 на основе Qwen2.5-Math-7B. Обучение с подкреплением и данные холодного старта оптимизируют производительность в логических задачах, устанавливая новые мультизадачные бенчмарки среди открытых моделей.",
  "DeepSeek-R1.description": "DeepSeek-R1 применяет масштабное обучение с подкреплением на этапе дообучения, значительно улучшая логическое мышление при минимальной разметке. Сопоставима с OpenAI o1 в задачах по математике, программированию и языковому рассуждению.",
  "DeepSeek-V3-1.description": "DeepSeek V3.1 — модель нового поколения для логических задач с улучшенными возможностями сложного рассуждения и цепочек размышлений, подходящая для глубокого анализа.",
  "DeepSeek-V3-Fast.description": "Провайдер: sophnet. DeepSeek V3 Fast — высокоэффективная версия DeepSeek V3 0324, с полной точностью (без квантования), улучшенной производительностью в коде и математике и более быстрыми ответами.",
  "DeepSeek-V3.1-Fast.description": "DeepSeek V3.1 Fast — высокоэффективный вариант DeepSeek V3.1. Гибридный режим мышления: через шаблоны чата одна модель поддерживает как мышление, так и немышление. Умное использование инструментов: дообучение улучшает производительность в агентных задачах и при использовании инструментов.",
  "DeepSeek-V3.1-Think.description": "Режим мышления DeepSeek-V3.1: новая гибридная модель рассуждения с режимами мышления и немышления, более эффективная, чем DeepSeek-R1-0528. Оптимизации после обучения значительно улучшают использование инструментов и выполнение агентных задач.",
  "DeepSeek-V3.description": "DeepSeek-V3 — модель MoE, разработанная DeepSeek. Превосходит другие открытые модели, такие как Qwen2.5-72B и Llama-3.1-405B, по многим бенчмаркам и конкурирует с ведущими закрытыми моделями, такими как GPT-4o и Claude 3.5 Sonnet.",
  "Doubao-lite-128k.description": "Doubao-lite обеспечивает сверхбыстрые ответы и отличное соотношение цены и качества, предлагая гибкие варианты для различных сценариев. Поддерживает контекст объемом 128K для вывода и дообучения.",
  "Doubao-lite-32k.description": "Doubao-lite обеспечивает сверхбыстрые ответы и отличное соотношение цены и качества, предлагая гибкие варианты для различных сценариев. Поддерживает контекст объемом 32K для вывода и дообучения.",
  "Doubao-lite-4k.description": "Doubao-lite обеспечивает сверхбыстрые ответы и отличное соотношение цены и качества, предлагая гибкие варианты для различных сценариев. Поддерживает контекст объемом 4K для вывода и дообучения.",
  "Doubao-pro-128k.description": "Флагманская модель с наилучшей производительностью для сложных задач, превосходно справляется с вопросно-ответными задачами, суммированием, созданием контента, классификацией и ролевыми сценариями. Поддерживает контекст объемом 128K для вывода и дообучения.",
  "Doubao-pro-32k.description": "Флагманская модель с наилучшей производительностью для сложных задач, превосходно справляется с вопросно-ответными задачами, суммированием, созданием контента, классификацией и ролевыми сценариями. Поддерживает контекст объемом 32K для вывода и дообучения.",
  "Doubao-pro-4k.description": "Флагманская модель с наилучшей производительностью для сложных задач, превосходно справляется с вопросно-ответными задачами, суммированием, созданием контента, классификацией и ролевыми сценариями. Поддерживает контекст объемом 4K для вывода и дообучения.",
  "DreamO.description": "DreamO — это модель для настройки изображений с открытым исходным кодом, совместно разработанная ByteDance и Пекинским университетом. Она использует единую архитектуру для поддержки многозадачной генерации изображений. Благодаря эффективному композиционному моделированию DreamO создает высоко согласованные и персонализированные изображения на основе заданных пользователем параметров, таких как личность, объект, стиль, фон и другие условия.",
  "ERNIE-3.5-128K.description": "Флагманская LLM-модель от Baidu, обученная на обширных корпусах китайского и английского языков, обладающая высокой универсальностью для чата, создания контента и использования плагинов. Поддерживает автоматическую интеграцию плагина Baidu Search для получения актуальных ответов.",
  "ERNIE-3.5-8K-Preview.description": "Флагманская LLM-модель от Baidu, обученная на обширных корпусах китайского и английского языков, обладающая высокой универсальностью для чата, создания контента и использования плагинов. Поддерживает автоматическую интеграцию плагина Baidu Search для получения актуальных ответов.",
  "ERNIE-3.5-8K.description": "Флагманская LLM-модель от Baidu, обученная на обширных корпусах китайского и английского языков, обладающая высокой универсальностью для чата, создания контента и использования плагинов. Поддерживает автоматическую интеграцию плагина Baidu Search для получения актуальных ответов.",
  "ERNIE-4.0-8K-Latest.description": "Флагманская сверхмощная LLM-модель от Baidu с комплексными улучшениями по сравнению с ERNIE 3.5, подходящая для сложных задач в различных областях. Поддерживает интеграцию плагина Baidu Search для получения актуальных ответов.",
  "ERNIE-4.0-8K-Preview.description": "Флагманская сверхмощная LLM-модель от Baidu с комплексными улучшениями по сравнению с ERNIE 3.5, подходящая для сложных задач в различных областях. Поддерживает интеграцию плагина Baidu Search для получения актуальных ответов.",
  "ERNIE-4.0-Turbo-8K-Latest.description": "Флагманская сверхмощная LLM-модель от Baidu с высокой общей производительностью для сложных задач. Поддерживает интеграцию плагина Baidu Search для получения актуальных ответов. Превосходит ERNIE 4.0.",
  "ERNIE-4.0-Turbo-8K-Preview.description": "Флагманская сверхмощная LLM-модель от Baidu с высокой общей производительностью для сложных задач. Поддерживает интеграцию плагина Baidu Search для получения актуальных ответов. Превосходит ERNIE 4.0.",
  "ERNIE-Character-8K.description": "Отраслевая LLM-модель от Baidu для игровых NPC, клиентской поддержки и ролевых сценариев. Обеспечивает более четкое соответствие персонажу, лучшее следование инструкциям и улучшенное логическое мышление.",
  "ERNIE-Lite-Pro-128K.description": "Легковесная LLM-модель от Baidu, сочетающая качество и производительность вывода. Превосходит ERNIE Lite и подходит для ускорителей с низким уровнем вычислений.",
  "ERNIE-Speed-128K.description": "Последняя высокопроизводительная LLM-модель от Baidu (2024), обладающая сильными универсальными способностями. Подходит в качестве основы для дообучения под конкретные сценарии, с отличной логикой рассуждений.",
  "ERNIE-Speed-Pro-128K.description": "Последняя высокопроизводительная LLM-модель от Baidu (2024), обладающая сильными универсальными способностями. Превосходит ERNIE Speed и подходит в качестве основы для дообучения с отличной логикой рассуждений.",
  "FLUX-1.1-pro.description": "FLUX.1.1 Pro",
  "FLUX.1-Kontext-dev.description": "FLUX.1-Kontext-dev — это мультимодальная модель генерации и редактирования изображений от Black Forest Labs, основанная на архитектуре Rectified Flow Transformer с 12 миллиардами параметров. Она предназначена для генерации, реконструкции, улучшения и редактирования изображений в заданных контекстных условиях. Модель сочетает управляемую генерацию диффузионных моделей с контекстным моделированием Transformer, обеспечивая высококачественные результаты для задач, таких как дорисовка, расширение изображения и реконструкция визуальных сцен.",
  "FLUX.1-Kontext-pro.description": "FLUX.1 Kontext [pro]",
  "FLUX.1-dev.description": "FLUX.1-dev — это мультимодальная языковая модель с открытым исходным кодом (MLLM) от Black Forest Labs, оптимизированная для задач, связанных с изображениями и текстом. Она объединяет понимание и генерацию изображений/текста. Построена на базе передовых LLM (например, Mistral-7B), использует тщательно разработанный визуальный энкодер и многоступенчатую настройку инструкций для обеспечения мультимодальной координации и сложного логического вывода.",
  "Gryphe/MythoMax-L2-13b.description": "MythoMax-L2 (13B) — инновационная модель для различных областей и сложных задач.",
  "HelloMeme.description": "HelloMeme — это ИИ-инструмент, который создает мемы, GIF-файлы или короткие видео на основе предоставленных вами изображений или движений. Не требует навыков рисования или программирования — достаточно эталонного изображения, чтобы получить веселый, привлекательный и стилистически согласованный контент.",
  "HiDream-I1-Full.description": "HiDream-E1-Full — это мультимодальная модель редактирования изображений с открытым исходным кодом от HiDream.ai, основанная на передовой архитектуре Diffusion Transformer и мощном языковом понимании (встроенная LLaMA 3.1-8B-Instruct). Поддерживает генерацию изображений на основе естественного языка, перенос стиля, локальное редактирование и перерисовку, с отличным пониманием и выполнением задач, связанных с изображениями и текстом.",
  "HunyuanDiT-v1.2-Diffusers-Distilled.description": "hunyuandit-v1.2-distilled — это легковесная модель преобразования текста в изображение, оптимизированная с помощью дистилляции для быстрой генерации высококачественных изображений. Особенно подходит для сред с ограниченными ресурсами и задач в реальном времени.",
  "InstantCharacter.description": "InstantCharacter — это модель персонализированной генерации персонажей без необходимости настройки, выпущенная Tencent AI в 2025 году. Она обеспечивает высокую точность и согласованность персонажей в различных сценариях. Модель может создать персонажа по одному эталонному изображению и гибко переносить его в разные стили, действия и фоны.",
  "InternVL2-8B.description": "InternVL2-8B — это мощная модель визуально-языкового понимания, поддерживающая мультимодальную обработку изображений и текста, точно распознающая содержимое изображений и генерирующая соответствующие описания или ответы.",
  "InternVL2.5-26B.description": "InternVL2.5-26B — это мощная модель визуально-языкового понимания, поддерживающая мультимодальную обработку изображений и текста, точно распознающая содержимое изображений и генерирующая соответствующие описания или ответы.",
  "Kolors.description": "Kolors — это модель преобразования текста в изображение, разработанная командой Kuaishou Kolors. Обученная на миллиардах параметров, она обладает заметными преимуществами в визуальном качестве, понимании китайской семантики и отображении текста.",
  "Kwai-Kolors/Kolors.description": "Kolors — это крупномасштабная латентно-диффузионная модель преобразования текста в изображение от команды Kuaishou Kolors. Обученная на миллиардах пар текст-изображение, она превосходит в визуальном качестве, точности сложной семантики и отображении текста на китайском и английском языках, с сильным пониманием и генерацией китайского контента.",
  "Kwaipilot/KAT-Dev.description": "KAT-Dev (32B) — это модель с открытым исходным кодом для задач программной инженерии. Она достигает 62,4% успешности на SWE-Bench Verified, занимая 5-е место среди открытых моделей. Оптимизирована с помощью промежуточного обучения, SFT и RL для автодополнения кода, исправления ошибок и рецензирования кода.",
  "Llama-3.2-11B-Vision-Instruct.description": "Мощное логическое мышление по изображениям высокого разрешения, подходит для приложений визуального понимания.",
  "Llama-3.2-90B-Vision-Instruct\t.description": "Продвинутое логическое мышление по изображениям для приложений визуального понимания с агентами.",
  "Meta-Llama-3-3-70B-Instruct.description": "Llama 3.3 70B — это универсальная модель Transformer для задач чата и генерации.",
  "Meta-Llama-3.1-405B-Instruct.description": "Llama 3.1 — модель, настроенная на выполнение инструкций, оптимизированная для многоязычного чата, демонстрирующая высокие результаты на отраслевых бенчмарках среди открытых и закрытых моделей.",
  "Meta-Llama-3.1-70B-Instruct.description": "Llama 3.1 — модель, настроенная на выполнение инструкций, оптимизированная для многоязычного чата, демонстрирующая высокие результаты на отраслевых бенчмарках среди открытых и закрытых моделей.",
  "Meta-Llama-3.1-8B-Instruct.description": "Llama 3.1 — модель, настроенная на выполнение инструкций, оптимизированная для многоязычного чата, демонстрирующая высокие результаты на отраслевых бенчмарках среди открытых и закрытых моделей.",
  "Meta-Llama-3.2-1B-Instruct.description": "Передовая компактная языковая модель с высоким уровнем понимания языка, отличной логикой и генерацией текста.",
  "Meta-Llama-3.2-3B-Instruct.description": "Передовая компактная языковая модель с высоким уровнем понимания языка, отличной логикой и генерацией текста.",
  "Meta-Llama-3.3-70B-Instruct.description": "Llama 3.3 — самая продвинутая многоязычная модель Llama с открытым исходным кодом, обеспечивающая производительность, близкую к 405B, при очень низкой стоимости. Основана на архитектуре Transformer и улучшена с помощью SFT и RLHF для повышения полезности и безопасности. Версия, настроенная на выполнение инструкций, оптимизирована для многоязычного чата и превосходит многие открытые и закрытые модели в отраслевых тестах. Дата отсечения знаний: декабрь 2023 года.",
  "Meta-Llama-4-Maverick-17B-128E-Instruct-FP8.description": "Llama 4 Maverick — это крупная модель MoE с эффективной активацией экспертов для высокой производительности в логических задачах.",
  "MiniMax-M1.description": "Новая внутренняя модель рассуждений с поддержкой 80K цепочек размышлений и 1M входных токенов, обеспечивающая производительность на уровне ведущих мировых моделей.",
  "MiniMax-M2-Stable.description": "Создана для эффективного программирования и работы агентов, с повышенной параллельностью для коммерческого использования.",
  "MiniMax-M2.1-Lightning.description": "Мощные многоязычные возможности программирования и всесторонне улучшенный опыт разработки. Быстрее и эффективнее.",
  "MiniMax-M2.1.description": "MiniMax-M2.1 — это флагманская модель с открытым исходным кодом от MiniMax, ориентированная на решение сложных задач из реального мира. Её ключевые преимущества — поддержка многозадачного программирования и способность выступать в роли интеллектуального агента.",
  "MiniMax-M2.description": "Создан специально для эффективного программирования и рабочих процессов с агентами",
  "MiniMax-Text-01.description": "MiniMax-01 представляет масштабное линейное внимание, выходящее за рамки классических трансформеров, с 456B параметрами и 45.9B активируемыми за проход. Обеспечивает производительность высшего уровня и поддерживает до 4M токенов контекста (в 32 раза больше GPT-4o, в 20 раз больше Claude-3.5-Sonnet).",
  "MiniMaxAI/MiniMax-M1-80k.description": "MiniMax-M1 — это модель рассуждений с открытыми весами, использующая гибридное внимание, с общим числом параметров 456B и ~45.9B активных на токен. Поддерживает 1M контекста и использует Flash Attention для снижения FLOPs на 75% при генерации 100K токенов по сравнению с DeepSeek R1. Благодаря архитектуре MoE, CISPO и обучению с подкреплением на гибридном внимании достигает лидирующих результатов в задачах рассуждения на длинных входах и реальных инженерных задачах.",
  "MiniMaxAI/MiniMax-M2.description": "MiniMax-M2 переопределяет эффективность агентов. Это компактная, быстрая и экономичная модель MoE с 230B общих и 10B активных параметров, созданная для задач программирования и агентов высшего уровня при сохранении сильного общего интеллекта. Имея всего 10B активных параметров, она сопоставима с гораздо более крупными моделями, что делает её идеальной для высокоэффективных приложений.",
  "Moonshot-Kimi-K2-Instruct.description": "1T общих параметров и 32B активных. Среди моделей без размышлений — одна из лучших по знаниям, математике и программированию, а также сильнее в общих задачах агентов. Оптимизирована для рабочих нагрузок агентов: может действовать, а не только отвечать. Идеальна для импровизационного общения, общего чата и агентных сценариев как модель рефлекторного уровня без длительного размышления.",
  "NousResearch/Nous-Hermes-2-Mixtral-8x7B-DPO.description": "Nous Hermes 2 - Mixtral 8x7B-DPO (46.7B) — высокоточная модель инструкций для сложных вычислений.",
  "OmniConsistency.description": "OmniConsistency повышает согласованность стиля и обобщающую способность в задачах преобразования изображений, внедряя масштабные Diffusion Transformers (DiTs) и парные стилизованные данные, предотвращая деградацию стиля.",
  "PaddlePaddle/PaddleOCR-VL-1.5.description": "PaddleOCR-VL-1.5 — обновлённая версия серии PaddleOCR-VL, достигшая точности 94,5% на бенчмарке OmniDocBench v1.5 по разбору документов, превзойдя ведущие универсальные и специализированные модели. Впервые реализована поддержка локализации элементов документа с нерегулярными рамками, что позволяет эффективно обрабатывать отсканированные, наклонённые и снятые с экрана изображения.",
  "Phi-3-medium-128k-instruct.description": "Та же модель Phi-3-medium с увеличенным окном контекста для RAG или few-shot подсказок.",
  "Phi-3-medium-4k-instruct.description": "Модель с 14B параметрами, обеспечивающая более высокое качество, чем Phi-3-mini, с акцентом на данные, требующие глубокого рассуждения.",
  "Phi-3-mini-128k-instruct.description": "Та же модель Phi-3-mini с увеличенным окном контекста для RAG или few-shot подсказок.",
  "Phi-3-mini-4k-instruct.description": "Наименьшая модель в семействе Phi-3, оптимизированная для качества и низкой задержки.",
  "Phi-3-small-128k-instruct.description": "Та же модель Phi-3-small с увеличенным окном контекста для RAG или few-shot подсказок.",
  "Phi-3-small-8k-instruct.description": "Модель с 7B параметрами, обеспечивающая более высокое качество, чем Phi-3-mini, с акцентом на данные, требующие глубокого рассуждения.",
  "Phi-3.5-mini-instruct.description": "Обновлённая версия модели Phi-3-mini.",
  "Phi-3.5-vision-instrust.description": "Обновлённая версия модели Phi-3-vision.",
  "Pro/MiniMaxAI/MiniMax-M2.1.description": "MiniMax-M2.1 — это модель большого языка с открытым исходным кодом, оптимизированная для агентных возможностей. Она превосходно справляется с программированием, использованием инструментов, следованием инструкциям и долгосрочным планированием. Модель поддерживает многоязычную разработку программного обеспечения и выполнение сложных многошаговых рабочих процессов, набирая 74.0 балла на SWE-bench Verified и превосходя Claude Sonnet 4.5 в многоязычных сценариях.",
  "Pro/Qwen/Qwen2-7B-Instruct.description": "Qwen2-7B-Instruct — это 7B модель с настройкой на инструкции из серии Qwen2. Использует архитектуру Transformer с SwiGLU, смещением QKV внимания и групповым вниманием по запросу, обрабатывает большие входные данные. Демонстрирует высокие результаты в понимании языка, генерации, многоязычных задачах, программировании, математике и рассуждении, превосходя большинство открытых моделей и конкурируя с закрытыми.",
  "Pro/Qwen/Qwen2.5-7B-Instruct.description": "Qwen2.5-7B-Instruct входит в последнюю серию LLM от Alibaba Cloud. Модель на 7B параметров демонстрирует значительный прогресс в программировании и математике, поддерживает более 29 языков и улучшает следование инструкциям, понимание структурированных данных и структурированный вывод (особенно JSON).",
  "Pro/Qwen/Qwen2.5-Coder-7B-Instruct.description": "Qwen2.5-Coder-7B-Instruct — последняя модель от Alibaba Cloud, ориентированная на программирование. Построена на базе Qwen2.5 и обучена на 5.5T токенов, значительно улучшает генерацию кода, рассуждение и исправление ошибок, сохраняя при этом сильные стороны в математике и общем интеллекте, обеспечивая надёжную основу для кодирующих агентов.",
  "Pro/Qwen/Qwen2.5-VL-7B-Instruct.description": "Qwen2.5-VL — новая модель Qwen для задач зрения и языка с сильным визуальным пониманием. Анализирует текст, графики и макеты на изображениях, понимает длинные видео и события, поддерживает рассуждение и использование инструментов, привязку объектов в разных форматах и структурированный вывод. Улучшает динамическое разрешение и обучение частоте кадров для понимания видео и повышает эффективность визуального энкодера.",
  "Pro/THUDM/GLM-4.1V-9B-Thinking.description": "GLM-4.1V-9B-Thinking — это открытая мультимодальная модель от Zhipu AI и лаборатории KEG Университета Цинхуа, разработанная для сложного мультимодального мышления. Построена на базе GLM-4-9B-0414, добавляет цепочку размышлений и обучение с подкреплением для значительного улучшения межмодального рассуждения и стабильности.",
  "Pro/THUDM/glm-4-9b-chat.description": "GLM-4-9B-Chat — это открытая модель GLM-4 от Zhipu AI. Обеспечивает высокую производительность в семантике, математике, рассуждении, коде и знаниях. Помимо многотурового чата, поддерживает веб-браузинг, выполнение кода, вызов пользовательских инструментов и рассуждение над длинными текстами. Поддерживает 26 языков (включая китайский, английский, японский, корейский, немецкий). Демонстрирует хорошие результаты на AlignBench-v2, MT-Bench, MMLU и C-Eval, поддерживает до 128K контекста для академического и бизнес-применения.",
  "Pro/deepseek-ai/DeepSeek-R1-Distill-Qwen-7B.description": "DeepSeek-R1-Distill-Qwen-7B — это дистиллированная модель на основе Qwen2.5-Math-7B, дообученная на 800K отобранных выборках DeepSeek-R1. Обеспечивает высокую производительность: 92.8% на MATH-500, 55.5% на AIME 2024 и рейтинг 1189 на CodeForces для модели с 7B параметрами.",
  "Pro/deepseek-ai/DeepSeek-R1.description": "DeepSeek-R1 — это модель рассуждений, обученная с использованием обучения с подкреплением, которая снижает повторяемость и повышает читаемость. Использует данные холодного старта до RL для дальнейшего улучшения рассуждений, сопоставима с OpenAI-o1 в задачах математики, программирования и логики, улучшает общие результаты благодаря тщательному обучению.",
  "Pro/deepseek-ai/DeepSeek-V3.1-Terminus.description": "DeepSeek-V3.1-Terminus — обновлённая модель V3.1, позиционируемая как гибридная агентная LLM. Исправляет ошибки, сообщённые пользователями, повышает стабильность, согласованность языка и снижает количество смешанных китайско-английских и аномальных символов. Интегрирует режимы размышления и без размышлений с шаблонами чата для гибкого переключения. Также улучшает производительность агентов кода и поиска для более надёжного использования инструментов и многошаговых задач.",
  "Pro/deepseek-ai/DeepSeek-V3.2-Exp.description": "DeepSeek-V3.2-Exp — экспериментальный выпуск V3.2, переходящий к следующей архитектуре. Добавляет DeepSeek Sparse Attention (DSA) поверх V3.1-Terminus для повышения эффективности обучения и вывода на длинных контекстах, с оптимизациями для использования инструментов, понимания длинных документов и многошагового рассуждения. Идеально подходит для изучения более эффективного рассуждения при больших бюджетах контекста.",
  "Pro/deepseek-ai/DeepSeek-V3.description": "DeepSeek-V3 — это модель MoE с 671B параметрами, использующая MLA и DeepSeekMoE с балансировкой нагрузки без потерь для эффективного вывода и обучения. Предобучена на 14.8T высококачественных токенов и дополнительно дообучена с использованием SFT и RL, превосходит другие открытые модели и приближается к ведущим закрытым моделям.",
  "Pro/moonshotai/Kimi-K2-Instruct-0905.description": "Kimi K2-Instruct-0905 — новейшая и самая мощная версия Kimi K2. Это передовая модель MoE с общим числом параметров 1 трлн и 32 млрд активных. Ключевые особенности включают усиленный агентный интеллект в программировании с заметным улучшением результатов на тестах и в реальных задачах, а также улучшенную эстетику и удобство интерфейсного кода.",
  "Pro/moonshotai/Kimi-K2-Thinking.description": "Kimi K2 Thinking Turbo — это ускоренный вариант, оптимизированный для скорости рассуждений и пропускной способности, при сохранении многошагового мышления и использования инструментов K2 Thinking. Это модель MoE с ~1 трлн параметров, нативной поддержкой контекста 256K и стабильным вызовом инструментов в масштабных производственных сценариях с жёсткими требованиями к задержке и параллельности.",
  "Pro/moonshotai/Kimi-K2.5.description": "Kimi K2.5 — это нативная мультимодальная агентная модель с открытым исходным кодом, построенная на базе Kimi-K2-Base и обученная на ~1,5 трлн токенов текста и изображений. Модель использует архитектуру MoE с 1 трлн общих параметров и 32 млрд активных, поддерживает контекст до 256K и объединяет визуальное и языковое понимание.",
  "Pro/zai-org/glm-4.7.description": "GLM-4.7 — флагманская модель нового поколения от Zhipu с общим числом параметров 355B и 32B активных. Полностью обновлена для улучшения диалога, логического мышления и возможностей агента. GLM-4.7 усиливает межшаговое мышление и вводит концепции сохранённого и пошагового мышления.",
  "QwQ-32B-Preview.description": "Qwen QwQ — это экспериментальная исследовательская модель, направленная на улучшение логического мышления.",
  "Qwen/QVQ-72B-Preview.description": "QVQ-72B-Preview — исследовательская модель от Qwen, ориентированная на визуальное мышление, с сильными сторонами в понимании сложных сцен и решении визуальных математических задач.",
  "Qwen/QwQ-32B-Preview.description": "Qwen QwQ — экспериментальная исследовательская модель, сосредоточенная на улучшении логического мышления ИИ.",
  "Qwen/QwQ-32B.description": "QwQ — модель логического мышления из семейства Qwen. В отличие от стандартных моделей, обученных на инструкциях, она добавляет элементы размышления и логики, что значительно повышает эффективность в сложных задачах. QwQ-32B — модель среднего размера, сопоставимая с лучшими моделями логического мышления, такими как DeepSeek-R1 и o1-mini. Использует RoPE, SwiGLU, RMSNorm и смещение QKV в механизме внимания, имеет 64 слоя и 40 голов внимания (8 KV в GQA).",
  "Qwen/Qwen-Image-Edit-2509.description": "Qwen-Image-Edit-2509 — последняя версия редактора изображений от команды Qwen. Основана на модели Qwen-Image с 20 млрд параметров и расширяет возможности точного редактирования текста в изображениях. Использует архитектуру двойного управления: Qwen2.5-VL для семантического контроля и VAE-энкодер для управления внешним видом, что позволяет редактировать как на уровне смысла, так и визуального оформления. Поддерживает локальные изменения (добавление/удаление/модификация) и высокоуровневые семантические правки, такие как создание IP и перенос стиля, сохраняя при этом смысл. Достигает SOTA-результатов на множестве тестов.",
  "Qwen/Qwen-Image.description": "Qwen-Image — базовая модель генерации изображений с 20 млрд параметров от команды Qwen. Обеспечивает значительный прогресс в сложной визуализации текста и точном редактировании изображений, особенно для китайского и английского языков. Поддерживает многострочные и абзацные макеты с сохранением типографики. Помимо визуализации текста, поддерживает широкий спектр стилей — от фотореализма до аниме, а также продвинутые функции редактирования: перенос стиля, добавление/удаление объектов, улучшение деталей, редактирование текста и управление позой. Стремится стать универсальной основой для визуального творчества.",
  "Qwen/Qwen2-72B-Instruct.description": "Qwen 2 Instruct (72B) обеспечивает точное выполнение инструкций для корпоративных задач.",
  "Qwen/Qwen2-7B-Instruct.description": "Qwen2-7B-Instruct — модель с 7 млрд параметров из серии Qwen2, использующая Transformer, SwiGLU, смещение QKV и групповое внимание. Обрабатывает большие входные данные и демонстрирует высокие результаты в понимании, генерации, многоязычии, программировании, математике и логике, превосходя большинство открытых моделей и Qwen1.5-7B-Chat в ряде тестов.",
  "Qwen/Qwen2-VL-72B-Instruct.description": "Qwen2-VL — последняя модель Qwen-VL, достигшая SOTA на визуальных тестах, таких как MathVista, DocVQA, RealWorldQA и MTVQA. Понимает видео длительностью более 20 минут для задач видео-QA, диалогов и создания контента. Поддерживает сложное логическое мышление и принятие решений, интегрируется с устройствами/роботами для действий, основанных на визуальном восприятии. Помимо английского и китайского, распознаёт текст на большинстве европейских языков, японском, корейском, арабском и вьетнамском.",
  "Qwen/Qwen2.5-14B-Instruct.description": "Qwen2.5-14B-Instruct — часть последней серии LLM от Alibaba Cloud. Модель с 14 млрд параметров демонстрирует значительный прогресс в программировании и математике, поддерживает более 29 языков и улучшает выполнение инструкций, понимание структурированных данных и генерацию структурированного вывода (особенно JSON).",
  "Qwen/Qwen2.5-32B-Instruct.description": "Qwen2.5-32B-Instruct — часть последней серии LLM от Alibaba Cloud. Модель с 32 млрд параметров демонстрирует значительный прогресс в программировании и математике, поддерживает более 29 языков и улучшает выполнение инструкций, понимание структурированных данных и генерацию структурированного вывода (особенно JSON).",
  "Qwen/Qwen2.5-72B-Instruct-128K.description": "Qwen2.5-72B-Instruct — часть последней серии LLM от Alibaba Cloud. Модель с 72 млрд параметров улучшает программирование и математику, поддерживает до 128K входных и более 8K выходных токенов, предлагает поддержку 29+ языков и улучшает выполнение инструкций и структурированный вывод (особенно JSON).",
  "Qwen/Qwen2.5-72B-Instruct-Turbo.description": "Qwen2.5 — новое семейство LLM, оптимизированное для задач в стиле инструкций.",
  "Qwen/Qwen2.5-72B-Instruct.description": "Qwen2.5-72B-Instruct — часть последней серии LLM от Alibaba Cloud. Модель с 72 млрд параметров демонстрирует значительный прогресс в программировании и математике, поддерживает более 29 языков и улучшает выполнение инструкций, понимание структурированных данных и генерацию структурированного вывода (особенно JSON).",
  "Qwen/Qwen2.5-7B-Instruct-Turbo.description": "Qwen2.5 — новое семейство LLM, оптимизированное для задач в стиле инструкций.",
  "Qwen/Qwen2.5-7B-Instruct.description": "Qwen2.5-7B-Instruct — часть последней серии LLM от Alibaba Cloud. Модель с 7 млрд параметров демонстрирует значительный прогресс в программировании и математике, поддерживает более 29 языков и улучшает выполнение инструкций, понимание структурированных данных и генерацию структурированного вывода (особенно JSON).",
  "Qwen/Qwen2.5-Coder-32B-Instruct.description": "Qwen2.5 Coder 32B Instruct — последняя модель от Alibaba Cloud, ориентированная на программирование. Построена на базе Qwen2.5 и обучена на 5.5 трлн токенов, значительно улучшает генерацию кода, логическое мышление и исправление ошибок, сохраняя при этом сильные стороны в математике и общем понимании, обеспечивая надёжную основу для кодирующих агентов.",
  "Qwen/Qwen2.5-Coder-7B-Instruct.description": "Qwen2.5-Coder-7B-Instruct — последняя модель от Alibaba Cloud, ориентированная на программирование. Построена на базе Qwen2.5 и обучена на 5.5 трлн токенов, значительно улучшает генерацию кода, логическое мышление и исправление ошибок, сохраняя при этом сильные стороны в математике и общем понимании, обеспечивая надёжную основу для кодирующих агентов.",
  "Qwen/Qwen2.5-VL-32B-Instruct.description": "Qwen2.5-VL-32B-Instruct — мультимодальная модель от команды Qwen. Распознаёт распространённые объекты и анализирует текст, графики, иконки, изображения и макеты. Как визуальный агент, может рассуждать и динамически управлять инструментами, включая использование компьютеров и телефонов. Точно локализует объекты и генерирует структурированный вывод для счетов и таблиц. По сравнению с Qwen2-VL, RL дополнительно улучшает математику и решение задач, предлагая более предпочтительные ответы.",
  "Qwen/Qwen2.5-VL-72B-Instruct.description": "Qwen2.5-VL — модель визуально-языкового типа из серии Qwen2.5 с крупными улучшениями: более сильное визуальное понимание объектов, текста, графиков и макетов; логическое мышление как визуальный агент с динамическим использованием инструментов; понимание видео длительностью более 1 часа и захват ключевых событий; точная привязка объектов через рамки или точки; и структурированный вывод для отсканированных данных, таких как счета и таблицы.",
  "Qwen/Qwen3-14B.description": "Qwen3 — это модель нового поколения Tongyi Qwen с существенными улучшениями в области рассуждений, общей способности, агентных возможностей и многоязычной производительности. Поддерживает переключение режимов мышления.",
  "Qwen/Qwen3-235B-A22B-Instruct-2507.description": "Qwen3-235B-A22B-Instruct-2507 — флагманская модель Qwen3 MoE с общим числом параметров 235B и 22B активных. Это обновлённая версия без режима мышления, ориентированная на улучшение следования инструкциям, логических рассуждений, понимания текста, математики, науки, программирования и использования инструментов. Также расширяет знания на длинном хвосте в многоязычной среде и лучше соответствует пользовательским предпочтениям в субъективных и открытых задачах.",
  "Qwen/Qwen3-235B-A22B-Thinking-2507.description": "Qwen3-235B-A22B-Thinking-2507 — модель Qwen3, ориентированная на сложные логические рассуждения. Использует архитектуру MoE с общим числом параметров 235B и ~22B активных на токен, что повышает эффективность. Как специализированная модель для мышления, она демонстрирует значительные улучшения в логике, математике, науке, программировании и академических тестах, достигая уровня лучших открытых моделей мышления. Также улучшает следование инструкциям, использование инструментов и генерацию текста, нативно поддерживает контекст до 256K для глубоких рассуждений и работы с длинными документами.",
  "Qwen/Qwen3-235B-A22B.description": "Qwen3 — это модель нового поколения Tongyi Qwen с существенными улучшениями в области рассуждений, общей способности, агентных возможностей и многоязычной производительности. Поддерживает переключение режимов мышления.",
  "Qwen/Qwen3-30B-A3B-Instruct-2507.description": "Qwen3-30B-A3B-Instruct-2507 — обновлённая версия модели Qwen3-30B-A3B без режима мышления. Это модель MoE с общим числом параметров 30.5B и 3.3B активных. Существенно улучшает следование инструкциям, логические рассуждения, понимание текста, математику, науку, программирование и использование инструментов, расширяет знания на длинном хвосте в многоязычной среде и лучше соответствует пользовательским предпочтениям в субъективных открытых задачах. Поддерживает контекст до 256K. Эта модель работает только в режиме без мышления и не будет выводить теги `<think></think>`.",
  "Qwen/Qwen3-30B-A3B-Thinking-2507.description": "Qwen3-30B-A3B-Thinking-2507 — новейшая модель мышления в серии Qwen3. Это модель MoE с общим числом параметров 30.5B и 3.3B активных, ориентированная на сложные задачи. Демонстрирует значительные улучшения в логике, математике, науке, программировании и академических тестах, а также улучшает следование инструкциям, использование инструментов, генерацию текста и соответствие предпочтениям. Нативно поддерживает контекст до 256K и может быть расширена до 1M токенов. Эта версия предназначена для режима мышления с пошаговыми рассуждениями и развитыми агентными возможностями.",
  "Qwen/Qwen3-30B-A3B.description": "Qwen3 — это модель нового поколения Tongyi Qwen с существенными улучшениями в области рассуждений, общей способности, агентных возможностей и многоязычной производительности. Поддерживает переключение режимов мышления.",
  "Qwen/Qwen3-32B.description": "Qwen3 — это модель нового поколения Tongyi Qwen с существенными улучшениями в области рассуждений, общей способности, агентных возможностей и многоязычной производительности. Поддерживает переключение режимов мышления.",
  "Qwen/Qwen3-8B.description": "Qwen3 — это модель нового поколения Tongyi Qwen с существенными улучшениями в области рассуждений, общей способности, агентных возможностей и многоязычной производительности. Поддерживает переключение режимов мышления.",
  "Qwen/Qwen3-Coder-30B-A3B-Instruct.description": "Qwen3-Coder-30B-A3B-Instruct — это модель программирования серии Qwen3 от команды Qwen. Оптимизирована для высокой производительности и эффективности при работе с кодом. Демонстрирует сильные стороны в агентном программировании, автоматизации браузера и использовании инструментов среди открытых моделей. Нативно поддерживает контекст до 256K и может быть расширена до 1M токенов для понимания на уровне кодовой базы. Обеспечивает агентное программирование на платформах, таких как Qwen Code и CLINE, с использованием специального формата вызова функций.",
  "Qwen/Qwen3-Coder-480B-A35B-Instruct.description": "Qwen3-Coder-480B-A35B-Instruct — самая агентная модель программирования от Alibaba на сегодняшний день. Это модель MoE с общим числом параметров 480B и 35B активных, обеспечивающая баланс между эффективностью и производительностью. Нативно поддерживает контекст до 256K и может быть расширена до 1M токенов с помощью YaRN, что позволяет обрабатывать большие кодовые базы. Разработана для агентных рабочих процессов программирования, может взаимодействовать с инструментами и средами для решения сложных задач. Достигает лучших результатов среди открытых моделей в тестах на программирование и агентность, сопоставима с ведущими моделями, такими как Claude Sonnet 4.",
  "Qwen/Qwen3-Next-80B-A3B-Instruct.description": "Qwen3-Next-80B-A3B-Instruct — это базовая модель нового поколения, использующая архитектуру Qwen3-Next для экстремальной эффективности обучения и вывода. Объединяет гибридное внимание (Gated DeltaNet + Gated Attention), высокоразреженную MoE и оптимизации стабильности обучения. Имеет 80B общих параметров, но только ~3B активных при выводе, что снижает вычислительные затраты и обеспечивает более чем 10-кратную пропускную способность по сравнению с Qwen3-32B при контексте >32K. Эта версия, настроенная на выполнение инструкций, ориентирована на общие задачи (без режима мышления). По некоторым тестам сопоставима с Qwen3-235B и демонстрирует сильные стороны в задачах с ультрадлинным контекстом.",
  "Qwen/Qwen3-Next-80B-A3B-Thinking.description": "Qwen3-Next-80B-A3B-Thinking — это базовая модель нового поколения для сложных рассуждений. Использует архитектуру Qwen3-Next с гибридным вниманием (Gated DeltaNet + Gated Attention) и высокоразреженной MoE для экстремальной эффективности обучения и вывода. Имеет 80B общих параметров, но только ~3B активных при выводе, что снижает вычислительные затраты и обеспечивает более чем 10-кратную пропускную способность по сравнению с Qwen3-32B при контексте >32K. Эта версия мышления ориентирована на многошаговые задачи, такие как доказательства, синтез кода, логический анализ и планирование, выводя структурированную цепочку рассуждений. Превосходит Qwen3-32B-Thinking и обходит Gemini-2.5-Flash-Thinking по нескольким тестам.",
  "Qwen/Qwen3-Omni-30B-A3B-Captioner.description": "Qwen3-Omni-30B-A3B-Captioner — это модель VLM из серии Qwen3, созданная для высококачественных, детализированных и точных описаний изображений. Использует архитектуру MoE с 30B параметров для глубокого понимания изображений и генерации беглых описаний, превосходя в захвате деталей, понимании сцен, распознавании объектов и логических связях.",
  "Qwen/Qwen3-Omni-30B-A3B-Instruct.description": "Qwen3-Omni-30B-A3B-Instruct — это модель MoE из серии Qwen3 с 30B общих и 3B активных параметров, обеспечивающая высокую производительность при низкой стоимости вывода. Обучена на высококачественных многоязычных данных из различных источников, поддерживает полные мультимодальные входы (текст, изображения, аудио, видео) и кросс-модальное понимание и генерацию.",
  "Qwen/Qwen3-Omni-30B-A3B-Thinking.description": "Qwen3-Omni-30B-A3B-Thinking — это основной компонент \"Thinker\" в Qwen3-Omni. Обрабатывает мультимодальные входы (текст, аудио, изображения, видео) и выполняет сложные цепочки рассуждений, объединяя входные данные в общее представление для глубокого кросс-модального понимания. Это модель MoE с 30B общих и 3B активных параметров, обеспечивающая баланс между мощными рассуждениями и вычислительной эффективностью.",
  "Qwen/Qwen3-VL-235B-A22B-Instruct.description": "Qwen3-VL-235B-A22B-Instruct — это крупная модель Qwen3-VL, настроенная на выполнение инструкций и построенная на архитектуре MoE, обеспечивающая отличное мультимодальное понимание и генерацию. Нативно поддерживает контекст до 256K и подходит для высоконагруженных производственных мультимодальных сервисов.",
  "Qwen/Qwen3-VL-235B-A22B-Thinking.description": "Qwen3-VL-235B-A22B-Thinking — флагманская версия мышления в серии Qwen3-VL, оптимизированная для сложных мультимодальных рассуждений, работы с длинным контекстом и взаимодействия с агентами в корпоративных сценариях.",
  "Qwen/Qwen3-VL-30B-A3B-Instruct.description": "Qwen3-VL-30B-A3B-Instruct — это модель Qwen3-VL, настроенная на выполнение инструкций, с сильным пониманием и генерацией в связке зрение-язык. Нативно поддерживает контекст до 256K для мультимодального чата и генерации, основанной на изображениях.",
  "Qwen/Qwen3-VL-30B-A3B-Thinking.description": "Qwen3-VL-30B-A3B-Thinking — версия Qwen3-VL с усиленными возможностями рассуждения, оптимизированная для мультимодальных рассуждений, преобразования изображений в код и сложного визуального понимания. Поддерживает контекст до 256K с улучшенной способностью к цепочкам рассуждений.",
  "Qwen/Qwen3-VL-32B-Instruct.description": "Qwen3-VL-32B-Instruct — это модель зрение-язык от команды Qwen с передовыми результатами на нескольких VL-бенчмарках. Поддерживает изображения с мегапиксельным разрешением и обеспечивает сильное визуальное понимание, многоязычное OCR, точную визуальную привязку и визуальный диалог. Обрабатывает сложные мультимодальные задачи и поддерживает вызов инструментов и автозавершение по префиксу.",
  "Qwen/Qwen3-VL-32B-Thinking.description": "Qwen3-VL-32B-Thinking оптимизирована для сложных визуальных рассуждений. Включает встроенный режим мышления, который генерирует промежуточные шаги рассуждений перед ответами, улучшая многошаговую логику, планирование и сложные рассуждения. Поддерживает изображения с мегапиксельным разрешением, сильное визуальное понимание, многоязычное OCR, точную привязку, визуальный диалог, вызов инструментов и автозавершение по префиксу.",
  "Qwen/Qwen3-VL-8B-Instruct.description": "Qwen3-VL-8B-Instruct — это модель зрение-язык из серии Qwen3, построенная на базе Qwen3-8B-Instruct и обученная на больших объемах данных изображение-текст. Отличается общим визуальным пониманием, диалогом с упором на визуальные элементы и многоязычным распознаванием текста на изображениях. Подходит для визуального QA, создания подписей, мультимодального следования инструкциям и использования инструментов.",
  "Qwen/Qwen3-VL-8B-Thinking.description": "Qwen3-VL-8B-Thinking — визуальная версия мышления в серии Qwen3, оптимизированная для сложных многошаговых рассуждений. Генерирует цепочку мышления перед ответами для повышения точности, идеально подходит для глубокого визуального QA и детального анализа изображений.",
  "Qwen2-72B-Instruct.description": "Qwen2 — это новейшая модель серии Qwen с поддержкой контекстного окна на 128 тысяч токенов. По сравнению с лучшими открытыми моделями на сегодняшний день, Qwen2-72B значительно превосходит их в понимании естественного языка, знаниях, программировании, математике и многоязычных возможностях.",
  "Qwen2-7B-Instruct.description": "Qwen2 — это новейшая модель серии Qwen, превосходящая лучшие открытые модели аналогичного и даже большего размера. Qwen2 7B демонстрирует значительные преимущества в различных тестах, особенно в программировании и понимании китайского языка.",
  "Qwen2-VL-72B.description": "Qwen2-VL-72B — это мощная мультимодальная модель, объединяющая зрение и язык, поддерживающая обработку изображений и текста. Она точно распознаёт содержимое изображений и генерирует соответствующие описания или ответы.",
  "Qwen2.5-14B-Instruct.description": "Qwen2.5-14B-Instruct — это языковая модель с 14 миллиардами параметров, обладающая высокой производительностью. Она оптимизирована для китайского языка и многоязычных сценариев, поддерживает интеллектуальные вопросы и ответы, а также генерацию контента.",
  "Qwen2.5-32B-Instruct.description": "Qwen2.5-32B-Instruct — это языковая модель с 32 миллиардами параметров, обеспечивающая сбалансированную производительность. Она оптимизирована для китайского языка и многоязычных задач, поддерживает интеллектуальные вопросы и ответы, а также генерацию контента.",
  "Qwen2.5-72B-Instruct.description": "Языковая модель для китайского и английского языков, настроенная для задач языка, программирования, математики и логического рассуждения.",
  "Qwen2.5-7B-Instruct.description": "Qwen2.5-7B-Instruct — это языковая модель с 7 миллиардами параметров, поддерживающая вызов функций и интеграцию с внешними системами, что значительно повышает гибкость и расширяемость. Она оптимизирована для китайского языка и многоязычных сценариев, поддерживает интеллектуальные вопросы и ответы, а также генерацию контента.",
  "Qwen2.5-Coder-14B-Instruct.description": "Qwen2.5-Coder-14B-Instruct — это крупномасштабная предварительно обученная модель для программирования, обладающая высокой способностью к пониманию и генерации кода. Она эффективно справляется с широким спектром задач программирования, идеально подходит для интеллектуального кодирования, автоматической генерации скриптов и вопросов по программированию.",
  "Qwen2.5-Coder-32B-Instruct.description": "Продвинутая языковая модель для генерации кода, логического рассуждения и исправления ошибок на основных языках программирования.",
  "Qwen3-235B-A22B-Instruct-2507-FP8.description": "Qwen3 235B A22B Instruct 2507 оптимизирована для продвинутого логического рассуждения и следования инструкциям, использует архитектуру MoE для эффективного масштабирования рассуждений.",
  "Qwen3-235B.description": "Qwen3-235B-A22B — это модель MoE с гибридным режимом рассуждения, позволяющим пользователям переключаться между режимами мышления и немышления. Она поддерживает понимание и рассуждение на 119 языках и диалектах, обладает мощными возможностями вызова инструментов и конкурирует с ведущими моделями, такими как DeepSeek R1, OpenAI o1, o3-mini, Grok 3 и Google Gemini 2.5 Pro, по общим способностям, программированию, математике, многоязычности и логическому мышлению.",
  "Qwen3-32B.description": "Qwen3-32B — это плотная модель с гибридным режимом рассуждения, позволяющая пользователям переключаться между режимами мышления и немышления. Благодаря улучшениям в архитектуре, большему объёму данных и более качественному обучению, она демонстрирует производительность, сопоставимую с Qwen2.5-72B.",
  "SenseChat-128K.description": "Базовая модель V4 с контекстом 128K, сильна в понимании и генерации длинных текстов.",
  "SenseChat-32K.description": "Базовая модель V4 с контекстом 32K, гибкая для различных сценариев.",
  "SenseChat-5-1202.description": "Последняя версия на основе V5.5 с существенными улучшениями в базовых знаниях китайского и английского языков, чатах, знаниях в области STEM и гуманитарных наук, письме, математике/логике и управлении длиной текста.",
  "SenseChat-5-Cantonese.description": "Разработана с учётом диалоговых привычек Гонконга, сленга и местных знаний; превосходит GPT-4 в понимании кантонского языка и сопоставима с GPT-4 Turbo по знаниям, логике, математике и программированию.",
  "SenseChat-5-beta.description": "Некоторые характеристики превосходят SenseChat-5-1202.",
  "SenseChat-5.description": "Последняя версия V5.5 с контекстом 128K; значительные улучшения в математическом рассуждении, английском чате, следовании инструкциям и понимании длинных текстов, сопоставима с GPT-4o.",
  "SenseChat-Character-Pro.description": "Продвинутая модель для общения с персонажами с контекстом 32K, улучшенными возможностями и поддержкой китайского и английского языков.",
  "SenseChat-Character.description": "Стандартная модель для общения с персонажами с контекстом 8K и высокой скоростью отклика.",
  "SenseChat-Turbo-1202.description": "Последняя облегчённая модель, достигающая более 90% возможностей полной модели при значительно меньших затратах на вывод.",
  "SenseChat-Turbo.description": "Подходит для быстрого ответа на вопросы и сценариев дообучения модели.",
  "SenseChat-Vision.description": "Последняя версия V5.5 с поддержкой нескольких изображений и широкими улучшениями в распознавании атрибутов, пространственных отношений, действий/событий, понимании сцен, распознавании эмоций, логическом мышлении и понимании/генерации текста.",
  "SenseChat.description": "Базовая модель V4 с контекстом 4K и высокой общей производительностью.",
  "SenseNova-V6-5-Pro.description": "Благодаря комплексным обновлениям мультимодальных, языковых и логических данных, а также оптимизации стратегии обучения, новая модель значительно улучшает мультимодальное рассуждение и универсальное следование инструкциям, поддерживает контекст до 128K и превосходно справляется с задачами OCR и распознаванием IP в сфере культуры и туризма.",
  "SenseNova-V6-5-Turbo.description": "Благодаря комплексным обновлениям мультимодальных, языковых и логических данных, а также оптимизации стратегии обучения, новая модель значительно улучшает мультимодальное рассуждение и универсальное следование инструкциям, поддерживает контекст до 128K и превосходно справляется с задачами OCR и распознаванием IP в сфере культуры и туризма.",
  "SenseNova-V6-Pro.description": "Нативно объединяет изображение, текст и видео, преодолевая традиционные ограничения мультимодальности; занимает лидирующие позиции в OpenCompass и SuperCLUE.",
  "SenseNova-V6-Reasoner.description": "Объединяет глубокое логическое мышление в области зрения и языка, поддерживает медленное мышление и полную цепочку рассуждений.",
  "SenseNova-V6-Turbo.description": "Нативно объединяет изображение, текст и видео, преодолевая традиционные ограничения мультимодальности. Лидирует по основным мультимодальным и языковым возможностям и занимает топовые позиции в различных оценках.",
  "Skylark2-lite-8k.description": "Модель второго поколения Skylark. Skylark2-lite обеспечивает быстрые ответы в реальном времени для задач с ограниченным бюджетом и невысокими требованиями к точности, с контекстом 8K.",
  "Skylark2-pro-32k.description": "Модель второго поколения Skylark. Skylark2-pro обеспечивает высокую точность для сложной генерации текста, такой как профессиональный копирайтинг, написание романов и высококачественный перевод, с контекстом 32K.",
  "Skylark2-pro-4k.description": "Модель второго поколения Skylark. Skylark2-pro обеспечивает высокую точность для сложной генерации текста, такой как профессиональный копирайтинг, написание романов и высококачественный перевод, с контекстом 4K.",
  "Skylark2-pro-character-4k.description": "Модель второго поколения Skylark. Skylark2-pro-character отлично справляется с ролевыми играми и чатами, точно подбирая стиль персонажа и обеспечивая естественный диалог для чат-ботов, виртуальных помощников и служб поддержки, с высокой скоростью отклика.",
  "Skylark2-pro-turbo-8k.description": "Модель второго поколения Skylark. Skylark2-pro-turbo-8k обеспечивает более быструю генерацию при меньших затратах с контекстом 8K.",
  "THUDM/GLM-4-32B-0414.description": "GLM-4-32B-0414 — это модель нового поколения с открытым исходным кодом на базе GLM с 32 миллиардами параметров, сопоставимая по производительности с OpenAI GPT и сериями DeepSeek V3/R1.",
  "THUDM/GLM-4-9B-0414.description": "GLM-4-9B-0414 — это модель GLM с 9 миллиардами параметров, унаследовавшая технологии GLM-4-32B и обеспечивающая более лёгкое развертывание. Отлично справляется с генерацией кода, веб-дизайном, созданием SVG и написанием текстов на основе поиска.",
  "THUDM/GLM-4.1V-9B-Thinking.description": "GLM-4.1V-9B-Thinking — это открытая мультимодальная модель от Zhipu AI и лаборатории KEG Университета Цинхуа, предназначенная для сложного мультимодального восприятия. Построена на базе GLM-4-9B-0414 и дополнена цепочкой рассуждений и обучением с подкреплением (RL), что значительно повышает устойчивость и кросс-модальное мышление.",
  "THUDM/GLM-Z1-32B-0414.description": "GLM-Z1-32B-0414 — это модель глубинного мышления, созданная на основе GLM-4-32B-0414 с использованием данных холодного старта и расширенного RL. Дополнительно обучена на математике, коде и логике, значительно улучшая способности к решению сложных задач по сравнению с базовой моделью.",
  "THUDM/GLM-Z1-9B-0414.description": "GLM-Z1-9B-0414 — компактная модель GLM с 9 миллиардами параметров, сочетающая открытость и высокую производительность. Демонстрирует отличные результаты в математических рассуждениях и решении общих задач, лидируя среди моделей своего класса.",
  "THUDM/GLM-Z1-Rumination-32B-0414.description": "GLM-Z1-Rumination-32B-0414 — это модель глубинного мышления с возможностью размышлений (по аналогии с OpenAI Deep Research). В отличие от обычных моделей, она тратит больше времени на обдумывание, чтобы решать более открытые и сложные задачи.",
  "THUDM/glm-4-9b-chat.description": "GLM-4-9B-Chat — это открытая модель GLM-4 от Zhipu AI. Обеспечивает высокую производительность в области семантики, математики, логики, программирования и знаний. Помимо многотурового чата, поддерживает веб-браузинг, выполнение кода, вызов пользовательских инструментов и работу с длинными текстами. Поддерживает 26 языков (включая китайский, английский, японский, корейский и немецкий). Демонстрирует отличные результаты на AlignBench-v2, MT-Bench, MMLU и C-Eval, а также поддерживает контекст до 128K токенов для академического и бизнес-применения.",
  "Tongyi-Zhiwen/QwenLong-L1-32B.description": "QwenLong-L1-32B — первая модель для рассуждений в длинном контексте (LRM), обученная с использованием RL и оптимизированная для понимания длинных текстов. Прогрессивное расширение контекста с помощью RL обеспечивает стабильный переход от короткого к длинному контексту. Превосходит OpenAI-o3-mini и Qwen3-235B-A22B на семи бенчмарках по вопросам к документам с длинным контекстом, сопоставима с Claude-3.7-Sonnet-Thinking. Особенно сильна в математике, логике и многошаговых рассуждениях.",
  "Yi-34B-Chat.description": "Yi-1.5-34B сохраняет сильные языковые способности серии, а также использует инкрементальное обучение на 500 миллиардах высококачественных токенов для значительного улучшения логики, математики и программирования.",
  "abab5.5-chat.description": "Создана для продуктивных сценариев с обработкой сложных задач и эффективной генерацией текста для профессионального использования.",
  "abab5.5s-chat.description": "Разработана для чатов с китайской персонализацией, обеспечивая высококачественный диалог на китайском языке для различных приложений.",
  "abab6.5g-chat.description": "Предназначена для многозначных чатов с персонализацией, поддерживает генерацию диалогов высокого качества на английском и других языках.",
  "abab6.5s-chat.description": "Подходит для широкого спектра задач обработки естественного языка, включая генерацию текста и диалоговые системы.",
  "abab6.5t-chat.description": "Оптимизирована для китайских чатов с персонализацией, обеспечивая плавный диалог, соответствующий привычкам китайского языка.",
  "accounts/fireworks/models/deepseek-r1.description": "DeepSeek-R1 — это передовая языковая модель, оптимизированная с помощью обучения с подкреплением и данных холодного старта, обеспечивающая отличные результаты в логике, математике и программировании.",
  "accounts/fireworks/models/deepseek-v3.description": "Мощная языковая модель с архитектурой Mixture-of-Experts (MoE) от DeepSeek с общим числом параметров 671B и 37B активных параметров на токен.",
  "accounts/fireworks/models/llama-v3-70b-instruct.description": "Meta разработала и выпустила серию LLM Meta Llama 3, включающую предварительно обученные и дообученные на инструкциях модели генерации текста с объемом 8B и 70B параметров. Модели Llama 3, дообученные на инструкциях, оптимизированы для ведения диалогов и превосходят многие существующие открытые чат-модели по общепринятым отраслевым метрикам.",
  "accounts/fireworks/models/llama-v3-8b-instruct-hf.description": "Модели Meta Llama 3, дообученные на инструкциях, оптимизированы для ведения диалогов и превосходят многие существующие открытые чат-модели по общепринятым отраслевым метрикам. Llama 3 8B Instruct (версия HF) — это оригинальная версия Llama 3 8B Instruct с точностью FP16, результаты которой соответствуют официальной реализации Hugging Face.",
  "accounts/fireworks/models/llama-v3-8b-instruct.description": "Meta разработала и выпустила серию LLM Meta Llama 3 — набор предварительно обученных и дообученных на инструкциях моделей генерации текста с объемом 8B и 70B параметров. Модели Llama 3, дообученные на инструкциях, оптимизированы для ведения диалогов и превосходят многие существующие открытые чат-модели по общепринятым отраслевым метрикам.",
  "accounts/fireworks/models/llama-v3p1-405b-instruct.description": "Meta Llama 3.1 — это многоязычное семейство LLM, включающее предварительно обученные и дообученные на инструкциях модели генерации текста с объемом 8B, 70B и 405B параметров. Модели, дообученные на инструкциях, оптимизированы для многоязычного диалога и превосходят многие существующие открытые и закрытые чат-модели по общепринятым отраслевым метрикам. Модель 405B — самая мощная в семействе Llama 3.1, использует вывод FP8, максимально приближенный к эталонной реализации.",
  "accounts/fireworks/models/llama-v3p1-70b-instruct.description": "Meta Llama 3.1 — это многоязычное семейство LLM, включающее предварительно обученные и дообученные на инструкциях модели генерации текста с объемом 8B, 70B и 405B параметров. Модели, дообученные на инструкциях, оптимизированы для многоязычного диалога и превосходят многие существующие открытые и закрытые чат-модели по общепринятым отраслевым метрикам.",
  "accounts/fireworks/models/llama-v3p1-8b-instruct.description": "Meta Llama 3.1 — это многоязычное семейство LLM, включающее предварительно обученные и дообученные на инструкциях модели генерации текста с объемом 8B, 70B и 405B параметров. Модели, дообученные на инструкциях, оптимизированы для многоязычного диалога и превосходят многие существующие открытые и закрытые чат-модели по общепринятым отраслевым метрикам.",
  "accounts/fireworks/models/llama-v3p2-11b-vision-instruct.description": "Дообученная на инструкциях модель визуального рассуждения от Meta с 11 миллиардами параметров, оптимизированная для распознавания изображений, логического анализа, генерации описаний и ответов на вопросы, связанные с изображениями. Понимает визуальные данные, такие как диаграммы и графики, и объединяет зрение и язык, создавая текстовые описания деталей изображений.",
  "accounts/fireworks/models/llama-v3p2-3b-instruct.description": "Llama 3.2 3B Instruct — это легковесная многоязычная модель от Meta, разработанная для эффективной работы с низкой задержкой и сниженной стоимостью по сравнению с более крупными моделями. Типичные сценарии использования включают переформулировку запросов и помощь в написании текстов.",
  "accounts/fireworks/models/llama-v3p2-90b-vision-instruct.description": "Дообученная на инструкциях модель визуального рассуждения от Meta с 90 миллиардами параметров, оптимизированная для распознавания изображений, логического анализа, генерации описаний и ответов на вопросы, связанные с изображениями. Понимает визуальные данные, такие как диаграммы и графики, и объединяет зрение и язык, создавая текстовые описания деталей изображений. Примечание: эта модель предоставляется в экспериментальном режиме как серверлесс-решение. Для использования в продакшене учтите, что Fireworks может прекратить развертывание без предварительного уведомления.",
  "accounts/fireworks/models/llama-v3p3-70b-instruct.description": "Llama 3.3 70B Instruct — обновление декабря для модели Llama 3.1 70B. Улучшает использование инструментов, поддержку многоязычного текста, математику и программирование по сравнению с выпуском июля 2024 года. Обеспечивает лидирующую в отрасли производительность в рассуждении, математике и следовании инструкциям, предлагая сопоставимую с 3.1 405B производительность при значительном выигрыше в скорости и стоимости.",
  "accounts/fireworks/models/mistral-small-24b-instruct-2501.description": "Модель с 24 миллиардами параметров, обладающая передовыми возможностями, сопоставимыми с более крупными моделями.",
  "accounts/fireworks/models/mixtral-8x22b-instruct.description": "Mixtral MoE 8x22B Instruct v0.1 — это дообученная на инструкциях версия модели Mixtral MoE 8x22B v0.1 с включенной поддержкой API завершения чата.",
  "accounts/fireworks/models/mixtral-8x7b-instruct.description": "Mixtral MoE 8x7B Instruct — это дообученная на инструкциях версия модели Mixtral MoE 8x7B с включенной поддержкой API завершения чата.",
  "accounts/fireworks/models/mythomax-l2-13b.description": "Улучшенный вариант MythoMix, возможно, его более изысканная форма, объединяющая MythoLogic-L2 и Huginn с использованием экспериментальной техники слияния тензорных типов. Благодаря своей уникальности отлично подходит для повествования и ролевых игр.",
  "accounts/fireworks/models/phi-3-vision-128k-instruct.description": "Phi-3-Vision-128K-Instruct — это легковесная, передовая открытая мультимодальная модель, построенная на синтетических данных и отобранных общедоступных веб-источниках, с акцентом на качественные данные, требующие рассуждений, в области текста и визуальной информации. Принадлежит к семейству Phi-3 и поддерживает мультимодальность с контекстом до 128K токенов. Модель проходит тщательную донастройку, включая обучение с учителем и оптимизацию предпочтений, чтобы обеспечить точное следование инструкциям и высокий уровень безопасности.",
  "accounts/fireworks/models/qwen-qwq-32b-preview.description": "Модель Qwen QwQ направлена на развитие возможностей ИИ в области рассуждений, демонстрируя, что открытые модели могут конкурировать с закрытыми передовыми решениями. QwQ-32B-Preview — это экспериментальный выпуск, сопоставимый с o1 и превосходящий GPT-4o и Claude 3.5 Sonnet по рассуждению и анализу на метриках GPQA, AIME, MATH-500 и LiveCodeBench. Примечание: модель предоставляется в экспериментальном режиме как серверлесс-решение. Для использования в продакшене учтите, что Fireworks может прекратить развертывание без предварительного уведомления.",
  "accounts/fireworks/models/qwen2-vl-72b-instruct.description": "Модель Qwen-VL с 72 миллиардами параметров — последняя разработка Alibaba, отражающая почти год инноваций.",
  "accounts/fireworks/models/qwen2p5-72b-instruct.description": "Qwen2.5 — это серия LLM только с декодером, разработанная командой Qwen и Alibaba Cloud, доступная в вариантах 0.5B, 1.5B, 3B, 7B, 14B, 32B и 72B, как в базовой, так и в дообученной на инструкциях версиях.",
  "accounts/fireworks/models/qwen2p5-coder-32b-instruct.description": "Qwen2.5-Coder — последняя модель LLM из серии Qwen, предназначенная для программирования (ранее CodeQwen). Примечание: модель предоставляется в экспериментальном режиме как серверлесс-решение. Для использования в продакшене учтите, что Fireworks может прекратить развертывание без предварительного уведомления.",
  "accounts/yi-01-ai/models/yi-large.description": "Yi-Large — это высококлассная LLM, занимающая позицию сразу за GPT-4, Gemini 1.5 Pro и Claude 3 Opus в рейтинге LMSYS. Отличается выдающимися многоязычными возможностями, особенно в испанском, китайском, японском, немецком и французском языках. Yi-Large также удобна для разработчиков, так как использует ту же схему API, что и OpenAI, обеспечивая легкую интеграцию.",
  "ai21-jamba-1.5-large.description": "Многоязычная модель с 398 миллиардами параметров (94 миллиарда активных), поддерживающая контекст до 256 тысяч токенов, вызов функций, структурированный вывод и генерацию с привязкой к источникам.",
  "ai21-jamba-1.5-mini.description": "Многоязычная модель с 52 миллиардами параметров (12 миллиардов активных), поддерживающая контекст до 256 тысяч токенов, вызов функций, структурированный вывод и генерацию с привязкой к источникам.",
  "ai21-labs/AI21-Jamba-1.5-Large.description": "Многоязычная модель с 398 миллиардами параметров (94 миллиарда активных), поддерживающая контекст до 256 тысяч токенов, вызов функций, структурированный вывод и генерацию с привязкой к источникам.",
  "ai21-labs/AI21-Jamba-1.5-Mini.description": "Многоязычная модель с 52 миллиардами параметров (12 миллиардов активных), поддерживающая контекст до 256 тысяч токенов, вызов функций, структурированный вывод и генерацию с привязкой к источникам.",
  "alibaba/qwen-3-14b.description": "Qwen3 — это новейшее поколение в серии Qwen, предлагающее широкий набор плотных и MoE-моделей. Обученная на обширных данных, модель демонстрирует прорывные результаты в логике, следовании инструкциям, агентных возможностях и многоязычной поддержке.",
  "alibaba/qwen-3-235b.description": "Qwen3 — это новейшее поколение в серии Qwen, предлагающее широкий набор плотных и MoE-моделей. Обученная на обширных данных, модель демонстрирует прорывные результаты в логике, следовании инструкциям, агентных возможностях и многоязычной поддержке.",
  "alibaba/qwen-3-30b.description": "Qwen3 — это новейшее поколение в серии Qwen, предлагающее широкий набор плотных и MoE-моделей. Обученная на обширных данных, модель демонстрирует прорывные результаты в логике, следовании инструкциям, агентных возможностях и многоязычной поддержке.",
  "alibaba/qwen-3-32b.description": "Qwen3 — это новейшее поколение в серии Qwen, предлагающее широкий набор плотных и MoE-моделей. Обученная на обширных данных, модель демонстрирует прорывные результаты в логике, следовании инструкциям, агентных возможностях и многоязычной поддержке.",
  "alibaba/qwen3-coder.description": "Qwen3-Coder-480B-A35B-Instruct — это самая агентно-ориентированная модель для программирования в серии Qwen, демонстрирующая высокие результаты в агентном кодировании, использовании браузера и других ключевых задачах программирования, сопоставимых с уровнем Claude Sonnet.",
  "amazon/nova-lite.description": "Очень недорогая мультимодальная модель с чрезвычайно быстрой обработкой изображений, видео и текста.",
  "amazon/nova-micro.description": "Только текстовая модель с ультранизкой задержкой и минимальными затратами.",
  "amazon/nova-pro.description": "Высокопроизводительная мультимодальная модель с оптимальным балансом точности, скорости и стоимости для широкого спектра задач.",
  "amazon/titan-embed-text-v2.description": "Amazon Titan Text Embeddings V2 — это легкая и эффективная многоязычная модель эмбеддингов, поддерживающая размеры 1024, 512 и 256.",
  "anthropic.claude-3-5-sonnet-20240620-v1:0.description": "Claude 3.5 Sonnet поднимает отраслевой стандарт, превосходя конкурентов и Claude 3 Opus по широкому спектру оценок, сохраняя при этом средний уровень скорости и стоимости.",
  "anthropic.claude-3-5-sonnet-20241022-v2:0.description": "Claude 3.5 Sonnet поднимает отраслевой стандарт, превосходя конкурентов и Claude 3 Opus по широкому спектру оценок, сохраняя при этом средний уровень скорости и стоимости.",
  "anthropic.claude-3-haiku-20240307-v1:0.description": "Claude 3 Haiku — самая быстрая и компактная модель от Anthropic, обеспечивающая почти мгновенные ответы на простые запросы. Обеспечивает плавное, человекоподобное взаимодействие с ИИ и поддерживает ввод изображений с контекстом до 200 тысяч токенов.",
  "anthropic.claude-3-opus-20240229-v1:0.description": "Claude 3 Opus — самая мощная модель от Anthropic с передовыми возможностями для сложных задач. Обеспечивает свободную генерацию и понимание новых сценариев, поддерживает ввод изображений и контекст до 200 тысяч токенов.",
  "anthropic.claude-3-sonnet-20240229-v1:0.description": "Claude 3 Sonnet сочетает интеллект и скорость для корпоративных задач, предлагая высокую ценность при низкой стоимости. Надежен для масштабируемого внедрения ИИ и поддерживает ввод изображений с контекстом до 200 тысяч токенов.",
  "anthropic.claude-instant-v1.description": "Быстрая, экономичная и при этом мощная модель для повседневного общения, анализа текста, суммирования и вопросов по документам.",
  "anthropic.claude-v2.description": "Высокопроизводительная модель для задач от сложного диалога и креативной генерации до точного следования инструкциям.",
  "anthropic.claude-v2:1.description": "Обновленная версия Claude 2 с удвоенным контекстом, улучшенной надежностью, сниженным уровнем галлюцинаций и повышенной точностью на основе доказательств для длинных документов и RAG.",
  "anthropic/claude-3-haiku.description": "Claude 3 Haiku — самая быстрая модель от Anthropic, предназначенная для корпоративных задач с длинными запросами. Быстро анализирует крупные документы, такие как квартальные отчеты, контракты или юридические дела, при этом стоит вдвое дешевле аналогов.",
  "anthropic/claude-3-opus.description": "Claude 3 Opus — самая интеллектуальная модель от Anthropic с лидирующей производительностью в сложных задачах, свободно обрабатывает открытые запросы и новые сценарии с высоким уровнем понимания.",
  "anthropic/claude-3.5-haiku.description": "Claude 3.5 Haiku отличается повышенной скоростью, точностью программирования и эффективным использованием инструментов, подходит для сценариев с высокими требованиями к скорости и взаимодействию с инструментами.",
  "anthropic/claude-3.5-sonnet.description": "Claude 3.5 Sonnet — быстрая и эффективная модель из семейства Sonnet, обеспечивающая улучшенную производительность в программировании и логике. Некоторые версии постепенно заменяются на Sonnet 3.7 и выше.",
  "anthropic/claude-3.7-sonnet.description": "Claude 3.7 Sonnet — обновленная модель Sonnet с улучшенными логическими и программными возможностями, подходящая для сложных корпоративных задач.",
  "anthropic/claude-haiku-4.5.description": "Claude Haiku 4.5 — высокопроизводительная быстрая модель от Anthropic с очень низкой задержкой и высокой точностью.",
  "anthropic/claude-opus-4.1.description": "Opus 4.1 — флагманская модель от Anthropic, оптимизированная для программирования, сложной логики и длительных задач.",
  "anthropic/claude-opus-4.5.description": "Claude Opus 4.5 — флагманская модель от Anthropic, сочетающая высший интеллект с масштабируемой производительностью для сложных задач, требующих качественного логического вывода.",
  "anthropic/claude-opus-4.description": "Opus 4 — флагманская модель от Anthropic, предназначенная для сложных задач и корпоративных приложений.",
  "anthropic/claude-sonnet-4.5.description": "Claude Sonnet 4.5 — новейшая гибридная модель логического вывода от Anthropic, оптимизированная для сложных рассуждений и программирования.",
  "anthropic/claude-sonnet-4.description": "Claude Sonnet 4 — гибридная модель логического вывода от Anthropic, сочетающая режимы мышления и немышления.",
  "ascend-tribe/pangu-pro-moe.description": "Pangu-Pro-MoE 72B-A16B — это разреженная LLM с 72 миллиардами общих и 16 миллиардами активных параметров, основанная на архитектуре группированной MoE (MoGE). Она группирует экспертов при выборе и ограничивает количество активируемых экспертов на группу, что обеспечивает равномерную нагрузку и повышает эффективность развертывания на Ascend.",
  "aya.description": "Aya 23 — многоязычная модель от Cohere, поддерживающая 23 языка для различных сценариев использования.",
  "aya:35b.description": "Aya 23 — многоязычная модель от Cohere, поддерживающая 23 языка для различных сценариев использования.",
  "azure-DeepSeek-R1-0528.description": "Развернута Microsoft; DeepSeek R1 обновлена до версии DeepSeek-R1-0528. Обновление включает увеличение вычислительных ресурсов и оптимизацию алгоритмов постобучения, что значительно улучшает глубину рассуждений и выводов. Модель демонстрирует высокие результаты в математике, программировании и логике, приближаясь к лидерам, таким как O3 и Gemini 2.5 Pro.",
  "baichuan-m2-32b.description": "Baichuan M2 32B — это модель MoE от Baichuan Intelligence с сильными способностями к рассуждению.",
  "baichuan/baichuan2-13b-chat.description": "Baichuan-13B — это открытая, коммерчески пригодная LLM с 13 миллиардами параметров от Baichuan, демонстрирующая лучшие в своем классе результаты на авторитетных китайских и английских бенчмарках.",
  "baidu/ERNIE-4.5-300B-A47B.description": "ERNIE-4.5-300B-A47B — это MoE LLM от Baidu с 300 миллиардами общих параметров и 47 миллиардами активных на токен, обеспечивающая баланс между высокой производительностью и эффективностью вычислений. Как основная модель ERNIE 4.5, она превосходна в понимании, генерации, рассуждении и программировании. Использует мультимодальный гетерогенный метод предобучения MoE с совместным обучением на текстах и изображениях, что усиливает общие возможности, особенно в следовании инструкциям и знании мира.",
  "baidu/ernie-5.0-thinking-preview.description": "ERNIE 5.0 Thinking Preview — это модель нового поколения от Baidu с нативной мультимодальностью, обладающая сильными возможностями в понимании мультимодальных данных, следовании инструкциям, создании контента, фактическом вопросо-ответе и использовании инструментов.",
  "black-forest-labs/flux-1.1-pro.description": "FLUX 1.1 Pro — это более быстрая и улучшенная версия FLUX Pro с отличным качеством изображений и точным следованием подсказкам.",
  "black-forest-labs/flux-dev.description": "FLUX Dev — это версия FLUX для разработки, предназначенная для некоммерческого использования.",
  "black-forest-labs/flux-pro.description": "FLUX Pro — профессиональная модель FLUX для генерации изображений высокого качества.",
  "black-forest-labs/flux-schnell.description": "FLUX Schnell — это модель генерации изображений, оптимизированная для высокой скорости.",
  "c4ai-aya-expanse-32b.description": "Aya Expanse — это высокопроизводительная многоязычная модель с 32 миллиардами параметров, использующая настройку по инструкциям, арбитраж данных, обучение предпочтениям и объединение моделей, чтобы конкурировать с монолингвальными моделями. Поддерживает 23 языка.",
  "c4ai-aya-expanse-8b.description": "Aya Expanse — это высокопроизводительная многоязычная модель с 8 миллиардами параметров, использующая настройку по инструкциям, арбитраж данных, обучение предпочтениям и объединение моделей, чтобы конкурировать с монолингвальными моделями. Поддерживает 23 языка.",
  "c4ai-aya-vision-32b.description": "Aya Vision — это передовая мультимодальная модель, демонстрирующая высокие результаты на ключевых языковых, текстовых и визуальных бенчмарках. Поддерживает 23 языка. Версия с 32 миллиардами параметров ориентирована на выдающуюся многоязычную производительность.",
  "c4ai-aya-vision-8b.description": "Aya Vision — это передовая мультимодальная модель, демонстрирующая высокие результаты на ключевых языковых, текстовых и визуальных бенчмарках. Версия с 8 миллиардами параметров ориентирована на низкую задержку и высокую производительность.",
  "charglm-3.description": "CharGLM-3 создана для ролевых игр и эмоционального общения, поддерживает сверхдолгую многотуровую память и персонализированный диалог.",
  "charglm-4.description": "CharGLM-4 создана для ролевых игр и эмоционального общения, поддерживает сверхдолгую многотуровую память и персонализированный диалог.",
  "chatgpt-4o-latest.description": "ChatGPT-4o — это динамическая модель с обновлением в реальном времени, сочетающая сильное понимание и генерацию для масштабных сценариев, таких как поддержка клиентов, образование и техническая помощь.",
  "claude-2.0.description": "Claude 2 предлагает ключевые улучшения для бизнеса, включая контекст до 200 тысяч токенов, снижение галлюцинаций, системные подсказки и новую функцию тестирования — вызов инструментов.",
  "claude-2.1.description": "Claude 2 предлагает ключевые улучшения для бизнеса, включая контекст до 200 тысяч токенов, снижение галлюцинаций, системные подсказки и новую функцию тестирования — вызов инструментов.",
  "claude-3-5-haiku-20241022.description": "Claude 3.5 Haiku — самая быстрая модель нового поколения от Anthropic, улучшенная по всем ключевым навыкам и превосходящая предыдущий флагман Claude 3 Opus по многим метрикам.",
  "claude-3-5-haiku-latest.description": "Claude 3.5 Haiku обеспечивает быстрые ответы для легких задач.",
  "claude-3-7-sonnet-20250219.description": "Claude Sonnet 3.7 — самая интеллектуальная модель от Anthropic и первая на рынке гибридная модель рассуждения, обеспечивающая мгновенные ответы или углублённое пошаговое мышление с тонкой настройкой.",
  "claude-3-7-sonnet-latest.description": "Claude 3.7 Sonnet — последняя и самая мощная модель от Anthropic для высокосложных задач, превосходящая по производительности, интеллекту, беглости и пониманию.",
  "claude-3-haiku-20240307.description": "Claude 3 Haiku — самая быстрая и компактная модель от Anthropic, предназначенная для мгновенных ответов с высокой точностью и скоростью.",
  "claude-3-opus-20240229.description": "Claude 3 Opus — самая мощная модель от Anthropic для высокосложных задач, превосходящая по производительности, интеллекту, беглости и пониманию.",
  "claude-3-sonnet-20240229.description": "Claude 3 Sonnet сочетает интеллект и скорость для корпоративных задач, обеспечивая высокую полезность при низкой стоимости и надежное масштабируемое развертывание.",
  "claude-haiku-4-5-20251001.description": "Claude Haiku 4.5 — самая быстрая и интеллектуальная модель серии Haiku от Anthropic, сочетающая молниеносную скорость и расширенное мышление.",
  "claude-opus-4-1-20250805-thinking.description": "Claude Opus 4.1 Thinking — продвинутая версия, способная демонстрировать процесс рассуждения.",
  "claude-opus-4-1-20250805.description": "Claude Opus 4.1 — новейшая и самая мощная модель от Anthropic для решения высоко сложных задач, превосходящая по производительности, интеллекту, беглости и пониманию.",
  "claude-opus-4-20250514.description": "Claude Opus 4 — самая мощная модель от Anthropic для решения сложных задач, обеспечивающая выдающуюся производительность, интеллект, беглость и понимание.",
  "claude-opus-4-5-20251101.description": "Claude Opus 4.5 — флагманская модель от Anthropic, сочетающая выдающийся интеллект с масштабируемой производительностью, идеально подходящая для сложных задач, требующих высококачественных ответов и рассуждений.",
  "claude-opus-4-6.description": "Claude Opus 4.6 — самая интеллектуальная модель от Anthropic для создания агентов и программирования.",
  "claude-sonnet-4-20250514-thinking.description": "Claude Sonnet 4 Thinking может выдавать как мгновенные ответы, так и пошаговое рассуждение с видимым процессом.",
  "claude-sonnet-4-20250514.description": "Claude Sonnet 4 — самая интеллектуальная модель от Anthropic на сегодняшний день, обеспечивающая мгновенные ответы или пошаговое мышление с тонкой настройкой для пользователей API.",
  "claude-sonnet-4-5-20250929.description": "Claude Sonnet 4.5 — самая интеллектуальная модель от Anthropic на сегодняшний день.",
  "codegeex-4.description": "CodeGeeX-4 — мощный AI-помощник для программирования, поддерживающий многоязычные вопросы и автодополнение кода для повышения продуктивности разработчиков.",
  "codegeex4-all-9b.description": "CodeGeeX4-ALL-9B — многоязычная модель генерации кода, поддерживающая автодополнение, генерацию кода, интерпретацию, веб-поиск, вызов функций и вопросы по репозиториям. Охватывает широкий спектр сценариев разработки ПО и является одной из лучших моделей кода с параметрами до 10B.",
  "codegemma.description": "CodeGemma — легковесная модель для различных задач программирования, обеспечивающая быструю итерацию и интеграцию.",
  "codegemma:2b.description": "CodeGemma — легковесная модель для различных задач программирования, обеспечивающая быструю итерацию и интеграцию.",
  "codellama.description": "Code Llama — LLM, ориентированная на генерацию и обсуждение кода, с широкой поддержкой языков для рабочих процессов разработчиков.",
  "codellama/CodeLlama-34b-Instruct-hf.description": "Code Llama — LLM, ориентированная на генерацию и обсуждение кода, с широкой поддержкой языков для рабочих процессов разработчиков.",
  "codellama:13b.description": "Code Llama — LLM, ориентированная на генерацию и обсуждение кода, с широкой поддержкой языков для рабочих процессов разработчиков.",
  "codellama:34b.description": "Code Llama — LLM, ориентированная на генерацию и обсуждение кода, с широкой поддержкой языков для рабочих процессов разработчиков.",
  "codellama:70b.description": "Code Llama — LLM, ориентированная на генерацию и обсуждение кода, с широкой поддержкой языков для рабочих процессов разработчиков.",
  "codeqwen.description": "CodeQwen1.5 — крупная языковая модель, обученная на обширных данных кода, предназначенная для сложных задач программирования.",
  "codestral-latest.description": "Codestral — наша самая продвинутая модель для программирования; версия v2 (январь 2025) оптимизирована для задач с низкой задержкой и высокой частотой, таких как FIM, исправление кода и генерация тестов.",
  "codestral.description": "Codestral — первая модель для программирования от Mistral AI, обеспечивающая высокое качество генерации кода.",
  "codex-mini-latest.description": "codex-mini-latest — дообученная модель o4-mini для Codex CLI. Для прямого использования через API мы рекомендуем начать с gpt-4.1.",
  "cogito-2.1:671b.description": "Cogito v2.1 671B — открытая LLM из США, свободная для коммерческого использования. Обеспечивает производительность на уровне ведущих моделей, более эффективную работу с токенами, поддержку контекста до 128k и высокую общую мощность.",
  "cogview-4.description": "CogView-4 — первая открытая модель от Zhipu для генерации изображений по тексту с поддержкой китайских иероглифов. Улучшает семантическое понимание, качество изображений и рендеринг текста на китайском и английском языках, поддерживает произвольную длину двуязычных подсказок и может генерировать изображения в любом разрешении в заданных пределах.",
  "cohere-command-r-plus.description": "Command R+ — продвинутая модель, оптимизированная для RAG, предназначенная для корпоративных задач.",
  "cohere-command-r.description": "Command R — масштабируемая генеративная модель, разработанная для RAG и использования инструментов, обеспечивающая промышленный уровень ИИ.",
  "cohere/Cohere-command-r-plus.description": "Command R+ — продвинутая модель, оптимизированная для RAG, предназначенная для корпоративных задач.",
  "cohere/Cohere-command-r.description": "Command R — масштабируемая генеративная модель, разработанная для RAG и использования инструментов, обеспечивающая промышленный уровень ИИ.",
  "cohere/command-a.description": "Command A — самая мощная модель Cohere на сегодняшний день, превосходно справляющаяся с использованием инструментов, агентами, RAG и многоязычными задачами. Поддерживает контекст длиной 256K, работает всего на двух GPU и обеспечивает на 150% большую пропускную способность по сравнению с Command R+ 08-2024.",
  "cohere/command-r-plus.description": "Command R+ — новейшая LLM от Cohere, оптимизированная для чатов и задач с длинным контекстом, обеспечивающая выдающуюся производительность, позволяя компаниям переходить от прототипов к реальному использованию.",
  "cohere/command-r.description": "Command R оптимизирована для чатов и задач с длинным контекстом, позиционируется как «масштабируемая» модель, сочетающая высокую производительность и точность, позволяя компаниям переходить от прототипов к промышленному применению.",
  "cohere/embed-v4.0.description": "Модель, преобразующая текст, изображения или смешанный контент в эмбеддинги для классификации или других задач.",
  "comfyui/flux-dev.description": "FLUX.1 Dev — высококачественная модель генерации изображений по тексту (10–50 шагов), идеально подходящая для креативных и художественных задач премиум-класса.",
  "comfyui/flux-kontext-dev.description": "FLUX.1 Kontext-dev — модель редактирования изображений с поддержкой редактирования по тексту, включая локальные изменения и перенос стиля.",
  "comfyui/flux-krea-dev.description": "FLUX.1 Krea-dev — безопасная модель генерации изображений по тексту, разработанная совместно с Krea, с встроенными фильтрами безопасности.",
  "comfyui/flux-schnell.description": "FLUX.1 Schnell — сверхбыстрая модель генерации изображений по тексту, создающая качественные изображения за 1–4 шага. Идеальна для задач в реальном времени и быстрого прототипирования.",
  "comfyui/stable-diffusion-15.description": "Stable Diffusion 1.5 — классическая модель генерации изображений по тексту с разрешением 512x512, идеально подходящая для быстрого прототипирования и творческих экспериментов.",
  "comfyui/stable-diffusion-35-inclclip.description": "Stable Diffusion 3.5 с встроенными энкодерами CLIP/T5 не требует внешних файлов энкодеров. Подходит для моделей, таких как sd3.5_medium_incl_clips, с низким потреблением ресурсов.",
  "comfyui/stable-diffusion-35.description": "Stable Diffusion 3.5 — модель нового поколения для генерации изображений по тексту с вариантами Large и Medium. Требует внешние файлы энкодеров CLIP и обеспечивает отличное качество изображений и соответствие подсказкам.",
  "comfyui/stable-diffusion-custom-refiner.description": "Пользовательская модель SDXL для преобразования изображений. Используйте имя файла custom_sd_lobe.safetensors; при наличии VAE — custom_sd_vae_lobe.safetensors. Поместите файлы моделей в соответствующие папки Comfy.",
  "comfyui/stable-diffusion-custom.description": "Пользовательская модель SD для генерации изображений по тексту. Используйте имя файла custom_sd_lobe.safetensors; при наличии VAE — custom_sd_vae_lobe.safetensors. Поместите файлы моделей в соответствующие папки Comfy.",
  "comfyui/stable-diffusion-refiner.description": "Модель SDXL для преобразования изображений, обеспечивающая высококачественные трансформации, включая перенос стиля, восстановление и креативные вариации.",
  "comfyui/stable-diffusion-xl.description": "SDXL — модель генерации изображений по тексту с поддержкой высокого разрешения 1024x1024, обеспечивающая лучшее качество и детализацию изображений.",
  "command-a-03-2025.description": "Command A — наша самая мощная модель на сегодняшний день, превосходно справляющаяся с использованием инструментов, агентами, RAG и многоязычными задачами. Поддерживает контекст до 256K, работает на двух GPU и обеспечивает на 150% большую пропускную способность по сравнению с Command R+ 08-2024.",
  "command-light-nightly.description": "Чтобы сократить интервал между основными релизами, мы предлагаем ночные сборки Command. Для серии command-light это называется command-light-nightly. Это самая новая и экспериментальная (возможно, нестабильная) версия, обновляется без уведомлений, поэтому не рекомендуется для продакшена.",
  "command-light.description": "Упрощённый и более быстрый вариант Command, почти такой же мощный, но с более высокой скоростью.",
  "command-nightly.description": "Чтобы сократить интервал между основными релизами, мы предлагаем ночные сборки Command. Для основной серии это называется command-nightly. Это самая новая и экспериментальная (возможно, нестабильная) версия, обновляется без уведомлений, поэтому не рекомендуется для продакшена.",
  "command-r-03-2024.description": "Command R — модель чата, следящая за инструкциями, с более высоким качеством, надёжностью и увеличенным окном контекста по сравнению с предыдущими версиями. Поддерживает сложные рабочие процессы, такие как генерация кода, RAG, использование инструментов и агентов.",
  "command-r-08-2024.description": "command-r-08-2024 — обновлённая модель Command R, выпущенная в августе 2024 года.",
  "command-r-plus-04-2024.description": "command-r-plus — псевдоним модели command-r-plus-04-2024, поэтому использование command-r-plus в API указывает на эту модель.",
  "command-r-plus-08-2024.description": "Command R+ — модель чата, следящая за инструкциями, с более высоким качеством, надёжностью и увеличенным окном контекста по сравнению с предыдущими версиями. Идеальна для сложных RAG-процессов и многошагового использования инструментов.",
  "command-r-plus.description": "Command R+ — высокопроизводительная LLM, предназначенная для реальных корпоративных сценариев и сложных приложений.",
  "command-r.description": "Command R — LLM, оптимизированная для чатов и задач с длинным контекстом, идеально подходящая для динамичного взаимодействия и управления знаниями.",
  "command-r7b-12-2024.description": "command-r7b-12-2024 — компактное и эффективное обновление, выпущенное в декабре 2024 года. Отлично справляется с задачами RAG, использования инструментов и агентов, требующих сложного многошагового рассуждения.",
  "command.description": "Модель чата, следящая за инструкциями, обеспечивающая более высокое качество и надёжность в языковых задачах, с увеличенным окном контекста по сравнению с базовыми генеративными моделями.",
  "computer-use-preview.description": "computer-use-preview — специализированная модель для инструмента \"использование компьютера\", обученная понимать и выполнять задачи, связанные с компьютером.",
  "dall-e-2.description": "Модель DALL·E второго поколения с более реалистичной и точной генерацией изображений и разрешением в 4 раза выше, чем у первого поколения.",
  "dall-e-3.description": "Последняя модель DALL·E, выпущенная в ноябре 2023 года, обеспечивает более реалистичную и точную генерацию изображений с улучшенной детализацией.",
  "databricks/dbrx-instruct.description": "DBRX Instruct обеспечивает надёжную обработку инструкций в различных отраслях.",
  "deepseek-ai/DeepSeek-OCR.description": "DeepSeek-OCR — это модель визуально-языкового типа от DeepSeek AI, ориентированная на оптическое распознавание текста (OCR) и «контекстное оптическое сжатие». Она исследует методы сжатия контекста из изображений, эффективно обрабатывает документы и преобразует их в структурированный текст (например, Markdown). Точно распознаёт текст на изображениях, подходит для оцифровки документов, извлечения текста и структурированной обработки.",
  "deepseek-ai/DeepSeek-R1-0528-Qwen3-8B.description": "DeepSeek-R1-0528-Qwen3-8B — это дистиллят модели DeepSeek-R1-0528 на базе Qwen3 8B. Она достигает уровня SOTA среди открытых моделей, превосходя Qwen3 8B на 10% в AIME 2024 и сопоставима с производительностью Qwen3-235B-thinking. Отличается выдающимися результатами в математике, программировании и логике. Использует архитектуру Qwen3-8B и токенизатор DeepSeek-R1-0528.",
  "deepseek-ai/DeepSeek-R1-0528.description": "DeepSeek R1 использует дополнительные вычислительные ресурсы и алгоритмические оптимизации постобучения для углубления рассуждений. Демонстрирует высокие результаты в математике, программировании и логике, приближаясь к лидерам, таким как o3 и Gemini 2.5 Pro.",
  "deepseek-ai/DeepSeek-R1-Distill-Llama-70B.description": "Дистиллированные модели DeepSeek-R1 используют обучение с подкреплением и cold-start данные для улучшения рассуждений и установления новых стандартов среди открытых моделей для многозадачных сценариев.",
  "deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B.description": "Дистиллированные модели DeepSeek-R1 используют обучение с подкреплением и cold-start данные для улучшения рассуждений и установления новых стандартов среди открытых моделей для многозадачных сценариев.",
  "deepseek-ai/DeepSeek-R1-Distill-Qwen-14B.description": "Дистиллированные модели DeepSeek-R1 используют обучение с подкреплением и cold-start данные для улучшения рассуждений и установления новых стандартов среди открытых моделей для многозадачных сценариев.",
  "deepseek-ai/DeepSeek-R1-Distill-Qwen-32B.description": "DeepSeek-R1-Distill-Qwen-32B — дистиллят модели Qwen2.5-32B, дообученный на 800 тысячах отобранных выборок DeepSeek-R1. Отличается выдающимися результатами в математике, программировании и логике, достигая высоких показателей на AIME 2024, MATH-500 (94.3% точности) и GPQA Diamond.",
  "deepseek-ai/DeepSeek-R1-Distill-Qwen-7B.description": "DeepSeek-R1-Distill-Qwen-7B — дистиллят модели Qwen2.5-Math-7B, дообученный на 800 тысячах отобранных выборок DeepSeek-R1. Демонстрирует высокие результаты: 92.8% на MATH-500, 55.5% на AIME 2024 и рейтинг 1189 на CodeForces для модели 7B.",
  "deepseek-ai/DeepSeek-R1.description": "DeepSeek-R1 улучшает рассуждения с помощью обучения с подкреплением и cold-start данных, устанавливая новые стандарты среди открытых моделей и превосходя OpenAI-o1-mini.",
  "deepseek-ai/DeepSeek-V2.5.description": "DeepSeek-V2.5 — это обновление моделей DeepSeek-V2-Chat и DeepSeek-Coder-V2-Instruct, объединяющее общие и программные способности. Улучшает написание текстов и следование инструкциям для лучшего соответствия предпочтениям, демонстрируя значительный прогресс на AlpacaEval 2.0, ArenaHard, AlignBench и MT-Bench.",
  "deepseek-ai/DeepSeek-V3.1-Terminus.description": "DeepSeek-V3.1-Terminus — обновлённая модель V3.1, позиционируемая как гибридный агентный LLM. Исправляет ошибки, сообщённые пользователями, повышает стабильность, согласованность языка и снижает количество смешанных китайско-английских и некорректных символов. Интегрирует режимы мышления и немышления с шаблонами чата для гибкого переключения. Также улучшает производительность Code Agent и Search Agent для более надёжного использования инструментов и выполнения многошаговых задач.",
  "deepseek-ai/DeepSeek-V3.1.description": "DeepSeek V3.1 использует гибридную архитектуру рассуждений и поддерживает как режим мышления, так и немышления.",
  "deepseek-ai/DeepSeek-V3.2-Exp.description": "DeepSeek-V3.2-Exp — экспериментальный выпуск V3.2, переходный к следующей архитектуре. Добавляет DeepSeek Sparse Attention (DSA) поверх V3.1-Terminus для повышения эффективности обучения и вывода на длинных контекстах, с оптимизациями для использования инструментов, понимания длинных документов и многошагового рассуждения. Идеально подходит для изучения более эффективного рассуждения при больших объёмах контекста.",
  "deepseek-ai/DeepSeek-V3.description": "DeepSeek-V3 — модель MoE с 671 миллиардами параметров, использующая MLA и DeepSeekMoE с балансировкой нагрузки без потерь для эффективного обучения и вывода. Предобучена на 14.8 триллионах высококачественных токенов с использованием SFT и RL, превосходит другие открытые модели и приближается к ведущим закрытым решениям.",
  "deepseek-ai/deepseek-llm-67b-chat.description": "DeepSeek LLM Chat (67B) — инновационная модель с глубоким пониманием языка и возможностью взаимодействия.",
  "deepseek-ai/deepseek-v3.1-terminus.description": "DeepSeek V3.1 — модель нового поколения для рассуждений, обладающая улучшенными возможностями для сложных рассуждений и цепочек размышлений, подходящая для задач глубокого анализа.",
  "deepseek-ai/deepseek-v3.1.description": "DeepSeek V3.1 — модель нового поколения для рассуждений, обладающая улучшенными возможностями для сложных рассуждений и цепочек размышлений, подходящая для задач глубокого анализа.",
  "deepseek-ai/deepseek-vl2.description": "DeepSeek-VL2 — модель визуально-языкового типа MoE на базе DeepSeekMoE-27B с разреженной активацией, достигающая высокой производительности при использовании всего 4.5B активных параметров. Отличается в задачах визуального QA, OCR, понимания документов/таблиц/диаграмм и визуального связывания.",
  "deepseek-chat.description": "DeepSeek V3.2 сочетает в себе баланс между рассуждением и длиной вывода для повседневных задач вопросов-ответов и агентов. На публичных бенчмарках достигает уровня GPT-5 и первой интегрирует мышление в использование инструментов, лидируя в оценках среди моделей с открытым кодом.",
  "deepseek-coder-33B-instruct.description": "DeepSeek Coder 33B — языковая модель для программирования, обученная на 2 триллионах токенов (87% кода, 13% китайского/английского текста). Поддерживает контекстное окно 16K и задачи заполнения в середине, обеспечивая автодополнение на уровне проекта и вставку фрагментов кода.",
  "deepseek-coder-v2.description": "DeepSeek Coder V2 — модель кода с открытым исходным кодом, демонстрирующая высокую производительность в задачах программирования, сопоставимую с GPT-4 Turbo.",
  "deepseek-coder-v2:236b.description": "DeepSeek Coder V2 — модель кода с открытым исходным кодом, демонстрирующая высокую производительность в задачах программирования, сопоставимую с GPT-4 Turbo.",
  "deepseek-ocr.description": "DeepSeek-OCR — визуально-языковая модель от DeepSeek AI, ориентированная на OCR и «контекстное оптическое сжатие». Она исследует методы сжатия контекста из изображений, эффективно обрабатывает документы и преобразует их в структурированные текстовые форматы, такие как Markdown. Точно распознаёт текст на изображениях, идеально подходит для оцифровки документов, извлечения текста и структурированной обработки.",
  "deepseek-r1-0528.description": "Полная модель 685B выпущена 28.05.2025. DeepSeek-R1 использует масштабное обучение с подкреплением на этапе постобучения, значительно улучшая логическое мышление при минимуме размеченных данных. Демонстрирует высокие результаты в математике, программировании и языковом рассуждении.",
  "deepseek-r1-250528.description": "DeepSeek R1 250528 — это полная модель логического вывода DeepSeek-R1, предназначенная для сложных математических и логических задач.",
  "deepseek-r1-70b-fast-online.description": "Быстрая версия DeepSeek R1 70B с поддержкой поиска в интернете в реальном времени, обеспечивающая быстрые ответы при сохранении высокой производительности.",
  "deepseek-r1-70b-online.description": "Стандартная версия DeepSeek R1 70B с поиском в интернете в реальном времени, подходящая для актуальных диалогов и текстовых задач.",
  "deepseek-r1-distill-llama-70b.description": "DeepSeek R1 Distill Llama 70B сочетает логическое мышление R1 с экосистемой Llama.",
  "deepseek-r1-distill-llama-8b.description": "DeepSeek-R1-Distill-Llama-8B — дистиллированная модель на основе Llama-3.1-8B, обученная на выходных данных DeepSeek R1.",
  "deepseek-r1-distill-llama.description": "deepseek-r1-distill-llama — дистиллированная модель DeepSeek-R1 на базе Llama.",
  "deepseek-r1-distill-qianfan-70b.description": "DeepSeek R1 Distill Qianfan 70B — дистиллированная модель R1 на основе Qianfan-70B с высокой ценностью.",
  "deepseek-r1-distill-qianfan-8b.description": "DeepSeek R1 Distill Qianfan 8B — дистиллированная модель R1 на базе Qianfan-8B, предназначенная для малых и средних приложений.",
  "deepseek-r1-distill-qianfan-llama-70b.description": "DeepSeek R1 Distill Qianfan Llama 70B — дистиллированная модель R1 на основе Llama-70B.",
  "deepseek-r1-distill-qwen-1.5b.description": "DeepSeek R1 Distill Qwen 1.5B — сверхлёгкая дистиллированная модель для сред с ограниченными ресурсами.",
  "deepseek-r1-distill-qwen-14b.description": "DeepSeek R1 Distill Qwen 14B — дистиллированная модель среднего размера для многосценарного применения.",
  "deepseek-r1-distill-qwen-32b.description": "DeepSeek R1 Distill Qwen 32B — дистиллированная модель R1 на базе Qwen-32B, обеспечивающая баланс между производительностью и стоимостью.",
  "deepseek-r1-distill-qwen-7b.description": "DeepSeek R1 Distill Qwen 7B — лёгкая дистиллированная модель для периферийных и корпоративных сред.",
  "deepseek-r1-distill-qwen.description": "deepseek-r1-distill-qwen — дистиллированная модель DeepSeek-R1 на базе Qwen.",
  "deepseek-r1-fast-online.description": "Быстрая полная версия DeepSeek R1 с поиском в интернете в реальном времени, объединяющая возможности масштаба 671B и ускоренный отклик.",
  "deepseek-r1-online.description": "Полная версия DeepSeek R1 с 671B параметрами и поиском в интернете в реальном времени, обеспечивающая улучшенное понимание и генерацию.",
  "deepseek-r1.description": "DeepSeek-R1 использует данные холодного старта до этапа RL и демонстрирует сопоставимую с OpenAI-o1 производительность в математике, программировании и логическом мышлении.",
  "deepseek-reasoner.description": "DeepSeek V3.2 Thinking — модель глубокого рассуждения, которая генерирует цепочку размышлений перед выводом для повышения точности. Демонстрирует выдающиеся результаты в соревнованиях и рассуждении, сравнимом с Gemini-3.0-Pro.",
  "deepseek-v2.description": "DeepSeek V2 — эффективная модель MoE для экономичной обработки.",
  "deepseek-v2:236b.description": "DeepSeek V2 236B — модель DeepSeek, ориентированная на программирование, с высокой способностью к генерации кода.",
  "deepseek-v3-0324.description": "DeepSeek-V3-0324 — модель MoE с 671B параметрами, выделяющаяся в программировании, технических задачах, понимании контекста и работе с длинными текстами.",
  "deepseek-v3.1-terminus.description": "DeepSeek-V3.1-Terminus — оптимизированная для терминальных устройств LLM от DeepSeek.",
  "deepseek-v3.1-think-250821.description": "DeepSeek V3.1 Think 250821 — модель глубокого мышления, соответствующая версии Terminus, созданная для высокоэффективного логического вывода.",
  "deepseek-v3.1.description": "DeepSeek-V3.1 — гибридная модель логического вывода нового поколения от DeepSeek, поддерживающая режимы с мышлением и без, с более высокой эффективностью мышления по сравнению с DeepSeek-R1-0528. Оптимизации после обучения значительно улучшают использование инструментов агентами и выполнение задач. Поддерживает окно контекста 128k и до 64k выходных токенов.",
  "deepseek-v3.1:671b.description": "DeepSeek V3.1 — модель логического вывода следующего поколения с улучшенным сложным мышлением и цепочкой рассуждений, подходящая для задач, требующих глубокого анализа.",
  "deepseek-v3.2-exp.description": "deepseek-v3.2-exp внедряет разреженное внимание для повышения эффективности обучения и вывода на длинных текстах по более низкой цене, чем deepseek-v3.1.",
  "deepseek-v3.2-think.description": "DeepSeek V3.2 Think — полноценная модель глубокого мышления с усиленным длинноцепочечным рассуждением.",
  "deepseek-v3.2.description": "DeepSeek-V3.2 — первая гибридная модель рассуждения от DeepSeek, интегрирующая мышление в использование инструментов. Использует эффективную архитектуру для снижения вычислительных затрат, масштабное обучение с подкреплением для повышения возможностей и синтетические задачи для лучшей обобщаемости. Эта комбинация обеспечивает производительность, сопоставимую с GPT-5-High, при значительно меньшей длине вывода, что снижает нагрузку и время ожидания пользователя.",
  "deepseek-v3.description": "DeepSeek-V3 — мощная модель MoE с 671B общих параметров и 37B активных на токен.",
  "deepseek-vl2-small.description": "DeepSeek VL2 Small — лёгкая мультимодальная модель для сред с ограниченными ресурсами и высокой нагрузкой.",
  "deepseek-vl2.description": "DeepSeek VL2 — мультимодальная модель для понимания изображений и текста и точного визуального вопросо-ответа.",
  "deepseek/deepseek-chat-v3-0324.description": "DeepSeek V3 — модель MoE с 685B параметрами и последняя итерация флагманской серии чатов DeepSeek.\n\nОснована на [DeepSeek V3](/deepseek/deepseek-chat-v3) и демонстрирует высокую производительность в различных задачах.",
  "deepseek/deepseek-chat-v3-0324:free.description": "DeepSeek V3 — модель MoE с 685B параметрами и последняя итерация флагманской серии чатов DeepSeek.\n\nОснована на [DeepSeek V3](/deepseek/deepseek-chat-v3) и демонстрирует высокую производительность в различных задачах.",
  "deepseek/deepseek-chat-v3.1.description": "DeepSeek-V3.1 — гибридная модель логического вывода с длинным контекстом от DeepSeek, поддерживающая смешанные режимы мышления/без мышления и интеграцию инструментов.",
  "deepseek/deepseek-chat.description": "DeepSeek-V3 — высокопроизводительная гибридная модель логического вывода от DeepSeek для сложных задач и интеграции инструментов.",
  "deepseek/deepseek-math-v2.description": "DeepSeek Math V2 — это модель, достигшая значительных прорывов в области математического рассуждения. Её ключевое новшество — механизм обучения с «самопроверкой», благодаря которому она достигла уровня золотой медали на нескольких ведущих математических соревнованиях.",
  "deepseek/deepseek-r1-0528.description": "DeepSeek R1 0528 — обновлённый вариант, ориентированный на открытую доступность и более глубокое логическое мышление.",
  "deepseek/deepseek-r1-0528:free.description": "DeepSeek-R1 значительно улучшает логическое мышление при минимуме размеченных данных и выводит цепочку рассуждений перед финальным ответом для повышения точности.",
  "deepseek/deepseek-r1-distill-llama-70b.description": "DeepSeek R1 Distill Llama 70B — дистиллированная LLM на основе Llama 3.3 70B, дообученная на выходных данных DeepSeek R1 для достижения конкурентной производительности с передовыми моделями.",
  "deepseek/deepseek-r1-distill-llama-8b.description": "DeepSeek R1 Distill Llama 8B — дистиллированная LLM на основе Llama-3.1-8B-Instruct, обученная на выходных данных DeepSeek R1.",
  "deepseek/deepseek-r1-distill-qwen-14b.description": "DeepSeek R1 Distill Qwen 14B — дистиллированная LLM на основе Qwen 2.5 14B, обученная на выходных данных DeepSeek R1. Превосходит OpenAI o1-mini по нескольким бенчмаркам, достигая передовых результатов среди плотных моделей. Основные показатели:\nAIME 2024 pass@1: 69.7\nMATH-500 pass@1: 93.9\nРейтинг CodeForces: 1481\nДообучение на выходных данных DeepSeek R1 обеспечивает конкурентную производительность с более крупными моделями.",
  "deepseek/deepseek-r1-distill-qwen-32b.description": "DeepSeek R1 Distill Qwen 32B — дистиллированная LLM на основе Qwen 2.5 32B, обученная на выходных данных DeepSeek R1. Превосходит OpenAI o1-mini по нескольким бенчмаркам, достигая передовых результатов среди плотных моделей. Основные показатели:\nAIME 2024 pass@1: 72.6\nMATH-500 pass@1: 94.3\nРейтинг CodeForces: 1691\nДообучение на выходных данных DeepSeek R1 обеспечивает конкурентную производительность с более крупными моделями.",
  "deepseek/deepseek-r1.description": "DeepSeek R1 обновлён до версии DeepSeek-R1-0528. Благодаря увеличенным вычислениям и алгоритмическим оптимизациям после обучения, модель значительно улучшает глубину и качество логического мышления. Демонстрирует высокие результаты в математике, программировании и логике, приближаясь к лидерам, таким как o3 и Gemini 2.5 Pro.",
  "deepseek/deepseek-r1/community.description": "DeepSeek R1 — последняя открытая модель от команды DeepSeek с очень высокой производительностью в логическом мышлении, особенно в математике, программировании и рассуждении, сопоставимая с OpenAI o1.",
  "deepseek/deepseek-r1:free.description": "DeepSeek-R1 значительно улучшает логическое мышление при минимуме размеченных данных и выводит цепочку рассуждений перед финальным ответом для повышения точности.",
  "deepseek/deepseek-reasoner.description": "DeepSeek-V3 Thinking (reasoner) — экспериментальная модель логического мышления от DeepSeek, подходящая для задач высокой сложности.",
  "deepseek/deepseek-v3.1-base.description": "DeepSeek V3.1 Base — улучшенная версия модели DeepSeek V3.",
  "deepseek/deepseek-v3.description": "Быстрая универсальная LLM с улучшенным логическим мышлением.",
  "deepseek/deepseek-v3/community.description": "DeepSeek-V3 обеспечивает значительный прорыв в скорости логического мышления по сравнению с предыдущими моделями. Занимает первое место среди открытых моделей и соперничает с самыми продвинутыми закрытыми решениями. DeepSeek-V3 использует Multi-Head Latent Attention (MLA) и архитектуру DeepSeekMoE, проверенные в DeepSeek-V2. Также внедрена вспомогательная стратегия без потерь для балансировки нагрузки и цель многотокенного предсказания для повышения производительности.",
  "deepseek_r1.description": "DeepSeek-R1 — модель логического мышления, основанная на обучении с подкреплением, решающая проблемы повторов и читаемости. До этапа RL использует данные холодного старта для повышения качества рассуждений. Сопоставима с OpenAI-o1 в задачах по математике, программированию и логике, с тщательно продуманным обучением для улучшения общих результатов.",
  "deepseek_r1_distill_llama_70b.description": "DeepSeek-R1-Distill-Llama-70B — дистиллированная модель на основе Llama-3.3-70B-Instruct. Является частью серии DeepSeek-R1, дообучена на выборках, сгенерированных DeepSeek-R1, и демонстрирует высокие результаты в математике, программировании и логике.",
  "deepseek_r1_distill_qwen_14b.description": "DeepSeek-R1-Distill-Qwen-14B — дистиллированная модель на основе Qwen2.5-14B, дообученная на 800K отобранных выборках, сгенерированных DeepSeek-R1, обеспечивая высокое качество логического мышления.",
  "deepseek_r1_distill_qwen_32b.description": "DeepSeek-R1-Distill-Qwen-32B — дистиллированная модель на основе Qwen2.5-32B, дообученная на 800K отобранных выборках, сгенерированных DeepSeek-R1, превосходящая в математике, программировании и логике.",
  "devstral-2:123b.description": "Devstral 2 123B превосходно использует инструменты для анализа кодовой базы, редактирования нескольких файлов и поддержки агентов в области программной инженерии.",
  "doubao-1.5-lite-32k.description": "Doubao-1.5-lite — новая облегчённая модель с ультрабыстрым откликом, обеспечивающая высокое качество и низкую задержку.",
  "doubao-1.5-pro-256k.description": "Doubao-1.5-pro-256k — комплексное обновление модели Doubao-1.5-Pro, повышающее общую производительность на 10%. Поддерживает контекстное окно 256k и до 12k токенов вывода, обеспечивая высокую производительность, расширенное окно и отличную ценность для широкого спектра задач.",
  "doubao-1.5-pro-32k.description": "Doubao-1.5-pro — флагманская модель нового поколения с улучшениями по всем направлениям, превосходящая в знаниях, программировании и рассуждении.",
  "doubao-1.5-thinking-pro-m.description": "Doubao-1.5 — новая модель глубокого рассуждения (версия m включает нативное мультимодальное глубокое рассуждение), превосходящая в математике, программировании, научном анализе и общих задачах, таких как креативное письмо. Достигает или приближается к топовым результатам на бенчмарках AIME 2024, Codeforces и GPQA. Поддерживает контекстное окно 128k и вывод до 16k токенов.",
  "doubao-1.5-thinking-pro.description": "Doubao-1.5 — новая модель глубокого рассуждения, превосходящая в математике, программировании, научном анализе и общих задачах, таких как креативное письмо. Достигает или приближается к топовым результатам на бенчмарках AIME 2024, Codeforces и GPQA. Поддерживает контекстное окно 128k и вывод до 16k токенов.",
  "doubao-1.5-thinking-vision-pro.description": "Новая визуальная модель глубокого рассуждения с улучшенным мультимодальным пониманием и логикой, достигающая SOTA-результатов на 37 из 59 публичных бенчмарков.",
  "doubao-1.5-ui-tars.description": "Doubao-1.5-UI-TARS — нативная модель-агент, ориентированная на графический интерфейс, которая взаимодействует с интерфейсами через человекоподобное восприятие, рассуждение и действия.",
  "doubao-1.5-vision-lite.description": "Doubao-1.5-vision-lite — обновлённая мультимодальная модель, поддерживающая изображения любого разрешения и экстремальных соотношений сторон, улучшая визуальное рассуждение, распознавание документов, понимание деталей и следование инструкциям. Поддерживает контекстное окно 128k и до 16k токенов вывода.",
  "doubao-1.5-vision-pro-32k.description": "Doubao-1.5-vision-pro — обновлённая мультимодальная модель, поддерживающая изображения любого разрешения и экстремальных соотношений сторон, улучшая визуальное рассуждение, распознавание документов, понимание деталей и следование инструкциям.",
  "doubao-1.5-vision-pro.description": "Doubao-1.5-vision-pro — обновлённая мультимодальная модель, поддерживающая изображения любого разрешения и экстремальных соотношений сторон, улучшая визуальное рассуждение, распознавание документов, понимание деталей и следование инструкциям.",
  "doubao-lite-128k.description": "Ультрабыстрый отклик с лучшей ценностью, предлагая более гибкие варианты для различных сценариев. Поддерживает рассуждение и дообучение с контекстным окном 128k.",
  "doubao-lite-32k.description": "Ультрабыстрый отклик с лучшей ценностью, предлагая более гибкие варианты для различных сценариев. Поддерживает рассуждение и дообучение с контекстным окном 32k.",
  "doubao-lite-4k.description": "Ультрабыстрый отклик с лучшей ценностью, предлагая более гибкие варианты для различных сценариев. Поддерживает рассуждение и дообучение с контекстным окном 4k.",
  "doubao-pro-256k.description": "Флагманская модель с наилучшей производительностью для сложных задач, демонстрирующая отличные результаты в вопросах по справочным данным, суммировании, создании контента, классификации текста и ролевых играх. Поддерживает рассуждение и дообучение с контекстным окном 256k.",
  "doubao-pro-32k.description": "Флагманская модель с наилучшей производительностью для сложных задач, демонстрирующая отличные результаты в вопросах по справочным данным, суммировании, создании контента, классификации текста и ролевых играх. Поддерживает рассуждение и дообучение с контекстным окном 32k.",
  "doubao-seed-1.6-flash.description": "Doubao-Seed-1.6-flash — ультрабыстрая мультимодальная модель глубокого рассуждения с TPOT до 10 мс. Поддерживает текст и изображения, превосходит предыдущую lite-модель в понимании текста и сопоставима с pro-моделями в области зрения. Поддерживает контекстное окно 256k и до 16k токенов вывода.",
  "doubao-seed-1.6-lite.description": "Doubao-Seed-1.6-lite — новая мультимодальная модель глубокого рассуждения с регулируемой степенью рассуждения (минимальная, низкая, средняя, высокая), обеспечивающая лучшую ценность и отличный выбор для повседневных задач. Поддерживает контекст до 256k.",
  "doubao-seed-1.6-thinking.description": "Doubao-Seed-1.6-thinking значительно усиливает рассуждение, улучшая ключевые способности в программировании, математике и логике по сравнению с Doubao-1.5-thinking-pro, а также добавляет понимание изображений. Поддерживает контекстное окно 256k и до 16k токенов вывода.",
  "doubao-seed-1.6-vision.description": "Doubao-Seed-1.6-vision — визуальная модель глубокого рассуждения с улучшенным мультимодальным пониманием и логикой для образования, анализа изображений, инспекции/безопасности и визуального поиска с вопросами и ответами. Поддерживает контекст до 256k и до 64k токенов вывода.",
  "doubao-seed-1.6.description": "Doubao-Seed-1.6 — новая мультимодальная модель глубокого рассуждения с режимами авто, мышления и без мышления. В режиме без мышления значительно превосходит Doubao-1.5-pro/250115. Поддерживает контекст до 256k и до 16k токенов вывода.",
  "doubao-seed-1.8.description": "Doubao-Seed-1.8 обладает улучшенным мультимодальным пониманием и агентными возможностями, поддерживает ввод текста, изображений и видео, а также кэширование контекста, обеспечивая высокую эффективность при выполнении сложных задач.",
  "doubao-seed-code.description": "Doubao-Seed-Code глубоко оптимизирован для агентного программирования, поддерживает мультимодальный ввод (текст/изображение/видео) и контекстное окно 256k, совместим с API Anthropic и подходит для программирования, понимания изображений и рабочих процессов агентов.",
  "doubao-seededit-3-0-i2i-250628.description": "Модель изображений Doubao от ByteDance Seed поддерживает ввод текста и изображений с высококачественной и управляемой генерацией изображений. Поддерживает редактирование изображений по тексту с размерами вывода от 512 до 1536 по длинной стороне.",
  "doubao-seedream-3-0-t2i-250415.description": "Seedream 3.0 — модель генерации изображений от ByteDance Seed, поддерживающая ввод текста и изображений с высококачественной и управляемой генерацией. Генерирует изображения по текстовым подсказкам.",
  "doubao-seedream-4-0-250828.description": "Seedream 4.0 — модель генерации изображений от ByteDance Seed, поддерживающая ввод текста и изображений с высококачественной и управляемой генерацией. Генерирует изображения по текстовым подсказкам.",
  "doubao-vision-lite-32k.description": "Doubao-vision — мультимодальная модель от Doubao с сильным пониманием изображений и логикой, а также точным следованием инструкциям. Отлично справляется с извлечением информации из изображений и задачами визуального рассуждения, расширяя возможности визуальных вопросов и ответов.",
  "doubao-vision-pro-32k.description": "Doubao-vision — мультимодальная модель от Doubao с сильным пониманием изображений и логикой, а также точным следованием инструкциям. Отлично справляется с извлечением информации из изображений и задачами визуального рассуждения, расширяя возможности визуальных вопросов и ответов.",
  "emohaa.description": "Emohaa — модель для поддержки психического здоровья с профессиональными навыками консультирования, помогающая пользователям разобраться в эмоциональных проблемах.",
  "ernie-4.5-0.3b.description": "ERNIE 4.5 0.3B — легковесная модель с открытым исходным кодом для локального и кастомизированного развертывания.",
  "ernie-4.5-21b-a3b.description": "ERNIE 4.5 21B A3B — крупная модель с открытым исходным кодом, обладающая улучшенными возможностями понимания и генерации.",
  "ernie-4.5-300b-a47b.description": "ERNIE 4.5 300B A47B — сверхкрупная модель MoE от Baidu ERNIE с выдающимися способностями к рассуждению.",
  "ernie-4.5-8k-preview.description": "ERNIE 4.5 8K Preview — модель с контекстом 8K для предварительной оценки возможностей ERNIE 4.5.",
  "ernie-4.5-turbo-128k-preview.description": "Предварительная версия ERNIE 4.5 Turbo 128K с возможностями уровня релиза, подходящая для интеграции и тестирования.",
  "ernie-4.5-turbo-128k.description": "ERNIE 4.5 Turbo 128K — высокопроизводительная универсальная модель с поддержкой поиска и вызова инструментов для задач Вопрос-Ответ, программирования и агентов.",
  "ernie-4.5-turbo-32k.description": "ERNIE 4.5 Turbo 32K — версия со средним контекстом для Вопрос-Ответ, поиска в базе знаний и многотурового диалога.",
  "ernie-4.5-turbo-latest.description": "Актуальная версия ERNIE 4.5 Turbo с оптимизированной общей производительностью, идеально подходит в качестве основной модели для продакшена.",
  "ernie-4.5-turbo-vl-32k-preview.description": "ERNIE 4.5 Turbo VL 32K Preview — предварительная мультимодальная модель с контекстом 32K для оценки возможностей в области зрения.",
  "ernie-4.5-turbo-vl-32k.description": "ERNIE 4.5 Turbo VL 32K — мультимодальная модель со средне-длинным контекстом для понимания длинных документов и изображений.",
  "ernie-4.5-turbo-vl-latest.description": "ERNIE 4.5 Turbo VL Latest — новейшая мультимодальная модель с улучшенным пониманием изображений и текста, а также рассуждением.",
  "ernie-4.5-turbo-vl-preview.description": "ERNIE 4.5 Turbo VL Preview — предварительная мультимодальная модель для понимания и генерации изображений и текста, подходит для визуального Вопрос-Ответ и анализа контента.",
  "ernie-4.5-turbo-vl.description": "ERNIE 4.5 Turbo VL — зрелая мультимодальная модель для промышленного понимания и распознавания изображений и текста.",
  "ernie-4.5-vl-28b-a3b.description": "ERNIE 4.5 VL 28B A3B — мультимодальная модель с открытым исходным кодом для понимания изображений и текста, а также рассуждения.",
  "ernie-5.0-thinking-latest.description": "Wenxin 5.0 Thinking — флагманская модель с нативной полной мультимодальностью, объединяющая текст, изображение, аудио и видео. Обеспечивает широкие улучшения для сложных задач Вопрос-Ответ, творчества и агентов.",
  "ernie-5.0-thinking-preview.description": "Wenxin 5.0 Thinking Preview — предварительная версия флагманской мультимодальной модели с объединением текста, изображения, аудио и видео. Обеспечивает широкие улучшения для сложных задач Вопрос-Ответ, творчества и агентов.",
  "ernie-char-8k.description": "ERNIE Character 8K — модель диалога с персонажем для создания IP-образов и длительного общения.",
  "ernie-char-fiction-8k-preview.description": "ERNIE Character Fiction 8K Preview — предварительная модель для создания персонажей и сюжетов, предназначенная для оценки и тестирования.",
  "ernie-char-fiction-8k.description": "ERNIE Character Fiction 8K — модель персонажа для написания романов и создания сюжетов, подходит для генерации длинных историй.",
  "ernie-irag-edit.description": "ERNIE iRAG Edit — модель редактирования изображений с поддержкой стирания, перерисовки и генерации вариантов.",
  "ernie-lite-pro-128k.description": "ERNIE Lite Pro 128K — легковесная высокопроизводительная модель для сценариев с чувствительностью к задержке и стоимости.",
  "ernie-novel-8k.description": "ERNIE Novel 8K предназначена для написания длинных романов и IP-сюжетов с участием нескольких персонажей.",
  "ernie-speed-pro-128k.description": "ERNIE Speed Pro 128K — модель с высокой пропускной способностью и ценностью для масштабных онлайн-сервисов и корпоративных приложений.",
  "ernie-x1-turbo-32k.description": "ERNIE X1 Turbo 32K — быстрая модель мышления с контекстом 32K для сложного рассуждения и многотурового общения.",
  "ernie-x1.1-preview.description": "ERNIE X1.1 Preview — предварительная версия модели мышления для оценки и тестирования.",
  "fal-ai/bytedance/seedream/v4.5.description": "Seedream 4.5, разработанная командой ByteDance Seed, поддерживает редактирование и компоновку нескольких изображений. Обеспечивает улучшенную согласованность объектов, точное следование инструкциям, понимание пространственной логики, эстетическое выражение, макет постеров и дизайн логотипов с высокоточной визуализацией текста и изображений.",
  "fal-ai/bytedance/seedream/v4.description": "Seedream 4.0, разработанная ByteDance Seed, поддерживает ввод текста и изображений для высококачественной генерации изображений с высокой степенью управляемости.",
  "fal-ai/flux-kontext/dev.description": "Модель FLUX.1, ориентированная на редактирование изображений, поддерживает ввод текста и изображений.",
  "fal-ai/flux-pro/kontext.description": "FLUX.1 Kontext [pro] принимает текст и эталонные изображения, позволяя выполнять локальные правки и сложные глобальные трансформации сцены.",
  "fal-ai/flux/krea.description": "Flux Krea [dev] — модель генерации изображений с эстетическим уклоном в сторону более реалистичных и естественных изображений.",
  "fal-ai/flux/schnell.description": "FLUX.1 [schnell] — модель генерации изображений с 12 миллиардами параметров, созданная для быстрой и качественной генерации.",
  "fal-ai/hunyuan-image/v3.description": "Мощная нативная мультимодальная модель генерации изображений.",
  "fal-ai/imagen4/preview.description": "Модель генерации изображений высокого качества от Google.",
  "fal-ai/nano-banana.description": "Nano Banana — новейшая, самая быстрая и эффективная нативная мультимодальная модель от Google, поддерживающая генерацию и редактирование изображений в диалоговом режиме.",
  "fal-ai/qwen-image-edit.description": "Профессиональная модель редактирования изображений от команды Qwen, поддерживающая семантическое и визуальное редактирование, точное редактирование текста на китайском и английском, перенос стиля, поворот и многое другое.",
  "fal-ai/qwen-image.description": "Мощная модель генерации изображений от команды Qwen с отличной визуализацией китайского текста и разнообразными визуальными стилями.",
  "flux-1-schnell.description": "Модель преобразования текста в изображение с 12 миллиардами параметров от Black Forest Labs, использующая латентную диффузию с дистилляцией для генерации качественных изображений за 1–4 шага. Конкурирует с закрытыми аналогами и распространяется по лицензии Apache-2.0 для личного, исследовательского и коммерческого использования.",
  "flux-dev.description": "FLUX.1 [dev] — модель с открытыми весами для некоммерческого использования. Сохраняет почти профессиональное качество изображений и следование инструкциям при более эффективной работе и лучшем использовании ресурсов по сравнению со стандартными моделями аналогичного размера.",
  "flux-kontext-max.description": "Передовая генерация и редактирование изображений с учётом контекста, объединяющая текст и изображения для точных и согласованных результатов.",
  "flux-kontext-pro.description": "Передовая генерация и редактирование изображений с учётом контекста, объединяющая текст и изображения для точных и согласованных результатов.",
  "flux-merged.description": "FLUX.1-merged объединяет глубокие возможности, исследованные в «DEV», с высокой скоростью «Schnell», расширяя границы производительности и области применения.",
  "flux-pro-1.1-ultra.description": "Генерация изображений сверхвысокого разрешения с выходом 4 МП, создаёт чёткие изображения за 10 секунд.",
  "flux-pro-1.1.description": "Обновлённая профессиональная модель генерации изображений с отличным качеством и точным следованием подсказкам.",
  "flux-pro.description": "Коммерческая модель генерации изображений высшего уровня с непревзойдённым качеством и разнообразием результатов.",
  "flux-schnell.description": "FLUX.1 [schnell] — самая продвинутая open-source модель с малым числом шагов, превосходящая аналогичные модели и даже сильные недистиллированные модели, такие как Midjourney v6.0 и DALL-E 3 (HD). Тщательно настроена для сохранения разнообразия предобучения, значительно улучшая визуальное качество, следование инструкциям, вариативность размеров/пропорций, работу со шрифтами и разнообразие вывода.",
  "flux.1-schnell.description": "FLUX.1-schnell — высокопроизводительная модель генерации изображений для быстрой генерации в разных стилях.",
  "gemini-1.0-pro-001.description": "Gemini 1.0 Pro 001 (Tuning) обеспечивает стабильную и настраиваемую производительность для сложных задач.",
  "gemini-1.0-pro-002.description": "Gemini 1.0 Pro 002 (Tuning) обеспечивает мощную мультимодальную поддержку для сложных задач.",
  "gemini-1.0-pro-latest.description": "Gemini 1.0 Pro — высокопроизводительная модель ИИ от Google, предназначенная для масштабирования широкого спектра задач.",
  "gemini-1.5-flash-001.description": "Gemini 1.5 Flash 001 — эффективная мультимодальная модель для масштабируемого применения.",
  "gemini-1.5-flash-002.description": "Gemini 1.5 Flash 002 — эффективная мультимодальная модель, созданная для широкого внедрения.",
  "gemini-1.5-flash-8b-exp-0924.description": "Gemini 1.5 Flash 8B 0924 — новейшая экспериментальная модель с заметными улучшениями в текстовых и мультимодальных сценариях.",
  "gemini-1.5-flash-8b-latest.description": "Gemini 1.5 Flash 8B — эффективная мультимодальная модель, созданная для широкого внедрения.",
  "gemini-1.5-flash-8b.description": "Gemini 1.5 Flash 8B — эффективная мультимодальная модель для масштабируемого применения.",
  "gemini-1.5-flash-exp-0827.description": "Gemini 1.5 Flash 0827 обеспечивает оптимизированную мультимодальную обработку для сложных задач.",
  "gemini-1.5-flash-latest.description": "Gemini 1.5 Flash — новейшая мультимодальная модель ИИ от Google с быстрой обработкой, поддержкой текста, изображений и видео для эффективного масштабирования задач.",
  "gemini-1.5-pro-001.description": "Gemini 1.5 Pro 001 — масштабируемое мультимодальное ИИ-решение для сложных задач.",
  "gemini-1.5-pro-002.description": "Gemini 1.5 Pro 002 — новейшая модель, готовая к производству, с более качественным выводом, особенно в математике, длинном контексте и визуальных задачах.",
  "gemini-1.5-pro-exp-0801.description": "Gemini 1.5 Pro 0801 обеспечивает мощную мультимодальную обработку с большей гибкостью для разработки приложений.",
  "gemini-1.5-pro-exp-0827.description": "Gemini 1.5 Pro 0827 использует последние оптимизации для более эффективной мультимодальной обработки.",
  "gemini-1.5-pro-latest.description": "Gemini 1.5 Pro поддерживает до 2 миллионов токенов, являясь идеальной мультимодальной моделью среднего размера для сложных задач.",
  "gemini-2.0-flash-001.description": "Gemini 2.0 Flash предлагает функции следующего поколения, включая исключительную скорость, нативное использование инструментов, мультимодальную генерацию и контекст до 1 миллиона токенов.",
  "gemini-2.0-flash-exp-image-generation.description": "Экспериментальная модель Gemini 2.0 Flash с поддержкой генерации изображений.",
  "gemini-2.0-flash-lite-001.description": "Вариант Gemini 2.0 Flash, оптимизированный по стоимости и задержке.",
  "gemini-2.0-flash-lite.description": "Вариант Gemini 2.0 Flash, оптимизированный по стоимости и задержке.",
  "gemini-2.0-flash.description": "Gemini 2.0 Flash предлагает функции следующего поколения, включая исключительную скорость, нативное использование инструментов, мультимодальную генерацию и контекст до 1 миллиона токенов.",
  "gemini-2.5-flash-image-preview.description": "Nano Banana — новейшая, самая быстрая и эффективная нативная мультимодальная модель от Google, обеспечивающая генерацию и редактирование изображений в диалоговом режиме.",
  "gemini-2.5-flash-image-preview:image.description": "Nano Banana — новейшая, самая быстрая и эффективная нативная мультимодальная модель от Google, обеспечивающая генерацию и редактирование изображений в диалоговом режиме.",
  "gemini-2.5-flash-image.description": "Nano Banana — новейшая, самая быстрая и эффективная нативная мультимодальная модель от Google, поддерживающая генерацию и редактирование изображений в диалоговом режиме.",
  "gemini-2.5-flash-image:image.description": "Nano Banana — новейшая, самая быстрая и эффективная нативная мультимодальная модель от Google, поддерживающая генерацию и редактирование изображений в диалоговом режиме.",
  "gemini-2.5-flash-lite-preview-06-17.description": "Gemini 2.5 Flash-Lite Preview — самая компактная и экономичная модель от Google, предназначенная для масштабного использования.",
  "gemini-2.5-flash-lite-preview-09-2025.description": "Предварительный выпуск (25 сентября 2025 г.) модели Gemini 2.5 Flash-Lite",
  "gemini-2.5-flash-lite.description": "Gemini 2.5 Flash-Lite — самая компактная и экономичная модель от Google, предназначенная для масштабного использования.",
  "gemini-2.5-flash-preview-04-17.description": "Gemini 2.5 Flash Preview — самая выгодная модель от Google с полным набором возможностей.",
  "gemini-2.5-flash-preview-09-2025.description": "Предварительный выпуск (25 сентября 2025 г.) модели Gemini 2.5 Flash",
  "gemini-2.5-flash.description": "Gemini 2.5 Flash — самая выгодная модель от Google с полным набором возможностей.",
  "gemini-2.5-pro-preview-03-25.description": "Gemini 2.5 Pro Preview — самая продвинутая модель рассуждения от Google, способная анализировать код, математику и задачи STEM, а также обрабатывать большие наборы данных, кодовые базы и документы с длинным контекстом.",
  "gemini-2.5-pro-preview-05-06.description": "Gemini 2.5 Pro Preview — самая продвинутая модель рассуждения от Google, способная анализировать код, математику и задачи STEM, а также обрабатывать большие наборы данных, кодовые базы и документы с длинным контекстом.",
  "gemini-2.5-pro-preview-06-05.description": "Gemini 2.5 Pro Preview — самая продвинутая модель рассуждения от Google, способная анализировать код, математику и задачи STEM, а также обрабатывать большие наборы данных, кодовые базы и документы с длинным контекстом.",
  "gemini-2.5-pro.description": "Gemini 2.5 Pro — флагманская модель рассуждения от Google с поддержкой длинного контекста для сложных задач.",
  "gemini-3-flash-preview.description": "Gemini 3 Flash — самая быстрая и интеллектуальная модель, сочетающая передовые ИИ-возможности с точной привязкой к поисковым данным.",
  "gemini-3-pro-image-preview.description": "Gemini 3 Pro Image (Nano Banana Pro) — модель генерации изображений от Google с поддержкой мультимодального диалога.",
  "gemini-3-pro-image-preview:image.description": "Gemini 3 Pro Image (Nano Banana Pro) — модель генерации изображений от Google, также поддерживающая мультимодальный чат.",
  "gemini-3-pro-preview.description": "Gemini 3 Pro — самая мощная агентная модель от Google с поддержкой визуализации и глубокой интерактивности, основанная на передовых возможностях рассуждения.",
  "gemini-flash-latest.description": "Последний выпуск Gemini Flash",
  "gemini-flash-lite-latest.description": "Последний выпуск Gemini Flash-Lite",
  "gemini-pro-latest.description": "Последний выпуск Gemini Pro",
  "gemma-7b-it.description": "Gemma 7B — экономичное решение для задач малого и среднего масштаба.",
  "gemma2-9b-it.description": "Gemma 2 9B оптимизирована для выполнения конкретных задач и интеграции с инструментами.",
  "gemma2.description": "Gemma 2 — эффективная модель от Google, охватывающая сценарии от небольших приложений до сложной обработки данных.",
  "gemma2:27b.description": "Gemma 2 — эффективная модель от Google, охватывающая сценарии от небольших приложений до сложной обработки данных.",
  "gemma2:2b.description": "Gemma 2 — эффективная модель от Google, охватывающая сценарии от небольших приложений до сложной обработки данных.",
  "generalv3.5.description": "Spark Max — самая функциональная версия, поддерживающая веб-поиск и множество встроенных плагинов. Оптимизированные базовые возможности, системные роли и вызов функций обеспечивают отличную производительность в сложных сценариях.",
  "generalv3.description": "Spark Pro — высокопроизводительная языковая модель, оптимизированная для профессиональных областей, таких как математика, программирование, здравоохранение и образование. Поддерживает веб-поиск и встроенные плагины (погода, дата и др.). Обеспечивает высокую эффективность в сложных задачах, понимании языка и создании текста, идеально подходит для профессионального использования.",
  "glm-4-0520.description": "GLM-4-0520 — последняя версия модели, разработанная для сложных и разнообразных задач с отличной производительностью.",
  "glm-4-7.description": "GLM-4.7 — флагманская модель от Zhipu AI. Улучшает возможности программирования, долгосрочного планирования задач и взаимодействия с инструментами в сценариях Agentic Coding, достигая лидирующих результатов среди моделей с открытым исходным кодом в различных публичных бенчмарках. Общие способности улучшены: ответы стали более лаконичными и естественными, а письмо — более захватывающим. В сложных агентных задачах улучшено следование инструкциям при вызове инструментов, а также эстетика интерфейса и эффективность выполнения долгосрочных задач. • Улучшенные возможности программирования: значительно улучшена многозадачная поддержка языков программирования и производительность терминальных агентов; GLM-4.7 реализует механизм «сначала подумай, потом действуй» в таких фреймворках, как Claude Code, Kilo Code, TRAE, Cline и Roo Code, с более стабильной работой на сложных задачах. • Улучшение эстетики интерфейса: GLM-4.7 демонстрирует значительный прогресс в качестве генерации интерфейсов, способна создавать сайты, презентации и постеры с лучшей визуальной привлекательностью. • Улучшенные вызовы инструментов: GLM-4.7 усиливает возможности вызова инструментов, набирая 67 баллов в оценке BrowseComp и 84.7 в τ²-Bench, превосходя Claude Sonnet 4.5 как SOTA среди open-source моделей. • Улучшенные способности к рассуждению: значительно улучшены математические и логические способности, 42.8% в HLE (\"Последний экзамен человечества\"), что на 41% выше, чем у GLM-4.6, и выше GPT-5.1. • Общие улучшения: диалоги GLM-4.7 стали более лаконичными, интеллектуальными и человечными; письмо и ролевая игра — более литературными и захватывающими.",
  "glm-4-9b-chat.description": "GLM-4-9B-Chat демонстрирует высокие результаты в семантике, математике, логике, программировании и знаниях. Поддерживает веб-браузинг, выполнение кода, вызов пользовательских инструментов и рассуждение над длинными текстами. Поддерживает 26 языков, включая японский, корейский и немецкий.",
  "glm-4-air-250414.description": "GLM-4-Air — выгодный вариант с производительностью, близкой к GLM-4, высокой скоростью и низкой стоимостью.",
  "glm-4-air.description": "GLM-4-Air — выгодный вариант с производительностью, близкой к GLM-4, высокой скоростью и низкой стоимостью.",
  "glm-4-airx.description": "GLM-4-AirX — более эффективный вариант GLM-4-Air с ускорением рассуждений до 2.6 раз.",
  "glm-4-alltools.description": "GLM-4-AllTools — универсальная агентная модель, оптимизированная для сложного планирования инструкций и использования инструментов, таких как веб-браузинг, объяснение кода и генерация текста. Подходит для многозадачного выполнения.",
  "glm-4-flash-250414.description": "GLM-4-Flash идеально подходит для простых задач: самая быстрая и бесплатная.",
  "glm-4-flash.description": "GLM-4-Flash идеально подходит для простых задач: самая быстрая и бесплатная.",
  "glm-4-flashx.description": "GLM-4-FlashX — улучшенная версия Flash с ультрабыстрым рассуждением.",
  "glm-4-long.description": "GLM-4-Long поддерживает сверхдлинные входные данные для задач, связанных с памятью, и обработки больших документов.",
  "glm-4-plus.description": "GLM-4-Plus — флагманская модель с высоким уровнем интеллекта, сильной поддержкой длинных текстов и сложных задач, а также улучшенной общей производительностью.",
  "glm-4.1v-thinking-flash.description": "GLM-4.1V-Thinking — самая мощная известная ~10B VLM, охватывающая передовые задачи, такие как понимание видео, визуальные вопросы и ответы, решение предметных задач, OCR, чтение документов и графиков, GUI-агенты, фронтенд-кодирование и привязка. Превосходит даже 8 раз более крупную Qwen2.5-VL-72B по многим задачам. Использует цепочку рассуждений для повышения точности и объяснимости, превосходя традиционные модели без мышления.",
  "glm-4.1v-thinking-flashx.description": "GLM-4.1V-Thinking — самая мощная известная ~10B VLM, охватывающая передовые задачи, такие как понимание видео, визуальные вопросы и ответы, решение предметных задач, OCR, чтение документов и графиков, GUI-агенты, фронтенд-кодирование и привязка. Превосходит даже 8 раз более крупную Qwen2.5-VL-72B по многим задачам. Использует цепочку рассуждений для повышения точности и объяснимости, превосходя традиционные модели без мышления.",
  "glm-4.5-air.description": "Облегчённая версия GLM-4.5, обеспечивающая баланс между производительностью и стоимостью, с гибкими режимами гибридного мышления.",
  "glm-4.5-airx.description": "GLM-4.5-AirX — ускоренная версия с быстрым откликом для масштабных и высокоскоростных сценариев.",
  "glm-4.5-x.description": "GLM-4.5 Fast — быстрая версия с производительностью до 100 токенов в секунду.",
  "glm-4.5.description": "Флагманская модель Zhipu с переключаемыми режимами мышления, открытым исходным кодом и поддержкой контекста до 128K.",
  "glm-4.5v.description": "Модель визуального логического вывода нового поколения от Zhipu с архитектурой MoE: 106B параметров, 12B активных. Достигает SOTA среди моделей аналогичного размера в задачах обработки изображений, видео, документов и GUI.",
  "glm-4.6.description": "GLM-4.6 (355B) — последняя флагманская модель Zhipu, превосходящая предшественников в программировании, обработке длинных текстов, логике и агентных задачах. Особенно сопоставима с Claude Sonnet 4 по программированию, став лучшей кодовой моделью Китая.",
  "glm-4.7-flash.description": "GLM-4.7-Flash — модель уровня 30B SOTA, предлагающая баланс между производительностью и эффективностью. Улучшает программирование, долгосрочное планирование задач и взаимодействие с инструментами в сценариях Agentic Coding, достигая лидирующих результатов среди моделей аналогичного размера с открытым исходным кодом. При выполнении сложных задач интеллектуальных агентов демонстрирует лучшее следование инструкциям при вызове инструментов, а также улучшает эстетику интерфейса и эффективность выполнения долгосрочных задач в Artifacts и Agentic Coding.",
  "glm-4.7-flashx.description": "GLM-4.7-Flash — модель уровня 30B SOTA, предлагающая баланс между производительностью и эффективностью. Улучшает программирование, долгосрочное планирование задач и взаимодействие с инструментами в сценариях Agentic Coding, достигая лидирующих результатов среди моделей аналогичного размера с открытым исходным кодом. При выполнении сложных задач интеллектуальных агентов демонстрирует лучшее следование инструкциям при вызове инструментов, а также улучшает эстетику интерфейса и эффективность выполнения долгосрочных задач в Artifacts и Agentic Coding.",
  "glm-4.7.description": "GLM-4.7 — новейшая флагманская модель Zhipu, оптимизированная для сценариев агентного программирования с улучшенными возможностями кода, долгосрочного планирования задач и взаимодействия с инструментами. Демонстрирует лидирующую производительность среди open-source моделей на множестве публичных бенчмарков. Общие возможности улучшены: ответы стали более лаконичными и естественными, а тексты — более выразительными. В сложных агентных задачах улучшено следование инструкциям при вызове инструментов, а также эстетика интерфейса и эффективность выполнения долгосрочных задач в Artifacts и Agentic Coding.",
  "glm-4.description": "GLM-4 — предыдущая флагманская модель, выпущенная в январе 2024 года, теперь заменена более мощной GLM-4-0520.",
  "glm-4v-flash.description": "GLM-4V-Flash ориентирована на эффективное понимание одиночных изображений в сценариях быстрого анализа, таких как обработка изображений в реальном времени или пакетная обработка.",
  "glm-4v-plus-0111.description": "GLM-4V-Plus понимает видео и несколько изображений, подходит для мультимодальных задач.",
  "glm-4v-plus.description": "GLM-4V-Plus понимает видео и несколько изображений, подходит для мультимодальных задач.",
  "glm-4v.description": "GLM-4V обеспечивает высокое качество понимания изображений и логического вывода в визуальных задачах.",
  "glm-z1-air.description": "Модель логического вывода с высокой точностью для задач, требующих глубокого анализа.",
  "glm-z1-airx.description": "Ультрабыстрая модель логического вывода с высоким качеством рассуждений.",
  "glm-z1-flash.description": "Серия GLM-Z1 обеспечивает мощный логический вывод, особенно в задачах логики, математики и программирования.",
  "glm-z1-flashx.description": "Быстрая и экономичная модель: ускоренная версия Flash с ультрабыстрым выводом и высокой параллельностью.",
  "glm-zero-preview.description": "GLM-Zero-Preview демонстрирует сильные способности к логическому выводу, особенно в логике, математике и программировании.",
  "global.anthropic.claude-opus-4-5-20251101-v1:0.description": "Claude Opus 4.5 — флагманская модель от Anthropic, сочетающая выдающийся интеллект и масштабируемую производительность для сложных задач, требующих высококачественных ответов и рассуждений.",
  "google/gemini-2.0-flash-001.description": "Gemini 2.0 Flash предлагает возможности следующего поколения, включая высокую скорость, встроенную работу с инструментами, мультимодальную генерацию и контекстное окно объёмом 1 миллион токенов.",
  "google/gemini-2.0-flash-lite-001.description": "Gemini 2.0 Flash Lite — облегчённый вариант Gemini с отключённым по умолчанию режимом мышления для снижения задержек и стоимости, который можно включить с помощью параметров.",
  "google/gemini-2.0-flash-lite.description": "Gemini 2.0 Flash Lite предлагает функции следующего поколения, включая высокую скорость, встроенную работу с инструментами, мультимодальную генерацию и контекстное окно объёмом 1 миллион токенов.",
  "google/gemini-2.0-flash.description": "Gemini 2.0 Flash — высокопроизводительная модель от Google, предназначенная для расширенных мультимодальных задач с элементами логического мышления.",
  "google/gemini-2.5-flash-image-free.description": "Бесплатный уровень Gemini 2.5 Flash Image с ограниченной квотой на мультимодальную генерацию.",
  "google/gemini-2.5-flash-image-preview.description": "Экспериментальная модель Gemini 2.5 Flash с поддержкой генерации изображений.",
  "google/gemini-2.5-flash-image.description": "Gemini 2.5 Flash Image (Nano Banana) — модель генерации изображений от Google с поддержкой мультимодального общения.",
  "google/gemini-2.5-flash-lite.description": "Gemini 2.5 Flash Lite — облегчённый вариант Gemini 2.5, оптимизированный по задержке и стоимости, подходит для сценариев с высокой пропускной способностью.",
  "google/gemini-2.5-flash-preview.description": "Gemini 2.5 Flash — самая продвинутая флагманская модель Google, созданная для сложных задач в области логики, программирования, математики и науки. Включает встроенное «мышление» для более точных ответов и тонкой обработки контекста.\n\nПримечание: у модели есть два варианта — с мышлением и без. Стоимость вывода значительно различается в зависимости от включения мышления. Если вы выберете стандартный вариант (без суффикса «:thinking»), модель будет явно избегать генерации токенов мышления.\n\nЧтобы использовать мышление и получать соответствующие токены, необходимо выбрать вариант с суффиксом «:thinking», что приведёт к более высокой стоимости вывода.\n\nGemini 2.5 Flash также можно настроить с помощью параметра «максимум токенов рассуждения», как указано в документации (https://openrouter.ai/docs/use-cases/reasoning-tokens#max-tokens-for-reasoning).",
  "google/gemini-2.5-flash-preview:thinking.description": "Gemini 2.5 Flash — самая продвинутая флагманская модель Google, созданная для сложных задач в области логики, программирования, математики и науки. Включает встроенное «мышление» для более точных ответов и тонкой обработки контекста.\n\nПримечание: у модели есть два варианта — с мышлением и без. Стоимость вывода значительно различается в зависимости от включения мышления. Если вы выберете стандартный вариант (без суффикса «:thinking»), модель будет явно избегать генерации токенов мышления.\n\nЧтобы использовать мышление и получать соответствующие токены, необходимо выбрать вариант с суффиксом «:thinking», что приведёт к более высокой стоимости вывода.\n\nGemini 2.5 Flash также можно настроить с помощью параметра «максимум токенов рассуждения», как указано в документации (https://openrouter.ai/docs/use-cases/reasoning-tokens#max-tokens-for-reasoning).",
  "google/gemini-2.5-flash.description": "Gemini 2.5 Flash (Lite/Pro/Flash) — семейство моделей Google, охватывающее от низкой задержки до высокопроизводительного логического мышления.",
  "google/gemini-2.5-pro-free.description": "Бесплатный уровень Gemini 2.5 Pro с ограниченной квотой на мультимодальную генерацию с длинным контекстом, подходит для тестирования и лёгких рабочих процессов.",
  "google/gemini-2.5-pro-preview.description": "Gemini 2.5 Pro Preview — самая продвинутая модель Google с режимом мышления, предназначенная для решения сложных задач в области программирования, математики и STEM, а также для анализа больших наборов данных, кодовых баз и документов с длинным контекстом.",
  "google/gemini-2.5-pro.description": "Gemini 2.5 Pro — флагманская модель логического мышления от Google с поддержкой длинного контекста для сложных задач.",
  "google/gemini-3-pro-image-preview-free.description": "Бесплатный уровень Gemini 3 Pro Image с ограниченной квотой на мультимодальную генерацию.",
  "google/gemini-3-pro-image-preview.description": "Gemini 3 Pro Image (Nano Banana Pro) — модель генерации изображений от Google с поддержкой мультимодального общения.",
  "google/gemini-3-pro-preview-free.description": "Бесплатная версия Gemini 3 Pro Preview с теми же возможностями мультимодального понимания и логики, что и стандартная версия, но с ограничениями по квоте и частоте, что делает её подходящей для тестирования и редкого использования.",
  "google/gemini-3-pro-preview.description": "Gemini 3 Pro — модель следующего поколения в семействе Gemini, способная понимать текст, аудио, изображения и видео, а также справляться со сложными задачами и большими кодовыми базами.",
  "google/gemini-embedding-001.description": "Современная модель встраивания с высокой производительностью для задач на английском языке, в многоязычной среде и в программировании.",
  "google/gemini-flash-1.5.description": "Gemini 1.5 Flash обеспечивает оптимизированную мультимодальную обработку для широкого спектра сложных задач.",
  "google/gemini-pro-1.5.description": "Gemini 1.5 Pro сочетает в себе новейшие оптимизации для более эффективной обработки мультимодальных данных.",
  "google/gemma-2-27b-it.description": "Gemma 2 27B — универсальная языковая модель с высокой производительностью в различных сценариях.",
  "google/gemma-2-27b.description": "Gemma 2 — семейство эффективных моделей от Google, подходящее как для небольших приложений, так и для сложной обработки данных.",
  "google/gemma-2-2b-it.description": "Продвинутая компактная языковая модель, предназначенная для использования на периферийных устройствах.",
  "google/gemma-2-9b-it.description": "Gemma 2 9B, разработанная Google, обеспечивает эффективное выполнение инструкций и общую высокую производительность.",
  "google/gemma-2-9b-it:free.description": "Gemma 2 — лёгкое семейство моделей с открытым исходным кодом от Google для обработки текста.",
  "google/gemma-2-9b.description": "Gemma 2 — семейство эффективных моделей от Google, подходящее как для небольших приложений, так и для сложной обработки данных.",
  "google/gemma-2b-it.description": "Gemma Instruct (2B) обеспечивает базовую обработку инструкций для лёгких приложений.",
  "google/gemma-3-12b-it.description": "Gemma 3 12B — языковая модель с открытым исходным кодом от Google, устанавливающая новый стандарт эффективности и производительности.",
  "google/gemma-3-27b-it.description": "Gemma 3 27B — языковая модель с открытым исходным кодом от Google, устанавливающая новый стандарт эффективности и производительности.",
  "google/text-embedding-005.description": "Модель встраивания текста, ориентированная на английский язык, оптимизирована для задач на английском и программировании.",
  "google/text-multilingual-embedding-002.description": "Многоязычная модель встраивания текста, оптимизированная для кросс-языковых задач на множестве языков.",
  "gpt-3.5-turbo-0125.description": "GPT 3.5 Turbo для генерации и понимания текста; в настоящее время указывает на gpt-3.5-turbo-0125.",
  "gpt-3.5-turbo-1106.description": "GPT 3.5 Turbo для генерации и понимания текста; в настоящее время указывает на gpt-3.5-turbo-0125.",
  "gpt-3.5-turbo-instruct.description": "GPT 3.5 Turbo для задач генерации и понимания текста, оптимизирован для выполнения инструкций.",
  "gpt-3.5-turbo.description": "GPT 3.5 Turbo для генерации и понимания текста; в настоящее время указывает на gpt-3.5-turbo-0125.",
  "gpt-35-turbo-16k.description": "GPT-3.5 Turbo 16k — высокоёмкая модель генерации текста для сложных задач.",
  "gpt-35-turbo.description": "GPT-3.5 Turbo — эффективная модель от OpenAI для чатов и генерации текста с поддержкой параллельного вызова функций.",
  "gpt-4-0125-preview.description": "Последняя версия GPT-4 Turbo теперь поддерживает обработку изображений. Визуальные запросы поддерживают режим JSON и вызов функций. Это экономичный мультимодальный ИИ, сочетающий точность и эффективность для приложений в реальном времени.",
  "gpt-4-0613.description": "GPT-4 предоставляет расширенное контекстное окно для обработки длинных входных данных, что делает его подходящим для комплексного анализа информации и синтеза данных.",
  "gpt-4-1106-preview.description": "Последняя версия GPT-4 Turbo теперь поддерживает обработку изображений. Визуальные запросы поддерживают режим JSON и вызов функций. Это экономичный мультимодальный ИИ, сочетающий точность и эффективность для приложений в реальном времени.",
  "gpt-4-32k-0613.description": "GPT-4 предоставляет расширенное контекстное окно для обработки длинных входных данных, что делает его подходящим для интеграции информации и анализа данных в сложных сценариях.",
  "gpt-4-32k.description": "GPT-4 предоставляет расширенное контекстное окно для обработки длинных входных данных, что делает его подходящим для интеграции информации и анализа данных в сложных сценариях.",
  "gpt-4-turbo-2024-04-09.description": "Последняя версия GPT-4 Turbo теперь поддерживает обработку изображений. Визуальные запросы поддерживают режим JSON и вызов функций. Это экономичный мультимодальный ИИ, сочетающий точность и эффективность для приложений в реальном времени.",
  "gpt-4-turbo-preview.description": "Последняя версия GPT-4 Turbo теперь поддерживает обработку изображений. Визуальные запросы поддерживают режим JSON и вызов функций. Это экономичный мультимодальный ИИ, сочетающий точность и эффективность для приложений в реальном времени.",
  "gpt-4-turbo.description": "Последняя версия GPT-4 Turbo теперь поддерживает обработку изображений. Визуальные запросы поддерживают режим JSON и вызов функций. Это экономичный мультимодальный ИИ, сочетающий точность и эффективность для приложений в реальном времени.",
  "gpt-4-vision-preview.description": "Предварительная версия GPT-4 Vision, предназначенная для анализа и обработки изображений.",
  "gpt-4.1-mini.description": "GPT-4.1 mini сочетает интеллект, скорость и экономичность, что делает его привлекательным для множества сценариев использования.",
  "gpt-4.1-nano.description": "GPT-4.1 nano — самая быстрая и экономичная модель в линейке GPT-4.1.",
  "gpt-4.1.description": "GPT-4.1 — наша флагманская модель для решения сложных задач и междисциплинарных проблем.",
  "gpt-4.5-preview.description": "GPT-4.5-preview — последняя универсальная модель с глубокими знаниями о мире и улучшенным пониманием намерений. Отлично справляется с творческими задачами и планированием агентов. Актуальность знаний — октябрь 2023 года.",
  "gpt-4.description": "GPT-4 предоставляет расширенное контекстное окно для обработки длинных входных данных, что делает его подходящим для комплексного анализа информации и синтеза данных.",
  "gpt-4o-2024-05-13.description": "ChatGPT-4o — это динамическая модель с обновлением в реальном времени, сочетающая глубокое понимание и генерацию текста для масштабных сценариев, таких как поддержка клиентов, образование и техническая помощь.",
  "gpt-4o-2024-08-06.description": "ChatGPT-4o — это динамическая модель с обновлением в реальном времени. Она сочетает в себе мощное языковое понимание и генерацию для масштабных сценариев, таких как поддержка клиентов, образование и техническая помощь.",
  "gpt-4o-2024-11-20.description": "ChatGPT-4o — это динамическая модель с обновлением в реальном времени, сочетающая глубокое понимание и генерацию текста для масштабных сценариев, таких как поддержка клиентов, образование и техническая помощь.",
  "gpt-4o-audio-preview.description": "Предварительная версия GPT-4o Audio с поддержкой аудиовхода и аудиовыхода.",
  "gpt-4o-mini-audio-preview.description": "Модель GPT-4o mini Audio с поддержкой аудиовхода и аудиовыхода.",
  "gpt-4o-mini-realtime-preview.description": "Вариант GPT-4o-mini с поддержкой аудио и текста в режиме реального времени.",
  "gpt-4o-mini-search-preview.description": "Предварительная версия GPT-4o mini Search обучена понимать и выполнять веб-поисковые запросы через API Chat Completions. Поиск в интернете тарифицируется отдельно за каждый вызов инструмента, помимо стоимости токенов.",
  "gpt-4o-mini-transcribe.description": "GPT-4o Mini Transcribe — это модель преобразования речи в текст, которая транскрибирует аудио с помощью GPT-4o, улучшая точность распознавания слов, определение языка и общую точность по сравнению с оригинальной моделью Whisper.",
  "gpt-4o-mini-tts.description": "GPT-4o mini TTS — это модель преобразования текста в речь, основанная на GPT-4o mini, преобразующая текст в естественно звучащую речь с максимальным входом до 2000 токенов.",
  "gpt-4o-mini.description": "GPT-4o mini — новейшая модель OpenAI после GPT-4 Omni, поддерживающая ввод текста и изображений с текстовым выводом. Это самая продвинутая компактная модель, значительно дешевле современных передовых моделей и более чем на 60% дешевле GPT-3.5 Turbo, при этом сохраняет высокий уровень интеллекта (82% MMLU).",
  "gpt-4o-realtime-preview-2024-10-01.description": "Вариант GPT-4o с поддержкой аудио и текста в режиме реального времени.",
  "gpt-4o-realtime-preview-2025-06-03.description": "Вариант GPT-4o с поддержкой аудио и текста в режиме реального времени.",
  "gpt-4o-realtime-preview.description": "Вариант GPT-4o с поддержкой аудио и текста в режиме реального времени.",
  "gpt-4o-search-preview.description": "Предварительная версия GPT-4o Search обучена понимать и выполнять веб-поисковые запросы через API Chat Completions. Поиск в интернете тарифицируется отдельно за каждый вызов инструмента, помимо стоимости токенов.",
  "gpt-4o-transcribe.description": "GPT-4o Transcribe — это модель преобразования речи в текст, которая транскрибирует аудио с помощью GPT-4o, улучшая точность распознавания слов, определение языка и общую точность по сравнению с оригинальной моделью Whisper.",
  "gpt-4o.description": "ChatGPT-4o — это динамическая модель с обновлением в реальном времени, сочетающая глубокое понимание и генерацию текста для масштабных сценариев, таких как поддержка клиентов, образование и техническая помощь.",
  "gpt-5-chat-latest.description": "Модель GPT-5, используемая в ChatGPT, сочетает в себе мощное понимание и генерацию для разговорных приложений.",
  "gpt-5-chat.description": "GPT-5 Chat — предварительная модель, оптимизированная для разговорных сценариев. Поддерживает ввод текста и изображений, выводит только текст и подходит для чат-ботов и разговорного ИИ.",
  "gpt-5-codex.description": "GPT-5 Codex — это вариант GPT-5, оптимизированный для агентных задач программирования в средах, подобных Codex.",
  "gpt-5-mini.description": "Быстрый и экономичный вариант GPT-5 для четко определенных задач, обеспечивающий быстрые ответы при сохранении качества.",
  "gpt-5-nano.description": "Самый быстрый и экономичный вариант GPT-5, идеально подходящий для приложений с чувствительностью к задержке и стоимости.",
  "gpt-5-pro.description": "GPT-5 Pro использует больше вычислительных ресурсов для более глубокого анализа и стабильно выдает более качественные ответы.",
  "gpt-5.1-chat-latest.description": "GPT-5.1 Chat: вариант GPT-5.1, предназначенный для сценариев общения.",
  "gpt-5.1-codex-mini.description": "GPT-5.1 Codex mini: уменьшенный и более дешевый вариант Codex, оптимизированный для агентных задач программирования.",
  "gpt-5.1-codex.description": "GPT-5.1 Codex: вариант GPT-5.1, оптимизированный для агентных задач программирования, включая сложные рабочие процессы с кодом и агентами в API ответов.",
  "gpt-5.1.description": "GPT-5.1 — флагманская модель, оптимизированная для программирования и агентных задач с настраиваемой глубиной рассуждений и поддержкой длинного контекста.",
  "gpt-5.2-chat-latest.description": "GPT-5.2 Chat — это вариант ChatGPT (chat-latest) с последними улучшениями в области диалогов.",
  "gpt-5.2-pro.description": "GPT-5.2 pro: более умный и точный вариант GPT-5.2 (только через Responses API), подходит для сложных задач и многошагового рассуждения.",
  "gpt-5.2.description": "GPT-5.2 — флагманская модель для программирования и агентных рабочих процессов с улучшенными логическими способностями и поддержкой длинного контекста.",
  "gpt-5.description": "Лучшая модель для междисциплинарного программирования и агентных задач. GPT-5 делает скачок в точности, скорости, логике, понимании контекста, структурированном мышлении и решении проблем.",
  "gpt-audio.description": "GPT Audio — универсальная модель общения с поддержкой ввода и вывода аудио, доступная через API завершения чата.",
  "gpt-image-1-mini.description": "Бюджетный вариант GPT Image 1 с нативной поддержкой ввода текста и изображений и генерацией изображений.",
  "gpt-image-1.5.description": "Улучшенная модель GPT Image 1 с генерацией в 4 раза быстрее, более точным редактированием и улучшенной визуализацией текста.",
  "gpt-image-1.description": "Нативная мультимодальная модель генерации изображений ChatGPT.",
  "gpt-oss-120b.description": "Требуется заявка на доступ. GPT-OSS-120B — это крупная open-source языковая модель от OpenAI с мощными возможностями генерации текста.",
  "gpt-oss-20b.description": "Требуется заявка на доступ. GPT-OSS-20B — это средняя open-source языковая модель от OpenAI с эффективной генерацией текста.",
  "gpt-oss:120b.description": "GPT-OSS 120B — крупная open-source LLM от OpenAI с квантованием MXFP4, позиционируемая как флагманская модель. Требует многопроцессорной или высокопроизводительной рабочей станции. Обеспечивает отличные результаты в сложных рассуждениях, генерации кода и многоязычной обработке, с поддержкой вызова функций и интеграции инструментов.",
  "gpt-oss:20b.description": "GPT-OSS 20B — open-source LLM от OpenAI с квантованием MXFP4, подходящая для мощных потребительских GPU или Apple Silicon. Эффективна в генерации диалогов, программировании и логических задачах, поддерживает вызов функций и использование инструментов.",
  "gpt-realtime.description": "Универсальная модель реального времени с поддержкой ввода/вывода текста и аудио, а также ввода изображений.",
  "grok-2-image-1212.description": "Наша новейшая модель генерации изображений создает яркие, реалистичные изображения по подсказкам и отлично подходит для маркетинга, социальных сетей и развлечений.",
  "grok-2-vision-1212.description": "Улучшенная точность, следование инструкциям и многоязычные возможности.",
  "grok-3-mini.description": "Легковесная модель, которая сначала думает, а потом отвечает. Быстрая и умная для логических задач, не требующих глубоких знаний, с доступом к необработанным следам рассуждений.",
  "grok-3.description": "Флагманская модель, превосходно справляющаяся с корпоративными задачами, такими как извлечение данных, программирование и суммирование, с глубокими знаниями в области финансов, здравоохранения, права и науки.",
  "grok-4-0709.description": "Grok 4 от xAI с мощными логическими возможностями.",
  "grok-4-1-fast-non-reasoning.description": "Передовая мультимодальная модель, оптимизированная для высокоэффективного использования инструментов агентами.",
  "grok-4-1-fast-reasoning.description": "Передовая мультимодальная модель, оптимизированная для высокоэффективного использования инструментов агентами.",
  "grok-4-fast-non-reasoning.description": "Мы рады представить Grok 4 Fast — наш последний прогресс в области экономичных моделей рассуждения.",
  "grok-4-fast-reasoning.description": "Мы рады представить Grok 4 Fast — наш последний прогресс в области экономичных моделей рассуждения.",
  "grok-4.description": "Наша новейшая и самая мощная флагманская модель, превосходящая в НЛП, математике и логике — идеальный универсал.",
  "grok-code-fast-1.description": "Мы рады представить grok-code-fast-1 — быструю и экономичную модель рассуждения, превосходную в агентном программировании.",
  "groq/compound-mini.description": "Compound-mini — это составная ИИ-система, работающая на базе общедоступных моделей в GroqCloud, которая интеллектуально и избирательно использует инструменты для ответа на запросы пользователей.",
  "groq/compound.description": "Compound — это составная ИИ-система, работающая на базе нескольких общедоступных моделей в GroqCloud, которая интеллектуально и избирательно использует инструменты для ответа на запросы пользователей.",
  "gryphe/mythomax-l2-13b.description": "MythoMax L2 13B — это креативная и интеллектуальная языковая модель, объединяющая лучшие качества нескольких топовых моделей.",
  "hunyuan-a13b.description": "Первая гибридная модель рассуждения от Hunyuan, улучшенная версия hunyuan-standard-256K (всего 80B, активных 13B). По умолчанию использует медленное мышление, поддерживает переключение между быстрым и медленным режимами через параметры или префикс /no_think. Общие возможности улучшены по сравнению с предыдущим поколением, особенно в математике, науке, понимании длинных текстов и задачах агентов.",
  "hunyuan-code.description": "Новейшая модель генерации кода, обученная на 200B высококачественного кода и шести месяцах SFT; контекст расширен до 8K. Лидирует в автоматических тестах по пяти языкам и в человеческих оценках по десяти критериям.",
  "hunyuan-functioncall.description": "Новейшая модель MoE FunctionCall, обученная на высококачественных данных вызова функций, с контекстным окном 32K и лидирующими результатами в различных метриках.",
  "hunyuan-large-longcontext.description": "Отлично справляется с задачами на длинные документы, такими как суммирование и ответы на вопросы, а также с общей генерацией. Сильна в анализе и генерации длинных текстов со сложным содержанием.",
  "hunyuan-large-vision.description": "Модель визуально-языкового понимания, обученная на базе Hunyuan Large. Поддерживает ввод нескольких изображений и текста в любом разрешении, улучшает мультиязычное визуальное понимание.",
  "hunyuan-large.description": "Hunyuan-large содержит ~389B общих параметров и ~52B активных — крупнейшая и самая мощная открытая модель MoE в архитектуре Transformer.",
  "hunyuan-lite-vision.description": "Новейшая мультимодальная модель на 7B с контекстом 32K, поддерживающая мультимодальный чат на китайском и английском, распознавание объектов, понимание таблиц и мультимодальную математику, превосходящая аналоги на 7B по многим метрикам.",
  "hunyuan-lite.description": "Обновлена до архитектуры MoE с контекстом 256K, опережает многие открытые модели в NLP, коде, математике и отраслевых тестах.",
  "hunyuan-pro.description": "Модель MoE с триллионом параметров и контекстом 32K, лидирующая в тестах, сильна в сложных инструкциях и рассуждениях, продвинутой математике, вызове функций и оптимизирована для перевода, финансов, права и медицины.",
  "hunyuan-role.description": "Новейшая ролевая модель, официально дообученная на ролевых датасетах, обеспечивающая более высокую базовую производительность в ролевых сценариях.",
  "hunyuan-standard-256K.description": "Использует улучшенную маршрутизацию для устранения дисбаланса нагрузки и коллапса экспертов. Достигает 99.9% точности в задаче «иголка в стоге сена» на длинном контексте. MOE-256K расширяет длину и качество контекста.",
  "hunyuan-standard-vision.description": "Новейшая мультимодальная модель с мультиязычными ответами и сбалансированными возможностями на китайском и английском языках.",
  "hunyuan-standard.description": "Использует улучшенную маршрутизацию для устранения дисбаланса нагрузки и коллапса экспертов. Достигает 99.9% точности в задаче «иголка в стоге сена» на длинном контексте. MOE-32K обеспечивает высокую ценность при работе с длинными входами.",
  "hunyuan-t1-20250321.description": "Формирует сбалансированные гуманитарные и технические навыки с сильным захватом информации из длинных текстов. Поддерживает рассуждения по математике, логике, науке и программированию на разных уровнях сложности.",
  "hunyuan-t1-20250403.description": "Улучшает генерацию кода на уровне проектов и качество письма, усиливает понимание тем в нескольких репликах и следование инструкциям B2B, улучшает понимание слов и снижает смешение упрощённого/традиционного китайского и китайско-английского вывода.",
  "hunyuan-t1-20250529.description": "Улучшает креативное письмо и сочинение, усиливает фронтенд-кодинг, математику и логическое рассуждение, а также следование инструкциям.",
  "hunyuan-t1-20250711.description": "Значительно улучшает сложную математику, логику и программирование, повышает стабильность вывода и усиливает работу с длинными текстами.",
  "hunyuan-t1-latest.description": "Существенно улучшает модель медленного мышления в сложной математике, рассуждениях, трудном программировании, следовании инструкциям и качестве креативного письма.",
  "hunyuan-t1-vision-20250619.description": "Новейшая мультимодальная модель глубокого рассуждения t1-vision с нативной цепочкой мыслей, значительно улучшенная по сравнению с предыдущей версией по умолчанию.",
  "hunyuan-t1-vision-20250916.description": "Новейшая модель глубокого рассуждения t1-vision с серьёзными улучшениями в VQA, визуальной привязке, OCR, графиках, решении задач по фото и создании изображений, а также с усиленной поддержкой английского и языков с низкими ресурсами.",
  "hunyuan-turbo-20241223.description": "Эта версия усиливает масштабирование инструкций для лучшей обобщаемости, значительно улучшает рассуждения в математике/коде/логике, усиливает понимание слов и улучшает качество письма.",
  "hunyuan-turbo-latest.description": "Общие улучшения пользовательского опыта в понимании NLP, письме, чате, QA, переводе и специализированных областях; более человечные ответы, лучшее уточнение неясных намерений, улучшенный разбор слов, более высокое качество креатива и интерактивности, а также более сильные диалоги в несколько реплик.",
  "hunyuan-turbo-vision.description": "Флагманская модель визуально-языкового понимания нового поколения с архитектурой MoE, с широкими улучшениями в распознавании, создании контента, QA по знаниям и аналитическом рассуждении.",
  "hunyuan-turbo.description": "Предварительная версия LLM нового поколения от Hunyuan с новой архитектурой MoE, обеспечивающая более быстрое рассуждение и лучшие результаты, чем hunyuan-pro.",
  "hunyuan-turbos-20250313.description": "Унифицирует стиль решения математических задач и усиливает QA по математике в несколько реплик. Стиль письма улучшен для уменьшения «ИИ-подобного» тона и придания изящности.",
  "hunyuan-turbos-20250416.description": "Обновлённая база предобучения для лучшего понимания и следования инструкциям; улучшенное соответствие усиливает математику, код, логику и науку; улучшает качество письма, понимание, точность перевода и QA по знаниям; усиливает способности агентов, особенно в понимании нескольких реплик.",
  "hunyuan-turbos-20250604.description": "Обновлённая база предобучения с улучшенным письмом и пониманием прочитанного, значительным прогрессом в коде и STEM, а также лучшим следованием сложным инструкциям.",
  "hunyuan-turbos-20250926.description": "Улучшено качество предобученных данных и стратегия постобучения, улучшены агенты, английский/языки с низкими ресурсами, следование инструкциям, код и STEM-навыки.",
  "hunyuan-turbos-latest.description": "Новейшая флагманская модель Hunyuan TurboS с более сильным рассуждением и улучшенным общим пользовательским опытом.",
  "hunyuan-turbos-longtext-128k-20250325.description": "Отлично справляется с задачами на длинные документы, такими как суммирование и QA, а также с общей генерацией. Сильна в анализе и генерации длинных текстов со сложным, детализированным содержанием.",
  "hunyuan-turbos-role-plus.description": "Новейшая ролевая модель, официально дообученная на ролевых датасетах, обеспечивающая более высокую базовую производительность в ролевых сценариях.",
  "hunyuan-turbos-vision-20250619.description": "Новейшая флагманская модель TurboS для визуально-языковых задач с серьёзными улучшениями в распознавании сущностей, QA по знаниям, копирайтинге и решении задач по фото.",
  "hunyuan-turbos-vision.description": "Флагманская модель визуально-языкового понимания нового поколения на базе последней версии TurboS, ориентированная на задачи понимания изображений и текста, такие как распознавание сущностей, QA по знаниям, копирайтинг и решение задач по фото.",
  "hunyuan-vision-1.5-instruct.description": "Модель быстрого мышления для генерации текста по изображению, созданная на базе TurboS. По сравнению с предыдущей версией значительно улучшена в распознавании изображений, анализе и логическом выводе.",
  "hunyuan-vision.description": "Новейшая мультимодальная модель, поддерживающая ввод изображения и текста для генерации текста.",
  "image-01-live.description": "Модель генерации изображений с высокой детализацией, поддерживает генерацию по тексту и управляемые стили.",
  "image-01.description": "Новая модель генерации изображений с высокой детализацией, поддерживает генерацию по тексту и по изображению.",
  "imagen-4.0-fast-generate-001.description": "Серия моделей генерации изображений Imagen 4-го поколения, версия Fast.",
  "imagen-4.0-generate-001.description": "Серия моделей генерации изображений Imagen 4-го поколения.",
  "imagen-4.0-generate-preview-06-06.description": "Семейство моделей генерации изображений Imagen 4-го поколения.",
  "imagen-4.0-ultra-generate-001.description": "Серия моделей генерации изображений Imagen 4-го поколения, версия Ultra.",
  "imagen-4.0-ultra-generate-preview-06-06.description": "Вариант Ultra семейства моделей генерации изображений Imagen 4-го поколения.",
  "inception/mercury-coder-small.description": "Mercury Coder Small идеально подходит для генерации, отладки и рефакторинга кода с минимальной задержкой.",
  "inclusionAI/Ling-flash-2.0.description": "Ling-flash-2.0 — третья модель архитектуры Ling 2.0 от команды Bailing компании Ant Group. Это модель MoE с 100 миллиардами параметров, из которых активно только 6.1 миллиарда на токен (4.8 миллиарда без учета эмбеддингов). Несмотря на легкую конфигурацию, она сопоставима или превосходит плотные модели на 40 миллиардов и более крупные MoE-модели по многим метрикам, демонстрируя высокую эффективность благодаря архитектуре и стратегии обучения.",
  "inclusionAI/Ling-mini-2.0.description": "Ling-mini-2.0 — компактная высокопроизводительная MoE LLM с 16 миллиардами параметров и только 1.4 миллиарда активных на токен (789 миллионов без эмбеддингов), обеспечивающая очень быструю генерацию. Благодаря эффективной архитектуре MoE и большому объему качественных обучающих данных, она достигает уровня производительности, сопоставимого с плотными моделями до 10 миллиардов и более крупными MoE-моделями.",
  "inclusionAI/Ring-flash-2.0.description": "Ring-flash-2.0 — высокопроизводительная модель мышления, оптимизированная на базе Ling-flash-2.0. Использует архитектуру MoE с 100 миллиардами параметров и только 6.1 миллиарда активных на инференс. Алгоритм icepop стабилизирует обучение с подкреплением для MoE, обеспечивая устойчивый рост в сложных задачах. Достигает прорывных результатов в сложных бенчмарках (математика, генерация кода, логика), превосходя плотные модели до 40 миллиардов и конкурируя с более крупными открытыми и закрытыми моделями. Также показывает отличные результаты в креативном письме, а ее эффективная архитектура обеспечивает быструю генерацию при низких затратах на развертывание и высокой нагрузке.",
  "inclusionai/ling-1t.description": "Ling-1T — MoE-модель от inclusionAI с триллионом параметров, оптимизированная для задач с высокой нагрузкой на мышление и работы с большим контекстом.",
  "inclusionai/ling-flash-2.0.description": "Ling-flash-2.0 — MoE-модель от inclusionAI, оптимизированная для эффективности и производительности в задачах мышления, подходит для задач среднего и крупного масштаба.",
  "inclusionai/ling-mini-2.0.description": "Ling-mini-2.0 — легковесная MoE-модель от inclusionAI, значительно снижает затраты при сохранении способности к логическому выводу.",
  "inclusionai/ming-flash-omini-preview.description": "Ming-flash-omni Preview — мультимодальная модель от inclusionAI, поддерживает ввод речи, изображений и видео, с улучшенной визуализацией и распознаванием речи.",
  "inclusionai/ring-1t.description": "Ring-1T — MoE-модель от inclusionAI с триллионом параметров, предназначенная для масштабных задач логического вывода и исследований.",
  "inclusionai/ring-flash-2.0.description": "Ring-flash-2.0 — вариант модели Ring от inclusionAI для сценариев с высокой пропускной способностью, с акцентом на скорость и экономичность.",
  "inclusionai/ring-mini-2.0.description": "Ring-mini-2.0 — легковесная MoE-модель от inclusionAI с высокой пропускной способностью, разработана для параллельной обработки.",
  "internlm/internlm2_5-7b-chat.description": "InternLM2.5-7B-Chat — открытая модель для чата на базе архитектуры InternLM2. Модель с 7 миллиардами параметров ориентирована на генерацию диалогов с поддержкой китайского и английского языков, использует современные методы обучения для создания плавных и интеллектуальных бесед. Подходит для сценариев, таких как поддержка клиентов и персональные ассистенты.",
  "internlm2.5-latest.description": "Поддерживаемые устаревшие модели с отличной и стабильной производительностью после множества итераций. Доступны в версиях 7B и 20B, поддерживают контекст до 1 миллиона токенов, улучшенное следование инструкциям и использование инструментов. По умолчанию используется последняя серия InternLM2.5 (в настоящее время internlm2.5-20b-chat).",
  "internlm3-latest.description": "Наша последняя серия моделей с выдающейся производительностью в логическом мышлении, лидирует среди открытых моделей в своем классе. По умолчанию используется последняя серия InternLM3 (в настоящее время internlm3-8b-instruct).",
  "internvl2.5-38b-mpo.description": "InternVL2.5 38B MPO — мультимодальная предварительно обученная модель для сложного логического вывода на основе изображений и текста.",
  "internvl2.5-latest.description": "InternVL2.5 по-прежнему поддерживается и демонстрирует стабильную высокую производительность. По умолчанию используется последняя версия серии InternVL2.5 (в настоящее время internvl2.5-78b).",
  "internvl3-14b.description": "InternVL3 14B — мультимодальная модель среднего размера, обеспечивающая баланс между производительностью и стоимостью.",
  "internvl3-1b.description": "InternVL3 1B — легковесная мультимодальная модель для развертывания в условиях ограниченных ресурсов.",
  "internvl3-38b.description": "InternVL3 38B — крупная открытая мультимодальная модель для высокоточного понимания изображений и текста.",
  "internvl3-latest.description": "Наша последняя мультимодальная модель с улучшенным пониманием изображений и текста, а также восприятием длинных последовательностей изображений, сопоставимая с ведущими закрытыми моделями. По умолчанию используется последняя серия InternVL (в настоящее время internvl3-78b).",
  "irag-1.0.description": "ERNIE iRAG — модель генерации с дополнением через поиск изображений, предназначенная для поиска изображений, извлечения информации из изображений и текста, а также генерации контента.",
  "jamba-large.description": "Наша самая мощная и продвинутая модель, предназначенная для сложных корпоративных задач с выдающейся производительностью.",
  "jamba-mini.description": "Самая эффективная модель в своем классе, обеспечивающая баланс между скоростью и качеством при минимальных ресурсах.",
  "jina-deepsearch-v1.description": "DeepSearch объединяет веб-поиск, чтение и логический анализ для глубокого исследования. Представьте себе агента, который берет вашу исследовательскую задачу, проводит многократный поиск, анализирует и только потом выдает ответ. Этот процесс включает непрерывное исследование, логическое мышление и многогранное решение задач, что принципиально отличается от стандартных LLM, отвечающих на основе предобученных данных или традиционных RAG-систем с одноразовым поиском.",
  "kimi-k2-0711-preview.description": "kimi-k2 — базовая модель MoE с мощными возможностями программирования и агентных задач (1T параметров, 32B активных), превосходящая другие открытые модели в логике, программировании, математике и агентных бенчмарках.",
  "kimi-k2-0905-preview.description": "kimi-k2-0905-preview предлагает окно контекста 256k, улучшенное агентное программирование, более качественный фронтенд-код и лучшее понимание контекста.",
  "kimi-k2-instruct.description": "Kimi K2 Instruct — официальная модель логического мышления от Kimi с поддержкой длинного контекста для кода, вопросов-ответов и других задач.",
  "kimi-k2-thinking-turbo.description": "Высокоскоростной вариант K2 с длинным мышлением, поддержкой контекста 256k, мощной логикой и скоростью вывода 60–100 токенов/сек.",
  "kimi-k2-thinking.description": "kimi-k2-thinking — модель мышления от Moonshot AI с общими агентными и логическими возможностями. Отличается глубоким рассуждением и способна решать сложные задачи с помощью многошагового использования инструментов.",
  "kimi-k2-turbo-preview.description": "kimi-k2 — базовая модель MoE с мощными возможностями программирования и агентных задач (1T параметров, 32B активных), превосходящая другие открытые модели в логике, программировании, математике и агентных бенчмарках.",
  "kimi-k2.5.description": "Kimi K2.5 — самая мощная модель Kimi, обеспечивающая передовые результаты с открытым кодом в задачах агентов, программировании и визуальном понимании. Поддерживает мультимодальный ввод и режимы с мышлением и без.",
  "kimi-k2.description": "Kimi-K2 — базовая модель MoE от Moonshot AI с мощными возможностями программирования и агентных задач, всего 1T параметров и 32B активных. Превосходит другие открытые модели в логике, программировании, математике и агентных задачах.",
  "kimi-k2:1t.description": "Kimi K2 — крупная модель MoE LLM от Moonshot AI с 1T параметров и 32B активных на проход. Оптимизирована для агентных задач, включая продвинутое использование инструментов, логическое мышление и синтез кода.",
  "kimi-latest.description": "Kimi Latest использует новейшую модель Kimi и может включать экспериментальные функции. Поддерживает понимание изображений и автоматически выбирает модели тарификации 8k/32k/128k в зависимости от длины контекста.",
  "kuaishou/kat-coder-pro-v1.description": "KAT-Coder-Pro-V1 (бесплатно на ограниченное время) ориентирован на понимание кода и автоматизацию для эффективных кодирующих агентов.",
  "learnlm-1.5-pro-experimental.description": "LearnLM — экспериментальная специализированная модель, обученная на принципах педагогики для выполнения системных инструкций в образовательных сценариях, выступая в роли эксперта-наставника.",
  "learnlm-2.0-flash-experimental.description": "LearnLM — экспериментальная специализированная модель, обученная на принципах педагогики для выполнения системных инструкций в образовательных сценариях, выступая в роли эксперта-наставника.",
  "lite.description": "Spark Lite — легковесная LLM с ультранизкой задержкой и эффективной обработкой. Полностью бесплатна и поддерживает поиск в интернете в реальном времени. Быстрые ответы хорошо работают на устройствах с низкой вычислительной мощностью и при дообучении модели, обеспечивая высокую экономичность и интеллектуальный опыт, особенно в задачах вопросов-ответов, генерации контента и поиска.",
  "llama-3.1-70b-versatile.description": "Llama 3.1 70B обеспечивает улучшенное логическое мышление для сложных приложений, поддерживая высокую вычислительную нагрузку с высокой эффективностью и точностью.",
  "llama-3.1-8b-instant.description": "Llama 3.1 8B — высокоэффективная модель с быстрой генерацией текста, идеально подходящая для масштабных и экономичных приложений.",
  "llama-3.1-instruct.description": "Модель Llama 3.1, настроенная на выполнение инструкций, оптимизирована для чатов и превосходит многие открытые модели чатов по отраслевым бенчмаркам.",
  "llama-3.2-11b-vision-instruct.description": "Мощное логическое мышление по изображениям высокого разрешения, подходит для приложений визуального понимания.",
  "llama-3.2-11b-vision-preview.description": "Llama 3.2 разработана для задач, сочетающих зрение и текст, превосходно справляется с описанием изображений и визуальными вопросами-ответами, объединяя генерацию языка и визуальное мышление.",
  "llama-3.2-90b-vision-instruct.description": "Продвинутое логическое мышление по изображениям для приложений агентов визуального понимания.",
  "llama-3.2-90b-vision-preview.description": "Llama 3.2 разработана для задач, сочетающих зрение и текст, превосходно справляется с описанием изображений и визуальными вопросами-ответами, объединяя генерацию языка и визуальное мышление.",
  "llama-3.2-vision-instruct.description": "Модель Llama 3.2-Vision, настроенная на выполнение инструкций, оптимизирована для визуального распознавания, логики по изображениям, описания и общих визуальных вопросов-ответов.",
  "llama-3.3-70b-versatile.description": "Meta Llama 3.3 — многоязычная LLM с 70B параметров (ввод/вывод текста), доступна в вариантах предварительного обучения и настройки на инструкции. Вариант, настроенный на инструкции, оптимизирован для многоязычного диалога и превосходит многие открытые и закрытые модели чатов по отраслевым бенчмаркам.",
  "llama-3.3-70b.description": "Llama 3.3 70B: модель среднего и крупного размера, обеспечивающая баланс между логикой и пропускной способностью.",
  "llama-3.3-instruct.description": "Модель Llama 3.3, настроенная на выполнение инструкций, оптимизирована для чатов и превосходит многие открытые модели чатов по отраслевым бенчмаркам.",
  "llama3-70b-8192.description": "Meta Llama 3 70B обеспечивает исключительную обработку сложных задач для требовательных проектов.",
  "llama3-8b-8192.description": "Meta Llama 3 8B демонстрирует высокую логическую производительность в различных сценариях.",
  "llama3-groq-70b-8192-tool-use-preview.description": "Llama 3 Groq 70B Tool Use обеспечивает мощный вызов инструментов для эффективной обработки сложных задач.",
  "llama3-groq-8b-8192-tool-use-preview.description": "Llama 3 Groq 8B Tool Use оптимизирована для эффективного использования инструментов с быстрой параллельной обработкой.",
  "llama3.1-8b.description": "Llama 3.1 8B: компактный вариант Llama с низкой задержкой для легких онлайн-инференций и чатов.",
  "llama3.1.description": "Llama 3.1 — флагманская модель Meta, масштабируемая до 405B параметров для сложных диалогов, многоязычного перевода и анализа данных.",
  "llama3.1:405b.description": "Llama 3.1 — флагманская модель Meta, масштабируемая до 405B параметров для сложных диалогов, многоязычного перевода и анализа данных.",
  "llama3.1:70b.description": "Llama 3.1 — флагманская модель Meta, масштабируемая до 405B параметров для сложных диалогов, многоязычного перевода и анализа данных.",
  "llava-v1.5-7b-4096-preview.description": "LLaVA 1.5 7B объединяет визуальную обработку для генерации сложных выводов на основе визуального ввода.",
  "llava.description": "LLaVA — мультимодальная модель, объединяющая визуальный энкодер и Vicuna для мощного понимания связки зрение-язык.",
  "llava:13b.description": "LLaVA — мультимодальная модель, объединяющая визуальный энкодер и Vicuna для мощного понимания связки зрение-язык.",
  "llava:34b.description": "LLaVA — мультимодальная модель, объединяющая визуальный энкодер и Vicuna для мощного понимания связки зрение-язык.",
  "magistral-medium-latest.description": "Magistral Medium 1.2 — это передовая модель рассуждений от Mistral AI (сентябрь 2025 года) с поддержкой обработки изображений.",
  "magistral-small-2509.description": "Magistral Small 1.2 — это компактная модель рассуждений с открытым исходным кодом от Mistral AI (сентябрь 2025 года) с поддержкой обработки изображений.",
  "mathstral.description": "MathΣtral создана для научных исследований и математических рассуждений, обладает высокой вычислительной мощностью и способностью к объяснению.",
  "max-32k.description": "Spark Max 32K обеспечивает обработку больших контекстов с улучшенным пониманием и логическим мышлением, поддерживает ввод до 32K токенов для чтения длинных документов и работы с приватными знаниями.",
  "megrez-3b-instruct.description": "Megrez 3B Instruct — это компактная и эффективная модель от Wuwen Xinqiong.",
  "meituan/longcat-flash-chat.description": "Открытая базовая модель без рассуждений от Meituan, оптимизированная для диалогов и агентных задач, сильна в использовании инструментов и сложных многоходовых взаимодействиях.",
  "meta-llama-3-70b-instruct.description": "Мощная модель с 70 миллиардами параметров, превосходно справляющаяся с рассуждениями, программированием и широким спектром языковых задач.",
  "meta-llama-3-8b-instruct.description": "Универсальная модель с 8 миллиардами параметров, оптимизированная для чатов и генерации текста.",
  "meta-llama-3.1-405b-instruct.description": "Llama 3.1 — модель, обученная на инструкциях, оптимизированная для многоязычных чатов, демонстрирует высокие результаты на отраслевых бенчмарках среди открытых и закрытых моделей.",
  "meta-llama-3.1-70b-instruct.description": "Llama 3.1 — модель, обученная на инструкциях, оптимизированная для многоязычных чатов, демонстрирует высокие результаты на отраслевых бенчмарках среди открытых и закрытых моделей.",
  "meta-llama-3.1-8b-instruct.description": "Llama 3.1 — модель, обученная на инструкциях, оптимизированная для многоязычных чатов, демонстрирует высокие результаты на отраслевых бенчмарках среди открытых и закрытых моделей.",
  "meta-llama/Llama-2-13b-chat-hf.description": "LLaMA-2 Chat (13B) обеспечивает высокое качество обработки языка и стабильный опыт общения.",
  "meta-llama/Llama-2-70b-hf.description": "LLaMA-2 обеспечивает высокое качество обработки языка и стабильное взаимодействие.",
  "meta-llama/Llama-3-70b-chat-hf.description": "Llama 3 70B Instruct Reference — мощная модель для сложных диалогов.",
  "meta-llama/Llama-3-8b-chat-hf.description": "Llama 3 8B Instruct Reference поддерживает многоязычность и обладает широкими знаниями в различных областях.",
  "meta-llama/Llama-3.2-11B-Vision-Instruct-Turbo.description": "LLaMA 3.2 разработана для задач, сочетающих изображение и текст. Отлично справляется с описанием изображений и визуальными вопросами, объединяя генерацию текста и визуальное мышление.",
  "meta-llama/Llama-3.2-3B-Instruct-Turbo.description": "LLaMA 3.2 разработана для задач, сочетающих изображение и текст. Отлично справляется с описанием изображений и визуальными вопросами, объединяя генерацию текста и визуальное мышление.",
  "meta-llama/Llama-3.2-90B-Vision-Instruct-Turbo.description": "LLaMA 3.2 разработана для задач, сочетающих изображение и текст. Отлично справляется с описанием изображений и визуальными вопросами, объединяя генерацию текста и визуальное мышление.",
  "meta-llama/Llama-3.3-70B-Instruct-Turbo.description": "Meta Llama 3.3 — многоязычная LLM с 70 миллиардами параметров (ввод/вывод текста), обученная на инструкциях. Оптимизирована для многоязычных чатов и превосходит многие открытые и закрытые модели на отраслевых бенчмарках.",
  "meta-llama/Llama-Vision-Free.description": "LLaMA 3.2 разработана для задач, сочетающих изображение и текст. Отлично справляется с описанием изображений и визуальными вопросами, объединяя генерацию текста и визуальное мышление.",
  "meta-llama/Meta-Llama-3-70B-Instruct-Lite.description": "Llama 3 70B Instruct Lite создана для высокой производительности с низкой задержкой.",
  "meta-llama/Meta-Llama-3-70B-Instruct-Turbo.description": "Llama 3 70B Instruct Turbo обеспечивает глубокое понимание и генерацию текста для самых требовательных задач.",
  "meta-llama/Meta-Llama-3-8B-Instruct-Lite.description": "Llama 3 8B Instruct Lite сбалансирована для работы в условиях ограниченных ресурсов.",
  "meta-llama/Meta-Llama-3-8B-Instruct-Turbo.description": "Llama 3 8B Instruct Turbo — высокопроизводительная LLM для широкого спектра задач.",
  "meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo.description": "Модель Llama 3.1 Turbo с 405 миллиардами параметров обладает огромной контекстной емкостью для обработки больших данных и превосходно справляется с задачами ультра-масштабного ИИ.",
  "meta-llama/Meta-Llama-3.1-405B-Instruct.description": "Llama 3.1 — флагманская модель Meta, масштабируемая до 405 миллиардов параметров, предназначена для сложных диалогов, многоязычного перевода и анализа данных.",
  "meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo.description": "Llama 3.1 70B точно настроена для высоконагруженных приложений; квантование FP8 обеспечивает эффективные вычисления и точность в сложных сценариях.",
  "meta-llama/Meta-Llama-3.1-70B.description": "Llama 3.1 — флагманская модель Meta, масштабируемая до 405 миллиардов параметров, предназначена для сложных диалогов, многоязычного перевода и анализа данных.",
  "meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo.description": "Llama 3.1 8B использует квантование FP8, поддерживает до 131 072 токенов контекста и входит в число лучших открытых моделей для сложных задач по многим бенчмаркам.",
  "meta-llama/llama-3-70b-instruct.description": "Llama 3 70B Instruct оптимизирована для высококачественных диалогов и демонстрирует отличные результаты в оценках с участием людей.",
  "meta-llama/llama-3-8b-instruct.description": "Llama 3 8B Instruct оптимизирована для высококачественных диалогов, превосходя многие закрытые модели.",
  "meta-llama/llama-3.1-70b-instruct.description": "Последняя серия Meta Llama 3.1, вариант с 70 миллиардами параметров, обученный на инструкциях и оптимизированный для высококачественных диалогов. В отраслевых оценках показывает отличные результаты по сравнению с ведущими закрытыми моделями. (Доступна только для проверенных корпоративных клиентов.)",
  "meta-llama/llama-3.1-8b-instruct.description": "Последняя серия Meta Llama 3.1, вариант с 8 миллиардами параметров, обученный на инструкциях, особенно быстр и эффективен. В отраслевых оценках демонстрирует отличные результаты, превосходя многие ведущие закрытые модели. (Доступна только для проверенных корпоративных клиентов.)",
  "meta-llama/llama-3.1-8b-instruct:free.description": "LLaMA 3.1 поддерживает многоязычие и является одной из ведущих генеративных моделей.",
  "meta-llama/llama-3.2-11b-vision-instruct.description": "LLaMA 3.2 разработан для задач, сочетающих зрение и текст. Превосходно справляется с описанием изображений и визуальными вопросами-ответами, объединяя генерацию языка и визуальное рассуждение.",
  "meta-llama/llama-3.2-3b-instruct.description": "meta-llama/llama-3.2-3b-instruct",
  "meta-llama/llama-3.2-90b-vision-instruct.description": "LLaMA 3.2 разработан для задач, сочетающих зрение и текст. Превосходно справляется с описанием изображений и визуальными вопросами-ответами, объединяя генерацию языка и визуальное рассуждение.",
  "meta-llama/llama-3.3-70b-instruct.description": "Llama 3.3 — самая продвинутая многоязычная модель Llama с открытым исходным кодом, обеспечивающая производительность, близкую к 405B, при очень низкой стоимости. Основана на архитектуре Transformer и улучшена с помощью SFT и RLHF для повышения полезности и безопасности. Вариант, настроенный на инструкции, оптимизирован для многоязычного чата и превосходит многие открытые и закрытые модели в отраслевых бенчмарках. Дата отсечения знаний: декабрь 2023.",
  "meta-llama/llama-3.3-70b-instruct:free.description": "Llama 3.3 — самая продвинутая многоязычная модель Llama с открытым исходным кодом, обеспечивающая производительность, близкую к 405B, при очень низкой стоимости. Основана на архитектуре Transformer и улучшена с помощью SFT и RLHF для повышения полезности и безопасности. Вариант, настроенный на инструкции, оптимизирован для многоязычного чата и превосходит многие открытые и закрытые модели в отраслевых бенчмарках. Дата отсечения знаний: декабрь 2023.",
  "meta.llama3-1-405b-instruct-v1:0.description": "Meta Llama 3.1 405B Instruct — самая крупная и мощная модель Llama 3.1 Instruct, высокоразвитая модель для диалогового рассуждения и генерации синтетических данных, а также прочная основа для дообучения в конкретных доменах. Многоязычные LLM Llama 3.1 — это набор предварительно обученных и настроенных на инструкции моделей генерации в размерах 8B, 70B и 405B (ввод текста/вывод текста). Модели, настроенные на инструкции, оптимизированы для многоязычного диалога и превосходят многие доступные открытые чат-модели в отраслевых бенчмарках. Llama 3.1 предназначена для коммерческого и исследовательского использования на разных языках. Модели, настроенные на инструкции, подходят для чатов в стиле помощника, а предварительно обученные модели — для более широких задач генерации естественного языка. Выводы Llama 3.1 также можно использовать для улучшения других моделей, включая генерацию и доработку синтетических данных. Llama 3.1 — это авторегрессионная модель Transformer с оптимизированной архитектурой. Настроенные версии используют SFT и RLHF для соответствия человеческим предпочтениям в полезности и безопасности.",
  "meta.llama3-1-70b-instruct-v1:0.description": "Обновлённая версия Meta Llama 3.1 70B Instruct с расширенным контекстом до 128K, поддержкой нескольких языков и улучшенным рассуждением. Модели Llama 3.1 предназначены для коммерческого и исследовательского использования, оптимизированы для диалогов и превосходят многие открытые модели в отраслевых бенчмарках.",
  "meta.llama3-1-8b-instruct-v1:0.description": "Обновлённая версия Meta Llama 3.1 8B Instruct с контекстом 128K, поддержкой нескольких языков и улучшенным рассуждением. Подходит для диалогов в стиле помощника и генерации текста. Результаты могут использоваться для улучшения других моделей, включая генерацию синтетических данных.",
  "meta.llama3-70b-instruct-v1:0.description": "Meta Llama 3 — открытая LLM для разработчиков, исследователей и компаний, предназначенная для создания, тестирования и масштабирования идей генеративного ИИ. Подходит для создания контента, диалогов, понимания языка и корпоративных приложений.",
  "meta.llama3-8b-instruct-v1:0.description": "Meta Llama 3 — это открытая LLM для разработчиков, исследователей и предприятий, созданная для поддержки создания, экспериментов и ответственного масштабирования идей генеративного ИИ. Являясь частью основы для глобальных инноваций сообщества, она хорошо подходит для ограниченных вычислительных ресурсов, устройств на периферии и ускоренного обучения.",
  "meta/Llama-3.2-11B-Vision-Instruct.description": "Модель с высокой способностью к визуальному рассуждению на изображениях высокого разрешения, подходящая для приложений визуального понимания.",
  "meta/Llama-3.2-90B-Vision-Instruct.description": "Продвинутая модель визуального рассуждения для агентов, ориентированных на визуальное понимание.",
  "meta/Llama-3.3-70B-Instruct.description": "Llama 3.3 — самая продвинутая многоязычная открытая модель Llama, обеспечивающая производительность, близкую к 405B, при очень низкой стоимости. Основана на архитектуре Transformer и улучшена с помощью SFT и RLHF для повышения полезности и безопасности. Версия с настройкой под инструкции оптимизирована для многоязычного общения и превосходит многие открытые и закрытые модели чатов по отраслевым бенчмаркам. Актуальность знаний: декабрь 2023.",
  "meta/Meta-Llama-3-70B-Instruct.description": "Мощная модель с 70 миллиардами параметров, превосходно справляющаяся с рассуждениями, программированием и широким спектром языковых задач.",
  "meta/Meta-Llama-3-8B-Instruct.description": "Универсальная модель с 8 миллиардами параметров, оптимизированная для общения и генерации текста.",
  "meta/Meta-Llama-3.1-405B-Instruct.description": "Модель Llama 3.1 с настройкой под инструкции, оптимизированная для многоязычного общения, демонстрирует высокие результаты по отраслевым бенчмаркам среди открытых и закрытых моделей чатов.",
  "meta/Meta-Llama-3.1-70B-Instruct.description": "Модель Llama 3.1 с настройкой под инструкции, оптимизированная для многоязычного общения, демонстрирует высокие результаты по отраслевым бенчмаркам среди открытых и закрытых моделей чатов.",
  "meta/Meta-Llama-3.1-8B-Instruct.description": "Модель Llama 3.1 с настройкой под инструкции, оптимизированная для многоязычного общения, демонстрирует высокие результаты по отраслевым бенчмаркам среди открытых и закрытых моделей чатов.",
  "meta/llama-3-70b.description": "Открытая модель с 70 миллиардами параметров, дообученная Meta для следования инструкциям, предоставляется через Groq на аппаратуре LPU для быстрого и эффективного вывода.",
  "meta/llama-3-8b.description": "Открытая модель с 8 миллиардами параметров, дообученная Meta для следования инструкциям, предоставляется через Groq на аппаратуре LPU для быстрого и эффективного вывода.",
  "meta/llama-3.1-405b-instruct.description": "Продвинутая LLM, поддерживающая генерацию синтетических данных, дистилляцию знаний и рассуждение для чат-ботов, программирования и специализированных задач.",
  "meta/llama-3.1-70b-instruct.description": "Создана для сложных диалогов с отличным пониманием контекста, рассуждением и генерацией текста.",
  "meta/llama-3.1-70b.description": "Обновлённая Meta Llama 3 70B Instruct с контекстом 128K, поддержкой многоязычности и улучшенным рассуждением.",
  "meta/llama-3.1-8b-instruct.description": "Передовая модель с высоким уровнем понимания языка, рассуждения и генерации текста.",
  "meta/llama-3.1-8b.description": "Llama 3.1 8B поддерживает окно контекста 128K, идеально подходит для общения в реальном времени и анализа данных, обеспечивая значительную экономию по сравнению с более крупными моделями. Предоставляется через Groq на аппаратуре LPU для быстрого и эффективного вывода.",
  "meta/llama-3.2-11b-vision-instruct.description": "Передовая модель визуально-языкового понимания, превосходно справляющаяся с высококачественным рассуждением по изображениям.",
  "meta/llama-3.2-11b.description": "Модель с настройкой под инструкции для визуального рассуждения (ввод: текст+изображение, вывод: текст), оптимизированная для визуального распознавания, рассуждения, описания и общего визуального QA.",
  "meta/llama-3.2-1b-instruct.description": "Передовая компактная языковая модель с высоким уровнем понимания, рассуждения и генерации текста.",
  "meta/llama-3.2-1b.description": "Модель только для текста, предназначенная для использования на устройствах, таких как многоязычный локальный поиск, суммирование и переформулирование.",
  "meta/llama-3.2-3b-instruct.description": "Передовая компактная языковая модель с высоким уровнем понимания, рассуждения и генерации текста.",
  "meta/llama-3.2-3b.description": "Модель только для текста, дообученная для использования на устройствах, таких как многоязычный локальный поиск, суммирование и переформулирование.",
  "meta/llama-3.2-90b-vision-instruct.description": "Передовая модель визуально-языкового понимания, превосходно справляющаяся с высококачественным рассуждением по изображениям.",
  "meta/llama-3.2-90b.description": "Модель с настройкой под инструкции для визуального рассуждения (ввод: текст+изображение, вывод: текст), оптимизированная для визуального распознавания, рассуждения, описания и общего визуального QA.",
  "meta/llama-3.3-70b-instruct.description": "Продвинутая LLM, сильная в рассуждении, математике, здравом смысле и вызове функций.",
  "meta/llama-3.3-70b.description": "Идеальный баланс производительности и эффективности. Создана для высокопроизводительного разговорного ИИ в создании контента, корпоративных приложениях и исследованиях, с высоким уровнем понимания языка для суммирования, классификации, анализа тональности и генерации кода.",
  "meta/llama-4-maverick.description": "Семейство Llama 4 — это нативные мультимодальные модели ИИ, поддерживающие текст и мультимодальные взаимодействия, использующие MoE для передового понимания текста и изображений. Llama 4 Maverick — это модель с 17B параметрами и 128 экспертами, предоставляемая DeepInfra.",
  "meta/llama-4-scout.description": "Семейство Llama 4 — это нативные мультимодальные модели ИИ, поддерживающие текст и мультимодальные взаимодействия, использующие MoE для передового понимания текста и изображений. Llama 4 Scout — это модель с 17B параметрами и 16 экспертами, предоставляемая DeepInfra.",
  "microsoft/Phi-3-medium-128k-instruct.description": "Та же модель Phi-3-medium, но с увеличенным окном контекста для задач RAG или few-shot.",
  "microsoft/Phi-3-medium-4k-instruct.description": "Модель с 14 млрд параметров, превосходящая Phi-3-mini по качеству, ориентирована на задачи, требующие глубокого рассуждения.",
  "microsoft/Phi-3-mini-128k-instruct.description": "Та же модель Phi-3-mini, но с увеличенным окном контекста для задач RAG или few-shot.",
  "microsoft/Phi-3-mini-4k-instruct.description": "Наименьшая модель в семействе Phi-3, оптимизированная для качества и низкой задержки.",
  "microsoft/Phi-3-small-128k-instruct.description": "Та же модель Phi-3-small, но с увеличенным окном контекста для задач RAG или few-shot.",
  "microsoft/Phi-3-small-8k-instruct.description": "Модель с 7 млрд параметров, превосходящая Phi-3-mini по качеству, ориентирована на задачи, требующие глубокого рассуждения.",
  "microsoft/Phi-3.5-mini-instruct.description": "Обновлённая версия модели Phi-3-mini.",
  "microsoft/Phi-3.5-vision-instruct.description": "Обновлённая версия модели Phi-3-vision.",
  "microsoft/WizardLM-2-8x22B.description": "WizardLM 2 — языковая модель от Microsoft AI, превосходно справляющаяся со сложными диалогами, многоязычными задачами, рассуждением и задачами помощников.",
  "microsoft/wizardlm-2-8x22b.description": "WizardLM-2 8x22B — самая продвинутая модель Wizard от Microsoft AI с высокой производительностью.",
  "mimo-v2-flash.description": "MiMo-V2-Flash: эффективная модель для рассуждений, программирования и создания агентов.",
  "minicpm-v.description": "MiniCPM-V — мультимодальная модель нового поколения от OpenBMB с отличным OCR и пониманием мультимодальных данных для широкого спектра задач.",
  "minimax-m2.1.description": "MiniMax-M2.1 — последняя версия серии MiniMax, оптимизированная для многоязычного программирования и сложных задач реального мира. Как нативная AI-модель, она значительно улучшает производительность, поддержку агентных фреймворков и адаптацию к различным сценариям, помогая компаниям и пользователям быстрее находить AI-решения для работы и жизни.",
  "minimax-m2.description": "MiniMax M2 — эффективная большая языковая модель, специально созданная для программирования и агентных рабочих процессов.",
  "minimax/minimax-m2.1.description": "MiniMax-M2.1 — лёгкая и передовая большая языковая модель, оптимизированная для программирования, агентных рабочих процессов и современного приложения, обеспечивающая более чистый и лаконичный вывод и быструю реакцию.",
  "minimax/minimax-m2.description": "MiniMax-M2 — высокоэффективная модель, превосходно справляющаяся с программированием и агентными задачами в инженерных сценариях.",
  "minimaxai/minimax-m2.description": "MiniMax-M2 — компактная, быстрая и экономичная модель MoE (230B общих, 10B активных параметров), созданная для высококлассного программирования и агентных задач при сохранении сильного общего интеллекта. Отлично справляется с редактированием нескольких файлов, циклами запуска-кода-исправления, проверкой тестов и сложными цепочками инструментов.",
  "ministral-3b-latest.description": "Ministral 3B — это флагманская модель edge-класса от Mistral.",
  "ministral-8b-latest.description": "Ministral 8B — высокоэффективная модель edge-класса от Mistral с оптимальным соотношением цена/качество.",
  "mistral-ai/Mistral-Large-2411.description": "Флагманская модель Mistral для сложных задач, требующих масштабного рассуждения или специализации (генерация синтетического текста, кода, RAG или агенты).",
  "mistral-ai/Mistral-Nemo.description": "Mistral Nemo — передовая LLM с выдающимися возможностями рассуждения, знаниями о мире и кодированием для своей размерности.",
  "mistral-ai/mistral-small-2503.description": "Mistral Small подходит для любых задач, связанных с языком, где важны высокая эффективность и низкая задержка.",
  "mistral-large-instruct.description": "Mistral-Large-Instruct-2407 — продвинутая плотная LLM с 123 миллиардами параметров, обладающая передовыми возможностями рассуждения, знаний и программирования.",
  "mistral-large-latest.description": "Mistral Large — флагманская модель, сильная в многоязычных задачах, сложном рассуждении и генерации кода — идеально подходит для высокоуровневых приложений.",
  "mistral-large.description": "Mixtral Large — флагманская модель от Mistral, сочетающая генерацию кода, математику и рассуждение с контекстным окном на 128K.",
  "mistral-medium-latest.description": "Mistral Medium 3 обеспечивает передовую производительность при 8-кратном снижении стоимости и упрощает корпоративное внедрение.",
  "mistral-nemo-instruct.description": "Mistral-Nemo-Instruct-2407 — версия модели Mistral-Nemo-Base-2407, адаптированная под инструкции.",
  "mistral-nemo.description": "Mistral Nemo — высокоэффективная модель на 12B параметров от Mistral AI и NVIDIA.",
  "mistral-small-latest.description": "Mistral Small — экономичное, быстрое и надежное решение для перевода, суммирования и анализа тональности.",
  "mistral-small.description": "Mistral Small подходит для любых языковых задач, где важны высокая эффективность и низкая задержка.",
  "mistral.description": "Mistral — модель на 7B параметров от Mistral AI, подходящая для разнообразных языковых задач.",
  "mistral/codestral-embed.description": "Модель для встраивания кода, предназначенная для индексирования кодовых баз и репозиториев в помощь ассистентам по программированию.",
  "mistral/codestral.description": "Mistral Codestral 25.01 — передовая модель программирования, оптимизированная для низкой задержки и частого использования. Поддерживает более 80 языков и превосходна в FIM, исправлении кода и генерации тестов.",
  "mistral/devstral-small.description": "Devstral — агентная LLM для задач в области разработки ПО, отличный выбор для инженерных агентов.",
  "mistral/magistral-medium.description": "Сложное мышление, поддерживаемое глубоким пониманием и прозрачной логикой, которую можно проследить и проверить. Сохраняет точность рассуждений на разных языках даже в середине задачи.",
  "mistral/magistral-small.description": "Сложное мышление, поддерживаемое глубоким пониманием и прозрачной логикой, которую можно проследить и проверить. Сохраняет точность рассуждений на разных языках даже в середине задачи.",
  "mistral/ministral-3b.description": "Компактная и эффективная модель для задач на устройстве, таких как ассистенты и локальная аналитика, с низкой задержкой.",
  "mistral/ministral-8b.description": "Более мощная модель с быстрой и экономной по памяти инференцией, идеально подходит для сложных рабочих процессов и требовательных edge-приложений.",
  "mistral/mistral-embed.description": "Универсальная модель встраивания текста для семантического поиска, оценки схожести, кластеризации и RAG-процессов.",
  "mistral/mistral-large.description": "Mistral Large идеально подходит для сложных задач, требующих мощного рассуждения или специализации — генерации синтетического текста, кода, RAG или агентов.",
  "mistral/mistral-small.description": "Mistral Small идеально подходит для простых, пакетных задач, таких как классификация, поддержка клиентов или генерация текста, обеспечивая отличную производительность по доступной цене.",
  "mistral/mixtral-8x22b-instruct.description": "Модель 8x22B Instruct. 8x22B — это открытая MoE-модель, предоставляемая Mistral.",
  "mistral/pixtral-12b.description": "Модель на 12B параметров с пониманием изображений и текста.",
  "mistral/pixtral-large.description": "Pixtral Large — вторая модель в нашей мультимодальной линейке с передовым пониманием изображений. Обрабатывает документы, графики и естественные изображения, сохраняя при этом выдающееся понимание текста от Mistral Large 2.",
  "mistralai/Mistral-7B-Instruct-v0.1.description": "Mistral (7B) Instruct известна своей высокой производительностью в различных языковых задачах.",
  "mistralai/Mistral-7B-Instruct-v0.2.description": "Mistral (7B) Instruct v0.2 улучшает обработку инструкций и точность результатов.",
  "mistralai/Mistral-7B-Instruct-v0.3.description": "Mistral (7B) Instruct v0.3 обеспечивает эффективные вычисления и отличное понимание языка для множества сценариев.",
  "mistralai/Mistral-7B-v0.1.description": "Mistral 7B — компактная, но высокопроизводительная модель, хорошо подходит для пакетной обработки и простых задач, таких как классификация и генерация текста, с уверенными логическими способностями.",
  "mistralai/Mixtral-8x22B-Instruct-v0.1.description": "Mixtral-8x22B Instruct (141B) — очень крупная языковая модель для работы с тяжёлыми нагрузками.",
  "mistralai/Mixtral-8x7B-Instruct-v0.1.description": "Mixtral-8x7B Instruct (46.7B) обладает высокой пропускной способностью для обработки данных в крупном масштабе.",
  "mistralai/Mixtral-8x7B-v0.1.description": "Mixtral 8x7B — разреженная модель MoE, ускоряющая вывод, подходит для многоязычных задач и генерации кода.",
  "mistralai/mistral-nemo.description": "Mistral Nemo — модель на 7.3B параметров с поддержкой нескольких языков и высокой производительностью в программировании.",
  "mixtral-8x7b-32768.description": "Mixtral 8x7B обеспечивает отказоустойчивую параллельную обработку для сложных задач.",
  "mixtral.description": "Mixtral — модель MoE от Mistral AI с открытыми весами, поддерживающая генерацию кода и понимание языка.",
  "mixtral:8x22b.description": "Mixtral — модель MoE от Mistral AI с открытыми весами, поддерживающая генерацию кода и понимание языка.",
  "moonshot-v1-128k-vision-preview.description": "Модели Kimi Vision (включая moonshot-v1-8k-vision-preview/moonshot-v1-32k-vision-preview/moonshot-v1-128k-vision-preview) способны понимать содержимое изображений, включая текст, цвета и формы объектов.",
  "moonshot-v1-128k.description": "Moonshot V1 128K предоставляет сверхдлинный контекст для генерации очень длинных текстов, обрабатывая до 128 000 токенов — идеально для исследований, академических задач и работы с большими документами.",
  "moonshot-v1-32k-vision-preview.description": "Модели Kimi Vision (включая moonshot-v1-8k-vision-preview/moonshot-v1-32k-vision-preview/moonshot-v1-128k-vision-preview) способны понимать содержимое изображений, включая текст, цвета и формы объектов.",
  "moonshot-v1-32k.description": "Moonshot V1 32K поддерживает 32 768 токенов для контекста средней длины, идеально подходит для длинных документов и сложных диалогов в создании контента, отчётах и чат-системах.",
  "moonshot-v1-8k-vision-preview.description": "Модели Kimi Vision (включая moonshot-v1-8k-vision-preview/moonshot-v1-32k-vision-preview/moonshot-v1-128k-vision-preview) способны понимать содержимое изображений, включая текст, цвета и формы объектов.",
  "moonshot-v1-8k.description": "Moonshot V1 8K оптимизирована для генерации коротких текстов с высокой эффективностью, обрабатывает 8192 токена — подходит для коротких чатов, заметок и быстрого контента.",
  "moonshot-v1-auto.description": "Moonshot V1 Auto автоматически выбирает подходящую модель в зависимости от текущего использования токенов контекста.",
  "moonshotai/Kimi-Dev-72B.description": "Kimi-Dev-72B — открытая языковая модель для программирования, оптимизированная с помощью масштабного обучения с подкреплением для создания надёжных, готовых к производству патчей. Набирает 60.4% на SWE-bench Verified, устанавливая новый рекорд среди открытых моделей для задач автоматизированной разработки ПО, таких как исправление ошибок и ревью кода.",
  "moonshotai/Kimi-K2-Instruct-0905.description": "Kimi K2-Instruct-0905 — новейшая и самая мощная версия Kimi K2. Это топовая модель MoE с 1 триллионом общих и 32 миллиардами активных параметров. Ключевые особенности: улучшенный интеллект в программировании агентов, значительный прирост в бенчмарках и реальных задачах, а также улучшенная эстетика и удобство фронтенд-кода.",
  "moonshotai/Kimi-K2-Thinking.description": "Kimi K2 Thinking — самая мощная открытая модель для рассуждений. Существенно увеличивает глубину многошагового мышления и стабильно использует инструменты на протяжении 200–300 последовательных вызовов. Устанавливает новые рекорды на Humanity's Last Exam (HLE), BrowseComp и других бенчмарках. Отлично справляется с программированием, математикой, логикой и агентными сценариями. Построена на архитектуре MoE с ~1 триллионом параметров, поддерживает окно контекста 256K и вызов инструментов.",
  "moonshotai/kimi-k2-0711.description": "Kimi K2 0711 — вариант instruct в серии Kimi, предназначен для высококачественного кода и использования инструментов.",
  "moonshotai/kimi-k2-0905.description": "Kimi K2 0905 — обновление, расширяющее контекст и логические возможности с оптимизациями для программирования.",
  "moonshotai/kimi-k2-instruct-0905.description": "Модель kimi-k2-0905-preview поддерживает окно контекста 256K, обладает улучшенными возможностями программирования агентов, более качественным и практичным фронтенд-кодом и лучшим пониманием контекста.",
  "moonshotai/kimi-k2-thinking-turbo.description": "Kimi K2 Thinking Turbo — высокоскоростная версия Kimi K2 Thinking, значительно снижает задержку при сохранении глубины рассуждений.",
  "moonshotai/kimi-k2-thinking.description": "Kimi K2 Thinking — модель рассуждений от Moonshot, оптимизированная для задач глубокого мышления, с общими агентными возможностями.",
  "moonshotai/kimi-k2.description": "Kimi K2 — крупная модель MoE от Moonshot AI с 1 триллионом параметров и 32 миллиардами активных на проход, оптимизирована для агентных возможностей, включая продвинутую работу с инструментами, логическое мышление и синтез кода.",
  "morph/morph-v3-fast.description": "Morph — специализированная модель для применения изменений в коде, предложенных передовыми моделями (например, Claude или GPT-4o), к существующим файлам со скоростью более 4500 токенов/сек. Это финальный этап в AI-пайплайне программирования, поддерживает 16k токенов на вход/выход.",
  "morph/morph-v3-large.description": "Morph — специализированная модель для применения изменений в коде, предложенных передовыми моделями (например, Claude или GPT-4o), к существующим файлам со скоростью более 2500 токенов/сек. Это финальный этап в AI-пайплайне программирования, поддерживает 16k токенов на вход/выход.",
  "nousresearch/hermes-2-pro-llama-3-8b.description": "Hermes 2 Pro Llama 3 8B — обновлённая версия Nous Hermes 2 с новейшими внутренними датасетами.",
  "nvidia/Llama-3.1-Nemotron-70B-Instruct-HF.description": "Llama 3.1 Nemotron 70B — кастомизированная модель от NVIDIA, улучшающая полезность. Демонстрирует высокие результаты на Arena Hard, AlpacaEval 2 LC и GPT-4-Turbo MT-Bench, занимая первое место на всех трёх бенчмарках авто-выравнивания по состоянию на 1 октября 2024 года. Обучена на основе Llama-3.1-70B-Instruct с использованием RLHF (REINFORCE), Llama-3.1-Nemotron-70B-Reward и HelpSteer2-Preference prompts.",
  "nvidia/llama-3.1-nemotron-51b-instruct.description": "Уникальная языковая модель с выдающейся точностью и эффективностью.",
  "nvidia/llama-3.1-nemotron-70b-instruct.description": "Llama-3.1-Nemotron-70B-Instruct — кастомизированная модель от NVIDIA, созданная для повышения полезности ответов LLM.",
  "o1-mini.description": "Меньше и быстрее, чем o1-preview, на 80% дешевле, силен в генерации кода и задачах с коротким контекстом.",
  "o1-preview.description": "Сфокусирован на продвинутом рассуждении и решении сложных задач, включая математику и науку. Идеален для приложений, требующих глубокого понимания контекста и автономных рабочих процессов.",
  "o1-pro.description": "Серия o1 обучена с использованием обучения с подкреплением для предварительного обдумывания ответов и решения сложных задач. o1-pro использует больше вычислений для более глубокого мышления и стабильно высокого качества ответов.",
  "o1.description": "o1 — новая модель рассуждения от OpenAI с вводом текст+изображение и текстовым выводом, подходящая для сложных задач, требующих обширных знаний. Имеет контекстное окно 200K и отсечку знаний на октябрь 2023 года.",
  "o3-2025-04-16.description": "o3 — новая модель рассуждения от OpenAI с вводом текст+изображение и текстовым выводом для сложных задач, требующих обширных знаний.",
  "o3-deep-research.description": "o3-deep-research — наша самая продвинутая модель для глубоких исследований и многошаговых задач. Может искать в интернете и получать доступ к вашим данным через MCP-коннекторы.",
  "o3-mini.description": "o3-mini — наша последняя компактная модель рассуждения, обеспечивающая более высокий интеллект при тех же затратах и задержке, что и o1-mini.",
  "o3-pro-2025-06-10.description": "o3 Pro — новая модель рассуждения от OpenAI с вводом текст+изображение и текстовым выводом для сложных задач, требующих обширных знаний.",
  "o3-pro.description": "o3-pro использует больше вычислений для более глубокого мышления и стабильно лучших ответов; доступна только через Responses API.",
  "o3.description": "o3 — мощная универсальная модель, устанавливающая новый стандарт в математике, науке, программировании и визуальном рассуждении. Превосходна в техническом письме, следовании инструкциям и анализе текста, кода и изображений для многошаговых задач.",
  "o4-mini-2025-04-16.description": "o4-mini — модель рассуждения от OpenAI с вводом текст+изображение и текстовым выводом, подходящая для сложных задач, требующих обширных знаний, с контекстным окном 200K.",
  "o4-mini-deep-research.description": "o4-mini-deep-research — более быстрая и доступная модель для глубоких исследований и многошаговых задач. Может искать в интернете и получать доступ к вашим данным через MCP-коннекторы.",
  "o4-mini.description": "o4-mini — последняя компактная модель серии o, оптимизированная для быстрого и эффективного рассуждения с высокой эффективностью в задачах программирования и компьютерного зрения.",
  "pixtral-12b-2409.description": "Pixtral отлично справляется с анализом графиков и изображений, вопросами по документам, мультимодальным рассуждением и выполнением инструкций. Он обрабатывает изображения в их исходном разрешении и соотношении сторон, поддерживая любое количество изображений в контексте до 128K.",
  "pixtral-large-latest.description": "Pixtral Large — это открытая мультимодальная модель с 124 миллиардами параметров, построенная на базе Mistral Large 2. Это вторая модель в нашей мультимодальной линейке, обладающая передовыми возможностями понимания изображений.",
  "pro-128k.description": "Spark Pro 128K обладает очень большой контекстной емкостью — до 128K, что делает его идеальным для анализа длинных документов, требующих полного охвата текста и логической связности, с поддержкой логики и разнообразных ссылок в сложных обсуждениях.",
  "pro-deepseek-r1.description": "Выделенная корпоративная модель обслуживания с включенной параллельной обработкой.",
  "pro-deepseek-v3.description": "Выделенная корпоративная модель обслуживания с включенной параллельной обработкой.",
  "qianfan-70b.description": "Qianfan 70B — это крупная китайская модель для высококачественной генерации текста и сложного рассуждения.",
  "qianfan-8b.description": "Qianfan 8B — это универсальная модель среднего размера, обеспечивающая баланс между стоимостью и качеством генерации текста и ответов на вопросы.",
  "qianfan-agent-intent-32k.description": "Qianfan Agent Intent 32K предназначена для распознавания намерений и координации агентов с поддержкой длинного контекста.",
  "qianfan-agent-lite-8k.description": "Qianfan Agent Lite 8K — это легковесная агентная модель для недорогих многотактных диалогов и рабочих процессов.",
  "qianfan-check-vl.description": "Qianfan Check VL — это мультимодальная модель для проверки соответствия контента изображений и текста, а также задач распознавания.",
  "qianfan-composition.description": "Qianfan Composition — это мультимодальная модель для создания и понимания смешанного контента изображение-текст.",
  "qianfan-engcard-vl.description": "Qianfan EngCard VL — это мультимодальная модель распознавания, ориентированная на англоязычные сценарии.",
  "qianfan-lightning-128b-a19b.description": "Qianfan Lightning 128B A19B — это высокопроизводительная китайская универсальная модель для сложных вопросов и масштабного рассуждения.",
  "qianfan-llama-vl-8b.description": "Qianfan Llama VL 8B — мультимодальная модель на базе Llama для общего понимания изображений и текста.",
  "qianfan-multipicocr.description": "Qianfan MultiPicOCR — это модель OCR для нескольких изображений, предназначенная для обнаружения и распознавания текста на изображениях.",
  "qianfan-qi-vl.description": "Qianfan QI VL — мультимодальная модель для точного поиска и ответов на вопросы в сложных сценариях изображение-текст.",
  "qianfan-singlepicocr.description": "Qianfan SinglePicOCR — это модель OCR для одного изображения с высокой точностью распознавания символов.",
  "qianfan-vl-70b.description": "Qianfan VL 70B — это крупная мультимодальная модель для сложного понимания изображений и текста.",
  "qianfan-vl-8b.description": "Qianfan VL 8B — это легковесная мультимодальная модель для повседневного анализа изображений и текстов и ответов на вопросы.",
  "qvq-72b-preview.description": "QVQ-72B-Preview — это экспериментальная исследовательская модель от Qwen, направленная на улучшение визуального рассуждения.",
  "qvq-max.description": "Модель визуального рассуждения Qwen QVQ поддерживает ввод изображений и вывод в виде цепочки рассуждений, демонстрируя высокую производительность в математике, программировании, визуальном анализе, творческих и общих задачах.",
  "qvq-plus.description": "Модель визуального рассуждения с вводом изображений и выводом в виде цепочки рассуждений. Серия qvq-plus следует за qvq-max и обеспечивает более быстрое рассуждение с лучшим соотношением качества и стоимости.",
  "qwen-3-32b.description": "Qwen 3 32B: сильна в многоязычных и программных задачах, подходит для средне-масштабного промышленного использования.",
  "qwen-coder-plus.description": "Модель программирования Qwen.",
  "qwen-coder-turbo-latest.description": "Модель программирования Qwen.",
  "qwen-coder-turbo.description": "Модель программирования Qwen.",
  "qwen-flash.description": "Самая быстрая и недорогая модель Qwen, идеально подходит для простых задач.",
  "qwen-image-edit.description": "Qwen Image Edit — это модель преобразования изображений, которая редактирует изображения на основе входных изображений и текстовых подсказок, обеспечивая точные корректировки и творческие трансформации.",
  "qwen-image.description": "Qwen-Image — это универсальная модель генерации изображений, поддерживающая различные художественные стили и сложную отрисовку текста, особенно на китайском и английском языках. Поддерживает многострочные макеты, абзацы и детализированную генерацию для сложных текстово-визуальных композиций.",
  "qwen-long.description": "Ультра-крупная модель Qwen с поддержкой длинного контекста и диалогов в рамках одного или нескольких документов.",
  "qwen-math-plus-latest.description": "Qwen Math — языковая модель, специализирующаяся на решении математических задач.",
  "qwen-math-plus.description": "Qwen Math — языковая модель, специализирующаяся на решении математических задач.",
  "qwen-math-turbo-latest.description": "Qwen Math — языковая модель, специализирующаяся на решении математических задач.",
  "qwen-math-turbo.description": "Qwen Math — языковая модель, специализирующаяся на решении математических задач.",
  "qwen-max.description": "Ультра-крупная модель Qwen с сотнями миллиардов параметров, поддерживающая китайский, английский и другие языки; API-модель, лежащая в основе текущих продуктов Qwen2.5.",
  "qwen-omni-turbo.description": "Модели Qwen-Omni поддерживают мультимодальный ввод (видео, аудио, изображения, текст) и вывод в виде аудио и текста.",
  "qwen-plus.description": "Улучшенная ультра-крупная модель Qwen с поддержкой китайского, английского и других языков.",
  "qwen-turbo.description": "Qwen Turbo больше не обновляется; рекомендуется заменить на Qwen Flash. Ультра-крупная модель Qwen с поддержкой китайского, английского и других языков.",
  "qwen-vl-chat-v1.description": "Qwen VL поддерживает гибкие взаимодействия, включая ввод нескольких изображений, многотактные вопросы и ответы, а также творческие задачи.",
  "qwen-vl-max-latest.description": "Ультра-крупная мультимодальная модель Qwen. По сравнению с улучшенной версией, она еще больше усиливает визуальное рассуждение и следование инструкциям, обеспечивая более сильное восприятие и когнитивные способности.",
  "qwen-vl-max.description": "Ультра-крупная мультимодальная модель Qwen. По сравнению с улучшенной версией, она еще больше усиливает визуальное рассуждение и следование инструкциям, обеспечивая более сильное визуальное восприятие и когнитивные способности.",
  "qwen-vl-ocr.description": "Qwen OCR — это модель извлечения текста из документов, таблиц, экзаменационных изображений и рукописного текста. Поддерживает китайский, английский, французский, японский, корейский, немецкий, русский, итальянский, вьетнамский и арабский языки.",
  "qwen-vl-plus-latest.description": "Улучшенная крупномасштабная мультимодальная модель Qwen с заметным улучшением детализации и распознавания текста, поддерживающая разрешение более одного мегапикселя и произвольные соотношения сторон.",
  "qwen-vl-plus.description": "Улучшенная крупномасштабная мультимодальная модель Qwen с заметным улучшением детализации и распознавания текста, поддерживающая разрешение более одного мегапикселя и произвольные соотношения сторон.",
  "qwen-vl-v1.description": "Предобученная модель, инициализированная от Qwen-7B с добавленным модулем зрения и входом изображения с разрешением 448.",
  "qwen/qwen-2-7b-instruct.description": "Qwen2 — это новая серия языковых моделей Qwen. Qwen2 7B — это модель на основе трансформеров, превосходно справляющаяся с пониманием языка, многоязычностью, программированием, математикой и рассуждением.",
  "qwen/qwen-2-7b-instruct:free.description": "Qwen2 — это новая серия крупных языковых моделей с улучшенным пониманием и генерацией.",
  "qwen2.5-7b-instruct.description": "Qwen2.5 7B Instruct — зрелая модель с открытым исходным кодом для инструкционного обучения, подходящая для многосценарного общения и генерации.",
  "qwen2.5-coder-1.5b-instruct.description": "Открытая модель кода Qwen.",
  "qwen2.5-coder-14b-instruct.description": "Открытая модель кода Qwen.",
  "qwen2.5-coder-32b-instruct.description": "Открытая модель кода Qwen.",
  "qwen2.5-coder-7b-instruct.description": "Открытая модель кода Qwen.",
  "qwen2.5-coder-instruct.description": "Qwen2.5-Coder — новейшая модель LLM с фокусом на программировании в семействе Qwen (ранее CodeQwen).",
  "qwen2.5-instruct.description": "Qwen2.5 — последняя серия LLM от Qwen, включающая базовые и инструкционно-обученные модели от 0.5B до 72B параметров.",
  "qwen2.5-math-1.5b-instruct.description": "Qwen-Math демонстрирует высокую эффективность в решении математических задач.",
  "qwen2.5-math-72b-instruct.description": "Qwen-Math демонстрирует высокую эффективность в решении математических задач.",
  "qwen2.5-math-7b-instruct.description": "Qwen-Math демонстрирует высокую эффективность в решении математических задач.",
  "qwen2.5-omni-7b.description": "Модели Qwen-Omni поддерживают мультимодальные входные данные (видео, аудио, изображения, текст) и вывод в виде аудио и текста.",
  "qwen2.5-vl-32b-instruct.description": "Qwen2.5 VL 32B Instruct — открытая мультимодальная модель, подходящая для частного развертывания и многосценарного использования.",
  "qwen2.5-vl-72b-instruct.description": "Улучшенное следование инструкциям, решение задач, математика и программирование, а также более точное распознавание объектов. Поддерживает точную локализацию визуальных элементов в различных форматах, понимание длинных видео (до 10 минут) с точной временной разметкой событий, определением порядка и скорости, а также агентов, способных управлять ОС или мобильными устройствами через парсинг и локализацию. Эффективное извлечение ключевой информации и вывод в формате JSON. Это версия 72B — самая мощная в серии.",
  "qwen2.5-vl-7b-instruct.description": "Qwen2.5 VL 7B Instruct — легковесная мультимодальная модель, сочетающая низкие затраты на развертывание и хорошие способности к распознаванию.",
  "qwen2.5-vl-instruct.description": "Qwen2.5-VL — новейшая модель слияния зрения и языка в семействе Qwen.",
  "qwen2.5.description": "Qwen2.5 — это LLM нового поколения от Alibaba с высокой производительностью в различных сценариях использования.",
  "qwen2.5:0.5b.description": "Qwen2.5 — это LLM нового поколения от Alibaba с высокой производительностью в различных сценариях использования.",
  "qwen2.5:1.5b.description": "Qwen2.5 — это LLM нового поколения от Alibaba с высокой производительностью в различных сценариях использования.",
  "qwen2.5:72b.description": "Qwen2.5 — это LLM нового поколения от Alibaba с высокой производительностью в различных сценариях использования.",
  "qwen2.description": "Qwen2 — это LLM нового поколения от Alibaba с высокой производительностью в различных сценариях использования.",
  "qwen2:0.5b.description": "Qwen2 — это LLM нового поколения от Alibaba с высокой производительностью в различных сценариях использования.",
  "qwen2:1.5b.description": "Qwen2 — это LLM нового поколения от Alibaba с высокой производительностью в различных сценариях использования.",
  "qwen2:72b.description": "Qwen2 — это LLM нового поколения от Alibaba с высокой производительностью в различных сценариях использования.",
  "qwen3-0.6b.description": "Qwen3 0.6B — начальная модель для простых рассуждений и ограниченных сред.",
  "qwen3-1.7b.description": "Qwen3 1.7B — ультралегкая модель для развертывания на устройствах и периферии.",
  "qwen3-14b.description": "Qwen3 14B — модель среднего размера для многоязычного ответа на вопросы и генерации текста.",
  "qwen3-235b-a22b-instruct-2507.description": "Qwen3 235B A22B Instruct 2507 — флагманская инструкционная модель для широкого спектра задач генерации и рассуждения.",
  "qwen3-235b-a22b-thinking-2507.description": "Qwen3 235B A22B Thinking 2507 — сверхкрупная модель для сложных задач рассуждения.",
  "qwen3-30b-a3b-instruct-2507.description": "Qwen3 30B A3B Instruct 2507 — инструкционная модель среднего размера для высококачественной генерации и ответов на вопросы.",
  "qwen3-30b-a3b-thinking-2507.description": "Qwen3 30B A3B Thinking 2507 — модель среднего размера для рассуждений, сочетающая точность и эффективность.",
  "qwen3-30b-a3b.description": "Qwen3 30B A3B — универсальная модель среднего размера, сочетающая качество и стоимость.",
  "qwen3-32b.description": "Qwen3 32B подходит для общих задач, требующих более глубокого понимания.",
  "qwen3-4b.description": "Qwen3 4B подходит для небольших и средних приложений и локального вывода.",
  "qwen3-8b.description": "Qwen3 8B — легковесная модель с гибким развертыванием для высоконагруженных задач.",
  "qwen3-coder-30b-a3b-instruct.description": "Открытая модель кода Qwen. Новейшая qwen3-coder-30b-a3b-instruct основана на Qwen3 и обладает мощными возможностями кодирующего агента, использования инструментов и взаимодействия со средой для автономного программирования, с отличной производительностью кода и общей функциональностью.",
  "qwen3-coder-480b-a35b-instruct.description": "Qwen3 Coder 480B A35B Instruct — флагманская модель кода для многоязычного программирования и сложного понимания кода.",
  "qwen3-coder-flash.description": "Модель кода Qwen. Новейшая серия Qwen3-Coder основана на Qwen3 и обладает мощными возможностями кодирующего агента, использования инструментов и взаимодействия со средой для автономного программирования, с отличной производительностью кода и общей функциональностью.",
  "qwen3-coder-plus.description": "Модель кода Qwen. Новейшая серия Qwen3-Coder основана на Qwen3 и обладает мощными возможностями кодирующего агента, использования инструментов и взаимодействия со средой для автономного программирования, с отличной производительностью кода и общей функциональностью.",
  "qwen3-coder:480b.description": "Высокопроизводительная модель от Alibaba с длинным контекстом для задач агентов и программирования.",
  "qwen3-max-preview.description": "Лучшая модель Qwen для сложных многошаговых задач. Превью-версия поддерживает рассуждение.",
  "qwen3-max.description": "Модели Qwen3 Max значительно превосходят серию 2.5 по общим возможностям, пониманию китайского и английского языков, следованию сложным инструкциям, выполнению открытых задач, многоязычности и использованию инструментов, с меньшим количеством галлюцинаций. Последняя версия qwen3-max улучшает программирование агентов и использование инструментов по сравнению с qwen3-max-preview. Эта версия достигает SOTA в своей области и ориентирована на более сложные потребности агентов.",
  "qwen3-next-80b-a3b-instruct.description": "Модель следующего поколения Qwen3 без рассуждений с открытым исходным кодом. По сравнению с предыдущей версией (Qwen3-235B-A22B-Instruct-2507), улучшено понимание китайского языка, логическое мышление и генерация текста.",
  "qwen3-next-80b-a3b-thinking.description": "Qwen3 Next 80B A3B Thinking — флагманская версия модели рассуждений для сложных задач.",
  "qwen3-omni-flash.description": "Qwen-Omni принимает комбинированные входные данные (текст, изображения, аудио, видео) и выдает текст или речь. Поддерживает различные естественные голоса, многоязычную и диалектную речь, подходит для задач письма, распознавания изображений и голосовых помощников.",
  "qwen3-vl-235b-a22b-instruct.description": "Qwen3 VL 235B A22B Instruct — флагманская мультимодальная модель для сложного понимания и генерации.",
  "qwen3-vl-235b-a22b-thinking.description": "Qwen3 VL 235B A22B Thinking — флагманская версия для сложного мультимодального рассуждения и планирования.",
  "qwen3-vl-30b-a3b-instruct.description": "Qwen3 VL 30B A3B Instruct — крупная мультимодальная модель, сочетающая точность и производительность рассуждений.",
  "qwen3-vl-30b-a3b-thinking.description": "Qwen3 VL 30B A3B Thinking — версия с глубоким мышлением для сложных мультимодальных задач.",
  "qwen3-vl-32b-instruct.description": "Qwen3 VL 32B Instruct — мультимодальная модель, обученная следованию инструкциям, для высококачественного визуально-текстового QA и генерации.",
  "qwen3-vl-32b-thinking.description": "Qwen3 VL 32B Thinking — мультимодальная версия с глубоким мышлением для сложного рассуждения и анализа длинных цепочек.",
  "qwen3-vl-8b-instruct.description": "Qwen3 VL 8B Instruct — легковесная мультимодальная модель для повседневного визуального QA и интеграции в приложения.",
  "qwen3-vl-8b-thinking.description": "Qwen3 VL 8B Thinking — мультимодальная модель с цепочкой рассуждений для детального визуального анализа.",
  "qwen3-vl-flash.description": "Qwen3 VL Flash: легковесная, высокоскоростная версия рассуждений для задач с низкой задержкой или высоким объемом запросов.",
  "qwen3-vl-plus.description": "Qwen VL — модель генерации текста с пониманием изображений. Поддерживает OCR, а также умеет обобщать и рассуждать, например, извлекать атрибуты с фото товаров или решать задачи по изображениям.",
  "qwen3.description": "Qwen3 — это LLM нового поколения от Alibaba с высокой производительностью в различных сценариях использования.",
  "taichu_o1.description": "taichu_o1 — это модель нового поколения для рассуждений, использующая мультимодальное взаимодействие и обучение с подкреплением для достижения человекоподобного хода мыслей. Она поддерживает моделирование сложных решений, демонстрирует логические цепочки и обеспечивает высокую точность, идеально подходя для стратегического анализа и глубокого мышления.",
  "taichu_vl.description": "Объединяет понимание изображений, перенос знаний и логическую атрибуцию, превосходно справляясь с задачами вопрос-ответ по изображению и тексту.",
  "tencent/Hunyuan-A13B-Instruct.description": "Hunyuan-A13B-Instruct использует 80 миллиардов параметров, из которых активно 13 миллиардов, обеспечивая производительность, сопоставимую с более крупными моделями. Поддерживает гибридное быстрое/медленное рассуждение, стабильное понимание длинных текстов и лидирующие возможности агентов на BFCL-v3 и τ-Bench. Поддержка GQA и мульти-квантованных форматов обеспечивает эффективный вывод.",
  "tencent/Hunyuan-MT-7B.description": "Модель перевода Hunyuan включает Hunyuan-MT-7B и ансамбль Hunyuan-MT-Chimera. Hunyuan-MT-7B — это легковесная модель на 7 миллиардов параметров, поддерживающая 33 языка и 5 языков китайских меньшинств. На WMT25 заняла первое место в 30 из 31 языковой пары. Tencent Hunyuan использует полный цикл обучения от предобучения до SFT, RL для перевода и ансамблевого RL, достигая выдающейся производительности при компактных размерах и легкости развертывания.",
  "text-embedding-3-large.description": "Самая мощная модель встраивания для задач на английском и других языках.",
  "text-embedding-3-small.description": "Эффективная и экономичная модель встраивания нового поколения для поиска и RAG-сценариев.",
  "thudm/glm-4-32b.description": "GLM-4-32B-0414 — это 32-миллиардная билингвальная модель (китайский/английский) с открытым доступом к весам, оптимизированная для генерации кода, вызова функций и задач агентов. Предобучена на 15Т высококачественных данных с акцентом на рассуждение и дополнительно дообучена с учетом предпочтений человека, выборочного отклонения и RL. Отличается выдающимися способностями к сложным рассуждениям, генерации артефактов и структурированному выводу, достигая уровня GPT-4o и DeepSeek-V3-0324 на множестве бенчмарков.",
  "thudm/glm-4-32b:free.description": "GLM-4-32B-0414 — это 32-миллиардная билингвальная модель (китайский/английский) с открытым доступом к весам, оптимизированная для генерации кода, вызова функций и задач агентов. Предобучена на 15Т высококачественных данных с акцентом на рассуждение и дополнительно дообучена с учетом предпочтений человека, выборочного отклонения и RL. Отличается выдающимися способностями к сложным рассуждениям, генерации артефактов и структурированному выводу, достигая уровня GPT-4o и DeepSeek-V3-0324 на множестве бенчмарков.",
  "thudm/glm-4-9b-chat.description": "Открытая версия последней предобученной модели GLM-4 от Zhipu AI.",
  "thudm/glm-z1-32b.description": "GLM-Z1-32B-0414 — это усовершенствованный вариант GLM-4-32B, ориентированный на глубокие математические, логические и кодовые задачи. Использует расширенное RL (специфические для задач и общие парные предпочтения) для улучшения многозадачных рассуждений. По сравнению с GLM-4-32B, Z1 значительно улучшает структурированное мышление и способности в формальных областях.\n\nПоддерживает принудительные «шаги размышлений» через инженерные подсказки, повышенную связность длинных ответов и оптимизирован для агентных рабочих процессов с длинным контекстом (через YaRN), вызов инструментов в формате JSON и тонкую выборку для стабильного рассуждения. Идеален для задач, требующих аккуратных многошаговых или формальных выводов.",
  "thudm/glm-z1-rumination-32b.description": "GLM Z1 Rumination 32B — это 32-миллиардная модель глубокого рассуждения из серии GLM-4-Z1, оптимизированная для сложных открытых задач, требующих длительного размышления. Построена на базе glm-4-32b-0414, включает дополнительные этапы RL и многоступенчатое выравнивание, вводя способность «размышления», имитирующую расширенную когнитивную обработку. Это включает итеративное рассуждение, многошаговый анализ и рабочие процессы с использованием инструментов, таких как поиск, извлечение и синтез с учетом цитирования.\n\nОтлично подходит для научного письма, сравнительного анализа и сложных вопросов. Поддерживает вызов функций для примитивов поиска/навигации (`search`, `click`, `open`, `finish`) в агентных пайплайнах. Поведение размышления управляется многоцикловыми петлями с формированием наград на основе правил и механизмами отложенных решений, протестировано на глубоких исследовательских фреймворках, таких как внутренняя стек-выравнивание OpenAI. Этот вариант ориентирован на глубину, а не на скорость.",
  "tngtech/deepseek-r1t-chimera:free.description": "DeepSeek-R1T-Chimera создан путем объединения DeepSeek-R1 и DeepSeek-V3 (0324), сочетая рассуждение R1 с эффективностью токенов V3. Основан на трансформере DeepSeek-MoE и оптимизирован для генерации общего текста.\n\nОбъединяет предобученные веса для баланса между рассуждением, эффективностью и следованием инструкциям. Выпущен под лицензией MIT для исследовательского и коммерческого использования.",
  "togethercomputer/StripedHyena-Nous-7B.description": "StripedHyena Nous (7B) обеспечивает повышенную вычислительную эффективность благодаря своей архитектуре и стратегии.",
  "tts-1-hd.description": "Последняя модель синтеза речи, оптимизированная для качества.",
  "tts-1.description": "Последняя модель синтеза речи, оптимизированная для скорости в реальном времени.",
  "upstage/SOLAR-10.7B-Instruct-v1.0.description": "Upstage SOLAR Instruct v1 (11B) настроена для точного выполнения инструкций с высокой языковой производительностью.",
  "us.anthropic.claude-3-5-sonnet-20241022-v2:0.description": "Claude 3.5 Sonnet поднимает отраслевой стандарт, превосходя конкурентов и Claude 3 Opus по широкому спектру оценок, сохраняя при этом средний уровень скорости и стоимости.",
  "v0-1.0-md.description": "v0-1.0-md — устаревшая модель, доступная через API v0.",
  "v0-1.5-lg.description": "v0-1.5-lg подходит для задач, требующих продвинутого мышления и рассуждений.",
  "v0-1.5-md.description": "v0-1.5-md подходит для повседневных задач и генерации пользовательских интерфейсов.",
  "vercel/v0-1.0-md.description": "Доступ к моделям v0 для генерации, исправления и оптимизации современных веб-приложений с учетом особенностей фреймворков и актуальных знаний.",
  "vercel/v0-1.5-md.description": "Доступ к моделям v0 для генерации, исправления и оптимизации современных веб-приложений с учетом особенностей фреймворков и актуальных знаний.",
  "volcengine/doubao-seed-code.description": "Doubao-Seed-Code — это LLM от ByteDance Volcano Engine, оптимизированная для агентного программирования, демонстрирующая высокие результаты на бенчмарках программирования и агентов с поддержкой контекста до 256K.",
  "wan2.2-t2i-flash.description": "Wanxiang 2.2 Speed — последняя модель с улучшениями в креативности, стабильности и реалистичности, обеспечивающая быструю генерацию и высокую ценность.",
  "wan2.2-t2i-plus.description": "Wanxiang 2.2 Pro — последняя модель с улучшениями в креативности, стабильности и реалистичности, создающая более детализированные изображения.",
  "wanx-v1.description": "Базовая модель преобразования текста в изображение. Соответствует Tongyi Wanxiang 1.0 General.",
  "wanx2.0-t2i-turbo.description": "Отличается текстурированными портретами при умеренной скорости и низкой стоимости. Соответствует Tongyi Wanxiang 2.0 Speed.",
  "wanx2.1-t2i-plus.description": "Полностью обновленная версия с более богатыми деталями изображения и немного меньшей скоростью. Соответствует Tongyi Wanxiang 2.1 Pro.",
  "wanx2.1-t2i-turbo.description": "Полностью обновленная версия с быстрой генерацией, высоким общим качеством и отличной ценностью. Соответствует Tongyi Wanxiang 2.1 Speed.",
  "whisper-1.description": "Универсальная модель распознавания речи с поддержкой многоязычного ASR, перевода речи и определения языка.",
  "wizardlm2.description": "WizardLM 2 — языковая модель от Microsoft AI, превосходно справляющаяся со сложными диалогами, многоязычными задачами, рассуждениями и помощниками.",
  "wizardlm2:8x22b.description": "WizardLM 2 — языковая модель от Microsoft AI, превосходно справляющаяся со сложными диалогами, многоязычными задачами, рассуждениями и помощниками.",
  "x-ai/grok-4-fast-non-reasoning.description": "Grok 4 Fast (без рассуждений) — это высокопроизводительная, недорогая мультимодальная модель от xAI (поддерживает контекст до 2M), предназначенная для сценариев, чувствительных к задержке и стоимости, не требующих встроенного рассуждения. Рассуждение можно включить через параметр reasoning в API. Подсказки и ответы могут использоваться xAI или OpenRouter для улучшения будущих моделей.",
  "x-ai/grok-4-fast.description": "Grok 4 Fast — это высокопроизводительная, недорогая модель от xAI (поддерживает контекст до 2M), идеально подходящая для сценариев с высокой конкуренцией и длинным контекстом.",
  "x-ai/grok-4.1-fast-non-reasoning.description": "Grok 4 Fast (без рассуждений) — это высокопроизводительная, недорогая мультимодальная модель от xAI (поддерживает контекст до 2M), предназначенная для сценариев, чувствительных к задержке и стоимости, не требующих встроенного рассуждения. Рассуждение можно включить через параметр reasoning в API. Подсказки и ответы могут использоваться xAI или OpenRouter для улучшения будущих моделей.",
  "x-ai/grok-4.1-fast.description": "Grok 4 Fast — это высокопроизводительная, недорогая модель от xAI (поддерживает контекст до 2M), идеально подходящая для сценариев с высокой конкуренцией и длинным контекстом.",
  "x-ai/grok-4.description": "Grok 4 — флагманская модель xAI с мощными возможностями рассуждения и мультимодальности.",
  "x-ai/grok-code-fast-1.description": "Grok Code Fast 1 — быстрая модель программирования от xAI с читаемым и удобным для инженеров выводом.",
  "xai/grok-2-vision.description": "Grok 2 Vision превосходно справляется с визуальными задачами, демонстрируя передовые результаты в визуальном математическом рассуждении (MathVista) и вопросах по документам (DocVQA). Обрабатывает документы, диаграммы, графики, скриншоты и фотографии.",
  "xai/grok-2.description": "Grok 2 — передовая модель с передовыми возможностями рассуждения, чата и программирования, превосходящая Claude 3.5 Sonnet и GPT-4 Turbo по LMSYS.",
  "xai/grok-3-fast.description": "Флагманская модель xAI, превосходно подходящая для корпоративных задач, таких как извлечение данных, программирование и суммирование, с глубокими знаниями в области финансов, здравоохранения, права и науки. Быстрая версия работает на ускоренной инфраструктуре для более быстрых ответов при более высокой стоимости за токен.",
  "xai/grok-3-mini-fast.description": "Легковесная модель xAI, которая «думает» перед ответом, идеально подходит для простых или логических задач без необходимости в глубоких знаниях. Доступны необработанные следы рассуждений. Быстрая версия работает на ускоренной инфраструктуре для более быстрых ответов при более высокой стоимости за токен.",
  "xai/grok-3-mini.description": "Легковесная модель xAI, которая «думает» перед ответом, идеально подходит для простых или логических задач без необходимости в глубоких знаниях. Доступны необработанные следы рассуждений.",
  "xai/grok-3.description": "Флагманская модель xAI, превосходно подходящая для корпоративных задач, таких как извлечение данных, программирование и суммирование, с глубокими знаниями в области финансов, здравоохранения, права и науки.",
  "xai/grok-4.description": "Новейшая флагманская модель xAI с непревзойденной производительностью в области естественного языка, математики и рассуждений — универсальный лидер.",
  "yi-large-fc.description": "Построена на базе yi-large с расширенными возможностями вызова инструментов, подходит для сценариев агентов и рабочих процессов.",
  "yi-large-preview.description": "Ранняя версия; рекомендуется использовать более новую yi-large.",
  "yi-large-rag.description": "Продвинутая служба на базе yi-large, объединяющая поиск и генерацию для точных ответов с поддержкой веб-поиска в реальном времени.",
  "yi-large-turbo.description": "Исключительное соотношение цены и качества, настроено для оптимального баланса между качеством, скоростью и стоимостью.",
  "yi-large.description": "Новая модель с 100 миллиардами параметров, обладающая сильными возможностями в вопросах и генерации текста.",
  "yi-lightning-lite.description": "Облегченная версия; рекомендуется использовать yi-lightning.",
  "yi-lightning.description": "Новая высокопроизводительная модель с быстрой генерацией и высоким качеством вывода.",
  "yi-medium-200k.description": "Модель с длинным контекстом (200K) для глубокого понимания и генерации длинных текстов.",
  "yi-medium.description": "Настроенная модель среднего размера с балансом возможностей и стоимости, оптимизирована для следования инструкциям.",
  "yi-spark.description": "Компактная и быстрая модель с усиленными возможностями в математике и программировании.",
  "yi-vision-v2.description": "Модель компьютерного зрения для сложных задач с мощным пониманием и анализом нескольких изображений.",
  "yi-vision.description": "Модель компьютерного зрения для сложных задач с мощным пониманием изображений и анализом.",
  "z-ai/glm-4.5-air.description": "GLM 4.5 Air — легковесный вариант GLM 4.5 для сценариев с ограниченным бюджетом, при этом сохраняет сильные способности к рассуждению.",
  "z-ai/glm-4.5.description": "GLM 4.5 — флагманская модель Z.AI с гибридным рассуждением, оптимизированная для инженерных задач и задач с длинным контекстом.",
  "z-ai/glm-4.6.description": "GLM 4.6 — флагманская модель Z.AI с расширенной длиной контекста и улучшенными возможностями программирования.",
  "zai-org/GLM-4.5-Air.description": "GLM-4.5-Air — базовая модель для агентных приложений с архитектурой Mixture-of-Experts. Оптимизирована для использования инструментов, веб-браузинга, программной инженерии и фронтенд-разработки, интегрируется с агентами кода, такими как Claude Code и Roo Code. Использует гибридное рассуждение для решения как сложных, так и повседневных задач.",
  "zai-org/GLM-4.5.description": "GLM-4.5 — базовая модель, созданная для агентных приложений с архитектурой Mixture-of-Experts. Глубоко оптимизирована для использования инструментов, веб-браузинга, программной инженерии и фронтенд-разработки, интегрируется с агентами кода, такими как Claude Code и Roo Code. Использует гибридное рассуждение для решения как сложных, так и повседневных задач.",
  "zai-org/GLM-4.5V.description": "GLM-4.5V — последняя мультимодальная модель Zhipu AI, построенная на флагманской текстовой модели GLM-4.5-Air (106B всего, 12B активно) с архитектурой MoE для высокой производительности при низкой стоимости. Следует пути GLM-4.1V-Thinking и добавляет 3D-RoPE для улучшения пространственного 3D-рассуждения. Оптимизирована через предобучение, SFT и RL, обрабатывает изображения, видео и длинные документы, занимает лидирующие позиции среди открытых моделей на 41 мультимодальном бенчмарке. Переключатель Thinking mode позволяет пользователям выбирать между скоростью и глубиной.",
  "zai-org/GLM-4.6.description": "По сравнению с GLM-4.5, GLM-4.6 расширяет контекст с 128K до 200K для более сложных агентных задач. Получает более высокие оценки на бенчмарках кода и демонстрирует лучшую производительность в реальных приложениях, таких как Claude Code, Cline, Roo Code и Kilo Code, включая улучшенную генерацию фронтенд-страниц. Улучшено рассуждение и поддержка инструментов во время рассуждения, что усиливает общие возможности. Лучше интегрируется в агентные фреймворки, улучшает агентов поиска/инструментов и обладает более естественным стилем письма и ролевой игрой, предпочтительным для человека.",
  "zai/glm-4.5-air.description": "GLM-4.5 и GLM-4.5-Air — наши последние флагманские модели для агентных приложений, обе используют MoE. GLM-4.5 имеет 355B параметров всего и 32B активно на проход; GLM-4.5-Air — более легкая версия с 106B всего и 12B активно.",
  "zai/glm-4.5.description": "Серия GLM-4.5 разработана для агентов. Флагманская модель GLM-4.5 сочетает рассуждение, программирование и агентные навыки с 355B параметров (32B активно) и предлагает два режима работы как гибридная система рассуждения.",
  "zai/glm-4.5v.description": "GLM-4.5V построена на базе GLM-4.5-Air, унаследовав проверенные техники GLM-4.1V-Thinking и масштабируясь с мощной архитектурой MoE на 106B параметров.",
  "zenmux/auto.description": "ZenMux auto-routing автоматически выбирает наиболее выгодную и производительную модель из поддерживаемых вариантов на основе вашего запроса."
}
