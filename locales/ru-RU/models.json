{
  "01-ai/yi-1.5-34b-chat.description": "Последняя открытая модель 01.AI с 34 миллиардами параметров, адаптированная для различных сценариев диалога, обученная на высококачественных данных и согласованная с человеческими предпочтениями.",
  "01-ai/yi-1.5-9b-chat.description": "Последняя открытая модель 01.AI с 9 миллиардами параметров, адаптированная для различных сценариев диалога, обученная на высококачественных данных и согласованная с человеческими предпочтениями.",
  "360/deepseek-r1.description": "DeepSeek-R1, развернутая компанией 360, использует масштабное обучение с подкреплением на этапе дообучения, значительно улучшая логическое мышление при минимальной разметке. Сопоставима с OpenAI o1 в задачах по математике, программированию и языковому рассуждению.",
  "360gpt-pro-trans.description": "Специализированная модель для перевода, глубоко дообученная для достижения передового качества перевода.",
  "360gpt-pro.description": "360GPT Pro — ключевая модель ИИ от 360 с эффективной обработкой текста для различных задач обработки естественного языка, поддерживает понимание длинных текстов и многотуровой диалог.",
  "360gpt-turbo-responsibility-8k.description": "360GPT Turbo Responsibility 8K делает акцент на семантической безопасности и ответственности в чувствительных к контенту приложениях, обеспечивая точный и надежный пользовательский опыт.",
  "360gpt-turbo.description": "360GPT Turbo обеспечивает высокую вычислительную и диалоговую производительность с отличным пониманием семантики и эффективной генерацией, идеально подходит для бизнеса и разработчиков.",
  "360gpt2-o1.description": "360gpt2-o1 формирует цепочку рассуждений с помощью древовидного поиска, механизма рефлексии и обучения с подкреплением, позволяя модели к саморефлексии и самокоррекции.",
  "360gpt2-pro.description": "360GPT2 Pro — продвинутая модель обработки естественного языка от 360 с выдающимися возможностями генерации и понимания текста, особенно в творческих задачах, включая сложные преобразования и ролевые сценарии.",
  "360zhinao2-o1.description": "360zhinao2-o1 формирует цепочку рассуждений с помощью древовидного поиска, механизма рефлексии и обучения с подкреплением, позволяя модели к саморефлексии и самокоррекции.",
  "4.0Ultra.description": "Spark Ultra — самая мощная модель в серии Spark, улучшает понимание текста и его резюмирование, а также расширяет возможности веб-поиска. Это комплексное решение для повышения продуктивности на рабочем месте и точности ответов, позиционирующееся как передовой интеллектуальный продукт.",
  "AnimeSharp.description": "AnimeSharp (также известная как \"4x-AnimeSharp\") — это открытая модель суперразрешения на основе ESRGAN от Kim2091, предназначенная для увеличения и повышения резкости изображений в аниме-стиле. В феврале 2022 года была переименована из \"4x-TextSharpV1\"; изначально также предназначалась для текстовых изображений, но была глубоко оптимизирована под аниме-контент.",
  "Baichuan2-Turbo.description": "Использует расширение поиска для подключения модели к отраслевым и веб-знаниям. Поддерживает загрузку PDF/Word и ввод URL для своевременного, всестороннего поиска и профессионального, точного вывода.",
  "Baichuan3-Turbo-128k.description": "С ультрадлинным контекстным окном на 128K, оптимизирована для частых корпоративных сценариев с существенным приростом ценности. По сравнению с Baichuan2, генерация контента улучшена на 20%, ответы на вопросы — на 17%, ролевые сценарии — на 40%. Общая производительность выше, чем у GPT-3.5.",
  "Baichuan3-Turbo.description": "Оптимизирована для частых корпоративных сценариев с существенным приростом ценности. По сравнению с Baichuan2, генерация контента улучшена на 20%, ответы на вопросы — на 17%, ролевые сценарии — на 40%. Общая производительность выше, чем у GPT-3.5.",
  "Baichuan4-Air.description": "Одна из лучших моделей в Китае, превосходит ведущие зарубежные модели в задачах на китайском языке, таких как энциклопедические знания, длинные тексты и творческая генерация. Также обладает передовыми мультимодальными возможностями с высокими результатами на авторитетных бенчмарках.",
  "Baichuan4-Turbo.description": "Одна из лучших моделей в Китае, превосходит ведущие зарубежные модели в задачах на китайском языке, таких как энциклопедические знания, длинные тексты и творческая генерация. Также обладает передовыми мультимодальными возможностями с высокими результатами на авторитетных бенчмарках.",
  "Baichuan4.description": "Лидер по производительности среди отечественных моделей, превосходит ведущие зарубежные модели в задачах на китайском языке, таких как энциклопедические знания, длинные тексты и творческая генерация. Также предлагает передовые мультимодальные возможности и высокие результаты на бенчмарках.",
  "ByteDance-Seed/Seed-OSS-36B-Instruct.description": "Seed-OSS — семейство открытых LLM от ByteDance Seed, разработанных для обработки длинного контекста, логического мышления, агентных задач и общих способностей. Seed-OSS-36B-Instruct — это модель с 36 миллиардами параметров, адаптированная под инструкции, с нативной поддержкой ультрадлинного контекста для обработки больших документов или кодовых баз. Оптимизирована для логики, генерации кода и агентных задач (использование инструментов), сохраняя при этом общую универсальность. Ключевая особенность — \"Бюджет мышления\", позволяющий гибко управлять длиной рассуждений для повышения эффективности.",
  "DeepSeek-R1-Distill-Llama-70B.description": "DeepSeek R1, более крупная и умная модель из набора DeepSeek, дистиллирована в архитектуру Llama 70B. Бенчмарки и оценки людей показывают, что она умнее базовой Llama 70B, особенно в задачах по математике и точности фактов.",
  "DeepSeek-R1-Distill-Qwen-1.5B.description": "Дистиллированная модель DeepSeek-R1 на основе Qwen2.5-Math-1.5B. Обучение с подкреплением и данные холодного старта оптимизируют производительность в логических задачах, устанавливая новые мультизадачные бенчмарки среди открытых моделей.",
  "DeepSeek-R1-Distill-Qwen-14B.description": "Модели DeepSeek-R1-Distill дообучены на основе открытых моделей с использованием выборок, сгенерированных DeepSeek-R1.",
  "DeepSeek-R1-Distill-Qwen-32B.description": "Модели DeepSeek-R1-Distill дообучены на основе открытых моделей с использованием выборок, сгенерированных DeepSeek-R1.",
  "DeepSeek-R1-Distill-Qwen-7B.description": "Дистиллированная модель DeepSeek-R1 на основе Qwen2.5-Math-7B. Обучение с подкреплением и данные холодного старта оптимизируют производительность в логических задачах, устанавливая новые мультизадачные бенчмарки среди открытых моделей.",
  "DeepSeek-R1.description": "DeepSeek-R1 применяет масштабное обучение с подкреплением на этапе дообучения, значительно улучшая логическое мышление при минимальной разметке. Сопоставима с OpenAI o1 в задачах по математике, программированию и языковому рассуждению.",
  "DeepSeek-V3-1.description": "DeepSeek V3.1 — модель нового поколения для логических задач с улучшенными возможностями сложного рассуждения и цепочек размышлений, подходящая для глубокого анализа.",
  "DeepSeek-V3-Fast.description": "Провайдер: sophnet. DeepSeek V3 Fast — высокоэффективная версия DeepSeek V3 0324, с полной точностью (без квантования), улучшенной производительностью в коде и математике и более быстрыми ответами.",
  "DeepSeek-V3.1-Fast.description": "DeepSeek V3.1 Fast — высокоэффективный вариант DeepSeek V3.1. Гибридный режим мышления: через шаблоны чата одна модель поддерживает как мышление, так и немышление. Умное использование инструментов: дообучение улучшает производительность в агентных задачах и при использовании инструментов.",
  "DeepSeek-V3.1-Think.description": "Режим мышления DeepSeek-V3.1: новая гибридная модель рассуждения с режимами мышления и немышления, более эффективная, чем DeepSeek-R1-0528. Оптимизации после обучения значительно улучшают использование инструментов и выполнение агентных задач.",
  "DeepSeek-V3.description": "DeepSeek-V3 — модель MoE, разработанная DeepSeek. Превосходит другие открытые модели, такие как Qwen2.5-72B и Llama-3.1-405B, по многим бенчмаркам и конкурирует с ведущими закрытыми моделями, такими как GPT-4o и Claude 3.5 Sonnet.",
  "Doubao-lite-128k.description": "Doubao-lite обеспечивает сверхбыстрые ответы и отличное соотношение цены и качества, предлагая гибкие варианты для различных сценариев. Поддерживает контекст объемом 128K для вывода и дообучения.",
  "Doubao-lite-32k.description": "Doubao-lite обеспечивает сверхбыстрые ответы и отличное соотношение цены и качества, предлагая гибкие варианты для различных сценариев. Поддерживает контекст объемом 32K для вывода и дообучения.",
  "Doubao-lite-4k.description": "Doubao-lite обеспечивает сверхбыстрые ответы и отличное соотношение цены и качества, предлагая гибкие варианты для различных сценариев. Поддерживает контекст объемом 4K для вывода и дообучения.",
  "Doubao-pro-128k.description": "Флагманская модель с наилучшей производительностью для сложных задач, превосходно справляется с вопросно-ответными задачами, суммированием, созданием контента, классификацией и ролевыми сценариями. Поддерживает контекст объемом 128K для вывода и дообучения.",
  "Doubao-pro-32k.description": "Флагманская модель с наилучшей производительностью для сложных задач, превосходно справляется с вопросно-ответными задачами, суммированием, созданием контента, классификацией и ролевыми сценариями. Поддерживает контекст объемом 32K для вывода и дообучения.",
  "Doubao-pro-4k.description": "Флагманская модель с наилучшей производительностью для сложных задач, превосходно справляется с вопросно-ответными задачами, суммированием, созданием контента, классификацией и ролевыми сценариями. Поддерживает контекст объемом 4K для вывода и дообучения.",
  "DreamO.description": "DreamO — это модель для настройки изображений с открытым исходным кодом, совместно разработанная ByteDance и Пекинским университетом. Она использует единую архитектуру для поддержки многозадачной генерации изображений. Благодаря эффективному композиционному моделированию DreamO создает высоко согласованные и персонализированные изображения на основе заданных пользователем параметров, таких как личность, объект, стиль, фон и другие условия.",
  "ERNIE-3.5-128K.description": "Флагманская LLM-модель от Baidu, обученная на обширных корпусах китайского и английского языков, обладающая высокой универсальностью для чата, создания контента и использования плагинов. Поддерживает автоматическую интеграцию плагина Baidu Search для получения актуальных ответов.",
  "ERNIE-3.5-8K-Preview.description": "Флагманская LLM-модель от Baidu, обученная на обширных корпусах китайского и английского языков, обладающая высокой универсальностью для чата, создания контента и использования плагинов. Поддерживает автоматическую интеграцию плагина Baidu Search для получения актуальных ответов.",
  "ERNIE-3.5-8K.description": "Флагманская LLM-модель от Baidu, обученная на обширных корпусах китайского и английского языков, обладающая высокой универсальностью для чата, создания контента и использования плагинов. Поддерживает автоматическую интеграцию плагина Baidu Search для получения актуальных ответов.",
  "ERNIE-4.0-8K-Latest.description": "Флагманская сверхмощная LLM-модель от Baidu с комплексными улучшениями по сравнению с ERNIE 3.5, подходящая для сложных задач в различных областях. Поддерживает интеграцию плагина Baidu Search для получения актуальных ответов.",
  "ERNIE-4.0-8K-Preview.description": "Флагманская сверхмощная LLM-модель от Baidu с комплексными улучшениями по сравнению с ERNIE 3.5, подходящая для сложных задач в различных областях. Поддерживает интеграцию плагина Baidu Search для получения актуальных ответов.",
  "ERNIE-4.0-Turbo-8K-Latest.description": "Флагманская сверхмощная LLM-модель от Baidu с высокой общей производительностью для сложных задач. Поддерживает интеграцию плагина Baidu Search для получения актуальных ответов. Превосходит ERNIE 4.0.",
  "ERNIE-4.0-Turbo-8K-Preview.description": "Флагманская сверхмощная LLM-модель от Baidu с высокой общей производительностью для сложных задач. Поддерживает интеграцию плагина Baidu Search для получения актуальных ответов. Превосходит ERNIE 4.0.",
  "ERNIE-Character-8K.description": "Отраслевая LLM-модель от Baidu для игровых NPC, клиентской поддержки и ролевых сценариев. Обеспечивает более четкое соответствие персонажу, лучшее следование инструкциям и улучшенное логическое мышление.",
  "ERNIE-Lite-Pro-128K.description": "Легковесная LLM-модель от Baidu, сочетающая качество и производительность вывода. Превосходит ERNIE Lite и подходит для ускорителей с низким уровнем вычислений.",
  "ERNIE-Speed-128K.description": "Последняя высокопроизводительная LLM-модель от Baidu (2024), обладающая сильными универсальными способностями. Подходит в качестве основы для дообучения под конкретные сценарии, с отличной логикой рассуждений.",
  "ERNIE-Speed-Pro-128K.description": "Последняя высокопроизводительная LLM-модель от Baidu (2024), обладающая сильными универсальными способностями. Превосходит ERNIE Speed и подходит в качестве основы для дообучения с отличной логикой рассуждений.",
  "FLUX-1.1-pro.description": "FLUX.1.1 Pro",
  "FLUX.1-Kontext-dev.description": "FLUX.1-Kontext-dev — это мультимодальная модель генерации и редактирования изображений от Black Forest Labs, основанная на архитектуре Rectified Flow Transformer с 12 миллиардами параметров. Она предназначена для генерации, реконструкции, улучшения и редактирования изображений в заданных контекстных условиях. Модель сочетает управляемую генерацию диффузионных моделей с контекстным моделированием Transformer, обеспечивая высококачественные результаты для задач, таких как дорисовка, расширение изображения и реконструкция визуальных сцен.",
  "FLUX.1-Kontext-pro.description": "FLUX.1 Kontext [pro]",
  "FLUX.1-dev.description": "FLUX.1-dev — это мультимодальная языковая модель с открытым исходным кодом (MLLM) от Black Forest Labs, оптимизированная для задач, связанных с изображениями и текстом. Она объединяет понимание и генерацию изображений/текста. Построена на базе передовых LLM (например, Mistral-7B), использует тщательно разработанный визуальный энкодер и многоступенчатую настройку инструкций для обеспечения мультимодальной координации и сложного логического вывода.",
  "Gryphe/MythoMax-L2-13b.description": "MythoMax-L2 (13B) — инновационная модель для различных областей и сложных задач.",
  "HelloMeme.description": "HelloMeme — это ИИ-инструмент, который создает мемы, GIF-файлы или короткие видео на основе предоставленных вами изображений или движений. Не требует навыков рисования или программирования — достаточно эталонного изображения, чтобы получить веселый, привлекательный и стилистически согласованный контент.",
  "HiDream-I1-Full.description": "HiDream-E1-Full — это мультимодальная модель редактирования изображений с открытым исходным кодом от HiDream.ai, основанная на передовой архитектуре Diffusion Transformer и мощном языковом понимании (встроенная LLaMA 3.1-8B-Instruct). Поддерживает генерацию изображений на основе естественного языка, перенос стиля, локальное редактирование и перерисовку, с отличным пониманием и выполнением задач, связанных с изображениями и текстом.",
  "HunyuanDiT-v1.2-Diffusers-Distilled.description": "hunyuandit-v1.2-distilled — это легковесная модель преобразования текста в изображение, оптимизированная с помощью дистилляции для быстрой генерации высококачественных изображений. Особенно подходит для сред с ограниченными ресурсами и задач в реальном времени.",
  "InstantCharacter.description": "InstantCharacter — это модель персонализированной генерации персонажей без необходимости настройки, выпущенная Tencent AI в 2025 году. Она обеспечивает высокую точность и согласованность персонажей в различных сценариях. Модель может создать персонажа по одному эталонному изображению и гибко переносить его в разные стили, действия и фоны.",
  "InternVL2-8B.description": "InternVL2-8B — это мощная модель визуально-языкового понимания, поддерживающая мультимодальную обработку изображений и текста, точно распознающая содержимое изображений и генерирующая соответствующие описания или ответы.",
  "InternVL2.5-26B.description": "InternVL2.5-26B — это мощная модель визуально-языкового понимания, поддерживающая мультимодальную обработку изображений и текста, точно распознающая содержимое изображений и генерирующая соответствующие описания или ответы.",
  "Kolors.description": "Kolors — это модель преобразования текста в изображение, разработанная командой Kuaishou Kolors. Обученная на миллиардах параметров, она обладает заметными преимуществами в визуальном качестве, понимании китайской семантики и отображении текста.",
  "Kwai-Kolors/Kolors.description": "Kolors — это крупномасштабная латентно-диффузионная модель преобразования текста в изображение от команды Kuaishou Kolors. Обученная на миллиардах пар текст-изображение, она превосходит в визуальном качестве, точности сложной семантики и отображении текста на китайском и английском языках, с сильным пониманием и генерацией китайского контента.",
  "Kwaipilot/KAT-Dev.description": "KAT-Dev (32B) — это модель с открытым исходным кодом для задач программной инженерии. Она достигает 62,4% успешности на SWE-Bench Verified, занимая 5-е место среди открытых моделей. Оптимизирована с помощью промежуточного обучения, SFT и RL для автодополнения кода, исправления ошибок и рецензирования кода.",
  "Llama-3.2-11B-Vision-Instruct.description": "Мощное логическое мышление по изображениям высокого разрешения, подходит для приложений визуального понимания.",
  "Llama-3.2-90B-Vision-Instruct\t.description": "Продвинутое логическое мышление по изображениям для приложений визуального понимания с агентами.",
  "Meta-Llama-3-3-70B-Instruct.description": "Llama 3.3 70B — это универсальная модель Transformer для задач чата и генерации.",
  "Meta-Llama-3.1-405B-Instruct.description": "Llama 3.1 — модель, настроенная на выполнение инструкций, оптимизированная для многоязычного чата, демонстрирующая высокие результаты на отраслевых бенчмарках среди открытых и закрытых моделей.",
  "Meta-Llama-3.1-70B-Instruct.description": "Llama 3.1 — модель, настроенная на выполнение инструкций, оптимизированная для многоязычного чата, демонстрирующая высокие результаты на отраслевых бенчмарках среди открытых и закрытых моделей.",
  "Meta-Llama-3.1-8B-Instruct.description": "Llama 3.1 — модель, настроенная на выполнение инструкций, оптимизированная для многоязычного чата, демонстрирующая высокие результаты на отраслевых бенчмарках среди открытых и закрытых моделей.",
  "Meta-Llama-3.2-1B-Instruct.description": "Передовая компактная языковая модель с высоким уровнем понимания языка, отличной логикой и генерацией текста.",
  "Meta-Llama-3.2-3B-Instruct.description": "Передовая компактная языковая модель с высоким уровнем понимания языка, отличной логикой и генерацией текста.",
  "Meta-Llama-3.3-70B-Instruct.description": "Llama 3.3 — самая продвинутая многоязычная модель Llama с открытым исходным кодом, обеспечивающая производительность, близкую к 405B, при очень низкой стоимости. Основана на архитектуре Transformer и улучшена с помощью SFT и RLHF для повышения полезности и безопасности. Версия, настроенная на выполнение инструкций, оптимизирована для многоязычного чата и превосходит многие открытые и закрытые модели в отраслевых тестах. Дата отсечения знаний: декабрь 2023 года.",
  "Meta-Llama-4-Maverick-17B-128E-Instruct-FP8.description": "Llama 4 Maverick — это крупная модель MoE с эффективной активацией экспертов для высокой производительности в логических задачах.",
  "MiniMax-M1.description": "Новая внутренняя модель рассуждений с поддержкой 80K цепочек размышлений и 1M входных токенов, обеспечивающая производительность на уровне ведущих мировых моделей.",
  "MiniMax-M2-Stable.description": "Создана для эффективного программирования и работы агентов, с повышенной параллельностью для коммерческого использования.",
  "MiniMax-M2.1-Lightning.description": "Мощные возможности многозадачного программирования, полностью обновлённый опыт кодирования. Быстрее и эффективнее.",
  "MiniMax-M2.1.description": "Мощные возможности многозадачного программирования, полностью обновлённый опыт кодирования",
  "MiniMax-M2.description": "Создан для эффективного программирования и рабочих процессов с агентами",
  "MiniMax-Text-01.description": "MiniMax-01 представляет масштабное линейное внимание, выходящее за рамки классических трансформеров, с 456B параметрами и 45.9B активируемыми за проход. Обеспечивает производительность высшего уровня и поддерживает до 4M токенов контекста (в 32 раза больше GPT-4o, в 20 раз больше Claude-3.5-Sonnet).",
  "MiniMaxAI/MiniMax-M1-80k.description": "MiniMax-M1 — это модель рассуждений с открытыми весами, использующая гибридное внимание, с общим числом параметров 456B и ~45.9B активных на токен. Поддерживает 1M контекста и использует Flash Attention для снижения FLOPs на 75% при генерации 100K токенов по сравнению с DeepSeek R1. Благодаря архитектуре MoE, CISPO и обучению с подкреплением на гибридном внимании достигает лидирующих результатов в задачах рассуждения на длинных входах и реальных инженерных задачах.",
  "MiniMaxAI/MiniMax-M2.description": "MiniMax-M2 переопределяет эффективность агентов. Это компактная, быстрая и экономичная модель MoE с 230B общих и 10B активных параметров, созданная для задач программирования и агентов высшего уровня при сохранении сильного общего интеллекта. Имея всего 10B активных параметров, она сопоставима с гораздо более крупными моделями, что делает её идеальной для высокоэффективных приложений.",
  "Moonshot-Kimi-K2-Instruct.description": "1T общих параметров и 32B активных. Среди моделей без размышлений — одна из лучших по знаниям, математике и программированию, а также сильнее в общих задачах агентов. Оптимизирована для рабочих нагрузок агентов: может действовать, а не только отвечать. Идеальна для импровизационного общения, общего чата и агентных сценариев как модель рефлекторного уровня без длительного размышления.",
  "NousResearch/Nous-Hermes-2-Mixtral-8x7B-DPO.description": "Nous Hermes 2 - Mixtral 8x7B-DPO (46.7B) — высокоточная модель инструкций для сложных вычислений.",
  "OmniConsistency.description": "OmniConsistency повышает согласованность стиля и обобщающую способность в задачах преобразования изображений, внедряя масштабные Diffusion Transformers (DiTs) и парные стилизованные данные, предотвращая деградацию стиля.",
  "Phi-3-medium-128k-instruct.description": "Та же модель Phi-3-medium с увеличенным окном контекста для RAG или few-shot подсказок.",
  "Phi-3-medium-4k-instruct.description": "Модель с 14B параметрами, обеспечивающая более высокое качество, чем Phi-3-mini, с акцентом на данные, требующие глубокого рассуждения.",
  "Phi-3-mini-128k-instruct.description": "Та же модель Phi-3-mini с увеличенным окном контекста для RAG или few-shot подсказок.",
  "Phi-3-mini-4k-instruct.description": "Наименьшая модель в семействе Phi-3, оптимизированная для качества и низкой задержки.",
  "Phi-3-small-128k-instruct.description": "Та же модель Phi-3-small с увеличенным окном контекста для RAG или few-shot подсказок.",
  "Phi-3-small-8k-instruct.description": "Модель с 7B параметрами, обеспечивающая более высокое качество, чем Phi-3-mini, с акцентом на данные, требующие глубокого рассуждения.",
  "Phi-3.5-mini-instruct.description": "Обновлённая версия модели Phi-3-mini.",
  "Phi-3.5-vision-instrust.description": "Обновлённая версия модели Phi-3-vision.",
  "Pro/Qwen/Qwen2-7B-Instruct.description": "Qwen2-7B-Instruct — это 7B модель с настройкой на инструкции из серии Qwen2. Использует архитектуру Transformer с SwiGLU, смещением QKV внимания и групповым вниманием по запросу, обрабатывает большие входные данные. Демонстрирует высокие результаты в понимании языка, генерации, многоязычных задачах, программировании, математике и рассуждении, превосходя большинство открытых моделей и конкурируя с закрытыми.",
  "Pro/Qwen/Qwen2.5-7B-Instruct.description": "Qwen2.5-7B-Instruct входит в последнюю серию LLM от Alibaba Cloud. Модель на 7B параметров демонстрирует значительный прогресс в программировании и математике, поддерживает более 29 языков и улучшает следование инструкциям, понимание структурированных данных и структурированный вывод (особенно JSON).",
  "Pro/Qwen/Qwen2.5-Coder-7B-Instruct.description": "Qwen2.5-Coder-7B-Instruct — последняя модель от Alibaba Cloud, ориентированная на программирование. Построена на базе Qwen2.5 и обучена на 5.5T токенов, значительно улучшает генерацию кода, рассуждение и исправление ошибок, сохраняя при этом сильные стороны в математике и общем интеллекте, обеспечивая надёжную основу для кодирующих агентов.",
  "Pro/Qwen/Qwen2.5-VL-7B-Instruct.description": "Qwen2.5-VL — новая модель Qwen для задач зрения и языка с сильным визуальным пониманием. Анализирует текст, графики и макеты на изображениях, понимает длинные видео и события, поддерживает рассуждение и использование инструментов, привязку объектов в разных форматах и структурированный вывод. Улучшает динамическое разрешение и обучение частоте кадров для понимания видео и повышает эффективность визуального энкодера.",
  "Pro/THUDM/GLM-4.1V-9B-Thinking.description": "GLM-4.1V-9B-Thinking — это открытая мультимодальная модель от Zhipu AI и лаборатории KEG Университета Цинхуа, разработанная для сложного мультимодального мышления. Построена на базе GLM-4-9B-0414, добавляет цепочку размышлений и обучение с подкреплением для значительного улучшения межмодального рассуждения и стабильности.",
  "Pro/THUDM/glm-4-9b-chat.description": "GLM-4-9B-Chat — это открытая модель GLM-4 от Zhipu AI. Обеспечивает высокую производительность в семантике, математике, рассуждении, коде и знаниях. Помимо многотурового чата, поддерживает веб-браузинг, выполнение кода, вызов пользовательских инструментов и рассуждение над длинными текстами. Поддерживает 26 языков (включая китайский, английский, японский, корейский, немецкий). Демонстрирует хорошие результаты на AlignBench-v2, MT-Bench, MMLU и C-Eval, поддерживает до 128K контекста для академического и бизнес-применения.",
  "Pro/deepseek-ai/DeepSeek-R1-Distill-Qwen-7B.description": "DeepSeek-R1-Distill-Qwen-7B — это дистиллированная модель на основе Qwen2.5-Math-7B, дообученная на 800K отобранных выборках DeepSeek-R1. Обеспечивает высокую производительность: 92.8% на MATH-500, 55.5% на AIME 2024 и рейтинг 1189 на CodeForces для модели с 7B параметрами.",
  "Pro/deepseek-ai/DeepSeek-R1.description": "DeepSeek-R1 — это модель рассуждений, обученная с использованием обучения с подкреплением, которая снижает повторяемость и повышает читаемость. Использует данные холодного старта до RL для дальнейшего улучшения рассуждений, сопоставима с OpenAI-o1 в задачах математики, программирования и логики, улучшает общие результаты благодаря тщательному обучению.",
  "Pro/deepseek-ai/DeepSeek-V3.1-Terminus.description": "DeepSeek-V3.1-Terminus — обновлённая модель V3.1, позиционируемая как гибридная агентная LLM. Исправляет ошибки, сообщённые пользователями, повышает стабильность, согласованность языка и снижает количество смешанных китайско-английских и аномальных символов. Интегрирует режимы размышления и без размышлений с шаблонами чата для гибкого переключения. Также улучшает производительность агентов кода и поиска для более надёжного использования инструментов и многошаговых задач.",
  "Pro/deepseek-ai/DeepSeek-V3.2-Exp.description": "DeepSeek-V3.2-Exp — экспериментальный выпуск V3.2, переходящий к следующей архитектуре. Добавляет DeepSeek Sparse Attention (DSA) поверх V3.1-Terminus для повышения эффективности обучения и вывода на длинных контекстах, с оптимизациями для использования инструментов, понимания длинных документов и многошагового рассуждения. Идеально подходит для изучения более эффективного рассуждения при больших бюджетах контекста.",
  "Pro/deepseek-ai/DeepSeek-V3.description": "DeepSeek-V3 — это модель MoE с 671B параметрами, использующая MLA и DeepSeekMoE с балансировкой нагрузки без потерь для эффективного вывода и обучения. Предобучена на 14.8T высококачественных токенов и дополнительно дообучена с использованием SFT и RL, превосходит другие открытые модели и приближается к ведущим закрытым моделям.",
  "Pro/moonshotai/Kimi-K2-Instruct-0905.description": "Kimi K2-Instruct-0905 — новейшая и самая мощная версия Kimi K2. Это передовая модель MoE с общим числом параметров 1 трлн и 32 млрд активных. Ключевые особенности включают усиленный агентный интеллект в программировании с заметным улучшением результатов на тестах и в реальных задачах, а также улучшенную эстетику и удобство интерфейсного кода.",
  "Pro/moonshotai/Kimi-K2-Thinking.description": "Kimi K2 Thinking Turbo — это ускоренный вариант, оптимизированный для скорости рассуждений и пропускной способности, при сохранении многошагового мышления и использования инструментов K2 Thinking. Это модель MoE с ~1 трлн параметров, нативной поддержкой контекста 256K и стабильным вызовом инструментов в масштабных производственных сценариях с жёсткими требованиями к задержке и параллельности.",
  "Pro/zai-org/glm-4.7.description": "GLM-4.7 — это флагманская модель нового поколения от Zhipu AI с общим числом параметров 355 миллиардов и 32 миллиардами активных параметров. Она представляет собой всестороннее обновление в области универсального диалога, рассуждений и возможностей интеллектуальных агентов. GLM-4.7 усиливает Interleaved Thinking (перекрёстное мышление), а также вводит концепции Preserved Thinking (сохранённое мышление) и Turn-level Thinking (пошаговое мышление).",
  "QwQ-32B-Preview.description": "Qwen QwQ — это экспериментальная исследовательская модель, направленная на улучшение логического мышления.",
  "Qwen/QVQ-72B-Preview.description": "QVQ-72B-Preview — исследовательская модель от Qwen, ориентированная на визуальное мышление, с сильными сторонами в понимании сложных сцен и решении визуальных математических задач.",
  "Qwen/QwQ-32B-Preview.description": "Qwen QwQ — экспериментальная исследовательская модель, сосредоточенная на улучшении логического мышления ИИ.",
  "Qwen/QwQ-32B.description": "QwQ — модель логического мышления из семейства Qwen. В отличие от стандартных моделей, обученных на инструкциях, она добавляет элементы размышления и логики, что значительно повышает эффективность в сложных задачах. QwQ-32B — модель среднего размера, сопоставимая с лучшими моделями логического мышления, такими как DeepSeek-R1 и o1-mini. Использует RoPE, SwiGLU, RMSNorm и смещение QKV в механизме внимания, имеет 64 слоя и 40 голов внимания (8 KV в GQA).",
  "Qwen/Qwen-Image-Edit-2509.description": "Qwen-Image-Edit-2509 — последняя версия редактора изображений от команды Qwen. Основана на модели Qwen-Image с 20 млрд параметров и расширяет возможности точного редактирования текста в изображениях. Использует архитектуру двойного управления: Qwen2.5-VL для семантического контроля и VAE-энкодер для управления внешним видом, что позволяет редактировать как на уровне смысла, так и визуального оформления. Поддерживает локальные изменения (добавление/удаление/модификация) и высокоуровневые семантические правки, такие как создание IP и перенос стиля, сохраняя при этом смысл. Достигает SOTA-результатов на множестве тестов.",
  "Qwen/Qwen-Image.description": "Qwen-Image — базовая модель генерации изображений с 20 млрд параметров от команды Qwen. Обеспечивает значительный прогресс в сложной визуализации текста и точном редактировании изображений, особенно для китайского и английского языков. Поддерживает многострочные и абзацные макеты с сохранением типографики. Помимо визуализации текста, поддерживает широкий спектр стилей — от фотореализма до аниме, а также продвинутые функции редактирования: перенос стиля, добавление/удаление объектов, улучшение деталей, редактирование текста и управление позой. Стремится стать универсальной основой для визуального творчества.",
  "Qwen/Qwen2-72B-Instruct.description": "Qwen 2 Instruct (72B) обеспечивает точное выполнение инструкций для корпоративных задач.",
  "Qwen/Qwen2-7B-Instruct.description": "Qwen2-7B-Instruct — модель с 7 млрд параметров из серии Qwen2, использующая Transformer, SwiGLU, смещение QKV и групповое внимание. Обрабатывает большие входные данные и демонстрирует высокие результаты в понимании, генерации, многоязычии, программировании, математике и логике, превосходя большинство открытых моделей и Qwen1.5-7B-Chat в ряде тестов.",
  "Qwen/Qwen2-VL-72B-Instruct.description": "Qwen2-VL — последняя модель Qwen-VL, достигшая SOTA на визуальных тестах, таких как MathVista, DocVQA, RealWorldQA и MTVQA. Понимает видео длительностью более 20 минут для задач видео-QA, диалогов и создания контента. Поддерживает сложное логическое мышление и принятие решений, интегрируется с устройствами/роботами для действий, основанных на визуальном восприятии. Помимо английского и китайского, распознаёт текст на большинстве европейских языков, японском, корейском, арабском и вьетнамском.",
  "Qwen/Qwen2.5-14B-Instruct.description": "Qwen2.5-14B-Instruct — часть последней серии LLM от Alibaba Cloud. Модель с 14 млрд параметров демонстрирует значительный прогресс в программировании и математике, поддерживает более 29 языков и улучшает выполнение инструкций, понимание структурированных данных и генерацию структурированного вывода (особенно JSON).",
  "Qwen/Qwen2.5-32B-Instruct.description": "Qwen2.5-32B-Instruct — часть последней серии LLM от Alibaba Cloud. Модель с 32 млрд параметров демонстрирует значительный прогресс в программировании и математике, поддерживает более 29 языков и улучшает выполнение инструкций, понимание структурированных данных и генерацию структурированного вывода (особенно JSON).",
  "Qwen/Qwen2.5-72B-Instruct-128K.description": "Qwen2.5-72B-Instruct — часть последней серии LLM от Alibaba Cloud. Модель с 72 млрд параметров улучшает программирование и математику, поддерживает до 128K входных и более 8K выходных токенов, предлагает поддержку 29+ языков и улучшает выполнение инструкций и структурированный вывод (особенно JSON).",
  "Qwen/Qwen2.5-72B-Instruct-Turbo.description": "Qwen2.5 — новое семейство LLM, оптимизированное для задач в стиле инструкций.",
  "Qwen/Qwen2.5-72B-Instruct.description": "Qwen2.5-72B-Instruct — часть последней серии LLM от Alibaba Cloud. Модель с 72 млрд параметров демонстрирует значительный прогресс в программировании и математике, поддерживает более 29 языков и улучшает выполнение инструкций, понимание структурированных данных и генерацию структурированного вывода (особенно JSON).",
  "Qwen/Qwen2.5-7B-Instruct-Turbo.description": "Qwen2.5 — новое семейство LLM, оптимизированное для задач в стиле инструкций.",
  "Qwen/Qwen2.5-7B-Instruct.description": "Qwen2.5-7B-Instruct — часть последней серии LLM от Alibaba Cloud. Модель с 7 млрд параметров демонстрирует значительный прогресс в программировании и математике, поддерживает более 29 языков и улучшает выполнение инструкций, понимание структурированных данных и генерацию структурированного вывода (особенно JSON).",
  "Qwen/Qwen2.5-Coder-32B-Instruct.description": "Qwen2.5 Coder 32B Instruct — последняя модель от Alibaba Cloud, ориентированная на программирование. Построена на базе Qwen2.5 и обучена на 5.5 трлн токенов, значительно улучшает генерацию кода, логическое мышление и исправление ошибок, сохраняя при этом сильные стороны в математике и общем понимании, обеспечивая надёжную основу для кодирующих агентов.",
  "Qwen/Qwen2.5-Coder-7B-Instruct.description": "Qwen2.5-Coder-7B-Instruct — последняя модель от Alibaba Cloud, ориентированная на программирование. Построена на базе Qwen2.5 и обучена на 5.5 трлн токенов, значительно улучшает генерацию кода, логическое мышление и исправление ошибок, сохраняя при этом сильные стороны в математике и общем понимании, обеспечивая надёжную основу для кодирующих агентов.",
  "Qwen/Qwen2.5-VL-32B-Instruct.description": "Qwen2.5-VL-32B-Instruct — мультимодальная модель от команды Qwen. Распознаёт распространённые объекты и анализирует текст, графики, иконки, изображения и макеты. Как визуальный агент, может рассуждать и динамически управлять инструментами, включая использование компьютеров и телефонов. Точно локализует объекты и генерирует структурированный вывод для счетов и таблиц. По сравнению с Qwen2-VL, RL дополнительно улучшает математику и решение задач, предлагая более предпочтительные ответы.",
  "Qwen/Qwen2.5-VL-72B-Instruct.description": "Qwen2.5-VL — модель визуально-языкового типа из серии Qwen2.5 с крупными улучшениями: более сильное визуальное понимание объектов, текста, графиков и макетов; логическое мышление как визуальный агент с динамическим использованием инструментов; понимание видео длительностью более 1 часа и захват ключевых событий; точная привязка объектов через рамки или точки; и структурированный вывод для отсканированных данных, таких как счета и таблицы.",
  "Qwen/Qwen3-14B.description": "Qwen3 — это модель нового поколения Tongyi Qwen с существенными улучшениями в области рассуждений, общей способности, агентных возможностей и многоязычной производительности. Поддерживает переключение режимов мышления.",
  "Qwen/Qwen3-235B-A22B-Instruct-2507.description": "Qwen3-235B-A22B-Instruct-2507 — флагманская модель Qwen3 MoE с общим числом параметров 235B и 22B активных. Это обновлённая версия без режима мышления, ориентированная на улучшение следования инструкциям, логических рассуждений, понимания текста, математики, науки, программирования и использования инструментов. Также расширяет знания на длинном хвосте в многоязычной среде и лучше соответствует пользовательским предпочтениям в субъективных и открытых задачах.",
  "Qwen/Qwen3-235B-A22B-Thinking-2507.description": "Qwen3-235B-A22B-Thinking-2507 — модель Qwen3, ориентированная на сложные логические рассуждения. Использует архитектуру MoE с общим числом параметров 235B и ~22B активных на токен, что повышает эффективность. Как специализированная модель для мышления, она демонстрирует значительные улучшения в логике, математике, науке, программировании и академических тестах, достигая уровня лучших открытых моделей мышления. Также улучшает следование инструкциям, использование инструментов и генерацию текста, нативно поддерживает контекст до 256K для глубоких рассуждений и работы с длинными документами.",
  "Qwen/Qwen3-235B-A22B.description": "Qwen3 — это модель нового поколения Tongyi Qwen с существенными улучшениями в области рассуждений, общей способности, агентных возможностей и многоязычной производительности. Поддерживает переключение режимов мышления.",
  "Qwen/Qwen3-30B-A3B-Instruct-2507.description": "Qwen3-30B-A3B-Instruct-2507 — обновлённая версия модели Qwen3-30B-A3B без режима мышления. Это модель MoE с общим числом параметров 30.5B и 3.3B активных. Существенно улучшает следование инструкциям, логические рассуждения, понимание текста, математику, науку, программирование и использование инструментов, расширяет знания на длинном хвосте в многоязычной среде и лучше соответствует пользовательским предпочтениям в субъективных открытых задачах. Поддерживает контекст до 256K. Эта модель работает только в режиме без мышления и не будет выводить теги `<think></think>`.",
  "Qwen/Qwen3-30B-A3B-Thinking-2507.description": "Qwen3-30B-A3B-Thinking-2507 — новейшая модель мышления в серии Qwen3. Это модель MoE с общим числом параметров 30.5B и 3.3B активных, ориентированная на сложные задачи. Демонстрирует значительные улучшения в логике, математике, науке, программировании и академических тестах, а также улучшает следование инструкциям, использование инструментов, генерацию текста и соответствие предпочтениям. Нативно поддерживает контекст до 256K и может быть расширена до 1M токенов. Эта версия предназначена для режима мышления с пошаговыми рассуждениями и развитыми агентными возможностями.",
  "Qwen/Qwen3-30B-A3B.description": "Qwen3 — это модель нового поколения Tongyi Qwen с существенными улучшениями в области рассуждений, общей способности, агентных возможностей и многоязычной производительности. Поддерживает переключение режимов мышления.",
  "Qwen/Qwen3-32B.description": "Qwen3 — это модель нового поколения Tongyi Qwen с существенными улучшениями в области рассуждений, общей способности, агентных возможностей и многоязычной производительности. Поддерживает переключение режимов мышления.",
  "Qwen/Qwen3-8B.description": "Qwen3 — это модель нового поколения Tongyi Qwen с существенными улучшениями в области рассуждений, общей способности, агентных возможностей и многоязычной производительности. Поддерживает переключение режимов мышления.",
  "Qwen/Qwen3-Coder-30B-A3B-Instruct.description": "Qwen3-Coder-30B-A3B-Instruct — это модель программирования серии Qwen3 от команды Qwen. Оптимизирована для высокой производительности и эффективности при работе с кодом. Демонстрирует сильные стороны в агентном программировании, автоматизации браузера и использовании инструментов среди открытых моделей. Нативно поддерживает контекст до 256K и может быть расширена до 1M токенов для понимания на уровне кодовой базы. Обеспечивает агентное программирование на платформах, таких как Qwen Code и CLINE, с использованием специального формата вызова функций.",
  "Qwen/Qwen3-Coder-480B-A35B-Instruct.description": "Qwen3-Coder-480B-A35B-Instruct — самая агентная модель программирования от Alibaba на сегодняшний день. Это модель MoE с общим числом параметров 480B и 35B активных, обеспечивающая баланс между эффективностью и производительностью. Нативно поддерживает контекст до 256K и может быть расширена до 1M токенов с помощью YaRN, что позволяет обрабатывать большие кодовые базы. Разработана для агентных рабочих процессов программирования, может взаимодействовать с инструментами и средами для решения сложных задач. Достигает лучших результатов среди открытых моделей в тестах на программирование и агентность, сопоставима с ведущими моделями, такими как Claude Sonnet 4.",
  "Qwen/Qwen3-Next-80B-A3B-Instruct.description": "Qwen3-Next-80B-A3B-Instruct — это базовая модель нового поколения, использующая архитектуру Qwen3-Next для экстремальной эффективности обучения и вывода. Объединяет гибридное внимание (Gated DeltaNet + Gated Attention), высокоразреженную MoE и оптимизации стабильности обучения. Имеет 80B общих параметров, но только ~3B активных при выводе, что снижает вычислительные затраты и обеспечивает более чем 10-кратную пропускную способность по сравнению с Qwen3-32B при контексте >32K. Эта версия, настроенная на выполнение инструкций, ориентирована на общие задачи (без режима мышления). По некоторым тестам сопоставима с Qwen3-235B и демонстрирует сильные стороны в задачах с ультрадлинным контекстом.",
  "Qwen/Qwen3-Next-80B-A3B-Thinking.description": "Qwen3-Next-80B-A3B-Thinking — это базовая модель нового поколения для сложных рассуждений. Использует архитектуру Qwen3-Next с гибридным вниманием (Gated DeltaNet + Gated Attention) и высокоразреженной MoE для экстремальной эффективности обучения и вывода. Имеет 80B общих параметров, но только ~3B активных при выводе, что снижает вычислительные затраты и обеспечивает более чем 10-кратную пропускную способность по сравнению с Qwen3-32B при контексте >32K. Эта версия мышления ориентирована на многошаговые задачи, такие как доказательства, синтез кода, логический анализ и планирование, выводя структурированную цепочку рассуждений. Превосходит Qwen3-32B-Thinking и обходит Gemini-2.5-Flash-Thinking по нескольким тестам.",
  "Qwen/Qwen3-Omni-30B-A3B-Captioner.description": "Qwen3-Omni-30B-A3B-Captioner — это модель VLM из серии Qwen3, созданная для высококачественных, детализированных и точных описаний изображений. Использует архитектуру MoE с 30B параметров для глубокого понимания изображений и генерации беглых описаний, превосходя в захвате деталей, понимании сцен, распознавании объектов и логических связях.",
  "Qwen/Qwen3-Omni-30B-A3B-Instruct.description": "Qwen3-Omni-30B-A3B-Instruct — это модель MoE из серии Qwen3 с 30B общих и 3B активных параметров, обеспечивающая высокую производительность при низкой стоимости вывода. Обучена на высококачественных многоязычных данных из различных источников, поддерживает полные мультимодальные входы (текст, изображения, аудио, видео) и кросс-модальное понимание и генерацию.",
  "Qwen/Qwen3-Omni-30B-A3B-Thinking.description": "Qwen3-Omni-30B-A3B-Thinking — это основной компонент \"Thinker\" в Qwen3-Omni. Обрабатывает мультимодальные входы (текст, аудио, изображения, видео) и выполняет сложные цепочки рассуждений, объединяя входные данные в общее представление для глубокого кросс-модального понимания. Это модель MoE с 30B общих и 3B активных параметров, обеспечивающая баланс между мощными рассуждениями и вычислительной эффективностью.",
  "Qwen/Qwen3-VL-235B-A22B-Instruct.description": "Qwen3-VL-235B-A22B-Instruct — это крупная модель Qwen3-VL, настроенная на выполнение инструкций и построенная на архитектуре MoE, обеспечивающая отличное мультимодальное понимание и генерацию. Нативно поддерживает контекст до 256K и подходит для высоконагруженных производственных мультимодальных сервисов.",
  "Qwen/Qwen3-VL-235B-A22B-Thinking.description": "Qwen3-VL-235B-A22B-Thinking — флагманская версия мышления в серии Qwen3-VL, оптимизированная для сложных мультимодальных рассуждений, работы с длинным контекстом и взаимодействия с агентами в корпоративных сценариях.",
  "Qwen/Qwen3-VL-30B-A3B-Instruct.description": "Qwen3-VL-30B-A3B-Instruct — это модель Qwen3-VL, настроенная на выполнение инструкций, с сильным пониманием и генерацией в связке зрение-язык. Нативно поддерживает контекст до 256K для мультимодального чата и генерации, основанной на изображениях.",
  "Qwen/Qwen3-VL-30B-A3B-Thinking.description": "Qwen3-VL-30B-A3B-Thinking — версия Qwen3-VL с усиленными возможностями рассуждения, оптимизированная для мультимодальных рассуждений, преобразования изображений в код и сложного визуального понимания. Поддерживает контекст до 256K с улучшенной способностью к цепочкам рассуждений.",
  "Qwen/Qwen3-VL-32B-Instruct.description": "Qwen3-VL-32B-Instruct — это модель зрение-язык от команды Qwen с передовыми результатами на нескольких VL-бенчмарках. Поддерживает изображения с мегапиксельным разрешением и обеспечивает сильное визуальное понимание, многоязычное OCR, точную визуальную привязку и визуальный диалог. Обрабатывает сложные мультимодальные задачи и поддерживает вызов инструментов и автозавершение по префиксу.",
  "Qwen/Qwen3-VL-32B-Thinking.description": "Qwen3-VL-32B-Thinking оптимизирована для сложных визуальных рассуждений. Включает встроенный режим мышления, который генерирует промежуточные шаги рассуждений перед ответами, улучшая многошаговую логику, планирование и сложные рассуждения. Поддерживает изображения с мегапиксельным разрешением, сильное визуальное понимание, многоязычное OCR, точную привязку, визуальный диалог, вызов инструментов и автозавершение по префиксу.",
  "Qwen/Qwen3-VL-8B-Instruct.description": "Qwen3-VL-8B-Instruct — это модель зрение-язык из серии Qwen3, построенная на базе Qwen3-8B-Instruct и обученная на больших объемах данных изображение-текст. Отличается общим визуальным пониманием, диалогом с упором на визуальные элементы и многоязычным распознаванием текста на изображениях. Подходит для визуального QA, создания подписей, мультимодального следования инструкциям и использования инструментов.",
  "Qwen/Qwen3-VL-8B-Thinking.description": "Qwen3-VL-8B-Thinking — визуальная версия мышления в серии Qwen3, оптимизированная для сложных многошаговых рассуждений. Генерирует цепочку мышления перед ответами для повышения точности, идеально подходит для глубокого визуального QA и детального анализа изображений.",
  "Qwen2-72B-Instruct.description": "Qwen2 — это новейшая модель серии Qwen с поддержкой контекстного окна на 128 тысяч токенов. По сравнению с лучшими открытыми моделями на сегодняшний день, Qwen2-72B значительно превосходит их в понимании естественного языка, знаниях, программировании, математике и многоязычных возможностях.",
  "Qwen2-7B-Instruct.description": "Qwen2 — это новейшая модель серии Qwen, превосходящая лучшие открытые модели аналогичного и даже большего размера. Qwen2 7B демонстрирует значительные преимущества в различных тестах, особенно в программировании и понимании китайского языка.",
  "Qwen2-VL-72B.description": "Qwen2-VL-72B — это мощная мультимодальная модель, объединяющая зрение и язык, поддерживающая обработку изображений и текста. Она точно распознаёт содержимое изображений и генерирует соответствующие описания или ответы.",
  "Qwen2.5-14B-Instruct.description": "Qwen2.5-14B-Instruct — это языковая модель с 14 миллиардами параметров, обладающая высокой производительностью. Она оптимизирована для китайского языка и многоязычных сценариев, поддерживает интеллектуальные вопросы и ответы, а также генерацию контента.",
  "Qwen2.5-32B-Instruct.description": "Qwen2.5-32B-Instruct — это языковая модель с 32 миллиардами параметров, обеспечивающая сбалансированную производительность. Она оптимизирована для китайского языка и многоязычных задач, поддерживает интеллектуальные вопросы и ответы, а также генерацию контента.",
  "Qwen2.5-72B-Instruct.description": "Языковая модель для китайского и английского языков, настроенная для задач языка, программирования, математики и логического рассуждения.",
  "Qwen2.5-7B-Instruct.description": "Qwen2.5-7B-Instruct — это языковая модель с 7 миллиардами параметров, поддерживающая вызов функций и интеграцию с внешними системами, что значительно повышает гибкость и расширяемость. Она оптимизирована для китайского языка и многоязычных сценариев, поддерживает интеллектуальные вопросы и ответы, а также генерацию контента.",
  "Qwen2.5-Coder-14B-Instruct.description": "Qwen2.5-Coder-14B-Instruct — это крупномасштабная предварительно обученная модель для программирования, обладающая высокой способностью к пониманию и генерации кода. Она эффективно справляется с широким спектром задач программирования, идеально подходит для интеллектуального кодирования, автоматической генерации скриптов и вопросов по программированию.",
  "Qwen2.5-Coder-32B-Instruct.description": "Продвинутая языковая модель для генерации кода, логического рассуждения и исправления ошибок на основных языках программирования.",
  "Qwen3-235B-A22B-Instruct-2507-FP8.description": "Qwen3 235B A22B Instruct 2507 оптимизирована для продвинутого логического рассуждения и следования инструкциям, использует архитектуру MoE для эффективного масштабирования рассуждений.",
  "Qwen3-235B.description": "Qwen3-235B-A22B — это модель MoE с гибридным режимом рассуждения, позволяющим пользователям переключаться между режимами мышления и немышления. Она поддерживает понимание и рассуждение на 119 языках и диалектах, обладает мощными возможностями вызова инструментов и конкурирует с ведущими моделями, такими как DeepSeek R1, OpenAI o1, o3-mini, Grok 3 и Google Gemini 2.5 Pro, по общим способностям, программированию, математике, многоязычности и логическому мышлению.",
  "Qwen3-32B.description": "Qwen3-32B — это плотная модель с гибридным режимом рассуждения, позволяющая пользователям переключаться между режимами мышления и немышления. Благодаря улучшениям в архитектуре, большему объёму данных и более качественному обучению, она демонстрирует производительность, сопоставимую с Qwen2.5-72B.",
  "SenseChat-128K.description": "Базовая модель V4 с контекстом 128K, сильна в понимании и генерации длинных текстов.",
  "SenseChat-32K.description": "Базовая модель V4 с контекстом 32K, гибкая для различных сценариев.",
  "SenseChat-5-1202.description": "Последняя версия на основе V5.5 с существенными улучшениями в базовых знаниях китайского и английского языков, чатах, знаниях в области STEM и гуманитарных наук, письме, математике/логике и управлении длиной текста.",
  "SenseChat-5-Cantonese.description": "Разработана с учётом диалоговых привычек Гонконга, сленга и местных знаний; превосходит GPT-4 в понимании кантонского языка и сопоставима с GPT-4 Turbo по знаниям, логике, математике и программированию.",
  "SenseChat-5-beta.description": "Некоторые характеристики превосходят SenseChat-5-1202.",
  "SenseChat-5.description": "Последняя версия V5.5 с контекстом 128K; значительные улучшения в математическом рассуждении, английском чате, следовании инструкциям и понимании длинных текстов, сопоставима с GPT-4o.",
  "SenseChat-Character-Pro.description": "Продвинутая модель для общения с персонажами с контекстом 32K, улучшенными возможностями и поддержкой китайского и английского языков.",
  "SenseChat-Character.description": "Стандартная модель для общения с персонажами с контекстом 8K и высокой скоростью отклика.",
  "SenseChat-Turbo-1202.description": "Последняя облегчённая модель, достигающая более 90% возможностей полной модели при значительно меньших затратах на вывод.",
  "SenseChat-Turbo.description": "Подходит для быстрого ответа на вопросы и сценариев дообучения модели.",
  "SenseChat-Vision.description": "Последняя версия V5.5 с поддержкой нескольких изображений и широкими улучшениями в распознавании атрибутов, пространственных отношений, действий/событий, понимании сцен, распознавании эмоций, логическом мышлении и понимании/генерации текста.",
  "SenseChat.description": "Базовая модель V4 с контекстом 4K и высокой общей производительностью.",
  "SenseNova-V6-5-Pro.description": "Благодаря комплексным обновлениям мультимодальных, языковых и логических данных, а также оптимизации стратегии обучения, новая модель значительно улучшает мультимодальное рассуждение и универсальное следование инструкциям, поддерживает контекст до 128K и превосходно справляется с задачами OCR и распознаванием IP в сфере культуры и туризма.",
  "SenseNova-V6-5-Turbo.description": "Благодаря комплексным обновлениям мультимодальных, языковых и логических данных, а также оптимизации стратегии обучения, новая модель значительно улучшает мультимодальное рассуждение и универсальное следование инструкциям, поддерживает контекст до 128K и превосходно справляется с задачами OCR и распознаванием IP в сфере культуры и туризма.",
  "SenseNova-V6-Pro.description": "Нативно объединяет изображение, текст и видео, преодолевая традиционные ограничения мультимодальности; занимает лидирующие позиции в OpenCompass и SuperCLUE.",
  "SenseNova-V6-Reasoner.description": "Объединяет глубокое логическое мышление в области зрения и языка, поддерживает медленное мышление и полную цепочку рассуждений.",
  "SenseNova-V6-Turbo.description": "Нативно объединяет изображение, текст и видео, преодолевая традиционные ограничения мультимодальности. Лидирует по основным мультимодальным и языковым возможностям и занимает топовые позиции в различных оценках.",
  "Skylark2-lite-8k.description": "Модель второго поколения Skylark. Skylark2-lite обеспечивает быстрые ответы в реальном времени для задач с ограниченным бюджетом и невысокими требованиями к точности, с контекстом 8K.",
  "Skylark2-pro-32k.description": "Модель второго поколения Skylark. Skylark2-pro обеспечивает высокую точность для сложной генерации текста, такой как профессиональный копирайтинг, написание романов и высококачественный перевод, с контекстом 32K.",
  "Skylark2-pro-4k.description": "Модель второго поколения Skylark. Skylark2-pro обеспечивает высокую точность для сложной генерации текста, такой как профессиональный копирайтинг, написание романов и высококачественный перевод, с контекстом 4K.",
  "Skylark2-pro-character-4k.description": "Модель второго поколения Skylark. Skylark2-pro-character отлично справляется с ролевыми играми и чатами, точно подбирая стиль персонажа и обеспечивая естественный диалог для чат-ботов, виртуальных помощников и служб поддержки, с высокой скоростью отклика.",
  "Skylark2-pro-turbo-8k.description": "Модель второго поколения Skylark. Skylark2-pro-turbo-8k обеспечивает более быструю генерацию при меньших затратах с контекстом 8K.",
  "THUDM/GLM-4-32B-0414.description": "GLM-4-32B-0414 — это модель нового поколения с открытым исходным кодом на базе GLM с 32 миллиардами параметров, сопоставимая по производительности с OpenAI GPT и сериями DeepSeek V3/R1.",
  "THUDM/GLM-4-9B-0414.description": "GLM-4-9B-0414 — это модель GLM с 9 миллиардами параметров, унаследовавшая технологии GLM-4-32B и обеспечивающая более лёгкое развертывание. Отлично справляется с генерацией кода, веб-дизайном, созданием SVG и написанием текстов на основе поиска.",
  "THUDM/GLM-4.1V-9B-Thinking.description": "GLM-4.1V-9B-Thinking — это открытая мультимодальная модель от Zhipu AI и лаборатории KEG Университета Цинхуа, предназначенная для сложного мультимодального восприятия. Построена на базе GLM-4-9B-0414 и дополнена цепочкой рассуждений и обучением с подкреплением (RL), что значительно повышает устойчивость и кросс-модальное мышление.",
  "THUDM/GLM-Z1-32B-0414.description": "GLM-Z1-32B-0414 — это модель глубинного мышления, созданная на основе GLM-4-32B-0414 с использованием данных холодного старта и расширенного RL. Дополнительно обучена на математике, коде и логике, значительно улучшая способности к решению сложных задач по сравнению с базовой моделью.",
  "THUDM/GLM-Z1-9B-0414.description": "GLM-Z1-9B-0414 — компактная модель GLM с 9 миллиардами параметров, сочетающая открытость и высокую производительность. Демонстрирует отличные результаты в математических рассуждениях и решении общих задач, лидируя среди моделей своего класса.",
  "THUDM/GLM-Z1-Rumination-32B-0414.description": "GLM-Z1-Rumination-32B-0414 — это модель глубинного мышления с возможностью размышлений (по аналогии с OpenAI Deep Research). В отличие от обычных моделей, она тратит больше времени на обдумывание, чтобы решать более открытые и сложные задачи.",
  "THUDM/glm-4-9b-chat.description": "GLM-4-9B-Chat — это открытая модель GLM-4 от Zhipu AI. Обеспечивает высокую производительность в области семантики, математики, логики, программирования и знаний. Помимо многотурового чата, поддерживает веб-браузинг, выполнение кода, вызов пользовательских инструментов и работу с длинными текстами. Поддерживает 26 языков (включая китайский, английский, японский, корейский и немецкий). Демонстрирует отличные результаты на AlignBench-v2, MT-Bench, MMLU и C-Eval, а также поддерживает контекст до 128K токенов для академического и бизнес-применения.",
  "Tongyi-Zhiwen/QwenLong-L1-32B.description": "QwenLong-L1-32B — первая модель для рассуждений в длинном контексте (LRM), обученная с использованием RL и оптимизированная для понимания длинных текстов. Прогрессивное расширение контекста с помощью RL обеспечивает стабильный переход от короткого к длинному контексту. Превосходит OpenAI-o3-mini и Qwen3-235B-A22B на семи бенчмарках по вопросам к документам с длинным контекстом, сопоставима с Claude-3.7-Sonnet-Thinking. Особенно сильна в математике, логике и многошаговых рассуждениях.",
  "Yi-34B-Chat.description": "Yi-1.5-34B сохраняет сильные языковые способности серии, а также использует инкрементальное обучение на 500 миллиардах высококачественных токенов для значительного улучшения логики, математики и программирования.",
  "abab5.5-chat.description": "Создана для продуктивных сценариев с обработкой сложных задач и эффективной генерацией текста для профессионального использования.",
  "abab5.5s-chat.description": "Разработана для чатов с китайской персонализацией, обеспечивая высококачественный диалог на китайском языке для различных приложений.",
  "abab6.5g-chat.description": "Предназначена для многозначных чатов с персонализацией, поддерживает генерацию диалогов высокого качества на английском и других языках.",
  "abab6.5s-chat.description": "Подходит для широкого спектра задач обработки естественного языка, включая генерацию текста и диалоговые системы.",
  "abab6.5t-chat.description": "Оптимизирована для китайских чатов с персонализацией, обеспечивая плавный диалог, соответствующий привычкам китайского языка.",
  "accounts/fireworks/models/deepseek-r1.description": "DeepSeek-R1 — это передовая языковая модель, оптимизированная с помощью обучения с подкреплением и данных холодного старта, обеспечивающая отличные результаты в логике, математике и программировании.",
  "accounts/fireworks/models/deepseek-v3.description": "Мощная языковая модель с архитектурой Mixture-of-Experts (MoE) от DeepSeek с общим числом параметров 671B и 37B активных параметров на токен.",
  "accounts/fireworks/models/llama-v3-70b-instruct.description": "Meta разработала и выпустила серию LLM Meta Llama 3, включающую предварительно обученные и дообученные на инструкциях модели генерации текста с объемом 8B и 70B параметров. Модели Llama 3, дообученные на инструкциях, оптимизированы для ведения диалогов и превосходят многие существующие открытые чат-модели по общепринятым отраслевым метрикам.",
  "accounts/fireworks/models/llama-v3-8b-instruct-hf.description": "Модели Meta Llama 3, дообученные на инструкциях, оптимизированы для ведения диалогов и превосходят многие существующие открытые чат-модели по общепринятым отраслевым метрикам. Llama 3 8B Instruct (версия HF) — это оригинальная версия Llama 3 8B Instruct с точностью FP16, результаты которой соответствуют официальной реализации Hugging Face.",
  "accounts/fireworks/models/llama-v3-8b-instruct.description": "Meta разработала и выпустила серию LLM Meta Llama 3 — набор предварительно обученных и дообученных на инструкциях моделей генерации текста с объемом 8B и 70B параметров. Модели Llama 3, дообученные на инструкциях, оптимизированы для ведения диалогов и превосходят многие существующие открытые чат-модели по общепринятым отраслевым метрикам.",
  "accounts/fireworks/models/llama-v3p1-405b-instruct.description": "Meta Llama 3.1 — это многоязычное семейство LLM, включающее предварительно обученные и дообученные на инструкциях модели генерации текста с объемом 8B, 70B и 405B параметров. Модели, дообученные на инструкциях, оптимизированы для многоязычного диалога и превосходят многие существующие открытые и закрытые чат-модели по общепринятым отраслевым метрикам. Модель 405B — самая мощная в семействе Llama 3.1, использует вывод FP8, максимально приближенный к эталонной реализации.",
  "accounts/fireworks/models/llama-v3p1-70b-instruct.description": "Meta Llama 3.1 — это многоязычное семейство LLM, включающее предварительно обученные и дообученные на инструкциях модели генерации текста с объемом 8B, 70B и 405B параметров. Модели, дообученные на инструкциях, оптимизированы для многоязычного диалога и превосходят многие существующие открытые и закрытые чат-модели по общепринятым отраслевым метрикам.",
  "accounts/fireworks/models/llama-v3p1-8b-instruct.description": "Meta Llama 3.1 — это многоязычное семейство LLM, включающее предварительно обученные и дообученные на инструкциях модели генерации текста с объемом 8B, 70B и 405B параметров. Модели, дообученные на инструкциях, оптимизированы для многоязычного диалога и превосходят многие существующие открытые и закрытые чат-модели по общепринятым отраслевым метрикам.",
  "accounts/fireworks/models/llama-v3p2-11b-vision-instruct.description": "Дообученная на инструкциях модель визуального рассуждения от Meta с 11 миллиардами параметров, оптимизированная для распознавания изображений, логического анализа, генерации описаний и ответов на вопросы, связанные с изображениями. Понимает визуальные данные, такие как диаграммы и графики, и объединяет зрение и язык, создавая текстовые описания деталей изображений.",
  "accounts/fireworks/models/llama-v3p2-3b-instruct.description": "Llama 3.2 3B Instruct — это легковесная многоязычная модель от Meta, разработанная для эффективной работы с низкой задержкой и сниженной стоимостью по сравнению с более крупными моделями. Типичные сценарии использования включают переформулировку запросов и помощь в написании текстов.",
  "accounts/fireworks/models/llama-v3p2-90b-vision-instruct.description": "Дообученная на инструкциях модель визуального рассуждения от Meta с 90 миллиардами параметров, оптимизированная для распознавания изображений, логического анализа, генерации описаний и ответов на вопросы, связанные с изображениями. Понимает визуальные данные, такие как диаграммы и графики, и объединяет зрение и язык, создавая текстовые описания деталей изображений. Примечание: эта модель предоставляется в экспериментальном режиме как серверлесс-решение. Для использования в продакшене учтите, что Fireworks может прекратить развертывание без предварительного уведомления.",
  "accounts/fireworks/models/llama-v3p3-70b-instruct.description": "Llama 3.3 70B Instruct — обновление декабря для модели Llama 3.1 70B. Улучшает использование инструментов, поддержку многоязычного текста, математику и программирование по сравнению с выпуском июля 2024 года. Обеспечивает лидирующую в отрасли производительность в рассуждении, математике и следовании инструкциям, предлагая сопоставимую с 3.1 405B производительность при значительном выигрыше в скорости и стоимости.",
  "accounts/fireworks/models/mistral-small-24b-instruct-2501.description": "Модель с 24 миллиардами параметров, обладающая передовыми возможностями, сопоставимыми с более крупными моделями.",
  "accounts/fireworks/models/mixtral-8x22b-instruct.description": "Mixtral MoE 8x22B Instruct v0.1 — это дообученная на инструкциях версия модели Mixtral MoE 8x22B v0.1 с включенной поддержкой API завершения чата.",
  "accounts/fireworks/models/mixtral-8x7b-instruct.description": "Mixtral MoE 8x7B Instruct — это дообученная на инструкциях версия модели Mixtral MoE 8x7B с включенной поддержкой API завершения чата.",
  "accounts/fireworks/models/mythomax-l2-13b.description": "Улучшенный вариант MythoMix, возможно, его более изысканная форма, объединяющая MythoLogic-L2 и Huginn с использованием экспериментальной техники слияния тензорных типов. Благодаря своей уникальности отлично подходит для повествования и ролевых игр.",
  "accounts/fireworks/models/phi-3-vision-128k-instruct.description": "Phi-3-Vision-128K-Instruct — это легковесная, передовая открытая мультимодальная модель, построенная на синтетических данных и отобранных общедоступных веб-источниках, с акцентом на качественные данные, требующие рассуждений, в области текста и визуальной информации. Принадлежит к семейству Phi-3 и поддерживает мультимодальность с контекстом до 128K токенов. Модель проходит тщательную донастройку, включая обучение с учителем и оптимизацию предпочтений, чтобы обеспечить точное следование инструкциям и высокий уровень безопасности.",
  "accounts/fireworks/models/qwen-qwq-32b-preview.description": "Модель Qwen QwQ направлена на развитие возможностей ИИ в области рассуждений, демонстрируя, что открытые модели могут конкурировать с закрытыми передовыми решениями. QwQ-32B-Preview — это экспериментальный выпуск, сопоставимый с o1 и превосходящий GPT-4o и Claude 3.5 Sonnet по рассуждению и анализу на метриках GPQA, AIME, MATH-500 и LiveCodeBench. Примечание: модель предоставляется в экспериментальном режиме как серверлесс-решение. Для использования в продакшене учтите, что Fireworks может прекратить развертывание без предварительного уведомления.",
  "accounts/fireworks/models/qwen2-vl-72b-instruct.description": "Модель Qwen-VL с 72 миллиардами параметров — последняя разработка Alibaba, отражающая почти год инноваций.",
  "accounts/fireworks/models/qwen2p5-72b-instruct.description": "Qwen2.5 — это серия LLM только с декодером, разработанная командой Qwen и Alibaba Cloud, доступная в вариантах 0.5B, 1.5B, 3B, 7B, 14B, 32B и 72B, как в базовой, так и в дообученной на инструкциях версиях.",
  "accounts/fireworks/models/qwen2p5-coder-32b-instruct.description": "Qwen2.5-Coder — последняя модель LLM из серии Qwen, предназначенная для программирования (ранее CodeQwen). Примечание: модель предоставляется в экспериментальном режиме как серверлесс-решение. Для использования в продакшене учтите, что Fireworks может прекратить развертывание без предварительного уведомления.",
  "accounts/yi-01-ai/models/yi-large.description": "Yi-Large — это высококлассная LLM, занимающая позицию сразу за GPT-4, Gemini 1.5 Pro и Claude 3 Opus в рейтинге LMSYS. Отличается выдающимися многоязычными возможностями, особенно в испанском, китайском, японском, немецком и французском языках. Yi-Large также удобна для разработчиков, так как использует ту же схему API, что и OpenAI, обеспечивая легкую интеграцию.",
  "ai21-jamba-1.5-large.description": "Многоязычная модель с 398 миллиардами параметров (94 миллиарда активных), поддерживающая контекст до 256 тысяч токенов, вызов функций, структурированный вывод и генерацию с привязкой к источникам.",
  "ai21-jamba-1.5-mini.description": "Многоязычная модель с 52 миллиардами параметров (12 миллиардов активных), поддерживающая контекст до 256 тысяч токенов, вызов функций, структурированный вывод и генерацию с привязкой к источникам.",
  "ai21-labs/AI21-Jamba-1.5-Large.description": "Многоязычная модель с 398 миллиардами параметров (94 миллиарда активных), поддерживающая контекст до 256 тысяч токенов, вызов функций, структурированный вывод и генерацию с привязкой к источникам.",
  "ai21-labs/AI21-Jamba-1.5-Mini.description": "Многоязычная модель с 52 миллиардами параметров (12 миллиардов активных), поддерживающая контекст до 256 тысяч токенов, вызов функций, структурированный вывод и генерацию с привязкой к источникам.",
  "alibaba/qwen-3-14b.description": "Qwen3 — это новейшее поколение в серии Qwen, предлагающее широкий набор плотных и MoE-моделей. Обученная на обширных данных, модель демонстрирует прорывные результаты в логике, следовании инструкциям, агентных возможностях и многоязычной поддержке.",
  "alibaba/qwen-3-235b.description": "Qwen3 — это новейшее поколение в серии Qwen, предлагающее широкий набор плотных и MoE-моделей. Обученная на обширных данных, модель демонстрирует прорывные результаты в логике, следовании инструкциям, агентных возможностях и многоязычной поддержке.",
  "alibaba/qwen-3-30b.description": "Qwen3 — это новейшее поколение в серии Qwen, предлагающее широкий набор плотных и MoE-моделей. Обученная на обширных данных, модель демонстрирует прорывные результаты в логике, следовании инструкциям, агентных возможностях и многоязычной поддержке.",
  "alibaba/qwen-3-32b.description": "Qwen3 — это новейшее поколение в серии Qwen, предлагающее широкий набор плотных и MoE-моделей. Обученная на обширных данных, модель демонстрирует прорывные результаты в логике, следовании инструкциям, агентных возможностях и многоязычной поддержке.",
  "alibaba/qwen3-coder.description": "Qwen3-Coder-480B-A35B-Instruct — это самая агентно-ориентированная модель для программирования в серии Qwen, демонстрирующая высокие результаты в агентном кодировании, использовании браузера и других ключевых задачах программирования, сопоставимых с уровнем Claude Sonnet.",
  "amazon/nova-lite.description": "Очень недорогая мультимодальная модель с чрезвычайно быстрой обработкой изображений, видео и текста.",
  "amazon/nova-micro.description": "Только текстовая модель с ультранизкой задержкой и минимальными затратами.",
  "amazon/nova-pro.description": "Высокопроизводительная мультимодальная модель с оптимальным балансом точности, скорости и стоимости для широкого спектра задач.",
  "amazon/titan-embed-text-v2.description": "Amazon Titan Text Embeddings V2 — это легкая и эффективная многоязычная модель эмбеддингов, поддерживающая размеры 1024, 512 и 256.",
  "anthropic.claude-3-5-sonnet-20240620-v1:0.description": "Claude 3.5 Sonnet поднимает отраслевой стандарт, превосходя конкурентов и Claude 3 Opus по широкому спектру оценок, сохраняя при этом средний уровень скорости и стоимости.",
  "anthropic.claude-3-5-sonnet-20241022-v2:0.description": "Claude 3.5 Sonnet поднимает отраслевой стандарт, превосходя конкурентов и Claude 3 Opus по широкому спектру оценок, сохраняя при этом средний уровень скорости и стоимости.",
  "anthropic.claude-3-haiku-20240307-v1:0.description": "Claude 3 Haiku — самая быстрая и компактная модель от Anthropic, обеспечивающая почти мгновенные ответы на простые запросы. Обеспечивает плавное, человекоподобное взаимодействие с ИИ и поддерживает ввод изображений с контекстом до 200 тысяч токенов.",
  "anthropic.claude-3-opus-20240229-v1:0.description": "Claude 3 Opus — самая мощная модель от Anthropic с передовыми возможностями для сложных задач. Обеспечивает свободную генерацию и понимание новых сценариев, поддерживает ввод изображений и контекст до 200 тысяч токенов.",
  "anthropic.claude-3-sonnet-20240229-v1:0.description": "Claude 3 Sonnet сочетает интеллект и скорость для корпоративных задач, предлагая высокую ценность при низкой стоимости. Надежен для масштабируемого внедрения ИИ и поддерживает ввод изображений с контекстом до 200 тысяч токенов.",
  "anthropic.claude-instant-v1.description": "Быстрая, экономичная и при этом мощная модель для повседневного общения, анализа текста, суммирования и вопросов по документам.",
  "anthropic.claude-v2.description": "Высокопроизводительная модель для задач от сложного диалога и креативной генерации до точного следования инструкциям.",
  "anthropic.claude-v2:1.description": "Обновленная версия Claude 2 с удвоенным контекстом, улучшенной надежностью, сниженным уровнем галлюцинаций и повышенной точностью на основе доказательств для длинных документов и RAG.",
  "anthropic/claude-3-haiku.description": "Claude 3 Haiku — самая быстрая модель от Anthropic, предназначенная для корпоративных задач с длинными запросами. Быстро анализирует крупные документы, такие как квартальные отчеты, контракты или юридические дела, при этом стоит вдвое дешевле аналогов.",
  "anthropic/claude-3-opus.description": "Claude 3 Opus — самая интеллектуальная модель от Anthropic с лидирующей производительностью в сложных задачах, свободно обрабатывает открытые запросы и новые сценарии с высоким уровнем понимания.",
  "anthropic/claude-3.5-haiku.description": "Claude 3.5 Haiku отличается повышенной скоростью, точностью программирования и эффективным использованием инструментов, подходит для сценариев с высокими требованиями к скорости и взаимодействию с инструментами.",
  "anthropic/claude-3.5-sonnet.description": "Claude 3.5 Sonnet — быстрая и эффективная модель из семейства Sonnet, обеспечивающая улучшенную производительность в программировании и логике. Некоторые версии постепенно заменяются на Sonnet 3.7 и выше.",
  "anthropic/claude-3.7-sonnet.description": "Claude 3.7 Sonnet — обновленная модель Sonnet с улучшенными логическими и программными возможностями, подходящая для сложных корпоративных задач.",
  "anthropic/claude-haiku-4.5.description": "Claude Haiku 4.5 — высокопроизводительная быстрая модель от Anthropic с очень низкой задержкой и высокой точностью.",
  "anthropic/claude-opus-4.1.description": "Opus 4.1 — флагманская модель от Anthropic, оптимизированная для программирования, сложной логики и длительных задач.",
  "anthropic/claude-opus-4.5.description": "Claude Opus 4.5 — флагманская модель от Anthropic, сочетающая высший интеллект с масштабируемой производительностью для сложных задач, требующих качественного логического вывода.",
  "anthropic/claude-opus-4.description": "Opus 4 — флагманская модель от Anthropic, предназначенная для сложных задач и корпоративных приложений.",
  "anthropic/claude-sonnet-4.5.description": "Claude Sonnet 4.5 — новейшая гибридная модель логического вывода от Anthropic, оптимизированная для сложных рассуждений и программирования.",
  "anthropic/claude-sonnet-4.description": "Claude Sonnet 4 — гибридная модель логического вывода от Anthropic, сочетающая режимы мышления и немышления.",
  "ascend-tribe/pangu-pro-moe.description": "Pangu-Pro-MoE 72B-A16B — это разреженная LLM с 72 миллиардами общих и 16 миллиардами активных параметров, основанная на архитектуре группированной MoE (MoGE). Она группирует экспертов при выборе и ограничивает количество активируемых экспертов на группу, что обеспечивает равномерную нагрузку и повышает эффективность развертывания на Ascend.",
  "aya.description": "Aya 23 — многоязычная модель от Cohere, поддерживающая 23 языка для различных сценариев использования.",
  "aya:35b.description": "Aya 23 — многоязычная модель от Cohere, поддерживающая 23 языка для различных сценариев использования.",
  "azure-DeepSeek-R1-0528.description": "Развернута Microsoft; DeepSeek R1 обновлена до версии DeepSeek-R1-0528. Обновление включает увеличение вычислительных ресурсов и оптимизацию алгоритмов постобучения, что значительно улучшает глубину рассуждений и выводов. Модель демонстрирует высокие результаты в математике, программировании и логике, приближаясь к лидерам, таким как O3 и Gemini 2.5 Pro.",
  "baichuan-m2-32b.description": "Baichuan M2 32B — это модель MoE от Baichuan Intelligence с сильными способностями к рассуждению.",
  "baichuan/baichuan2-13b-chat.description": "Baichuan-13B — это открытая, коммерчески пригодная LLM с 13 миллиардами параметров от Baichuan, демонстрирующая лучшие в своем классе результаты на авторитетных китайских и английских бенчмарках.",
  "baidu/ERNIE-4.5-300B-A47B.description": "ERNIE-4.5-300B-A47B — это MoE LLM от Baidu с 300 миллиардами общих параметров и 47 миллиардами активных на токен, обеспечивающая баланс между высокой производительностью и эффективностью вычислений. Как основная модель ERNIE 4.5, она превосходна в понимании, генерации, рассуждении и программировании. Использует мультимодальный гетерогенный метод предобучения MoE с совместным обучением на текстах и изображениях, что усиливает общие возможности, особенно в следовании инструкциям и знании мира.",
  "baidu/ernie-5.0-thinking-preview.description": "ERNIE 5.0 Thinking Preview — это модель нового поколения от Baidu с нативной мультимодальностью, обладающая сильными возможностями в понимании мультимодальных данных, следовании инструкциям, создании контента, фактическом вопросо-ответе и использовании инструментов.",
  "black-forest-labs/flux-1.1-pro.description": "FLUX 1.1 Pro — это более быстрая и улучшенная версия FLUX Pro с отличным качеством изображений и точным следованием подсказкам.",
  "black-forest-labs/flux-dev.description": "FLUX Dev — это версия FLUX для разработки, предназначенная для некоммерческого использования.",
  "black-forest-labs/flux-pro.description": "FLUX Pro — профессиональная модель FLUX для генерации изображений высокого качества.",
  "black-forest-labs/flux-schnell.description": "FLUX Schnell — это модель генерации изображений, оптимизированная для высокой скорости.",
  "c4ai-aya-expanse-32b.description": "Aya Expanse — это высокопроизводительная многоязычная модель с 32 миллиардами параметров, использующая настройку по инструкциям, арбитраж данных, обучение предпочтениям и объединение моделей, чтобы конкурировать с монолингвальными моделями. Поддерживает 23 языка.",
  "c4ai-aya-expanse-8b.description": "Aya Expanse — это высокопроизводительная многоязычная модель с 8 миллиардами параметров, использующая настройку по инструкциям, арбитраж данных, обучение предпочтениям и объединение моделей, чтобы конкурировать с монолингвальными моделями. Поддерживает 23 языка.",
  "c4ai-aya-vision-32b.description": "Aya Vision — это передовая мультимодальная модель, демонстрирующая высокие результаты на ключевых языковых, текстовых и визуальных бенчмарках. Поддерживает 23 языка. Версия с 32 миллиардами параметров ориентирована на выдающуюся многоязычную производительность.",
  "c4ai-aya-vision-8b.description": "Aya Vision — это передовая мультимодальная модель, демонстрирующая высокие результаты на ключевых языковых, текстовых и визуальных бенчмарках. Версия с 8 миллиардами параметров ориентирована на низкую задержку и высокую производительность.",
  "charglm-3.description": "CharGLM-3 создана для ролевых игр и эмоционального общения, поддерживает сверхдолгую многотуровую память и персонализированный диалог.",
  "charglm-4.description": "CharGLM-4 создана для ролевых игр и эмоционального общения, поддерживает сверхдолгую многотуровую память и персонализированный диалог.",
  "chatgpt-4o-latest.description": "ChatGPT-4o — это динамическая модель с обновлением в реальном времени, сочетающая сильное понимание и генерацию для масштабных сценариев, таких как поддержка клиентов, образование и техническая помощь.",
  "claude-2.0.description": "Claude 2 предлагает ключевые улучшения для бизнеса, включая контекст до 200 тысяч токенов, снижение галлюцинаций, системные подсказки и новую функцию тестирования — вызов инструментов.",
  "claude-2.1.description": "Claude 2 предлагает ключевые улучшения для бизнеса, включая контекст до 200 тысяч токенов, снижение галлюцинаций, системные подсказки и новую функцию тестирования — вызов инструментов.",
  "claude-3-5-haiku-20241022.description": "Claude 3.5 Haiku — самая быстрая модель нового поколения от Anthropic, улучшенная по множеству навыков и превосходящая предыдущий флагман Claude 3 Opus по многим бенчмаркам.",
  "claude-3-5-haiku-latest.description": "Claude 3.5 Haiku обеспечивает быстрые ответы для легких задач.",
  "claude-3-7-sonnet-20250219.description": "Claude Sonnet 3.7 — самая интеллектуальная модель от Anthropic и первая гибридная модель рассуждения на рынке, обеспечивающая мгновенные ответы или углублённое мышление с тонкой настройкой.",
  "claude-3-7-sonnet-latest.description": "Claude 3.7 Sonnet — последняя и самая мощная модель от Anthropic для высокосложных задач, превосходящая по производительности, интеллекту, беглости и пониманию.",
  "claude-3-haiku-20240307.description": "Claude 3 Haiku — самая быстрая и компактная модель от Anthropic, предназначенная для мгновенных ответов с высокой точностью и скоростью.",
  "claude-3-opus-20240229.description": "Claude 3 Opus — самая мощная модель от Anthropic для высокосложных задач, превосходящая по производительности, интеллекту, беглости и пониманию.",
  "claude-3-sonnet-20240229.description": "Claude 3 Sonnet сочетает интеллект и скорость для корпоративных задач, обеспечивая высокую полезность при низкой стоимости и надежное масштабируемое развертывание.",
  "claude-haiku-4-5-20251001.description": "Claude Haiku 4.5 — самая быстрая и интеллектуальная модель Haiku от Anthropic, сочетающая молниеносную скорость и способность к длительному размышлению.",
  "claude-opus-4-1-20250805-thinking.description": "Claude Opus 4.1 Thinking — продвинутая версия, способная демонстрировать процесс рассуждения.",
  "claude-opus-4-1-20250805.description": "Claude Opus 4.1 — последняя и самая мощная модель от Anthropic для высокосложных задач, превосходящая по производительности, интеллекту, беглости и пониманию.",
  "claude-opus-4-20250514.description": "Claude Opus 4 — самая мощная модель от Anthropic для сверхсложных задач, демонстрирующая выдающиеся результаты в производительности, интеллекте, беглости и понимании.",
  "claude-opus-4-5-20251101.description": "Claude Opus 4.5 — флагманская модель от Anthropic, сочетающая выдающийся интеллект с масштабируемой производительностью, идеально подходящая для сложных задач, требующих высококачественных ответов и рассуждений.",
  "claude-sonnet-4-20250514-thinking.description": "Claude Sonnet 4 Thinking может выдавать как мгновенные ответы, так и пошаговое рассуждение с видимым процессом.",
  "claude-sonnet-4-20250514.description": "Claude Sonnet 4 — самая интеллектуальная модель Anthropic на сегодняшний день, предлагающая мгновенные ответы или пошаговое размышление с тонкой настройкой для пользователей API.",
  "claude-sonnet-4-5-20250929.description": "Claude Sonnet 4.5 — самая интеллектуальная модель от Anthropic на сегодняшний день.",
  "codegeex-4.description": "CodeGeeX-4 — мощный AI-помощник для программирования, поддерживающий многоязычные вопросы и автодополнение кода для повышения продуктивности разработчиков.",
  "codegeex4-all-9b.description": "CodeGeeX4-ALL-9B — многоязычная модель генерации кода, поддерживающая автодополнение, генерацию кода, интерпретацию, веб-поиск, вызов функций и вопросы по репозиториям. Охватывает широкий спектр сценариев разработки ПО и является одной из лучших моделей кода с параметрами до 10B.",
  "codegemma.description": "CodeGemma — легковесная модель для различных задач программирования, обеспечивающая быструю итерацию и интеграцию.",
  "codegemma:2b.description": "CodeGemma — легковесная модель для различных задач программирования, обеспечивающая быструю итерацию и интеграцию.",
  "codellama.description": "Code Llama — LLM, ориентированная на генерацию и обсуждение кода, с широкой поддержкой языков для рабочих процессов разработчиков.",
  "codellama/CodeLlama-34b-Instruct-hf.description": "Code Llama — LLM, ориентированная на генерацию и обсуждение кода, с широкой поддержкой языков для рабочих процессов разработчиков.",
  "codellama:13b.description": "Code Llama — LLM, ориентированная на генерацию и обсуждение кода, с широкой поддержкой языков для рабочих процессов разработчиков.",
  "codellama:34b.description": "Code Llama — LLM, ориентированная на генерацию и обсуждение кода, с широкой поддержкой языков для рабочих процессов разработчиков.",
  "codellama:70b.description": "Code Llama — LLM, ориентированная на генерацию и обсуждение кода, с широкой поддержкой языков для рабочих процессов разработчиков.",
  "codeqwen.description": "CodeQwen1.5 — крупная языковая модель, обученная на обширных данных кода, предназначенная для сложных задач программирования.",
  "codestral-latest.description": "Codestral — наша самая продвинутая модель для программирования; версия v2 (январь 2025) оптимизирована для задач с низкой задержкой и высокой частотой, таких как FIM, исправление кода и генерация тестов.",
  "codestral.description": "Codestral — первая модель для программирования от Mistral AI, обеспечивающая высокое качество генерации кода.",
  "codex-mini-latest.description": "codex-mini-latest — дообученная модель o4-mini для Codex CLI. Для прямого использования через API мы рекомендуем начать с gpt-4.1.",
  "cogito-2.1:671b.description": "Cogito v2.1 671B — открытая LLM из США, свободная для коммерческого использования. Обеспечивает производительность на уровне ведущих моделей, более эффективную работу с токенами, поддержку контекста до 128k и высокую общую мощность.",
  "cogview-4.description": "CogView-4 — первая открытая модель от Zhipu для генерации изображений по тексту с поддержкой китайских иероглифов. Улучшает семантическое понимание, качество изображений и рендеринг текста на китайском и английском языках, поддерживает произвольную длину двуязычных подсказок и может генерировать изображения в любом разрешении в заданных пределах.",
  "cohere-command-r-plus.description": "Command R+ — продвинутая модель, оптимизированная для RAG, предназначенная для корпоративных задач.",
  "cohere-command-r.description": "Command R — масштабируемая генеративная модель, разработанная для RAG и использования инструментов, обеспечивающая промышленный уровень ИИ.",
  "cohere/Cohere-command-r-plus.description": "Command R+ — продвинутая модель, оптимизированная для RAG, предназначенная для корпоративных задач.",
  "cohere/Cohere-command-r.description": "Command R — масштабируемая генеративная модель, разработанная для RAG и использования инструментов, обеспечивающая промышленный уровень ИИ.",
  "cohere/command-a.description": "Command A — самая мощная модель Cohere на сегодняшний день, превосходно справляющаяся с использованием инструментов, агентами, RAG и многоязычными задачами. Поддерживает контекст длиной 256K, работает всего на двух GPU и обеспечивает на 150% большую пропускную способность по сравнению с Command R+ 08-2024.",
  "cohere/command-r-plus.description": "Command R+ — новейшая LLM от Cohere, оптимизированная для чатов и задач с длинным контекстом, обеспечивающая выдающуюся производительность, позволяя компаниям переходить от прототипов к реальному использованию.",
  "cohere/command-r.description": "Command R оптимизирована для чатов и задач с длинным контекстом, позиционируется как «масштабируемая» модель, сочетающая высокую производительность и точность, позволяя компаниям переходить от прототипов к промышленному применению.",
  "cohere/embed-v4.0.description": "Модель, преобразующая текст, изображения или смешанный контент в эмбеддинги для классификации или других задач.",
  "comfyui/flux-dev.description": "FLUX.1 Dev — высококачественная модель генерации изображений по тексту (10–50 шагов), идеально подходящая для креативных и художественных задач премиум-класса.",
  "comfyui/flux-kontext-dev.description": "FLUX.1 Kontext-dev — модель редактирования изображений с поддержкой редактирования по тексту, включая локальные изменения и перенос стиля.",
  "comfyui/flux-krea-dev.description": "FLUX.1 Krea-dev — безопасная модель генерации изображений по тексту, разработанная совместно с Krea, с встроенными фильтрами безопасности.",
  "comfyui/flux-schnell.description": "FLUX.1 Schnell — сверхбыстрая модель генерации изображений по тексту, создающая качественные изображения за 1–4 шага. Идеальна для задач в реальном времени и быстрого прототипирования.",
  "comfyui/stable-diffusion-15.description": "Stable Diffusion 1.5 — классическая модель генерации изображений по тексту с разрешением 512x512, идеально подходящая для быстрого прототипирования и творческих экспериментов.",
  "comfyui/stable-diffusion-35-inclclip.description": "Stable Diffusion 3.5 с встроенными энкодерами CLIP/T5 не требует внешних файлов энкодеров. Подходит для моделей, таких как sd3.5_medium_incl_clips, с низким потреблением ресурсов.",
  "comfyui/stable-diffusion-35.description": "Stable Diffusion 3.5 — модель нового поколения для генерации изображений по тексту с вариантами Large и Medium. Требует внешние файлы энкодеров CLIP и обеспечивает отличное качество изображений и соответствие подсказкам.",
  "comfyui/stable-diffusion-custom-refiner.description": "Пользовательская модель SDXL для преобразования изображений. Используйте имя файла custom_sd_lobe.safetensors; при наличии VAE — custom_sd_vae_lobe.safetensors. Поместите файлы моделей в соответствующие папки Comfy.",
  "comfyui/stable-diffusion-custom.description": "Пользовательская модель SD для генерации изображений по тексту. Используйте имя файла custom_sd_lobe.safetensors; при наличии VAE — custom_sd_vae_lobe.safetensors. Поместите файлы моделей в соответствующие папки Comfy.",
  "comfyui/stable-diffusion-refiner.description": "Модель SDXL для преобразования изображений, обеспечивающая высококачественные трансформации, включая перенос стиля, восстановление и креативные вариации.",
  "comfyui/stable-diffusion-xl.description": "SDXL — модель генерации изображений по тексту с поддержкой высокого разрешения 1024x1024, обеспечивающая лучшее качество и детализацию изображений.",
  "command-a-03-2025.description": "Command A — наша самая мощная модель на сегодняшний день, превосходно справляющаяся с использованием инструментов, агентами, RAG и многоязычными задачами. Поддерживает контекст до 256K, работает на двух GPU и обеспечивает на 150% большую пропускную способность по сравнению с Command R+ 08-2024.",
  "command-light-nightly.description": "Чтобы сократить интервал между основными релизами, мы предлагаем ночные сборки Command. Для серии command-light это называется command-light-nightly. Это самая новая и экспериментальная (возможно, нестабильная) версия, обновляется без уведомлений, поэтому не рекомендуется для продакшена.",
  "command-light.description": "Упрощённый и более быстрый вариант Command, почти такой же мощный, но с более высокой скоростью.",
  "command-nightly.description": "Чтобы сократить интервал между основными релизами, мы предлагаем ночные сборки Command. Для основной серии это называется command-nightly. Это самая новая и экспериментальная (возможно, нестабильная) версия, обновляется без уведомлений, поэтому не рекомендуется для продакшена.",
  "command-r-03-2024.description": "Command R — модель чата, следящая за инструкциями, с более высоким качеством, надёжностью и увеличенным окном контекста по сравнению с предыдущими версиями. Поддерживает сложные рабочие процессы, такие как генерация кода, RAG, использование инструментов и агентов.",
  "command-r-08-2024.description": "command-r-08-2024 — обновлённая модель Command R, выпущенная в августе 2024 года.",
  "command-r-plus-04-2024.description": "command-r-plus — псевдоним модели command-r-plus-04-2024, поэтому использование command-r-plus в API указывает на эту модель.",
  "command-r-plus-08-2024.description": "Command R+ — модель чата, следящая за инструкциями, с более высоким качеством, надёжностью и увеличенным окном контекста по сравнению с предыдущими версиями. Идеальна для сложных RAG-процессов и многошагового использования инструментов.",
  "command-r-plus.description": "Command R+ — высокопроизводительная LLM, предназначенная для реальных корпоративных сценариев и сложных приложений.",
  "command-r.description": "Command R — LLM, оптимизированная для чатов и задач с длинным контекстом, идеально подходящая для динамичного взаимодействия и управления знаниями.",
  "command-r7b-12-2024.description": "command-r7b-12-2024 — компактное и эффективное обновление, выпущенное в декабре 2024 года. Отлично справляется с задачами RAG, использования инструментов и агентов, требующих сложного многошагового рассуждения.",
  "command.description": "Модель чата, следящая за инструкциями, обеспечивающая более высокое качество и надёжность в языковых задачах, с увеличенным окном контекста по сравнению с базовыми генеративными моделями.",
  "computer-use-preview.description": "computer-use-preview — специализированная модель для инструмента \"использование компьютера\", обученная понимать и выполнять задачи, связанные с компьютером.",
  "dall-e-2.description": "Модель DALL·E второго поколения с более реалистичной и точной генерацией изображений и разрешением в 4 раза выше, чем у первого поколения.",
  "dall-e-3.description": "Последняя модель DALL·E, выпущенная в ноябре 2023 года, обеспечивает более реалистичную и точную генерацию изображений с улучшенной детализацией.",
  "databricks/dbrx-instruct.description": "DBRX Instruct обеспечивает надёжную обработку инструкций в различных отраслях.",
  "deepseek-ai/DeepSeek-OCR.description": "DeepSeek-OCR — это модель визуально-языкового типа от DeepSeek AI, ориентированная на оптическое распознавание текста (OCR) и «контекстное оптическое сжатие». Она исследует методы сжатия контекста из изображений, эффективно обрабатывает документы и преобразует их в структурированный текст (например, Markdown). Точно распознаёт текст на изображениях, подходит для оцифровки документов, извлечения текста и структурированной обработки.",
  "deepseek-ai/DeepSeek-R1-0528-Qwen3-8B.description": "DeepSeek-R1-0528-Qwen3-8B — это дистиллят модели DeepSeek-R1-0528 на базе Qwen3 8B. Она достигает уровня SOTA среди открытых моделей, превосходя Qwen3 8B на 10% в AIME 2024 и сопоставима с производительностью Qwen3-235B-thinking. Отличается выдающимися результатами в математике, программировании и логике. Использует архитектуру Qwen3-8B и токенизатор DeepSeek-R1-0528.",
  "deepseek-ai/DeepSeek-R1-0528.description": "DeepSeek R1 использует дополнительные вычислительные ресурсы и алгоритмические оптимизации постобучения для углубления рассуждений. Демонстрирует высокие результаты в математике, программировании и логике, приближаясь к лидерам, таким как o3 и Gemini 2.5 Pro.",
  "deepseek-ai/DeepSeek-R1-Distill-Llama-70B.description": "Дистиллированные модели DeepSeek-R1 используют обучение с подкреплением и cold-start данные для улучшения рассуждений и установления новых стандартов среди открытых моделей для многозадачных сценариев.",
  "deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B.description": "Дистиллированные модели DeepSeek-R1 используют обучение с подкреплением и cold-start данные для улучшения рассуждений и установления новых стандартов среди открытых моделей для многозадачных сценариев.",
  "deepseek-ai/DeepSeek-R1-Distill-Qwen-14B.description": "Дистиллированные модели DeepSeek-R1 используют обучение с подкреплением и cold-start данные для улучшения рассуждений и установления новых стандартов среди открытых моделей для многозадачных сценариев.",
  "deepseek-ai/DeepSeek-R1-Distill-Qwen-32B.description": "DeepSeek-R1-Distill-Qwen-32B — дистиллят модели Qwen2.5-32B, дообученный на 800 тысячах отобранных выборок DeepSeek-R1. Отличается выдающимися результатами в математике, программировании и логике, достигая высоких показателей на AIME 2024, MATH-500 (94.3% точности) и GPQA Diamond.",
  "deepseek-ai/DeepSeek-R1-Distill-Qwen-7B.description": "DeepSeek-R1-Distill-Qwen-7B — дистиллят модели Qwen2.5-Math-7B, дообученный на 800 тысячах отобранных выборок DeepSeek-R1. Демонстрирует высокие результаты: 92.8% на MATH-500, 55.5% на AIME 2024 и рейтинг 1189 на CodeForces для модели 7B.",
  "deepseek-ai/DeepSeek-R1.description": "DeepSeek-R1 улучшает рассуждения с помощью обучения с подкреплением и cold-start данных, устанавливая новые стандарты среди открытых моделей и превосходя OpenAI-o1-mini.",
  "deepseek-ai/DeepSeek-V2.5.description": "DeepSeek-V2.5 — это обновление моделей DeepSeek-V2-Chat и DeepSeek-Coder-V2-Instruct, объединяющее общие и программные способности. Улучшает написание текстов и следование инструкциям для лучшего соответствия предпочтениям, демонстрируя значительный прогресс на AlpacaEval 2.0, ArenaHard, AlignBench и MT-Bench.",
  "deepseek-ai/DeepSeek-V3.1-Terminus.description": "DeepSeek-V3.1-Terminus — обновлённая модель V3.1, позиционируемая как гибридный агентный LLM. Исправляет ошибки, сообщённые пользователями, повышает стабильность, согласованность языка и снижает количество смешанных китайско-английских и некорректных символов. Интегрирует режимы мышления и немышления с шаблонами чата для гибкого переключения. Также улучшает производительность Code Agent и Search Agent для более надёжного использования инструментов и выполнения многошаговых задач.",
  "deepseek-ai/DeepSeek-V3.1.description": "DeepSeek V3.1 использует гибридную архитектуру рассуждений и поддерживает как режим мышления, так и немышления.",
  "deepseek-ai/DeepSeek-V3.2-Exp.description": "DeepSeek-V3.2-Exp — экспериментальный выпуск V3.2, переходный к следующей архитектуре. Добавляет DeepSeek Sparse Attention (DSA) поверх V3.1-Terminus для повышения эффективности обучения и вывода на длинных контекстах, с оптимизациями для использования инструментов, понимания длинных документов и многошагового рассуждения. Идеально подходит для изучения более эффективного рассуждения при больших объёмах контекста.",
  "deepseek-ai/DeepSeek-V3.description": "DeepSeek-V3 — модель MoE с 671 миллиардами параметров, использующая MLA и DeepSeekMoE с балансировкой нагрузки без потерь для эффективного обучения и вывода. Предобучена на 14.8 триллионах высококачественных токенов с использованием SFT и RL, превосходит другие открытые модели и приближается к ведущим закрытым решениям.",
  "deepseek-ai/deepseek-llm-67b-chat.description": "DeepSeek LLM Chat (67B) — инновационная модель с глубоким пониманием языка и возможностью взаимодействия.",
  "deepseek-ai/deepseek-r1.description": "Современная эффективная LLM, сильная в рассуждениях, математике и программировании.",
  "deepseek-ai/deepseek-v3.1-terminus.description": "DeepSeek V3.1 — модель нового поколения для рассуждений, обладающая улучшенными возможностями для сложных рассуждений и цепочек размышлений, подходящая для задач глубокого анализа.",
  "deepseek-ai/deepseek-v3.1.description": "DeepSeek V3.1 — модель нового поколения для рассуждений, обладающая улучшенными возможностями для сложных рассуждений и цепочек размышлений, подходящая для задач глубокого анализа.",
  "deepseek-ai/deepseek-vl2.description": "DeepSeek-VL2 — модель визуально-языкового типа MoE на базе DeepSeekMoE-27B с разреженной активацией, достигающая высокой производительности при использовании всего 4.5B активных параметров. Отличается в задачах визуального QA, OCR, понимания документов/таблиц/диаграмм и визуального связывания.",
  "deepseek-chat.description": "DeepSeek V3.2 сочетает в себе логическое мышление и длину вывода для повседневных задач вопросов-ответов и агентов. На публичных бенчмарках достигает уровня GPT-5 и первым интегрирует мышление в использование инструментов, лидируя в оценках open-source агентов.",
  "deepseek-coder-33B-instruct.description": "DeepSeek Coder 33B — языковая модель для программирования, обученная на 2 триллионах токенов (87% кода, 13% китайского/английского текста). Поддерживает контекстное окно 16K и задачи заполнения в середине, обеспечивая автодополнение на уровне проекта и вставку фрагментов кода.",
  "deepseek-coder-v2.description": "DeepSeek Coder V2 — модель кода с открытым исходным кодом, демонстрирующая высокую производительность в задачах программирования, сопоставимую с GPT-4 Turbo.",
  "deepseek-coder-v2:236b.description": "DeepSeek Coder V2 — модель кода с открытым исходным кодом, демонстрирующая высокую производительность в задачах программирования, сопоставимую с GPT-4 Turbo.",
  "deepseek-ocr.description": "DeepSeek-OCR — визуально-языковая модель от DeepSeek AI, ориентированная на OCR и «контекстное оптическое сжатие». Она исследует методы сжатия контекста из изображений, эффективно обрабатывает документы и преобразует их в структурированные текстовые форматы, такие как Markdown. Точно распознаёт текст на изображениях, идеально подходит для оцифровки документов, извлечения текста и структурированной обработки.",
  "deepseek-r1-0528.description": "Полная модель 685B выпущена 28.05.2025. DeepSeek-R1 использует масштабное обучение с подкреплением на этапе постобучения, значительно улучшая логическое мышление при минимуме размеченных данных. Демонстрирует высокие результаты в математике, программировании и языковом рассуждении.",
  "deepseek-r1-250528.description": "DeepSeek R1 250528 — это полная модель логического вывода DeepSeek-R1, предназначенная для сложных математических и логических задач.",
  "deepseek-r1-70b-fast-online.description": "Быстрая версия DeepSeek R1 70B с поддержкой поиска в интернете в реальном времени, обеспечивающая быстрые ответы при сохранении высокой производительности.",
  "deepseek-r1-70b-online.description": "Стандартная версия DeepSeek R1 70B с поиском в интернете в реальном времени, подходящая для актуальных диалогов и текстовых задач.",
  "deepseek-r1-distill-llama-70b.description": "DeepSeek R1 Distill Llama 70B сочетает логическое мышление R1 с экосистемой Llama.",
  "deepseek-r1-distill-llama-8b.description": "DeepSeek-R1-Distill-Llama-8B — дистиллированная модель на основе Llama-3.1-8B, обученная на выходных данных DeepSeek R1.",
  "deepseek-r1-distill-llama.description": "deepseek-r1-distill-llama — дистиллированная модель DeepSeek-R1 на базе Llama.",
  "deepseek-r1-distill-qianfan-70b.description": "DeepSeek R1 Distill Qianfan 70B — дистиллированная модель R1 на основе Qianfan-70B с высокой ценностью.",
  "deepseek-r1-distill-qianfan-8b.description": "DeepSeek R1 Distill Qianfan 8B — дистиллированная модель R1 на базе Qianfan-8B, предназначенная для малых и средних приложений.",
  "deepseek-r1-distill-qianfan-llama-70b.description": "DeepSeek R1 Distill Qianfan Llama 70B — дистиллированная модель R1 на основе Llama-70B.",
  "deepseek-r1-distill-qwen-1.5b.description": "DeepSeek R1 Distill Qwen 1.5B — сверхлёгкая дистиллированная модель для сред с ограниченными ресурсами.",
  "deepseek-r1-distill-qwen-14b.description": "DeepSeek R1 Distill Qwen 14B — дистиллированная модель среднего размера для многосценарного применения.",
  "deepseek-r1-distill-qwen-32b.description": "DeepSeek R1 Distill Qwen 32B — дистиллированная модель R1 на базе Qwen-32B, обеспечивающая баланс между производительностью и стоимостью.",
  "deepseek-r1-distill-qwen-7b.description": "DeepSeek R1 Distill Qwen 7B — лёгкая дистиллированная модель для периферийных и корпоративных сред.",
  "deepseek-r1-distill-qwen.description": "deepseek-r1-distill-qwen — дистиллированная модель DeepSeek-R1 на базе Qwen.",
  "deepseek-r1-fast-online.description": "Быстрая полная версия DeepSeek R1 с поиском в интернете в реальном времени, объединяющая возможности масштаба 671B и ускоренный отклик.",
  "deepseek-r1-online.description": "Полная версия DeepSeek R1 с 671B параметрами и поиском в интернете в реальном времени, обеспечивающая улучшенное понимание и генерацию.",
  "deepseek-r1.description": "DeepSeek-R1 использует данные холодного старта до этапа RL и демонстрирует сопоставимую с OpenAI-o1 производительность в математике, программировании и логическом мышлении.",
  "deepseek-reasoner.description": "DeepSeek V3.2 Thinking — модель глубокого рассуждения, которая генерирует цепочку размышлений перед выводом для повышения точности, демонстрируя лучшие результаты в соревнованиях и уровень рассуждения, сопоставимый с Gemini-3.0-Pro.",
  "deepseek-v2.description": "DeepSeek V2 — эффективная модель MoE для экономичной обработки.",
  "deepseek-v2:236b.description": "DeepSeek V2 236B — модель DeepSeek, ориентированная на программирование, с высокой способностью к генерации кода.",
  "deepseek-v3-0324.description": "DeepSeek-V3-0324 — модель MoE с 671B параметрами, выделяющаяся в программировании, технических задачах, понимании контекста и работе с длинными текстами.",
  "deepseek-v3.1-terminus.description": "DeepSeek-V3.1-Terminus — оптимизированная для терминальных устройств LLM от DeepSeek.",
  "deepseek-v3.1-think-250821.description": "DeepSeek V3.1 Think 250821 — модель глубокого мышления, соответствующая версии Terminus, созданная для высокоэффективного логического вывода.",
  "deepseek-v3.1.description": "DeepSeek-V3.1 — гибридная модель логического вывода нового поколения от DeepSeek, поддерживающая режимы с мышлением и без, с более высокой эффективностью мышления по сравнению с DeepSeek-R1-0528. Оптимизации после обучения значительно улучшают использование инструментов агентами и выполнение задач. Поддерживает окно контекста 128k и до 64k выходных токенов.",
  "deepseek-v3.1:671b.description": "DeepSeek V3.1 — модель логического вывода следующего поколения с улучшенным сложным мышлением и цепочкой рассуждений, подходящая для задач, требующих глубокого анализа.",
  "deepseek-v3.2-exp.description": "deepseek-v3.2-exp внедряет разреженное внимание для повышения эффективности обучения и вывода на длинных текстах по более низкой цене, чем deepseek-v3.1.",
  "deepseek-v3.2-think.description": "DeepSeek V3.2 Think — полноценная модель глубокого мышления с усиленным длинноцепочечным рассуждением.",
  "deepseek-v3.2.description": "DeepSeek-V3.2 — первая гибридная модель логического вывода от DeepSeek, объединяющая мышление с использованием инструментов. Эффективная архитектура снижает потребление ресурсов, масштабное обучение с подкреплением повышает способности, а синтетические данные задач улучшают обобщение. В совокупности модель достигает производительности, сопоставимой с GPT-5-High, при значительно меньших вычислительных затратах и времени ожидания пользователя.",
  "deepseek-v3.description": "DeepSeek-V3 — мощная модель MoE с 671B общих параметров и 37B активных на токен.",
  "deepseek-vl2-small.description": "DeepSeek VL2 Small — лёгкая мультимодальная модель для сред с ограниченными ресурсами и высокой нагрузкой.",
  "deepseek-vl2.description": "DeepSeek VL2 — мультимодальная модель для понимания изображений и текста и точного визуального вопросо-ответа.",
  "deepseek/deepseek-chat-v3-0324.description": "DeepSeek V3 — модель MoE с 685B параметрами и последняя итерация флагманской серии чатов DeepSeek.\n\nОснована на [DeepSeek V3](/deepseek/deepseek-chat-v3) и демонстрирует высокую производительность в различных задачах.",
  "deepseek/deepseek-chat-v3-0324:free.description": "DeepSeek V3 — модель MoE с 685B параметрами и последняя итерация флагманской серии чатов DeepSeek.\n\nОснована на [DeepSeek V3](/deepseek/deepseek-chat-v3) и демонстрирует высокую производительность в различных задачах.",
  "deepseek/deepseek-chat-v3.1.description": "DeepSeek-V3.1 — гибридная модель логического вывода с длинным контекстом от DeepSeek, поддерживающая смешанные режимы мышления/без мышления и интеграцию инструментов.",
  "deepseek/deepseek-chat.description": "DeepSeek-V3 — высокопроизводительная гибридная модель логического вывода от DeepSeek для сложных задач и интеграции инструментов.",
  "deepseek/deepseek-r1-0528.description": "DeepSeek R1 0528 — обновлённый вариант, ориентированный на открытую доступность и более глубокое логическое мышление.",
  "deepseek/deepseek-r1-0528:free.description": "DeepSeek-R1 значительно улучшает логическое мышление при минимуме размеченных данных и выводит цепочку рассуждений перед финальным ответом для повышения точности.",
  "deepseek/deepseek-r1-distill-llama-70b.description": "DeepSeek R1 Distill Llama 70B — дистиллированная LLM на основе Llama 3.3 70B, дообученная на выходных данных DeepSeek R1 для достижения конкурентной производительности с передовыми моделями.",
  "deepseek/deepseek-r1-distill-llama-8b.description": "DeepSeek R1 Distill Llama 8B — дистиллированная LLM на основе Llama-3.1-8B-Instruct, обученная на выходных данных DeepSeek R1.",
  "deepseek/deepseek-r1-distill-qwen-14b.description": "DeepSeek R1 Distill Qwen 14B — дистиллированная LLM на основе Qwen 2.5 14B, обученная на выходных данных DeepSeek R1. Превосходит OpenAI o1-mini по нескольким бенчмаркам, достигая передовых результатов среди плотных моделей. Основные показатели:\nAIME 2024 pass@1: 69.7\nMATH-500 pass@1: 93.9\nРейтинг CodeForces: 1481\nДообучение на выходных данных DeepSeek R1 обеспечивает конкурентную производительность с более крупными моделями.",
  "deepseek/deepseek-r1-distill-qwen-32b.description": "DeepSeek R1 Distill Qwen 32B — дистиллированная LLM на основе Qwen 2.5 32B, обученная на выходных данных DeepSeek R1. Превосходит OpenAI o1-mini по нескольким бенчмаркам, достигая передовых результатов среди плотных моделей. Основные показатели:\nAIME 2024 pass@1: 72.6\nMATH-500 pass@1: 94.3\nРейтинг CodeForces: 1691\nДообучение на выходных данных DeepSeek R1 обеспечивает конкурентную производительность с более крупными моделями.",
  "deepseek/deepseek-r1.description": "DeepSeek R1 обновлён до версии DeepSeek-R1-0528. Благодаря увеличенным вычислениям и алгоритмическим оптимизациям после обучения, модель значительно улучшает глубину и качество логического мышления. Демонстрирует высокие результаты в математике, программировании и логике, приближаясь к лидерам, таким как o3 и Gemini 2.5 Pro.",
  "deepseek/deepseek-r1/community.description": "DeepSeek R1 — последняя открытая модель от команды DeepSeek с очень высокой производительностью в логическом мышлении, особенно в математике, программировании и рассуждении, сопоставимая с OpenAI o1.",
  "deepseek/deepseek-r1:free.description": "DeepSeek-R1 значительно улучшает логическое мышление при минимуме размеченных данных и выводит цепочку рассуждений перед финальным ответом для повышения точности.",
  "deepseek/deepseek-reasoner.description": "DeepSeek-V3 Thinking (reasoner) — экспериментальная модель логического мышления от DeepSeek, подходящая для задач высокой сложности.",
  "deepseek/deepseek-v3.1-base.description": "DeepSeek V3.1 Base — улучшенная версия модели DeepSeek V3.",
  "deepseek/deepseek-v3.description": "Быстрая универсальная LLM с улучшенным логическим мышлением.",
  "deepseek/deepseek-v3/community.description": "DeepSeek-V3 обеспечивает значительный прорыв в скорости логического мышления по сравнению с предыдущими моделями. Занимает первое место среди открытых моделей и соперничает с самыми продвинутыми закрытыми решениями. DeepSeek-V3 использует Multi-Head Latent Attention (MLA) и архитектуру DeepSeekMoE, проверенные в DeepSeek-V2. Также внедрена вспомогательная стратегия без потерь для балансировки нагрузки и цель многотокенного предсказания для повышения производительности.",
  "deepseek_r1.description": "DeepSeek-R1 — модель логического мышления, основанная на обучении с подкреплением, решающая проблемы повторов и читаемости. До этапа RL использует данные холодного старта для повышения качества рассуждений. Сопоставима с OpenAI-o1 в задачах по математике, программированию и логике, с тщательно продуманным обучением для улучшения общих результатов.",
  "deepseek_r1_distill_llama_70b.description": "DeepSeek-R1-Distill-Llama-70B — дистиллированная модель на основе Llama-3.3-70B-Instruct. Является частью серии DeepSeek-R1, дообучена на выборках, сгенерированных DeepSeek-R1, и демонстрирует высокие результаты в математике, программировании и логике.",
  "deepseek_r1_distill_qwen_14b.description": "DeepSeek-R1-Distill-Qwen-14B — дистиллированная модель на основе Qwen2.5-14B, дообученная на 800K отобранных выборках, сгенерированных DeepSeek-R1, обеспечивая высокое качество логического мышления.",
  "deepseek_r1_distill_qwen_32b.description": "DeepSeek-R1-Distill-Qwen-32B — дистиллированная модель на основе Qwen2.5-32B, дообученная на 800K отобранных выборках, сгенерированных DeepSeek-R1, превосходящая в математике, программировании и логике.",
  "devstral-2:123b.description": "Devstral 2 123B превосходно использует инструменты для анализа кодовой базы, редактирования нескольких файлов и поддержки агентов в области программной инженерии.",
  "doubao-1.5-lite-32k.description": "Doubao-1.5-lite — новая облегчённая модель с ультрабыстрым откликом, обеспечивающая высокое качество и низкую задержку.",
  "doubao-1.5-pro-256k.description": "Doubao-1.5-pro-256k — комплексное обновление модели Doubao-1.5-Pro, повышающее общую производительность на 10%. Поддерживает контекстное окно 256k и до 12k токенов вывода, обеспечивая высокую производительность, расширенное окно и отличную ценность для широкого спектра задач.",
  "doubao-1.5-pro-32k.description": "Doubao-1.5-pro — флагманская модель нового поколения с улучшениями по всем направлениям, превосходящая в знаниях, программировании и рассуждении.",
  "doubao-1.5-thinking-pro-m.description": "Doubao-1.5 — новая модель глубокого рассуждения (версия m включает нативное мультимодальное глубокое рассуждение), превосходящая в математике, программировании, научном анализе и общих задачах, таких как креативное письмо. Достигает или приближается к топовым результатам на бенчмарках AIME 2024, Codeforces и GPQA. Поддерживает контекстное окно 128k и вывод до 16k токенов.",
  "doubao-1.5-thinking-pro.description": "Doubao-1.5 — новая модель глубокого рассуждения, превосходящая в математике, программировании, научном анализе и общих задачах, таких как креативное письмо. Достигает или приближается к топовым результатам на бенчмарках AIME 2024, Codeforces и GPQA. Поддерживает контекстное окно 128k и вывод до 16k токенов.",
  "doubao-1.5-thinking-vision-pro.description": "Новая визуальная модель глубокого рассуждения с улучшенным мультимодальным пониманием и логикой, достигающая SOTA-результатов на 37 из 59 публичных бенчмарков.",
  "doubao-1.5-ui-tars.description": "Doubao-1.5-UI-TARS — нативная модель-агент, ориентированная на графический интерфейс, которая взаимодействует с интерфейсами через человекоподобное восприятие, рассуждение и действия.",
  "doubao-1.5-vision-lite.description": "Doubao-1.5-vision-lite — обновлённая мультимодальная модель, поддерживающая изображения любого разрешения и экстремальных соотношений сторон, улучшая визуальное рассуждение, распознавание документов, понимание деталей и следование инструкциям. Поддерживает контекстное окно 128k и до 16k токенов вывода.",
  "doubao-1.5-vision-pro-32k.description": "Doubao-1.5-vision-pro — обновлённая мультимодальная модель, поддерживающая изображения любого разрешения и экстремальных соотношений сторон, улучшая визуальное рассуждение, распознавание документов, понимание деталей и следование инструкциям.",
  "doubao-1.5-vision-pro.description": "Doubao-1.5-vision-pro — обновлённая мультимодальная модель, поддерживающая изображения любого разрешения и экстремальных соотношений сторон, улучшая визуальное рассуждение, распознавание документов, понимание деталей и следование инструкциям.",
  "doubao-lite-128k.description": "Ультрабыстрый отклик с лучшей ценностью, предлагая более гибкие варианты для различных сценариев. Поддерживает рассуждение и дообучение с контекстным окном 128k.",
  "doubao-lite-32k.description": "Ультрабыстрый отклик с лучшей ценностью, предлагая более гибкие варианты для различных сценариев. Поддерживает рассуждение и дообучение с контекстным окном 32k.",
  "doubao-lite-4k.description": "Ультрабыстрый отклик с лучшей ценностью, предлагая более гибкие варианты для различных сценариев. Поддерживает рассуждение и дообучение с контекстным окном 4k.",
  "doubao-pro-256k.description": "Флагманская модель с наилучшей производительностью для сложных задач, демонстрирующая отличные результаты в вопросах по справочным данным, суммировании, создании контента, классификации текста и ролевых играх. Поддерживает рассуждение и дообучение с контекстным окном 256k.",
  "doubao-pro-32k.description": "Флагманская модель с наилучшей производительностью для сложных задач, демонстрирующая отличные результаты в вопросах по справочным данным, суммировании, создании контента, классификации текста и ролевых играх. Поддерживает рассуждение и дообучение с контекстным окном 32k.",
  "doubao-seed-1.6-flash.description": "Doubao-Seed-1.6-flash — ультрабыстрая мультимодальная модель глубокого рассуждения с TPOT до 10 мс. Поддерживает текст и изображения, превосходит предыдущую lite-модель в понимании текста и сопоставима с pro-моделями в области зрения. Поддерживает контекстное окно 256k и до 16k токенов вывода.",
  "doubao-seed-1.6-lite.description": "Doubao-Seed-1.6-lite — новая мультимодальная модель глубокого рассуждения с регулируемой степенью рассуждения (минимальная, низкая, средняя, высокая), обеспечивающая лучшую ценность и отличный выбор для повседневных задач. Поддерживает контекст до 256k.",
  "doubao-seed-1.6-thinking.description": "Doubao-Seed-1.6-thinking значительно усиливает рассуждение, улучшая ключевые способности в программировании, математике и логике по сравнению с Doubao-1.5-thinking-pro, а также добавляет понимание изображений. Поддерживает контекстное окно 256k и до 16k токенов вывода.",
  "doubao-seed-1.6-vision.description": "Doubao-Seed-1.6-vision — визуальная модель глубокого рассуждения с улучшенным мультимодальным пониманием и логикой для образования, анализа изображений, инспекции/безопасности и визуального поиска с вопросами и ответами. Поддерживает контекст до 256k и до 64k токенов вывода.",
  "doubao-seed-1.6.description": "Doubao-Seed-1.6 — новая мультимодальная модель глубокого рассуждения с режимами авто, мышления и без мышления. В режиме без мышления значительно превосходит Doubao-1.5-pro/250115. Поддерживает контекст до 256k и до 16k токенов вывода.",
  "doubao-seed-1.8.description": "Doubao-Seed-1.8 обладает улучшенными возможностями мультимодального понимания и работы в роли агента, поддерживает ввод текста/изображений/видео и кэширование контекста, обеспечивая выдающуюся производительность в сложных задачах.",
  "doubao-seed-code.description": "Doubao-Seed-Code глубоко оптимизирован для агентного программирования, поддерживает мультимодальный ввод (текст/изображение/видео) и контекстное окно 256k, совместим с API Anthropic и подходит для программирования, понимания изображений и рабочих процессов агентов.",
  "doubao-seededit-3-0-i2i-250628.description": "Модель изображений Doubao от ByteDance Seed поддерживает ввод текста и изображений с высококачественной и управляемой генерацией изображений. Поддерживает редактирование изображений по тексту с размерами вывода от 512 до 1536 по длинной стороне.",
  "doubao-seedream-3-0-t2i-250415.description": "Seedream 3.0 — модель генерации изображений от ByteDance Seed, поддерживающая ввод текста и изображений с высококачественной и управляемой генерацией. Генерирует изображения по текстовым подсказкам.",
  "doubao-seedream-4-0-250828.description": "Seedream 4.0 — модель генерации изображений от ByteDance Seed, поддерживающая ввод текста и изображений с высококачественной и управляемой генерацией. Генерирует изображения по текстовым подсказкам.",
  "doubao-vision-lite-32k.description": "Doubao-vision — мультимодальная модель от Doubao с сильным пониманием изображений и логикой, а также точным следованием инструкциям. Отлично справляется с извлечением информации из изображений и задачами визуального рассуждения, расширяя возможности визуальных вопросов и ответов.",
  "doubao-vision-pro-32k.description": "Doubao-vision — мультимодальная модель от Doubao с сильным пониманием изображений и логикой, а также точным следованием инструкциям. Отлично справляется с извлечением информации из изображений и задачами визуального рассуждения, расширяя возможности визуальных вопросов и ответов.",
  "emohaa.description": "Emohaa — модель для поддержки психического здоровья с профессиональными навыками консультирования, помогающая пользователям разобраться в эмоциональных проблемах.",
  "ernie-4.5-0.3b.description": "ERNIE 4.5 0.3B — легковесная модель с открытым исходным кодом для локального и кастомизированного развертывания.",
  "ernie-4.5-21b-a3b.description": "ERNIE 4.5 21B A3B — крупная модель с открытым исходным кодом, обладающая улучшенными возможностями понимания и генерации.",
  "ernie-4.5-300b-a47b.description": "ERNIE 4.5 300B A47B — сверхкрупная модель MoE от Baidu ERNIE с выдающимися способностями к рассуждению.",
  "ernie-4.5-8k-preview.description": "ERNIE 4.5 8K Preview — модель с контекстом 8K для предварительной оценки возможностей ERNIE 4.5.",
  "ernie-4.5-turbo-128k-preview.description": "Предварительная версия ERNIE 4.5 Turbo 128K с возможностями уровня релиза, подходящая для интеграции и тестирования.",
  "ernie-4.5-turbo-128k.description": "ERNIE 4.5 Turbo 128K — высокопроизводительная универсальная модель с поддержкой поиска и вызова инструментов для задач Вопрос-Ответ, программирования и агентов.",
  "ernie-4.5-turbo-32k.description": "ERNIE 4.5 Turbo 32K — версия со средним контекстом для Вопрос-Ответ, поиска в базе знаний и многотурового диалога.",
  "ernie-4.5-turbo-latest.description": "Актуальная версия ERNIE 4.5 Turbo с оптимизированной общей производительностью, идеально подходит в качестве основной модели для продакшена.",
  "ernie-4.5-turbo-vl-32k-preview.description": "ERNIE 4.5 Turbo VL 32K Preview — предварительная мультимодальная модель с контекстом 32K для оценки возможностей в области зрения.",
  "ernie-4.5-turbo-vl-32k.description": "ERNIE 4.5 Turbo VL 32K — мультимодальная модель со средне-длинным контекстом для понимания длинных документов и изображений.",
  "ernie-4.5-turbo-vl-latest.description": "ERNIE 4.5 Turbo VL Latest — новейшая мультимодальная модель с улучшенным пониманием изображений и текста, а также рассуждением.",
  "ernie-4.5-turbo-vl-preview.description": "ERNIE 4.5 Turbo VL Preview — предварительная мультимодальная модель для понимания и генерации изображений и текста, подходит для визуального Вопрос-Ответ и анализа контента.",
  "ernie-4.5-turbo-vl.description": "ERNIE 4.5 Turbo VL — зрелая мультимодальная модель для промышленного понимания и распознавания изображений и текста.",
  "ernie-4.5-vl-28b-a3b.description": "ERNIE 4.5 VL 28B A3B — мультимодальная модель с открытым исходным кодом для понимания изображений и текста, а также рассуждения.",
  "ernie-5.0-thinking-latest.description": "Wenxin 5.0 Thinking — флагманская модель с нативной полной мультимодальностью, объединяющая текст, изображение, аудио и видео. Обеспечивает широкие улучшения для сложных задач Вопрос-Ответ, творчества и агентов.",
  "ernie-5.0-thinking-preview.description": "Wenxin 5.0 Thinking Preview — предварительная версия флагманской мультимодальной модели с объединением текста, изображения, аудио и видео. Обеспечивает широкие улучшения для сложных задач Вопрос-Ответ, творчества и агентов.",
  "ernie-char-8k.description": "ERNIE Character 8K — модель диалога с персонажем для создания IP-образов и длительного общения.",
  "ernie-char-fiction-8k-preview.description": "ERNIE Character Fiction 8K Preview — предварительная модель для создания персонажей и сюжетов, предназначенная для оценки и тестирования.",
  "ernie-char-fiction-8k.description": "ERNIE Character Fiction 8K — модель персонажа для написания романов и создания сюжетов, подходит для генерации длинных историй.",
  "ernie-irag-edit.description": "ERNIE iRAG Edit — модель редактирования изображений с поддержкой стирания, перерисовки и генерации вариантов.",
  "ernie-lite-8k.description": "ERNIE Lite 8K — легковесная универсальная модель для повседневных задач Вопрос-Ответ и генерации контента с ограниченным бюджетом.",
  "ernie-lite-pro-128k.description": "ERNIE Lite Pro 128K — легковесная высокопроизводительная модель для сценариев с чувствительностью к задержке и стоимости.",
  "ernie-novel-8k.description": "ERNIE Novel 8K предназначена для написания длинных романов и IP-сюжетов с участием нескольких персонажей.",
  "ernie-speed-128k.description": "ERNIE Speed 128K — модель без платы за ввод/вывод для понимания длинных текстов и масштабного тестирования.",
  "ernie-speed-8k.description": "ERNIE Speed 8K — бесплатная и быстрая модель для повседневного общения и простых текстовых задач.",
  "ernie-speed-pro-128k.description": "ERNIE Speed Pro 128K — модель с высокой пропускной способностью и ценностью для масштабных онлайн-сервисов и корпоративных приложений.",
  "ernie-tiny-8k.description": "ERNIE Tiny 8K — ультралегкая модель для простых задач Вопрос-Ответ, классификации и недорогого вывода.",
  "ernie-x1-turbo-32k.description": "ERNIE X1 Turbo 32K — быстрая модель мышления с контекстом 32K для сложного рассуждения и многотурового общения.",
  "ernie-x1.1-preview.description": "ERNIE X1.1 Preview — предварительная версия модели мышления для оценки и тестирования.",
  "fal-ai/bytedance/seedream/v4.description": "Seedream 4.0 от ByteDance Seed поддерживает ввод текста и изображений для высококачественной и управляемой генерации изображений по подсказкам.",
  "fal-ai/flux-kontext/dev.description": "Модель FLUX.1, ориентированная на редактирование изображений, поддерживает ввод текста и изображений.",
  "fal-ai/flux-pro/kontext.description": "FLUX.1 Kontext [pro] принимает текст и эталонные изображения, позволяя выполнять локальные правки и сложные глобальные трансформации сцены.",
  "fal-ai/flux/krea.description": "Flux Krea [dev] — модель генерации изображений с эстетическим уклоном в сторону более реалистичных и естественных изображений.",
  "fal-ai/flux/schnell.description": "FLUX.1 [schnell] — модель генерации изображений с 12 миллиардами параметров, созданная для быстрой и качественной генерации.",
  "fal-ai/hunyuan-image/v3.description": "Мощная нативная мультимодальная модель генерации изображений.",
  "fal-ai/imagen4/preview.description": "Модель генерации изображений высокого качества от Google.",
  "fal-ai/nano-banana.description": "Nano Banana — новейшая, самая быстрая и эффективная нативная мультимодальная модель от Google, поддерживающая генерацию и редактирование изображений в диалоговом режиме.",
  "fal-ai/qwen-image-edit.description": "Профессиональная модель редактирования изображений от команды Qwen, поддерживающая семантические и визуальные правки, точное редактирование текста на китайском/английском, перенос стиля, поворот и многое другое.",
  "fal-ai/qwen-image.description": "Мощная модель генерации изображений от команды Qwen с отличной отрисовкой китайского текста и разнообразными визуальными стилями.",
  "flux-1-schnell.description": "Модель преобразования текста в изображение с 12 миллиардами параметров от Black Forest Labs, использующая латентную диффузию с дистилляцией для генерации качественных изображений за 1–4 шага. Конкурирует с закрытыми аналогами и распространяется по лицензии Apache-2.0 для личного, исследовательского и коммерческого использования.",
  "flux-dev.description": "FLUX.1 [dev] — модель с открытыми весами для некоммерческого использования. Сохраняет почти профессиональное качество изображений и следование инструкциям при более эффективной работе и лучшем использовании ресурсов по сравнению со стандартными моделями аналогичного размера.",
  "flux-kontext-max.description": "Передовая генерация и редактирование изображений с учётом контекста, объединяющая текст и изображения для точных и согласованных результатов.",
  "flux-kontext-pro.description": "Передовая генерация и редактирование изображений с учётом контекста, объединяющая текст и изображения для точных и согласованных результатов.",
  "flux-merged.description": "FLUX.1-merged объединяет глубокие возможности, исследованные в «DEV», с высокой скоростью «Schnell», расширяя границы производительности и области применения.",
  "flux-pro-1.1-ultra.description": "Генерация изображений сверхвысокого разрешения с выходом 4 МП, создаёт чёткие изображения за 10 секунд.",
  "flux-pro-1.1.description": "Обновлённая профессиональная модель генерации изображений с отличным качеством и точным следованием подсказкам.",
  "flux-pro.description": "Коммерческая модель генерации изображений высшего уровня с непревзойдённым качеством и разнообразием результатов.",
  "flux-schnell.description": "FLUX.1 [schnell] — самая продвинутая open-source модель с малым числом шагов, превосходящая аналогичные модели и даже сильные недистиллированные модели, такие как Midjourney v6.0 и DALL-E 3 (HD). Тщательно настроена для сохранения разнообразия предобучения, значительно улучшая визуальное качество, следование инструкциям, вариативность размеров/пропорций, работу со шрифтами и разнообразие вывода.",
  "flux.1-schnell.description": "FLUX.1-schnell — высокопроизводительная модель генерации изображений для быстрой генерации в разных стилях.",
  "gemini-1.0-pro-001.description": "Gemini 1.0 Pro 001 (Tuning) обеспечивает стабильную и настраиваемую производительность для сложных задач.",
  "gemini-1.0-pro-002.description": "Gemini 1.0 Pro 002 (Tuning) обеспечивает мощную мультимодальную поддержку для сложных задач.",
  "gemini-1.0-pro-latest.description": "Gemini 1.0 Pro — высокопроизводительная модель ИИ от Google, предназначенная для масштабирования широкого спектра задач.",
  "gemini-1.5-flash-001.description": "Gemini 1.5 Flash 001 — эффективная мультимодальная модель для масштабируемого применения.",
  "gemini-1.5-flash-002.description": "Gemini 1.5 Flash 002 — эффективная мультимодальная модель, созданная для широкого внедрения.",
  "gemini-1.5-flash-8b-exp-0924.description": "Gemini 1.5 Flash 8B 0924 — новейшая экспериментальная модель с заметными улучшениями в текстовых и мультимодальных сценариях.",
  "gemini-1.5-flash-8b-latest.description": "Gemini 1.5 Flash 8B — эффективная мультимодальная модель, созданная для широкого внедрения.",
  "gemini-1.5-flash-8b.description": "Gemini 1.5 Flash 8B — эффективная мультимодальная модель для масштабируемого применения.",
  "gemini-1.5-flash-exp-0827.description": "Gemini 1.5 Flash 0827 обеспечивает оптимизированную мультимодальную обработку для сложных задач.",
  "gemini-1.5-flash-latest.description": "Gemini 1.5 Flash — новейшая мультимодальная модель ИИ от Google с быстрой обработкой, поддержкой текста, изображений и видео для эффективного масштабирования задач.",
  "gemini-1.5-pro-001.description": "Gemini 1.5 Pro 001 — масштабируемое мультимодальное ИИ-решение для сложных задач.",
  "gemini-1.5-pro-002.description": "Gemini 1.5 Pro 002 — новейшая модель, готовая к производству, с более качественным выводом, особенно в математике, длинном контексте и визуальных задачах.",
  "gemini-1.5-pro-exp-0801.description": "Gemini 1.5 Pro 0801 обеспечивает мощную мультимодальную обработку с большей гибкостью для разработки приложений.",
  "gemini-1.5-pro-exp-0827.description": "Gemini 1.5 Pro 0827 использует последние оптимизации для более эффективной мультимодальной обработки.",
  "gemini-1.5-pro-latest.description": "Gemini 1.5 Pro поддерживает до 2 миллионов токенов, являясь идеальной мультимодальной моделью среднего размера для сложных задач.",
  "gemini-2.0-flash-001.description": "Gemini 2.0 Flash предлагает функции следующего поколения, включая исключительную скорость, нативное использование инструментов, мультимодальную генерацию и контекст до 1 миллиона токенов.",
  "gemini-2.0-flash-exp-image-generation.description": "Экспериментальная модель Gemini 2.0 Flash с поддержкой генерации изображений.",
  "gemini-2.0-flash-exp.description": "Вариант Gemini 2.0 Flash, оптимизированный по стоимости и задержке.",
  "gemini-2.0-flash-lite-001.description": "Вариант Gemini 2.0 Flash, оптимизированный по стоимости и задержке.",
  "gemini-2.0-flash-lite.description": "Вариант Gemini 2.0 Flash, оптимизированный по стоимости и задержке.",
  "gemini-2.0-flash.description": "Gemini 2.0 Flash предлагает функции следующего поколения, включая исключительную скорость, нативное использование инструментов, мультимодальную генерацию и контекст до 1 миллиона токенов.",
  "meta.llama3-8b-instruct-v1:0.description": "Meta Llama 3 — это открытая LLM для разработчиков, исследователей и предприятий, созданная для поддержки создания, экспериментов и ответственного масштабирования идей генеративного ИИ. Являясь частью основы для глобальных инноваций сообщества, она хорошо подходит для ограниченных вычислительных ресурсов, устройств на периферии и ускоренного обучения.",
  "meta/Llama-3.2-11B-Vision-Instruct.description": "Модель с высокой способностью к визуальному рассуждению на изображениях высокого разрешения, подходящая для приложений визуального понимания.",
  "meta/Llama-3.2-90B-Vision-Instruct.description": "Продвинутая модель визуального рассуждения для агентов, ориентированных на визуальное понимание.",
  "meta/Llama-3.3-70B-Instruct.description": "Llama 3.3 — самая продвинутая многоязычная открытая модель Llama, обеспечивающая производительность, близкую к 405B, при очень низкой стоимости. Основана на архитектуре Transformer и улучшена с помощью SFT и RLHF для повышения полезности и безопасности. Версия с настройкой под инструкции оптимизирована для многоязычного общения и превосходит многие открытые и закрытые модели чатов по отраслевым бенчмаркам. Актуальность знаний: декабрь 2023.",
  "meta/Meta-Llama-3-70B-Instruct.description": "Мощная модель с 70 миллиардами параметров, превосходно справляющаяся с рассуждениями, программированием и широким спектром языковых задач.",
  "meta/Meta-Llama-3-8B-Instruct.description": "Универсальная модель с 8 миллиардами параметров, оптимизированная для общения и генерации текста.",
  "meta/Meta-Llama-3.1-405B-Instruct.description": "Модель Llama 3.1 с настройкой под инструкции, оптимизированная для многоязычного общения, демонстрирует высокие результаты по отраслевым бенчмаркам среди открытых и закрытых моделей чатов.",
  "meta/Meta-Llama-3.1-70B-Instruct.description": "Модель Llama 3.1 с настройкой под инструкции, оптимизированная для многоязычного общения, демонстрирует высокие результаты по отраслевым бенчмаркам среди открытых и закрытых моделей чатов.",
  "meta/Meta-Llama-3.1-8B-Instruct.description": "Модель Llama 3.1 с настройкой под инструкции, оптимизированная для многоязычного общения, демонстрирует высокие результаты по отраслевым бенчмаркам среди открытых и закрытых моделей чатов.",
  "meta/llama-3-70b.description": "Открытая модель с 70 миллиардами параметров, дообученная Meta для следования инструкциям, предоставляется через Groq на аппаратуре LPU для быстрого и эффективного вывода.",
  "meta/llama-3-8b.description": "Открытая модель с 8 миллиардами параметров, дообученная Meta для следования инструкциям, предоставляется через Groq на аппаратуре LPU для быстрого и эффективного вывода.",
  "meta/llama-3.1-405b-instruct.description": "Продвинутая LLM, поддерживающая генерацию синтетических данных, дистилляцию знаний и рассуждение для чат-ботов, программирования и специализированных задач.",
  "meta/llama-3.1-70b-instruct.description": "Создана для сложных диалогов с отличным пониманием контекста, рассуждением и генерацией текста.",
  "meta/llama-3.1-70b.description": "Обновлённая Meta Llama 3 70B Instruct с контекстом 128K, поддержкой многоязычности и улучшенным рассуждением.",
  "meta/llama-3.1-8b-instruct.description": "Передовая модель с высоким уровнем понимания языка, рассуждения и генерации текста.",
  "meta/llama-3.1-8b.description": "Llama 3.1 8B поддерживает окно контекста 128K, идеально подходит для общения в реальном времени и анализа данных, обеспечивая значительную экономию по сравнению с более крупными моделями. Предоставляется через Groq на аппаратуре LPU для быстрого и эффективного вывода.",
  "meta/llama-3.2-11b-vision-instruct.description": "Передовая модель визуально-языкового понимания, превосходно справляющаяся с высококачественным рассуждением по изображениям.",
  "meta/llama-3.2-11b.description": "Модель с настройкой под инструкции для визуального рассуждения (ввод: текст+изображение, вывод: текст), оптимизированная для визуального распознавания, рассуждения, описания и общего визуального QA.",
  "meta/llama-3.2-1b-instruct.description": "Передовая компактная языковая модель с высоким уровнем понимания, рассуждения и генерации текста.",
  "meta/llama-3.2-1b.description": "Модель только для текста, предназначенная для использования на устройствах, таких как многоязычный локальный поиск, суммирование и переформулирование.",
  "meta/llama-3.2-3b-instruct.description": "Передовая компактная языковая модель с высоким уровнем понимания, рассуждения и генерации текста.",
  "meta/llama-3.2-3b.description": "Модель только для текста, дообученная для использования на устройствах, таких как многоязычный локальный поиск, суммирование и переформулирование.",
  "meta/llama-3.2-90b-vision-instruct.description": "Передовая модель визуально-языкового понимания, превосходно справляющаяся с высококачественным рассуждением по изображениям.",
  "meta/llama-3.2-90b.description": "Модель с настройкой под инструкции для визуального рассуждения (ввод: текст+изображение, вывод: текст), оптимизированная для визуального распознавания, рассуждения, описания и общего визуального QA.",
  "meta/llama-3.3-70b-instruct.description": "Продвинутая LLM, сильная в рассуждении, математике, здравом смысле и вызове функций.",
  "meta/llama-3.3-70b.description": "Идеальный баланс производительности и эффективности. Создана для высокопроизводительного разговорного ИИ в создании контента, корпоративных приложениях и исследованиях, с высоким уровнем понимания языка для суммирования, классификации, анализа тональности и генерации кода.",
  "meta/llama-4-maverick.description": "Семейство Llama 4 — это нативные мультимодальные модели ИИ, поддерживающие текст и мультимодальные взаимодействия, использующие MoE для передового понимания текста и изображений. Llama 4 Maverick — это модель с 17B параметрами и 128 экспертами, предоставляемая DeepInfra.",
  "meta/llama-4-scout.description": "Семейство Llama 4 — это нативные мультимодальные модели ИИ, поддерживающие текст и мультимодальные взаимодействия, использующие MoE для передового понимания текста и изображений. Llama 4 Scout — это модель с 17B параметрами и 16 экспертами, предоставляемая DeepInfra.",
  "mistralai/Mistral-7B-v0.1.description": "Mistral 7B — компактная, но высокопроизводительная модель, хорошо подходит для пакетной обработки и простых задач, таких как классификация и генерация текста, с уверенными логическими способностями.",
  "mistralai/Mixtral-8x22B-Instruct-v0.1.description": "Mixtral-8x22B Instruct (141B) — очень крупная языковая модель для работы с тяжёлыми нагрузками.",
  "mistralai/Mixtral-8x7B-Instruct-v0.1.description": "Mixtral-8x7B Instruct (46.7B) обладает высокой пропускной способностью для обработки данных в крупном масштабе.",
  "mistralai/Mixtral-8x7B-v0.1.description": "Mixtral 8x7B — разреженная модель MoE, ускоряющая вывод, подходит для многоязычных задач и генерации кода.",
  "mistralai/mistral-nemo.description": "Mistral Nemo — модель на 7.3B параметров с поддержкой нескольких языков и высокой производительностью в программировании.",
  "mixtral-8x7b-32768.description": "Mixtral 8x7B обеспечивает отказоустойчивую параллельную обработку для сложных задач.",
  "mixtral.description": "Mixtral — модель MoE от Mistral AI с открытыми весами, поддерживающая генерацию кода и понимание языка.",
  "mixtral:8x22b.description": "Mixtral — модель MoE от Mistral AI с открытыми весами, поддерживающая генерацию кода и понимание языка.",
  "moonshot-v1-128k-vision-preview.description": "Модели Kimi Vision (включая moonshot-v1-8k-vision-preview/moonshot-v1-32k-vision-preview/moonshot-v1-128k-vision-preview) способны понимать содержимое изображений, включая текст, цвета и формы объектов.",
  "moonshot-v1-128k.description": "Moonshot V1 128K предоставляет сверхдлинный контекст для генерации очень длинных текстов, обрабатывая до 128 000 токенов — идеально для исследований, академических задач и работы с большими документами.",
  "moonshot-v1-32k-vision-preview.description": "Модели Kimi Vision (включая moonshot-v1-8k-vision-preview/moonshot-v1-32k-vision-preview/moonshot-v1-128k-vision-preview) способны понимать содержимое изображений, включая текст, цвета и формы объектов.",
  "moonshot-v1-32k.description": "Moonshot V1 32K поддерживает 32 768 токенов для контекста средней длины, идеально подходит для длинных документов и сложных диалогов в создании контента, отчётах и чат-системах.",
  "moonshot-v1-8k-vision-preview.description": "Модели Kimi Vision (включая moonshot-v1-8k-vision-preview/moonshot-v1-32k-vision-preview/moonshot-v1-128k-vision-preview) способны понимать содержимое изображений, включая текст, цвета и формы объектов.",
  "moonshot-v1-8k.description": "Moonshot V1 8K оптимизирована для генерации коротких текстов с высокой эффективностью, обрабатывает 8192 токена — подходит для коротких чатов, заметок и быстрого контента.",
  "moonshot-v1-auto.description": "Moonshot V1 Auto автоматически выбирает подходящую модель в зависимости от текущего использования токенов контекста.",
  "moonshotai/Kimi-Dev-72B.description": "Kimi-Dev-72B — открытая языковая модель для программирования, оптимизированная с помощью масштабного обучения с подкреплением для создания надёжных, готовых к производству патчей. Набирает 60.4% на SWE-bench Verified, устанавливая новый рекорд среди открытых моделей для задач автоматизированной разработки ПО, таких как исправление ошибок и ревью кода.",
  "moonshotai/Kimi-K2-Instruct-0905.description": "Kimi K2-Instruct-0905 — новейшая и самая мощная версия Kimi K2. Это топовая модель MoE с 1 триллионом общих и 32 миллиардами активных параметров. Ключевые особенности: улучшенный интеллект в программировании агентов, значительный прирост в бенчмарках и реальных задачах, а также улучшенная эстетика и удобство фронтенд-кода.",
  "moonshotai/Kimi-K2-Thinking.description": "Kimi K2 Thinking — самая мощная открытая модель для рассуждений. Существенно увеличивает глубину многошагового мышления и стабильно использует инструменты на протяжении 200–300 последовательных вызовов. Устанавливает новые рекорды на Humanity's Last Exam (HLE), BrowseComp и других бенчмарках. Отлично справляется с программированием, математикой, логикой и агентными сценариями. Построена на архитектуре MoE с ~1 триллионом параметров, поддерживает окно контекста 256K и вызов инструментов.",
  "moonshotai/kimi-k2-0711.description": "Kimi K2 0711 — вариант instruct в серии Kimi, предназначен для высококачественного кода и использования инструментов.",
  "moonshotai/kimi-k2-0905.description": "Kimi K2 0905 — обновление, расширяющее контекст и логические возможности с оптимизациями для программирования.",
  "moonshotai/kimi-k2-instruct-0905.description": "Модель kimi-k2-0905-preview поддерживает окно контекста 256K, обладает улучшенными возможностями программирования агентов, более качественным и практичным фронтенд-кодом и лучшим пониманием контекста.",
  "moonshotai/kimi-k2-thinking-turbo.description": "Kimi K2 Thinking Turbo — высокоскоростная версия Kimi K2 Thinking, значительно снижает задержку при сохранении глубины рассуждений.",
  "moonshotai/kimi-k2-thinking.description": "Kimi K2 Thinking — модель рассуждений от Moonshot, оптимизированная для задач глубокого мышления, с общими агентными возможностями.",
  "moonshotai/kimi-k2.description": "Kimi K2 — крупная модель MoE от Moonshot AI с 1 триллионом параметров и 32 миллиардами активных на проход, оптимизирована для агентных возможностей, включая продвинутую работу с инструментами, логическое мышление и синтез кода.",
  "morph/morph-v3-fast.description": "Morph — специализированная модель для применения изменений в коде, предложенных передовыми моделями (например, Claude или GPT-4o), к существующим файлам со скоростью более 4500 токенов/сек. Это финальный этап в AI-пайплайне программирования, поддерживает 16k токенов на вход/выход.",
  "morph/morph-v3-large.description": "Morph — специализированная модель для применения изменений в коде, предложенных передовыми моделями (например, Claude или GPT-4o), к существующим файлам со скоростью более 2500 токенов/сек. Это финальный этап в AI-пайплайне программирования, поддерживает 16k токенов на вход/выход.",
  "nousresearch/hermes-2-pro-llama-3-8b.description": "Hermes 2 Pro Llama 3 8B — обновлённая версия Nous Hermes 2 с новейшими внутренними датасетами.",
  "nvidia/Llama-3.1-Nemotron-70B-Instruct-HF.description": "Llama 3.1 Nemotron 70B — кастомизированная модель от NVIDIA, улучшающая полезность. Демонстрирует высокие результаты на Arena Hard, AlpacaEval 2 LC и GPT-4-Turbo MT-Bench, занимая первое место на всех трёх бенчмарках авто-выравнивания по состоянию на 1 октября 2024 года. Обучена на основе Llama-3.1-70B-Instruct с использованием RLHF (REINFORCE), Llama-3.1-Nemotron-70B-Reward и HelpSteer2-Preference prompts.",
  "nvidia/llama-3.1-nemotron-51b-instruct.description": "Уникальная языковая модель с выдающейся точностью и эффективностью.",
  "nvidia/llama-3.1-nemotron-70b-instruct.description": "Llama-3.1-Nemotron-70B-Instruct — кастомизированная модель от NVIDIA, созданная для повышения полезности ответов LLM.",
  "pixtral-12b-2409.description": "Pixtral отлично справляется с анализом графиков и изображений, вопросами по документам, мультимодальным рассуждением и выполнением инструкций. Он обрабатывает изображения в их исходном разрешении и соотношении сторон, поддерживая любое количество изображений в контексте до 128K.",
  "pixtral-large-latest.description": "Pixtral Large — это открытая мультимодальная модель с 124 миллиардами параметров, построенная на базе Mistral Large 2. Это вторая модель в нашей мультимодальной линейке, обладающая передовыми возможностями понимания изображений.",
  "pro-128k.description": "Spark Pro 128K обладает очень большой контекстной емкостью — до 128K, что делает его идеальным для анализа длинных документов, требующих полного охвата текста и логической связности, с поддержкой логики и разнообразных ссылок в сложных обсуждениях.",
  "pro-deepseek-r1.description": "Выделенная корпоративная модель обслуживания с включенной параллельной обработкой.",
  "pro-deepseek-v3.description": "Выделенная корпоративная модель обслуживания с включенной параллельной обработкой.",
  "qianfan-70b.description": "Qianfan 70B — это крупная китайская модель для высококачественной генерации текста и сложного рассуждения.",
  "qianfan-8b.description": "Qianfan 8B — это универсальная модель среднего размера, обеспечивающая баланс между стоимостью и качеством генерации текста и ответов на вопросы.",
  "qianfan-agent-intent-32k.description": "Qianfan Agent Intent 32K предназначена для распознавания намерений и координации агентов с поддержкой длинного контекста.",
  "qianfan-agent-lite-8k.description": "Qianfan Agent Lite 8K — это легковесная агентная модель для недорогих многотактных диалогов и рабочих процессов.",
  "qianfan-agent-speed-32k.description": "Qianfan Agent Speed 32K — это высокопроизводительная агентная модель для масштабных многозадачных приложений.",
  "qianfan-agent-speed-8k.description": "Qianfan Agent Speed 8K — это высококонкурентная агентная модель для коротких и средних диалогов с быстрым откликом.",
  "qianfan-check-vl.description": "Qianfan Check VL — это мультимодальная модель для проверки соответствия контента изображений и текста, а также задач распознавания.",
  "qianfan-composition.description": "Qianfan Composition — это мультимодальная модель для создания и понимания смешанного контента изображение-текст.",
  "qianfan-engcard-vl.description": "Qianfan EngCard VL — это мультимодальная модель распознавания, ориентированная на англоязычные сценарии.",
  "qianfan-lightning-128b-a19b.description": "Qianfan Lightning 128B A19B — это высокопроизводительная китайская универсальная модель для сложных вопросов и масштабного рассуждения.",
  "qianfan-llama-vl-8b.description": "Qianfan Llama VL 8B — мультимодальная модель на базе Llama для общего понимания изображений и текста.",
  "qianfan-multipicocr.description": "Qianfan MultiPicOCR — это модель OCR для нескольких изображений, предназначенная для обнаружения и распознавания текста на изображениях.",
  "qianfan-qi-vl.description": "Qianfan QI VL — мультимодальная модель для точного поиска и ответов на вопросы в сложных сценариях изображение-текст.",
  "qianfan-singlepicocr.description": "Qianfan SinglePicOCR — это модель OCR для одного изображения с высокой точностью распознавания символов.",
  "qianfan-vl-70b.description": "Qianfan VL 70B — это крупная мультимодальная модель для сложного понимания изображений и текста.",
  "qianfan-vl-8b.description": "Qianfan VL 8B — это легковесная мультимодальная модель для повседневного анализа изображений и текстов и ответов на вопросы.",
  "qvq-72b-preview.description": "QVQ-72B-Preview — это экспериментальная исследовательская модель от Qwen, направленная на улучшение визуального рассуждения.",
  "qvq-max.description": "Модель визуального рассуждения Qwen QVQ поддерживает ввод изображений и вывод в виде цепочки рассуждений, демонстрируя высокую производительность в математике, программировании, визуальном анализе, творческих и общих задачах.",
  "qvq-plus.description": "Модель визуального рассуждения с вводом изображений и выводом в виде цепочки рассуждений. Серия qvq-plus следует за qvq-max и обеспечивает более быстрое рассуждение с лучшим соотношением качества и стоимости.",
  "qwen-3-32b.description": "Qwen 3 32B: сильна в многоязычных и программных задачах, подходит для средне-масштабного промышленного использования.",
  "qwen-coder-plus.description": "Модель программирования Qwen.",
  "qwen-coder-turbo-latest.description": "Модель программирования Qwen.",
  "qwen-coder-turbo.description": "Модель программирования Qwen.",
  "qwen-flash.description": "Самая быстрая и недорогая модель Qwen, идеально подходит для простых задач.",
  "qwen-image-edit.description": "Qwen Image Edit — это модель преобразования изображений, которая редактирует изображения на основе входных изображений и текстовых подсказок, обеспечивая точные корректировки и творческие трансформации.",
  "qwen-image.description": "Qwen-Image — это универсальная модель генерации изображений, поддерживающая различные художественные стили и сложную отрисовку текста, особенно на китайском и английском языках. Поддерживает многострочные макеты, абзацы и детализированную генерацию для сложных текстово-визуальных композиций.",
  "qwen-long.description": "Ультра-крупная модель Qwen с поддержкой длинного контекста и диалогов в рамках одного или нескольких документов.",
  "qwen-math-plus-latest.description": "Qwen Math — языковая модель, специализирующаяся на решении математических задач.",
  "qwen-math-plus.description": "Qwen Math — языковая модель, специализирующаяся на решении математических задач.",
  "qwen-math-turbo-latest.description": "Qwen Math — языковая модель, специализирующаяся на решении математических задач.",
  "qwen-math-turbo.description": "Qwen Math — языковая модель, специализирующаяся на решении математических задач.",
  "qwen-max.description": "Ультра-крупная модель Qwen с сотнями миллиардов параметров, поддерживающая китайский, английский и другие языки; API-модель, лежащая в основе текущих продуктов Qwen2.5.",
  "qwen-omni-turbo.description": "Модели Qwen-Omni поддерживают мультимодальный ввод (видео, аудио, изображения, текст) и вывод в виде аудио и текста.",
  "qwen-plus.description": "Улучшенная ультра-крупная модель Qwen с поддержкой китайского, английского и других языков.",
  "qwen-turbo.description": "Qwen Turbo больше не обновляется; рекомендуется заменить на Qwen Flash. Ультра-крупная модель Qwen с поддержкой китайского, английского и других языков.",
  "qwen-vl-chat-v1.description": "Qwen VL поддерживает гибкие взаимодействия, включая ввод нескольких изображений, многотактные вопросы и ответы, а также творческие задачи.",
  "qwen-vl-max-latest.description": "Ультра-крупная мультимодальная модель Qwen. По сравнению с улучшенной версией, она еще больше усиливает визуальное рассуждение и следование инструкциям, обеспечивая более сильное восприятие и когнитивные способности.",
  "qwen-vl-max.description": "Ультра-крупная мультимодальная модель Qwen. По сравнению с улучшенной версией, она еще больше усиливает визуальное рассуждение и следование инструкциям, обеспечивая более сильное визуальное восприятие и когнитивные способности.",
  "qwen-vl-ocr.description": "Qwen OCR — это модель извлечения текста из документов, таблиц, экзаменационных изображений и рукописного текста. Поддерживает китайский, английский, французский, японский, корейский, немецкий, русский, итальянский, вьетнамский и арабский языки.",
  "qwen-vl-plus-latest.description": "Улучшенная крупномасштабная мультимодальная модель Qwen с заметным улучшением детализации и распознавания текста, поддерживающая разрешение более одного мегапикселя и произвольные соотношения сторон.",
  "qwen-vl-plus.description": "Улучшенная крупномасштабная мультимодальная модель Qwen с заметным улучшением детализации и распознавания текста, поддерживающая разрешение более одного мегапикселя и произвольные соотношения сторон.",
  "qwen-vl-v1.description": "Предобученная модель, инициализированная от Qwen-7B с добавленным модулем зрения и входом изображения с разрешением 448.",
  "qwen/qwen-2-7b-instruct.description": "Qwen2 — это новая серия языковых моделей Qwen. Qwen2 7B — это модель на основе трансформеров, превосходно справляющаяся с пониманием языка, многоязычностью, программированием, математикой и рассуждением.",
  "qwen/qwen-2-7b-instruct:free.description": "Qwen2 — это новая серия крупных языковых моделей с улучшенным пониманием и генерацией.",
  "qwen2.5-7b-instruct.description": "Qwen2.5 7B Instruct — зрелая модель с открытым исходным кодом для инструкционного обучения, подходящая для многосценарного общения и генерации.",
  "qwen2.5-coder-1.5b-instruct.description": "Открытая модель кода Qwen.",
  "qwen2.5-coder-14b-instruct.description": "Открытая модель кода Qwen.",
  "qwen2.5-coder-32b-instruct.description": "Открытая модель кода Qwen.",
  "qwen2.5-coder-7b-instruct.description": "Открытая модель кода Qwen.",
  "qwen2.5-coder-instruct.description": "Qwen2.5-Coder — новейшая модель LLM с фокусом на программировании в семействе Qwen (ранее CodeQwen).",
  "qwen2.5-instruct.description": "Qwen2.5 — последняя серия LLM от Qwen, включающая базовые и инструкционно-обученные модели от 0.5B до 72B параметров.",
  "qwen2.5-math-1.5b-instruct.description": "Qwen-Math демонстрирует высокую эффективность в решении математических задач.",
  "qwen2.5-math-72b-instruct.description": "Qwen-Math демонстрирует высокую эффективность в решении математических задач.",
  "qwen2.5-math-7b-instruct.description": "Qwen-Math демонстрирует высокую эффективность в решении математических задач.",
  "qwen2.5-omni-7b.description": "Модели Qwen-Omni поддерживают мультимодальные входные данные (видео, аудио, изображения, текст) и вывод в виде аудио и текста.",
  "qwen2.5-vl-32b-instruct.description": "Qwen2.5 VL 32B Instruct — открытая мультимодальная модель, подходящая для частного развертывания и многосценарного использования.",
  "qwen2.5-vl-72b-instruct.description": "Улучшенное следование инструкциям, решение задач, математика и программирование, а также более точное распознавание объектов. Поддерживает точную локализацию визуальных элементов в различных форматах, понимание длинных видео (до 10 минут) с точной временной разметкой событий, определением порядка и скорости, а также агентов, способных управлять ОС или мобильными устройствами через парсинг и локализацию. Эффективное извлечение ключевой информации и вывод в формате JSON. Это версия 72B — самая мощная в серии.",
  "qwen2.5-vl-7b-instruct.description": "Qwen2.5 VL 7B Instruct — легковесная мультимодальная модель, сочетающая низкие затраты на развертывание и хорошие способности к распознаванию.",
  "qwen2.5-vl-instruct.description": "Qwen2.5-VL — новейшая модель слияния зрения и языка в семействе Qwen.",
  "qwen2.5.description": "Qwen2.5 — это LLM нового поколения от Alibaba с высокой производительностью в различных сценариях использования.",
  "qwen2.5:0.5b.description": "Qwen2.5 — это LLM нового поколения от Alibaba с высокой производительностью в различных сценариях использования.",
  "qwen2.5:1.5b.description": "Qwen2.5 — это LLM нового поколения от Alibaba с высокой производительностью в различных сценариях использования.",
  "qwen2.5:72b.description": "Qwen2.5 — это LLM нового поколения от Alibaba с высокой производительностью в различных сценариях использования.",
  "qwen2.description": "Qwen2 — это LLM нового поколения от Alibaba с высокой производительностью в различных сценариях использования.",
  "qwen2:0.5b.description": "Qwen2 — это LLM нового поколения от Alibaba с высокой производительностью в различных сценариях использования.",
  "qwen2:1.5b.description": "Qwen2 — это LLM нового поколения от Alibaba с высокой производительностью в различных сценариях использования.",
  "qwen2:72b.description": "Qwen2 — это LLM нового поколения от Alibaba с высокой производительностью в различных сценариях использования.",
  "qwen3-0.6b.description": "Qwen3 0.6B — начальная модель для простых рассуждений и ограниченных сред.",
  "qwen3-1.7b.description": "Qwen3 1.7B — ультралегкая модель для развертывания на устройствах и периферии.",
  "qwen3-14b.description": "Qwen3 14B — модель среднего размера для многоязычного ответа на вопросы и генерации текста.",
  "qwen3-235b-a22b-instruct-2507.description": "Qwen3 235B A22B Instruct 2507 — флагманская инструкционная модель для широкого спектра задач генерации и рассуждения.",
  "qwen3-235b-a22b-thinking-2507.description": "Qwen3 235B A22B Thinking 2507 — сверхкрупная модель для сложных задач рассуждения.",
  "qwen3-235b-a22b.description": "Qwen3 235B A22B — универсальная крупная модель для сложных задач.",
  "qwen3-30b-a3b-instruct-2507.description": "Qwen3 30B A3B Instruct 2507 — инструкционная модель среднего размера для высококачественной генерации и ответов на вопросы.",
  "qwen3-30b-a3b-thinking-2507.description": "Qwen3 30B A3B Thinking 2507 — модель среднего размера для рассуждений, сочетающая точность и эффективность.",
  "qwen3-30b-a3b.description": "Qwen3 30B A3B — универсальная модель среднего размера, сочетающая качество и стоимость.",
  "qwen3-32b.description": "Qwen3 32B подходит для общих задач, требующих более глубокого понимания.",
  "qwen3-4b.description": "Qwen3 4B подходит для небольших и средних приложений и локального вывода.",
  "qwen3-8b.description": "Qwen3 8B — легковесная модель с гибким развертыванием для высоконагруженных задач.",
  "qwen3-coder-30b-a3b-instruct.description": "Открытая модель кода Qwen. Новейшая qwen3-coder-30b-a3b-instruct основана на Qwen3 и обладает мощными возможностями кодирующего агента, использования инструментов и взаимодействия со средой для автономного программирования, с отличной производительностью кода и общей функциональностью.",
  "qwen3-coder-480b-a35b-instruct.description": "Qwen3 Coder 480B A35B Instruct — флагманская модель кода для многоязычного программирования и сложного понимания кода.",
  "qwen3-coder-flash.description": "Модель кода Qwen. Новейшая серия Qwen3-Coder основана на Qwen3 и обладает мощными возможностями кодирующего агента, использования инструментов и взаимодействия со средой для автономного программирования, с отличной производительностью кода и общей функциональностью.",
  "qwen3-coder-plus.description": "Модель кода Qwen. Новейшая серия Qwen3-Coder основана на Qwen3 и обладает мощными возможностями кодирующего агента, использования инструментов и взаимодействия со средой для автономного программирования, с отличной производительностью кода и общей функциональностью.",
  "qwen3-coder:480b.description": "Высокопроизводительная модель от Alibaba с длинным контекстом для задач агентов и программирования.",
  "qwen3-max-preview.description": "Лучшая модель Qwen для сложных многошаговых задач. Превью-версия поддерживает рассуждение.",
  "qwen3-max.description": "Модели Qwen3 Max значительно превосходят серию 2.5 по общим возможностям, пониманию китайского и английского языков, следованию сложным инструкциям, выполнению открытых задач, многоязычности и использованию инструментов, с меньшим количеством галлюцинаций. Последняя версия qwen3-max улучшает программирование агентов и использование инструментов по сравнению с qwen3-max-preview. Эта версия достигает SOTA в своей области и ориентирована на более сложные потребности агентов.",
  "qwen3-next-80b-a3b-instruct.description": "Модель следующего поколения Qwen3 без рассуждений с открытым исходным кодом. По сравнению с предыдущей версией (Qwen3-235B-A22B-Instruct-2507), улучшено понимание китайского языка, логическое мышление и генерация текста.",
  "qwen3-next-80b-a3b-thinking.description": "Qwen3 Next 80B A3B Thinking — флагманская версия модели рассуждений для сложных задач.",
  "qwen3-omni-flash.description": "Qwen-Omni принимает комбинированные входные данные (текст, изображения, аудио, видео) и выдает текст или речь. Поддерживает различные естественные голоса, многоязычную и диалектную речь, подходит для задач письма, распознавания изображений и голосовых помощников.",
  "qwen3-vl-235b-a22b-instruct.description": "Qwen3 VL 235B A22B Instruct — флагманская мультимодальная модель для сложного понимания и генерации.",
  "qwen3-vl-235b-a22b-thinking.description": "Qwen3 VL 235B A22B Thinking — флагманская версия для сложного мультимодального рассуждения и планирования.",
  "qwen3-vl-30b-a3b-instruct.description": "Qwen3 VL 30B A3B Instruct — крупная мультимодальная модель, сочетающая точность и производительность рассуждений.",
  "qwen3-vl-30b-a3b-thinking.description": "Qwen3 VL 30B A3B Thinking — версия с глубоким мышлением для сложных мультимодальных задач.",
  "qwen3-vl-32b-instruct.description": "Qwen3 VL 32B Instruct — мультимодальная модель, обученная следованию инструкциям, для высококачественного визуально-текстового QA и генерации.",
  "qwen3-vl-32b-thinking.description": "Qwen3 VL 32B Thinking — мультимодальная версия с глубоким мышлением для сложного рассуждения и анализа длинных цепочек.",
  "qwen3-vl-8b-instruct.description": "Qwen3 VL 8B Instruct — легковесная мультимодальная модель для повседневного визуального QA и интеграции в приложения.",
  "qwen3-vl-8b-thinking.description": "Qwen3 VL 8B Thinking — мультимодальная модель с цепочкой рассуждений для детального визуального анализа.",
  "qwen3-vl-flash.description": "Qwen3 VL Flash: легковесная, высокоскоростная версия рассуждений для задач с низкой задержкой или высоким объемом запросов.",
  "qwen3-vl-plus.description": "Qwen VL — модель генерации текста с пониманием изображений. Поддерживает OCR, а также умеет обобщать и рассуждать, например, извлекать атрибуты с фото товаров или решать задачи по изображениям.",
  "qwen3.description": "Qwen3 — это LLM нового поколения от Alibaba с высокой производительностью в различных сценариях использования.",
  "taichu_o1.description": "taichu_o1 — это модель нового поколения для рассуждений, использующая мультимодальное взаимодействие и обучение с подкреплением для достижения человекоподобного хода мыслей. Она поддерживает моделирование сложных решений, демонстрирует логические цепочки и обеспечивает высокую точность, идеально подходя для стратегического анализа и глубокого мышления.",
  "taichu_vl.description": "Объединяет понимание изображений, перенос знаний и логическую атрибуцию, превосходно справляясь с задачами вопрос-ответ по изображению и тексту.",
  "tencent/Hunyuan-A13B-Instruct.description": "Hunyuan-A13B-Instruct использует 80 миллиардов параметров, из которых активно 13 миллиардов, обеспечивая производительность, сопоставимую с более крупными моделями. Поддерживает гибридное быстрое/медленное рассуждение, стабильное понимание длинных текстов и лидирующие возможности агентов на BFCL-v3 и τ-Bench. Поддержка GQA и мульти-квантованных форматов обеспечивает эффективный вывод.",
  "tencent/Hunyuan-MT-7B.description": "Модель перевода Hunyuan включает Hunyuan-MT-7B и ансамбль Hunyuan-MT-Chimera. Hunyuan-MT-7B — это легковесная модель на 7 миллиардов параметров, поддерживающая 33 языка и 5 языков китайских меньшинств. На WMT25 заняла первое место в 30 из 31 языковой пары. Tencent Hunyuan использует полный цикл обучения от предобучения до SFT, RL для перевода и ансамблевого RL, достигая выдающейся производительности при компактных размерах и легкости развертывания.",
  "text-embedding-3-large.description": "Самая мощная модель встраивания для задач на английском и других языках.",
  "text-embedding-3-small.description": "Эффективная и экономичная модель встраивания нового поколения для поиска и RAG-сценариев.",
  "thudm/glm-4-32b.description": "GLM-4-32B-0414 — это 32-миллиардная билингвальная модель (китайский/английский) с открытым доступом к весам, оптимизированная для генерации кода, вызова функций и задач агентов. Предобучена на 15Т высококачественных данных с акцентом на рассуждение и дополнительно дообучена с учетом предпочтений человека, выборочного отклонения и RL. Отличается выдающимися способностями к сложным рассуждениям, генерации артефактов и структурированному выводу, достигая уровня GPT-4o и DeepSeek-V3-0324 на множестве бенчмарков.",
  "thudm/glm-4-32b:free.description": "GLM-4-32B-0414 — это 32-миллиардная билингвальная модель (китайский/английский) с открытым доступом к весам, оптимизированная для генерации кода, вызова функций и задач агентов. Предобучена на 15Т высококачественных данных с акцентом на рассуждение и дополнительно дообучена с учетом предпочтений человека, выборочного отклонения и RL. Отличается выдающимися способностями к сложным рассуждениям, генерации артефактов и структурированному выводу, достигая уровня GPT-4o и DeepSeek-V3-0324 на множестве бенчмарков.",
  "thudm/glm-4-9b-chat.description": "Открытая версия последней предобученной модели GLM-4 от Zhipu AI.",
  "thudm/glm-z1-32b.description": "GLM-Z1-32B-0414 — это усовершенствованный вариант GLM-4-32B, ориентированный на глубокие математические, логические и кодовые задачи. Использует расширенное RL (специфические для задач и общие парные предпочтения) для улучшения многозадачных рассуждений. По сравнению с GLM-4-32B, Z1 значительно улучшает структурированное мышление и способности в формальных областях.\n\nПоддерживает принудительные «шаги размышлений» через инженерные подсказки, повышенную связность длинных ответов и оптимизирован для агентных рабочих процессов с длинным контекстом (через YaRN), вызов инструментов в формате JSON и тонкую выборку для стабильного рассуждения. Идеален для задач, требующих аккуратных многошаговых или формальных выводов.",
  "thudm/glm-z1-rumination-32b.description": "GLM Z1 Rumination 32B — это 32-миллиардная модель глубокого рассуждения из серии GLM-4-Z1, оптимизированная для сложных открытых задач, требующих длительного размышления. Построена на базе glm-4-32b-0414, включает дополнительные этапы RL и многоступенчатое выравнивание, вводя способность «размышления», имитирующую расширенную когнитивную обработку. Это включает итеративное рассуждение, многошаговый анализ и рабочие процессы с использованием инструментов, таких как поиск, извлечение и синтез с учетом цитирования.\n\nОтлично подходит для научного письма, сравнительного анализа и сложных вопросов. Поддерживает вызов функций для примитивов поиска/навигации (`search`, `click`, `open`, `finish`) в агентных пайплайнах. Поведение размышления управляется многоцикловыми петлями с формированием наград на основе правил и механизмами отложенных решений, протестировано на глубоких исследовательских фреймворках, таких как внутренняя стек-выравнивание OpenAI. Этот вариант ориентирован на глубину, а не на скорость.",
  "tngtech/deepseek-r1t-chimera:free.description": "DeepSeek-R1T-Chimera создан путем объединения DeepSeek-R1 и DeepSeek-V3 (0324), сочетая рассуждение R1 с эффективностью токенов V3. Основан на трансформере DeepSeek-MoE и оптимизирован для генерации общего текста.\n\nОбъединяет предобученные веса для баланса между рассуждением, эффективностью и следованием инструкциям. Выпущен под лицензией MIT для исследовательского и коммерческого использования.",
  "togethercomputer/StripedHyena-Nous-7B.description": "StripedHyena Nous (7B) обеспечивает повышенную вычислительную эффективность благодаря своей архитектуре и стратегии.",
  "tts-1-hd.description": "Последняя модель синтеза речи, оптимизированная для качества.",
  "tts-1.description": "Последняя модель синтеза речи, оптимизированная для скорости в реальном времени.",
  "upstage/SOLAR-10.7B-Instruct-v1.0.description": "Upstage SOLAR Instruct v1 (11B) настроена для точного выполнения инструкций с высокой языковой производительностью.",
  "us.anthropic.claude-3-5-sonnet-20241022-v2:0.description": "Claude 3.5 Sonnet поднимает отраслевой стандарт, превосходя конкурентов и Claude 3 Opus по широкому спектру оценок, сохраняя при этом средний уровень скорости и стоимости.",
  "us.anthropic.claude-3-7-sonnet-20250219-v1:0.description": "Claude 3.7 Sonnet — самая быстрая модель нового поколения от Anthropic. По сравнению с Claude 3 Haiku, она улучшена по всем навыкам и превосходит предыдущий флагман Claude 3 Opus по многим интеллектуальным бенчмаркам.",
  "us.anthropic.claude-haiku-4-5-20251001-v1:0.description": "Claude Haiku 4.5 — самая быстрая и интеллектуальная модель Haiku от Anthropic, с молниеносной скоростью и расширенными возможностями мышления.",
  "us.anthropic.claude-sonnet-4-5-20250929-v1:0.description": "Claude Sonnet 4.5 — самая интеллектуальная модель от Anthropic на сегодняшний день.",
  "v0-1.0-md.description": "v0-1.0-md — устаревшая модель, доступная через API v0.",
  "v0-1.5-lg.description": "v0-1.5-lg подходит для задач, требующих продвинутого мышления и рассуждений.",
  "v0-1.5-md.description": "v0-1.5-md подходит для повседневных задач и генерации пользовательских интерфейсов.",
  "vercel/v0-1.0-md.description": "Доступ к моделям v0 для генерации, исправления и оптимизации современных веб-приложений с учетом особенностей фреймворков и актуальных знаний.",
  "vercel/v0-1.5-md.description": "Доступ к моделям v0 для генерации, исправления и оптимизации современных веб-приложений с учетом особенностей фреймворков и актуальных знаний.",
  "volcengine/doubao-seed-code.description": "Doubao-Seed-Code — это LLM от ByteDance Volcano Engine, оптимизированная для агентного программирования, демонстрирующая высокие результаты на бенчмарках программирования и агентов с поддержкой контекста до 256K.",
  "wan2.2-t2i-flash.description": "Wanxiang 2.2 Speed — последняя модель с улучшениями в креативности, стабильности и реалистичности, обеспечивающая быструю генерацию и высокую ценность.",
  "wan2.2-t2i-plus.description": "Wanxiang 2.2 Pro — последняя модель с улучшениями в креативности, стабильности и реалистичности, создающая более детализированные изображения.",
  "wanx-v1.description": "Базовая модель преобразования текста в изображение. Соответствует Tongyi Wanxiang 1.0 General.",
  "wanx2.0-t2i-turbo.description": "Отличается текстурированными портретами при умеренной скорости и низкой стоимости. Соответствует Tongyi Wanxiang 2.0 Speed.",
  "wanx2.1-t2i-plus.description": "Полностью обновленная версия с более богатыми деталями изображения и немного меньшей скоростью. Соответствует Tongyi Wanxiang 2.1 Pro.",
  "wanx2.1-t2i-turbo.description": "Полностью обновленная версия с быстрой генерацией, высоким общим качеством и отличной ценностью. Соответствует Tongyi Wanxiang 2.1 Speed.",
  "whisper-1.description": "Универсальная модель распознавания речи с поддержкой многоязычного ASR, перевода речи и определения языка.",
  "wizardlm2.description": "WizardLM 2 — языковая модель от Microsoft AI, превосходно справляющаяся со сложными диалогами, многоязычными задачами, рассуждениями и помощниками.",
  "wizardlm2:8x22b.description": "WizardLM 2 — языковая модель от Microsoft AI, превосходно справляющаяся со сложными диалогами, многоязычными задачами, рассуждениями и помощниками.",
  "x-ai/grok-4-fast-non-reasoning.description": "Grok 4 Fast (без рассуждений) — это высокопроизводительная, недорогая мультимодальная модель от xAI (поддерживает контекст до 2M), предназначенная для сценариев, чувствительных к задержке и стоимости, не требующих встроенного рассуждения. Рассуждение можно включить через параметр reasoning в API. Подсказки и ответы могут использоваться xAI или OpenRouter для улучшения будущих моделей.",
  "x-ai/grok-4-fast.description": "Grok 4 Fast — это высокопроизводительная, недорогая модель от xAI (поддерживает контекст до 2M), идеально подходящая для сценариев с высокой конкуренцией и длинным контекстом.",
  "x-ai/grok-4.1-fast-non-reasoning.description": "Grok 4 Fast (без рассуждений) — это высокопроизводительная, недорогая мультимодальная модель от xAI (поддерживает контекст до 2M), предназначенная для сценариев, чувствительных к задержке и стоимости, не требующих встроенного рассуждения. Рассуждение можно включить через параметр reasoning в API. Подсказки и ответы могут использоваться xAI или OpenRouter для улучшения будущих моделей.",
  "x-ai/grok-4.1-fast.description": "Grok 4 Fast — это высокопроизводительная, недорогая модель от xAI (поддерживает контекст до 2M), идеально подходящая для сценариев с высокой конкуренцией и длинным контекстом.",
  "x-ai/grok-4.description": "Grok 4 — флагманская модель xAI с мощными возможностями рассуждения и мультимодальности.",
  "x-ai/grok-code-fast-1.description": "Grok Code Fast 1 — быстрая модель программирования от xAI с читаемым и удобным для инженеров выводом.",
  "xai/grok-2-vision.description": "Grok 2 Vision превосходно справляется с визуальными задачами, демонстрируя передовые результаты в визуальном математическом рассуждении (MathVista) и вопросах по документам (DocVQA). Обрабатывает документы, диаграммы, графики, скриншоты и фотографии.",
  "xai/grok-2.description": "Grok 2 — передовая модель с передовыми возможностями рассуждения, чата и программирования, превосходящая Claude 3.5 Sonnet и GPT-4 Turbo по LMSYS.",
  "xai/grok-3-fast.description": "Флагманская модель xAI, превосходно подходящая для корпоративных задач, таких как извлечение данных, программирование и суммирование, с глубокими знаниями в области финансов, здравоохранения, права и науки. Быстрая версия работает на ускоренной инфраструктуре для более быстрых ответов при более высокой стоимости за токен.",
  "xai/grok-3-mini-fast.description": "Легковесная модель xAI, которая «думает» перед ответом, идеально подходит для простых или логических задач без необходимости в глубоких знаниях. Доступны необработанные следы рассуждений. Быстрая версия работает на ускоренной инфраструктуре для более быстрых ответов при более высокой стоимости за токен.",
  "xai/grok-3-mini.description": "Легковесная модель xAI, которая «думает» перед ответом, идеально подходит для простых или логических задач без необходимости в глубоких знаниях. Доступны необработанные следы рассуждений.",
  "xai/grok-3.description": "Флагманская модель xAI, превосходно подходящая для корпоративных задач, таких как извлечение данных, программирование и суммирование, с глубокими знаниями в области финансов, здравоохранения, права и науки.",
  "xai/grok-4.description": "Новейшая флагманская модель xAI с непревзойденной производительностью в области естественного языка, математики и рассуждений — универсальный лидер.",
  "yi-large-fc.description": "Построена на базе yi-large с расширенными возможностями вызова инструментов, подходит для сценариев агентов и рабочих процессов.",
  "yi-large-preview.description": "Ранняя версия; рекомендуется использовать более новую yi-large.",
  "yi-large-rag.description": "Продвинутая служба на базе yi-large, объединяющая поиск и генерацию для точных ответов с поддержкой веб-поиска в реальном времени.",
  "yi-large-turbo.description": "Исключительное соотношение цены и качества, настроено для оптимального баланса между качеством, скоростью и стоимостью.",
  "yi-large.description": "Новая модель с 100 миллиардами параметров, обладающая сильными возможностями в вопросах и генерации текста.",
  "yi-lightning-lite.description": "Облегченная версия; рекомендуется использовать yi-lightning.",
  "yi-lightning.description": "Новая высокопроизводительная модель с быстрой генерацией и высоким качеством вывода.",
  "yi-medium-200k.description": "Модель с длинным контекстом (200K) для глубокого понимания и генерации длинных текстов.",
  "yi-medium.description": "Настроенная модель среднего размера с балансом возможностей и стоимости, оптимизирована для следования инструкциям.",
  "yi-spark.description": "Компактная и быстрая модель с усиленными возможностями в математике и программировании.",
  "yi-vision-v2.description": "Модель компьютерного зрения для сложных задач с мощным пониманием и анализом нескольких изображений.",
  "yi-vision.description": "Модель компьютерного зрения для сложных задач с мощным пониманием изображений и анализом.",
  "z-ai/glm-4.5-air.description": "GLM 4.5 Air — легковесный вариант GLM 4.5 для сценариев с ограниченным бюджетом, при этом сохраняет сильные способности к рассуждению.",
  "z-ai/glm-4.5.description": "GLM 4.5 — флагманская модель Z.AI с гибридным рассуждением, оптимизированная для инженерных задач и задач с длинным контекстом.",
  "z-ai/glm-4.6.description": "GLM 4.6 — флагманская модель Z.AI с расширенной длиной контекста и улучшенными возможностями программирования.",
  "zai-glm-4.6.description": "Отлично справляется с задачами программирования и рассуждений, поддерживает потоковую передачу и вызов инструментов, подходит для агентного программирования и сложных рассуждений.",
  "zai-org/GLM-4.5-Air.description": "GLM-4.5-Air — базовая модель для агентных приложений с архитектурой Mixture-of-Experts. Оптимизирована для использования инструментов, веб-браузинга, программной инженерии и фронтенд-разработки, интегрируется с агентами кода, такими как Claude Code и Roo Code. Использует гибридное рассуждение для решения как сложных, так и повседневных задач.",
  "zai-org/GLM-4.5.description": "GLM-4.5 — базовая модель, созданная для агентных приложений с архитектурой Mixture-of-Experts. Глубоко оптимизирована для использования инструментов, веб-браузинга, программной инженерии и фронтенд-разработки, интегрируется с агентами кода, такими как Claude Code и Roo Code. Использует гибридное рассуждение для решения как сложных, так и повседневных задач.",
  "zai-org/GLM-4.5V.description": "GLM-4.5V — последняя мультимодальная модель Zhipu AI, построенная на флагманской текстовой модели GLM-4.5-Air (106B всего, 12B активно) с архитектурой MoE для высокой производительности при низкой стоимости. Следует пути GLM-4.1V-Thinking и добавляет 3D-RoPE для улучшения пространственного 3D-рассуждения. Оптимизирована через предобучение, SFT и RL, обрабатывает изображения, видео и длинные документы, занимает лидирующие позиции среди открытых моделей на 41 мультимодальном бенчмарке. Переключатель Thinking mode позволяет пользователям выбирать между скоростью и глубиной.",
  "zai-org/GLM-4.6.description": "По сравнению с GLM-4.5, GLM-4.6 расширяет контекст с 128K до 200K для более сложных агентных задач. Получает более высокие оценки на бенчмарках кода и демонстрирует лучшую производительность в реальных приложениях, таких как Claude Code, Cline, Roo Code и Kilo Code, включая улучшенную генерацию фронтенд-страниц. Улучшено рассуждение и поддержка инструментов во время рассуждения, что усиливает общие возможности. Лучше интегрируется в агентные фреймворки, улучшает агентов поиска/инструментов и обладает более естественным стилем письма и ролевой игрой, предпочтительным для человека.",
  "zai/glm-4.5-air.description": "GLM-4.5 и GLM-4.5-Air — наши последние флагманские модели для агентных приложений, обе используют MoE. GLM-4.5 имеет 355B параметров всего и 32B активно на проход; GLM-4.5-Air — более легкая версия с 106B всего и 12B активно.",
  "zai/glm-4.5.description": "Серия GLM-4.5 разработана для агентов. Флагманская модель GLM-4.5 сочетает рассуждение, программирование и агентные навыки с 355B параметров (32B активно) и предлагает два режима работы как гибридная система рассуждения.",
  "zai/glm-4.5v.description": "GLM-4.5V построена на базе GLM-4.5-Air, унаследовав проверенные техники GLM-4.1V-Thinking и масштабируясь с мощной архитектурой MoE на 106B параметров.",
  "zenmux/auto.description": "ZenMux auto-routing автоматически выбирает наиболее выгодную и производительную модель из поддерживаемых вариантов на основе вашего запроса."
}
