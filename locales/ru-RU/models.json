{
  "01-ai/yi-1.5-34b-chat.description": "Последняя открытая модель 01.AI с 34 миллиардами параметров, адаптированная для различных сценариев диалога, обученная на высококачественных данных и согласованная с человеческими предпочтениями.",
  "01-ai/yi-1.5-9b-chat.description": "Последняя открытая модель 01.AI с 9 миллиардами параметров, адаптированная для различных сценариев диалога, обученная на высококачественных данных и согласованная с человеческими предпочтениями.",
  "360/deepseek-r1.description": "DeepSeek-R1, развернутая компанией 360, использует масштабное обучение с подкреплением на этапе дообучения, значительно улучшая логическое мышление при минимальной разметке. Сопоставима с OpenAI o1 в задачах по математике, программированию и языковому рассуждению.",
  "360gpt-pro-trans.description": "Специализированная модель для перевода, глубоко дообученная для достижения передового качества перевода.",
  "360gpt-pro.description": "360GPT Pro — ключевая модель ИИ от 360 с эффективной обработкой текста для различных задач НЛП, поддерживает понимание длинных текстов и многотуровые диалоги.",
  "360gpt-turbo-responsibility-8k.description": "360GPT Turbo Responsibility 8K делает акцент на семантической безопасности и ответственности в чувствительных к содержанию приложениях, обеспечивая точный и надежный пользовательский опыт.",
  "360gpt-turbo.description": "360GPT Turbo обеспечивает высокую вычислительную и диалоговую производительность с отличным пониманием семантики и эффективной генерацией, идеально подходит для бизнеса и разработчиков.",
  "360gpt2-o1.description": "360gpt2-o1 строит цепочку рассуждений с помощью древовидного поиска, механизма рефлексии и обучения с подкреплением, позволяя модели к саморефлексии и самокоррекции.",
  "360gpt2-pro.description": "360GPT2 Pro — продвинутая модель НЛП от 360 с выдающимися возможностями генерации и понимания текста, особенно в творческих задачах, включая сложные преобразования и ролевые сценарии.",
  "360zhinao2-o1.description": "360zhinao2-o1 строит цепочку рассуждений с помощью древовидного поиска, механизма рефлексии и обучения с подкреплением, позволяя модели к саморефлексии и самокоррекции.",
  "4.0Ultra.description": "Spark Ultra — самая мощная модель в серии Spark, улучшает понимание текста и его резюмирование, а также расширяет возможности веб-поиска. Это комплексное решение для повышения продуктивности на рабочем месте и точности ответов, позиционирующееся как передовой интеллектуальный продукт.",
  "AnimeSharp.description": "AnimeSharp (также известная как \"4x-AnimeSharp\") — это открытая модель суперразрешения на основе ESRGAN от Kim2091, ориентированная на масштабирование и улучшение четкости изображений в аниме-стиле. В феврале 2022 года была переименована из \"4x-TextSharpV1\"; изначально предназначалась также для текстовых изображений, но была сильно оптимизирована под аниме-контент.",
  "Baichuan2-Turbo.description": "Использует расширение поиска для подключения модели к отраслевым и веб-знаниям. Поддерживает загрузку PDF/Word и ввод URL для своевременного, комплексного поиска и профессионального, точного вывода.",
  "Baichuan3-Turbo-128k.description": "С контекстным окном на 128K токенов, оптимизирована для частых бизнес-сценариев с высокой эффективностью. По сравнению с Baichuan2, генерация контента улучшена на 20%, ответы на вопросы — на 17%, ролевые сценарии — на 40%. Общая производительность выше, чем у GPT-3.5.",
  "Baichuan3-Turbo.description": "Оптимизирована для частых бизнес-сценариев с высокой эффективностью. По сравнению с Baichuan2, генерация контента улучшена на 20%, ответы на вопросы — на 17%, ролевые сценарии — на 40%. Общая производительность выше, чем у GPT-3.5.",
  "Baichuan4-Air.description": "Одна из лучших моделей в Китае, превосходящая ведущие зарубежные модели в задачах на китайском языке, таких как энциклопедические знания, длинные тексты и творческая генерация. Также обладает передовыми мультимодальными возможностями с высокими результатами на авторитетных бенчмарках.",
  "Baichuan4-Turbo.description": "Одна из лучших моделей в Китае, превосходящая ведущие зарубежные модели в задачах на китайском языке, таких как энциклопедические знания, длинные тексты и творческая генерация. Также обладает передовыми мультимодальными возможностями с высокими результатами на авторитетных бенчмарках.",
  "Baichuan4.description": "Лидер по производительности в Китае, превосходящий ведущие зарубежные модели в задачах на китайском языке, таких как энциклопедические знания, длинные тексты и творческая генерация. Также предлагает передовые мультимодальные возможности и высокие результаты на бенчмарках.",
  "ByteDance-Seed/Seed-OSS-36B-Instruct.description": "Seed-OSS — семейство открытых LLM от ByteDance Seed, разработанных для обработки длинного контекста, логического мышления, агентных задач и общих способностей. Seed-OSS-36B-Instruct — это модель с 36 миллиардами параметров, адаптированная под инструкции, с нативной поддержкой сверхдлинного контекста для обработки больших документов или кодовых баз. Оптимизирована для логики, генерации кода и агентных задач (использование инструментов), сохраняя при этом общие способности. Ключевая особенность — \"Бюджет мышления\", позволяющий гибко управлять длиной рассуждений для повышения эффективности.",
  "DeepSeek-R1-Distill-Llama-70B.description": "DeepSeek R1, более крупная и умная модель из набора DeepSeek, дистиллирована в архитектуру Llama 70B. Бенчмарки и оценки людей показывают, что она умнее базовой Llama 70B, особенно в задачах по математике и точности фактов.",
  "DeepSeek-R1-Distill-Qwen-1.5B.description": "Дистиллированная модель DeepSeek-R1 на основе Qwen2.5-Math-1.5B. Обучение с подкреплением и cold-start данные оптимизируют логическое мышление, устанавливая новые мультизадачные бенчмарки для открытых моделей.",
  "DeepSeek-R1-Distill-Qwen-14B.description": "Модели DeepSeek-R1-Distill дообучены на основе открытых моделей с использованием выборок, сгенерированных DeepSeek-R1.",
  "DeepSeek-R1-Distill-Qwen-32B.description": "Модели DeepSeek-R1-Distill дообучены на основе открытых моделей с использованием выборок, сгенерированных DeepSeek-R1.",
  "DeepSeek-R1-Distill-Qwen-7B.description": "Дистиллированная модель DeepSeek-R1 на основе Qwen2.5-Math-7B. Обучение с подкреплением и cold-start данные оптимизируют логическое мышление, устанавливая новые мультизадачные бенчмарки для открытых моделей.",
  "DeepSeek-R1.description": "DeepSeek-R1 применяет масштабное обучение с подкреплением на этапе дообучения, значительно улучшая логическое мышление при минимальной разметке. Сопоставима с OpenAI o1 в задачах по математике, программированию и языковому рассуждению.",
  "DeepSeek-V3-1.description": "DeepSeek V3.1 — модель нового поколения для логических задач с улучшенным сложным рассуждением и цепочкой мыслей, подходящая для задач глубокого анализа.",
  "DeepSeek-V3-Fast.description": "Провайдер: sophnet. DeepSeek V3 Fast — высокоскоростная версия DeepSeek V3 0324, с полной точностью (без квантования), улучшенной работой с кодом и математикой и более быстрыми ответами.",
  "DeepSeek-V3.1-Fast.description": "DeepSeek V3.1 Fast — высокоскоростной вариант DeepSeek V3.1. Гибридный режим мышления: через шаблоны чата одна модель поддерживает как мышление, так и немышление. Умное использование инструментов: дообучение улучшает работу с инструментами и агентными задачами.",
  "DeepSeek-V3.1-Think.description": "Режим мышления DeepSeek-V3.1: новая гибридная модель рассуждения с режимами мышления и немышления, более эффективная, чем DeepSeek-R1-0528. Оптимизации после обучения значительно улучшают использование инструментов и выполнение агентных задач.",
  "DeepSeek-V3.description": "DeepSeek-V3 — модель MoE, разработанная DeepSeek. Превосходит другие открытые модели, такие как Qwen2.5-72B и Llama-3.1-405B, по многим бенчмаркам и конкурирует с ведущими закрытыми моделями, такими как GPT-4o и Claude 3.5 Sonnet.",
  "Doubao-lite-128k.description": "Doubao-lite обеспечивает сверхбыстрые ответы и высокую ценность, предлагая гибкие варианты для различных сценариев. Поддерживает контекст до 128K токенов для вывода и дообучения.",
  "Doubao-lite-32k.description": "Doubao-lite обеспечивает сверхбыстрые ответы и высокую ценность, предлагая гибкие варианты для различных сценариев. Поддерживает контекст до 32K токенов для вывода и дообучения.",
  "Doubao-lite-4k.description": "Doubao-lite обеспечивает сверхбыстрые ответы и высокую ценность, предлагая гибкие варианты для различных сценариев. Поддерживает контекст до 4K токенов для вывода и дообучения.",
  "Doubao-pro-128k.description": "Флагманская модель с лучшей производительностью для сложных задач, сильна в справочных вопросах, резюмировании, создании контента, классификации и ролевых сценариях. Поддерживает контекст до 128K токенов для вывода и дообучения.",
  "Doubao-pro-32k.description": "Флагманская модель с лучшей производительностью для сложных задач, сильна в справочных вопросах, резюмировании, создании контента, классификации и ролевых сценариях. Поддерживает контекст до 32K токенов для вывода и дообучения.",
  "Doubao-pro-4k.description": "Флагманская модель с лучшей производительностью для сложных задач, сильна в справочных вопросах, резюмировании, создании контента, классификации и ролевых сценариях. Поддерживает контекст до 4K токенов для вывода и дообучения.",
  "DreamO.description": "DreamO — это открытая модель настройки изображений, совместно разработанная ByteDance и Пекинским университетом. Использует единую архитектуру для поддержки многозадачной генерации изображений. Применяет эффективное композиционное моделирование для создания высокосогласованных, персонализированных изображений на основе заданных пользователем параметров: идентичность, объект, стиль, фон и другие условия.",
  "amazon/titan-embed-text-v2.description": "Amazon Titan Text Embeddings V2 — легкая и эффективная многоязычная модель встраивания с поддержкой размерностей 1024, 512 и 256.",
  "gemini-flash-latest.description": "Последний релиз Gemini Flash",
  "gemini-flash-lite-latest.description": "Последний релиз Gemini Flash-Lite",
  "gemini-pro-latest.description": "Последний релиз Gemini Pro",
  "meta/Llama-3.2-90B-Vision-Instruct.description": "Продвинутая визуальная логика для приложений с агентами визуального понимания.",
  "meta/Llama-3.3-70B-Instruct.description": "Llama 3.3 — самая продвинутая многоязычная модель Llama с открытым исходным кодом, обеспечивающая производительность, близкую к 405B, при очень низкой стоимости. Основана на архитектуре Transformer и улучшена с помощью SFT и RLHF для повышения полезности и безопасности. Версия, адаптированная под инструкции, оптимизирована для многоязычного общения и превосходит многие открытые и закрытые модели чатов по отраслевым бенчмаркам. Актуальность знаний: декабрь 2023.",
  "meta/Meta-Llama-3-70B-Instruct.description": "Мощная модель с 70 миллиардами параметров, превосходно справляющаяся с логикой, программированием и широким спектром языковых задач.",
  "meta/Meta-Llama-3-8B-Instruct.description": "Универсальная модель с 8 миллиардами параметров, оптимизированная для общения и генерации текста.",
  "meta/Meta-Llama-3.1-405B-Instruct.description": "Модель Llama 3.1, адаптированная под инструкции, оптимизирована для многоязычного общения и демонстрирует высокие результаты на популярных отраслевых бенчмарках среди открытых и закрытых моделей чатов.",
  "meta/Meta-Llama-3.1-70B-Instruct.description": "Модель Llama 3.1, адаптированная под инструкции, оптимизирована для многоязычного общения и демонстрирует высокие результаты на популярных отраслевых бенчмарках среди открытых и закрытых моделей чатов.",
  "meta/Meta-Llama-3.1-8B-Instruct.description": "Модель Llama 3.1, адаптированная под инструкции, оптимизирована для многоязычного общения и демонстрирует высокие результаты на популярных отраслевых бенчмарках среди открытых и закрытых моделей чатов.",
  "meta/llama-3-70b.description": "Открытая модель с 70 миллиардами параметров, дообученная Meta для выполнения инструкций, работает на аппаратуре Groq LPU для быстрой и эффективной инференции.",
  "meta/llama-3-8b.description": "Открытая модель с 8 миллиардами параметров, дообученная Meta для выполнения инструкций, работает на аппаратуре Groq LPU для быстрой и эффективной инференции.",
  "meta/llama-3.1-405b-instruct.description": "Продвинутая языковая модель, поддерживающая генерацию синтетических данных, дистилляцию знаний и логические рассуждения для чат-ботов, программирования и специализированных задач.",
  "meta/llama-3.1-70b-instruct.description": "Создана для сложных диалогов с отличным пониманием контекста, логикой и генерацией текста.",
  "meta/llama-3.1-70b.description": "Обновлённая модель Meta Llama 3 70B Instruct с контекстом 128K, поддержкой многоязычности и улучшенной логикой.",
  "meta/llama-3.1-8b-instruct.description": "Передовая модель с высоким уровнем понимания языка, логики и генерации текста.",
  "meta/llama-3.1-8b.description": "Llama 3.1 8B поддерживает окно контекста 128K, идеально подходит для общения в реальном времени и анализа данных, обеспечивая значительную экономию по сравнению с более крупными моделями. Работает на аппаратуре Groq LPU для быстрой и эффективной инференции.",
  "meta/llama-3.2-11b-vision-instruct.description": "Передовая модель визуально-языкового понимания, превосходно справляющаяся с логическим анализом изображений.",
  "meta/llama-3.2-11b.description": "Модель, адаптированная под инструкции, для логического анализа изображений (вход: текст+изображение, выход: текст), оптимизирована для визуального распознавания, логики, описания и общего визуального QA.",
  "meta/llama-3.2-1b-instruct.description": "Передовая компактная языковая модель с высоким уровнем понимания, логики и генерации текста.",
  "meta/llama-3.2-1b.description": "Модель только для текста, предназначенная для локальных задач на устройствах, таких как многоязычный поиск, суммирование и переформулирование.",
  "meta/llama-3.2-3b-instruct.description": "Передовая компактная языковая модель с высоким уровнем понимания, логики и генерации текста.",
  "meta/llama-3.2-3b.description": "Модель только для текста, дообученная для локальных задач на устройствах, таких как многоязычный поиск, суммирование и переформулирование.",
  "meta/llama-3.2-90b-vision-instruct.description": "Передовая модель визуально-языкового понимания, превосходно справляющаяся с логическим анализом изображений.",
  "meta/llama-3.2-90b.description": "Модель, адаптированная под инструкции, для логического анализа изображений (вход: текст+изображение, выход: текст), оптимизирована для визуального распознавания, логики, описания и общего визуального QA.",
  "meta/llama-3.3-70b-instruct.description": "Продвинутая языковая модель с сильными навыками логики, математики, здравого смысла и вызова функций.",
  "meta/llama-3.3-70b.description": "Идеальный баланс производительности и эффективности. Создана для высокопроизводительного ИИ-общения в создании контента, корпоративных приложениях и исследованиях, с высоким уровнем понимания языка для суммирования, классификации, анализа тональности и генерации кода.",
  "meta/llama-4-maverick.description": "Семейство Llama 4 — это нативные мультимодальные ИИ-модели, поддерживающие текст и мультимодальные взаимодействия, использующие MoE для передового понимания текста и изображений. Llama 4 Maverick — модель с 17B параметрами и 128 экспертами, обслуживается DeepInfra.",
  "meta/llama-4-scout.description": "Семейство Llama 4 — это нативные мультимодальные ИИ-модели, поддерживающие текст и мультимодальные взаимодействия, использующие MoE для передового понимания текста и изображений. Llama 4 Scout — модель с 17B параметрами и 16 экспертами, обслуживается DeepInfra."
}
