{
  "01-ai/yi-1.5-34b-chat.description": "Mô hình tinh chỉnh mã nguồn mở mới nhất của 01.AI với 34 tỷ tham số, hỗ trợ nhiều tình huống hội thoại, được huấn luyện trên dữ liệu chất lượng cao và điều chỉnh theo sở thích của con người.",
  "01-ai/yi-1.5-9b-chat.description": "Mô hình tinh chỉnh mã nguồn mở mới nhất của 01.AI với 9 tỷ tham số, hỗ trợ nhiều tình huống hội thoại, được huấn luyện trên dữ liệu chất lượng cao và điều chỉnh theo sở thích của con người.",
  "360/deepseek-r1.description": "DeepSeek-R1 do 360 triển khai sử dụng học tăng cường quy mô lớn trong giai đoạn hậu huấn luyện để tăng cường khả năng suy luận với dữ liệu gán nhãn tối thiểu. Mô hình đạt hiệu suất tương đương OpenAI o1 trong các bài toán toán học, lập trình và suy luận ngôn ngữ tự nhiên.",
  "360gpt-pro-trans.description": "Mô hình chuyên biệt cho dịch thuật, được tinh chỉnh sâu để đạt chất lượng dịch hàng đầu.",
  "360gpt-pro.description": "360GPT Pro là mô hình AI chủ lực của 360 với khả năng xử lý văn bản hiệu quả trong nhiều tình huống NLP, hỗ trợ hiểu văn bản dài và hội thoại nhiều lượt.",
  "360gpt-turbo-responsibility-8k.description": "360GPT Turbo Responsibility 8K nhấn mạnh tính an toàn ngữ nghĩa và trách nhiệm trong các ứng dụng nhạy cảm về nội dung, đảm bảo trải nghiệm người dùng chính xác và ổn định.",
  "360gpt-turbo.description": "360GPT Turbo cung cấp khả năng tính toán và hội thoại mạnh mẽ với khả năng hiểu ngữ nghĩa và hiệu suất sinh văn bản vượt trội, lý tưởng cho doanh nghiệp và nhà phát triển.",
  "360gpt2-o1.description": "360gpt2-o1 xây dựng chuỗi suy nghĩ thông qua tìm kiếm cây kết hợp cơ chế phản tư và huấn luyện bằng học tăng cường, cho phép tự phản ánh và tự điều chỉnh.",
  "360gpt2-pro.description": "360GPT2 Pro là mô hình NLP tiên tiến của 360 với khả năng sinh và hiểu văn bản xuất sắc, đặc biệt phù hợp với các tác vụ sáng tạo, xử lý chuyển đổi phức tạp và nhập vai vai trò.",
  "360zhinao2-o1.description": "360zhinao2-o1 xây dựng chuỗi suy nghĩ thông qua tìm kiếm cây kết hợp cơ chế phản tư và huấn luyện bằng học tăng cường, cho phép tự phản ánh và tự điều chỉnh.",
  "4.0Ultra.description": "Spark Ultra là mô hình mạnh mẽ nhất trong dòng Spark, nâng cao khả năng hiểu và tóm tắt văn bản đồng thời cải thiện tìm kiếm web. Đây là giải pháp toàn diện giúp tăng năng suất làm việc và phản hồi chính xác, định vị như một sản phẩm trí tuệ hàng đầu.",
  "AnimeSharp.description": "AnimeSharp (còn gọi là \"4x-AnimeSharp\") là mô hình nâng cấp độ phân giải mã nguồn mở dựa trên ESRGAN của Kim2091, tập trung vào phóng to và làm sắc nét hình ảnh phong cách anime. Mô hình được đổi tên từ \"4x-TextSharpV1\" vào tháng 2 năm 2022, ban đầu cũng dùng cho hình ảnh văn bản nhưng đã được tối ưu mạnh cho nội dung anime.",
  "Baichuan2-Turbo.description": "Sử dụng tăng cường tìm kiếm để kết nối mô hình với tri thức chuyên ngành và web. Hỗ trợ tải lên PDF/Word và nhập URL để truy xuất kịp thời, toàn diện và tạo đầu ra chuyên nghiệp, chính xác.",
  "Baichuan3-Turbo-128k.description": "Với cửa sổ ngữ cảnh siêu dài 128K, mô hình được tối ưu cho các tình huống doanh nghiệp có tần suất cao với giá trị và hiệu quả vượt trội. So với Baichuan2, khả năng sáng tạo nội dung tăng 20%, hỏi đáp tri thức tăng 17% và nhập vai tăng 40%. Hiệu suất tổng thể vượt GPT-3.5.",
  "Baichuan3-Turbo.description": "Tối ưu cho các tình huống doanh nghiệp có tần suất cao với giá trị và hiệu quả vượt trội. So với Baichuan2, khả năng sáng tạo nội dung tăng 20%, hỏi đáp tri thức tăng 17% và nhập vai tăng 40%. Hiệu suất tổng thể vượt GPT-3.5.",
  "Baichuan4-Air.description": "Mô hình hàng đầu tại Trung Quốc, vượt qua nhiều mô hình quốc tế trong các tác vụ tiếng Trung như tri thức, văn bản dài và sáng tạo. Ngoài ra còn có khả năng đa phương tiện hàng đầu ngành với kết quả mạnh mẽ trên các bộ đánh giá uy tín.",
  "Baichuan4-Turbo.description": "Mô hình hàng đầu tại Trung Quốc, vượt qua nhiều mô hình quốc tế trong các tác vụ tiếng Trung như tri thức, văn bản dài và sáng tạo. Ngoài ra còn có khả năng đa phương tiện hàng đầu ngành với kết quả mạnh mẽ trên các bộ đánh giá uy tín.",
  "Baichuan4.description": "Hiệu suất hàng đầu trong nước, vượt qua các mô hình quốc tế hàng đầu trong các tác vụ tiếng Trung như tri thức bách khoa, văn bản dài và sáng tạo. Đồng thời cung cấp khả năng đa phương tiện hàng đầu ngành và kết quả đánh giá mạnh mẽ.",
  "ByteDance-Seed/Seed-OSS-36B-Instruct.description": "Seed-OSS là dòng mô hình LLM mã nguồn mở từ ByteDance Seed, thiết kế để xử lý ngữ cảnh dài, suy luận, tác vụ đại lý và khả năng tổng quát mạnh. Seed-OSS-36B-Instruct là mô hình 36B được tinh chỉnh theo hướng dẫn với khả năng xử lý ngữ cảnh siêu dài, phù hợp cho tài liệu hoặc mã nguồn lớn. Mô hình được tối ưu cho suy luận, sinh mã và tác vụ đại lý (sử dụng công cụ) trong khi vẫn giữ khả năng tổng quát mạnh. Tính năng nổi bật là \"Ngân sách Suy nghĩ\", cho phép điều chỉnh độ dài suy luận linh hoạt để tăng hiệu quả.",
  "DeepSeek-R1-Distill-Llama-70B.description": "DeepSeek R1, mô hình lớn và thông minh hơn trong bộ DeepSeek, được chưng cất vào kiến trúc Llama 70B. Các bài đánh giá và đánh giá người dùng cho thấy mô hình thông minh hơn Llama 70B gốc, đặc biệt trong các tác vụ toán học và độ chính xác thực tế.",
  "DeepSeek-R1-Distill-Qwen-1.5B.description": "Mô hình chưng cất DeepSeek-R1 dựa trên Qwen2.5-Math-1.5B. Học tăng cường và dữ liệu khởi động lạnh tối ưu hóa hiệu suất suy luận, thiết lập các chuẩn mới cho mô hình mã nguồn mở đa nhiệm.",
  "DeepSeek-R1-Distill-Qwen-14B.description": "Các mô hình DeepSeek-R1-Distill được tinh chỉnh từ các mô hình mã nguồn mở bằng dữ liệu mẫu do DeepSeek-R1 tạo ra.",
  "DeepSeek-R1-Distill-Qwen-32B.description": "Các mô hình DeepSeek-R1-Distill được tinh chỉnh từ các mô hình mã nguồn mở bằng dữ liệu mẫu do DeepSeek-R1 tạo ra.",
  "DeepSeek-R1-Distill-Qwen-7B.description": "Mô hình chưng cất DeepSeek-R1 dựa trên Qwen2.5-Math-7B. Học tăng cường và dữ liệu khởi động lạnh tối ưu hóa hiệu suất suy luận, thiết lập các chuẩn mới cho mô hình mã nguồn mở đa nhiệm.",
  "DeepSeek-R1.description": "DeepSeek-R1 áp dụng học tăng cường quy mô lớn trong giai đoạn hậu huấn luyện, tăng cường đáng kể khả năng suy luận với rất ít dữ liệu gán nhãn. Mô hình đạt hiệu suất tương đương OpenAI o1 trong các tác vụ toán học, lập trình và suy luận ngôn ngữ tự nhiên.",
  "DeepSeek-V3-1.description": "DeepSeek V3.1 là mô hình suy luận thế hệ tiếp theo với khả năng suy luận phức tạp và chuỗi suy nghĩ được cải thiện, phù hợp cho các tác vụ phân tích chuyên sâu.",
  "DeepSeek-V3-Fast.description": "Nhà cung cấp: sophnet. DeepSeek V3 Fast là phiên bản tốc độ cao của DeepSeek V3 0324, sử dụng độ chính xác đầy đủ (không lượng tử hóa) với khả năng lập trình và toán học mạnh hơn và phản hồi nhanh hơn.",
  "DeepSeek-V3.1-Fast.description": "DeepSeek V3.1 Fast là biến thể tốc độ cao của DeepSeek V3.1. Chế độ suy nghĩ kết hợp: thông qua mẫu hội thoại, một mô hình hỗ trợ cả suy nghĩ và không suy nghĩ. Sử dụng công cụ thông minh hơn: hậu huấn luyện tăng cường hiệu suất tác vụ công cụ và đại lý.",
  "DeepSeek-V3.1-Think.description": "Chế độ suy nghĩ DeepSeek-V3.1: mô hình suy luận kết hợp mới với chế độ suy nghĩ và không suy nghĩ, hiệu quả hơn DeepSeek-R1-0528. Tối ưu hóa hậu huấn luyện cải thiện đáng kể việc sử dụng công cụ đại lý và hiệu suất tác vụ đại lý.",
  "DeepSeek-V3.description": "DeepSeek-V3 là mô hình MoE do DeepSeek phát triển. Mô hình vượt qua các mô hình mã nguồn mở khác như Qwen2.5-72B và Llama-3.1-405B trên nhiều bộ đánh giá và cạnh tranh với các mô hình đóng hàng đầu như GPT-4o và Claude 3.5 Sonnet.",
  "Doubao-lite-128k.description": "Doubao-lite cung cấp phản hồi siêu nhanh và giá trị tốt hơn, với các tùy chọn linh hoạt cho nhiều tình huống. Hỗ trợ ngữ cảnh 128K cho suy luận và tinh chỉnh.",
  "Doubao-lite-32k.description": "Doubao-lite cung cấp phản hồi siêu nhanh và giá trị tốt hơn, với các tùy chọn linh hoạt cho nhiều tình huống. Hỗ trợ ngữ cảnh 32K cho suy luận và tinh chỉnh.",
  "Doubao-lite-4k.description": "Doubao-lite cung cấp phản hồi siêu nhanh và giá trị tốt hơn, với các tùy chọn linh hoạt cho nhiều tình huống. Hỗ trợ ngữ cảnh 4K cho suy luận và tinh chỉnh.",
  "Doubao-pro-128k.description": "Mô hình chủ lực có hiệu suất tốt nhất cho các tác vụ phức tạp, mạnh về hỏi đáp tham chiếu, tóm tắt, sáng tạo, phân loại và nhập vai. Hỗ trợ ngữ cảnh 128K cho suy luận và tinh chỉnh.",
  "Doubao-pro-32k.description": "Mô hình chủ lực có hiệu suất tốt nhất cho các tác vụ phức tạp, mạnh về hỏi đáp tham chiếu, tóm tắt, sáng tạo, phân loại và nhập vai. Hỗ trợ ngữ cảnh 32K cho suy luận và tinh chỉnh.",
  "Doubao-pro-4k.description": "Mô hình chủ lực có hiệu suất tốt nhất cho các tác vụ phức tạp, mạnh về hỏi đáp tham chiếu, tóm tắt, sáng tạo, phân loại và nhập vai. Hỗ trợ ngữ cảnh 4K cho suy luận và tinh chỉnh.",
  "DreamO.description": "DreamO là mô hình tùy chỉnh hình ảnh mã nguồn mở do ByteDance và Đại học Bắc Kinh phát triển, sử dụng kiến trúc thống nhất để hỗ trợ sinh ảnh đa nhiệm. Mô hình sử dụng mô hình hóa thành phần hiệu quả để tạo ra hình ảnh tùy chỉnh, nhất quán cao dựa trên danh tính, chủ đề, phong cách, nền và các điều kiện khác do người dùng chỉ định.",
  "amazon/titan-embed-text-v2.description": "Amazon Titan Text Embeddings V2 là mô hình nhúng đa ngôn ngữ nhẹ, hiệu quả, hỗ trợ các chiều 1024, 512 và 256.",
  "gemini-flash-latest.description": "Phiên bản mới nhất của Gemini Flash",
  "gemini-flash-lite-latest.description": "Phiên bản mới nhất của Gemini Flash-Lite",
  "gemini-pro-latest.description": "Phiên bản mới nhất của Gemini Pro",
  "meta/Llama-3.2-90B-Vision-Instruct.description": "Khả năng suy luận hình ảnh tiên tiến cho các ứng dụng tác nhân hiểu thị giác.",
  "meta/Llama-3.3-70B-Instruct.description": "Llama 3.3 là mô hình Llama mã nguồn mở đa ngôn ngữ tiên tiến nhất, đạt hiệu suất gần tương đương mô hình 405B với chi phí rất thấp. Dựa trên kiến trúc Transformer và được cải tiến bằng SFT và RLHF để tăng tính hữu ích và an toàn. Phiên bản tinh chỉnh theo hướng dẫn được tối ưu cho trò chuyện đa ngôn ngữ và vượt trội hơn nhiều mô hình trò chuyện mở và đóng trong các tiêu chuẩn ngành. Giới hạn kiến thức: Tháng 12 năm 2023.",
  "meta/Meta-Llama-3-70B-Instruct.description": "Mô hình mạnh mẽ với 70 tỷ tham số, xuất sắc trong suy luận, lập trình và các tác vụ ngôn ngữ tổng quát.",
  "meta/Meta-Llama-3-8B-Instruct.description": "Mô hình linh hoạt với 8 tỷ tham số, được tối ưu hóa cho trò chuyện và tạo văn bản.",
  "meta/Meta-Llama-3.1-405B-Instruct.description": "Mô hình văn bản Llama 3.1 tinh chỉnh theo hướng dẫn, tối ưu cho trò chuyện đa ngôn ngữ, đạt hiệu suất cao trong các tiêu chuẩn ngành giữa các mô hình trò chuyện mở và đóng.",
  "meta/Meta-Llama-3.1-70B-Instruct.description": "Mô hình văn bản Llama 3.1 tinh chỉnh theo hướng dẫn, tối ưu cho trò chuyện đa ngôn ngữ, đạt hiệu suất cao trong các tiêu chuẩn ngành giữa các mô hình trò chuyện mở và đóng.",
  "meta/Meta-Llama-3.1-8B-Instruct.description": "Mô hình văn bản Llama 3.1 tinh chỉnh theo hướng dẫn, tối ưu cho trò chuyện đa ngôn ngữ, đạt hiệu suất cao trong các tiêu chuẩn ngành giữa các mô hình trò chuyện mở và đóng.",
  "meta/llama-3-70b.description": "Mô hình mã nguồn mở 70B được Meta tinh chỉnh để tuân theo hướng dẫn, được triển khai bởi Groq trên phần cứng LPU cho suy luận nhanh và hiệu quả.",
  "meta/llama-3-8b.description": "Mô hình mã nguồn mở 8B được Meta tinh chỉnh để tuân theo hướng dẫn, được triển khai bởi Groq trên phần cứng LPU cho suy luận nhanh và hiệu quả.",
  "meta/llama-3.1-405b-instruct.description": "Mô hình ngôn ngữ tiên tiến hỗ trợ tạo dữ liệu tổng hợp, chưng cất tri thức và suy luận cho chatbot, lập trình và các tác vụ chuyên ngành.",
  "meta/llama-3.1-70b-instruct.description": "Được xây dựng cho đối thoại phức tạp với khả năng hiểu ngữ cảnh, suy luận và tạo văn bản xuất sắc.",
  "meta/llama-3.1-70b.description": "Phiên bản cập nhật của Meta Llama 3 70B Instruct với ngữ cảnh 128K, hỗ trợ đa ngôn ngữ và khả năng suy luận được cải thiện.",
  "meta/llama-3.1-8b-instruct.description": "Mô hình tiên tiến với khả năng hiểu ngôn ngữ, suy luận và tạo văn bản mạnh mẽ.",
  "meta/llama-3.1-8b.description": "Llama 3.1 8B hỗ trợ cửa sổ ngữ cảnh 128K, lý tưởng cho trò chuyện thời gian thực và phân tích dữ liệu, đồng thời tiết kiệm chi phí đáng kể so với các mô hình lớn hơn. Được triển khai bởi Groq trên phần cứng LPU cho suy luận nhanh và hiệu quả.",
  "meta/llama-3.2-11b-vision-instruct.description": "Mô hình ngôn ngữ-thị giác tiên phong, xuất sắc trong suy luận chất lượng cao từ hình ảnh.",
  "meta/llama-3.2-11b.description": "Mô hình suy luận hình ảnh tinh chỉnh theo hướng dẫn (đầu vào văn bản + hình ảnh, đầu ra văn bản), được tối ưu hóa cho nhận diện thị giác, suy luận hình ảnh, tạo chú thích và hỏi đáp hình ảnh tổng quát.",
  "meta/llama-3.2-1b-instruct.description": "Mô hình ngôn ngữ nhỏ tiên tiến với khả năng hiểu, suy luận và tạo văn bản mạnh mẽ.",
  "meta/llama-3.2-1b.description": "Mô hình chỉ văn bản dành cho các trường hợp sử dụng trên thiết bị như truy xuất cục bộ đa ngôn ngữ, tóm tắt và viết lại.",
  "meta/llama-3.2-3b-instruct.description": "Mô hình ngôn ngữ nhỏ tiên tiến với khả năng hiểu, suy luận và tạo văn bản mạnh mẽ.",
  "meta/llama-3.2-3b.description": "Mô hình chỉ văn bản được tinh chỉnh cho các trường hợp sử dụng trên thiết bị như truy xuất cục bộ đa ngôn ngữ, tóm tắt và viết lại.",
  "meta/llama-3.2-90b-vision-instruct.description": "Mô hình ngôn ngữ-thị giác tiên phong, xuất sắc trong suy luận chất lượng cao từ hình ảnh.",
  "meta/llama-3.2-90b.description": "Mô hình suy luận hình ảnh tinh chỉnh theo hướng dẫn (đầu vào văn bản + hình ảnh, đầu ra văn bản), được tối ưu hóa cho nhận diện thị giác, suy luận hình ảnh, tạo chú thích và hỏi đáp hình ảnh tổng quát.",
  "meta/llama-3.3-70b-instruct.description": "Mô hình ngôn ngữ tiên tiến với khả năng suy luận, toán học, tư duy thông thường và gọi hàm mạnh mẽ.",
  "meta/llama-3.3-70b.description": "Sự cân bằng hoàn hảo giữa hiệu suất và hiệu quả. Được xây dựng cho AI hội thoại hiệu suất cao trong sáng tạo nội dung, ứng dụng doanh nghiệp và nghiên cứu, với khả năng hiểu ngôn ngữ mạnh mẽ cho tóm tắt, phân loại, phân tích cảm xúc và tạo mã.",
  "meta/llama-4-maverick.description": "Dòng Llama 4 là bộ mô hình AI đa phương thức gốc hỗ trợ văn bản và trải nghiệm đa phương thức, sử dụng MoE để hiểu văn bản và hình ảnh hàng đầu. Llama 4 Maverick là mô hình 17B với 128 chuyên gia, được triển khai bởi DeepInfra.",
  "meta/llama-4-scout.description": "Dòng Llama 4 là bộ mô hình AI đa phương thức gốc hỗ trợ văn bản và trải nghiệm đa phương thức, sử dụng MoE để hiểu văn bản và hình ảnh hàng đầu. Llama 4 Scout là mô hình 17B với 16 chuyên gia, được triển khai bởi DeepInfra."
}
