{
  "01-ai/yi-1.5-34b-chat.description": "Mô hình mã nguồn mở mới nhất của 01.AI với 34 tỷ tham số, hỗ trợ nhiều tình huống hội thoại, được huấn luyện trên dữ liệu chất lượng cao và điều chỉnh theo sở thích của con người.",
  "01-ai/yi-1.5-9b-chat.description": "Mô hình mã nguồn mở mới nhất của 01.AI với 9 tỷ tham số, hỗ trợ nhiều tình huống hội thoại, được huấn luyện trên dữ liệu chất lượng cao và điều chỉnh theo sở thích của con người.",
  "360/deepseek-r1.description": "DeepSeek-R1 do 360 triển khai sử dụng học tăng cường quy mô lớn trong giai đoạn hậu huấn luyện để tăng cường khả năng suy luận với lượng nhãn tối thiểu. Mô hình đạt hiệu suất tương đương OpenAI o1 trong các bài toán toán học, lập trình và suy luận ngôn ngữ tự nhiên.",
  "360gpt-pro-trans.description": "Mô hình chuyên biệt cho dịch thuật, được tinh chỉnh sâu để đạt chất lượng dịch hàng đầu.",
  "360gpt-pro.description": "360GPT Pro là mô hình AI chủ lực của 360 với khả năng xử lý văn bản hiệu quả trong nhiều tình huống NLP, hỗ trợ hiểu văn bản dài và hội thoại nhiều lượt.",
  "360gpt-turbo-responsibility-8k.description": "360GPT Turbo Responsibility 8K nhấn mạnh tính an toàn ngữ nghĩa và trách nhiệm trong các ứng dụng nhạy cảm về nội dung, đảm bảo trải nghiệm người dùng chính xác và ổn định.",
  "360gpt-turbo.description": "360GPT Turbo cung cấp khả năng tính toán và hội thoại mạnh mẽ với khả năng hiểu và sinh ngữ nghĩa xuất sắc, lý tưởng cho doanh nghiệp và nhà phát triển.",
  "360gpt2-o1.description": "360gpt2-o1 xây dựng chuỗi suy nghĩ thông qua tìm kiếm cây kết hợp cơ chế phản chiếu và huấn luyện bằng học tăng cường, cho phép tự phản ánh và tự điều chỉnh.",
  "360gpt2-pro.description": "360GPT2 Pro là mô hình NLP tiên tiến của 360 với khả năng sinh và hiểu văn bản xuất sắc, đặc biệt phù hợp với các tác vụ sáng tạo, xử lý chuyển đổi phức tạp và nhập vai.",
  "360zhinao2-o1.description": "360zhinao2-o1 xây dựng chuỗi suy nghĩ thông qua tìm kiếm cây kết hợp cơ chế phản chiếu và huấn luyện bằng học tăng cường, cho phép tự phản ánh và tự điều chỉnh.",
  "4.0Ultra.description": "Spark Ultra là mô hình mạnh mẽ nhất trong dòng Spark, nâng cao khả năng hiểu và tóm tắt văn bản đồng thời cải thiện tìm kiếm web. Đây là giải pháp toàn diện giúp tăng năng suất làm việc và phản hồi chính xác, định vị như một sản phẩm trí tuệ hàng đầu.",
  "AnimeSharp.description": "AnimeSharp (còn gọi là \"4x-AnimeSharp\") là mô hình nâng cấp độ phân giải mã nguồn mở dựa trên ESRGAN của Kim2091, tập trung vào việc phóng to và làm sắc nét hình ảnh phong cách anime. Mô hình được đổi tên từ \"4x-TextSharpV1\" vào tháng 2 năm 2022, ban đầu cũng dùng cho hình ảnh văn bản nhưng đã được tối ưu mạnh cho nội dung anime.",
  "Baichuan2-Turbo.description": "Sử dụng tăng cường tìm kiếm để kết nối mô hình với tri thức chuyên ngành và web. Hỗ trợ tải lên PDF/Word và nhập URL để truy xuất kịp thời, toàn diện và tạo đầu ra chuyên nghiệp, chính xác.",
  "Baichuan3-Turbo-128k.description": "Với cửa sổ ngữ cảnh siêu dài 128K, mô hình được tối ưu cho các tình huống doanh nghiệp có tần suất cao với giá trị và hiệu quả vượt trội. So với Baichuan2, khả năng sáng tạo nội dung tăng 20%, hỏi đáp tri thức tăng 17% và nhập vai tăng 40%. Hiệu suất tổng thể vượt GPT-3.5.",
  "Baichuan3-Turbo.description": "Tối ưu cho các tình huống doanh nghiệp có tần suất cao với giá trị và hiệu quả vượt trội. So với Baichuan2, khả năng sáng tạo nội dung tăng 20%, hỏi đáp tri thức tăng 17% và nhập vai tăng 40%. Hiệu suất tổng thể vượt GPT-3.5.",
  "Baichuan4-Air.description": "Mô hình hàng đầu tại Trung Quốc, vượt qua nhiều mô hình quốc tế trong các tác vụ tiếng Trung như tri thức, văn bản dài và sáng tạo. Ngoài ra còn có khả năng đa phương tiện hàng đầu với kết quả mạnh mẽ trên các bảng đánh giá uy tín.",
  "Baichuan4-Turbo.description": "Mô hình hàng đầu tại Trung Quốc, vượt qua nhiều mô hình quốc tế trong các tác vụ tiếng Trung như tri thức, văn bản dài và sáng tạo. Ngoài ra còn có khả năng đa phương tiện hàng đầu với kết quả mạnh mẽ trên các bảng đánh giá uy tín.",
  "Baichuan4.description": "Hiệu suất hàng đầu trong nước, vượt qua các mô hình quốc tế hàng đầu trong các tác vụ tiếng Trung như tri thức bách khoa, văn bản dài và sáng tạo. Đồng thời cung cấp khả năng đa phương tiện hàng đầu và kết quả mạnh mẽ trên các bảng đánh giá.",
  "ByteDance-Seed/Seed-OSS-36B-Instruct.description": "Seed-OSS là dòng mô hình LLM mã nguồn mở từ ByteDance Seed, được thiết kế để xử lý ngữ cảnh dài, suy luận, tác vụ đại lý và khả năng tổng quát mạnh mẽ. Seed-OSS-36B-Instruct là mô hình 36B được tinh chỉnh theo hướng dẫn với khả năng xử lý ngữ cảnh siêu dài, phù hợp cho tài liệu hoặc mã nguồn lớn. Mô hình được tối ưu cho suy luận, sinh mã và tác vụ đại lý (sử dụng công cụ) trong khi vẫn giữ được khả năng tổng quát mạnh. Tính năng nổi bật là \"Ngân sách Suy nghĩ\" cho phép điều chỉnh độ dài suy luận linh hoạt để tăng hiệu quả.",
  "DeepSeek-R1-Distill-Llama-70B.description": "DeepSeek R1, mô hình lớn và thông minh hơn trong bộ DeepSeek, được chưng cất vào kiến trúc Llama 70B. Các bài đánh giá và đánh giá người dùng cho thấy mô hình thông minh hơn Llama 70B gốc, đặc biệt trong các tác vụ toán học và độ chính xác tri thức.",
  "DeepSeek-R1-Distill-Qwen-1.5B.description": "Mô hình chưng cất DeepSeek-R1 dựa trên Qwen2.5-Math-1.5B. Học tăng cường và dữ liệu khởi đầu lạnh được sử dụng để tối ưu hóa hiệu suất suy luận, thiết lập các chuẩn mới cho mô hình mã nguồn mở đa nhiệm.",
  "DeepSeek-R1-Distill-Qwen-14B.description": "Các mô hình DeepSeek-R1-Distill được tinh chỉnh từ các mô hình mã nguồn mở bằng cách sử dụng dữ liệu mẫu do DeepSeek-R1 tạo ra.",
  "DeepSeek-R1-Distill-Qwen-32B.description": "Các mô hình DeepSeek-R1-Distill được tinh chỉnh từ các mô hình mã nguồn mở bằng cách sử dụng dữ liệu mẫu do DeepSeek-R1 tạo ra.",
  "DeepSeek-R1-Distill-Qwen-7B.description": "Mô hình chưng cất DeepSeek-R1 dựa trên Qwen2.5-Math-7B. Học tăng cường và dữ liệu khởi đầu lạnh được sử dụng để tối ưu hóa hiệu suất suy luận, thiết lập các chuẩn mới cho mô hình mã nguồn mở đa nhiệm.",
  "DeepSeek-R1.description": "DeepSeek-R1 áp dụng học tăng cường quy mô lớn trong giai đoạn hậu huấn luyện, giúp tăng cường khả năng suy luận với rất ít dữ liệu gán nhãn. Mô hình đạt hiệu suất tương đương với OpenAI o1 trong các tác vụ toán học, lập trình và suy luận ngôn ngữ tự nhiên.",
  "DeepSeek-V3-1.description": "DeepSeek V3.1 là mô hình suy luận thế hệ tiếp theo với khả năng suy luận phức tạp và chuỗi suy nghĩ được cải thiện, phù hợp với các tác vụ phân tích chuyên sâu.",
  "DeepSeek-V3-Fast.description": "Nhà cung cấp: sophnet. DeepSeek V3 Fast là phiên bản tốc độ cao của DeepSeek V3 0324, sử dụng độ chính xác đầy đủ (không nén) với khả năng lập trình và toán học mạnh hơn cùng phản hồi nhanh hơn.",
  "DeepSeek-V3.1-Fast.description": "DeepSeek V3.1 Fast là biến thể tốc độ cao của DeepSeek V3.1. Chế độ suy nghĩ kết hợp: thông qua mẫu hội thoại, một mô hình hỗ trợ cả suy nghĩ và không suy nghĩ. Sử dụng công cụ thông minh hơn: hậu huấn luyện tăng hiệu suất tác vụ công cụ và đại lý.",
  "DeepSeek-V3.1-Think.description": "Chế độ suy nghĩ DeepSeek-V3.1: mô hình suy luận kết hợp mới với chế độ suy nghĩ và không suy nghĩ, hiệu quả hơn DeepSeek-R1-0528. Tối ưu hóa hậu huấn luyện cải thiện đáng kể việc sử dụng công cụ đại lý và hiệu suất tác vụ đại lý.",
  "DeepSeek-V3.description": "DeepSeek-V3 là mô hình MoE do DeepSeek phát triển. Mô hình vượt qua các mô hình mã nguồn mở khác như Qwen2.5-72B và Llama-3.1-405B trên nhiều bảng đánh giá và cạnh tranh với các mô hình đóng hàng đầu như GPT-4o và Claude 3.5 Sonnet.",
  "Doubao-lite-128k.description": "Doubao-lite cung cấp phản hồi siêu nhanh và giá trị tốt hơn, với các tùy chọn linh hoạt cho nhiều tình huống. Hỗ trợ ngữ cảnh 128K cho suy luận và tinh chỉnh.",
  "Doubao-lite-32k.description": "Doubao-lite cung cấp phản hồi siêu nhanh và giá trị tốt hơn, với các tùy chọn linh hoạt cho nhiều tình huống. Hỗ trợ ngữ cảnh 32K cho suy luận và tinh chỉnh.",
  "Doubao-lite-4k.description": "Doubao-lite cung cấp phản hồi siêu nhanh và giá trị tốt hơn, với các tùy chọn linh hoạt cho nhiều tình huống. Hỗ trợ ngữ cảnh 4K cho suy luận và tinh chỉnh.",
  "Doubao-pro-128k.description": "Mô hình chủ lực có hiệu suất tốt nhất cho các tác vụ phức tạp, mạnh về hỏi đáp tham chiếu, tóm tắt, sáng tạo, phân loại và nhập vai. Hỗ trợ ngữ cảnh 128K cho suy luận và tinh chỉnh.",
  "Doubao-pro-32k.description": "Mô hình chủ lực có hiệu suất tốt nhất cho các tác vụ phức tạp, mạnh về hỏi đáp tham chiếu, tóm tắt, sáng tạo, phân loại và nhập vai. Hỗ trợ ngữ cảnh 32K cho suy luận và tinh chỉnh.",
  "Doubao-pro-4k.description": "Mô hình chủ lực có hiệu suất tốt nhất cho các tác vụ phức tạp, mạnh về hỏi đáp tham chiếu, tóm tắt, sáng tạo, phân loại và nhập vai. Hỗ trợ ngữ cảnh 4K cho suy luận và tinh chỉnh.",
  "DreamO.description": "DreamO là mô hình tùy chỉnh hình ảnh mã nguồn mở do ByteDance và Đại học Bắc Kinh phát triển, sử dụng kiến trúc thống nhất để hỗ trợ tạo hình ảnh đa nhiệm. Mô hình sử dụng mô hình hóa thành phần hiệu quả để tạo ra hình ảnh tùy chỉnh, nhất quán cao dựa trên danh tính, chủ đề, phong cách, nền và các điều kiện khác do người dùng chỉ định.",
  "ERNIE-3.5-128K.description": "Mô hình LLM quy mô lớn hàng đầu của Baidu, được huấn luyện trên kho dữ liệu tiếng Trung/Anh khổng lồ, có khả năng vượt trội trong trò chuyện, sáng tạo và sử dụng plugin; hỗ trợ tích hợp tự động plugin Tìm kiếm Baidu để cung cấp câu trả lời mới nhất.",
  "ERNIE-3.5-8K-Preview.description": "Mô hình LLM quy mô lớn hàng đầu của Baidu, được huấn luyện trên kho dữ liệu tiếng Trung/Anh khổng lồ, có khả năng vượt trội trong trò chuyện, sáng tạo và sử dụng plugin; hỗ trợ tích hợp tự động plugin Tìm kiếm Baidu để cung cấp câu trả lời mới nhất.",
  "ERNIE-3.5-8K.description": "Mô hình LLM quy mô lớn hàng đầu của Baidu, được huấn luyện trên kho dữ liệu tiếng Trung/Anh khổng lồ, có khả năng vượt trội trong trò chuyện, sáng tạo và sử dụng plugin; hỗ trợ tích hợp tự động plugin Tìm kiếm Baidu để cung cấp câu trả lời mới nhất.",
  "ERNIE-4.0-8K-Latest.description": "Mô hình LLM siêu lớn hàng đầu của Baidu với các nâng cấp toàn diện so với ERNIE 3.5, phù hợp cho các tác vụ phức tạp đa lĩnh vực; hỗ trợ tích hợp plugin Tìm kiếm Baidu để cung cấp câu trả lời mới nhất.",
  "ERNIE-4.0-8K-Preview.description": "Mô hình LLM siêu lớn hàng đầu của Baidu với các nâng cấp toàn diện so với ERNIE 3.5, phù hợp cho các tác vụ phức tạp đa lĩnh vực; hỗ trợ tích hợp plugin Tìm kiếm Baidu để cung cấp câu trả lời mới nhất.",
  "ERNIE-4.0-Turbo-8K-Latest.description": "Mô hình LLM siêu lớn hàng đầu của Baidu với hiệu suất tổng thể mạnh mẽ cho các tác vụ phức tạp, tích hợp plugin Tìm kiếm Baidu để cung cấp câu trả lời mới nhất. Vượt trội hơn ERNIE 4.0.",
  "ERNIE-4.0-Turbo-8K-Preview.description": "Mô hình LLM siêu lớn hàng đầu của Baidu với hiệu suất tổng thể mạnh mẽ cho các tác vụ phức tạp, tích hợp plugin Tìm kiếm Baidu để cung cấp câu trả lời mới nhất. Vượt trội hơn ERNIE 4.0.",
  "ERNIE-Character-8K.description": "Mô hình LLM chuyên biệt theo lĩnh vực của Baidu dành cho NPC trong game, dịch vụ khách hàng và nhập vai, với tính nhất quán nhân vật rõ ràng hơn, khả năng tuân thủ hướng dẫn tốt hơn và tư duy logic mạnh mẽ hơn.",
  "ERNIE-Lite-Pro-128K.description": "Mô hình LLM nhẹ của Baidu cân bằng giữa chất lượng và hiệu suất suy luận, vượt trội hơn ERNIE Lite và phù hợp với các thiết bị tăng tốc tính toán thấp.",
  "ERNIE-Speed-128K.description": "Mô hình LLM hiệu suất cao mới nhất của Baidu (2024) với khả năng tổng quát mạnh mẽ, phù hợp làm nền tảng tinh chỉnh cho các tình huống cụ thể, có hiệu suất tư duy xuất sắc.",
  "ERNIE-Speed-Pro-128K.description": "Mô hình LLM hiệu suất cao mới nhất của Baidu (2024) với khả năng tổng quát mạnh mẽ, vượt trội hơn ERNIE Speed, phù hợp làm nền tảng tinh chỉnh với hiệu suất tư duy xuất sắc.",
  "FLUX-1.1-pro.description": "FLUX.1.1 Pro",
  "FLUX.1-Kontext-dev.description": "FLUX.1-Kontext-dev là một mô hình tạo và chỉnh sửa hình ảnh đa phương thức từ Black Forest Labs, dựa trên kiến trúc Rectified Flow Transformer với 12 tỷ tham số. Mô hình tập trung vào việc tạo, tái tạo, nâng cao hoặc chỉnh sửa hình ảnh theo các điều kiện ngữ cảnh được cung cấp. Nó kết hợp khả năng tạo có kiểm soát của các mô hình khuếch tán với mô hình hóa ngữ cảnh của Transformer, hỗ trợ đầu ra chất lượng cao cho các tác vụ như inpainting, outpainting và tái tạo cảnh thị giác.",
  "FLUX.1-Kontext-pro.description": "FLUX.1 Kontext [pro]",
  "FLUX.1-dev.description": "FLUX.1-dev là một mô hình ngôn ngữ đa phương thức mã nguồn mở (MLLM) từ Black Forest Labs, được tối ưu hóa cho các tác vụ hình ảnh-văn bản, kết hợp khả năng hiểu và tạo hình ảnh/văn bản. Dựa trên các LLM tiên tiến (như Mistral-7B), mô hình sử dụng bộ mã hóa thị giác được thiết kế cẩn thận và tinh chỉnh theo nhiều giai đoạn để hỗ trợ phối hợp đa phương thức và suy luận các tác vụ phức tạp.",
  "Gryphe/MythoMax-L2-13b.description": "MythoMax-L2 (13B) là một mô hình sáng tạo cho nhiều lĩnh vực và tác vụ phức tạp.",
  "HelloMeme.description": "HelloMeme là một công cụ AI tạo meme, GIF hoặc video ngắn từ hình ảnh hoặc chuyển động bạn cung cấp. Không cần kỹ năng vẽ hoặc lập trình—chỉ cần một hình ảnh tham chiếu—để tạo ra nội dung vui nhộn, hấp dẫn và nhất quán về mặt phong cách.",
  "HiDream-I1-Full.description": "HiDream-E1-Full là một mô hình chỉnh sửa hình ảnh đa phương thức mã nguồn mở từ HiDream.ai, dựa trên kiến trúc Diffusion Transformer tiên tiến và khả năng hiểu ngôn ngữ mạnh mẽ (tích hợp sẵn LLaMA 3.1-8B-Instruct). Mô hình hỗ trợ tạo hình ảnh bằng ngôn ngữ tự nhiên, chuyển đổi phong cách, chỉnh sửa cục bộ và vẽ lại, với khả năng hiểu và thực thi văn bản-hình ảnh xuất sắc.",
  "HunyuanDiT-v1.2-Diffusers-Distilled.description": "hunyuandit-v1.2-distilled là một mô hình chuyển văn bản thành hình ảnh nhẹ, được tối ưu hóa thông qua quá trình chưng cất để tạo hình ảnh chất lượng cao nhanh chóng, đặc biệt phù hợp với môi trường tài nguyên thấp và yêu cầu tạo thời gian thực.",
  "InstantCharacter.description": "InstantCharacter là một mô hình tạo nhân vật cá nhân hóa không cần tinh chỉnh do Tencent AI phát hành năm 2025, hướng đến việc tạo nhân vật nhất quán, độ trung thực cao trong nhiều bối cảnh khác nhau. Mô hình có thể tạo nhân vật từ một hình ảnh tham chiếu duy nhất và linh hoạt chuyển đổi qua các phong cách, hành động và nền khác nhau.",
  "InternVL2-8B.description": "InternVL2-8B là một mô hình ngôn ngữ-thị giác mạnh mẽ hỗ trợ xử lý hình ảnh-văn bản đa phương thức, nhận diện chính xác nội dung hình ảnh và tạo mô tả hoặc câu trả lời phù hợp.",
  "InternVL2.5-26B.description": "InternVL2.5-26B là một mô hình ngôn ngữ-thị giác mạnh mẽ hỗ trợ xử lý hình ảnh-văn bản đa phương thức, nhận diện chính xác nội dung hình ảnh và tạo mô tả hoặc câu trả lời phù hợp.",
  "Kolors.description": "Kolors là một mô hình chuyển văn bản thành hình ảnh do nhóm Kuaishou Kolors phát triển. Được huấn luyện với hàng tỷ tham số, mô hình có ưu thế nổi bật về chất lượng hình ảnh, hiểu ngữ nghĩa tiếng Trung và hiển thị văn bản.",
  "Kwai-Kolors/Kolors.description": "Kolors là một mô hình chuyển văn bản thành hình ảnh quy mô lớn dựa trên khuếch tán tiềm ẩn do nhóm Kuaishou Kolors phát triển. Được huấn luyện trên hàng tỷ cặp văn bản-hình ảnh, mô hình vượt trội về chất lượng hình ảnh, độ chính xác ngữ nghĩa phức tạp và hiển thị văn bản tiếng Trung/Anh, với khả năng hiểu và tạo nội dung tiếng Trung mạnh mẽ.",
  "Kwaipilot/KAT-Dev.description": "KAT-Dev (32B) là một mô hình mã nguồn mở 32B dành cho các tác vụ kỹ thuật phần mềm. Mô hình đạt tỷ lệ giải quyết 62,4% trên SWE-Bench Verified, xếp hạng thứ 5 trong số các mô hình mã nguồn mở. Được tối ưu thông qua huấn luyện trung gian, SFT và RL cho các tác vụ hoàn thành mã, sửa lỗi và đánh giá mã.",
  "Llama-3.2-11B-Vision-Instruct.description": "Khả năng suy luận hình ảnh mạnh mẽ trên hình ảnh độ phân giải cao, phù hợp cho các ứng dụng hiểu thị giác.",
  "Llama-3.2-90B-Vision-Instruct\t.description": "Khả năng suy luận hình ảnh tiên tiến cho các ứng dụng tác tử hiểu thị giác.",
  "Meta-Llama-3-3-70B-Instruct.description": "Llama 3.3 70B là một mô hình Transformer đa năng cho các tác vụ trò chuyện và tạo nội dung.",
  "Meta-Llama-3.1-405B-Instruct.description": "Llama 3.1 là mô hình văn bản được tinh chỉnh theo hướng dẫn, tối ưu cho trò chuyện đa ngôn ngữ, đạt hiệu suất cao trên các tiêu chuẩn ngành phổ biến trong cả mô hình mở và đóng.",
  "Meta-Llama-3.1-70B-Instruct.description": "Llama 3.1 là mô hình văn bản được tinh chỉnh theo hướng dẫn, tối ưu cho trò chuyện đa ngôn ngữ, đạt hiệu suất cao trên các tiêu chuẩn ngành phổ biến trong cả mô hình mở và đóng.",
  "Meta-Llama-3.1-8B-Instruct.description": "Llama 3.1 là mô hình văn bản được tinh chỉnh theo hướng dẫn, tối ưu cho trò chuyện đa ngôn ngữ, đạt hiệu suất cao trên các tiêu chuẩn ngành phổ biến trong cả mô hình mở và đóng.",
  "Meta-Llama-3.2-1B-Instruct.description": "Mô hình ngôn ngữ nhỏ tiên tiến với khả năng hiểu ngôn ngữ mạnh mẽ, suy luận xuất sắc và tạo văn bản hiệu quả.",
  "Meta-Llama-3.2-3B-Instruct.description": "Mô hình ngôn ngữ nhỏ tiên tiến với khả năng hiểu ngôn ngữ mạnh mẽ, suy luận xuất sắc và tạo văn bản hiệu quả.",
  "Meta-Llama-3.3-70B-Instruct.description": "Llama 3.3 là mô hình Llama mã nguồn mở đa ngôn ngữ tiên tiến nhất, đạt hiệu suất gần tương đương 405B với chi phí rất thấp. Dựa trên kiến trúc Transformer và được cải tiến bằng SFT và RLHF để tăng tính hữu ích và an toàn. Phiên bản tinh chỉnh theo hướng dẫn được tối ưu cho trò chuyện đa ngôn ngữ và vượt qua nhiều mô hình mở và đóng trên các tiêu chuẩn ngành. Ngày cắt kiến thức: Tháng 12 năm 2023.",
  "Meta-Llama-4-Maverick-17B-128E-Instruct-FP8.description": "Llama 4 Maverick là một mô hình MoE lớn với kích hoạt chuyên gia hiệu quả, mang lại hiệu suất suy luận mạnh mẽ.",
  "MiniMax-M1.description": "Mô hình suy luận nội bộ mới với 80K chuỗi suy nghĩ và đầu vào 1M, đạt hiệu suất tương đương các mô hình hàng đầu toàn cầu.",
  "MiniMax-M2-Stable.description": "Được xây dựng cho lập trình hiệu quả và quy trình tác tử, với khả năng đồng thời cao hơn cho mục đích thương mại.",
  "MiniMax-M2.1-Lightning.description": "Khả năng lập trình đa ngôn ngữ mạnh mẽ, trải nghiệm lập trình được nâng cấp toàn diện. Nhanh hơn và hiệu quả hơn.",
  "MiniMax-M2.1.description": "MiniMax-M2.1 là mô hình mã nguồn mở hàng đầu của MiniMax, tập trung vào việc giải quyết các tác vụ phức tạp trong thế giới thực. Thế mạnh cốt lõi của nó là khả năng lập trình đa ngôn ngữ và xử lý các nhiệm vụ phức tạp như một Tác nhân (Agent).",
  "MiniMax-M2.description": "Được xây dựng chuyên biệt cho lập trình hiệu quả và quy trình làm việc của Agent",
  "MiniMax-Text-01.description": "MiniMax-01 giới thiệu cơ chế chú ý tuyến tính quy mô lớn vượt ra ngoài Transformer cổ điển, với 456B tham số và 45.9B được kích hoạt mỗi lượt. Mô hình đạt hiệu suất hàng đầu và hỗ trợ ngữ cảnh lên đến 4M token (gấp 32 lần GPT-4o, 20 lần Claude-3.5-Sonnet).",
  "MiniMaxAI/MiniMax-M1-80k.description": "MiniMax-M1 là mô hình suy luận quy mô lớn với trọng số mở, sử dụng kiến trúc chú ý lai với tổng 456B tham số và khoảng 45.9B được kích hoạt mỗi token. Mô hình hỗ trợ ngữ cảnh 1M gốc và sử dụng Flash Attention để giảm 75% FLOPs khi tạo 100K token so với DeepSeek R1. Với kiến trúc MoE cùng CISPO và huấn luyện RL chú ý lai, mô hình đạt hiệu suất hàng đầu trong suy luận đầu vào dài và các tác vụ kỹ thuật phần mềm thực tế.",
  "MiniMaxAI/MiniMax-M2.description": "MiniMax-M2 định nghĩa lại hiệu quả của tác tử. Đây là mô hình MoE nhỏ gọn, nhanh, tiết kiệm chi phí với tổng 230B và 10B tham số hoạt động, được xây dựng cho các tác vụ lập trình và tác tử hàng đầu trong khi vẫn giữ được trí tuệ tổng quát mạnh mẽ. Với chỉ 10B tham số hoạt động, mô hình có thể cạnh tranh với các mô hình lớn hơn nhiều, lý tưởng cho các ứng dụng hiệu suất cao.",
  "Moonshot-Kimi-K2-Instruct.description": "Tổng số tham số 1T với 32B đang hoạt động. Trong số các mô hình không tư duy, đây là mô hình hàng đầu về kiến thức tiên tiến, toán học và lập trình, và mạnh hơn trong các tác vụ đại lý tổng quát. Được tối ưu hóa cho khối lượng công việc của đại lý, nó có thể thực hiện hành động chứ không chỉ trả lời câu hỏi. Phù hợp nhất cho trò chuyện ứng biến, trò chuyện tổng quát và trải nghiệm đại lý như một mô hình phản xạ không cần suy nghĩ lâu.",
  "NousResearch/Nous-Hermes-2-Mixtral-8x7B-DPO.description": "Nous Hermes 2 - Mixtral 8x7B-DPO (46.7B) là một mô hình hướng dẫn có độ chính xác cao dành cho các phép tính phức tạp.",
  "OmniConsistency.description": "OmniConsistency cải thiện tính nhất quán về phong cách và khả năng tổng quát trong các tác vụ chuyển đổi hình ảnh bằng cách giới thiệu các bộ khuếch tán quy mô lớn (DiTs) và dữ liệu phong cách hóa theo cặp, tránh suy giảm phong cách.",
  "PaddlePaddle/PaddleOCR-VL-1.5.description": "PaddleOCR-VL-1.5 là phiên bản nâng cấp của dòng PaddleOCR-VL, đạt độ chính xác 94,5% trên bộ đánh giá phân tích tài liệu OmniDocBench v1.5, vượt qua các mô hình lớn tổng quát và chuyên biệt hàng đầu. Mô hình này hỗ trợ định vị hộp giới hạn không đều cho các thành phần tài liệu, xử lý hiệu quả hình ảnh quét, nghiêng và chụp màn hình.",
  "Phi-3-medium-128k-instruct.description": "Cùng một mô hình Phi-3-medium với cửa sổ ngữ cảnh lớn hơn để sử dụng trong RAG hoặc các lời nhắc few-shot.",
  "Phi-3-medium-4k-instruct.description": "Mô hình 14B tham số với chất lượng cao hơn Phi-3-mini, tập trung vào dữ liệu chất lượng cao và yêu cầu suy luận.",
  "Phi-3-mini-128k-instruct.description": "Cùng một mô hình Phi-3-mini với cửa sổ ngữ cảnh lớn hơn để sử dụng trong RAG hoặc các lời nhắc few-shot.",
  "Phi-3-mini-4k-instruct.description": "Thành viên nhỏ nhất trong dòng Phi-3, được tối ưu hóa cho chất lượng và độ trễ thấp.",
  "Phi-3-small-128k-instruct.description": "Cùng một mô hình Phi-3-small với cửa sổ ngữ cảnh lớn hơn để sử dụng trong RAG hoặc các lời nhắc few-shot.",
  "Phi-3-small-8k-instruct.description": "Mô hình 7B tham số với chất lượng cao hơn Phi-3-mini, tập trung vào dữ liệu chất lượng cao và yêu cầu suy luận.",
  "Phi-3.5-mini-instruct.description": "Phiên bản cập nhật của mô hình Phi-3-mini.",
  "Phi-3.5-vision-instrust.description": "Phiên bản cập nhật của mô hình Phi-3-vision.",
  "Pro/MiniMaxAI/MiniMax-M2.1.description": "MiniMax-M2.1 là một mô hình ngôn ngữ lớn mã nguồn mở được tối ưu hóa cho khả năng tác nhân, vượt trội trong lập trình, sử dụng công cụ, tuân thủ hướng dẫn và lập kế hoạch dài hạn. Mô hình hỗ trợ phát triển phần mềm đa ngôn ngữ và thực thi quy trình công việc phức tạp nhiều bước, đạt điểm 74.0 trên SWE-bench Verified và vượt qua Claude Sonnet 4.5 trong các tình huống đa ngôn ngữ.",
  "Pro/Qwen/Qwen2-7B-Instruct.description": "Qwen2-7B-Instruct là mô hình LLM 7B được tinh chỉnh theo hướng dẫn trong dòng Qwen2. Sử dụng kiến trúc Transformer với SwiGLU, thiên vị QKV trong attention và attention theo nhóm, hỗ trợ đầu vào lớn. Mô hình thể hiện hiệu suất mạnh mẽ trong hiểu ngôn ngữ, sinh văn bản, đa ngôn ngữ, lập trình, toán học và suy luận, vượt trội hơn hầu hết các mô hình mã nguồn mở và cạnh tranh với các mô hình độc quyền. Nó vượt qua Qwen1.5-7B-Chat trong nhiều bài đánh giá.",
  "Pro/Qwen/Qwen2.5-7B-Instruct.description": "Qwen2.5-7B-Instruct là một phần của dòng LLM mới nhất từ Alibaba Cloud. Mô hình 7B mang lại cải tiến đáng kể trong lập trình và toán học, hỗ trợ hơn 29 ngôn ngữ, và cải thiện khả năng tuân theo hướng dẫn, hiểu dữ liệu có cấu trúc và xuất dữ liệu có cấu trúc (đặc biệt là JSON).",
  "Pro/Qwen/Qwen2.5-Coder-7B-Instruct.description": "Qwen2.5-Coder-7B-Instruct là mô hình LLM mới nhất của Alibaba Cloud tập trung vào lập trình. Được xây dựng trên Qwen2.5 và huấn luyện với 5.5T token, nó cải thiện đáng kể khả năng sinh mã, suy luận và sửa lỗi trong khi vẫn giữ được thế mạnh về toán học và khả năng tổng quát, cung cấp nền tảng vững chắc cho các đại lý lập trình.",
  "Pro/Qwen/Qwen2.5-VL-7B-Instruct.description": "Qwen2.5-VL là mô hình thị giác-ngôn ngữ mới trong dòng Qwen với khả năng hiểu hình ảnh mạnh mẽ. Nó phân tích văn bản, biểu đồ và bố cục trong hình ảnh, hiểu video dài và sự kiện, hỗ trợ suy luận và sử dụng công cụ, định vị đối tượng đa định dạng và xuất dữ liệu có cấu trúc. Nó cải thiện độ phân giải động và huấn luyện tốc độ khung hình để hiểu video và tăng hiệu quả bộ mã hóa thị giác.",
  "Pro/THUDM/GLM-4.1V-9B-Thinking.description": "GLM-4.1V-9B-Thinking là mô hình VLM mã nguồn mở từ Zhipu AI và Phòng thí nghiệm KEG của Đại học Thanh Hoa, được thiết kế cho nhận thức đa phương thức phức tạp. Dựa trên GLM-4-9B-0414, nó bổ sung suy luận chuỗi tư duy và học tăng cường (RL) để cải thiện đáng kể khả năng suy luận xuyên phương thức và độ ổn định.",
  "Pro/THUDM/glm-4-9b-chat.description": "GLM-4-9B-Chat là mô hình GLM-4 mã nguồn mở từ Zhipu AI. Nó thể hiện hiệu suất mạnh mẽ trong ngữ nghĩa, toán học, suy luận, lập trình và kiến thức. Ngoài trò chuyện nhiều lượt, nó hỗ trợ duyệt web, thực thi mã, gọi công cụ tùy chỉnh và suy luận văn bản dài. Hỗ trợ 26 ngôn ngữ (bao gồm tiếng Trung, Anh, Nhật, Hàn, Đức). Hiệu suất tốt trên AlignBench-v2, MT-Bench, MMLU và C-Eval, hỗ trợ ngữ cảnh lên đến 128K cho mục đích học thuật và kinh doanh.",
  "Pro/deepseek-ai/DeepSeek-R1-Distill-Qwen-7B.description": "DeepSeek-R1-Distill-Qwen-7B được chưng cất từ Qwen2.5-Math-7B và tinh chỉnh trên 800K mẫu DeepSeek-R1 được chọn lọc. Nó thể hiện hiệu suất mạnh mẽ, đạt 92.8% trên MATH-500, 55.5% trên AIME 2024 và xếp hạng CodeForces 1189 cho mô hình 7B.",
  "Pro/deepseek-ai/DeepSeek-R1.description": "DeepSeek-R1 là mô hình suy luận dựa trên học tăng cường (RL) giúp giảm lặp lại và cải thiện khả năng đọc. Nó sử dụng dữ liệu khởi động lạnh trước RL để tăng cường khả năng suy luận, đạt hiệu suất tương đương OpenAI-o1 trong các tác vụ toán học, lập trình và suy luận, và cải thiện kết quả tổng thể thông qua huấn luyện cẩn thận.",
  "Pro/deepseek-ai/DeepSeek-V3.1-Terminus.description": "DeepSeek-V3.1-Terminus là phiên bản cập nhật của mô hình V3.1, được định vị là LLM đại lý lai. Nó khắc phục các vấn đề do người dùng báo cáo và cải thiện độ ổn định, tính nhất quán ngôn ngữ, đồng thời giảm ký tự bất thường và trộn tiếng Trung/Anh. Nó tích hợp chế độ Tư duy và Không tư duy với mẫu trò chuyện để chuyển đổi linh hoạt. Ngoài ra, nó còn cải thiện hiệu suất của Code Agent và Search Agent để sử dụng công cụ đáng tin cậy hơn và thực hiện các tác vụ nhiều bước.",
  "Pro/deepseek-ai/DeepSeek-V3.2-Exp.description": "DeepSeek-V3.2-Exp là bản phát hành thử nghiệm của V3.2, là cầu nối đến kiến trúc tiếp theo. Nó bổ sung DeepSeek Sparse Attention (DSA) trên nền tảng V3.1-Terminus để cải thiện hiệu quả huấn luyện và suy luận với ngữ cảnh dài, được tối ưu hóa cho sử dụng công cụ, hiểu tài liệu dài và suy luận nhiều bước. Lý tưởng để khám phá hiệu quả suy luận cao hơn với ngân sách ngữ cảnh lớn.",
  "Pro/deepseek-ai/DeepSeek-V3.description": "DeepSeek-V3 là mô hình MoE với 671B tham số, sử dụng MLA và DeepSeekMoE với cân bằng tải không mất mát để suy luận và huấn luyện hiệu quả. Được huấn luyện sơ bộ trên 14.8T token chất lượng cao và tinh chỉnh thêm bằng SFT và RL, nó vượt trội hơn các mô hình mã nguồn mở khác và tiệm cận các mô hình đóng hàng đầu.",
  "Pro/moonshotai/Kimi-K2-Instruct-0905.description": "Kimi K2-Instruct-0905 là phiên bản mới nhất và mạnh nhất của Kimi K2. Đây là mô hình MoE hàng đầu với tổng 1T và 32B tham số đang hoạt động. Các tính năng chính bao gồm trí tuệ lập trình đại lý mạnh hơn với cải tiến đáng kể trên các điểm chuẩn và tác vụ đại lý thực tế, cùng với thẩm mỹ và khả năng sử dụng mã giao diện người dùng được cải thiện.",
  "Pro/moonshotai/Kimi-K2-Thinking.description": "Kimi K2 Thinking Turbo là biến thể Turbo được tối ưu hóa cho tốc độ suy luận và thông lượng trong khi vẫn giữ khả năng suy luận nhiều bước và sử dụng công cụ của K2 Thinking. Đây là mô hình MoE với khoảng 1T tham số, hỗ trợ ngữ cảnh gốc 256K và gọi công cụ quy mô lớn ổn định cho các tình huống sản xuất có yêu cầu nghiêm ngặt về độ trễ và đồng thời.",
  "Pro/moonshotai/Kimi-K2.5.description": "Kimi K2.5 là mô hình tác nhân đa phương thức mã nguồn mở, được xây dựng trên nền tảng Kimi-K2-Base, được huấn luyện với khoảng 1,5 nghìn tỷ token kết hợp giữa thị giác và văn bản. Mô hình sử dụng kiến trúc MoE với tổng 1 nghìn tỷ tham số và 32 tỷ tham số hoạt động, hỗ trợ cửa sổ ngữ cảnh 256K, tích hợp liền mạch khả năng hiểu thị giác và ngôn ngữ.",
  "Pro/zai-org/glm-4.7.description": "GLM-4.7 là mô hình chủ lực thế hệ mới của Zhipu với tổng số tham số 355 tỷ và 32 tỷ tham số hoạt động, được nâng cấp toàn diện về khả năng đối thoại, suy luận và tác tử. GLM-4.7 tăng cường khả năng Tư duy Đan xen và giới thiệu thêm Tư duy Bảo tồn và Tư duy theo lượt.",
  "QwQ-32B-Preview.description": "Qwen QwQ là một mô hình nghiên cứu thử nghiệm tập trung vào việc cải thiện khả năng suy luận.",
  "Qwen/QVQ-72B-Preview.description": "QVQ-72B-Preview là một mô hình nghiên cứu từ Qwen tập trung vào suy luận thị giác, nổi bật trong việc hiểu các cảnh phức tạp và giải các bài toán thị giác.",
  "Qwen/QwQ-32B-Preview.description": "Qwen QwQ là một mô hình nghiên cứu thử nghiệm tập trung vào việc nâng cao khả năng suy luận của AI.",
  "Qwen/QwQ-32B.description": "QwQ là một mô hình suy luận thuộc họ Qwen. So với các mô hình huấn luyện theo hướng dẫn tiêu chuẩn, nó bổ sung khả năng tư duy và suy luận giúp cải thiện đáng kể hiệu suất trong các tác vụ phức tạp. QwQ-32B là một mô hình suy luận tầm trung có khả năng cạnh tranh với các mô hình hàng đầu như DeepSeek-R1 và o1-mini. Nó sử dụng RoPE, SwiGLU, RMSNorm và thiên vị QKV trong attention, với 64 lớp và 40 đầu attention Q (8 KV trong GQA).",
  "Qwen/Qwen-Image-Edit-2509.description": "Qwen-Image-Edit-2509 là phiên bản chỉnh sửa mới nhất của Qwen-Image từ nhóm Qwen. Dựa trên mô hình Qwen-Image 20B, nó mở rộng khả năng hiển thị văn bản mạnh mẽ sang chỉnh sửa hình ảnh để thực hiện các chỉnh sửa văn bản chính xác. Mô hình sử dụng kiến trúc điều khiển kép, gửi đầu vào đến Qwen2.5-VL để kiểm soát ngữ nghĩa và bộ mã hóa VAE để kiểm soát hình thức, cho phép chỉnh sửa ở cả cấp độ ngữ nghĩa và hình thức. Nó hỗ trợ chỉnh sửa cục bộ (thêm/xóa/chỉnh sửa) và chỉnh sửa ngữ nghĩa cấp cao như tạo IP và chuyển đổi phong cách trong khi vẫn giữ nguyên ý nghĩa. Mô hình đạt kết quả SOTA trên nhiều bộ đánh giá.",
  "Qwen/Qwen-Image.description": "Qwen-Image là một mô hình nền tảng tạo hình ảnh với 20 tỷ tham số từ nhóm Qwen. Mô hình đạt được những tiến bộ lớn trong hiển thị văn bản phức tạp và chỉnh sửa hình ảnh chính xác, đặc biệt là với văn bản tiếng Trung/Anh có độ trung thực cao. Nó hỗ trợ bố cục nhiều dòng và đoạn văn trong khi vẫn giữ được sự nhất quán về kiểu chữ. Ngoài hiển thị văn bản, mô hình còn hỗ trợ nhiều phong cách từ ảnh thực tế đến anime, và các chỉnh sửa nâng cao như chuyển đổi phong cách, thêm/xóa đối tượng, tăng cường chi tiết, chỉnh sửa văn bản và điều khiển tư thế, hướng tới việc trở thành nền tảng sáng tạo hình ảnh toàn diện.",
  "Qwen/Qwen2-72B-Instruct.description": "Qwen 2 Instruct (72B) cung cấp khả năng tuân thủ hướng dẫn chính xác cho các tác vụ doanh nghiệp.",
  "Qwen/Qwen2-7B-Instruct.description": "Qwen2-7B-Instruct là một mô hình 7B được tinh chỉnh theo hướng dẫn trong dòng Qwen2, sử dụng Transformer, SwiGLU, QKV bias và attention truy vấn nhóm. Mô hình xử lý đầu vào lớn và thể hiện hiệu suất mạnh mẽ trong các bài đánh giá về hiểu ngôn ngữ, sinh văn bản, đa ngôn ngữ, lập trình, toán học và suy luận, vượt trội hơn hầu hết các mô hình mã nguồn mở và vượt qua Qwen1.5-7B-Chat trong nhiều đánh giá.",
  "Qwen/Qwen2-VL-72B-Instruct.description": "Qwen2-VL là mô hình Qwen-VL mới nhất, đạt SOTA trên các bộ đánh giá thị giác như MathVista, DocVQA, RealWorldQA và MTVQA. Mô hình có thể hiểu video dài hơn 20 phút để trả lời câu hỏi, đối thoại và tạo nội dung. Nó cũng hỗ trợ suy luận phức tạp và ra quyết định, tích hợp với thiết bị/robot để thực hiện hành động dựa trên thị giác. Ngoài tiếng Anh và tiếng Trung, mô hình còn có thể đọc văn bản bằng nhiều ngôn ngữ khác như hầu hết các ngôn ngữ châu Âu, tiếng Nhật, Hàn, Ả Rập và tiếng Việt.",
  "Qwen/Qwen2.5-14B-Instruct.description": "Qwen2.5-14B-Instruct là một phần trong dòng mô hình LLM mới nhất của Alibaba Cloud. Mô hình 14B mang lại cải tiến đáng kể trong lập trình và toán học, hỗ trợ hơn 29 ngôn ngữ và cải thiện khả năng tuân thủ hướng dẫn, hiểu dữ liệu có cấu trúc và xuất dữ liệu có cấu trúc (đặc biệt là JSON).",
  "Qwen/Qwen2.5-32B-Instruct.description": "Qwen2.5-32B-Instruct là một phần trong dòng mô hình LLM mới nhất của Alibaba Cloud. Mô hình 32B mang lại cải tiến đáng kể trong lập trình và toán học, hỗ trợ hơn 29 ngôn ngữ và cải thiện khả năng tuân thủ hướng dẫn, hiểu dữ liệu có cấu trúc và xuất dữ liệu có cấu trúc (đặc biệt là JSON).",
  "Qwen/Qwen2.5-72B-Instruct-128K.description": "Qwen2.5-72B-Instruct là một phần trong dòng mô hình LLM mới nhất của Alibaba Cloud. Mô hình 72B cải thiện khả năng lập trình và toán học, hỗ trợ đầu vào lên đến 128K và đầu ra hơn 8K, cung cấp hơn 29 ngôn ngữ và cải thiện khả năng tuân thủ hướng dẫn và xuất dữ liệu có cấu trúc (đặc biệt là JSON).",
  "Qwen/Qwen2.5-72B-Instruct-Turbo.description": "Qwen2.5 là dòng mô hình LLM mới được tối ưu hóa cho các tác vụ theo kiểu hướng dẫn.",
  "Qwen/Qwen2.5-72B-Instruct.description": "Qwen2.5-72B-Instruct là một phần trong dòng mô hình LLM mới nhất của Alibaba Cloud. Mô hình 72B mang lại cải tiến đáng kể trong lập trình và toán học, hỗ trợ hơn 29 ngôn ngữ và cải thiện khả năng tuân thủ hướng dẫn, hiểu dữ liệu có cấu trúc và xuất dữ liệu có cấu trúc (đặc biệt là JSON).",
  "Qwen/Qwen2.5-7B-Instruct-Turbo.description": "Qwen2.5 là dòng mô hình LLM mới được tối ưu hóa cho các tác vụ theo kiểu hướng dẫn.",
  "Qwen/Qwen2.5-7B-Instruct.description": "Qwen2.5-7B-Instruct là một phần trong dòng mô hình LLM mới nhất của Alibaba Cloud. Mô hình 7B mang lại cải tiến đáng kể trong lập trình và toán học, hỗ trợ hơn 29 ngôn ngữ và cải thiện khả năng tuân thủ hướng dẫn, hiểu dữ liệu có cấu trúc và xuất dữ liệu có cấu trúc (đặc biệt là JSON).",
  "Qwen/Qwen2.5-Coder-32B-Instruct.description": "Qwen2.5 Coder 32B Instruct là mô hình LLM mới nhất của Alibaba Cloud tập trung vào lập trình. Dựa trên Qwen2.5 và được huấn luyện với 5.5 nghìn tỷ token, mô hình cải thiện đáng kể khả năng sinh mã, suy luận và sửa lỗi trong khi vẫn giữ được thế mạnh về toán học và khả năng tổng quát, cung cấp nền tảng vững chắc cho các tác nhân lập trình.",
  "Qwen/Qwen2.5-Coder-7B-Instruct.description": "Qwen2.5-Coder-7B-Instruct là mô hình LLM mới nhất của Alibaba Cloud tập trung vào lập trình. Dựa trên Qwen2.5 và được huấn luyện với 5.5 nghìn tỷ token, mô hình cải thiện đáng kể khả năng sinh mã, suy luận và sửa lỗi trong khi vẫn giữ được thế mạnh về toán học và khả năng tổng quát, cung cấp nền tảng vững chắc cho các tác nhân lập trình.",
  "Qwen/Qwen2.5-VL-32B-Instruct.description": "Qwen2.5-VL-32B-Instruct là một mô hình đa phương thức từ nhóm Qwen. Mô hình nhận diện các đối tượng phổ biến và phân tích văn bản, biểu đồ, biểu tượng, đồ họa và bố cục. Là một tác nhân thị giác, nó có thể suy luận và điều khiển công cụ một cách linh hoạt, bao gồm cả việc sử dụng máy tính và điện thoại. Mô hình định vị chính xác các đối tượng và tạo đầu ra có cấu trúc cho hóa đơn và bảng biểu. So với Qwen2-VL, RL cải thiện thêm khả năng toán học và giải quyết vấn đề, với phản hồi được người dùng ưa thích hơn.",
  "Qwen/Qwen2.5-VL-72B-Instruct.description": "Qwen2.5-VL là mô hình thị giác-ngôn ngữ trong dòng Qwen2.5 với các nâng cấp lớn: khả năng hiểu hình ảnh mạnh mẽ hơn đối với vật thể, văn bản, biểu đồ và bố cục; suy luận như một tác nhân thị giác với khả năng sử dụng công cụ linh hoạt; hiểu video dài hơn 1 giờ và nắm bắt các sự kiện chính; định vị vật thể chính xác qua hộp hoặc điểm; và xuất dữ liệu có cấu trúc cho các tài liệu quét như hóa đơn và bảng biểu.",
  "Qwen/Qwen3-14B.description": "Qwen3 là mô hình Tongyi Qwen thế hệ mới với những cải tiến vượt bậc về suy luận, năng lực tổng quát, khả năng tác nhân và hiệu suất đa ngôn ngữ, đồng thời hỗ trợ chuyển đổi giữa các chế độ tư duy.",
  "Qwen/Qwen3-235B-A22B-Instruct-2507.description": "Qwen3-235B-A22B-Instruct-2507 là mô hình MoE hàng đầu trong dòng Qwen3 với tổng 235 tỷ và 22 tỷ tham số hoạt động. Đây là phiên bản không tư duy được cập nhật, tập trung vào việc cải thiện khả năng làm theo hướng dẫn, suy luận logic, hiểu văn bản, toán học, khoa học, lập trình và sử dụng công cụ. Mô hình cũng mở rộng kiến thức đa ngôn ngữ hiếm gặp và điều chỉnh tốt hơn với sở thích người dùng trong các tác vụ mở mang tính chủ quan.",
  "Qwen/Qwen3-235B-A22B-Thinking-2507.description": "Qwen3-235B-A22B-Thinking-2507 là mô hình Qwen3 tập trung vào suy luận phức tạp. Sử dụng kiến trúc MoE với tổng 235 tỷ và khoảng 22 tỷ tham số hoạt động mỗi token để tăng hiệu quả. Là mô hình tư duy chuyên biệt, nó đạt được cải tiến lớn trong logic, toán học, khoa học, lập trình và các chuẩn học thuật, đạt hiệu suất tư duy hàng đầu. Mô hình cũng cải thiện khả năng làm theo hướng dẫn, sử dụng công cụ và tạo văn bản, đồng thời hỗ trợ ngữ cảnh 256K gốc cho suy luận sâu và tài liệu dài.",
  "Qwen/Qwen3-235B-A22B.description": "Qwen3 là mô hình Tongyi Qwen thế hệ mới với những cải tiến vượt bậc về suy luận, năng lực tổng quát, khả năng tác nhân và hiệu suất đa ngôn ngữ, đồng thời hỗ trợ chuyển đổi giữa các chế độ tư duy.",
  "Qwen/Qwen3-30B-A3B-Instruct-2507.description": "Qwen3-30B-A3B-Instruct-2507 là phiên bản không tư duy được cập nhật của Qwen3-30B-A3B. Đây là mô hình MoE với tổng 30,5 tỷ và 3,3 tỷ tham số hoạt động. Mô hình cải thiện đáng kể khả năng làm theo hướng dẫn, suy luận logic, hiểu văn bản, toán học, khoa học, lập trình và sử dụng công cụ, mở rộng kiến thức đa ngôn ngữ hiếm gặp và điều chỉnh tốt hơn với sở thích người dùng trong các tác vụ mở mang tính chủ quan. Hỗ trợ ngữ cảnh 256K. Phiên bản này chỉ hỗ trợ chế độ không tư duy và sẽ không tạo thẻ `<think></think>`.",
  "Qwen/Qwen3-30B-A3B-Thinking-2507.description": "Qwen3-30B-A3B-Thinking-2507 là mô hình tư duy mới nhất trong dòng Qwen3. Đây là mô hình MoE với tổng 30,5 tỷ và 3,3 tỷ tham số hoạt động, tập trung vào các tác vụ phức tạp. Mô hình đạt được cải tiến đáng kể trong logic, toán học, khoa học, lập trình và các chuẩn học thuật, đồng thời cải thiện khả năng làm theo hướng dẫn, sử dụng công cụ, tạo văn bản và điều chỉnh theo sở thích. Hỗ trợ ngữ cảnh 256K gốc và có thể mở rộng đến 1 triệu token. Phiên bản này được thiết kế cho chế độ tư duy với suy luận từng bước chi tiết và khả năng tác nhân mạnh mẽ.",
  "Qwen/Qwen3-30B-A3B.description": "Qwen3 là mô hình Tongyi Qwen thế hệ mới với những cải tiến vượt bậc về suy luận, năng lực tổng quát, khả năng tác nhân và hiệu suất đa ngôn ngữ, đồng thời hỗ trợ chuyển đổi giữa các chế độ tư duy.",
  "Qwen/Qwen3-32B.description": "Qwen3 là mô hình Tongyi Qwen thế hệ mới với những cải tiến vượt bậc về suy luận, năng lực tổng quát, khả năng tác nhân và hiệu suất đa ngôn ngữ, đồng thời hỗ trợ chuyển đổi giữa các chế độ tư duy.",
  "Qwen/Qwen3-8B.description": "Qwen3 là mô hình Tongyi Qwen thế hệ mới với những cải tiến vượt bậc về suy luận, năng lực tổng quát, khả năng tác nhân và hiệu suất đa ngôn ngữ, đồng thời hỗ trợ chuyển đổi giữa các chế độ tư duy.",
  "Qwen/Qwen3-Coder-30B-A3B-Instruct.description": "Qwen3-Coder-30B-A3B-Instruct là mô hình lập trình Qwen3 từ nhóm Qwen. Mô hình được tối ưu hóa để đạt hiệu suất cao và hiệu quả, đồng thời tăng cường khả năng lập trình. Nó thể hiện ưu thế vượt trội trong lập trình tác nhân, thao tác trình duyệt tự động và sử dụng công cụ trong số các mô hình mã nguồn mở. Hỗ trợ ngữ cảnh 256K gốc và có thể mở rộng đến 1 triệu token để hiểu ở cấp độ mã nguồn. Mô hình hỗ trợ lập trình tác nhân trên các nền tảng như Qwen Code và CLINE với định dạng gọi hàm chuyên biệt.",
  "Qwen/Qwen3-Coder-480B-A35B-Instruct.description": "Qwen3-Coder-480B-A35B-Instruct là mô hình lập trình tác nhân mạnh mẽ nhất của Alibaba cho đến nay. Đây là mô hình MoE với tổng 480 tỷ và 35 tỷ tham số hoạt động, cân bằng giữa hiệu suất và hiệu quả. Hỗ trợ ngữ cảnh 256K gốc và có thể mở rộng đến 1 triệu token qua YaRN, cho phép xử lý mã nguồn lớn. Được thiết kế cho quy trình lập trình tác nhân, mô hình có thể tương tác với công cụ và môi trường để giải quyết các tác vụ lập trình phức tạp. Đạt kết quả hàng đầu trong số các mô hình mã nguồn mở về lập trình và chuẩn tác nhân, sánh ngang với các mô hình hàng đầu như Claude Sonnet 4.",
  "Qwen/Qwen3-Next-80B-A3B-Instruct.description": "Qwen3-Next-80B-A3B-Instruct là mô hình nền thế hệ mới sử dụng kiến trúc Qwen3-Next để đạt hiệu quả huấn luyện và suy luận tối đa. Kết hợp attention lai (Gated DeltaNet + Gated Attention), MoE siêu thưa và tối ưu hóa độ ổn định huấn luyện. Với tổng 80 tỷ tham số nhưng chỉ ~3 tỷ tham số hoạt động khi suy luận, mô hình giảm chi phí tính toán và đạt thông lượng gấp 10 lần so với Qwen3-32B trên ngữ cảnh >32K. Phiên bản tinh chỉnh theo hướng dẫn này nhắm đến các tác vụ tổng quát (không có chế độ tư duy). Hiệu suất tương đương Qwen3-235B trên một số chuẩn và thể hiện ưu thế mạnh trong các tác vụ ngữ cảnh siêu dài.",
  "Qwen/Qwen3-Next-80B-A3B-Thinking.description": "Qwen3-Next-80B-A3B-Thinking là mô hình nền thế hệ mới dành cho suy luận phức tạp. Sử dụng kiến trúc Qwen3-Next với attention lai (Gated DeltaNet + Gated Attention) và MoE siêu thưa để đạt hiệu quả huấn luyện/suy luận tối đa. Với tổng 80 tỷ tham số nhưng chỉ ~3 tỷ tham số hoạt động khi suy luận, mô hình giảm chi phí tính toán và đạt thông lượng gấp 10 lần so với Qwen3-32B trên ngữ cảnh >32K. Phiên bản Thinking này nhắm đến các tác vụ nhiều bước như chứng minh, tổng hợp mã, phân tích logic và lập kế hoạch, tạo chuỗi suy nghĩ có cấu trúc. Vượt trội so với Qwen3-32B-Thinking và đánh bại Gemini-2.5-Flash-Thinking trên nhiều chuẩn.",
  "Qwen/Qwen3-Omni-30B-A3B-Captioner.description": "Qwen3-Omni-30B-A3B-Captioner là mô hình VLM trong dòng Qwen3 được xây dựng để tạo mô tả hình ảnh chất lượng cao, chi tiết và chính xác. Sử dụng kiến trúc MoE 30B tham số để hiểu sâu hình ảnh và tạo mô tả trôi chảy, xuất sắc trong việc nắm bắt chi tiết, hiểu cảnh, nhận diện vật thể và suy luận quan hệ.",
  "Qwen/Qwen3-Omni-30B-A3B-Instruct.description": "Qwen3-Omni-30B-A3B-Instruct là mô hình MoE dòng Qwen3 với tổng 30B và 3B tham số hoạt động, mang lại hiệu suất mạnh mẽ với chi phí suy luận thấp hơn. Được huấn luyện trên dữ liệu đa nguồn đa ngôn ngữ chất lượng cao, mô hình hỗ trợ đầu vào toàn bộ các phương thức (văn bản, hình ảnh, âm thanh, video) và hiểu/generating xuyên phương thức.",
  "Qwen/Qwen3-Omni-30B-A3B-Thinking.description": "Qwen3-Omni-30B-A3B-Thinking là thành phần \"Thinker\" cốt lõi của Qwen3-Omni. Mô hình xử lý đầu vào đa phương thức (văn bản, âm thanh, hình ảnh, video) và thực hiện suy luận chuỗi phức tạp, hợp nhất đầu vào thành biểu diễn chung để hiểu sâu xuyên phương thức. Đây là mô hình MoE với tổng 30B và 3B tham số hoạt động, cân bằng giữa suy luận mạnh và hiệu quả tính toán.",
  "Qwen/Qwen3-VL-235B-A22B-Instruct.description": "Qwen3-VL-235B-A22B-Instruct là mô hình Qwen3-VL lớn được tinh chỉnh theo hướng dẫn, xây dựng trên kiến trúc MoE, mang lại khả năng hiểu và tạo đa phương thức xuất sắc. Hỗ trợ ngữ cảnh 256K gốc và phù hợp cho các dịch vụ đa phương thức sản xuất có độ đồng thời cao.",
  "Qwen/Qwen3-VL-235B-A22B-Thinking.description": "Qwen3-VL-235B-A22B-Thinking là phiên bản tư duy hàng đầu của Qwen3-VL, được tối ưu hóa cho suy luận đa phương thức phức tạp, suy luận ngữ cảnh dài và tương tác tác nhân trong các tình huống doanh nghiệp.",
  "Qwen/Qwen3-VL-30B-A3B-Instruct.description": "Qwen3-VL-30B-A3B-Instruct là mô hình Qwen3-VL được tinh chỉnh theo hướng dẫn với khả năng hiểu và tạo thị giác-ngôn ngữ mạnh mẽ. Hỗ trợ ngữ cảnh 256K gốc cho trò chuyện đa phương thức và tạo nội dung dựa trên hình ảnh.",
  "Qwen/Qwen3-VL-30B-A3B-Thinking.description": "Qwen3-VL-30B-A3B-Thinking là phiên bản tăng cường suy luận của Qwen3-VL, được tối ưu hóa cho suy luận đa phương thức, chuyển đổi hình ảnh thành mã và hiểu thị giác phức tạp. Hỗ trợ ngữ cảnh 256K với khả năng chuỗi suy nghĩ mạnh mẽ.",
  "Qwen/Qwen3-VL-32B-Instruct.description": "Qwen3-VL-32B-Instruct là mô hình thị giác-ngôn ngữ từ nhóm Qwen với kết quả SOTA hàng đầu trên nhiều chuẩn VL. Hỗ trợ hình ảnh độ phân giải megapixel và cung cấp khả năng hiểu thị giác mạnh mẽ, OCR đa ngôn ngữ, định vị thị giác chi tiết và đối thoại thị giác. Mô hình xử lý các tác vụ đa phương thức phức tạp và hỗ trợ gọi công cụ và hoàn thành tiền tố.",
  "Qwen/Qwen3-VL-32B-Thinking.description": "Qwen3-VL-32B-Thinking được tối ưu hóa cho suy luận thị giác phức tạp. Bao gồm chế độ tư duy tích hợp tạo các bước suy luận trung gian trước khi đưa ra câu trả lời, tăng cường logic nhiều bước, lập kế hoạch và suy luận phức tạp. Hỗ trợ hình ảnh megapixel, hiểu thị giác mạnh, OCR đa ngôn ngữ, định vị chi tiết, đối thoại thị giác, gọi công cụ và hoàn thành tiền tố.",
  "Qwen/Qwen3-VL-8B-Instruct.description": "Qwen3-VL-8B-Instruct là mô hình thị giác-ngôn ngữ Qwen3 được xây dựng trên Qwen3-8B-Instruct và huấn luyện trên dữ liệu hình ảnh-văn bản lớn. Mô hình xuất sắc trong hiểu thị giác tổng quát, đối thoại tập trung vào hình ảnh và nhận diện văn bản đa ngôn ngữ trong hình ảnh, phù hợp cho hỏi đáp thị giác, tạo chú thích, làm theo hướng dẫn đa phương thức và sử dụng công cụ.",
  "Qwen/Qwen3-VL-8B-Thinking.description": "Qwen3-VL-8B-Thinking là phiên bản tư duy thị giác của Qwen3, được tối ưu hóa cho suy luận nhiều bước phức tạp. Mô hình tạo chuỗi suy nghĩ trước khi đưa ra câu trả lời để cải thiện độ chính xác, lý tưởng cho hỏi đáp thị giác sâu và phân tích hình ảnh chi tiết.",
  "Qwen2-72B-Instruct.description": "Qwen2 là dòng Qwen mới nhất, hỗ trợ cửa sổ ngữ cảnh 128k. So với các mô hình mã nguồn mở hàng đầu hiện nay, Qwen2-72B vượt trội đáng kể trong hiểu ngôn ngữ tự nhiên, kiến thức, lập trình, toán học và khả năng đa ngôn ngữ.",
  "Qwen2-7B-Instruct.description": "Qwen2 là dòng Qwen mới nhất, vượt qua các mô hình mã nguồn mở tốt nhất cùng kích thước và thậm chí cả các mô hình lớn hơn. Qwen2 7B thể hiện ưu thế rõ rệt trên nhiều chuẩn, đặc biệt là trong lập trình và hiểu tiếng Trung.",
  "Qwen2-VL-72B.description": "Qwen2-VL-72B là mô hình thị giác-ngôn ngữ mạnh mẽ hỗ trợ xử lý hình ảnh-văn bản đa phương thức, nhận diện chính xác nội dung hình ảnh và tạo mô tả hoặc câu trả lời phù hợp.",
  "Qwen2.5-14B-Instruct.description": "Qwen2.5-14B-Instruct là mô hình LLM 14B tham số với hiệu suất mạnh mẽ, được tối ưu hóa cho các tình huống tiếng Trung và đa ngôn ngữ, hỗ trợ hỏi đáp thông minh và tạo nội dung.",
  "Qwen2.5-32B-Instruct.description": "Qwen2.5-32B-Instruct là mô hình LLM 32B tham số với hiệu suất cân bằng, được tối ưu hóa cho các tình huống tiếng Trung và đa ngôn ngữ, hỗ trợ hỏi đáp thông minh và tạo nội dung.",
  "Qwen2.5-72B-Instruct.description": "LLM cho tiếng Trung và tiếng Anh, được tinh chỉnh cho ngôn ngữ, lập trình, toán học và suy luận.",
  "Qwen2.5-7B-Instruct.description": "Qwen2.5-7B-Instruct là mô hình LLM 7B tham số hỗ trợ gọi hàm và tích hợp liền mạch với hệ thống bên ngoài, cải thiện đáng kể tính linh hoạt và khả năng mở rộng. Mô hình được tối ưu hóa cho các tình huống tiếng Trung và đa ngôn ngữ, hỗ trợ hỏi đáp thông minh và tạo nội dung.",
  "Qwen2.5-Coder-14B-Instruct.description": "Qwen2.5-Coder-14B-Instruct là mô hình hướng dẫn lập trình quy mô lớn được huấn luyện trước với khả năng hiểu và tạo mã mạnh mẽ. Mô hình xử lý hiệu quả nhiều tác vụ lập trình, lý tưởng cho lập trình thông minh, tạo script tự động và hỏi đáp lập trình.",
  "Qwen2.5-Coder-32B-Instruct.description": "LLM tiên tiến cho tạo mã, suy luận và sửa lỗi trên các ngôn ngữ lập trình chính.",
  "Qwen3-235B-A22B-Instruct-2507-FP8.description": "Qwen3 235B A22B Instruct 2507 được tối ưu hóa cho lập luận nâng cao và tuân theo hướng dẫn, sử dụng MoE để duy trì hiệu quả suy luận ở quy mô lớn.",
  "Qwen3-235B.description": "Qwen3-235B-A22B là một mô hình MoE giới thiệu chế độ suy luận lai, cho phép người dùng chuyển đổi mượt mà giữa trạng thái suy nghĩ và không suy nghĩ. Mô hình hỗ trợ hiểu và suy luận trên 119 ngôn ngữ và phương ngữ, có khả năng gọi công cụ mạnh mẽ, cạnh tranh với các mô hình phổ biến như DeepSeek R1, OpenAI o1, o3-mini, Grok 3 và Google Gemini 2.5 Pro trong các bài kiểm tra về năng lực tổng quát, lập trình và toán học, khả năng đa ngôn ngữ và suy luận kiến thức.",
  "Qwen3-32B.description": "Qwen3-32B là một mô hình dense giới thiệu chế độ suy luận lai, cho phép người dùng chuyển đổi giữa trạng thái suy nghĩ và không suy nghĩ. Với cải tiến kiến trúc, dữ liệu phong phú hơn và huấn luyện tốt hơn, mô hình đạt hiệu suất tương đương với Qwen2.5-72B.",
  "SenseChat-128K.description": "Phiên bản Base V4 với ngữ cảnh 128K, mạnh về hiểu và tạo văn bản dài.",
  "SenseChat-32K.description": "Phiên bản Base V4 với ngữ cảnh 32K, linh hoạt cho nhiều tình huống sử dụng.",
  "SenseChat-5-1202.description": "Phiên bản mới nhất dựa trên V5.5, cải thiện đáng kể về nền tảng tiếng Trung/Anh, trò chuyện, kiến thức STEM, nhân văn, viết lách, toán học/lôgic và kiểm soát độ dài.",
  "SenseChat-5-Cantonese.description": "Thiết kế phù hợp với thói quen hội thoại, tiếng lóng và kiến thức địa phương của Hồng Kông; vượt GPT-4 về hiểu tiếng Quảng Đông và ngang tầm GPT-4 Turbo về kiến thức, suy luận, toán học và lập trình.",
  "SenseChat-5-beta.description": "Một số hiệu suất vượt trội hơn SenseChat-5-1202.",
  "SenseChat-5.description": "Phiên bản V5.5 mới nhất với ngữ cảnh 128K; cải thiện lớn về suy luận toán học, trò chuyện tiếng Anh, tuân theo hướng dẫn và hiểu văn bản dài, tương đương GPT-4o.",
  "SenseChat-Character-Pro.description": "Mô hình trò chuyện nhân vật nâng cao với ngữ cảnh 32K, năng lực cải thiện và hỗ trợ tiếng Trung/Anh.",
  "SenseChat-Character.description": "Mô hình trò chuyện nhân vật tiêu chuẩn với ngữ cảnh 8K và tốc độ phản hồi cao.",
  "SenseChat-Turbo-1202.description": "Mô hình nhẹ mới nhất đạt hơn 90% năng lực của mô hình đầy đủ với chi phí suy luận thấp hơn đáng kể.",
  "SenseChat-Turbo.description": "Phù hợp cho các tình huống hỏi đáp nhanh và tinh chỉnh mô hình.",
  "SenseChat-Vision.description": "Phiên bản V5.5 mới nhất hỗ trợ đầu vào đa hình ảnh và cải tiến toàn diện về nhận diện thuộc tính, quan hệ không gian, phát hiện hành động/sự kiện, hiểu cảnh, nhận diện cảm xúc, suy luận thông thường và hiểu/tạo văn bản.",
  "SenseChat.description": "Phiên bản Base V4 với ngữ cảnh 4K và năng lực tổng quát mạnh.",
  "SenseNova-V6-5-Pro.description": "Với cập nhật toàn diện về dữ liệu đa phương thức, ngôn ngữ và suy luận cùng tối ưu hóa chiến lược huấn luyện, mô hình mới cải thiện đáng kể khả năng suy luận đa phương thức và tuân theo hướng dẫn tổng quát, hỗ trợ cửa sổ ngữ cảnh lên đến 128K và xuất sắc trong các tác vụ nhận diện OCR và IP du lịch văn hóa.",
  "SenseNova-V6-5-Turbo.description": "Với cập nhật toàn diện về dữ liệu đa phương thức, ngôn ngữ và suy luận cùng tối ưu hóa chiến lược huấn luyện, mô hình mới cải thiện đáng kể khả năng suy luận đa phương thức và tuân theo hướng dẫn tổng quát, hỗ trợ cửa sổ ngữ cảnh lên đến 128K và xuất sắc trong các tác vụ nhận diện OCR và IP du lịch văn hóa.",
  "SenseNova-V6-Pro.description": "Hợp nhất tự nhiên hình ảnh, văn bản và video, phá vỡ rào cản truyền thống của mô hình đa phương thức; đạt vị trí hàng đầu trên OpenCompass và SuperCLUE.",
  "SenseNova-V6-Reasoner.description": "Kết hợp suy luận sâu giữa thị giác và ngôn ngữ, hỗ trợ tư duy chậm và chuỗi suy nghĩ đầy đủ.",
  "SenseNova-V6-Turbo.description": "Hợp nhất tự nhiên hình ảnh, văn bản và video, phá vỡ rào cản truyền thống của mô hình đa phương thức. Dẫn đầu về năng lực cốt lõi đa phương thức và ngôn ngữ, xếp hạng hàng đầu trong nhiều đánh giá.",
  "Skylark2-lite-8k.description": "Mô hình Skylark thế hệ thứ hai. Skylark2-lite phản hồi nhanh cho các tình huống thời gian thực, nhạy cảm về chi phí với yêu cầu độ chính xác thấp hơn, hỗ trợ ngữ cảnh 8K.",
  "Skylark2-pro-32k.description": "Mô hình Skylark thế hệ thứ hai. Skylark2-pro cung cấp độ chính xác cao hơn cho các tác vụ tạo văn bản phức tạp như viết nội dung chuyên nghiệp, tiểu thuyết và dịch chất lượng cao, hỗ trợ ngữ cảnh 32K.",
  "Skylark2-pro-4k.description": "Mô hình Skylark thế hệ thứ hai. Skylark2-pro cung cấp độ chính xác cao hơn cho các tác vụ tạo văn bản phức tạp như viết nội dung chuyên nghiệp, tiểu thuyết và dịch chất lượng cao, hỗ trợ ngữ cảnh 4K.",
  "Skylark2-pro-character-4k.description": "Mô hình Skylark thế hệ thứ hai. Skylark2-pro-character xuất sắc trong nhập vai và trò chuyện, phù hợp với phong cách nhân vật riêng biệt và đối thoại tự nhiên cho chatbot, trợ lý ảo và dịch vụ khách hàng, phản hồi nhanh.",
  "Skylark2-pro-turbo-8k.description": "Mô hình Skylark thế hệ thứ hai. Skylark2-pro-turbo-8k cung cấp suy luận nhanh hơn với chi phí thấp hơn, hỗ trợ ngữ cảnh 8K.",
  "THUDM/GLM-4-32B-0414.description": "GLM-4-32B-0414 là mô hình GLM thế hệ tiếp theo mã nguồn mở với 32 tỷ tham số, hiệu suất tương đương OpenAI GPT và dòng DeepSeek V3/R1.",
  "THUDM/GLM-4-9B-0414.description": "GLM-4-9B-0414 là mô hình GLM 9B kế thừa kỹ thuật từ GLM-4-32B nhưng triển khai nhẹ hơn. Mô hình hoạt động tốt trong tạo mã, thiết kế web, tạo SVG và viết dựa trên tìm kiếm.",
  "THUDM/GLM-4.1V-9B-Thinking.description": "GLM-4.1V-9B-Thinking là mô hình VLM mã nguồn mở từ Zhipu AI và Tsinghua KEG Lab, thiết kế cho nhận thức đa phương thức phức tạp. Dựa trên GLM-4-9B-0414, mô hình bổ sung suy luận chuỗi tư duy và RL để cải thiện đáng kể suy luận xuyên phương thức và độ ổn định.",
  "THUDM/GLM-Z1-32B-0414.description": "GLM-Z1-32B-0414 là mô hình suy luận sâu được xây dựng từ GLM-4-32B-0414 với dữ liệu khởi động lạnh và RL mở rộng, được huấn luyện thêm về toán học, mã và logic. Mô hình cải thiện đáng kể khả năng toán học và giải quyết nhiệm vụ phức tạp so với mô hình gốc.",
  "THUDM/GLM-Z1-9B-0414.description": "GLM-Z1-9B-0414 là mô hình GLM nhỏ với 9 tỷ tham số, giữ vững thế mạnh mã nguồn mở và cung cấp năng lực ấn tượng. Mô hình hoạt động mạnh về suy luận toán học và các tác vụ tổng quát, dẫn đầu phân khúc kích thước của mình trong số các mô hình mở.",
  "THUDM/GLM-Z1-Rumination-32B-0414.description": "GLM-Z1-Rumination-32B-0414 là mô hình suy luận sâu với khả năng nghiền ngẫm (được đánh giá so với OpenAI Deep Research). Khác với các mô hình suy nghĩ sâu thông thường, mô hình dành nhiều thời gian hơn để giải quyết các vấn đề mở và phức tạp.",
  "THUDM/glm-4-9b-chat.description": "GLM-4-9B-Chat là mô hình GLM-4 mã nguồn mở từ Zhipu AI. Mô hình hoạt động mạnh về ngữ nghĩa, toán học, suy luận, mã và kiến thức. Ngoài trò chuyện nhiều lượt, mô hình còn hỗ trợ duyệt web, thực thi mã, gọi công cụ tùy chỉnh và suy luận văn bản dài. Hỗ trợ 26 ngôn ngữ (bao gồm tiếng Trung, Anh, Nhật, Hàn, Đức). Mô hình đạt kết quả tốt trên AlignBench-v2, MT-Bench, MMLU và C-Eval, hỗ trợ ngữ cảnh lên đến 128K cho mục đích học thuật và kinh doanh.",
  "Tongyi-Zhiwen/QwenLong-L1-32B.description": "QwenLong-L1-32B là mô hình suy luận ngữ cảnh dài đầu tiên (LRM) được huấn luyện với RL, tối ưu hóa cho suy luận văn bản dài. RL mở rộng ngữ cảnh dần dần giúp chuyển đổi ổn định từ ngữ cảnh ngắn sang dài. Mô hình vượt OpenAI-o3-mini và Qwen3-235B-A22B trên bảy bài kiểm tra QA tài liệu ngữ cảnh dài, ngang tầm Claude-3.7-Sonnet-Thinking. Đặc biệt mạnh về toán học, logic và suy luận nhiều bước.",
  "Yi-34B-Chat.description": "Yi-1.5-34B giữ vững năng lực ngôn ngữ tổng quát mạnh mẽ của dòng Yi, đồng thời sử dụng huấn luyện gia tăng trên 500 tỷ token chất lượng cao để cải thiện đáng kể logic toán học và lập trình.",
  "abab5.5-chat.description": "Thiết kế cho các tình huống năng suất với khả năng xử lý tác vụ phức tạp và tạo văn bản hiệu quả cho mục đích chuyên nghiệp.",
  "abab5.5s-chat.description": "Thiết kế cho trò chuyện nhân vật tiếng Trung, mang lại đối thoại tiếng Trung chất lượng cao cho nhiều ứng dụng.",
  "abab6.5g-chat.description": "Thiết kế cho trò chuyện nhân vật đa ngôn ngữ, hỗ trợ tạo đối thoại chất lượng cao bằng tiếng Anh và các ngôn ngữ khác.",
  "abab6.5s-chat.description": "Phù hợp với nhiều tác vụ NLP, bao gồm tạo văn bản và hệ thống đối thoại.",
  "abab6.5t-chat.description": "Tối ưu hóa cho trò chuyện nhân vật tiếng Trung, cung cấp đối thoại trôi chảy phù hợp với thói quen biểu đạt tiếng Trung.",
  "accounts/fireworks/models/deepseek-r1.description": "DeepSeek-R1 là một mô hình ngôn ngữ tiên tiến được tối ưu hóa bằng học tăng cường và dữ liệu khởi đầu lạnh, mang lại hiệu suất vượt trội trong lập luận, toán học và lập trình.",
  "accounts/fireworks/models/deepseek-v3.description": "Một mô hình ngôn ngữ Mixture-of-Experts (MoE) mạnh mẽ từ DeepSeek với tổng số tham số là 671 tỷ và 37 tỷ tham số hoạt động cho mỗi token.",
  "accounts/fireworks/models/llama-v3-70b-instruct.description": "Meta đã phát triển và phát hành dòng mô hình Meta Llama 3 LLM, bao gồm các mô hình tạo văn bản được huấn luyện trước và tinh chỉnh theo hướng dẫn với kích thước 8B và 70B. Các mô hình Llama 3 được tinh chỉnh theo hướng dẫn được tối ưu hóa cho hội thoại và vượt trội hơn nhiều mô hình trò chuyện mở hiện có trong các bài kiểm tra tiêu chuẩn của ngành.",
  "accounts/fireworks/models/llama-v3-8b-instruct-hf.description": "Các mô hình Llama 3 được tinh chỉnh theo hướng dẫn của Meta được tối ưu hóa cho hội thoại và vượt trội hơn nhiều mô hình trò chuyện mở hiện có trong các bài kiểm tra tiêu chuẩn của ngành. Llama 3 8B Instruct (phiên bản HF) là phiên bản FP16 gốc của Llama 3 8B Instruct, với kết quả dự kiến tương đương với triển khai chính thức trên Hugging Face.",
  "accounts/fireworks/models/llama-v3-8b-instruct.description": "Meta đã phát triển và phát hành dòng mô hình Meta Llama 3 LLM, bao gồm các mô hình tạo văn bản được huấn luyện trước và tinh chỉnh theo hướng dẫn với kích thước 8B và 70B. Các mô hình Llama 3 được tinh chỉnh theo hướng dẫn được tối ưu hóa cho hội thoại và vượt trội hơn nhiều mô hình trò chuyện mở hiện có trong các bài kiểm tra tiêu chuẩn của ngành.",
  "accounts/fireworks/models/llama-v3p1-405b-instruct.description": "Meta Llama 3.1 là một dòng mô hình LLM đa ngôn ngữ với các mô hình tạo văn bản được huấn luyện trước và tinh chỉnh theo hướng dẫn ở các kích thước 8B, 70B và 405B. Các mô hình văn bản được tinh chỉnh theo hướng dẫn được tối ưu hóa cho hội thoại đa ngôn ngữ và vượt trội hơn nhiều mô hình trò chuyện mở và đóng hiện có trong các bài kiểm tra tiêu chuẩn của ngành. 405B là mô hình mạnh nhất trong dòng Llama 3.1, sử dụng suy luận FP8 gần như tương đương với triển khai tham chiếu.",
  "accounts/fireworks/models/llama-v3p1-70b-instruct.description": "Meta Llama 3.1 là một dòng mô hình LLM đa ngôn ngữ với các mô hình tạo văn bản được huấn luyện trước và tinh chỉnh theo hướng dẫn ở các kích thước 8B, 70B và 405B. Các mô hình văn bản được tinh chỉnh theo hướng dẫn được tối ưu hóa cho hội thoại đa ngôn ngữ và vượt trội hơn nhiều mô hình trò chuyện mở và đóng hiện có trong các bài kiểm tra tiêu chuẩn của ngành.",
  "accounts/fireworks/models/llama-v3p1-8b-instruct.description": "Meta Llama 3.1 là một dòng mô hình LLM đa ngôn ngữ với các mô hình tạo văn bản được huấn luyện trước và tinh chỉnh theo hướng dẫn ở các kích thước 8B, 70B và 405B. Các mô hình văn bản được tinh chỉnh theo hướng dẫn được tối ưu hóa cho hội thoại đa ngôn ngữ và vượt trội hơn nhiều mô hình trò chuyện mở và đóng hiện có trong các bài kiểm tra tiêu chuẩn của ngành.",
  "accounts/fireworks/models/llama-v3p2-11b-vision-instruct.description": "Một mô hình suy luận thị giác được tinh chỉnh theo hướng dẫn từ Meta với 11 tỷ tham số, được tối ưu hóa cho nhận diện hình ảnh, suy luận hình ảnh, tạo chú thích và hỏi đáp liên quan đến hình ảnh. Mô hình hiểu dữ liệu thị giác như biểu đồ và đồ thị, kết nối giữa thị giác và ngôn ngữ bằng cách tạo mô tả văn bản cho chi tiết hình ảnh.",
  "accounts/fireworks/models/llama-v3p2-3b-instruct.description": "Llama 3.2 3B Instruct là một mô hình đa ngôn ngữ nhẹ từ Meta, được thiết kế để chạy hiệu quả với độ trễ thấp và chi phí thấp hơn so với các mô hình lớn hơn. Các trường hợp sử dụng phổ biến bao gồm viết lại truy vấn/lời nhắc và hỗ trợ viết.",
  "accounts/fireworks/models/llama-v3p2-90b-vision-instruct.description": "Một mô hình suy luận thị giác được tinh chỉnh theo hướng dẫn từ Meta với 90 tỷ tham số, được tối ưu hóa cho nhận diện hình ảnh, suy luận hình ảnh, tạo chú thích và hỏi đáp liên quan đến hình ảnh. Mô hình hiểu dữ liệu thị giác như biểu đồ và đồ thị, kết nối giữa thị giác và ngôn ngữ bằng cách tạo mô tả văn bản cho chi tiết hình ảnh. Lưu ý: mô hình này hiện đang được cung cấp thử nghiệm dưới dạng không máy chủ. Đối với môi trường sản xuất, lưu ý rằng Fireworks có thể ngừng triển khai mà không báo trước.",
  "accounts/fireworks/models/llama-v3p3-70b-instruct.description": "Llama 3.3 70B Instruct là bản cập nhật tháng 12 cho Llama 3.1 70B. Nó cải thiện khả năng sử dụng công cụ, hỗ trợ văn bản đa ngôn ngữ, toán học và lập trình so với bản phát hành tháng 7 năm 2024. Mô hình đạt hiệu suất hàng đầu trong ngành về lập luận, toán học và tuân theo hướng dẫn, mang lại hiệu suất tương đương với Llama 3.1 405B nhưng với tốc độ và chi phí tốt hơn đáng kể.",
  "accounts/fireworks/models/mistral-small-24b-instruct-2501.description": "Mô hình với 24 tỷ tham số có khả năng tiên tiến tương đương với các mô hình lớn hơn.",
  "accounts/fireworks/models/mixtral-8x22b-instruct.description": "Mixtral MoE 8x22B Instruct v0.1 là phiên bản được tinh chỉnh theo hướng dẫn của Mixtral MoE 8x22B v0.1, với API hoàn thành hội thoại được kích hoạt.",
  "accounts/fireworks/models/mixtral-8x7b-instruct.description": "Mixtral MoE 8x7B Instruct là phiên bản được tinh chỉnh theo hướng dẫn của Mixtral MoE 8x7B, với API hoàn thành hội thoại được kích hoạt.",
  "accounts/fireworks/models/mythomax-l2-13b.description": "Một biến thể cải tiến của MythoMix, có thể là phiên bản tinh tế hơn, kết hợp MythoLogic-L2 và Huginn bằng kỹ thuật hợp nhất tensor thử nghiệm cao. Tính độc đáo của nó khiến nó rất phù hợp cho kể chuyện và nhập vai.",
  "accounts/fireworks/models/phi-3-vision-128k-instruct.description": "Phi-3-Vision-128K-Instruct là một mô hình đa phương thức tiên tiến, nhẹ, được xây dựng từ dữ liệu tổng hợp và tập dữ liệu công khai được chọn lọc, tập trung vào dữ liệu văn bản và hình ảnh chất lượng cao, đòi hỏi suy luận. Nó thuộc dòng Phi-3, với phiên bản đa phương thức hỗ trợ độ dài ngữ cảnh 128K (tính theo token). Mô hình được nâng cấp kỹ lưỡng, bao gồm tinh chỉnh có giám sát và tối ưu hóa theo sở thích trực tiếp, để đảm bảo tuân theo hướng dẫn chính xác và các biện pháp an toàn mạnh mẽ.",
  "accounts/fireworks/models/qwen-qwq-32b-preview.description": "Mô hình Qwen QwQ tập trung vào việc nâng cao khả năng suy luận của AI, chứng minh rằng các mô hình mở có thể cạnh tranh với các mô hình tiên tiến đóng trong suy luận. QwQ-32B-Preview là bản phát hành thử nghiệm đạt mức o1 và vượt qua GPT-4o và Claude 3.5 Sonnet về suy luận và phân tích trên các bài kiểm tra GPQA, AIME, MATH-500 và LiveCodeBench. Lưu ý: mô hình này hiện đang được cung cấp thử nghiệm dưới dạng không máy chủ. Đối với môi trường sản xuất, lưu ý rằng Fireworks có thể ngừng triển khai mà không báo trước.",
  "accounts/fireworks/models/qwen2-vl-72b-instruct.description": "Mô hình Qwen-VL 72B là phiên bản mới nhất của Alibaba, phản ánh gần một năm đổi mới.",
  "accounts/fireworks/models/qwen2p5-72b-instruct.description": "Qwen2.5 là dòng mô hình LLM chỉ giải mã do nhóm Qwen và Alibaba Cloud phát triển, cung cấp các kích thước 0.5B, 1.5B, 3B, 7B, 14B, 32B và 72B, với cả biến thể cơ bản và được tinh chỉnh theo hướng dẫn.",
  "accounts/fireworks/models/qwen2p5-coder-32b-instruct.description": "Qwen2.5-Coder là mô hình LLM mới nhất của Qwen được thiết kế cho lập trình (trước đây là CodeQwen). Lưu ý: mô hình này hiện đang được cung cấp thử nghiệm dưới dạng không máy chủ. Đối với môi trường sản xuất, lưu ý rằng Fireworks có thể ngừng triển khai mà không báo trước.",
  "accounts/yi-01-ai/models/yi-large.description": "Yi-Large là một mô hình LLM hàng đầu, chỉ xếp sau GPT-4, Gemini 1.5 Pro và Claude 3 Opus trên bảng xếp hạng LMSYS. Nó xuất sắc trong khả năng đa ngôn ngữ, đặc biệt là tiếng Tây Ban Nha, Trung Quốc, Nhật Bản, Đức và Pháp. Yi-Large cũng thân thiện với nhà phát triển, sử dụng cùng cấu trúc API như OpenAI để dễ dàng tích hợp.",
  "ai21-jamba-1.5-large.description": "Mô hình đa ngôn ngữ với 398 tỷ tham số (94 tỷ đang hoạt động), hỗ trợ cửa sổ ngữ cảnh 256K, gọi hàm, đầu ra có cấu trúc và sinh văn bản có căn cứ.",
  "ai21-jamba-1.5-mini.description": "Mô hình đa ngôn ngữ với 52 tỷ tham số (12 tỷ đang hoạt động), hỗ trợ cửa sổ ngữ cảnh 256K, gọi hàm, đầu ra có cấu trúc và sinh văn bản có căn cứ.",
  "ai21-labs/AI21-Jamba-1.5-Large.description": "Mô hình đa ngôn ngữ với 398 tỷ tham số (94 tỷ đang hoạt động), hỗ trợ cửa sổ ngữ cảnh 256K, gọi hàm, đầu ra có cấu trúc và sinh văn bản có căn cứ.",
  "ai21-labs/AI21-Jamba-1.5-Mini.description": "Mô hình đa ngôn ngữ với 52 tỷ tham số (12 tỷ đang hoạt động), hỗ trợ cửa sổ ngữ cảnh 256K, gọi hàm, đầu ra có cấu trúc và sinh văn bản có căn cứ.",
  "alibaba/qwen-3-14b.description": "Qwen3 là thế hệ mới nhất trong dòng Qwen, cung cấp bộ mô hình dày đặc và MoE toàn diện. Được huấn luyện trên dữ liệu lớn, nó mang lại đột phá trong suy luận, tuân theo hướng dẫn, khả năng tác tử và hỗ trợ đa ngôn ngữ.",
  "alibaba/qwen-3-235b.description": "Qwen3 là thế hệ mới nhất trong dòng Qwen, cung cấp bộ mô hình dày đặc và MoE toàn diện. Được huấn luyện trên dữ liệu lớn, nó mang lại đột phá trong suy luận, tuân theo hướng dẫn, khả năng tác tử và hỗ trợ đa ngôn ngữ.",
  "alibaba/qwen-3-30b.description": "Qwen3 là thế hệ mới nhất trong dòng Qwen, cung cấp bộ mô hình dày đặc và MoE toàn diện. Được huấn luyện trên dữ liệu lớn, nó mang lại đột phá trong suy luận, tuân theo hướng dẫn, khả năng tác tử và hỗ trợ đa ngôn ngữ.",
  "alibaba/qwen-3-32b.description": "Qwen3 là thế hệ mới nhất trong dòng Qwen, cung cấp bộ mô hình dày đặc và MoE toàn diện. Được huấn luyện trên dữ liệu lớn, nó mang lại đột phá trong suy luận, tuân theo hướng dẫn, khả năng tác tử và hỗ trợ đa ngôn ngữ.",
  "alibaba/qwen3-coder.description": "Qwen3-Coder-480B-A35B-Instruct là mô hình mã hóa có khả năng tác tử cao nhất của Qwen, thể hiện hiệu suất vượt trội trong lập trình tác tử, sử dụng trình duyệt và các tác vụ mã hóa cốt lõi khác, đạt kết quả tương đương với Claude Sonnet.",
  "amazon/nova-lite.description": "Mô hình đa phương tiện chi phí cực thấp với khả năng xử lý cực nhanh các đầu vào hình ảnh, video và văn bản.",
  "amazon/nova-micro.description": "Mô hình chỉ xử lý văn bản với độ trễ cực thấp và chi phí rất thấp.",
  "amazon/nova-pro.description": "Mô hình đa phương tiện mạnh mẽ với sự cân bằng tối ưu giữa độ chính xác, tốc độ và chi phí cho nhiều tác vụ khác nhau.",
  "amazon/titan-embed-text-v2.description": "Amazon Titan Text Embeddings V2 là mô hình nhúng đa ngôn ngữ nhẹ, hiệu quả, hỗ trợ các kích thước 1024, 512 và 256.",
  "anthropic.claude-3-5-sonnet-20240620-v1:0.description": "Claude 3.5 Sonnet nâng tầm tiêu chuẩn ngành, vượt trội so với các đối thủ và Claude 3 Opus trong nhiều đánh giá, đồng thời duy trì tốc độ và chi phí ở mức trung bình.",
  "anthropic.claude-3-5-sonnet-20241022-v2:0.description": "Claude 3.5 Sonnet nâng tầm tiêu chuẩn ngành, vượt trội so với các đối thủ và Claude 3 Opus trong nhiều đánh giá, đồng thời duy trì tốc độ và chi phí ở mức trung bình.",
  "anthropic.claude-3-haiku-20240307-v1:0.description": "Claude 3 Haiku là mô hình nhanh nhất và nhỏ gọn nhất của Anthropic, cung cấp phản hồi gần như tức thì cho các truy vấn đơn giản. Nó mang lại trải nghiệm AI mượt mà, giống con người và hỗ trợ đầu vào hình ảnh với cửa sổ ngữ cảnh 200K.",
  "anthropic.claude-3-opus-20240229-v1:0.description": "Claude 3 Opus là mô hình AI mạnh mẽ nhất của Anthropic với hiệu suất hàng đầu trong các tác vụ phức tạp. Nó xử lý các yêu cầu mở và tình huống mới với độ trôi chảy và hiểu biết giống con người, đồng thời hỗ trợ đầu vào hình ảnh với cửa sổ ngữ cảnh 200K.",
  "anthropic.claude-3-sonnet-20240229-v1:0.description": "Claude 3 Sonnet cân bằng giữa trí tuệ và tốc độ cho khối lượng công việc doanh nghiệp, mang lại giá trị cao với chi phí thấp hơn. Nó được thiết kế như một công cụ đáng tin cậy cho triển khai AI quy mô lớn và hỗ trợ đầu vào hình ảnh với cửa sổ ngữ cảnh 200K.",
  "anthropic.claude-instant-v1.description": "Mô hình nhanh, tiết kiệm nhưng vẫn mạnh mẽ cho trò chuyện hàng ngày, phân tích văn bản, tóm tắt và hỏi đáp tài liệu.",
  "anthropic.claude-v2.description": "Mô hình có khả năng cao trong các tác vụ từ đối thoại phức tạp và sáng tạo đến tuân theo hướng dẫn chi tiết.",
  "anthropic.claude-v2:1.description": "Claude 2 được cập nhật với cửa sổ ngữ cảnh gấp đôi và cải thiện độ tin cậy, giảm ảo giác và tăng độ chính xác dựa trên bằng chứng cho tài liệu dài và RAG.",
  "anthropic/claude-3-haiku.description": "Claude 3 Haiku là mô hình nhanh nhất của Anthropic, được thiết kế cho khối lượng công việc doanh nghiệp với các yêu cầu dài. Nó có thể nhanh chóng phân tích các tài liệu lớn như báo cáo quý, hợp đồng hoặc vụ kiện với chi phí bằng một nửa so với các đối thủ.",
  "anthropic/claude-3-opus.description": "Claude 3 Opus là mô hình thông minh nhất của Anthropic với hiệu suất hàng đầu trong các tác vụ phức tạp, xử lý các yêu cầu mở và tình huống mới với độ trôi chảy và hiểu biết giống con người.",
  "anthropic/claude-3.5-haiku.description": "Claude 3.5 Haiku có tốc độ, độ chính xác mã hóa và khả năng sử dụng công cụ được nâng cao, phù hợp với các tình huống yêu cầu cao về tốc độ và tương tác công cụ.",
  "anthropic/claude-3.5-sonnet.description": "Claude 3.5 Sonnet là mô hình nhanh và hiệu quả trong dòng Sonnet, cung cấp hiệu suất mã hóa và suy luận tốt hơn, với một số phiên bản dần được thay thế bởi Sonnet 3.7 trở đi.",
  "anthropic/claude-3.7-sonnet.description": "Claude 3.7 Sonnet là phiên bản nâng cấp của dòng Sonnet với khả năng suy luận và mã hóa mạnh mẽ hơn, phù hợp cho các tác vụ phức tạp cấp doanh nghiệp.",
  "anthropic/claude-haiku-4.5.description": "Claude Haiku 4.5 là mô hình nhanh hiệu suất cao của Anthropic, mang lại độ trễ rất thấp trong khi vẫn duy trì độ chính xác cao.",
  "anthropic/claude-opus-4.1.description": "Opus 4.1 là mô hình cao cấp của Anthropic được tối ưu hóa cho lập trình, suy luận phức tạp và các tác vụ kéo dài.",
  "anthropic/claude-opus-4.5.description": "Claude Opus 4.5 là mô hình hàng đầu của Anthropic, kết hợp trí tuệ đỉnh cao với hiệu suất có thể mở rộng cho các tác vụ suy luận phức tạp và chất lượng cao.",
  "anthropic/claude-opus-4.description": "Opus 4 là mô hình hàng đầu của Anthropic được thiết kế cho các tác vụ phức tạp và ứng dụng doanh nghiệp.",
  "anthropic/claude-sonnet-4.5.description": "Claude Sonnet 4.5 là mô hình suy luận lai mới nhất của Anthropic, được tối ưu hóa cho suy luận phức tạp và mã hóa.",
  "anthropic/claude-sonnet-4.description": "Claude Sonnet 4 là mô hình suy luận lai của Anthropic với khả năng tư duy và không tư duy kết hợp.",
  "ascend-tribe/pangu-pro-moe.description": "Pangu-Pro-MoE 72B-A16B là một mô hình ngôn ngữ lớn dạng thưa với 72 tỷ tham số tổng và 16 tỷ tham số kích hoạt, dựa trên kiến trúc MoE nhóm (MoGE). Nó nhóm các chuyên gia trong quá trình lựa chọn và giới hạn số token để kích hoạt số chuyên gia bằng nhau trong mỗi nhóm, giúp cân bằng tải và nâng cao hiệu quả triển khai trên Ascend.",
  "aya.description": "Aya 23 là mô hình đa ngôn ngữ của Cohere, hỗ trợ 23 ngôn ngữ cho nhiều tình huống sử dụng khác nhau.",
  "aya:35b.description": "Aya 23 là mô hình đa ngôn ngữ của Cohere, hỗ trợ 23 ngôn ngữ cho nhiều tình huống sử dụng khác nhau.",
  "azure-DeepSeek-R1-0528.description": "Triển khai bởi Microsoft; DeepSeek R1 đã được nâng cấp thành DeepSeek-R1-0528. Bản cập nhật tăng cường tính toán và tối ưu hóa thuật toán hậu huấn luyện, cải thiện đáng kể độ sâu suy luận và khả năng suy diễn. Mô hình thể hiện mạnh mẽ trong các bài kiểm tra toán học, lập trình và logic tổng quát, tiệm cận các mô hình hàng đầu như O3 và Gemini 2.5 Pro.",
  "baichuan-m2-32b.description": "Baichuan M2 32B là mô hình MoE từ Baichuan Intelligence với khả năng suy luận mạnh mẽ.",
  "baichuan/baichuan2-13b-chat.description": "Baichuan-13B là mô hình mã nguồn mở với 13 tỷ tham số, có thể sử dụng thương mại từ Baichuan, đạt kết quả hàng đầu trong phân khúc trên các bài kiểm tra tiếng Trung và tiếng Anh uy tín.",
  "baidu/ERNIE-4.5-300B-A47B.description": "ERNIE-4.5-300B-A47B là mô hình MoE của Baidu với 300 tỷ tham số tổng và 47 tỷ tham số kích hoạt mỗi token, cân bằng giữa hiệu suất mạnh mẽ và hiệu quả tính toán. Là mô hình cốt lõi của ERNIE 4.5, nó xuất sắc trong hiểu ngôn ngữ, sinh văn bản, suy luận và lập trình. Mô hình sử dụng phương pháp tiền huấn luyện MoE đa phương thức dị thể với huấn luyện kết hợp văn bản-hình ảnh để tăng cường năng lực tổng thể, đặc biệt là khả năng tuân thủ hướng dẫn và kiến thức thế giới.",
  "baidu/ernie-5.0-thinking-preview.description": "ERNIE 5.0 Thinking Preview là mô hình ERNIE đa phương thức thế hệ mới của Baidu, mạnh mẽ trong hiểu đa phương thức, tuân thủ hướng dẫn, sáng tạo, hỏi đáp thực tế và gọi công cụ.",
  "black-forest-labs/flux-1.1-pro.description": "FLUX 1.1 Pro là phiên bản nâng cấp nhanh hơn của FLUX Pro với chất lượng hình ảnh xuất sắc và khả năng tuân thủ prompt tốt.",
  "black-forest-labs/flux-dev.description": "FLUX Dev là phiên bản phát triển của FLUX dành cho mục đích phi thương mại.",
  "black-forest-labs/flux-pro.description": "FLUX Pro là mô hình FLUX chuyên nghiệp cho đầu ra hình ảnh chất lượng cao.",
  "black-forest-labs/flux-schnell.description": "FLUX Schnell là mô hình tạo ảnh nhanh được tối ưu hóa cho tốc độ.",
  "c4ai-aya-expanse-32b.description": "Aya Expanse là mô hình đa ngôn ngữ hiệu suất cao với 32 tỷ tham số, sử dụng tinh chỉnh theo hướng dẫn, phân bổ dữ liệu, huấn luyện theo sở thích và hợp nhất mô hình để cạnh tranh với các mô hình đơn ngữ. Hỗ trợ 23 ngôn ngữ.",
  "c4ai-aya-expanse-8b.description": "Aya Expanse là mô hình đa ngôn ngữ hiệu suất cao với 8 tỷ tham số, sử dụng tinh chỉnh theo hướng dẫn, phân bổ dữ liệu, huấn luyện theo sở thích và hợp nhất mô hình để cạnh tranh với các mô hình đơn ngữ. Hỗ trợ 23 ngôn ngữ.",
  "c4ai-aya-vision-32b.description": "Aya Vision là mô hình đa phương thức tiên tiến với hiệu suất mạnh mẽ trên các bài kiểm tra ngôn ngữ, văn bản và hình ảnh. Hỗ trợ 23 ngôn ngữ. Phiên bản 32B tập trung vào hiệu suất đa ngôn ngữ hàng đầu.",
  "c4ai-aya-vision-8b.description": "Aya Vision là mô hình đa phương thức tiên tiến với hiệu suất mạnh mẽ trên các bài kiểm tra ngôn ngữ, văn bản và hình ảnh. Phiên bản 8B tập trung vào độ trễ thấp và hiệu suất mạnh mẽ.",
  "charglm-3.description": "CharGLM-3 được xây dựng cho nhập vai và đồng hành cảm xúc, hỗ trợ bộ nhớ nhiều lượt siêu dài và đối thoại cá nhân hóa.",
  "charglm-4.description": "CharGLM-4 được xây dựng cho nhập vai và đồng hành cảm xúc, hỗ trợ bộ nhớ nhiều lượt siêu dài và đối thoại cá nhân hóa.",
  "chatgpt-4o-latest.description": "ChatGPT-4o là mô hình động được cập nhật theo thời gian thực, kết hợp khả năng hiểu và sinh văn bản mạnh mẽ cho các tình huống sử dụng quy mô lớn như hỗ trợ khách hàng, giáo dục và hỗ trợ kỹ thuật.",
  "claude-2.0.description": "Claude 2 mang đến những cải tiến quan trọng cho doanh nghiệp, bao gồm ngữ cảnh 200K token hàng đầu, giảm ảo giác, prompt hệ thống và tính năng thử nghiệm mới: gọi công cụ.",
  "claude-2.1.description": "Claude 2 mang đến những cải tiến quan trọng cho doanh nghiệp, bao gồm ngữ cảnh 200K token hàng đầu, giảm ảo giác, prompt hệ thống và tính năng thử nghiệm mới: gọi công cụ.",
  "claude-3-5-haiku-20241022.description": "Claude 3.5 Haiku là mô hình thế hệ mới nhanh nhất của Anthropic. So với Claude 3 Haiku, nó cải thiện toàn diện về kỹ năng và vượt qua mô hình lớn nhất trước đó là Claude 3 Opus trong nhiều bài kiểm tra trí tuệ.",
  "claude-3-5-haiku-latest.description": "Claude 3.5 Haiku cung cấp phản hồi nhanh cho các tác vụ nhẹ.",
  "claude-3-7-sonnet-20250219.description": "Claude 3.7 Sonnet là mô hình thông minh nhất của Anthropic và là mô hình lai đầu tiên về suy luận trên thị trường. Nó có thể tạo phản hồi gần như tức thì hoặc suy luận từng bước mở rộng mà người dùng có thể theo dõi. Sonnet đặc biệt mạnh về lập trình, khoa học dữ liệu, thị giác máy tính và các tác vụ đại lý.",
  "claude-3-7-sonnet-latest.description": "Claude 3.7 Sonnet là mô hình mới nhất và mạnh mẽ nhất của Anthropic cho các tác vụ phức tạp, xuất sắc về hiệu suất, trí tuệ, lưu loát và hiểu biết.",
  "claude-3-haiku-20240307.description": "Claude 3 Haiku là mô hình nhanh nhất và nhỏ gọn nhất của Anthropic, được thiết kế cho phản hồi gần như tức thì với hiệu suất nhanh và chính xác.",
  "claude-3-opus-20240229.description": "Claude 3 Opus là mô hình mạnh mẽ nhất của Anthropic cho các tác vụ phức tạp, xuất sắc về hiệu suất, trí tuệ, lưu loát và hiểu biết.",
  "claude-3-sonnet-20240229.description": "Claude 3 Sonnet cân bằng giữa trí tuệ và tốc độ cho khối lượng công việc doanh nghiệp, mang lại giá trị cao với chi phí thấp hơn và triển khai quy mô lớn đáng tin cậy.",
  "claude-haiku-4-5-20251001.description": "Claude Haiku 4.5 là mô hình Haiku nhanh nhất và thông minh nhất của Anthropic, với tốc độ cực nhanh và khả năng suy luận mở rộng.",
  "claude-opus-4-1-20250805-thinking.description": "Claude Opus 4.1 Thinking là biến thể nâng cao có thể hiển thị quá trình suy luận của nó.",
  "claude-opus-4-1-20250805.description": "Claude Opus 4.1 là mô hình mới nhất và mạnh mẽ nhất của Anthropic dành cho các tác vụ phức tạp, vượt trội về hiệu suất, trí tuệ, độ trôi chảy và khả năng hiểu.",
  "claude-opus-4-20250514.description": "Claude Opus 4 là mô hình mạnh mẽ nhất của Anthropic dành cho các tác vụ phức tạp, vượt trội về hiệu suất, trí tuệ, độ trôi chảy và khả năng hiểu.",
  "claude-opus-4-5-20251101.description": "Claude Opus 4.5 là mô hình hàng đầu của Anthropic, kết hợp trí tuệ vượt trội với hiệu suất có thể mở rộng, lý tưởng cho các tác vụ phức tạp đòi hỏi phản hồi và suy luận chất lượng cao nhất.",
  "claude-opus-4-6.description": "Claude Opus 4.6 là mô hình thông minh nhất của Anthropic dành cho xây dựng đại lý và lập trình.",
  "claude-sonnet-4-20250514-thinking.description": "Claude Sonnet 4 Thinking có thể tạo phản hồi gần như tức thì hoặc suy luận từng bước mở rộng với quy trình hiển thị.",
  "claude-sonnet-4-20250514.description": "Claude Sonnet 4 có thể tạo phản hồi gần như tức thì hoặc suy nghĩ từng bước với quy trình hiển thị rõ ràng.",
  "claude-sonnet-4-5-20250929.description": "Claude Sonnet 4.5 là mô hình thông minh nhất của Anthropic tính đến thời điểm hiện tại.",
  "codegeex-4.description": "CodeGeeX-4 là trợ lý lập trình AI mạnh mẽ hỗ trợ hỏi đáp đa ngôn ngữ và hoàn thành mã để tăng năng suất lập trình viên.",
  "codegeex4-all-9b.description": "CodeGeeX4-ALL-9B là mô hình tạo mã đa ngôn ngữ hỗ trợ hoàn thành và sinh mã, thông dịch mã, tìm kiếm web, gọi hàm và hỏi đáp mã ở cấp độ kho lưu trữ, bao phủ nhiều tình huống phát triển phần mềm. Đây là mô hình mã hàng đầu dưới 10 tỷ tham số.",
  "codegemma.description": "CodeGemma là mô hình nhẹ cho các tác vụ lập trình đa dạng, cho phép lặp lại nhanh và tích hợp dễ dàng.",
  "codegemma:2b.description": "CodeGemma là mô hình nhẹ cho các tác vụ lập trình đa dạng, cho phép lặp lại nhanh và tích hợp dễ dàng.",
  "codellama.description": "Code Llama là mô hình ngôn ngữ lớn tập trung vào sinh mã và thảo luận mã, hỗ trợ nhiều ngôn ngữ lập trình cho quy trình làm việc của lập trình viên.",
  "codellama/CodeLlama-34b-Instruct-hf.description": "Code Llama là mô hình ngôn ngữ lớn tập trung vào sinh mã và thảo luận mã, hỗ trợ nhiều ngôn ngữ lập trình cho quy trình làm việc của lập trình viên.",
  "codellama:13b.description": "Code Llama là mô hình ngôn ngữ lớn tập trung vào sinh mã và thảo luận mã, hỗ trợ nhiều ngôn ngữ lập trình cho quy trình làm việc của lập trình viên.",
  "codellama:34b.description": "Code Llama là mô hình ngôn ngữ lớn tập trung vào sinh mã và thảo luận mã, hỗ trợ nhiều ngôn ngữ lập trình cho quy trình làm việc của lập trình viên.",
  "codellama:70b.description": "Code Llama là mô hình ngôn ngữ lớn tập trung vào sinh mã và thảo luận mã, hỗ trợ nhiều ngôn ngữ lập trình cho quy trình làm việc của lập trình viên.",
  "codeqwen.description": "CodeQwen1.5 là mô hình ngôn ngữ lớn được huấn luyện trên dữ liệu mã phong phú, được xây dựng cho các tác vụ lập trình phức tạp.",
  "codestral-latest.description": "Codestral là mô hình lập trình tiên tiến nhất của chúng tôi; phiên bản v2 (tháng 1 năm 2025) nhắm đến các tác vụ tần suất cao, độ trễ thấp như FIM, sửa mã và sinh bài kiểm tra.",
  "codestral.description": "Codestral là mô hình lập trình đầu tiên của Mistral AI, cung cấp hỗ trợ sinh mã mạnh mẽ.",
  "codex-mini-latest.description": "codex-mini-latest là một mô hình o4-mini được tinh chỉnh dành cho Codex CLI. Đối với việc sử dụng API trực tiếp, chúng tôi khuyến nghị bắt đầu với gpt-4.1.",
  "cogito-2.1:671b.description": "Cogito v2.1 671B là một mô hình ngôn ngữ mã nguồn mở của Mỹ, miễn phí cho mục đích thương mại, có hiệu suất sánh ngang với các mô hình hàng đầu, hiệu quả suy luận theo token cao hơn, hỗ trợ ngữ cảnh dài 128k và khả năng tổng thể mạnh mẽ.",
  "cogview-4.description": "CogView-4 là mô hình chuyển văn bản thành hình ảnh mã nguồn mở đầu tiên của Zhipu có khả năng tạo ký tự Trung Quốc. Mô hình cải thiện khả năng hiểu ngữ nghĩa, chất lượng hình ảnh và hiển thị văn bản Trung/Anh, hỗ trợ lời nhắc song ngữ với độ dài tùy ý và có thể tạo hình ảnh ở bất kỳ độ phân giải nào trong phạm vi chỉ định.",
  "cohere-command-r-plus.description": "Command R+ là một mô hình tiên tiến được tối ưu hóa cho RAG, được xây dựng để xử lý khối lượng công việc doanh nghiệp.",
  "cohere-command-r.description": "Command R là một mô hình sinh văn bản có khả năng mở rộng, được thiết kế cho RAG và sử dụng công cụ, cho phép triển khai AI ở cấp độ sản xuất.",
  "cohere/Cohere-command-r-plus.description": "Command R+ là một mô hình tiên tiến được tối ưu hóa cho RAG, được xây dựng để xử lý khối lượng công việc doanh nghiệp.",
  "cohere/Cohere-command-r.description": "Command R là một mô hình sinh văn bản có khả năng mở rộng, được thiết kế cho RAG và sử dụng công cụ, cho phép triển khai AI ở cấp độ sản xuất.",
  "cohere/command-a.description": "Command A là mô hình mạnh nhất của Cohere cho đến nay, vượt trội trong việc sử dụng công cụ, tác tử, RAG và các trường hợp đa ngôn ngữ. Mô hình có độ dài ngữ cảnh 256K, chạy chỉ với hai GPU và đạt thông lượng cao hơn 150% so với Command R+ 08-2024.",
  "cohere/command-r-plus.description": "Command R+ là mô hình LLM mới nhất của Cohere, được tối ưu hóa cho trò chuyện và ngữ cảnh dài, hướng đến hiệu suất vượt trội để các công ty có thể vượt qua giai đoạn nguyên mẫu và đi vào sản xuất.",
  "cohere/command-r.description": "Command R được tối ưu hóa cho các tác vụ trò chuyện và ngữ cảnh dài, được định vị là mô hình \"có thể mở rộng\" cân bằng giữa hiệu suất cao và độ chính xác, giúp các công ty vượt qua giai đoạn nguyên mẫu và triển khai thực tế.",
  "cohere/embed-v4.0.description": "Một mô hình phân loại hoặc chuyển đổi văn bản, hình ảnh hoặc nội dung hỗn hợp thành các vector nhúng.",
  "comfyui/flux-dev.description": "FLUX.1 Dev là mô hình chuyển văn bản thành hình ảnh chất lượng cao (10–50 bước), lý tưởng cho các sản phẩm sáng tạo và nghệ thuật cao cấp.",
  "comfyui/flux-kontext-dev.description": "FLUX.1 Kontext-dev là mô hình chỉnh sửa hình ảnh hỗ trợ chỉnh sửa theo hướng dẫn văn bản, bao gồm chỉnh sửa cục bộ và chuyển đổi phong cách.",
  "comfyui/flux-krea-dev.description": "FLUX.1 Krea-dev là mô hình chuyển văn bản thành hình ảnh được tăng cường an toàn, đồng phát triển với Krea, có bộ lọc an toàn tích hợp.",
  "comfyui/flux-schnell.description": "FLUX.1 Schnell là mô hình chuyển văn bản thành hình ảnh siêu nhanh, tạo hình ảnh chất lượng cao chỉ trong 1–4 bước, lý tưởng cho sử dụng thời gian thực và tạo mẫu nhanh.",
  "comfyui/stable-diffusion-15.description": "Stable Diffusion 1.5 là mô hình chuyển văn bản thành hình ảnh cổ điển với độ phân giải 512x512, lý tưởng cho tạo mẫu nhanh và thử nghiệm sáng tạo.",
  "comfyui/stable-diffusion-35-inclclip.description": "Stable Diffusion 3.5 với bộ mã hóa CLIP/T5 tích hợp, không cần tệp mã hóa bên ngoài, phù hợp với các mô hình như sd3.5_medium_incl_clips sử dụng ít tài nguyên hơn.",
  "comfyui/stable-diffusion-35.description": "Stable Diffusion 3.5 là mô hình chuyển văn bản thành hình ảnh thế hệ mới với các biến thể Large và Medium. Cần tệp mã hóa CLIP bên ngoài và mang lại chất lượng hình ảnh xuất sắc cùng khả năng tuân thủ lời nhắc cao.",
  "comfyui/stable-diffusion-custom-refiner.description": "Mô hình SDXL chuyển hình ảnh thành hình ảnh tùy chỉnh. Sử dụng tên tệp mô hình là custom_sd_lobe.safetensors; nếu có VAE, sử dụng custom_sd_vae_lobe.safetensors. Đặt các tệp mô hình vào thư mục yêu cầu của Comfy.",
  "comfyui/stable-diffusion-custom.description": "Mô hình SD chuyển văn bản thành hình ảnh tùy chỉnh. Sử dụng tên tệp mô hình là custom_sd_lobe.safetensors; nếu có VAE, sử dụng custom_sd_vae_lobe.safetensors. Đặt các tệp mô hình vào thư mục yêu cầu của Comfy.",
  "comfyui/stable-diffusion-refiner.description": "Mô hình SDXL chuyển hình ảnh thành hình ảnh thực hiện các chuyển đổi chất lượng cao từ hình ảnh đầu vào, hỗ trợ chuyển đổi phong cách, phục hồi và biến thể sáng tạo.",
  "comfyui/stable-diffusion-xl.description": "SDXL là mô hình chuyển văn bản thành hình ảnh hỗ trợ tạo hình ảnh độ phân giải cao 1024x1024 với chất lượng và chi tiết tốt hơn.",
  "command-a-03-2025.description": "Command A là mô hình mạnh nhất của chúng tôi cho đến nay, vượt trội trong việc sử dụng công cụ, tác tử, RAG và các tình huống đa ngôn ngữ. Mô hình có cửa sổ ngữ cảnh 256K, chạy chỉ với hai GPU và đạt thông lượng cao hơn 150% so với Command R+ 08-2024.",
  "command-light-nightly.description": "Để rút ngắn khoảng cách giữa các bản phát hành chính, chúng tôi cung cấp các bản dựng Command hàng đêm. Với dòng command-light, đây là command-light-nightly. Đây là phiên bản mới nhất, mang tính thử nghiệm cao (và có thể không ổn định), được cập nhật thường xuyên mà không báo trước, do đó không khuyến nghị sử dụng trong môi trường sản xuất.",
  "command-light.description": "Biến thể Command nhỏ hơn, nhanh hơn, gần như mạnh mẽ như bản gốc nhưng có tốc độ cao hơn.",
  "command-nightly.description": "Để rút ngắn khoảng cách giữa các bản phát hành chính, chúng tôi cung cấp các bản dựng Command hàng đêm. Với dòng Command, đây là command-nightly. Đây là phiên bản mới nhất, mang tính thử nghiệm cao (và có thể không ổn định), được cập nhật thường xuyên mà không báo trước, do đó không khuyến nghị sử dụng trong môi trường sản xuất.",
  "command-r-03-2024.description": "Command R là mô hình trò chuyện theo hướng dẫn với chất lượng cao hơn, độ tin cậy lớn hơn và cửa sổ ngữ cảnh dài hơn so với các mô hình trước đó. Mô hình hỗ trợ các quy trình phức tạp như tạo mã, RAG, sử dụng công cụ và tác tử.",
  "command-r-08-2024.description": "command-r-08-2024 là phiên bản cập nhật của mô hình Command R được phát hành vào tháng 8 năm 2024.",
  "command-r-plus-04-2024.description": "command-r-plus là bí danh của command-r-plus-04-2024, vì vậy sử dụng command-r-plus trong API sẽ trỏ đến mô hình đó.",
  "command-r-plus-08-2024.description": "Command R+ là mô hình trò chuyện theo hướng dẫn với chất lượng cao hơn, độ tin cậy lớn hơn và cửa sổ ngữ cảnh dài hơn so với các mô hình trước đó. Mô hình phù hợp nhất cho các quy trình RAG phức tạp và sử dụng công cụ nhiều bước.",
  "command-r-plus.description": "Command R+ là mô hình LLM hiệu suất cao được thiết kế cho các tình huống doanh nghiệp thực tế và ứng dụng phức tạp.",
  "command-r.description": "Command R là mô hình LLM được tối ưu hóa cho trò chuyện và các tác vụ ngữ cảnh dài, lý tưởng cho tương tác động và quản lý tri thức.",
  "command-r7b-12-2024.description": "command-r7b-12-2024 là bản cập nhật nhỏ, hiệu quả được phát hành vào tháng 12 năm 2024. Mô hình vượt trội trong các tác vụ RAG, sử dụng công cụ và tác tử đòi hỏi suy luận phức tạp nhiều bước.",
  "command.description": "Mô hình trò chuyện theo hướng dẫn cung cấp chất lượng và độ tin cậy cao hơn trong các tác vụ ngôn ngữ, với cửa sổ ngữ cảnh dài hơn so với các mô hình sinh văn bản cơ bản của chúng tôi.",
  "computer-use-preview.description": "computer-use-preview là mô hình chuyên biệt cho công cụ \"sử dụng máy tính\", được huấn luyện để hiểu và thực hiện các tác vụ liên quan đến máy tính.",
  "dall-e-2.description": "DALL·E thế hệ thứ hai với khả năng tạo hình ảnh thực tế, chính xác hơn và độ phân giải gấp 4 lần thế hệ đầu.",
  "dall-e-3.description": "Mô hình DALL·E mới nhất, phát hành vào tháng 11 năm 2023, hỗ trợ tạo hình ảnh thực tế, chính xác hơn với chi tiết mạnh mẽ hơn.",
  "databricks/dbrx-instruct.description": "DBRX Instruct cung cấp khả năng xử lý hướng dẫn đáng tin cậy cao trong nhiều ngành công nghiệp.",
  "deepseek-ai/DeepSeek-OCR.description": "DeepSeek-OCR là một mô hình thị giác-ngôn ngữ từ DeepSeek AI tập trung vào OCR và \"nén quang học theo ngữ cảnh.\" Mô hình này khám phá cách nén thông tin ngữ cảnh từ hình ảnh, xử lý tài liệu một cách hiệu quả và chuyển đổi chúng thành văn bản có cấu trúc (ví dụ: Markdown). Nó nhận diện văn bản trong hình ảnh một cách chính xác, phù hợp cho số hóa tài liệu, trích xuất văn bản và xử lý có cấu trúc.",
  "deepseek-ai/DeepSeek-R1-0528-Qwen3-8B.description": "DeepSeek-R1-0528-Qwen3-8B chắt lọc chuỗi suy nghĩ từ DeepSeek-R1-0528 vào Qwen3 8B Base. Mô hình này đạt trạng thái tiên tiến nhất (SOTA) trong số các mô hình mã nguồn mở, vượt Qwen3 8B 10% trên AIME 2024 và tương đương hiệu suất của Qwen3-235B-thinking. Nó vượt trội trong các bài kiểm tra suy luận toán học, lập trình và logic tổng quát. Mô hình sử dụng kiến trúc Qwen3-8B nhưng dùng bộ mã hóa của DeepSeek-R1-0528.",
  "deepseek-ai/DeepSeek-R1-0528.description": "DeepSeek R1 tận dụng sức mạnh tính toán bổ sung và tối ưu hóa thuật toán sau huấn luyện để tăng cường khả năng suy luận. Mô hình thể hiện hiệu suất mạnh mẽ trên các bài kiểm tra toán học, lập trình và logic tổng quát, tiệm cận các mô hình hàng đầu như o3 và Gemini 2.5 Pro.",
  "deepseek-ai/DeepSeek-R1-Distill-Llama-70B.description": "Các mô hình chắt lọc DeepSeek-R1 sử dụng học tăng cường (RL) và dữ liệu khởi đầu lạnh để cải thiện khả năng suy luận và thiết lập các chuẩn mực mới cho mô hình mã nguồn mở đa nhiệm.",
  "deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B.description": "Các mô hình chắt lọc DeepSeek-R1 sử dụng học tăng cường (RL) và dữ liệu khởi đầu lạnh để cải thiện khả năng suy luận và thiết lập các chuẩn mực mới cho mô hình mã nguồn mở đa nhiệm.",
  "deepseek-ai/DeepSeek-R1-Distill-Qwen-14B.description": "Các mô hình chắt lọc DeepSeek-R1 sử dụng học tăng cường (RL) và dữ liệu khởi đầu lạnh để cải thiện khả năng suy luận và thiết lập các chuẩn mực mới cho mô hình mã nguồn mở đa nhiệm.",
  "deepseek-ai/DeepSeek-R1-Distill-Qwen-32B.description": "DeepSeek-R1-Distill-Qwen-32B được chắt lọc từ Qwen2.5-32B và tinh chỉnh trên 800K mẫu dữ liệu được chọn lọc từ DeepSeek-R1. Mô hình này vượt trội trong toán học, lập trình và suy luận, đạt kết quả cao trên AIME 2024, MATH-500 (độ chính xác 94.3%) và GPQA Diamond.",
  "deepseek-ai/DeepSeek-R1-Distill-Qwen-7B.description": "DeepSeek-R1-Distill-Qwen-7B được chắt lọc từ Qwen2.5-Math-7B và tinh chỉnh trên 800K mẫu dữ liệu được chọn lọc từ DeepSeek-R1. Mô hình này thể hiện hiệu suất mạnh mẽ, đạt 92.8% trên MATH-500, 55.5% trên AIME 2024 và xếp hạng CodeForces 1189 cho một mô hình 7B.",
  "deepseek-ai/DeepSeek-R1.description": "DeepSeek-R1 cải thiện khả năng suy luận thông qua học tăng cường (RL) và dữ liệu khởi đầu lạnh, thiết lập các chuẩn mực mới cho mô hình mã nguồn mở đa nhiệm và vượt qua OpenAI-o1-mini.",
  "deepseek-ai/DeepSeek-V2.5.description": "DeepSeek-V2.5 nâng cấp từ DeepSeek-V2-Chat và DeepSeek-Coder-V2-Instruct, kết hợp khả năng tổng quát và lập trình. Mô hình cải thiện khả năng viết và tuân thủ hướng dẫn để phù hợp hơn với sở thích người dùng, và đạt tiến bộ đáng kể trên các bài kiểm tra như AlpacaEval 2.0, ArenaHard, AlignBench và MT-Bench.",
  "deepseek-ai/DeepSeek-V3.1-Terminus.description": "DeepSeek-V3.1-Terminus là phiên bản cập nhật của mô hình V3.1, được định vị như một mô hình đại lý lai (hybrid agent LLM). Mô hình khắc phục các vấn đề do người dùng báo cáo, cải thiện độ ổn định, tính nhất quán ngôn ngữ và giảm ký tự bất thường hoặc pha trộn Trung-Anh. Nó tích hợp chế độ Suy nghĩ và Không suy nghĩ với mẫu trò chuyện để chuyển đổi linh hoạt. Ngoài ra, mô hình còn nâng cao hiệu suất của Code Agent và Search Agent để sử dụng công cụ đáng tin cậy hơn và thực hiện các tác vụ nhiều bước.",
  "deepseek-ai/DeepSeek-V3.1.description": "DeepSeek V3.1 sử dụng kiến trúc suy luận lai và hỗ trợ cả chế độ suy nghĩ và không suy nghĩ.",
  "deepseek-ai/DeepSeek-V3.2-Exp.description": "DeepSeek-V3.2-Exp là phiên bản thử nghiệm của V3.2, là cầu nối đến kiến trúc tiếp theo. Mô hình bổ sung DeepSeek Sparse Attention (DSA) trên nền tảng V3.1-Terminus để cải thiện hiệu quả huấn luyện và suy luận với ngữ cảnh dài, cùng các tối ưu hóa cho việc sử dụng công cụ, hiểu tài liệu dài và suy luận nhiều bước. Đây là lựa chọn lý tưởng để khám phá hiệu quả suy luận cao hơn với ngân sách ngữ cảnh lớn.",
  "deepseek-ai/DeepSeek-V3.description": "DeepSeek-V3 là mô hình MoE với 671 tỷ tham số, sử dụng MLA và DeepSeekMoE với cân bằng tải không tổn thất để huấn luyện và suy luận hiệu quả. Được huấn luyện trước trên 14.8T token chất lượng cao với SFT và RL, mô hình vượt trội so với các mô hình mã nguồn mở khác và tiệm cận các mô hình đóng hàng đầu.",
  "deepseek-ai/deepseek-llm-67b-chat.description": "DeepSeek LLM Chat (67B) là một mô hình sáng tạo cung cấp khả năng hiểu và tương tác ngôn ngữ sâu sắc.",
  "deepseek-ai/deepseek-v3.1-terminus.description": "DeepSeek V3.1 là mô hình suy luận thế hệ mới với khả năng suy luận phức tạp mạnh mẽ và chuỗi suy nghĩ cho các tác vụ phân tích chuyên sâu.",
  "deepseek-ai/deepseek-v3.1.description": "DeepSeek V3.1 là mô hình suy luận thế hệ mới với khả năng suy luận phức tạp mạnh mẽ và chuỗi suy nghĩ cho các tác vụ phân tích chuyên sâu.",
  "deepseek-ai/deepseek-vl2.description": "DeepSeek-VL2 là mô hình thị giác-ngôn ngữ MoE dựa trên DeepSeekMoE-27B với kích hoạt thưa, đạt hiệu suất cao với chỉ 4.5B tham số hoạt động. Mô hình vượt trội trong QA thị giác, OCR, hiểu tài liệu/bảng/biểu đồ và định vị hình ảnh.",
  "deepseek-chat.description": "Một mô hình mã nguồn mở mới kết hợp khả năng tổng quát và lập trình. Nó giữ lại khả năng đối thoại chung của mô hình trò chuyện và khả năng lập trình mạnh mẽ của mô hình lập trình viên, với sự điều chỉnh sở thích tốt hơn. DeepSeek-V2.5 cũng cải thiện khả năng viết và tuân thủ hướng dẫn.",
  "deepseek-coder-33B-instruct.description": "DeepSeek Coder 33B là mô hình ngôn ngữ lập trình được huấn luyện trên 2 nghìn tỷ token (87% mã nguồn, 13% văn bản tiếng Trung/Anh). Mô hình này hỗ trợ cửa sổ ngữ cảnh 16K và nhiệm vụ điền vào giữa đoạn mã, cung cấp khả năng hoàn thành mã ở cấp độ dự án và chèn đoạn mã chính xác.",
  "deepseek-coder-v2.description": "DeepSeek Coder V2 là mô hình mã nguồn MoE mã nguồn mở với hiệu suất mạnh mẽ trong các tác vụ lập trình, có thể so sánh với GPT-4 Turbo.",
  "deepseek-coder-v2:236b.description": "DeepSeek Coder V2 là mô hình mã nguồn MoE mã nguồn mở với hiệu suất mạnh mẽ trong các tác vụ lập trình, có thể so sánh với GPT-4 Turbo.",
  "deepseek-ocr.description": "DeepSeek-OCR là mô hình thị giác-ngôn ngữ từ DeepSeek AI tập trung vào nhận dạng ký tự quang học (OCR) và \"nén quang học theo ngữ cảnh\". Mô hình này khám phá cách nén thông tin ngữ cảnh từ hình ảnh, xử lý tài liệu hiệu quả và chuyển đổi chúng thành định dạng văn bản có cấu trúc như Markdown. Nó nhận diện văn bản trong hình ảnh một cách chính xác, lý tưởng cho số hóa tài liệu, trích xuất văn bản và xử lý có cấu trúc.",
  "deepseek-r1-0528.description": "Mô hình đầy đủ 685B được phát hành vào ngày 28-05-2025. DeepSeek-R1 sử dụng học tăng cường quy mô lớn trong giai đoạn hậu huấn luyện, cải thiện đáng kể khả năng suy luận với dữ liệu gán nhãn tối thiểu, và thể hiện hiệu suất vượt trội trong toán học, lập trình và suy luận ngôn ngữ tự nhiên.",
  "deepseek-r1-250528.description": "DeepSeek R1 250528 là mô hình suy luận đầy đủ của DeepSeek-R1 dành cho các tác vụ toán học và logic phức tạp.",
  "deepseek-r1-70b-fast-online.description": "DeepSeek R1 70B phiên bản nhanh với tìm kiếm web thời gian thực, mang lại phản hồi nhanh hơn mà vẫn duy trì hiệu suất.",
  "deepseek-r1-70b-online.description": "DeepSeek R1 70B phiên bản tiêu chuẩn với tìm kiếm web thời gian thực, phù hợp cho trò chuyện và xử lý văn bản cập nhật.",
  "deepseek-r1-distill-llama-70b.description": "DeepSeek R1 Distill Llama 70B kết hợp khả năng suy luận của R1 với hệ sinh thái Llama.",
  "deepseek-r1-distill-llama-8b.description": "DeepSeek-R1-Distill-Llama-8B được chưng cất từ Llama-3.1-8B sử dụng đầu ra từ DeepSeek R1.",
  "deepseek-r1-distill-llama.description": "deepseek-r1-distill-llama được chưng cất từ DeepSeek-R1 trên nền tảng Llama.",
  "deepseek-r1-distill-qianfan-70b.description": "DeepSeek R1 Distill Qianfan 70B là phiên bản chưng cất R1 dựa trên Qianfan-70B với giá trị vượt trội.",
  "deepseek-r1-distill-qianfan-8b.description": "DeepSeek R1 Distill Qianfan 8B là phiên bản chưng cất R1 dựa trên Qianfan-8B, phù hợp cho các ứng dụng quy mô nhỏ và trung bình.",
  "deepseek-r1-distill-qianfan-llama-70b.description": "DeepSeek R1 Distill Qianfan Llama 70B là phiên bản chưng cất R1 dựa trên Llama-70B.",
  "deepseek-r1-distill-qwen-1.5b.description": "DeepSeek R1 Distill Qwen 1.5B là mô hình chưng cất siêu nhẹ dành cho môi trường tài nguyên rất hạn chế.",
  "deepseek-r1-distill-qwen-14b.description": "DeepSeek R1 Distill Qwen 14B là mô hình chưng cất cỡ trung cho triển khai đa kịch bản.",
  "deepseek-r1-distill-qwen-32b.description": "DeepSeek R1 Distill Qwen 32B là phiên bản chưng cất R1 dựa trên Qwen-32B, cân bằng giữa hiệu suất và chi phí.",
  "deepseek-r1-distill-qwen-7b.description": "DeepSeek R1 Distill Qwen 7B là mô hình chưng cất nhẹ dành cho môi trường biên và doanh nghiệp riêng tư.",
  "deepseek-r1-distill-qwen.description": "deepseek-r1-distill-qwen được chưng cất từ DeepSeek-R1 trên nền tảng Qwen.",
  "deepseek-r1-fast-online.description": "Phiên bản đầy đủ DeepSeek R1 nhanh với tìm kiếm web thời gian thực, kết hợp khả năng 671B và phản hồi nhanh hơn.",
  "deepseek-r1-online.description": "Phiên bản đầy đủ DeepSeek R1 với 671B tham số và tìm kiếm web thời gian thực, mang lại khả năng hiểu và tạo nội dung mạnh mẽ hơn.",
  "deepseek-r1.description": "DeepSeek-R1 sử dụng dữ liệu khởi động lạnh trước khi áp dụng học tăng cường và đạt hiệu suất tương đương OpenAI-o1 trong các tác vụ toán học, lập trình và suy luận.",
  "deepseek-reasoner.description": "Chế độ tư duy DeepSeek V3.2 tạo ra chuỗi suy nghĩ trước khi đưa ra câu trả lời cuối cùng để nâng cao độ chính xác.",
  "deepseek-v2.description": "DeepSeek V2 là mô hình MoE hiệu quả cho xử lý tiết kiệm chi phí.",
  "deepseek-v2:236b.description": "DeepSeek V2 236B là mô hình tập trung vào mã nguồn của DeepSeek với khả năng tạo mã mạnh mẽ.",
  "deepseek-v3-0324.description": "DeepSeek-V3-0324 là mô hình MoE với 671B tham số, nổi bật về lập trình, khả năng kỹ thuật, hiểu ngữ cảnh và xử lý văn bản dài.",
  "deepseek-v3.1-terminus.description": "DeepSeek-V3.1-Terminus là mô hình LLM tối ưu hóa cho thiết bị đầu cuối từ DeepSeek.",
  "deepseek-v3.1-think-250821.description": "DeepSeek V3.1 Think 250821 là mô hình suy nghĩ sâu tương ứng với phiên bản Terminus, được xây dựng cho suy luận hiệu suất cao.",
  "deepseek-v3.1.description": "DeepSeek-V3.1 là mô hình suy luận lai mới từ DeepSeek, hỗ trợ cả chế độ suy nghĩ và không suy nghĩ, mang lại hiệu quả suy luận cao hơn so với DeepSeek-R1-0528. Tối ưu hóa sau huấn luyện giúp cải thiện đáng kể việc sử dụng công cụ và hiệu suất tác vụ của tác nhân. Hỗ trợ cửa sổ ngữ cảnh 128k và đầu ra lên đến 64k token.",
  "deepseek-v3.1:671b.description": "DeepSeek V3.1 là mô hình suy luận thế hệ tiếp theo với khả năng suy luận phức tạp và chuỗi suy nghĩ được cải thiện, phù hợp cho các tác vụ yêu cầu phân tích sâu.",
  "deepseek-v3.2-exp.description": "deepseek-v3.2-exp giới thiệu cơ chế chú ý thưa để cải thiện hiệu quả huấn luyện và suy luận trên văn bản dài, với chi phí thấp hơn deepseek-v3.1.",
  "deepseek-v3.2-think.description": "DeepSeek V3.2 Think là mô hình suy nghĩ sâu đầy đủ với khả năng suy luận chuỗi dài mạnh mẽ hơn.",
  "deepseek-v3.2.description": "DeepSeek-V3.2 là mô hình suy luận lai đầu tiên từ DeepSeek tích hợp tư duy vào việc sử dụng công cụ. Mô hình sử dụng kiến trúc hiệu quả để tiết kiệm tính toán, học tăng cường quy mô lớn để nâng cao năng lực, và dữ liệu tác vụ tổng hợp quy mô lớn để tăng khả năng tổng quát. Sự kết hợp này đạt hiệu suất tương đương GPT-5-High, với độ dài đầu ra giảm đáng kể, từ đó giảm chi phí tính toán và thời gian chờ của người dùng.",
  "deepseek-v3.description": "DeepSeek-V3 là mô hình MoE mạnh mẽ với tổng số tham số 671B và 37B hoạt động trên mỗi token.",
  "deepseek-vl2-small.description": "DeepSeek VL2 Small là phiên bản đa phương thức nhẹ, phù hợp cho môi trường hạn chế tài nguyên và yêu cầu đồng thời cao.",
  "deepseek-vl2.description": "DeepSeek VL2 là mô hình đa phương thức cho hiểu hình ảnh-văn bản và hỏi đáp thị giác chi tiết.",
  "deepseek/deepseek-chat-v3-0324.description": "DeepSeek V3 là mô hình MoE với 685 tỷ tham số và là phiên bản mới nhất trong dòng mô hình trò chuyện hàng đầu của DeepSeek.\n\nMô hình kế thừa từ [DeepSeek V3](/deepseek/deepseek-chat-v3) và thể hiện hiệu suất mạnh mẽ trên nhiều tác vụ.",
  "deepseek/deepseek-chat-v3-0324:free.description": "DeepSeek V3 là mô hình MoE với 685 tỷ tham số và là phiên bản mới nhất trong dòng mô hình trò chuyện hàng đầu của DeepSeek.\n\nMô hình kế thừa từ [DeepSeek V3](/deepseek/deepseek-chat-v3) và thể hiện hiệu suất mạnh mẽ trên nhiều tác vụ.",
  "deepseek/deepseek-chat-v3.1.description": "DeepSeek-V3.1 là mô hình suy luận lai với ngữ cảnh dài của DeepSeek, hỗ trợ chế độ tư duy và không tư duy, tích hợp công cụ.",
  "deepseek/deepseek-chat.description": "DeepSeek-V3 là mô hình suy luận lai hiệu suất cao của DeepSeek dành cho các tác vụ phức tạp và tích hợp công cụ.",
  "deepseek/deepseek-math-v2.description": "DeepSeek Math V2 là mô hình đạt đột phá lớn trong khả năng suy luận toán học. Đổi mới cốt lõi nằm ở cơ chế huấn luyện \"tự xác minh\", giúp mô hình đạt cấp huy chương vàng trong nhiều cuộc thi toán học hàng đầu.",
  "deepseek/deepseek-r1-0528.description": "DeepSeek R1 0528 là phiên bản cập nhật tập trung vào khả năng truy cập mở và suy luận sâu hơn.",
  "deepseek/deepseek-r1-0528:free.description": "DeepSeek-R1 cải thiện đáng kể khả năng suy luận với dữ liệu gán nhãn tối thiểu và tạo chuỗi tư duy trước khi đưa ra câu trả lời cuối cùng để nâng cao độ chính xác.",
  "deepseek/deepseek-r1-distill-llama-70b.description": "DeepSeek R1 Distill Llama 70B là mô hình LLM chưng cất dựa trên Llama 3.3 70B, được tinh chỉnh bằng đầu ra từ DeepSeek R1 để đạt hiệu suất cạnh tranh với các mô hình tiên phong quy mô lớn.",
  "deepseek/deepseek-r1-distill-llama-8b.description": "DeepSeek R1 Distill Llama 8B là mô hình LLM chưng cất dựa trên Llama-3.1-8B-Instruct, được huấn luyện bằng đầu ra từ DeepSeek R1.",
  "deepseek/deepseek-r1-distill-qwen-14b.description": "DeepSeek R1 Distill Qwen 14B là mô hình LLM chưng cất dựa trên Qwen 2.5 14B, được huấn luyện bằng đầu ra từ DeepSeek R1. Mô hình vượt qua OpenAI o1-mini trên nhiều tiêu chuẩn, đạt kết quả hàng đầu trong các mô hình đặc.",
  "deepseek/deepseek-r1-distill-qwen-32b.description": "DeepSeek R1 Distill Qwen 32B là mô hình LLM chưng cất dựa trên Qwen 2.5 32B, được huấn luyện bằng đầu ra từ DeepSeek R1. Mô hình vượt qua OpenAI o1-mini trên nhiều tiêu chuẩn, đạt kết quả hàng đầu trong các mô hình đặc.",
  "deepseek/deepseek-r1.description": "DeepSeek R1 đã được cập nhật thành DeepSeek-R1-0528. Với tài nguyên tính toán lớn hơn và tối ưu hóa thuật toán sau huấn luyện, mô hình cải thiện đáng kể độ sâu và khả năng suy luận. Mô hình thể hiện hiệu suất mạnh mẽ trên các tiêu chuẩn toán học, lập trình và logic tổng quát, tiệm cận các mô hình hàng đầu như o3 và Gemini 2.5 Pro.",
  "deepseek/deepseek-r1/community.description": "DeepSeek R1 là mô hình mã nguồn mở mới nhất do nhóm DeepSeek phát hành, có hiệu suất suy luận rất mạnh, đặc biệt trong các tác vụ toán học, lập trình và suy luận, tương đương với OpenAI o1.",
  "deepseek/deepseek-r1:free.description": "DeepSeek-R1 cải thiện đáng kể khả năng suy luận với dữ liệu gán nhãn tối thiểu và tạo chuỗi tư duy trước khi đưa ra câu trả lời cuối cùng để nâng cao độ chính xác.",
  "deepseek/deepseek-reasoner.description": "DeepSeek-V3 Thinking (reasoner) là mô hình suy luận thử nghiệm của DeepSeek, phù hợp với các tác vụ suy luận có độ phức tạp cao.",
  "deepseek/deepseek-v3.1-base.description": "DeepSeek V3.1 Base là phiên bản cải tiến của mô hình DeepSeek V3.",
  "deepseek/deepseek-v3.description": "Mô hình LLM đa năng tốc độ cao với khả năng suy luận nâng cao.",
  "deepseek/deepseek-v3/community.description": "DeepSeek-V3 mang lại đột phá lớn về tốc độ suy luận so với các mô hình trước. Mô hình xếp hạng đầu trong các mô hình mã nguồn mở và cạnh tranh với các mô hình đóng tiên tiến nhất. DeepSeek-V3 áp dụng kiến trúc Multi-Head Latent Attention (MLA) và DeepSeekMoE, cả hai đều đã được xác thực trong DeepSeek-V2. Mô hình cũng giới thiệu chiến lược phụ trợ không mất dữ liệu để cân bằng tải và mục tiêu huấn luyện dự đoán đa token để tăng cường hiệu suất.",
  "deepseek_r1.description": "DeepSeek-R1 là mô hình suy luận dựa trên học tăng cường, giải quyết các vấn đề lặp lại và khả năng đọc hiểu. Trước khi áp dụng học tăng cường, mô hình sử dụng dữ liệu khởi đầu lạnh để cải thiện thêm khả năng suy luận. Mô hình đạt hiệu suất tương đương OpenAI-o1 trong các tác vụ toán học, lập trình và suy luận, với quy trình huấn luyện được thiết kế cẩn thận để nâng cao kết quả tổng thể.",
  "deepseek_r1_distill_llama_70b.description": "DeepSeek-R1-Distill-Llama-70B được chưng cất từ Llama-3.3-70B-Instruct. Là một phần của dòng DeepSeek-R1, mô hình được tinh chỉnh trên các mẫu do DeepSeek-R1 tạo ra và thể hiện hiệu suất mạnh mẽ trong toán học, lập trình và suy luận.",
  "deepseek_r1_distill_qwen_14b.description": "DeepSeek-R1-Distill-Qwen-14B được chưng cất từ Qwen2.5-14B và tinh chỉnh trên 800K mẫu được chọn lọc do DeepSeek-R1 tạo ra, mang lại khả năng suy luận mạnh mẽ.",
  "deepseek_r1_distill_qwen_32b.description": "DeepSeek-R1-Distill-Qwen-32B được chưng cất từ Qwen2.5-32B và tinh chỉnh trên 800K mẫu được chọn lọc do DeepSeek-R1 tạo ra, vượt trội trong toán học, lập trình và suy luận.",
  "devstral-2:123b.description": "Devstral 2 123B vượt trội trong việc sử dụng công cụ để khám phá mã nguồn, chỉnh sửa nhiều tệp và hỗ trợ các đại lý kỹ thuật phần mềm.",
  "doubao-1.5-lite-32k.description": "Doubao-1.5-lite là mô hình nhẹ mới với phản hồi siêu nhanh, mang lại chất lượng và độ trễ hàng đầu.",
  "doubao-1.5-pro-256k.description": "Doubao-1.5-pro-256k là bản nâng cấp toàn diện của Doubao-1.5-Pro, cải thiện hiệu suất tổng thể 10%. Mô hình hỗ trợ cửa sổ ngữ cảnh 256k và tối đa 12k token đầu ra, mang lại hiệu suất cao hơn, cửa sổ lớn hơn và giá trị mạnh mẽ cho nhiều trường hợp sử dụng.",
  "doubao-1.5-pro-32k.description": "Doubao-1.5-pro là mô hình hàng đầu thế hệ mới với nâng cấp toàn diện, vượt trội về kiến thức, lập trình và suy luận.",
  "doubao-1.5-thinking-pro-m.description": "Doubao-1.5 là mô hình suy luận sâu mới (phiên bản m hỗ trợ suy luận sâu đa phương thức gốc), nổi bật trong toán học, lập trình, suy luận khoa học và các tác vụ tổng quát như sáng tác sáng tạo. Mô hình đạt hoặc tiệm cận kết quả hàng đầu trên các chuẩn đánh giá như AIME 2024, Codeforces và GPQA. Hỗ trợ cửa sổ ngữ cảnh 128k và đầu ra lên đến 16k.",
  "doubao-1.5-thinking-pro.description": "Doubao-1.5 là mô hình suy luận sâu mới, nổi bật trong toán học, lập trình, suy luận khoa học và các tác vụ tổng quát như sáng tác sáng tạo. Mô hình đạt hoặc tiệm cận kết quả hàng đầu trên các chuẩn đánh giá như AIME 2024, Codeforces và GPQA. Hỗ trợ cửa sổ ngữ cảnh 128k và đầu ra lên đến 16k.",
  "doubao-1.5-thinking-vision-pro.description": "Mô hình suy luận sâu thị giác mới với khả năng hiểu và suy luận đa phương thức mạnh mẽ hơn, đạt kết quả SOTA trên 37 trong số 59 chuẩn đánh giá công khai.",
  "doubao-1.5-ui-tars.description": "Doubao-1.5-UI-TARS là mô hình tác tử tập trung vào giao diện người dùng gốc, tương tác liền mạch với giao diện thông qua nhận thức, suy luận và hành động giống con người.",
  "doubao-1.5-vision-lite.description": "Doubao-1.5-vision-lite là mô hình đa phương thức nâng cấp hỗ trợ hình ảnh ở mọi độ phân giải và tỷ lệ khung hình cực đoan, nâng cao khả năng suy luận thị giác, nhận diện tài liệu, hiểu chi tiết và tuân thủ hướng dẫn. Hỗ trợ cửa sổ ngữ cảnh 128k và đầu ra lên đến 16k token.",
  "doubao-1.5-vision-pro-32k.description": "Doubao-1.5-vision-pro là mô hình đa phương thức nâng cấp hỗ trợ hình ảnh ở mọi độ phân giải và tỷ lệ khung hình cực đoan, nâng cao khả năng suy luận thị giác, nhận diện tài liệu, hiểu chi tiết và tuân thủ hướng dẫn.",
  "doubao-1.5-vision-pro.description": "Doubao-1.5-vision-pro là mô hình đa phương thức nâng cấp hỗ trợ hình ảnh ở mọi độ phân giải và tỷ lệ khung hình cực đoan, nâng cao khả năng suy luận thị giác, nhận diện tài liệu, hiểu chi tiết và tuân thủ hướng dẫn.",
  "doubao-lite-128k.description": "Phản hồi siêu nhanh với giá trị vượt trội, cung cấp lựa chọn linh hoạt hơn cho nhiều tình huống. Hỗ trợ suy luận và tinh chỉnh với cửa sổ ngữ cảnh 128k.",
  "doubao-lite-32k.description": "Phản hồi siêu nhanh với giá trị vượt trội, cung cấp lựa chọn linh hoạt hơn cho nhiều tình huống. Hỗ trợ suy luận và tinh chỉnh với cửa sổ ngữ cảnh 32k.",
  "doubao-lite-4k.description": "Phản hồi siêu nhanh với giá trị vượt trội, cung cấp lựa chọn linh hoạt hơn cho nhiều tình huống. Hỗ trợ suy luận và tinh chỉnh với cửa sổ ngữ cảnh 4k.",
  "doubao-pro-256k.description": "Mô hình hàng đầu có hiệu suất tốt nhất cho các tác vụ phức tạp, đạt kết quả mạnh mẽ trong hỏi đáp tham chiếu, tóm tắt, sáng tạo, phân loại văn bản và nhập vai. Hỗ trợ suy luận và tinh chỉnh với cửa sổ ngữ cảnh 256k.",
  "doubao-pro-32k.description": "Mô hình hàng đầu có hiệu suất tốt nhất cho các tác vụ phức tạp, đạt kết quả mạnh mẽ trong hỏi đáp tham chiếu, tóm tắt, sáng tạo, phân loại văn bản và nhập vai. Hỗ trợ suy luận và tinh chỉnh với cửa sổ ngữ cảnh 32k.",
  "doubao-seed-1.6-flash.description": "Doubao-Seed-1.6-flash là mô hình suy luận sâu đa phương thức siêu nhanh với TPOT chỉ 10ms. Hỗ trợ cả văn bản và hình ảnh, vượt trội mô hình lite trước đó về hiểu văn bản và ngang tầm các mô hình pro cạnh tranh về thị giác. Hỗ trợ cửa sổ ngữ cảnh 256k và đầu ra lên đến 16k token.",
  "doubao-seed-1.6-lite.description": "Doubao-Seed-1.6-lite là mô hình suy luận sâu đa phương thức mới với mức độ suy luận có thể điều chỉnh (Tối thiểu, Thấp, Trung bình, Cao), mang lại giá trị tốt hơn và là lựa chọn mạnh mẽ cho các tác vụ phổ biến, hỗ trợ cửa sổ ngữ cảnh lên đến 256k.",
  "doubao-seed-1.6-thinking.description": "Doubao-Seed-1.6-thinking tăng cường đáng kể khả năng suy luận, cải thiện hơn nữa năng lực cốt lõi trong lập trình, toán học và suy luận logic so với Doubao-1.5-thinking-pro, đồng thời bổ sung khả năng hiểu thị giác. Hỗ trợ cửa sổ ngữ cảnh 256k và đầu ra lên đến 16k token.",
  "doubao-seed-1.6-vision.description": "Doubao-Seed-1.6-vision là mô hình suy luận sâu thị giác cung cấp khả năng hiểu và suy luận đa phương thức mạnh mẽ hơn cho giáo dục, đánh giá hình ảnh, kiểm tra/an ninh và hỏi đáp AI. Hỗ trợ cửa sổ ngữ cảnh 256k và đầu ra lên đến 64k token.",
  "doubao-seed-1.6.description": "Doubao-Seed-1.6 là mô hình suy luận sâu đa phương thức mới với các chế độ tự động, suy luận và không suy luận. Ở chế độ không suy luận, mô hình vượt trội đáng kể so với Doubao-1.5-pro/250115. Hỗ trợ cửa sổ ngữ cảnh 256k và đầu ra lên đến 16k token.",
  "doubao-seed-1.8.description": "Doubao-Seed-1.8 có khả năng hiểu đa phương thức và tác tử mạnh mẽ hơn, hỗ trợ đầu vào văn bản/hình ảnh/video và lưu trữ ngữ cảnh, mang lại hiệu suất xuất sắc trong các tác vụ phức tạp.",
  "doubao-seed-code.description": "Doubao-Seed-Code được tối ưu hóa sâu cho lập trình tác tử, hỗ trợ đầu vào đa phương thức (văn bản/hình ảnh/video) và cửa sổ ngữ cảnh 256k, tương thích với API Anthropic, phù hợp với lập trình, hiểu thị giác và quy trình tác tử.",
  "doubao-seededit-3-0-i2i-250628.description": "Mô hình hình ảnh Doubao từ ByteDance Seed hỗ trợ đầu vào văn bản và hình ảnh với khả năng tạo hình ảnh chất lượng cao, dễ kiểm soát. Hỗ trợ chỉnh sửa hình ảnh theo văn bản, với kích thước đầu ra từ 512 đến 1536 theo cạnh dài.",
  "doubao-seedream-3-0-t2i-250415.description": "Seedream 3.0 là mô hình tạo hình ảnh từ ByteDance Seed, hỗ trợ đầu vào văn bản và hình ảnh với khả năng tạo hình ảnh chất lượng cao, dễ kiểm soát. Mô hình tạo hình ảnh từ văn bản gợi ý.",
  "doubao-seedream-4-0-250828.description": "Seedream 4.0 là mô hình tạo hình ảnh từ ByteDance Seed, hỗ trợ đầu vào văn bản và hình ảnh với khả năng tạo hình ảnh chất lượng cao, dễ kiểm soát. Mô hình tạo hình ảnh từ văn bản gợi ý.",
  "doubao-vision-lite-32k.description": "Doubao-vision là mô hình đa phương thức từ Doubao với khả năng hiểu và suy luận hình ảnh mạnh mẽ cùng khả năng tuân thủ hướng dẫn chính xác. Mô hình hoạt động tốt trong các tác vụ trích xuất văn bản từ hình ảnh và suy luận dựa trên hình ảnh, cho phép mở rộng các tình huống hỏi đáp thị giác phức tạp hơn.",
  "doubao-vision-pro-32k.description": "Doubao-vision là mô hình đa phương thức từ Doubao với khả năng hiểu và suy luận hình ảnh mạnh mẽ cùng khả năng tuân thủ hướng dẫn chính xác. Mô hình hoạt động tốt trong các tác vụ trích xuất văn bản từ hình ảnh và suy luận dựa trên hình ảnh, cho phép mở rộng các tình huống hỏi đáp thị giác phức tạp hơn.",
  "emohaa.description": "Emohaa là mô hình hỗ trợ sức khỏe tinh thần với khả năng tư vấn chuyên nghiệp, giúp người dùng hiểu rõ các vấn đề cảm xúc.",
  "ernie-4.5-0.3b.description": "ERNIE 4.5 0.3B là mô hình nhẹ mã nguồn mở, phù hợp để triển khai cục bộ và tùy chỉnh.",
  "ernie-4.5-21b-a3b.description": "ERNIE 4.5 21B A3B là mô hình mã nguồn mở với số lượng tham số lớn, có khả năng hiểu và tạo nội dung mạnh mẽ hơn.",
  "ernie-4.5-300b-a47b.description": "ERNIE 4.5 300B A47B là mô hình MoE siêu lớn của Baidu ERNIE với khả năng lý luận xuất sắc.",
  "ernie-4.5-8k-preview.description": "ERNIE 4.5 8K Preview là mô hình xem trước với ngữ cảnh 8K để đánh giá ERNIE 4.5.",
  "ernie-4.5-turbo-128k-preview.description": "Bản xem trước ERNIE 4.5 Turbo 128K với khả năng tương đương bản phát hành chính thức, phù hợp để tích hợp và thử nghiệm canary.",
  "ernie-4.5-turbo-128k.description": "ERNIE 4.5 Turbo 128K là mô hình tổng quát hiệu suất cao với khả năng tăng cường tìm kiếm và gọi công cụ cho các tình huống hỏi đáp, lập trình và đại lý.",
  "ernie-4.5-turbo-32k.description": "ERNIE 4.5 Turbo 32K là phiên bản ngữ cảnh trung bình dành cho hỏi đáp, truy xuất cơ sở tri thức và đối thoại nhiều lượt.",
  "ernie-4.5-turbo-latest.description": "Phiên bản ERNIE 4.5 Turbo mới nhất với hiệu suất tổng thể được tối ưu hóa, lý tưởng để sử dụng làm mô hình sản xuất chính.",
  "ernie-4.5-turbo-vl-32k-preview.description": "ERNIE 4.5 Turbo VL 32K Preview là bản xem trước đa phương thức 32K để đánh giá khả năng thị giác ngữ cảnh dài.",
  "ernie-4.5-turbo-vl-32k.description": "ERNIE 4.5 Turbo VL 32K là phiên bản đa phương thức trung-dài cho việc hiểu tài liệu dài và hình ảnh kết hợp.",
  "ernie-4.5-turbo-vl-latest.description": "ERNIE 4.5 Turbo VL Latest là phiên bản đa phương thức mới nhất với khả năng hiểu và lý luận hình ảnh-văn bản được cải thiện.",
  "ernie-4.5-turbo-vl-preview.description": "ERNIE 4.5 Turbo VL Preview là mô hình xem trước đa phương thức để hiểu và tạo nội dung hình ảnh-văn bản, phù hợp cho hỏi đáp trực quan và hiểu nội dung.",
  "ernie-4.5-turbo-vl.description": "ERNIE 4.5 Turbo VL là mô hình đa phương thức trưởng thành để hiểu và nhận diện hình ảnh-văn bản trong sản xuất.",
  "ernie-4.5-vl-28b-a3b.description": "ERNIE 4.5 VL 28B A3B là mô hình đa phương thức mã nguồn mở để hiểu và lý luận hình ảnh-văn bản.",
  "ernie-5.0-thinking-latest.description": "Wenxin 5.0 Thinking là mô hình chủ lực toàn phương thức bản địa với khả năng mô hình hóa văn bản, hình ảnh, âm thanh và video thống nhất. Nó mang lại nâng cấp toàn diện cho các tình huống hỏi đáp phức tạp, sáng tạo và đại lý.",
  "ernie-5.0-thinking-preview.description": "Wenxin 5.0 Thinking Preview là mô hình chủ lực toàn phương thức bản địa với khả năng mô hình hóa văn bản, hình ảnh, âm thanh và video thống nhất. Nó mang lại nâng cấp toàn diện cho các tình huống hỏi đáp phức tạp, sáng tạo và đại lý.",
  "ernie-char-8k.description": "ERNIE Character 8K là mô hình đối thoại nhân vật để xây dựng nhân vật IP và trò chuyện đồng hành lâu dài.",
  "ernie-char-fiction-8k-preview.description": "ERNIE Character Fiction 8K Preview là bản xem trước mô hình tạo nhân vật và cốt truyện để đánh giá và thử nghiệm tính năng.",
  "ernie-char-fiction-8k.description": "ERNIE Character Fiction 8K là mô hình nhân vật dành cho tiểu thuyết và sáng tạo cốt truyện, phù hợp để tạo truyện dài.",
  "ernie-irag-edit.description": "ERNIE iRAG Edit là mô hình chỉnh sửa hình ảnh hỗ trợ xóa, vẽ lại và tạo biến thể.",
  "ernie-lite-pro-128k.description": "ERNIE Lite Pro 128K là mô hình nhẹ hiệu suất cao dành cho các tình huống nhạy cảm về độ trễ và chi phí.",
  "ernie-novel-8k.description": "ERNIE Novel 8K được xây dựng để tạo tiểu thuyết dài và cốt truyện IP với nhiều nhân vật.",
  "ernie-speed-pro-128k.description": "ERNIE Speed Pro 128K là mô hình giá trị cao, hỗ trợ đồng thời cao dành cho dịch vụ trực tuyến quy mô lớn và ứng dụng doanh nghiệp.",
  "ernie-x1-turbo-32k.description": "ERNIE X1 Turbo 32K là mô hình tư duy nhanh với ngữ cảnh 32K dành cho lý luận phức tạp và trò chuyện nhiều lượt.",
  "ernie-x1.1-preview.description": "ERNIE X1.1 Preview là bản xem trước mô hình tư duy để đánh giá và thử nghiệm.",
  "fal-ai/flux-kontext/dev.description": "Mô hình FLUX.1 tập trung vào chỉnh sửa hình ảnh, hỗ trợ đầu vào văn bản và hình ảnh.",
  "fal-ai/flux-pro/kontext.description": "FLUX.1 Kontext [pro] chấp nhận đầu vào là văn bản và hình ảnh tham chiếu, cho phép chỉnh sửa cục bộ chính xác và biến đổi toàn cảnh phức tạp.",
  "fal-ai/flux/krea.description": "Flux Krea [dev] là mô hình tạo hình ảnh với thiên hướng thẩm mỹ hướng đến hình ảnh chân thực và tự nhiên hơn.",
  "fal-ai/flux/schnell.description": "FLUX.1 [schnell] là mô hình tạo hình ảnh với 12 tỷ tham số, được thiết kế để tạo ra hình ảnh chất lượng cao một cách nhanh chóng.",
  "fal-ai/hunyuan-image/v3.description": "Mô hình tạo hình ảnh đa phương thức mạnh mẽ bản địa.",
  "fal-ai/imagen4/preview.description": "Mô hình tạo hình ảnh chất lượng cao từ Google.",
  "fal-ai/nano-banana.description": "Nano Banana là mô hình đa phương thức bản địa mới nhất, nhanh nhất và hiệu quả nhất của Google, cho phép tạo và chỉnh sửa hình ảnh thông qua hội thoại.",
  "flux-1-schnell.description": "Mô hình chuyển văn bản thành hình ảnh với 12 tỷ tham số từ Black Forest Labs, sử dụng phương pháp khuếch tán đối kháng tiềm ẩn để tạo hình ảnh chất lượng cao chỉ trong 1–4 bước. Mô hình cạnh tranh với các lựa chọn đóng và được phát hành theo giấy phép Apache-2.0 cho mục đích cá nhân, nghiên cứu và thương mại.",
  "flux-dev.description": "FLUX.1 [dev] là mô hình chưng cất mã nguồn mở dành cho mục đích phi thương mại. Mô hình giữ chất lượng hình ảnh gần như chuyên nghiệp và khả năng tuân thủ hướng dẫn, đồng thời hoạt động hiệu quả hơn, sử dụng tài nguyên tốt hơn so với các mô hình tiêu chuẩn cùng kích thước.",
  "flux-kontext-max.description": "Tạo và chỉnh sửa hình ảnh theo ngữ cảnh tiên tiến, kết hợp văn bản và hình ảnh để tạo ra kết quả chính xác và mạch lạc.",
  "flux-kontext-pro.description": "Tạo và chỉnh sửa hình ảnh theo ngữ cảnh tiên tiến, kết hợp văn bản và hình ảnh để tạo ra kết quả chính xác và mạch lạc.",
  "flux-merged.description": "FLUX.1-merged kết hợp các đặc điểm sâu sắc từ phiên bản \"DEV\" với lợi thế tốc độ cao của \"Schnell\", mở rộng giới hạn hiệu suất và mở rộng phạm vi ứng dụng.",
  "flux-pro-1.1-ultra.description": "Tạo hình ảnh độ phân giải siêu cao với đầu ra 4MP, tạo hình ảnh sắc nét chỉ trong 10 giây.",
  "flux-pro-1.1.description": "Mô hình tạo hình ảnh chuyên nghiệp nâng cấp với chất lượng hình ảnh xuất sắc và khả năng tuân thủ lời nhắc chính xác.",
  "flux-pro.description": "Mô hình tạo hình ảnh thương mại hàng đầu với chất lượng hình ảnh vượt trội và đầu ra đa dạng.",
  "flux-schnell.description": "FLUX.1 [schnell] là mô hình mã nguồn mở tiên tiến nhất với số bước ít, vượt qua các đối thủ tương tự và thậm chí cả các mô hình không chưng cất mạnh như Midjourney v6.0 và DALL-E 3 (HD). Mô hình được tinh chỉnh để giữ sự đa dạng từ giai đoạn tiền huấn luyện, cải thiện đáng kể chất lượng hình ảnh, tuân thủ hướng dẫn, thay đổi kích thước/tỷ lệ, xử lý phông chữ và đa dạng đầu ra.",
  "flux.1-schnell.description": "FLUX.1-schnell là mô hình tạo hình ảnh hiệu suất cao cho đầu ra nhanh với nhiều phong cách.",
  "gemini-1.0-pro-001.description": "Gemini 1.0 Pro 001 (Tuning) cung cấp hiệu suất ổn định và có thể điều chỉnh cho các tác vụ phức tạp.",
  "gemini-1.0-pro-002.description": "Gemini 1.0 Pro 002 (Tuning) hỗ trợ đa phương thức mạnh mẽ cho các tác vụ phức tạp.",
  "gemini-1.0-pro-latest.description": "Gemini 1.0 Pro là mô hình AI hiệu suất cao của Google, được thiết kế để mở rộng quy mô cho nhiều tác vụ.",
  "gemini-1.5-flash-001.description": "Gemini 1.5 Flash 001 là mô hình đa phương thức hiệu quả cho việc mở rộng ứng dụng rộng rãi.",
  "gemini-1.5-flash-002.description": "Gemini 1.5 Flash 002 là mô hình đa phương thức hiệu quả được xây dựng để triển khai quy mô lớn.",
  "gemini-1.5-flash-8b-exp-0924.description": "Gemini 1.5 Flash 8B 0924 là mô hình thử nghiệm mới nhất với cải tiến đáng kể trong các trường hợp sử dụng văn bản và đa phương thức.",
  "gemini-1.5-flash-8b-latest.description": "Gemini 1.5 Flash 8B là mô hình đa phương thức hiệu quả được xây dựng để triển khai quy mô lớn.",
  "gemini-1.5-flash-8b.description": "Gemini 1.5 Flash 8B là mô hình đa phương thức hiệu quả cho việc mở rộng ứng dụng rộng rãi.",
  "gemini-1.5-flash-exp-0827.description": "Gemini 1.5 Flash 0827 cung cấp xử lý đa phương thức tối ưu cho các tác vụ phức tạp.",
  "gemini-1.5-flash-latest.description": "Gemini 1.5 Flash là mô hình AI đa phương thức mới nhất của Google với khả năng xử lý nhanh, hỗ trợ đầu vào văn bản, hình ảnh và video để mở rộng hiệu quả trên nhiều tác vụ.",
  "gemini-1.5-pro-001.description": "Gemini 1.5 Pro 001 là giải pháp AI đa phương thức có thể mở rộng cho các tác vụ phức tạp.",
  "gemini-1.5-pro-002.description": "Gemini 1.5 Pro 002 là mô hình sẵn sàng sản xuất mới nhất với đầu ra chất lượng cao hơn, đặc biệt trong toán học, ngữ cảnh dài và thị giác.",
  "gemini-1.5-pro-exp-0801.description": "Gemini 1.5 Pro 0801 cung cấp xử lý đa phương thức mạnh mẽ với tính linh hoạt cao hơn cho phát triển ứng dụng.",
  "gemini-1.5-pro-exp-0827.description": "Gemini 1.5 Pro 0827 áp dụng các tối ưu hóa mới nhất để xử lý đa phương thức hiệu quả hơn.",
  "gemini-1.5-pro-latest.description": "Gemini 1.5 Pro hỗ trợ lên đến 2 triệu token, là mô hình đa phương thức tầm trung lý tưởng cho các tác vụ phức tạp.",
  "gemini-2.0-flash-001.description": "Gemini 2.0 Flash mang đến các tính năng thế hệ mới bao gồm tốc độ vượt trội, sử dụng công cụ gốc, tạo nội dung đa phương thức và cửa sổ ngữ cảnh 1 triệu token.",
  "gemini-2.0-flash-exp-image-generation.description": "Mô hình thử nghiệm Gemini 2.0 Flash với hỗ trợ tạo hình ảnh.",
  "gemini-2.0-flash-lite-001.description": "Biến thể Gemini 2.0 Flash được tối ưu hóa cho hiệu quả chi phí và độ trễ thấp.",
  "gemini-2.0-flash-lite.description": "Biến thể Gemini 2.0 Flash được tối ưu hóa cho hiệu quả chi phí và độ trễ thấp.",
  "gemini-2.0-flash.description": "Gemini 2.0 Flash mang đến các tính năng thế hệ mới bao gồm tốc độ vượt trội, sử dụng công cụ gốc, tạo nội dung đa phương thức và cửa sổ ngữ cảnh 1 triệu token.",
  "gemini-2.5-flash-image.description": "Nano Banana là mô hình đa phương thức gốc mới nhất, nhanh nhất và hiệu quả nhất của Google, cho phép tạo và chỉnh sửa hình ảnh thông qua hội thoại.",
  "gemini-2.5-flash-image:image.description": "Nano Banana là mô hình đa phương thức gốc mới nhất, nhanh nhất và hiệu quả nhất của Google, cho phép tạo và chỉnh sửa hình ảnh thông qua hội thoại.",
  "gemini-2.5-flash-lite-preview-06-17.description": "Gemini 2.5 Flash-Lite Preview là mô hình nhỏ nhất và có giá trị tốt nhất của Google, được thiết kế cho các trường hợp sử dụng quy mô lớn.",
  "gemini-2.5-flash-lite-preview-09-2025.description": "Phiên bản xem trước (25 tháng 9, 2025) của Gemini 2.5 Flash-Lite",
  "gemini-2.5-flash-lite.description": "Gemini 2.5 Flash-Lite là mô hình nhỏ nhất và có giá trị tốt nhất của Google, được thiết kế cho các trường hợp sử dụng quy mô lớn.",
  "gemini-2.5-flash-preview-04-17.description": "Gemini 2.5 Flash Preview là mô hình có giá trị tốt nhất của Google với đầy đủ tính năng.",
  "gemini-2.5-flash-preview-09-2025.description": "Phiên bản xem trước (25 tháng 9, 2025) của Gemini 2.5 Flash",
  "gemini-2.5-flash.description": "Gemini 2.5 Flash là mô hình có giá trị tốt nhất của Google với đầy đủ tính năng.",
  "gemini-2.5-pro-preview-03-25.description": "Gemini 2.5 Pro Preview là mô hình suy luận tiên tiến nhất của Google, có khả năng suy luận trên mã, toán học và các vấn đề STEM, cũng như phân tích tập dữ liệu lớn, mã nguồn và tài liệu với ngữ cảnh dài.",
  "gemini-2.5-pro-preview-05-06.description": "Gemini 2.5 Pro Preview là mô hình suy luận tiên tiến nhất của Google, có khả năng suy luận trên mã, toán học và các vấn đề STEM, cũng như phân tích tập dữ liệu lớn, mã nguồn và tài liệu với ngữ cảnh dài.",
  "gemini-2.5-pro-preview-06-05.description": "Gemini 2.5 Pro Preview là mô hình suy luận tiên tiến nhất của Google, có khả năng suy luận trên mã, toán học và các vấn đề STEM, cũng như phân tích tập dữ liệu lớn, mã nguồn và tài liệu với ngữ cảnh dài.",
  "gemini-2.5-pro.description": "Gemini 2.5 Pro là mô hình suy luận tiên tiến nhất của Google, có khả năng suy luận trên mã, toán học và các vấn đề STEM, cũng như phân tích tập dữ liệu lớn, mã nguồn và tài liệu với ngữ cảnh dài.",
  "gemini-3-flash-preview.description": "Gemini 3 Flash là mô hình thông minh nhất được xây dựng để tối ưu tốc độ, kết hợp trí tuệ tiên tiến với khả năng tìm kiếm chính xác.",
  "gemini-3-pro-image-preview.description": "Gemini 3 Pro Image（Nano Banana Pro）là mô hình tạo hình ảnh của Google, đồng thời hỗ trợ hội thoại đa phương thức.",
  "gemini-3-pro-preview.description": "Gemini 3 Pro là mô hình mạnh mẽ nhất của Google, kết hợp khả năng mã hóa cảm xúc và suy luận tiên tiến, mang đến hình ảnh phong phú và tương tác sâu sắc.",
  "gemini-flash-latest.description": "Phiên bản mới nhất của Gemini Flash",
  "gemini-flash-lite-latest.description": "Phiên bản mới nhất của Gemini Flash-Lite",
  "gemini-pro-latest.description": "Phiên bản mới nhất của Gemini Pro",
  "gemma-7b-it.description": "Gemma 7B là lựa chọn tiết kiệm chi phí cho các tác vụ quy mô nhỏ đến trung bình.",
  "gemma2-9b-it.description": "Gemma 2 9B được tối ưu hóa cho các tác vụ cụ thể và tích hợp công cụ.",
  "gemma2.description": "Gemma 2 là mô hình hiệu quả của Google, phục vụ từ ứng dụng nhỏ đến xử lý dữ liệu phức tạp.",
  "gemma2:27b.description": "Gemma 2 là mô hình hiệu quả của Google, phục vụ từ ứng dụng nhỏ đến xử lý dữ liệu phức tạp.",
  "gemma2:2b.description": "Gemma 2 là mô hình hiệu quả của Google, phục vụ từ ứng dụng nhỏ đến xử lý dữ liệu phức tạp.",
  "generalv3.5.description": "Spark Max là phiên bản đầy đủ tính năng nhất, hỗ trợ tìm kiếm web và nhiều plugin tích hợp. Các khả năng cốt lõi được tối ưu hóa hoàn toàn, vai trò hệ thống và gọi hàm mang lại hiệu suất vượt trội trong các tình huống ứng dụng phức tạp.",
  "generalv3.description": "Spark Pro là mô hình LLM hiệu suất cao được tối ưu cho các lĩnh vực chuyên môn, tập trung vào toán học, lập trình, y tế và giáo dục, với tìm kiếm web và các plugin tích hợp như thời tiết và ngày tháng. Nó mang lại hiệu suất mạnh mẽ và hiệu quả trong hỏi đáp kiến thức phức tạp, hiểu ngôn ngữ và sáng tạo văn bản nâng cao, là lựa chọn lý tưởng cho các trường hợp sử dụng chuyên nghiệp.",
  "glm-4-0520.description": "GLM-4-0520 là phiên bản mô hình mới nhất, được thiết kế cho các tác vụ phức tạp và đa dạng với hiệu suất vượt trội.",
  "glm-4-7.description": "GLM-4.7 là mô hình hàng đầu mới nhất từ Zhipu AI. GLM-4.7 nâng cao khả năng lập trình, lập kế hoạch tác vụ dài hạn và hợp tác công cụ cho các tình huống Lập trình Tác nhân, đạt hiệu suất hàng đầu trong số các mô hình mã nguồn mở trên nhiều bảng xếp hạng công khai. Khả năng tổng quát được cải thiện, phản hồi ngắn gọn và tự nhiên hơn, và trải nghiệm viết sâu sắc hơn. Trong các tác vụ tác nhân phức tạp, khả năng tuân thủ hướng dẫn khi gọi công cụ mạnh hơn, thẩm mỹ giao diện và hiệu quả hoàn thành tác vụ dài hạn cũng được nâng cao. • Khả năng lập trình mạnh hơn: Cải thiện đáng kể lập trình đa ngôn ngữ và hiệu suất tác nhân dòng lệnh; GLM-4.7 có thể triển khai cơ chế \"nghĩ trước, hành động sau\" trong các khung lập trình như Claude Code, Kilo Code, TRAE, Cline và Roo Code, với hiệu suất ổn định hơn trong các tác vụ phức tạp. • Cải thiện thẩm mỹ giao diện: GLM-4.7 thể hiện tiến bộ rõ rệt trong chất lượng tạo giao diện, có thể tạo trang web, bản trình chiếu và áp phích với tính thẩm mỹ cao hơn. • Khả năng gọi công cụ mạnh hơn: GLM-4.7 nâng cao khả năng gọi công cụ, đạt 67 điểm trong đánh giá tác vụ web BrowseComp; đạt 84.7 điểm trong đánh giá gọi công cụ tương tác τ²-Bench, vượt qua Claude Sonnet 4.5 và trở thành SOTA mã nguồn mở. • Cải thiện khả năng suy luận: Tăng cường đáng kể khả năng toán học và suy luận, đạt 42.8% trong tiêu chuẩn HLE (\"Kỳ thi cuối cùng của nhân loại\"), tăng 41% so với GLM-4.6, vượt qua GPT-5.1. • Tăng cường khả năng tổng quát: Đối thoại của GLM-4.7 ngắn gọn, thông minh và gần gũi hơn; viết và nhập vai có tính văn học và nhập vai hơn.",
  "glm-4-9b-chat.description": "GLM-4-9B-Chat thể hiện hiệu suất mạnh mẽ trong ngữ nghĩa, toán học, suy luận, mã hóa và kiến thức. Nó cũng hỗ trợ duyệt web, thực thi mã, gọi công cụ tùy chỉnh và suy luận văn bản dài, hỗ trợ 26 ngôn ngữ bao gồm tiếng Nhật, Hàn và Đức.",
  "glm-4-air-250414.description": "GLM-4-Air là lựa chọn có giá trị cao với hiệu suất gần GLM-4, tốc độ nhanh và chi phí thấp hơn.",
  "glm-4-air.description": "GLM-4-Air là lựa chọn có giá trị cao với hiệu suất gần GLM-4, tốc độ nhanh và chi phí thấp hơn.",
  "glm-4-airx.description": "GLM-4-AirX là biến thể hiệu quả hơn của GLM-4-Air với khả năng suy luận nhanh hơn đến 2.6 lần.",
  "glm-4-alltools.description": "GLM-4-AllTools là mô hình tác tử đa năng được tối ưu hóa cho lập kế hoạch hướng dẫn phức tạp và sử dụng công cụ như duyệt web, giải thích mã và tạo văn bản, phù hợp cho thực thi đa nhiệm.",
  "glm-4-flash-250414.description": "GLM-4-Flash lý tưởng cho các tác vụ đơn giản: nhanh nhất và miễn phí.",
  "glm-4-flash.description": "GLM-4-Flash lý tưởng cho các tác vụ đơn giản: nhanh nhất và miễn phí.",
  "glm-4-flashx.description": "GLM-4-FlashX là phiên bản Flash nâng cao với khả năng suy luận siêu nhanh.",
  "glm-4-long.description": "GLM-4-Long hỗ trợ đầu vào siêu dài cho các tác vụ kiểu ghi nhớ và xử lý tài liệu quy mô lớn.",
  "glm-4-plus.description": "GLM-4-Plus là mô hình cao cấp với trí tuệ vượt trội, xử lý tốt văn bản dài và tác vụ phức tạp, hiệu suất tổng thể được nâng cấp.",
  "glm-4.1v-thinking-flash.description": "GLM-4.1V-Thinking là mô hình VLM ~10B mạnh nhất hiện nay, bao phủ các tác vụ SOTA như hiểu video, hỏi đáp hình ảnh, giải đề, OCR, đọc tài liệu và biểu đồ, tác tử GUI, lập trình giao diện và liên kết ngữ nghĩa. Với học tăng cường tiên tiến, nó sử dụng suy luận chuỗi tư duy để cải thiện độ chính xác và độ phong phú, vượt trội hơn các mô hình không suy nghĩ truyền thống cả về kết quả và khả năng giải thích.",
  "glm-4.1v-thinking-flashx.description": "GLM-4.1V-Thinking là mô hình VLM ~10B mạnh nhất hiện nay, bao phủ các tác vụ SOTA như hiểu video, hỏi đáp hình ảnh, giải đề, OCR, đọc tài liệu và biểu đồ, tác tử GUI, lập trình giao diện và liên kết ngữ nghĩa. Với học tăng cường tiên tiến, nó sử dụng suy luận chuỗi tư duy để cải thiện độ chính xác và độ phong phú, vượt trội hơn các mô hình không suy nghĩ truyền thống cả về kết quả và khả năng giải thích.",
  "glm-4.5-air.description": "Phiên bản nhẹ của GLM-4.5 cân bằng giữa hiệu suất và chi phí, với chế độ suy nghĩ kết hợp linh hoạt.",
  "glm-4.5-airx.description": "Phiên bản nhanh của GLM-4.5-Air với phản hồi nhanh hơn cho các trường hợp sử dụng quy mô lớn, tốc độ cao.",
  "glm-4.5-x.description": "Phiên bản nhanh của GLM-4.5, mang lại hiệu suất mạnh mẽ với tốc độ tạo lên đến 100 token/giây.",
  "glm-4.5.description": "Mô hình hàng đầu của Zhipu với chế độ suy nghĩ có thể chuyển đổi, cung cấp SOTA mã nguồn mở tổng thể và hỗ trợ ngữ cảnh lên đến 128K.",
  "glm-4.5v.description": "Mô hình suy luận thị giác thế hệ tiếp theo của Zhipu với tổng 106B tham số, 12B hoạt động, đạt SOTA trong các mô hình đa phương thức mã nguồn mở cùng kích thước về hình ảnh, video, hiểu tài liệu và tác vụ GUI.",
  "glm-4.6.description": "GLM-4.6 là mô hình hàng đầu mới nhất của Zhipu (355B), vượt trội hoàn toàn so với các phiên bản trước về mã hóa nâng cao, xử lý văn bản dài, suy luận và khả năng tác tử. Đặc biệt phù hợp với Claude Sonnet 4 về khả năng lập trình, trở thành mô hình mã hóa hàng đầu tại Trung Quốc.",
  "glm-4.7-flash.description": "GLM-4.7-Flash là mô hình SOTA cấp 30B, mang đến lựa chọn mới cân bằng giữa hiệu suất và hiệu quả. Mô hình tăng cường khả năng lập trình, lập kế hoạch nhiệm vụ dài hạn và hợp tác công cụ cho các kịch bản Agentic Coding, đạt hiệu suất hàng đầu trong các bảng xếp hạng mã nguồn mở cùng kích thước. Khi thực hiện các nhiệm vụ tác nhân thông minh phức tạp, mô hình tuân thủ hướng dẫn tốt hơn khi gọi công cụ, đồng thời cải thiện thẩm mỹ giao diện và hiệu quả hoàn thành nhiệm vụ dài hạn cho Artifacts và Agentic Coding.",
  "glm-4.7-flashx.description": "GLM-4.7-Flash là mô hình SOTA cấp 30B, mang đến lựa chọn mới cân bằng giữa hiệu suất và hiệu quả. Mô hình tăng cường khả năng lập trình, lập kế hoạch nhiệm vụ dài hạn và hợp tác công cụ cho các kịch bản Agentic Coding, đạt hiệu suất hàng đầu trong các bảng xếp hạng mã nguồn mở cùng kích thước. Khi thực hiện các nhiệm vụ tác nhân thông minh phức tạp, mô hình tuân thủ hướng dẫn tốt hơn khi gọi công cụ, đồng thời cải thiện thẩm mỹ giao diện và hiệu quả hoàn thành nhiệm vụ dài hạn cho Artifacts và Agentic Coding.",
  "glm-4.7.description": "GLM-4.7 là mô hình chủ lực mới nhất của Zhipu, được nâng cấp cho các tình huống Lập trình Tác nhân (Agentic Coding) với khả năng lập trình vượt trội, lập kế hoạch nhiệm vụ dài hạn và phối hợp công cụ. Mô hình đạt hiệu suất hàng đầu trong số các mô hình mã nguồn mở trên nhiều bộ đánh giá công khai. Năng lực tổng quát được cải thiện với phản hồi ngắn gọn, tự nhiên hơn và khả năng viết lôi cuốn hơn. Đối với các tác vụ tác nhân phức tạp, khả năng tuân thủ hướng dẫn khi gọi công cụ được tăng cường, đồng thời giao diện người dùng và hiệu quả hoàn thành nhiệm vụ dài hạn trong Artifacts và Agentic Coding cũng được cải thiện.",
  "glm-4.description": "GLM-4 là mô hình chủ lực cũ được phát hành vào tháng 1 năm 2024, hiện đã được thay thế bởi GLM-4-0520 mạnh mẽ hơn.",
  "glm-4v-flash.description": "GLM-4V-Flash tập trung vào khả năng hiểu hình ảnh đơn hiệu quả cho các tình huống phân tích nhanh như xử lý hình ảnh theo thời gian thực hoặc theo lô.",
  "glm-4v-plus-0111.description": "GLM-4V-Plus có khả năng hiểu video và nhiều hình ảnh, phù hợp với các tác vụ đa phương thức.",
  "glm-4v-plus.description": "GLM-4V-Plus có khả năng hiểu video và nhiều hình ảnh, phù hợp với các tác vụ đa phương thức.",
  "glm-4v.description": "GLM-4V cung cấp khả năng hiểu và suy luận hình ảnh mạnh mẽ trong các tác vụ thị giác.",
  "glm-z1-air.description": "Mô hình suy luận với khả năng suy luận sâu cho các tác vụ yêu cầu phân tích phức tạp.",
  "glm-z1-airx.description": "Suy luận siêu nhanh với chất lượng suy luận cao.",
  "glm-z1-flash.description": "Dòng GLM-Z1 cung cấp khả năng suy luận phức tạp mạnh mẽ, vượt trội trong logic, toán học và lập trình.",
  "glm-z1-flashx.description": "Nhanh và tiết kiệm chi phí: Được tăng tốc với khả năng suy luận siêu nhanh và hỗ trợ đồng thời cao.",
  "glm-zero-preview.description": "GLM-Zero-Preview mang lại khả năng suy luận phức tạp mạnh mẽ, vượt trội trong logic, toán học và lập trình.",
  "global.anthropic.claude-opus-4-5-20251101-v1:0.description": "Claude Opus 4.5 là mô hình hàng đầu của Anthropic, kết hợp trí tuệ vượt trội và hiệu suất mở rộng cho các nhiệm vụ phức tạp đòi hỏi phản hồi và suy luận chất lượng cao nhất.",
  "google/gemini-2.0-flash-001.description": "Gemini 2.0 Flash mang đến các khả năng thế hệ mới, bao gồm tốc độ vượt trội, sử dụng công cụ tích hợp, tạo nội dung đa phương thức và cửa sổ ngữ cảnh lên đến 1 triệu token.",
  "google/gemini-2.0-flash-lite-001.description": "Gemini 2.0 Flash Lite là biến thể nhẹ của Gemini với chế độ suy nghĩ bị tắt mặc định để cải thiện độ trễ và chi phí, nhưng có thể bật thông qua tham số.",
  "google/gemini-2.0-flash-lite.description": "Gemini 2.0 Flash Lite cung cấp các tính năng thế hệ mới bao gồm tốc độ vượt trội, sử dụng công cụ tích hợp, tạo nội dung đa phương thức và cửa sổ ngữ cảnh lên đến 1 triệu token.",
  "google/gemini-2.0-flash.description": "Gemini 2.0 Flash là mô hình suy luận hiệu suất cao của Google dành cho các tác vụ đa phương thức mở rộng.",
  "google/gemini-2.5-flash-image-free.description": "Gemini 2.5 Flash Image phiên bản miễn phí với hạn ngạch tạo nội dung đa phương thức giới hạn.",
  "google/gemini-2.5-flash-image-preview.description": "Gemini 2.5 Flash là mô hình thử nghiệm hỗ trợ tạo hình ảnh.",
  "google/gemini-2.5-flash-image.description": "Gemini 2.5 Flash Image (Nano Banana) là mô hình tạo hình ảnh của Google với hỗ trợ hội thoại đa phương thức.",
  "google/gemini-2.5-flash-lite.description": "Gemini 2.5 Flash Lite là biến thể nhẹ của Gemini 2.5 được tối ưu hóa cho độ trễ và chi phí, phù hợp với các tình huống yêu cầu thông lượng cao.",
  "google/gemini-2.5-flash-preview.description": "Gemini 2.5 Flash là mô hình chủ lực tiên tiến nhất của Google, được xây dựng cho các tác vụ suy luận, lập trình, toán học và khoa học nâng cao. Mô hình tích hợp khả năng “suy nghĩ” để cung cấp phản hồi chính xác hơn với xử lý ngữ cảnh tinh tế hơn.\n\nLưu ý: Mô hình này có hai biến thể — có suy nghĩ và không suy nghĩ. Giá đầu ra khác nhau đáng kể tùy theo việc suy nghĩ có được bật hay không. Nếu bạn chọn biến thể tiêu chuẩn (không có hậu tố “:thinking”), mô hình sẽ tránh tạo token suy nghĩ.\n\nĐể sử dụng suy nghĩ và nhận token suy nghĩ, bạn phải chọn biến thể “:thinking”, điều này sẽ tính giá cao hơn cho đầu ra suy nghĩ.\n\nGemini 2.5 Flash cũng có thể được cấu hình thông qua tham số “max reasoning tokens” như được tài liệu hóa (https://openrouter.ai/docs/use-cases/reasoning-tokens#max-tokens-for-reasoning).",
  "google/gemini-2.5-flash-preview:thinking.description": "Gemini 2.5 Flash là mô hình chủ lực tiên tiến nhất của Google, được xây dựng cho các tác vụ suy luận, lập trình, toán học và khoa học nâng cao. Mô hình tích hợp khả năng “suy nghĩ” để cung cấp phản hồi chính xác hơn với xử lý ngữ cảnh tinh tế hơn.\n\nLưu ý: Mô hình này có hai biến thể — có suy nghĩ và không suy nghĩ. Giá đầu ra khác nhau đáng kể tùy theo việc suy nghĩ có được bật hay không. Nếu bạn chọn biến thể tiêu chuẩn (không có hậu tố “:thinking”), mô hình sẽ tránh tạo token suy nghĩ.\n\nĐể sử dụng suy nghĩ và nhận token suy nghĩ, bạn phải chọn biến thể “:thinking”, điều này sẽ tính giá cao hơn cho đầu ra suy nghĩ.\n\nGemini 2.5 Flash cũng có thể được cấu hình thông qua tham số “max reasoning tokens” như được tài liệu hóa (https://openrouter.ai/docs/use-cases/reasoning-tokens#max-tokens-for-reasoning).",
  "google/gemini-2.5-flash.description": "Gemini 2.5 Flash (Lite/Pro/Flash) là dòng sản phẩm của Google trải dài từ độ trễ thấp đến suy luận hiệu suất cao.",
  "google/gemini-2.5-pro-free.description": "Gemini 2.5 Pro phiên bản miễn phí cung cấp ngữ cảnh dài đa phương thức với hạn ngạch giới hạn, phù hợp cho thử nghiệm và quy trình nhẹ.",
  "google/gemini-2.5-pro-preview.description": "Gemini 2.5 Pro Preview là mô hình suy nghĩ tiên tiến nhất của Google để suy luận các vấn đề phức tạp trong lập trình, toán học và STEM, cũng như phân tích tập dữ liệu lớn, mã nguồn và tài liệu với ngữ cảnh dài.",
  "google/gemini-2.5-pro.description": "Gemini 2.5 Pro là mô hình suy luận chủ lực của Google với hỗ trợ ngữ cảnh dài cho các tác vụ phức tạp.",
  "google/gemini-3-pro-image-preview-free.description": "Gemini 3 Pro Image phiên bản miễn phí với hạn ngạch tạo nội dung đa phương thức giới hạn.",
  "google/gemini-3-pro-image-preview.description": "Gemini 3 Pro Image (Nano Banana Pro) là mô hình tạo hình ảnh của Google với hỗ trợ hội thoại đa phương thức.",
  "google/gemini-3-pro-preview-free.description": "Gemini 3 Pro Preview Free cung cấp khả năng hiểu và suy luận đa phương thức giống như phiên bản tiêu chuẩn, nhưng có giới hạn về hạn ngạch và tốc độ, phù hợp hơn cho thử nghiệm và sử dụng tần suất thấp.",
  "google/gemini-3-pro-preview.description": "Gemini 3 Pro là mô hình suy luận đa phương thức thế hệ tiếp theo trong dòng Gemini, có khả năng hiểu văn bản, âm thanh, hình ảnh và video, xử lý các tác vụ phức tạp và mã nguồn lớn.",
  "google/gemini-embedding-001.description": "Mô hình embedding tiên tiến với hiệu suất mạnh mẽ trong các tác vụ tiếng Anh, đa ngôn ngữ và lập trình.",
  "google/gemini-flash-1.5.description": "Gemini 1.5 Flash cung cấp xử lý đa phương thức tối ưu cho nhiều tác vụ phức tạp.",
  "google/gemini-pro-1.5.description": "Gemini 1.5 Pro kết hợp các tối ưu hóa mới nhất để xử lý dữ liệu đa phương thức hiệu quả hơn.",
  "google/gemma-2-27b-it.description": "Gemma 2 27B là mô hình LLM đa năng với hiệu suất mạnh mẽ trong nhiều tình huống.",
  "google/gemma-2-27b.description": "Gemma 2 là dòng mô hình hiệu quả của Google, phù hợp từ ứng dụng nhỏ đến xử lý dữ liệu phức tạp.",
  "google/gemma-2-2b-it.description": "Mô hình ngôn ngữ nhỏ tiên tiến được thiết kế cho các ứng dụng biên.",
  "google/gemma-2-9b-it.description": "Gemma 2 9B, do Google phát triển, cung cấp khả năng tuân thủ hướng dẫn hiệu quả và năng lực tổng thể vững chắc.",
  "google/gemma-2-9b-it:free.description": "Gemma 2 là dòng mô hình văn bản mã nguồn mở nhẹ của Google.",
  "google/gemma-2-9b.description": "Gemma 2 là dòng mô hình hiệu quả của Google, phù hợp từ ứng dụng nhỏ đến xử lý dữ liệu phức tạp.",
  "google/gemma-2b-it.description": "Gemma Instruct (2B) cung cấp xử lý hướng dẫn cơ bản cho các ứng dụng nhẹ.",
  "google/gemma-3-12b-it.description": "Gemma 3 12B là mô hình ngôn ngữ mã nguồn mở của Google, thiết lập tiêu chuẩn mới về hiệu quả và hiệu suất.",
  "google/gemma-3-27b-it.description": "Gemma 3 27B là mô hình ngôn ngữ mã nguồn mở của Google, thiết lập tiêu chuẩn mới về hiệu quả và hiệu suất.",
  "google/text-embedding-005.description": "Mô hình embedding văn bản tập trung vào tiếng Anh, được tối ưu hóa cho các tác vụ mã và ngôn ngữ tiếng Anh.",
  "google/text-multilingual-embedding-002.description": "Mô hình embedding văn bản đa ngôn ngữ được tối ưu hóa cho các tác vụ xuyên ngôn ngữ trên nhiều ngôn ngữ.",
  "gpt-3.5-turbo-0125.description": "GPT 3.5 Turbo để tạo và hiểu văn bản; hiện đang trỏ đến gpt-3.5-turbo-0125.",
  "gpt-3.5-turbo-1106.description": "GPT 3.5 Turbo để tạo và hiểu văn bản; hiện đang trỏ đến gpt-3.5-turbo-0125.",
  "gpt-3.5-turbo-instruct.description": "GPT 3.5 Turbo cho các tác vụ tạo và hiểu văn bản, được tối ưu hóa để làm theo hướng dẫn.",
  "gpt-3.5-turbo.description": "GPT 3.5 Turbo để tạo và hiểu văn bản; hiện đang trỏ đến gpt-3.5-turbo-0125.",
  "gpt-35-turbo-16k.description": "GPT-3.5 Turbo 16k là mô hình tạo văn bản dung lượng cao dành cho các tác vụ phức tạp.",
  "gpt-35-turbo.description": "GPT-3.5 Turbo là mô hình hiệu quả của OpenAI cho trò chuyện và tạo văn bản, hỗ trợ gọi hàm song song.",
  "gpt-4-0125-preview.description": "GPT-4 Turbo mới nhất bổ sung khả năng xử lý hình ảnh. Yêu cầu hình ảnh hỗ trợ chế độ JSON và gọi hàm. Đây là mô hình đa phương tiện hiệu quả về chi phí, cân bằng giữa độ chính xác và hiệu suất cho các ứng dụng thời gian thực.",
  "gpt-4-0613.description": "GPT-4 cung cấp cửa sổ ngữ cảnh lớn hơn để xử lý đầu vào dài, phù hợp cho việc tổng hợp thông tin rộng và phân tích dữ liệu.",
  "gpt-4-1106-preview.description": "GPT-4 Turbo mới nhất bổ sung khả năng xử lý hình ảnh. Yêu cầu hình ảnh hỗ trợ chế độ JSON và gọi hàm. Đây là mô hình đa phương tiện hiệu quả về chi phí, cân bằng giữa độ chính xác và hiệu suất cho các ứng dụng thời gian thực.",
  "gpt-4-32k-0613.description": "GPT-4 cung cấp cửa sổ ngữ cảnh lớn hơn để xử lý đầu vào dài trong các tình huống cần tích hợp thông tin rộng và phân tích dữ liệu.",
  "gpt-4-32k.description": "GPT-4 cung cấp cửa sổ ngữ cảnh lớn hơn để xử lý đầu vào dài trong các tình huống cần tích hợp thông tin rộng và phân tích dữ liệu.",
  "gpt-4-turbo-2024-04-09.description": "GPT-4 Turbo mới nhất bổ sung khả năng xử lý hình ảnh. Yêu cầu hình ảnh hỗ trợ chế độ JSON và gọi hàm. Đây là mô hình đa phương tiện hiệu quả về chi phí, cân bằng giữa độ chính xác và hiệu suất cho các ứng dụng thời gian thực.",
  "gpt-4-turbo-preview.description": "GPT-4 Turbo mới nhất bổ sung khả năng xử lý hình ảnh. Yêu cầu hình ảnh hỗ trợ chế độ JSON và gọi hàm. Đây là mô hình đa phương tiện hiệu quả về chi phí, cân bằng giữa độ chính xác và hiệu suất cho các ứng dụng thời gian thực.",
  "gpt-4-turbo.description": "GPT-4 Turbo mới nhất bổ sung khả năng xử lý hình ảnh. Yêu cầu hình ảnh hỗ trợ chế độ JSON và gọi hàm. Đây là mô hình đa phương tiện hiệu quả về chi phí, cân bằng giữa độ chính xác và hiệu suất cho các ứng dụng thời gian thực.",
  "gpt-4-vision-preview.description": "Bản xem trước GPT-4 Vision, được thiết kế cho các tác vụ phân tích và xử lý hình ảnh.",
  "gpt-4.1-mini.description": "GPT-4.1 mini cân bằng giữa trí tuệ, tốc độ và chi phí, phù hợp với nhiều trường hợp sử dụng.",
  "gpt-4.1-nano.description": "GPT-4.1 nano là mô hình GPT-4.1 nhanh nhất và tiết kiệm chi phí nhất.",
  "gpt-4.1.description": "GPT-4.1 là mô hình hàng đầu của chúng tôi cho các tác vụ phức tạp và giải quyết vấn đề đa lĩnh vực.",
  "gpt-4.5-preview.description": "GPT-4.5-preview là mô hình đa năng mới nhất với kiến thức sâu rộng và khả năng hiểu ý định tốt hơn, mạnh mẽ trong các tác vụ sáng tạo và lập kế hoạch tác nhân. Mốc kiến thức là tháng 10 năm 2023.",
  "gpt-4.description": "GPT-4 cung cấp cửa sổ ngữ cảnh lớn hơn để xử lý đầu vào dài, phù hợp cho việc tổng hợp thông tin rộng và phân tích dữ liệu.",
  "gpt-4o-2024-05-13.description": "ChatGPT-4o là mô hình động được cập nhật theo thời gian thực, kết hợp khả năng hiểu và tạo nội dung mạnh mẽ cho các trường hợp sử dụng quy mô lớn như hỗ trợ khách hàng, giáo dục và hỗ trợ kỹ thuật.",
  "gpt-4o-2024-08-06.description": "ChatGPT-4o là mô hình động được cập nhật theo thời gian thực. Nó kết hợp khả năng hiểu và tạo ngôn ngữ mạnh mẽ cho các trường hợp sử dụng quy mô lớn như hỗ trợ khách hàng, giáo dục và hỗ trợ kỹ thuật.",
  "gpt-4o-2024-11-20.description": "ChatGPT-4o là mô hình động được cập nhật theo thời gian thực, kết hợp khả năng hiểu và tạo nội dung mạnh mẽ cho các trường hợp sử dụng quy mô lớn như hỗ trợ khách hàng, giáo dục và hỗ trợ kỹ thuật.",
  "gpt-4o-audio-preview.description": "Mô hình xem trước âm thanh GPT-4o với đầu vào và đầu ra âm thanh.",
  "gpt-4o-mini-audio-preview.description": "Mô hình âm thanh GPT-4o mini với đầu vào và đầu ra âm thanh.",
  "gpt-4o-mini-realtime-preview.description": "Biến thể GPT-4o-mini thời gian thực với đầu vào/ra âm thanh và văn bản.",
  "gpt-4o-mini-search-preview.description": "GPT-4o mini Search Preview được huấn luyện để hiểu và thực thi các truy vấn tìm kiếm web thông qua API Chat Completions. Tìm kiếm web được tính phí theo mỗi lần sử dụng công cụ ngoài chi phí token.",
  "gpt-4o-mini-transcribe.description": "GPT-4o Mini Transcribe là mô hình chuyển giọng nói thành văn bản sử dụng GPT-4o, cải thiện tỷ lệ lỗi từ, nhận diện ngôn ngữ và độ chính xác so với mô hình Whisper gốc.",
  "gpt-4o-mini-tts.description": "GPT-4o mini TTS là mô hình chuyển văn bản thành giọng nói dựa trên GPT-4o mini, chuyển đổi văn bản thành giọng nói tự nhiên với đầu vào tối đa 2000 token.",
  "gpt-4o-mini.description": "GPT-4o mini là mô hình mới nhất của OpenAI sau GPT-4 Omni, hỗ trợ đầu vào văn bản + hình ảnh với đầu ra văn bản. Đây là mô hình nhỏ tiên tiến nhất của họ, rẻ hơn nhiều so với các mô hình tiên tiến gần đây và rẻ hơn GPT-3.5 Turbo hơn 60%, trong khi vẫn duy trì trí tuệ hàng đầu (82% MMLU).",
  "gpt-4o-realtime-preview-2024-10-01.description": "Biến thể GPT-4o thời gian thực với đầu vào/ra âm thanh và văn bản.",
  "gpt-4o-realtime-preview-2025-06-03.description": "Biến thể GPT-4o thời gian thực với đầu vào/ra âm thanh và văn bản.",
  "gpt-4o-realtime-preview.description": "Biến thể GPT-4o thời gian thực với đầu vào/ra âm thanh và văn bản.",
  "gpt-4o-search-preview.description": "GPT-4o Search Preview được huấn luyện để hiểu và thực thi các truy vấn tìm kiếm web thông qua API Chat Completions. Tìm kiếm web được tính phí theo mỗi lần sử dụng công cụ ngoài chi phí token.",
  "gpt-4o-transcribe.description": "GPT-4o Transcribe là mô hình chuyển giọng nói thành văn bản sử dụng GPT-4o, cải thiện tỷ lệ lỗi từ, nhận diện ngôn ngữ và độ chính xác so với mô hình Whisper gốc.",
  "gpt-4o.description": "ChatGPT-4o là mô hình động được cập nhật theo thời gian thực, kết hợp khả năng hiểu và tạo nội dung mạnh mẽ cho các trường hợp sử dụng quy mô lớn như hỗ trợ khách hàng, giáo dục và hỗ trợ kỹ thuật.",
  "gpt-5-chat-latest.description": "Mô hình GPT-5 được sử dụng trong ChatGPT, kết hợp khả năng hiểu và tạo nội dung mạnh mẽ cho các ứng dụng hội thoại.",
  "gpt-5-chat.description": "GPT-5 Chat là mô hình xem trước được tối ưu hóa cho các tình huống hội thoại. Nó hỗ trợ đầu vào văn bản và hình ảnh, đầu ra chỉ văn bản, phù hợp cho chatbot và ứng dụng AI hội thoại.",
  "gpt-5-codex.description": "GPT-5 Codex là biến thể GPT-5 được tối ưu hóa cho các tác vụ lập trình tác nhân trong môi trường giống Codex.",
  "gpt-5-mini.description": "Biến thể GPT-5 nhanh hơn, tiết kiệm chi phí hơn cho các tác vụ được xác định rõ, cung cấp phản hồi nhanh hơn trong khi vẫn duy trì chất lượng.",
  "gpt-5-nano.description": "Biến thể GPT-5 nhanh nhất và tiết kiệm chi phí nhất, lý tưởng cho các ứng dụng nhạy cảm về độ trễ và chi phí.",
  "gpt-5-pro.description": "GPT-5 pro sử dụng nhiều tài nguyên tính toán hơn để suy nghĩ sâu hơn và liên tục đưa ra câu trả lời tốt hơn.",
  "meta.llama3-8b-instruct-v1:0.description": "Meta Llama 3 là một mô hình ngôn ngữ mở dành cho nhà phát triển, nhà nghiên cứu và doanh nghiệp, được thiết kế để hỗ trợ xây dựng, thử nghiệm và mở rộng các ý tưởng AI sinh ngữ một cách có trách nhiệm. Là một phần trong nền tảng đổi mới cộng đồng toàn cầu, mô hình này phù hợp với môi trường có tài nguyên hạn chế, thiết bị biên và yêu cầu thời gian huấn luyện nhanh hơn.",
  "meta/Llama-3.2-11B-Vision-Instruct.description": "Khả năng suy luận hình ảnh mạnh mẽ trên ảnh độ phân giải cao, phù hợp cho các ứng dụng hiểu thị giác.",
  "meta/Llama-3.2-90B-Vision-Instruct.description": "Khả năng suy luận hình ảnh tiên tiến dành cho các ứng dụng tác tử hiểu thị giác.",
  "meta/Llama-3.3-70B-Instruct.description": "Llama 3.3 là mô hình Llama mã nguồn mở đa ngôn ngữ tiên tiến nhất, đạt hiệu suất gần tương đương mô hình 405B với chi phí rất thấp. Dựa trên kiến trúc Transformer và được cải tiến bằng SFT và RLHF để tăng tính hữu ích và an toàn. Phiên bản tinh chỉnh theo hướng dẫn được tối ưu cho trò chuyện đa ngôn ngữ và vượt trội hơn nhiều mô hình trò chuyện mở và đóng trong các bài đánh giá ngành. Mốc kiến thức: Tháng 12 năm 2023.",
  "meta/Meta-Llama-3-70B-Instruct.description": "Mô hình mạnh mẽ với 70 tỷ tham số, xuất sắc trong suy luận, lập trình và các tác vụ ngôn ngữ tổng quát.",
  "meta/Meta-Llama-3-8B-Instruct.description": "Mô hình linh hoạt với 8 tỷ tham số, được tối ưu hóa cho trò chuyện và sinh văn bản.",
  "meta/Meta-Llama-3.1-405B-Instruct.description": "Mô hình văn bản Llama 3.1 tinh chỉnh theo hướng dẫn, được tối ưu cho trò chuyện đa ngôn ngữ, đạt hiệu suất cao trong các bài đánh giá ngành giữa các mô hình trò chuyện mở và đóng.",
  "meta/Meta-Llama-3.1-70B-Instruct.description": "Mô hình văn bản Llama 3.1 tinh chỉnh theo hướng dẫn, được tối ưu cho trò chuyện đa ngôn ngữ, đạt hiệu suất cao trong các bài đánh giá ngành giữa các mô hình trò chuyện mở và đóng.",
  "meta/Meta-Llama-3.1-8B-Instruct.description": "Mô hình văn bản Llama 3.1 tinh chỉnh theo hướng dẫn, được tối ưu cho trò chuyện đa ngôn ngữ, đạt hiệu suất cao trong các bài đánh giá ngành giữa các mô hình trò chuyện mở và đóng.",
  "meta/llama-3-70b.description": "Mô hình mã nguồn mở 70B được Meta tinh chỉnh để tuân theo hướng dẫn, được phục vụ bởi Groq trên phần cứng LPU cho suy luận nhanh và hiệu quả.",
  "meta/llama-3-8b.description": "Mô hình mã nguồn mở 8B được Meta tinh chỉnh để tuân theo hướng dẫn, được phục vụ bởi Groq trên phần cứng LPU cho suy luận nhanh và hiệu quả.",
  "meta/llama-3.1-405b-instruct.description": "Mô hình LLM tiên tiến hỗ trợ sinh dữ liệu tổng hợp, chưng cất tri thức và suy luận cho chatbot, lập trình và các tác vụ chuyên ngành.",
  "meta/llama-3.1-70b-instruct.description": "Được xây dựng cho đối thoại phức tạp với khả năng hiểu ngữ cảnh, suy luận và sinh văn bản xuất sắc.",
  "meta/llama-3.1-70b.description": "Phiên bản cập nhật của Meta Llama 3 70B Instruct với ngữ cảnh 128K, hỗ trợ đa ngôn ngữ và khả năng suy luận được cải thiện.",
  "meta/llama-3.1-8b-instruct.description": "Mô hình tiên tiến với khả năng hiểu ngôn ngữ, suy luận và sinh văn bản mạnh mẽ.",
  "meta/llama-3.1-8b.description": "Llama 3.1 8B hỗ trợ cửa sổ ngữ cảnh 128K, lý tưởng cho trò chuyện thời gian thực và phân tích dữ liệu, đồng thời tiết kiệm chi phí đáng kể so với các mô hình lớn hơn. Được phục vụ bởi Groq trên phần cứng LPU cho suy luận nhanh và hiệu quả.",
  "meta/llama-3.2-11b-vision-instruct.description": "Mô hình tiên phong kết hợp thị giác và ngôn ngữ, xuất sắc trong suy luận chất lượng cao từ hình ảnh.",
  "meta/llama-3.2-11b.description": "Mô hình suy luận hình ảnh tinh chỉnh theo hướng dẫn (đầu vào văn bản + hình ảnh, đầu ra văn bản) được tối ưu cho nhận diện thị giác, suy luận hình ảnh, tạo chú thích và hỏi đáp hình ảnh tổng quát.",
  "meta/llama-3.2-1b-instruct.description": "Mô hình ngôn ngữ nhỏ tiên tiến với khả năng hiểu, suy luận và sinh văn bản mạnh mẽ.",
  "meta/llama-3.2-1b.description": "Mô hình chỉ văn bản dành cho các trường hợp sử dụng trên thiết bị như truy xuất cục bộ đa ngôn ngữ, tóm tắt và viết lại.",
  "meta/llama-3.2-3b-instruct.description": "Mô hình ngôn ngữ nhỏ tiên tiến với khả năng hiểu, suy luận và sinh văn bản mạnh mẽ.",
  "meta/llama-3.2-3b.description": "Mô hình chỉ văn bản được tinh chỉnh cho các trường hợp sử dụng trên thiết bị như truy xuất cục bộ đa ngôn ngữ, tóm tắt và viết lại.",
  "meta/llama-3.2-90b-vision-instruct.description": "Mô hình tiên phong kết hợp thị giác và ngôn ngữ, xuất sắc trong suy luận chất lượng cao từ hình ảnh.",
  "meta/llama-3.2-90b.description": "Mô hình suy luận hình ảnh tinh chỉnh theo hướng dẫn (đầu vào văn bản + hình ảnh, đầu ra văn bản) được tối ưu cho nhận diện thị giác, suy luận hình ảnh, tạo chú thích và hỏi đáp hình ảnh tổng quát.",
  "meta/llama-3.3-70b-instruct.description": "Mô hình LLM tiên tiến mạnh về suy luận, toán học, tư duy thông thường và gọi hàm.",
  "meta/llama-3.3-70b.description": "Sự cân bằng hoàn hảo giữa hiệu suất và hiệu quả. Được xây dựng cho AI hội thoại hiệu suất cao trong sáng tạo nội dung, ứng dụng doanh nghiệp và nghiên cứu, với khả năng hiểu ngôn ngữ mạnh mẽ cho tóm tắt, phân loại, phân tích cảm xúc và sinh mã.",
  "meta/llama-4-maverick.description": "Dòng Llama 4 là bộ mô hình AI đa phương thức gốc hỗ trợ văn bản và trải nghiệm đa phương thức, sử dụng MoE để hiểu văn bản và hình ảnh hàng đầu. Llama 4 Maverick là mô hình 17B với 128 chuyên gia, được phục vụ bởi DeepInfra.",
  "meta/llama-4-scout.description": "Dòng Llama 4 là bộ mô hình AI đa phương thức gốc hỗ trợ văn bản và trải nghiệm đa phương thức, sử dụng MoE để hiểu văn bản và hình ảnh hàng đầu. Llama 4 Scout là mô hình 17B với 16 chuyên gia, được phục vụ bởi DeepInfra.",
  "moonshot-v1-128k-vision-preview.description": "Các mô hình thị giác Kimi (bao gồm moonshot-v1-8k-vision-preview/moonshot-v1-32k-vision-preview/moonshot-v1-128k-vision-preview) có khả năng hiểu nội dung hình ảnh như văn bản, màu sắc và hình dạng đối tượng.",
  "moonshot-v1-128k.description": "Moonshot V1 128K cung cấp ngữ cảnh siêu dài để tạo văn bản rất dài, xử lý lên đến 128.000 token, phù hợp cho nghiên cứu, học thuật và các tài liệu lớn.",
  "moonshot-v1-32k-vision-preview.description": "Các mô hình thị giác Kimi (bao gồm moonshot-v1-8k-vision-preview/moonshot-v1-32k-vision-preview/moonshot-v1-128k-vision-preview) có khả năng hiểu nội dung hình ảnh như văn bản, màu sắc và hình dạng đối tượng.",
  "moonshot-v1-32k.description": "Moonshot V1 32K hỗ trợ 32.768 token cho ngữ cảnh trung bình, lý tưởng cho tài liệu dài và hội thoại phức tạp trong sáng tạo nội dung, báo cáo và hệ thống trò chuyện.",
  "moonshot-v1-8k-vision-preview.description": "Các mô hình thị giác Kimi (bao gồm moonshot-v1-8k-vision-preview/moonshot-v1-32k-vision-preview/moonshot-v1-128k-vision-preview) có khả năng hiểu nội dung hình ảnh như văn bản, màu sắc và hình dạng đối tượng.",
  "moonshot-v1-8k.description": "Moonshot V1 8K được tối ưu hóa cho việc tạo văn bản ngắn với hiệu suất cao, xử lý 8.192 token cho các cuộc trò chuyện ngắn, ghi chú và nội dung nhanh.",
  "moonshot-v1-auto.description": "Moonshot V1 Auto tự động chọn mô hình phù hợp dựa trên mức sử dụng token ngữ cảnh hiện tại.",
  "moonshotai/Kimi-Dev-72B.description": "Kimi-Dev-72B là mô hình mã nguồn mở được tối ưu hóa bằng học tăng cường quy mô lớn để tạo ra các bản vá ổn định, sẵn sàng cho sản xuất. Mô hình đạt 60,4% trên SWE-bench Verified, lập kỷ lục mới cho các tác vụ kỹ thuật phần mềm tự động như sửa lỗi và đánh giá mã.",
  "moonshotai/Kimi-K2-Instruct-0905.description": "Kimi K2-Instruct-0905 là phiên bản Kimi K2 mới nhất và mạnh mẽ nhất. Đây là mô hình MoE hàng đầu với tổng 1T và 32B tham số hoạt động. Các điểm nổi bật bao gồm trí tuệ lập trình tác tử mạnh hơn với cải thiện đáng kể trên các bài kiểm tra và tác vụ thực tế, cùng với mã giao diện người dùng đẹp hơn và dễ sử dụng hơn.",
  "moonshotai/Kimi-K2-Thinking.description": "Kimi K2 Thinking là mô hình tư duy mã nguồn mở mới nhất và mạnh mẽ nhất. Nó mở rộng đáng kể độ sâu suy luận nhiều bước và duy trì việc sử dụng công cụ ổn định qua 200–300 lượt gọi liên tiếp, lập kỷ lục mới trên Humanity's Last Exam (HLE), BrowseComp và các bài kiểm tra khác. Mô hình vượt trội trong lập trình, toán học, logic và các kịch bản tác tử. Được xây dựng trên kiến trúc MoE với khoảng 1T tham số, hỗ trợ cửa sổ ngữ cảnh 256K và gọi công cụ.",
  "moonshotai/kimi-k2-0711.description": "Kimi K2 0711 là biến thể instruct trong dòng Kimi, phù hợp cho mã chất lượng cao và sử dụng công cụ.",
  "moonshotai/kimi-k2-0905.description": "Kimi K2 0905 là bản cập nhật mở rộng hiệu suất ngữ cảnh và suy luận với các tối ưu hóa lập trình.",
  "moonshotai/kimi-k2-instruct-0905.description": "Mô hình kimi-k2-0905-preview hỗ trợ cửa sổ ngữ cảnh 256k, với khả năng lập trình tác tử mạnh hơn, mã giao diện người dùng mượt mà và thực tế hơn, cùng khả năng hiểu ngữ cảnh tốt hơn.",
  "moonshotai/kimi-k2-thinking-turbo.description": "Kimi K2 Thinking Turbo là phiên bản tốc độ cao của Kimi K2 Thinking, giảm đáng kể độ trễ trong khi vẫn giữ được khả năng suy luận sâu.",
  "moonshotai/kimi-k2-thinking.description": "Kimi K2 Thinking là mô hình suy luận của Moonshot được tối ưu hóa cho các tác vụ suy luận sâu, với khả năng tác tử tổng quát.",
  "moonshotai/kimi-k2.description": "Kimi K2 là mô hình MoE lớn từ Moonshot AI với tổng 1T tham số và 32B hoạt động mỗi lần truyền, được tối ưu hóa cho khả năng tác tử bao gồm sử dụng công cụ nâng cao, suy luận và tổng hợp mã.",
  "morph/morph-v3-fast.description": "Morph cung cấp mô hình chuyên biệt để áp dụng các thay đổi mã do các mô hình tiên tiến (ví dụ: Claude hoặc GPT-4o) đề xuất vào tệp hiện có của bạn với tốc độ NHANH 4500+ token/giây. Đây là bước cuối cùng trong quy trình lập trình AI và hỗ trợ 16k token đầu vào/đầu ra.",
  "morph/morph-v3-large.description": "Morph cung cấp mô hình chuyên biệt để áp dụng các thay đổi mã do các mô hình tiên tiến (ví dụ: Claude hoặc GPT-4o) đề xuất vào tệp hiện có của bạn với tốc độ NHANH 2500+ token/giây. Đây là bước cuối cùng trong quy trình lập trình AI và hỗ trợ 16k token đầu vào/đầu ra.",
  "nousresearch/hermes-2-pro-llama-3-8b.description": "Hermes 2 Pro Llama 3 8B là phiên bản cập nhật của Nous Hermes 2 với bộ dữ liệu nội bộ mới nhất được phát triển.",
  "nvidia/Llama-3.1-Nemotron-70B-Instruct-HF.description": "Llama 3.1 Nemotron 70B là mô hình LLM tùy chỉnh của NVIDIA nhằm cải thiện tính hữu ích. Nó đạt hiệu suất cao trên Arena Hard, AlpacaEval 2 LC và GPT-4-Turbo MT-Bench, xếp hạng #1 trên cả ba bài kiểm tra tự động căn chỉnh tính đến ngày 1 tháng 10 năm 2024. Mô hình được huấn luyện từ Llama-3.1-70B-Instruct bằng RLHF (REINFORCE), Llama-3.1-Nemotron-70B-Reward và các prompt HelpSteer2-Preference.",
  "nvidia/llama-3.1-nemotron-51b-instruct.description": "Mô hình ngôn ngữ đặc biệt với độ chính xác và hiệu quả vượt trội.",
  "nvidia/llama-3.1-nemotron-70b-instruct.description": "Llama-3.1-Nemotron-70B-Instruct là mô hình tùy chỉnh của NVIDIA được thiết kế để cải thiện tính hữu ích của phản hồi LLM.",
  "o1-mini.description": "Nhỏ hơn và nhanh hơn o1-preview, chi phí thấp hơn 80%, mạnh về tạo mã và các tác vụ ngữ cảnh ngắn.",
  "o1-preview.description": "Tập trung vào suy luận nâng cao và giải quyết vấn đề phức tạp, bao gồm toán học và khoa học. Lý tưởng cho các ứng dụng cần hiểu ngữ cảnh sâu và quy trình tự động.",
  "o1-pro.description": "Dòng o1 được huấn luyện bằng học tăng cường để suy nghĩ trước khi trả lời và xử lý suy luận phức tạp. o1-pro sử dụng nhiều tài nguyên tính toán hơn để suy nghĩ sâu hơn và cung cấp câu trả lời chất lượng cao hơn một cách nhất quán.",
  "o1.description": "o1 là mô hình suy luận mới của OpenAI với đầu vào văn bản + hình ảnh và đầu ra văn bản, phù hợp cho các tác vụ phức tạp đòi hỏi kiến thức rộng. Nó có cửa sổ ngữ cảnh 200K và mốc kiến thức đến tháng 10 năm 2023.",
  "openai/gpt-3.5-turbo-instruct.description": "Khả năng tương tự các mô hình GPT-3, tương thích với các điểm cuối hoàn thành cũ thay vì trò chuyện.",
  "openai/gpt-3.5-turbo.description": "Mô hình GPT-3.5 mạnh mẽ và tiết kiệm chi phí nhất của OpenAI, được tối ưu cho trò chuyện nhưng vẫn hiệu quả với các tác vụ hoàn thành truyền thống.",
  "openai/gpt-4-turbo.description": "GPT-4-turbo của OpenAI có kiến thức tổng quát rộng và chuyên môn theo lĩnh vực, tuân theo hướng dẫn ngôn ngữ tự nhiên phức tạp và giải quyết các vấn đề khó một cách chính xác. Giới hạn kiến thức đến tháng 4 năm 2023 với cửa sổ ngữ cảnh 128k.",
  "openai/gpt-4.1-mini.description": "GPT-4.1 Mini cung cấp độ trễ thấp hơn và giá trị tốt hơn cho các tác vụ có ngữ cảnh trung bình.",
  "openai/gpt-4.1-nano.description": "GPT-4.1 Nano là lựa chọn siêu tiết kiệm chi phí và độ trễ thấp cho các cuộc trò chuyện ngắn tần suất cao hoặc phân loại.",
  "openai/gpt-4.1.description": "Dòng GPT-4.1 cung cấp cửa sổ ngữ cảnh lớn hơn và khả năng kỹ thuật cũng như suy luận mạnh mẽ hơn.",
  "openai/gpt-4o-mini.description": "GPT-4o-mini là biến thể nhỏ, nhanh của GPT-4o dành cho các trường hợp sử dụng đa phương thức có độ trễ thấp.",
  "openai/gpt-4o.description": "Dòng GPT-4o là mô hình Omni của OpenAI hỗ trợ đầu vào văn bản + hình ảnh và đầu ra văn bản.",
  "openai/gpt-5-chat.description": "GPT-5 Chat là biến thể GPT-5 được tối ưu cho hội thoại với độ trễ thấp hơn để tăng tính tương tác.",
  "openai/gpt-5-codex.description": "GPT-5-Codex là biến thể GPT-5 được tối ưu thêm cho lập trình và quy trình mã quy mô lớn.",
  "openai/gpt-5-mini.description": "GPT-5 Mini là biến thể nhỏ hơn của GPT-5 dành cho các tình huống yêu cầu độ trễ thấp và chi phí thấp.",
  "openai/gpt-5-nano.description": "GPT-5 Nano là biến thể siêu nhỏ dành cho các tình huống có yêu cầu nghiêm ngặt về chi phí và độ trễ.",
  "openai/gpt-5-pro.description": "GPT-5 Pro là mô hình hàng đầu của OpenAI, cung cấp khả năng suy luận mạnh mẽ, sinh mã và các tính năng cấp doanh nghiệp, với định tuyến thời gian thực và chính sách an toàn nghiêm ngặt hơn.",
  "openai/gpt-5.1-chat.description": "GPT-5.1 Chat là thành viên nhẹ của dòng GPT-5.1, được tối ưu cho hội thoại độ trễ thấp trong khi vẫn giữ khả năng suy luận và thực thi hướng dẫn mạnh mẽ.",
  "openai/gpt-5.1-codex-mini.description": "GPT-5.1-Codex-Mini là phiên bản nhỏ hơn, nhanh hơn của GPT-5.1-Codex, phù hợp hơn cho các tình huống lập trình nhạy cảm với độ trễ và chi phí.",
  "openai/gpt-5.1-codex.description": "GPT-5.1-Codex là biến thể GPT-5.1 được tối ưu cho kỹ thuật phần mềm và quy trình lập trình, phù hợp với tái cấu trúc lớn, gỡ lỗi phức tạp và các tác vụ lập trình tự động dài.",
  "openai/gpt-5.1.description": "GPT-5.1 là mô hình hàng đầu mới nhất trong dòng GPT-5, với cải tiến đáng kể so với GPT-5 về suy luận tổng quát, tuân theo hướng dẫn và tính tự nhiên trong hội thoại, phù hợp với nhiều tác vụ.",
  "openai/gpt-5.description": "GPT-5 là mô hình hiệu suất cao của OpenAI dành cho nhiều tác vụ sản xuất và nghiên cứu.",
  "openai/gpt-oss-120b.description": "Mô hình ngôn ngữ lớn đa năng với khả năng suy luận mạnh mẽ và có thể kiểm soát.",
  "openai/gpt-oss-20b.description": "Mô hình ngôn ngữ nhỏ gọn, mã nguồn mở, được tối ưu cho độ trễ thấp và môi trường hạn chế tài nguyên, bao gồm triển khai cục bộ và biên.",
  "openai/o1-mini.description": "o1-mini là mô hình suy luận nhanh, tiết kiệm chi phí được thiết kế cho lập trình, toán học và khoa học. Có ngữ cảnh 128K và giới hạn kiến thức đến tháng 10 năm 2023.",
  "openai/o1-preview.description": "o1 là mô hình suy luận mới của OpenAI dành cho các tác vụ phức tạp yêu cầu kiến thức rộng. Có ngữ cảnh 128K và giới hạn kiến thức đến tháng 10 năm 2023.",
  "openai/o1.description": "OpenAI o1 là mô hình suy luận hàng đầu được xây dựng để giải quyết các vấn đề phức tạp đòi hỏi tư duy sâu, mang lại khả năng suy luận mạnh mẽ và độ chính xác cao trong các tác vụ nhiều bước.",
  "openai/o3-mini-high.description": "o3-mini (suy luận cao) cung cấp trí tuệ cao hơn với cùng chi phí và độ trễ như o1-mini.",
  "openai/o3-mini.description": "o3-mini là mô hình suy luận nhỏ mới nhất của OpenAI, cung cấp trí tuệ cao hơn với cùng chi phí và độ trễ như o1-mini.",
  "openai/o3.description": "OpenAI o3 là mô hình suy luận mạnh mẽ nhất, thiết lập chuẩn mới trong lập trình, toán học, khoa học và nhận thức thị giác. Xuất sắc trong các truy vấn phức tạp, đa chiều và đặc biệt mạnh trong phân tích hình ảnh, biểu đồ và sơ đồ.",
  "openai/o4-mini-high.description": "o4-mini cấp suy luận cao, được tối ưu cho suy luận nhanh, hiệu quả với hiệu suất lập trình và thị giác mạnh mẽ.",
  "openai/o4-mini.description": "OpenAI o4-mini là mô hình suy luận nhỏ, hiệu quả dành cho các tình huống yêu cầu độ trễ thấp.",
  "openai/text-embedding-3-large.description": "Mô hình nhúng văn bản mạnh mẽ nhất của OpenAI cho các tác vụ tiếng Anh và không phải tiếng Anh.",
  "openai/text-embedding-3-small.description": "Biến thể mô hình nhúng ada cải tiến của OpenAI với hiệu suất cao hơn.",
  "openai/text-embedding-ada-002.description": "Mô hình nhúng văn bản cũ của OpenAI.",
  "openrouter/auto.description": "Dựa trên độ dài ngữ cảnh, chủ đề và độ phức tạp, yêu cầu của bạn sẽ được định tuyến đến Llama 3 70B Instruct, Claude 3.5 Sonnet (tự kiểm duyệt) hoặc GPT-4o.",
  "perplexity/sonar-pro.description": "Sản phẩm hàng đầu của Perplexity với khả năng tìm kiếm làm nền, hỗ trợ truy vấn nâng cao và theo dõi.",
  "perplexity/sonar-reasoning-pro.description": "Mô hình tập trung vào suy luận nâng cao, xuất ra chuỗi suy nghĩ (CoT) với tìm kiếm nâng cao, bao gồm nhiều truy vấn tìm kiếm cho mỗi yêu cầu.",
  "perplexity/sonar-reasoning.description": "Mô hình tập trung vào suy luận, xuất ra chuỗi suy nghĩ (CoT) với giải thích chi tiết dựa trên tìm kiếm.",
  "perplexity/sonar.description": "Sản phẩm nhẹ của Perplexity với tìm kiếm làm nền, nhanh hơn và rẻ hơn Sonar Pro.",
  "phi3.description": "Phi-3 là mô hình nhẹ mã nguồn mở của Microsoft dành cho tích hợp hiệu quả và suy luận quy mô lớn.",
  "phi3:14b.description": "Phi-3 là mô hình nhẹ mã nguồn mở của Microsoft dành cho tích hợp hiệu quả và suy luận quy mô lớn.",
  "pixtral-12b-2409.description": "Pixtral mạnh trong hiểu biểu đồ/hình ảnh, hỏi đáp tài liệu, suy luận đa phương thức và tuân theo hướng dẫn. Có thể xử lý hình ảnh ở độ phân giải/tỷ lệ gốc và hỗ trợ nhiều hình ảnh trong cửa sổ ngữ cảnh 128K.",
  "pixtral-large-latest.description": "Pixtral Large là mô hình đa phương thức mã nguồn mở 124B, được xây dựng trên Mistral Large 2, là mô hình thứ hai trong dòng đa phương thức của chúng tôi với khả năng hiểu hình ảnh tiên tiến.",
  "qwen/qwen-2-vl-72b-instruct.description": "Qwen2-VL là phiên bản mới nhất của Qwen-VL, đạt hiệu suất hàng đầu trên các tiêu chuẩn đánh giá thị giác như MathVista, DocVQA, RealWorldQA và MTVQA. Mô hình có khả năng hiểu video dài hơn 20 phút để thực hiện hỏi đáp, đối thoại và sáng tạo nội dung chất lượng cao. Nó cũng xử lý tốt các nhiệm vụ suy luận phức tạp và ra quyết định, tích hợp với thiết bị di động và robot để hành động dựa trên ngữ cảnh hình ảnh và hướng dẫn văn bản. Ngoài tiếng Anh và tiếng Trung, mô hình còn đọc được văn bản trong hình ảnh ở nhiều ngôn ngữ khác, bao gồm hầu hết các ngôn ngữ châu Âu, tiếng Nhật, tiếng Hàn, tiếng Ả Rập và tiếng Việt.",
  "qwen/qwen-2.5-72b-instruct.description": "Qwen2.5-72B-Instruct là một trong những mô hình ngôn ngữ lớn (LLM) mới nhất của Alibaba Cloud. Mô hình 72B mang lại cải tiến đáng kể trong lập trình và toán học, hỗ trợ hơn 29 ngôn ngữ (bao gồm tiếng Trung và tiếng Anh), và cải thiện rõ rệt khả năng tuân theo hướng dẫn, hiểu dữ liệu có cấu trúc và xuất dữ liệu có cấu trúc (đặc biệt là JSON).",
  "qwen/qwen2.5-32b-instruct.description": "Qwen2.5-32B-Instruct là một trong những mô hình ngôn ngữ lớn (LLM) mới nhất của Alibaba Cloud. Mô hình 32B mang lại cải tiến đáng kể trong lập trình và toán học, hỗ trợ hơn 29 ngôn ngữ (bao gồm tiếng Trung và tiếng Anh), và cải thiện rõ rệt khả năng tuân theo hướng dẫn, hiểu dữ liệu có cấu trúc và xuất dữ liệu có cấu trúc (đặc biệt là JSON).",
  "qwen/qwen2.5-7b-instruct.description": "Một mô hình ngôn ngữ song ngữ cho tiếng Trung và tiếng Anh, hỗ trợ ngôn ngữ, lập trình, toán học và suy luận.",
  "qwen/qwen2.5-coder-32b-instruct.description": "Một mô hình LLM tiên tiến dành cho sinh mã, suy luận và sửa lỗi trên các ngôn ngữ lập trình phổ biến.",
  "qwen/qwen2.5-coder-7b-instruct.description": "Một mô hình lập trình tầm trung mạnh mẽ với ngữ cảnh 32K, xuất sắc trong lập trình đa ngôn ngữ.",
  "qwen/qwen3-14b.description": "Qwen3-14B là biến thể 14B dành cho các tình huống suy luận tổng quát và trò chuyện.",
  "qwen/qwen3-14b:free.description": "Qwen3-14B là mô hình ngôn ngữ nhân quả với 14.8 tỷ tham số, được thiết kế cho suy luận phức tạp và trò chuyện hiệu quả. Mô hình có thể chuyển đổi giữa chế độ suy nghĩ (cho toán học, lập trình và logic) và chế độ không suy nghĩ (cho trò chuyện thông thường). Được tinh chỉnh để tuân theo hướng dẫn, sử dụng công cụ tác tử và sáng tạo nội dung bằng hơn 100 ngôn ngữ và phương ngữ. Hỗ trợ ngữ cảnh gốc 32K và mở rộng đến 131K với YaRN.",
  "qwen/qwen3-235b-a22b-2507.description": "Qwen3-235B-A22B-Instruct-2507 là biến thể Instruct trong dòng Qwen3, cân bằng giữa sử dụng đa ngôn ngữ và các tình huống ngữ cảnh dài.",
  "qwen/qwen3-235b-a22b-thinking-2507.description": "Qwen3-235B-A22B-Thinking-2507 là biến thể Thinking của Qwen3, được tăng cường cho các nhiệm vụ toán học và suy luận phức tạp.",
  "qwen/qwen3-235b-a22b.description": "Qwen3-235B-A22B là mô hình MoE với 235 tỷ tham số từ Qwen, sử dụng 22 tỷ tham số hoạt động mỗi lần truyền. Mô hình có thể chuyển đổi giữa chế độ suy nghĩ cho suy luận phức tạp, toán học và lập trình, và chế độ không suy nghĩ cho trò chuyện hiệu quả. Cung cấp khả năng suy luận mạnh mẽ, hỗ trợ đa ngôn ngữ (hơn 100 ngôn ngữ/phương ngữ), tuân theo hướng dẫn nâng cao và sử dụng công cụ tác tử. Hỗ trợ ngữ cảnh gốc 32K và mở rộng đến 131K với YaRN.",
  "qwen/qwen3-235b-a22b:free.description": "Qwen3-235B-A22B là mô hình MoE với 235 tỷ tham số từ Qwen, sử dụng 22 tỷ tham số hoạt động mỗi lần truyền. Mô hình có thể chuyển đổi giữa chế độ suy nghĩ cho suy luận phức tạp, toán học và lập trình, và chế độ không suy nghĩ cho trò chuyện hiệu quả. Cung cấp khả năng suy luận mạnh mẽ, hỗ trợ đa ngôn ngữ (hơn 100 ngôn ngữ/phương ngữ), tuân theo hướng dẫn nâng cao và sử dụng công cụ tác tử. Hỗ trợ ngữ cảnh gốc 32K và mở rộng đến 131K với YaRN.",
  "qwen/qwen3-30b-a3b.description": "Qwen3 là thế hệ mô hình LLM mới nhất của Qwen với kiến trúc dày đặc và MoE, xuất sắc trong suy luận, hỗ trợ đa ngôn ngữ và các nhiệm vụ tác tử nâng cao. Khả năng chuyển đổi độc đáo giữa chế độ suy nghĩ cho suy luận phức tạp và chế độ không suy nghĩ cho trò chuyện hiệu quả đảm bảo hiệu suất linh hoạt và chất lượng cao.\n\nQwen3 vượt trội so với các mô hình trước như QwQ và Qwen2.5, mang lại hiệu suất xuất sắc trong toán học, lập trình, suy luận thông thường, sáng tạo nội dung và trò chuyện tương tác. Biến thể Qwen3-30B-A3B có 30.5 tỷ tham số (3.3B hoạt động), 48 lớp, 128 chuyên gia (8 hoạt động mỗi tác vụ), và hỗ trợ ngữ cảnh lên đến 131K với YaRN, thiết lập tiêu chuẩn mới cho các mô hình mã nguồn mở.",
  "qwen/qwen3-30b-a3b:free.description": "Qwen3 là thế hệ mô hình LLM mới nhất của Qwen với kiến trúc dày đặc và MoE, xuất sắc trong suy luận, hỗ trợ đa ngôn ngữ và các nhiệm vụ tác tử nâng cao. Khả năng chuyển đổi độc đáo giữa chế độ suy nghĩ cho suy luận phức tạp và chế độ không suy nghĩ cho trò chuyện hiệu quả đảm bảo hiệu suất linh hoạt và chất lượng cao.\n\nQwen3 vượt trội so với các mô hình trước như QwQ và Qwen2.5, mang lại hiệu suất xuất sắc trong toán học, lập trình, suy luận thông thường, sáng tạo nội dung và trò chuyện tương tác. Biến thể Qwen3-30B-A3B có 30.5 tỷ tham số (3.3B hoạt động), 48 lớp, 128 chuyên gia (8 hoạt động mỗi tác vụ), và hỗ trợ ngữ cảnh lên đến 131K với YaRN, thiết lập tiêu chuẩn mới cho các mô hình mã nguồn mở.",
  "qwen/qwen3-32b.description": "Qwen3-32B là mô hình ngôn ngữ nhân quả dày đặc với 32.8 tỷ tham số, được tối ưu hóa cho suy luận phức tạp và trò chuyện hiệu quả. Mô hình có thể chuyển đổi giữa chế độ suy nghĩ cho toán học, lập trình và logic, và chế độ không suy nghĩ cho trò chuyện nhanh hơn. Hiệu suất mạnh mẽ trong tuân theo hướng dẫn, sử dụng công cụ tác tử và sáng tạo nội dung bằng hơn 100 ngôn ngữ và phương ngữ. Hỗ trợ ngữ cảnh gốc 32K và mở rộng đến 131K với YaRN.",
  "qwen/qwen3-32b:free.description": "Qwen3-32B là mô hình ngôn ngữ nhân quả dày đặc với 32.8 tỷ tham số, được tối ưu hóa cho suy luận phức tạp và trò chuyện hiệu quả. Mô hình có thể chuyển đổi giữa chế độ suy nghĩ cho toán học, lập trình và logic, và chế độ không suy nghĩ cho trò chuyện nhanh hơn. Hiệu suất mạnh mẽ trong tuân theo hướng dẫn, sử dụng công cụ tác tử và sáng tạo nội dung bằng hơn 100 ngôn ngữ và phương ngữ. Hỗ trợ ngữ cảnh gốc 32K và mở rộng đến 131K với YaRN.",
  "qwen/qwen3-8b:free.description": "Qwen3-8B là mô hình ngôn ngữ nhân quả dày đặc với 8.2 tỷ tham số, được xây dựng cho các nhiệm vụ đòi hỏi suy luận và trò chuyện hiệu quả. Mô hình có thể chuyển đổi giữa chế độ suy nghĩ cho toán học, lập trình và logic, và chế độ không suy nghĩ cho trò chuyện thông thường. Được tinh chỉnh để tuân theo hướng dẫn, tích hợp tác tử và sáng tạo nội dung bằng hơn 100 ngôn ngữ và phương ngữ. Hỗ trợ ngữ cảnh gốc 32K và mở rộng đến 131K với YaRN.",
  "qwen/qwen3-coder-plus.description": "Qwen3-Coder-Plus là mô hình tác tử lập trình thuộc dòng Qwen, được tối ưu hóa cho việc sử dụng công cụ phức tạp hơn và các phiên làm việc kéo dài.",
  "qwen/qwen3-coder.description": "Qwen3-Coder là dòng mô hình sinh mã của Qwen3, mạnh mẽ trong việc hiểu và sinh mã từ tài liệu dài.",
  "qwen/qwen3-max-preview.description": "Qwen3 Max (bản xem trước) là biến thể Max dành cho suy luận nâng cao và tích hợp công cụ.",
  "qwen/qwen3-max.description": "Qwen3 Max là mô hình suy luận cao cấp trong dòng Qwen3, hỗ trợ suy luận đa ngôn ngữ và tích hợp công cụ.",
  "qwen3-max-preview.description": "Mô hình Qwen hiệu suất cao nhất cho các nhiệm vụ phức tạp, nhiều bước. Phiên bản xem trước hỗ trợ khả năng tư duy.",
  "qwen3-max.description": "Các mô hình Qwen3 Max mang lại cải tiến lớn so với dòng 2.5 về năng lực tổng thể, hiểu tiếng Trung/Anh, tuân thủ hướng dẫn phức tạp, xử lý nhiệm vụ mở mang tính chủ quan, khả năng đa ngôn ngữ và sử dụng công cụ, với ít ảo giác hơn. Phiên bản qwen3-max mới nhất cải thiện lập trình tác tử và sử dụng công cụ so với qwen3-max-preview. Bản phát hành này đạt chuẩn SOTA thực tế và nhắm đến các nhu cầu tác tử phức tạp hơn.",
  "qwen3-next-80b-a3b-instruct.description": "Mô hình mã nguồn mở Qwen3 thế hệ tiếp theo không hỗ trợ tư duy. So với phiên bản trước (Qwen3-235B-A22B-Instruct-2507), nó có khả năng hiểu tiếng Trung tốt hơn, lý luận logic mạnh hơn và cải thiện khả năng sinh văn bản.",
  "qwen3-next-80b-a3b-thinking.description": "Qwen3 Next 80B A3B Thinking là phiên bản mô hình tư duy hàng đầu dành cho các nhiệm vụ phức tạp.",
  "qwen3-omni-flash.description": "Qwen-Omni chấp nhận đầu vào kết hợp giữa văn bản, hình ảnh, âm thanh và video, và xuất ra văn bản hoặc giọng nói. Nó cung cấp nhiều phong cách giọng nói tự nhiên, hỗ trợ đa ngôn ngữ và phương ngữ, phù hợp với các trường hợp sử dụng như viết lách, nhận diện hình ảnh và trợ lý giọng nói.",
  "qwen3-vl-235b-a22b-instruct.description": "Qwen3 VL 235B A22B Instruct là mô hình đa phương thức hàng đầu dành cho các nhiệm vụ hiểu và sáng tạo đòi hỏi cao.",
  "qwen3-vl-235b-a22b-thinking.description": "Qwen3 VL 235B A22B Thinking là phiên bản tư duy hàng đầu cho lập luận và lập kế hoạch đa phương thức phức tạp.",
  "qwen3-vl-30b-a3b-instruct.description": "Qwen3 VL 30B A3B Instruct là mô hình đa phương thức lớn cân bằng giữa độ chính xác và hiệu suất lập luận.",
  "qwen3-vl-30b-a3b-thinking.description": "Qwen3 VL 30B A3B Thinking là phiên bản tư duy sâu cho các nhiệm vụ đa phương thức phức tạp.",
  "qwen3-vl-32b-instruct.description": "Qwen3 VL 32B Instruct là mô hình điều chỉnh theo hướng dẫn đa phương thức cho hỏi đáp hình ảnh-văn bản và sáng tạo chất lượng cao.",
  "qwen3-vl-32b-thinking.description": "Qwen3 VL 32B Thinking là phiên bản tư duy sâu đa phương thức cho lập luận phức tạp và phân tích chuỗi dài.",
  "qwen3-vl-8b-instruct.description": "Qwen3 VL 8B Instruct là mô hình đa phương thức nhẹ cho hỏi đáp hình ảnh hàng ngày và tích hợp ứng dụng.",
  "qwen3-vl-8b-thinking.description": "Qwen3 VL 8B Thinking là mô hình chuỗi tư duy đa phương thức cho lập luận hình ảnh chi tiết.",
  "qwen3-vl-flash.description": "Qwen3 VL Flash: phiên bản lập luận nhẹ, tốc độ cao cho các yêu cầu nhạy cảm với độ trễ hoặc khối lượng lớn.",
  "qwen3-vl-plus.description": "Qwen VL là mô hình sinh văn bản với khả năng hiểu hình ảnh. Nó có thể thực hiện OCR, tóm tắt và lập luận, chẳng hạn như trích xuất thuộc tính từ ảnh sản phẩm hoặc giải quyết vấn đề từ hình ảnh.",
  "qwen3.description": "Qwen3 là mô hình ngôn ngữ lớn thế hệ tiếp theo của Alibaba với hiệu suất mạnh mẽ trên nhiều trường hợp sử dụng khác nhau.",
  "qwq-32b-preview.description": "QwQ là mô hình nghiên cứu thử nghiệm từ Qwen tập trung vào cải thiện khả năng lập luận.",
  "qwq-32b.description": "QwQ là mô hình lập luận trong họ Qwen. So với các mô hình điều chỉnh theo hướng dẫn tiêu chuẩn, nó mang lại khả năng tư duy và lập luận giúp cải thiện đáng kể hiệu suất các tác vụ phía sau, đặc biệt là các vấn đề phức tạp. QwQ-32B là mô hình lập luận tầm trung có thể cạnh tranh với các mô hình hàng đầu như DeepSeek-R1 và o1-mini.",
  "qwq-plus.description": "Mô hình lập luận QwQ được huấn luyện trên Qwen2.5 sử dụng học tăng cường (RL) để cải thiện đáng kể khả năng lập luận. Các chỉ số cốt lõi trong toán/mã (AIME 24/25, LiveCodeBench) và một số chuẩn đánh giá tổng quát (IFEval, LiveBench) đạt mức DeepSeek-R1 đầy đủ.",
  "qwq.description": "QwQ là mô hình lập luận trong họ Qwen. So với các mô hình điều chỉnh theo hướng dẫn tiêu chuẩn, nó mang lại khả năng tư duy và lập luận giúp cải thiện đáng kể hiệu suất các tác vụ phía sau, đặc biệt là các vấn đề khó. QwQ-32B là mô hình lập luận tầm trung có thể cạnh tranh với các mô hình hàng đầu như DeepSeek-R1 và o1-mini.",
  "qwq_32b.description": "Mô hình lập luận tầm trung trong họ Qwen. So với các mô hình điều chỉnh theo hướng dẫn tiêu chuẩn, khả năng tư duy và lập luận của QwQ giúp cải thiện đáng kể hiệu suất các tác vụ phía sau, đặc biệt là các vấn đề khó.",
  "r1-1776.description": "R1-1776 là biến thể hậu huấn luyện của DeepSeek R1 được thiết kế để cung cấp thông tin thực tế không kiểm duyệt, không thiên lệch.",
  "solar-mini-ja.description": "Solar Mini (Ja) mở rộng Solar Mini với trọng tâm vào tiếng Nhật trong khi vẫn duy trì hiệu suất mạnh mẽ và hiệu quả với tiếng Anh và tiếng Hàn.",
  "solar-mini.description": "Solar Mini là mô hình ngôn ngữ nhỏ gọn vượt trội hơn GPT-3.5, với khả năng đa ngôn ngữ mạnh mẽ hỗ trợ tiếng Anh và tiếng Hàn, mang lại giải pháp hiệu quả với dung lượng nhỏ.",
  "solar-pro.description": "Solar Pro là mô hình ngôn ngữ thông minh cao từ Upstage, tập trung vào tuân thủ hướng dẫn trên một GPU duy nhất, với điểm IFEval trên 80. Hiện hỗ trợ tiếng Anh; bản phát hành đầy đủ dự kiến vào tháng 11 năm 2024 với hỗ trợ ngôn ngữ mở rộng và ngữ cảnh dài hơn.",
  "sonar-deep-research.description": "Deep Research thực hiện nghiên cứu chuyên sâu cấp chuyên gia và tổng hợp thành các báo cáo dễ tiếp cận và có thể hành động.",
  "sonar-pro.description": "Sản phẩm tìm kiếm nâng cao với khả năng liên kết tìm kiếm cho các truy vấn phức tạp và truy vấn tiếp theo.",
  "sonar-reasoning-pro.description": "Sản phẩm tìm kiếm nâng cao với khả năng liên kết tìm kiếm cho các truy vấn phức tạp và truy vấn tiếp theo.",
  "sonar-reasoning.description": "Sản phẩm tìm kiếm nâng cao với khả năng liên kết tìm kiếm cho các truy vấn phức tạp và truy vấn tiếp theo.",
  "sonar.description": "Sản phẩm tìm kiếm nhẹ, nhanh hơn và rẻ hơn Sonar Pro.",
  "spark-x.description": "Cập nhật X1.5: (1) thêm chế độ tư duy động điều khiển qua trường `thinking`; (2) độ dài ngữ cảnh lớn hơn với đầu vào 64K và đầu ra 64K; (3) hỗ trợ FunctionCall.",
  "stable-diffusion-3-medium.description": "Mô hình chuyển văn bản thành hình ảnh mới nhất từ Stability AI. Phiên bản này cải thiện đáng kể chất lượng hình ảnh, hiểu văn bản và đa dạng phong cách, diễn giải chính xác hơn các yêu cầu ngôn ngữ tự nhiên phức tạp và tạo ra hình ảnh chính xác, đa dạng hơn.",
  "stable-diffusion-3.5-large-turbo.description": "stable-diffusion-3.5-large-turbo áp dụng kỹ thuật khuếch tán đối kháng (ADD) cho stable-diffusion-3.5-large để tăng tốc độ.",
  "stable-diffusion-3.5-large.description": "stable-diffusion-3.5-large là mô hình chuyển văn bản thành hình ảnh MMDiT với 800 triệu tham số, chất lượng xuất sắc và phù hợp với yêu cầu, hỗ trợ hình ảnh 1 megapixel và chạy hiệu quả trên phần cứng người dùng.",
  "stable-diffusion-v1.5.description": "stable-diffusion-v1.5 được khởi tạo từ điểm kiểm tra v1.2 và tinh chỉnh trong 595k bước trên \"laion-aesthetics v2 5+\" ở độ phân giải 512x512, giảm điều kiện hóa văn bản 10% để cải thiện lấy mẫu hướng dẫn không phân loại.",
  "stable-diffusion-xl-base-1.0.description": "Mô hình chuyển văn bản thành hình ảnh mã nguồn mở từ Stability AI với khả năng sáng tạo hình ảnh hàng đầu ngành. Nó có khả năng hiểu hướng dẫn mạnh mẽ và hỗ trợ định nghĩa ngược yêu cầu để tạo hình ảnh chính xác.",
  "stable-diffusion-xl.description": "stable-diffusion-xl mang lại cải tiến lớn so với v1.5 và đạt kết quả hàng đầu trong các mô hình chuyển văn bản thành hình ảnh mã nguồn mở. Cải tiến bao gồm backbone UNet lớn gấp 3 lần, mô-đun tinh chỉnh để cải thiện chất lượng hình ảnh và kỹ thuật huấn luyện hiệu quả hơn.",
  "thudm/glm-z1-32b.description": "GLM-Z1-32B-0414 là phiên bản nâng cao khả năng suy luận của GLM-4-32B, được thiết kế để giải quyết các bài toán phức tạp về toán học, logic và lập trình. Mô hình này áp dụng học tăng cường mở rộng (RL) với ưu tiên cặp nhiệm vụ cụ thể và tổng quát để cải thiện các tác vụ nhiều bước phức tạp. So với GLM-4-32B, Z1 cải thiện đáng kể khả năng suy luận có cấu trúc và năng lực trong các lĩnh vực hình thức.\n\nMô hình hỗ trợ việc áp dụng các bước “tư duy” thông qua kỹ thuật nhắc lệnh, cải thiện tính mạch lạc cho các đầu ra dài, và được tối ưu hóa cho quy trình làm việc của tác nhân với ngữ cảnh dài (qua YaRN), gọi công cụ JSON, và lấy mẫu chi tiết để đảm bảo suy luận ổn định. Lý tưởng cho các trường hợp sử dụng yêu cầu suy luận nhiều bước hoặc diễn giải hình thức cẩn thận.",
  "thudm/glm-z1-rumination-32b.description": "GLM Z1 Rumination 32B là mô hình suy luận sâu 32B thuộc dòng GLM-4-Z1, được tối ưu hóa cho các tác vụ mở phức tạp đòi hỏi tư duy kéo dài. Dựa trên glm-4-32b-0414, mô hình bổ sung các giai đoạn học tăng cường và căn chỉnh nhiều tầng, mang đến khả năng “suy ngẫm” mô phỏng quá trình xử lý nhận thức kéo dài. Điều này bao gồm suy luận lặp lại, phân tích nhiều bước và quy trình làm việc hỗ trợ công cụ như tìm kiếm, truy xuất và tổng hợp có nhận thức về trích dẫn.\n\nMô hình vượt trội trong viết nghiên cứu, phân tích so sánh và hỏi đáp phức tạp. Hỗ trợ gọi hàm cho các thao tác tìm kiếm/điều hướng (`search`, `click`, `open`, `finish`) trong quy trình tác nhân. Hành vi suy ngẫm được điều khiển bởi các vòng lặp nhiều lượt với định hình phần thưởng theo quy tắc và cơ chế ra quyết định trì hoãn, được đánh giá theo các khung nghiên cứu sâu như hệ thống căn chỉnh nội bộ của OpenAI. Phiên bản này ưu tiên chiều sâu hơn tốc độ.",
  "tngtech/deepseek-r1t-chimera:free.description": "DeepSeek-R1T-Chimera được tạo ra bằng cách kết hợp DeepSeek-R1 và DeepSeek-V3 (0324), kết hợp khả năng suy luận của R1 với hiệu quả mã hóa của V3. Dựa trên kiến trúc DeepSeek-MoE Transformer và được tối ưu hóa cho việc tạo văn bản tổng quát.\n\nMô hình hợp nhất trọng số đã huấn luyện để cân bằng giữa suy luận, hiệu suất và khả năng tuân theo hướng dẫn. Phát hành theo giấy phép MIT cho mục đích nghiên cứu và thương mại.",
  "togethercomputer/StripedHyena-Nous-7B.description": "StripedHyena Nous (7B) mang lại hiệu suất tính toán cao hơn nhờ kiến trúc và chiến lược tối ưu.",
  "tts-1-hd.description": "Mô hình chuyển văn bản thành giọng nói mới nhất, được tối ưu hóa cho chất lượng cao.",
  "tts-1.description": "Mô hình chuyển văn bản thành giọng nói mới nhất, được tối ưu hóa cho tốc độ thời gian thực.",
  "upstage/SOLAR-10.7B-Instruct-v1.0.description": "Upstage SOLAR Instruct v1 (11B) được tinh chỉnh cho các tác vụ hướng dẫn chính xác với hiệu suất ngôn ngữ mạnh mẽ.",
  "us.anthropic.claude-3-5-sonnet-20241022-v2:0.description": "Claude 3.5 Sonnet nâng tầm tiêu chuẩn ngành, vượt trội hơn các đối thủ và Claude 3 Opus trong nhiều đánh giá, đồng thời duy trì tốc độ và chi phí ở mức trung bình.",
  "v0-1.0-md.description": "v0-1.0-md là mô hình cũ được cung cấp qua API v0.",
  "v0-1.5-lg.description": "v0-1.5-lg phù hợp cho các tác vụ tư duy hoặc suy luận nâng cao.",
  "v0-1.5-md.description": "v0-1.5-md phù hợp cho các tác vụ hàng ngày và tạo giao diện người dùng.",
  "vercel/v0-1.0-md.description": "Truy cập các mô hình phía sau v0 để tạo, sửa và tối ưu hóa ứng dụng web hiện đại với khả năng suy luận theo framework và kiến thức cập nhật.",
  "vercel/v0-1.5-md.description": "Truy cập các mô hình phía sau v0 để tạo, sửa và tối ưu hóa ứng dụng web hiện đại với khả năng suy luận theo framework và kiến thức cập nhật.",
  "volcengine/doubao-seed-code.description": "Doubao-Seed-Code là mô hình ngôn ngữ lớn của ByteDance Volcano Engine, được tối ưu hóa cho lập trình tác nhân, thể hiện hiệu suất cao trong các bài kiểm tra lập trình và tác nhân với hỗ trợ ngữ cảnh 256K.",
  "wan2.2-t2i-flash.description": "Wanxiang 2.2 Speed là mô hình mới nhất với cải tiến về sáng tạo, ổn định và tính chân thực, mang lại tốc độ tạo nhanh và giá trị cao.",
  "wan2.2-t2i-plus.description": "Wanxiang 2.2 Pro là mô hình mới nhất với cải tiến về sáng tạo, ổn định và tính chân thực, tạo ra chi tiết hình ảnh phong phú hơn.",
  "wanx-v1.description": "Mô hình chuyển văn bản thành hình ảnh cơ bản. Tương ứng với Tongyi Wanxiang 1.0 General.",
  "wanx2.0-t2i-turbo.description": "Vượt trội trong tạo chân dung có kết cấu với tốc độ vừa phải và chi phí thấp. Tương ứng với Tongyi Wanxiang 2.0 Speed.",
  "wanx2.1-t2i-plus.description": "Phiên bản nâng cấp toàn diện với chi tiết hình ảnh phong phú hơn và tốc độ chậm hơn một chút. Tương ứng với Tongyi Wanxiang 2.1 Pro.",
  "wanx2.1-t2i-turbo.description": "Phiên bản nâng cấp toàn diện với tốc độ tạo nhanh, chất lượng tổng thể mạnh mẽ và giá trị cao. Tương ứng với Tongyi Wanxiang 2.1 Speed.",
  "whisper-1.description": "Mô hình nhận dạng giọng nói tổng quát hỗ trợ ASR đa ngôn ngữ, dịch giọng nói và nhận diện ngôn ngữ.",
  "wizardlm2.description": "WizardLM 2 là mô hình ngôn ngữ từ Microsoft AI, vượt trội trong đối thoại phức tạp, tác vụ đa ngôn ngữ, suy luận và trợ lý.",
  "wizardlm2:8x22b.description": "WizardLM 2 là mô hình ngôn ngữ từ Microsoft AI, vượt trội trong đối thoại phức tạp, tác vụ đa ngôn ngữ, suy luận và trợ lý.",
  "x-ai/grok-4-fast-non-reasoning.description": "Grok 4 Fast (Không Suy Luận) là mô hình đa phương thức hiệu suất cao, chi phí thấp của xAI (hỗ trợ cửa sổ ngữ cảnh 2M), phù hợp cho các tình huống nhạy cảm với độ trễ và chi phí mà không cần suy luận trong mô hình. Có thể bật suy luận qua tham số API khi cần. Lời nhắc và phản hồi có thể được xAI hoặc OpenRouter sử dụng để cải thiện các mô hình tương lai.",
  "x-ai/grok-4-fast.description": "Grok 4 Fast là mô hình hiệu suất cao, chi phí thấp của xAI (hỗ trợ cửa sổ ngữ cảnh 2M), lý tưởng cho các trường hợp sử dụng có tính đồng thời cao và ngữ cảnh dài."
}
