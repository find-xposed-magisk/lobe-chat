{
  "01-ai/yi-1.5-34b-chat.description": "Das neueste quelloffene, feinabgestimmte Modell von 01.AI mit 34 Milliarden Parametern, das verschiedene Dialogszenarien unterstützt. Es wurde mit hochwertigen Daten trainiert und auf menschliche Präferenzen abgestimmt.",
  "01-ai/yi-1.5-9b-chat.description": "Das neueste quelloffene, feinabgestimmte Modell von 01.AI mit 9 Milliarden Parametern, das verschiedene Dialogszenarien unterstützt. Es wurde mit hochwertigen Daten trainiert und auf menschliche Präferenzen abgestimmt.",
  "360/deepseek-r1.description": "Das von 360 eingesetzte DeepSeek-R1 nutzt großflächiges Reinforcement Learning in der Nachtrainingsphase, um das logische Denken mit minimaler Beschriftung deutlich zu verbessern. Es erreicht vergleichbare Leistungen wie OpenAI o1 bei Aufgaben in Mathematik, Programmierung und Sprachverständnis.",
  "360gpt-pro-trans.description": "Ein auf Übersetzungen spezialisiertes Modell, das tiefgreifend feinabgestimmt wurde, um führende Übersetzungsqualität zu liefern.",
  "360gpt-pro.description": "360GPT Pro ist ein zentrales KI-Modell von 360 mit effizienter Textverarbeitung für vielfältige NLP-Szenarien. Es unterstützt das Verständnis von Langtexten und mehrstufige Dialoge.",
  "360gpt-turbo-responsibility-8k.description": "360GPT Turbo Responsibility 8K legt den Fokus auf semantische Sicherheit und verantwortungsvolle Inhalte für sensible Anwendungen und gewährleistet dabei präzise und robuste Nutzererfahrungen.",
  "360gpt-turbo.description": "360GPT Turbo bietet starke Rechen- und Chatfähigkeiten mit exzellentem semantischen Verständnis und effizienter Textgenerierung – ideal für Unternehmen und Entwickler.",
  "360gpt2-o1.description": "360gpt2-o1 entwickelt Gedankengänge durch Baumsuche mit Reflexionsmechanismus und RL-Training, was Selbstreflexion und Selbstkorrektur ermöglicht.",
  "360gpt2-pro.description": "360GPT2 Pro ist ein fortschrittliches NLP-Modell von 360 mit herausragender Textgenerierung und -verarbeitung, besonders für kreative Aufgaben. Es bewältigt komplexe Transformationen und Rollenspiele.",
  "360zhinao2-o1.description": "360zhinao2-o1 entwickelt Gedankengänge durch Baumsuche mit Reflexionsmechanismus und RL-Training, was Selbstreflexion und Selbstkorrektur ermöglicht.",
  "4.0Ultra.description": "Spark Ultra ist das leistungsstärkste Modell der Spark-Serie. Es verbessert das Textverständnis und die Zusammenfassung und optimiert die Websuche. Als umfassende Lösung steigert es die Produktivität am Arbeitsplatz und liefert präzise Antworten – ein führendes intelligentes Produkt.",
  "AnimeSharp.description": "AnimeSharp (auch bekannt als „4x-AnimeSharp“) ist ein quelloffenes Super-Resolution-Modell basierend auf ESRGAN von Kim2091. Es ist auf das Hochskalieren und Schärfen von Anime-Bildern spezialisiert. Im Februar 2022 wurde es von „4x-TextSharpV1“ umbenannt, ursprünglich auch für Textbilder gedacht, aber stark für Anime-Inhalte optimiert.",
  "Baichuan2-Turbo.description": "Verwendet Sucherweiterung, um das Modell mit domänenspezifischem und Webwissen zu verbinden. Unterstützt PDF-/Word-Uploads und URL-Eingaben für zeitnahe, umfassende Recherche und professionelle, präzise Ausgaben.",
  "Baichuan3-Turbo-128k.description": "Mit einem ultralangen Kontextfenster von 128K ist es für häufige Unternehmensszenarien optimiert und bietet erhebliche Leistungssteigerungen. Im Vergleich zu Baichuan2 verbessert sich die Inhaltserstellung um 20 %, Wissens-Q&A um 17 % und Rollenspiel um 40 %. Die Gesamtleistung übertrifft GPT-3.5.",
  "Baichuan3-Turbo.description": "Optimiert für häufige Unternehmensszenarien mit deutlichen Leistungsgewinnen. Im Vergleich zu Baichuan2 verbessert sich die Inhaltserstellung um 20 %, Wissens-Q&A um 17 % und Rollenspiel um 40 %. Die Gesamtleistung übertrifft GPT-3.5.",
  "Baichuan4-Air.description": "Ein Spitzenmodell in China, das führende internationale Modelle bei chinesischen Aufgaben wie Wissen, Langtextverarbeitung und kreativer Generierung übertrifft. Es bietet zudem branchenführende multimodale Fähigkeiten mit starken Ergebnissen in anerkannten Benchmarks.",
  "Baichuan4-Turbo.description": "Ein Spitzenmodell in China, das führende internationale Modelle bei chinesischen Aufgaben wie Wissen, Langtextverarbeitung und kreativer Generierung übertrifft. Es bietet zudem branchenführende multimodale Fähigkeiten mit starken Ergebnissen in anerkannten Benchmarks.",
  "Baichuan4.description": "Hervorragende nationale Leistung, übertrifft führende internationale Modelle bei chinesischen Aufgaben wie enzyklopädischem Wissen, langen Texten und kreativer Generierung. Bietet zudem branchenführende multimodale Fähigkeiten und starke Benchmark-Ergebnisse.",
  "ByteDance-Seed/Seed-OSS-36B-Instruct.description": "Seed-OSS ist eine Familie quelloffener LLMs von ByteDance Seed, entwickelt für starke Langkontextverarbeitung, logisches Denken, Agentenfunktionen und allgemeine Fähigkeiten. Seed-OSS-36B-Instruct ist ein 36B-Modell, das auf Anweisungen abgestimmt ist und nativ ultralangen Kontext unterstützt – ideal für große Dokumente oder Codebasen. Es ist für logisches Denken, Codegenerierung und Agentenaufgaben (Toolnutzung) optimiert und behält dabei starke allgemeine Fähigkeiten. Ein zentrales Merkmal ist das „Thinking Budget“, das eine flexible Denklänge zur Effizienzsteigerung ermöglicht.",
  "DeepSeek-R1-Distill-Llama-70B.description": "DeepSeek R1, das größere und intelligentere Modell der DeepSeek-Reihe, wurde in die Llama-70B-Architektur destilliert. Benchmarks und menschliche Bewertungen zeigen, dass es intelligenter ist als das ursprüngliche Llama-70B, insbesondere bei Mathematik- und Faktenaufgaben.",
  "DeepSeek-R1-Distill-Qwen-1.5B.description": "Ein aus Qwen2.5-Math-1.5B destilliertes DeepSeek-R1-Modell. Verstärkendes Lernen und Cold-Start-Daten optimieren die Denkleistung und setzen neue Maßstäbe für offene Multitasking-Modelle.",
  "DeepSeek-R1-Distill-Qwen-14B.description": "DeepSeek-R1-Distill-Modelle sind feinabgestimmte Versionen quelloffener Modelle, die mit von DeepSeek-R1 generierten Beispieldaten trainiert wurden.",
  "DeepSeek-R1-Distill-Qwen-32B.description": "DeepSeek-R1-Distill-Modelle sind feinabgestimmte Versionen quelloffener Modelle, die mit von DeepSeek-R1 generierten Beispieldaten trainiert wurden.",
  "DeepSeek-R1-Distill-Qwen-7B.description": "Ein aus Qwen2.5-Math-7B destilliertes DeepSeek-R1-Modell. Verstärkendes Lernen und Cold-Start-Daten optimieren die Denkleistung und setzen neue Maßstäbe für offene Multitasking-Modelle.",
  "DeepSeek-R1.description": "DeepSeek-R1 nutzt großflächiges Reinforcement Learning in der Nachtrainingsphase, um das logische Denken mit sehr wenig beschrifteten Daten deutlich zu verbessern. Es erreicht vergleichbare Leistungen wie das OpenAI o1-Produktionsmodell bei Mathematik-, Programmier- und Sprachverständnisaufgaben.",
  "DeepSeek-V3-1.description": "DeepSeek V3.1 ist ein Modell der nächsten Generation für logisches Denken mit verbessertem komplexem Schlussfolgern und Gedankenkette, geeignet für tiefgreifende Analyseaufgaben.",
  "DeepSeek-V3-Fast.description": "Anbieter: sophnet. DeepSeek V3 Fast ist die Hoch-TPS-Version von DeepSeek V3 0324, in voller Präzision (nicht quantisiert) mit stärkerer Leistung bei Code und Mathematik sowie schnelleren Antworten.",
  "DeepSeek-V3.1-Fast.description": "DeepSeek V3.1 Fast ist die Hoch-TPS-Variante von DeepSeek V3.1. Hybrid-Denkmodus: Über Chatvorlagen unterstützt ein Modell sowohl Denk- als auch Nicht-Denk-Modi. Intelligente Toolnutzung: Nachtrainingsoptimierungen verbessern die Leistung bei Tool- und Agentenaufgaben.",
  "DeepSeek-V3.1-Think.description": "DeepSeek-V3.1 Denkmodus: Ein neues hybrides Denkmodell mit Denk- und Nicht-Denk-Modi, effizienter als DeepSeek-R1-0528. Nachtrainingsoptimierungen verbessern die Toolnutzung und Agentenleistung erheblich.",
  "DeepSeek-V3.description": "DeepSeek-V3 ist ein MoE-Modell, das von DeepSeek entwickelt wurde. Es übertrifft andere offene Modelle wie Qwen2.5-72B und Llama-3.1-405B in vielen Benchmarks und ist konkurrenzfähig mit führenden geschlossenen Modellen wie GPT-4o und Claude 3.5 Sonnet.",
  "Doubao-lite-128k.description": "Doubao-lite bietet ultraschnelle Antworten und ein hervorragendes Preis-Leistungs-Verhältnis mit flexiblen Optionen für verschiedene Szenarien. Unterstützt 128K Kontext für Inferenz und Feinabstimmung.",
  "Doubao-lite-32k.description": "Doubao-lite bietet ultraschnelle Antworten und ein hervorragendes Preis-Leistungs-Verhältnis mit flexiblen Optionen für verschiedene Szenarien. Unterstützt 32K Kontext für Inferenz und Feinabstimmung.",
  "Doubao-lite-4k.description": "Doubao-lite bietet ultraschnelle Antworten und ein hervorragendes Preis-Leistungs-Verhältnis mit flexiblen Optionen für verschiedene Szenarien. Unterstützt 4K Kontext für Inferenz und Feinabstimmung.",
  "Doubao-pro-128k.description": "Leistungsstärkstes Flaggschiffmodell für komplexe Aufgaben, stark bei Referenz-Q&A, Zusammenfassungen, kreativer Erstellung, Klassifikation und Rollenspiel. Unterstützt 128K Kontext für Inferenz und Feinabstimmung.",
  "Doubao-pro-32k.description": "Leistungsstärkstes Flaggschiffmodell für komplexe Aufgaben, stark bei Referenz-Q&A, Zusammenfassungen, kreativer Erstellung, Klassifikation und Rollenspiel. Unterstützt 32K Kontext für Inferenz und Feinabstimmung.",
  "Doubao-pro-4k.description": "Leistungsstärkstes Flaggschiffmodell für komplexe Aufgaben, stark bei Referenz-Q&A, Zusammenfassungen, kreativer Erstellung, Klassifikation und Rollenspiel. Unterstützt 4K Kontext für Inferenz und Feinabstimmung.",
  "DreamO.description": "DreamO ist ein quelloffenes Modell zur Bildanpassung, das gemeinsam von ByteDance und der Peking-Universität entwickelt wurde. Es verwendet eine einheitliche Architektur zur Unterstützung mehrerer Bildgenerierungsaufgaben. Durch effizientes kompositionelles Modellieren erzeugt es hochkonsistente, benutzerdefinierte Bilder basierend auf Identität, Motiv, Stil, Hintergrund und weiteren Vorgaben.",
  "ERNIE-3.5-128K.description": "Baidus Flaggschiff-LLM im Großformat, trainiert auf umfangreichen chinesischen und englischen Korpora. Es bietet starke allgemeine Fähigkeiten für Konversation, kreative Inhalte und Plug-in-Nutzung und unterstützt die automatische Integration des Baidu-Such-Plug-ins für aktuelle Antworten.",
  "ERNIE-3.5-8K-Preview.description": "Baidus Flaggschiff-LLM im Großformat, trainiert auf umfangreichen chinesischen und englischen Korpora. Es bietet starke allgemeine Fähigkeiten für Konversation, kreative Inhalte und Plug-in-Nutzung und unterstützt die automatische Integration des Baidu-Such-Plug-ins für aktuelle Antworten.",
  "ERNIE-3.5-8K.description": "Baidus Flaggschiff-LLM im Großformat, trainiert auf umfangreichen chinesischen und englischen Korpora. Es bietet starke allgemeine Fähigkeiten für Konversation, kreative Inhalte und Plug-in-Nutzung und unterstützt die automatische Integration des Baidu-Such-Plug-ins für aktuelle Antworten.",
  "ERNIE-4.0-8K-Latest.description": "Baidus Flaggschiff-LLM der neuesten Generation mit umfassenden Verbesserungen gegenüber ERNIE 3.5. Geeignet für komplexe Aufgaben in verschiedenen Bereichen. Unterstützt die Integration des Baidu-Such-Plug-ins für aktuelle Antworten.",
  "ERNIE-4.0-8K-Preview.description": "Baidus Flaggschiff-LLM der neuesten Generation mit umfassenden Verbesserungen gegenüber ERNIE 3.5. Geeignet für komplexe Aufgaben in verschiedenen Bereichen. Unterstützt die Integration des Baidu-Such-Plug-ins für aktuelle Antworten.",
  "ERNIE-4.0-Turbo-8K-Latest.description": "Baidus leistungsstarkes Flaggschiff-LLM für komplexe Aufgaben mit Integration des Baidu-Such-Plug-ins für aktuelle Antworten. Übertrifft ERNIE 4.0 in der Gesamtleistung.",
  "ERNIE-4.0-Turbo-8K-Preview.description": "Baidus leistungsstarkes Flaggschiff-LLM für komplexe Aufgaben mit Integration des Baidu-Such-Plug-ins für aktuelle Antworten. Übertrifft ERNIE 4.0 in der Gesamtleistung.",
  "ERNIE-Character-8K.description": "Baidus spezialisiertes LLM für Spiel-NPCs, Kundenservice und Rollenspiel mit verbesserter Konsistenz der Charakterdarstellung, besserer Befolgung von Anweisungen und stärkerem logischen Denken.",
  "ERNIE-Lite-Pro-128K.description": "Baidus leichtgewichtiges LLM mit ausgewogenem Verhältnis zwischen Qualität und Inferenzleistung. Besser als ERNIE Lite und geeignet für Systeme mit geringer Rechenleistung.",
  "ERNIE-Speed-128K.description": "Baidus neuestes Hochleistungs-LLM (2024) mit starker allgemeiner Fähigkeit. Ideal als Basis für Feintuning in spezifischen Szenarien mit exzellenter Argumentationsleistung.",
  "ERNIE-Speed-Pro-128K.description": "Baidus neuestes Hochleistungs-LLM (2024) mit starker allgemeiner Fähigkeit. Besser als ERNIE Speed und ideal als Basis für Feintuning mit exzellenter Argumentationsleistung.",
  "FLUX-1.1-pro.description": "FLUX.1.1 Pro",
  "FLUX.1-Kontext-dev.description": "FLUX.1-Kontext-dev ist ein multimodales Modell zur Bildgenerierung und -bearbeitung von Black Forest Labs, basierend auf einer Rectified Flow Transformer-Architektur mit 12 Milliarden Parametern. Es konzentriert sich auf die Erzeugung, Rekonstruktion, Verbesserung oder Bearbeitung von Bildern unter gegebenen Kontextbedingungen. Es kombiniert die kontrollierbare Generierung von Diffusionsmodellen mit der Kontextmodellierung von Transformern und unterstützt hochwertige Ergebnisse für Aufgaben wie Inpainting, Outpainting und visuelle Szenenrekonstruktion.",
  "FLUX.1-Kontext-pro.description": "FLUX.1 Kontext [pro]",
  "FLUX.1-dev.description": "FLUX.1-dev ist ein Open-Source-multimodales Sprachmodell (MLLM) von Black Forest Labs, optimiert für Bild-Text-Aufgaben. Es kombiniert Bild-/Textverständnis und -generierung. Basierend auf fortschrittlichen LLMs (z. B. Mistral-7B) nutzt es einen sorgfältig entwickelten Vision-Encoder und mehrstufiges Instruction-Tuning für multimodale Koordination und komplexes logisches Denken.",
  "Gryphe/MythoMax-L2-13b.description": "MythoMax-L2 (13B) ist ein innovatives Modell für vielfältige Anwendungsbereiche und komplexe Aufgaben.",
  "HelloMeme.description": "HelloMeme ist ein KI-Tool zur Erstellung von Memes, GIFs oder Kurzvideos aus bereitgestellten Bildern oder Bewegungen. Es erfordert keine Zeichen- oder Programmierkenntnisse – ein Referenzbild genügt, um unterhaltsame, ansprechende und stilistisch konsistente Inhalte zu erzeugen.",
  "HiDream-I1-Full.description": "HiDream-E1-Full ist ein Open-Source-Modell zur multimodalen Bildbearbeitung von HiDream.ai, basierend auf einer fortschrittlichen Diffusion Transformer-Architektur und starkem Sprachverständnis (integriertes LLaMA 3.1-8B-Instruct). Es unterstützt bildgesteuerte Generierung, Stilübertragungen, lokale Bearbeitungen und Neumalerei mit exzellentem Bild-Text-Verständnis und präziser Ausführung.",
  "HunyuanDiT-v1.2-Diffusers-Distilled.description": "hunyuandit-v1.2-distilled ist ein leichtgewichtiges Text-zu-Bild-Modell, das durch Distillation optimiert wurde, um schnell hochwertige Bilder zu erzeugen. Besonders geeignet für ressourcenschwache Umgebungen und Echtzeitanwendungen.",
  "InstantCharacter.description": "InstantCharacter ist ein personalisiertes Charaktergenerierungsmodell ohne Feintuning, veröffentlicht von Tencent AI im Jahr 2025. Es ermöglicht hochrealistische, szenenübergreifend konsistente Charaktere. Ein einzelnes Referenzbild genügt, um den Charakter flexibel in verschiedene Stile, Aktionen und Hintergründe zu übertragen.",
  "InternVL2-8B.description": "InternVL2-8B ist ein leistungsstarkes Vision-Language-Modell für multimodale Bild-Text-Verarbeitung. Es erkennt Bildinhalte präzise und generiert passende Beschreibungen oder Antworten.",
  "InternVL2.5-26B.description": "InternVL2.5-26B ist ein leistungsstarkes Vision-Language-Modell für multimodale Bild-Text-Verarbeitung. Es erkennt Bildinhalte präzise und generiert passende Beschreibungen oder Antworten.",
  "Kolors.description": "Kolors ist ein Text-zu-Bild-Modell, entwickelt vom Kuaishou-Kolors-Team. Mit Milliarden von Parametern trainiert, bietet es herausragende visuelle Qualität, starkes Verständnis chinesischer Semantik und präzise Textdarstellung.",
  "Kwai-Kolors/Kolors.description": "Kolors ist ein großskaliges Latent-Diffusion-Text-zu-Bild-Modell des Kuaishou-Kolors-Teams. Trainiert auf Milliarden Text-Bild-Paaren, überzeugt es durch visuelle Qualität, semantische Präzision und Textdarstellung in Chinesisch und Englisch. Es bietet starkes Verständnis und Generierung chinesischer Inhalte.",
  "Kwaipilot/KAT-Dev.description": "KAT-Dev (32B) ist ein Open-Source-Modell für Softwareentwicklung. Es erreicht eine Lösungsrate von 62,4 % auf SWE-Bench Verified und belegt Platz 5 unter Open-Source-Modellen. Optimiert durch Mid-Training, SFT und RL für Codevervollständigung, Fehlerbehebung und Code-Review.",
  "Llama-3.2-11B-Vision-Instruct.description": "Starkes Bildverständnis bei hochauflösenden Bildern, ideal für visuelle Analyseanwendungen.",
  "Llama-3.2-90B-Vision-Instruct\t.description": "Fortgeschrittenes Bildverständnis für visuelle Agentenanwendungen.",
  "Meta-Llama-3-3-70B-Instruct.description": "Llama 3.3 70B ist ein vielseitiges Transformer-Modell für Konversation und Textgenerierung.",
  "Meta-Llama-3.1-405B-Instruct.description": "Llama 3.1 ist ein instruktionstaugliches Textmodell, optimiert für mehrsprachige Konversation. Es erzielt starke Ergebnisse in gängigen Benchmarks und übertrifft viele offene und geschlossene Chatmodelle.",
  "Meta-Llama-3.1-70B-Instruct.description": "Llama 3.1 ist ein instruktionstaugliches Textmodell, optimiert für mehrsprachige Konversation. Es erzielt starke Ergebnisse in gängigen Benchmarks und übertrifft viele offene und geschlossene Chatmodelle.",
  "Meta-Llama-3.1-8B-Instruct.description": "Llama 3.1 ist ein instruktionstaugliches Textmodell, optimiert für mehrsprachige Konversation. Es erzielt starke Ergebnisse in gängigen Benchmarks und übertrifft viele offene und geschlossene Chatmodelle.",
  "Meta-Llama-3.2-1B-Instruct.description": "Modernes kompaktes Sprachmodell mit starkem Sprachverständnis, exzellenter Argumentation und Textgenerierung.",
  "Meta-Llama-3.2-3B-Instruct.description": "Modernes kompaktes Sprachmodell mit starkem Sprachverständnis, exzellenter Argumentation und Textgenerierung.",
  "Meta-Llama-3.3-70B-Instruct.description": "Llama 3.3 ist das fortschrittlichste mehrsprachige Open-Source-Modell der Llama-Reihe. Es bietet nahezu 405B-Leistung zu sehr niedrigen Kosten. Basierend auf Transformer-Architektur, verbessert durch SFT und RLHF für Nützlichkeit und Sicherheit. Die instruktionstaugliche Version ist für mehrsprachige Konversation optimiert und übertrifft viele offene und geschlossene Modelle in Benchmarks. Wissensstand: Dezember 2023.",
  "Meta-Llama-4-Maverick-17B-128E-Instruct-FP8.description": "Llama 4 Maverick ist ein großes MoE-Modell mit effizienter Expertenaktivierung für starke Argumentationsleistung.",
  "MiniMax-M1.description": "Ein neues Inhouse-Argumentationsmodell mit 80K Chain-of-Thought und 1M Eingabe, vergleichbar mit führenden globalen Modellen.",
  "MiniMax-M2-Stable.description": "Entwickelt für effizientes Coden und Agenten-Workflows mit höherer Parallelität für den kommerziellen Einsatz.",
  "MiniMax-M2.description": "Entwickelt für effizientes Coden und Agenten-Workflows.",
  "MiniMax-Text-01.description": "MiniMax-01 führt großskalige lineare Aufmerksamkeit über klassische Transformer hinaus ein. Mit 456B Parametern und 45,9B aktiv pro Durchlauf erreicht es Spitzenleistung und unterstützt bis zu 4M Token Kontext (32× GPT-4o, 20× Claude-3.5-Sonnet).",
  "MiniMaxAI/MiniMax-M1-80k.description": "MiniMax-M1 ist ein Open-Weights-Modell für großskalige hybride Aufmerksamkeits- und Schlussfolgerungsaufgaben mit insgesamt 456 Milliarden Parametern und etwa 45,9 Milliarden aktiven Parametern pro Token. Es unterstützt nativ einen Kontext von 1 Million Tokens und nutzt Flash Attention, um die FLOPs bei der Generierung von 100.000 Tokens im Vergleich zu DeepSeek R1 um 75 % zu reduzieren. Durch die MoE-Architektur, CISPO und hybrides RL-Training erzielt es führende Leistungen bei Aufgaben mit langen Eingaben und realer Softwareentwicklung.",
  "MiniMaxAI/MiniMax-M2.description": "MiniMax-M2 definiert Effizienz für Agenten neu. Es handelt sich um ein kompaktes, schnelles und kosteneffizientes MoE-Modell mit insgesamt 230 Milliarden und 10 Milliarden aktiven Parametern, das für erstklassige Programmier- und Agentenaufgaben entwickelt wurde und gleichzeitig eine starke allgemeine Intelligenz beibehält. Trotz nur 10 Milliarden aktiver Parameter konkurriert es mit deutlich größeren Modellen und eignet sich ideal für Anwendungen mit hoher Effizienz.",
  "Moonshot-Kimi-K2-Instruct.description": "1 Billion Gesamtparameter mit 32 Milliarden aktiven. Unter den nicht-denkenden Modellen gehört es zur Spitzenklasse in den Bereichen aktuelles Wissen, Mathematik und Programmierung und ist besonders stark bei allgemeinen Agentenaufgaben. Optimiert für Agenten-Workloads kann es nicht nur Fragen beantworten, sondern auch Handlungen ausführen. Ideal für improvisierte, allgemeine Chats und Agentenerlebnisse als reflexartiges Modell ohne langes Nachdenken.",
  "NousResearch/Nous-Hermes-2-Mixtral-8x7B-DPO.description": "Nous Hermes 2 - Mixtral 8x7B-DPO (46,7B) ist ein hochpräzises Anweisungsmodell für komplexe Berechnungen.",
  "OmniConsistency.description": "OmniConsistency verbessert die Stil-Konsistenz und Generalisierung bei Bild-zu-Bild-Aufgaben durch den Einsatz großskaliger Diffusion Transformers (DiTs) und gepaarter stilisierter Daten, wodurch Stilverluste vermieden werden.",
  "Phi-3-medium-128k-instruct.description": "Dasselbe Phi-3-medium-Modell mit erweitertem Kontextfenster für RAG- oder Few-Shot-Prompts.",
  "Phi-3-medium-4k-instruct.description": "Ein Modell mit 14 Milliarden Parametern, das qualitativ hochwertiger ist als Phi-3-mini und sich auf hochwertige, schlussfolgerungsintensive Daten konzentriert.",
  "Phi-3-mini-128k-instruct.description": "Dasselbe Phi-3-mini-Modell mit erweitertem Kontextfenster für RAG- oder Few-Shot-Prompts.",
  "Phi-3-mini-4k-instruct.description": "Das kleinste Mitglied der Phi-3-Familie, optimiert für Qualität und geringe Latenz.",
  "Phi-3-small-128k-instruct.description": "Dasselbe Phi-3-small-Modell mit erweitertem Kontextfenster für RAG- oder Few-Shot-Prompts.",
  "Phi-3-small-8k-instruct.description": "Ein Modell mit 7 Milliarden Parametern, das qualitativ hochwertiger ist als Phi-3-mini und sich auf hochwertige, schlussfolgerungsintensive Daten konzentriert.",
  "Phi-3.5-mini-instruct.description": "Eine aktualisierte Version des Phi-3-mini-Modells.",
  "Phi-3.5-vision-instrust.description": "Eine aktualisierte Version des Phi-3-vision-Modells.",
  "Pro/Qwen/Qwen2-7B-Instruct.description": "Qwen2-7B-Instruct ist ein 7B-Instruktionsmodell der Qwen2-Serie. Es verwendet eine Transformer-Architektur mit SwiGLU, Attention-QKV-Bias und Grouped-Query-Attention und verarbeitet große Eingaben. Es zeigt starke Leistungen in Sprachverständnis, Textgenerierung, Mehrsprachigkeit, Programmierung, Mathematik und logischem Denken, übertrifft die meisten Open-Source-Modelle und konkurriert mit proprietären Modellen. Es übertrifft Qwen1.5-7B-Chat in mehreren Benchmarks.",
  "Pro/Qwen/Qwen2.5-7B-Instruct.description": "Qwen2.5-7B-Instruct ist Teil der neuesten LLM-Serie von Alibaba Cloud. Das 7B-Modell bietet deutliche Verbesserungen in den Bereichen Programmierung und Mathematik, unterstützt über 29 Sprachen und verbessert das Befolgen von Anweisungen, das Verständnis strukturierter Daten und strukturierte Ausgaben (insbesondere JSON).",
  "Pro/Qwen/Qwen2.5-Coder-7B-Instruct.description": "Qwen2.5-Coder-7B-Instruct ist das neueste codefokussierte LLM von Alibaba Cloud. Basierend auf Qwen2.5 und trainiert mit 5,5 Billionen Tokens verbessert es die Codegenerierung, das logische Denken und die Fehlerbehebung erheblich, während es mathematische und allgemeine Stärken beibehält – eine solide Grundlage für Coding-Agenten.",
  "Pro/Qwen/Qwen2.5-VL-7B-Instruct.description": "Qwen2.5-VL ist ein neues Vision-Language-Modell der Qwen-Serie mit starker visueller Verständnisfähigkeit. Es analysiert Text, Diagramme und Layouts in Bildern, versteht lange Videos und Ereignisse, unterstützt logisches Denken und Werkzeugnutzung, Objektverankerung in mehreren Formaten und strukturierte Ausgaben. Es verbessert die dynamische Auflösung und das Frame-Rate-Training für Videoverständnis und steigert die Effizienz des Vision-Encoders.",
  "Pro/THUDM/GLM-4.1V-9B-Thinking.description": "GLM-4.1V-9B-Thinking ist ein Open-Source-VLM von Zhipu AI und dem Tsinghua KEG Lab, entwickelt für komplexe multimodale Kognition. Basierend auf GLM-4-9B-0414 erweitert es das Chain-of-Thought-Denken und RL, um das multimodale Schlussfolgern und die Stabilität deutlich zu verbessern.",
  "Pro/THUDM/glm-4-9b-chat.description": "GLM-4-9B-Chat ist das Open-Source-Modell GLM-4 von Zhipu AI. Es zeigt starke Leistungen in Semantik, Mathematik, logischem Denken, Programmierung und Wissen. Neben mehrstufigem Chat unterstützt es Web-Browsing, Codeausführung, benutzerdefinierte Tool-Aufrufe und langes Textverständnis. Es unterstützt 26 Sprachen (darunter Chinesisch, Englisch, Japanisch, Koreanisch, Deutsch) und bietet bis zu 128K Kontext für akademische und geschäftliche Anwendungen.",
  "Pro/deepseek-ai/DeepSeek-R1-Distill-Qwen-7B.description": "DeepSeek-R1-Distill-Qwen-7B ist eine Destillation von Qwen2.5-Math-7B und wurde mit 800.000 kuratierten DeepSeek-R1-Beispielen feinabgestimmt. Es erzielt starke Leistungen mit 92,8 % auf MATH-500, 55,5 % auf AIME 2024 und einem CodeForces-Rating von 1189 für ein 7B-Modell.",
  "Pro/deepseek-ai/DeepSeek-R1.description": "DeepSeek-R1 ist ein durch RL optimiertes Schlussfolgerungsmodell, das Wiederholungen reduziert und die Lesbarkeit verbessert. Es verwendet Cold-Start-Daten vor dem RL, um das logische Denken weiter zu verbessern, erreicht vergleichbare Leistungen wie OpenAI-o1 bei Mathematik-, Code- und Denkaufgaben und verbessert die Gesamtergebnisse durch sorgfältiges Training.",
  "Pro/deepseek-ai/DeepSeek-V3.1-Terminus.description": "DeepSeek-V3.1-Terminus ist eine aktualisierte Version des V3.1-Modells, das als hybrides Agenten-LLM positioniert ist. Es behebt von Nutzern gemeldete Probleme, verbessert die Stabilität und Sprachkonsistenz und reduziert gemischte chinesisch/englische Ausgaben und fehlerhafte Zeichen. Es integriert Denk- und Nicht-Denk-Modi mit Chat-Vorlagen für flexibles Umschalten. Außerdem verbessert es die Leistung von Code- und Suchagenten für zuverlässigere Werkzeugnutzung und mehrstufige Aufgaben.",
  "Pro/deepseek-ai/DeepSeek-V3.2-Exp.description": "DeepSeek-V3.2-Exp ist eine experimentelle V3.2-Version, die den Übergang zur nächsten Architektur bildet. Sie ergänzt DeepSeek Sparse Attention (DSA) auf Basis von V3.1-Terminus, um das Training und die Inferenz bei langen Kontexten effizienter zu gestalten, mit Optimierungen für Werkzeugnutzung, Verständnis langer Dokumente und mehrstufiges Denken. Ideal zur Erforschung höherer Effizienz bei großem Kontextbudget.",
  "Pro/deepseek-ai/DeepSeek-V3.description": "DeepSeek-V3 ist ein MoE-Modell mit 671 Milliarden Parametern, das MLA und DeepSeekMoE mit verlustfreier Lastverteilung für effizientes Training und Inferenz nutzt. Es wurde mit 14,8 Billionen hochwertigen Tokens vortrainiert und mit SFT und RL weiter abgestimmt. Es übertrifft andere Open-Source-Modelle und nähert sich führenden Closed-Source-Modellen an.",
  "Pro/moonshotai/Kimi-K2-Instruct-0905.description": "Kimi K2-Instruct-0905 ist das neueste und leistungsstärkste Modell der Kimi K2-Reihe. Es handelt sich um ein MoE-Spitzenmodell mit insgesamt 1 Billion und 32 Milliarden aktiven Parametern. Zu den Hauptmerkmalen zählen eine verbesserte agentenbasierte Programmierintelligenz mit deutlichen Leistungssteigerungen bei Benchmarks und realen Agentenaufgaben sowie eine optimierte Ästhetik und Benutzerfreundlichkeit im Frontend-Coding.",
  "Pro/moonshotai/Kimi-K2-Thinking.description": "Kimi K2 Thinking Turbo ist die Turbo-Variante, die für hohe Geschwindigkeit und Durchsatz beim logischen Denken optimiert wurde, während die Fähigkeit zu mehrstufigem Denken und Werkzeugnutzung von K2 Thinking erhalten bleibt. Es handelt sich um ein MoE-Modell mit etwa 1 Billion Parametern, nativem 256K-Kontext und stabiler großskaliger Tool-Nutzung für Produktionsszenarien mit strengen Anforderungen an Latenz und Parallelität.",
  "QwQ-32B-Preview.description": "Qwen QwQ ist ein experimentelles Forschungsmodell mit Fokus auf die Verbesserung logischer Schlussfolgerungen.",
  "Qwen/QVQ-72B-Preview.description": "QVQ-72B-Preview ist ein Forschungsmodell von Qwen mit Schwerpunkt auf visuellem Denken. Es überzeugt durch seine Fähigkeit zur Analyse komplexer Szenen und zur Lösung visueller Mathematikaufgaben.",
  "Qwen/QwQ-32B-Preview.description": "Qwen QwQ ist ein experimentelles Forschungsmodell zur Verbesserung der KI-Logik und des Denkvermögens.",
  "Qwen/QwQ-32B.description": "QwQ ist ein Modell für logisches Denken aus der Qwen-Familie. Im Vergleich zu standardmäßig instruktionstunierten Modellen bietet es erweitertes Denkvermögen, das die Leistung bei anspruchsvollen Aufgaben deutlich steigert. QwQ-32B ist ein mittelgroßes Modell, das mit führenden Denkmodellen wie DeepSeek-R1 und o1-mini konkurriert. Es verwendet RoPE, SwiGLU, RMSNorm und Attention QKV Bias, mit 64 Schichten und 40 Q-Attention-Köpfen (8 KV in GQA).",
  "Qwen/Qwen-Image-Edit-2509.description": "Qwen-Image-Edit-2509 ist die neueste Bearbeitungsversion von Qwen-Image aus dem Qwen-Team. Basierend auf dem 20B Qwen-Image-Modell erweitert es die präzise Textdarstellung um Bildbearbeitungsfunktionen. Es nutzt eine Dual-Control-Architektur, bei der Eingaben an Qwen2.5-VL zur semantischen Steuerung und an einen VAE-Encoder zur visuellen Steuerung gesendet werden. Dadurch sind sowohl semantische als auch visuelle Bearbeitungen möglich. Es unterstützt lokale Änderungen (Hinzufügen/Entfernen/Modifizieren) sowie semantische Bearbeitungen wie IP-Erstellung und Stilübertragungen bei gleichzeitiger Wahrung der Bedeutung. Es erzielt SOTA-Ergebnisse in mehreren Benchmarks.",
  "Qwen/Qwen-Image.description": "Qwen-Image ist ein 20-Milliarden-Parameter-Basismodell zur Bildgenerierung vom Qwen-Team. Es erzielt große Fortschritte bei der Darstellung komplexer Texte und präziser Bildbearbeitung, insbesondere bei hochauflösendem chinesischen/englischen Text. Es unterstützt mehrzeilige und absatzweise Layouts mit konsistenter Typografie. Neben der Textdarstellung unterstützt es eine Vielzahl von Stilen – von fotorealistisch bis Anime – sowie fortgeschrittene Bearbeitungen wie Stilübertragung, Objektmanipulation, Detailverbesserung, Textbearbeitung und Posensteuerung. Ziel ist es, eine umfassende visuelle Kreativplattform zu bieten.",
  "Qwen/Qwen2-72B-Instruct.description": "Qwen 2 Instruct (72B) bietet präzise Befolgung von Anweisungen für Unternehmensanwendungen.",
  "Qwen/Qwen2-7B-Instruct.description": "Qwen2-7B-Instruct ist ein 7B-Instruktionsmodell der Qwen2-Serie mit Transformer, SwiGLU, QKV-Bias und gruppierter Query-Attention. Es verarbeitet große Eingaben und erzielt starke Ergebnisse in den Bereichen Verständnis, Textgenerierung, Mehrsprachigkeit, Programmierung, Mathematik und logisches Denken. Es übertrifft die meisten Open-Source-Modelle und schlägt Qwen1.5-7B-Chat in mehreren Bewertungen.",
  "Qwen/Qwen2-VL-72B-Instruct.description": "Qwen2-VL ist das neueste Qwen-VL-Modell und erreicht SOTA-Ergebnisse in Vision-Benchmarks wie MathVista, DocVQA, RealWorldQA und MTVQA. Es versteht Videos mit einer Länge von über 20 Minuten für Video-QA, Dialoge und Inhaltserstellung. Es unterstützt komplexes Denken und Entscheidungsfindung und kann mit Geräten/Robotern für visuell gesteuerte Aktionen interagieren. Neben Englisch und Chinesisch erkennt es auch Texte in vielen weiteren Sprachen, darunter die meisten europäischen Sprachen, Japanisch, Koreanisch, Arabisch und Vietnamesisch.",
  "Qwen/Qwen2.5-14B-Instruct.description": "Qwen2.5-14B-Instruct ist Teil der neuesten LLM-Serie von Alibaba Cloud. Das 14B-Modell bietet deutliche Verbesserungen in den Bereichen Programmierung und Mathematik, unterstützt über 29 Sprachen und verbessert die Befolgung von Anweisungen, das Verständnis strukturierter Daten und die strukturierte Ausgabe (insbesondere JSON).",
  "Qwen/Qwen2.5-32B-Instruct.description": "Qwen2.5-32B-Instruct ist Teil der neuesten LLM-Serie von Alibaba Cloud. Das 32B-Modell bietet deutliche Verbesserungen in den Bereichen Programmierung und Mathematik, unterstützt über 29 Sprachen und verbessert die Befolgung von Anweisungen, das Verständnis strukturierter Daten und die strukturierte Ausgabe (insbesondere JSON).",
  "Qwen/Qwen2.5-72B-Instruct-128K.description": "Qwen2.5-72B-Instruct ist Teil der neuesten LLM-Serie von Alibaba Cloud. Das 72B-Modell verbessert Programmierung und Mathematik, unterstützt bis zu 128K Eingabe- und über 8K Ausgabetokens, bietet 29+ Sprachen und verbessert die Befolgung von Anweisungen sowie strukturierte Ausgaben (insbesondere JSON).",
  "Qwen/Qwen2.5-72B-Instruct-Turbo.description": "Qwen2.5 ist eine neue LLM-Familie, die für aufgabenorientierte Anweisungen optimiert wurde.",
  "Qwen/Qwen2.5-72B-Instruct.description": "Qwen2.5-72B-Instruct ist Teil der neuesten LLM-Serie von Alibaba Cloud. Das 72B-Modell bietet deutliche Verbesserungen in den Bereichen Programmierung und Mathematik, unterstützt über 29 Sprachen und verbessert die Befolgung von Anweisungen, das Verständnis strukturierter Daten und die strukturierte Ausgabe (insbesondere JSON).",
  "Qwen/Qwen2.5-7B-Instruct-Turbo.description": "Qwen2.5 ist eine neue LLM-Familie, die für aufgabenorientierte Anweisungen optimiert wurde.",
  "Qwen/Qwen2.5-7B-Instruct.description": "Qwen2.5-7B-Instruct ist Teil der neuesten LLM-Serie von Alibaba Cloud. Das 7B-Modell bietet deutliche Verbesserungen in den Bereichen Programmierung und Mathematik, unterstützt über 29 Sprachen und verbessert die Befolgung von Anweisungen, das Verständnis strukturierter Daten und die strukturierte Ausgabe (insbesondere JSON).",
  "Qwen/Qwen2.5-Coder-32B-Instruct.description": "Qwen2.5 Coder 32B Instruct ist das neueste codefokussierte LLM von Alibaba Cloud. Es basiert auf Qwen2.5 und wurde mit 5,5 Billionen Tokens trainiert. Es verbessert die Codegenerierung, das logische Denken und die Fehlerbehebung erheblich, während es seine Stärken in Mathematik und allgemeinen Aufgaben beibehält – eine starke Grundlage für Coding-Agenten.",
  "Qwen/Qwen2.5-Coder-7B-Instruct.description": "Qwen2.5-Coder-7B-Instruct ist das neueste codefokussierte LLM von Alibaba Cloud. Es basiert auf Qwen2.5 und wurde mit 5,5 Billionen Tokens trainiert. Es verbessert die Codegenerierung, das logische Denken und die Fehlerbehebung erheblich, während es seine Stärken in Mathematik und allgemeinen Aufgaben beibehält – eine solide Grundlage für Coding-Agenten.",
  "Qwen/Qwen2.5-VL-32B-Instruct.description": "Qwen2.5-VL-32B-Instruct ist ein multimodales Modell des Qwen-Teams. Es erkennt gängige Objekte und analysiert Texte, Diagramme, Symbole, Grafiken und Layouts. Als visueller Agent kann es logisch denken und Werkzeuge dynamisch steuern, einschließlich Computer- und Smartphone-Nutzung. Es lokalisiert Objekte präzise und erzeugt strukturierte Ausgaben für Rechnungen und Tabellen. Im Vergleich zu Qwen2-VL verbessert RL Mathematik und Problemlösung weiter und liefert benutzerfreundlichere Antworten.",
  "Qwen/Qwen2.5-VL-72B-Instruct.description": "Qwen2.5-VL ist das Vision-Language-Modell der Qwen2.5-Serie mit umfassenden Verbesserungen: stärkere visuelle Erkennung von Objekten, Texten, Diagrammen und Layouts; logisches Denken als visueller Agent mit dynamischer Werkzeugnutzung; Verständnis von Videos über 1 Stunde und Erfassung wichtiger Ereignisse; präzise Objektverortung über Boxen oder Punkte; sowie strukturierte Ausgaben für gescannte Daten wie Rechnungen und Tabellen.",
  "Qwen/Qwen3-14B.description": "Qwen3 ist ein Next-Gen-Modell der Tongyi Qwen-Reihe mit erheblichen Fortschritten in den Bereichen logisches Denken, allgemeine Fähigkeiten, Agentenfunktionen und mehrsprachige Leistung. Es unterstützt den Wechsel zwischen verschiedenen Denkmodi.",
  "Qwen/Qwen3-235B-A22B-Instruct-2507.description": "Qwen3-235B-A22B-Instruct-2507 ist das Flaggschiff-MoE-Modell der Qwen3-Reihe mit insgesamt 235 Milliarden und 22 Milliarden aktiven Parametern. Es handelt sich um eine aktualisierte Nicht-Denk-Version, die auf die Verbesserung der Befolgung von Anweisungen, logisches Denken, Textverständnis, Mathematik, Naturwissenschaften, Programmierung und Werkzeugnutzung fokussiert ist. Zudem erweitert es das mehrsprachige Wissen zu Nischenthemen und passt sich besser an Nutzerpräferenzen bei offenen, subjektiven Aufgaben an.",
  "Qwen/Qwen3-235B-A22B-Thinking-2507.description": "Qwen3-235B-A22B-Thinking-2507 ist ein Qwen3-Modell, das auf komplexes logisches Denken spezialisiert ist. Es nutzt eine MoE-Architektur mit insgesamt 235 Milliarden Parametern und etwa 22 Milliarden aktiven Parametern pro Token zur Effizienzsteigerung. Als dediziertes Denkmodell erzielt es erhebliche Fortschritte in Logik, Mathematik, Naturwissenschaften, Programmierung und akademischen Benchmarks und erreicht Spitzenleistungen im offenen Denken. Es verbessert zudem die Befolgung von Anweisungen, Werkzeugnutzung und Textgenerierung und unterstützt nativ einen Kontext von 256.000 Tokens für tiefes Denken und lange Dokumente.",
  "Qwen/Qwen3-235B-A22B.description": "Qwen3 ist ein Next-Gen-Modell der Tongyi Qwen-Reihe mit erheblichen Fortschritten in den Bereichen logisches Denken, allgemeine Fähigkeiten, Agentenfunktionen und mehrsprachige Leistung. Es unterstützt den Wechsel zwischen verschiedenen Denkmodi.",
  "Qwen/Qwen3-30B-A3B-Instruct-2507.description": "Qwen3-30B-A3B-Instruct-2507 ist die aktualisierte Nicht-Denk-Version von Qwen3-30B-A3B. Es handelt sich um ein MoE-Modell mit insgesamt 30,5 Milliarden und 3,3 Milliarden aktiven Parametern. Es verbessert deutlich die Befolgung von Anweisungen, logisches Denken, Textverständnis, Mathematik, Naturwissenschaften, Programmierung und Werkzeugnutzung, erweitert das mehrsprachige Wissen zu Nischenthemen und passt sich besser an Nutzerpräferenzen bei offenen Aufgaben an. Es unterstützt einen Kontext von 256.000 Tokens. Dieses Modell ist ausschließlich für Nicht-Denk-Aufgaben konzipiert und gibt keine `<think></think>`-Tags aus.",
  "Qwen/Qwen3-30B-A3B-Thinking-2507.description": "Qwen3-30B-A3B-Thinking-2507 ist das neueste Denkmodell der Qwen3-Serie. Es handelt sich um ein MoE-Modell mit insgesamt 30,5 Milliarden und 3,3 Milliarden aktiven Parametern, das auf komplexe Aufgaben fokussiert ist. Es zeigt deutliche Fortschritte in Logik, Mathematik, Naturwissenschaften, Programmierung und akademischen Benchmarks und verbessert die Befolgung von Anweisungen, Werkzeugnutzung, Textgenerierung und Präferenzabgleich. Es unterstützt nativ einen Kontext von 256.000 Tokens und kann auf bis zu 1 Million Tokens erweitert werden. Diese Version ist für den Denkmodus mit detaillierter schrittweiser Argumentation und starken Agentenfähigkeiten konzipiert.",
  "Qwen/Qwen3-30B-A3B.description": "Qwen3 ist ein Next-Gen-Modell der Tongyi Qwen-Reihe mit erheblichen Fortschritten in den Bereichen logisches Denken, allgemeine Fähigkeiten, Agentenfunktionen und mehrsprachige Leistung. Es unterstützt den Wechsel zwischen verschiedenen Denkmodi.",
  "Qwen/Qwen3-32B.description": "Qwen3 ist ein Next-Gen-Modell der Tongyi Qwen-Reihe mit erheblichen Fortschritten in den Bereichen logisches Denken, allgemeine Fähigkeiten, Agentenfunktionen und mehrsprachige Leistung. Es unterstützt den Wechsel zwischen verschiedenen Denkmodi.",
  "Qwen/Qwen3-8B.description": "Qwen3 ist ein Next-Gen-Modell der Tongyi Qwen-Reihe mit erheblichen Fortschritten in den Bereichen logisches Denken, allgemeine Fähigkeiten, Agentenfunktionen und mehrsprachige Leistung. Es unterstützt den Wechsel zwischen verschiedenen Denkmodi.",
  "Qwen/Qwen3-Coder-30B-A3B-Instruct.description": "Qwen3-Coder-30B-A3B-Instruct ist ein Qwen3-Code-Modell des Qwen-Teams. Es ist auf hohe Leistung und Effizienz optimiert und verbessert die Fähigkeiten im Bereich Code. Es zeigt starke Vorteile bei agentenbasiertem Programmieren, automatisierten Browser-Operationen und Werkzeugnutzung unter offenen Modellen. Es unterstützt nativ einen Kontext von 256.000 Tokens und kann auf 1 Million Tokens erweitert werden, um ein Verständnis auf Codebasis-Ebene zu ermöglichen. Es ermöglicht agentenbasiertes Programmieren auf Plattformen wie Qwen Code und CLINE mit einem speziellen Funktionsaufruf-Format.",
  "Qwen/Qwen3-Coder-480B-A35B-Instruct.description": "Qwen3-Coder-480B-A35B-Instruct ist Alibabas bisher leistungsfähigstes agentenbasiertes Code-Modell. Es handelt sich um ein MoE-Modell mit insgesamt 480 Milliarden und 35 Milliarden aktiven Parametern, das Effizienz und Leistung ausbalanciert. Es unterstützt nativ einen Kontext von 256.000 Tokens und kann über YaRN auf 1 Million Tokens erweitert werden, um große Codebasen zu verarbeiten. Entwickelt für agentenbasierte Programmierabläufe, kann es mit Werkzeugen und Umgebungen interagieren, um komplexe Programmieraufgaben zu lösen. Es erzielt Spitzenleistungen unter offenen Modellen bei Benchmarks für Programmierung und Agenten, vergleichbar mit führenden Modellen wie Claude Sonnet 4.",
  "Qwen/Qwen3-Next-80B-A3B-Instruct.description": "Qwen3-Next-80B-A3B-Instruct ist ein Next-Gen-Basismodell mit der Qwen3-Next-Architektur für extrem effizientes Training und Inferenz. Es kombiniert hybrides Attention (Gated DeltaNet + Gated Attention), hochgradig sparsames MoE und Optimierungen für Trainingsstabilität. Mit insgesamt 80 Milliarden Parametern, aber nur etwa 3 Milliarden aktiven bei der Inferenz, reduziert es den Rechenaufwand und liefert über 10-fachen Durchsatz im Vergleich zu Qwen3-32B bei Kontexten über 32K. Diese auf Anweisungen abgestimmte Version zielt auf allgemeine Aufgaben (kein Denkmodus) ab. Sie erreicht in einigen Benchmarks vergleichbare Leistungen wie Qwen3-235B und zeigt starke Vorteile bei Aufgaben mit extrem langem Kontext.",
  "Qwen/Qwen3-Next-80B-A3B-Thinking.description": "Qwen3-Next-80B-A3B-Thinking ist ein Next-Gen-Basismodell für komplexes logisches Denken. Es verwendet die Qwen3-Next-Architektur mit hybridem Attention (Gated DeltaNet + Gated Attention) und hochgradig sparsames MoE für extrem effizientes Training und Inferenz. Mit insgesamt 80 Milliarden Parametern, aber nur etwa 3 Milliarden aktiven bei der Inferenz, reduziert es den Rechenaufwand und liefert über 10-fachen Durchsatz im Vergleich zu Qwen3-32B bei Kontexten über 32K. Diese Denk-Version zielt auf mehrstufige Aufgaben wie Beweise, Code-Synthese, logische Analyse und Planung ab und gibt strukturierte Denkverkettungen aus. Sie übertrifft Qwen3-32B-Thinking und schlägt Gemini-2.5-Flash-Thinking in mehreren Benchmarks.",
  "Qwen/Qwen3-Omni-30B-A3B-Captioner.description": "Qwen3-Omni-30B-A3B-Captioner ist ein VLM der Qwen3-Serie, das für hochwertige, detaillierte und präzise Bildbeschreibungen entwickelt wurde. Es verwendet eine MoE-Architektur mit 30 Milliarden Parametern, um Bilder tiefgreifend zu verstehen und flüssige Beschreibungen zu erzeugen. Es überzeugt bei der Erfassung von Details, Szenenverständnis, Objekterkennung und relationalem Denken.",
  "Qwen/Qwen3-Omni-30B-A3B-Instruct.description": "Qwen3-Omni-30B-A3B-Instruct ist ein MoE-Modell der Qwen3-Serie mit insgesamt 30 Milliarden und 3 Milliarden aktiven Parametern, das starke Leistung bei geringeren Inferenzkosten bietet. Es wurde mit hochwertigen, mehrsprachigen Daten aus verschiedenen Quellen trainiert und unterstützt vollständige multimodale Eingaben (Text, Bilder, Audio, Video) sowie Verständnis und Generierung über Modalitäten hinweg.",
  "Qwen/Qwen3-Omni-30B-A3B-Thinking.description": "Qwen3-Omni-30B-A3B-Thinking ist die zentrale \"Denk\"-Komponente von Qwen3-Omni. Es verarbeitet multimodale Eingaben (Text, Audio, Bilder, Video) und führt komplexe Denkverkettungen durch, indem es Eingaben in eine gemeinsame Repräsentation für tiefes, modalitätsübergreifendes Verständnis integriert. Es ist ein MoE-Modell mit 30 Milliarden Gesamt- und 3 Milliarden aktiven Parametern und bietet ein ausgewogenes Verhältnis zwischen starker Denkfähigkeit und Recheneffizienz.",
  "Qwen/Qwen3-VL-235B-A22B-Instruct.description": "Qwen3-VL-235B-A22B-Instruct ist ein großes, auf Anweisungen abgestimmtes Qwen3-VL-Modell auf MoE-Basis, das exzellentes multimodales Verständnis und Generierung bietet. Es unterstützt nativ einen Kontext von 256.000 Tokens und eignet sich für produktive multimodale Dienste mit hoher Parallelität.",
  "Qwen/Qwen3-VL-235B-A22B-Thinking.description": "Qwen3-VL-235B-A22B-Thinking ist die Flaggschiff-Denkversion von Qwen3-VL, optimiert für komplexes multimodales Denken, langkontextuelles Denken und Agenteninteraktion in Unternehmensszenarien.",
  "Qwen/Qwen3-VL-30B-A3B-Instruct.description": "Qwen3-VL-30B-A3B-Instruct ist das auf Anweisungen abgestimmte Qwen3-VL-Modell mit starkem Verständnis und Generierung im Bereich Vision und Sprache. Es unterstützt nativ einen Kontext von 256.000 Tokens für multimodalen Chat und bildbasierte Generierung.",
  "Qwen/Qwen3-VL-30B-A3B-Thinking.description": "Qwen3-VL-30B-A3B-Thinking ist die denkverstärkte Version von Qwen3-VL, optimiert für multimodales Denken, Bild-zu-Code-Generierung und komplexes visuelles Verständnis. Es unterstützt 256.000 Tokens Kontext mit verbesserter Denkverkettung.",
  "Qwen/Qwen3-VL-32B-Instruct.description": "Qwen3-VL-32B-Instruct ist ein Vision-Language-Modell des Qwen-Teams mit führenden SOTA-Ergebnissen in mehreren VL-Benchmarks. Es unterstützt Bilder in Megapixel-Auflösung und bietet starkes visuelles Verständnis, mehrsprachige Texterkennung (OCR), feingranulare visuelle Verankerung und visuelle Dialoge. Es bewältigt komplexe multimodale Aufgaben und unterstützt Werkzeugaufrufe und Präfixvervollständigung.",
  "Qwen/Qwen3-VL-32B-Thinking.description": "Qwen3-VL-32B-Thinking ist für komplexes visuelles Denken optimiert. Es enthält einen integrierten Denkmodus, der vor der Antwort Zwischenschritte des Denkens generiert, um mehrstufige Logik, Planung und komplexes Denken zu verbessern. Es unterstützt Megapixel-Bilder, starkes visuelles Verständnis, mehrsprachige OCR, feingranulare Verankerung, visuelle Dialoge, Werkzeugaufrufe und Präfixvervollständigung.",
  "Qwen/Qwen3-VL-8B-Instruct.description": "Qwen3-VL-8B-Instruct ist ein Vision-Language-Modell der Qwen3-Reihe, basierend auf Qwen3-8B-Instruct und trainiert mit umfangreichen Bild-Text-Daten. Es überzeugt durch allgemeines visuelles Verständnis, visuelle Dialoge und mehrsprachige Texterkennung in Bildern und eignet sich für visuelle Frage-Antwort-Systeme, Bildbeschreibungen, multimodale Anweisungsbefolgung und Werkzeugnutzung.",
  "Qwen/Qwen3-VL-8B-Thinking.description": "Qwen3-VL-8B-Thinking ist die visuelle Denkversion von Qwen3, optimiert für komplexes, mehrstufiges Denken. Es generiert eine Denkverkettung vor der Antwort zur Verbesserung der Genauigkeit und eignet sich ideal für tiefgehende visuelle Frage-Antwort-Systeme und detaillierte Bildanalysen.",
  "Qwen2-72B-Instruct.description": "Qwen2 ist die neueste Generation der Qwen-Serie und unterstützt ein Kontextfenster von 128k. Im Vergleich zu den derzeit besten offenen Modellen übertrifft Qwen2-72B führende Modelle deutlich in den Bereichen Sprachverständnis, Wissen, Programmierung, Mathematik und Mehrsprachigkeit.",
  "Qwen2-7B-Instruct.description": "Qwen2 ist die neueste Generation der Qwen-Serie und übertrifft die besten offenen Modelle vergleichbarer Größe sowie sogar größere Modelle. Qwen2 7B zeigt deutliche Vorteile in verschiedenen Benchmarks, insbesondere im Bereich Programmierung und chinesisches Sprachverständnis.",
  "Qwen2-VL-72B.description": "Qwen2-VL-72B ist ein leistungsstarkes Vision-Language-Modell, das multimodale Bild-Text-Verarbeitung unterstützt. Es erkennt Bildinhalte präzise und generiert passende Beschreibungen oder Antworten.",
  "Qwen2.5-14B-Instruct.description": "Qwen2.5-14B-Instruct ist ein LLM mit 14 Milliarden Parametern und starker Leistung, optimiert für chinesische und mehrsprachige Szenarien. Es unterstützt intelligente Frage-Antwort-Systeme und Inhaltserstellung.",
  "Qwen2.5-32B-Instruct.description": "Qwen2.5-32B-Instruct ist ein LLM mit 32 Milliarden Parametern und ausgewogener Leistung, optimiert für chinesische und mehrsprachige Szenarien. Es unterstützt intelligente Frage-Antwort-Systeme und Inhaltserstellung.",
  "Qwen2.5-72B-Instruct.description": "LLM für Chinesisch und Englisch, abgestimmt auf Sprache, Programmierung, Mathematik und logisches Denken.",
  "Qwen2.5-7B-Instruct.description": "Qwen2.5-7B-Instruct ist ein LLM mit 7 Milliarden Parametern, das Funktionsaufrufe und nahtlose Integration externer Systeme unterstützt und so Flexibilität und Erweiterbarkeit erheblich verbessert. Es ist für chinesische und mehrsprachige Szenarien optimiert und unterstützt intelligente Frage-Antwort-Systeme sowie Inhaltserstellung.",
  "Qwen2.5-Coder-14B-Instruct.description": "Qwen2.5-Coder-14B-Instruct ist ein großskaliges, vortrainiertes Modell für Programmieranweisungen mit starker Codeverständnis- und Generierungsfähigkeit. Es bewältigt effizient eine Vielzahl von Programmieraufgaben und eignet sich ideal für intelligentes Codieren, automatisierte Skripterstellung und Programmierfragen.",
  "Qwen2.5-Coder-32B-Instruct.description": "Fortschrittliches LLM für Codegenerierung, logisches Denken und Fehlerbehebung in gängigen Programmiersprachen.",
  "Qwen3-235B-A22B-Instruct-2507-FP8.description": "Qwen3 235B A22B Instruct 2507 ist für fortgeschrittenes logisches Denken und Befolgen von Anweisungen optimiert. Es nutzt MoE, um effizientes Denken im großen Maßstab zu ermöglichen.",
  "Qwen3-235B.description": "Qwen3-235B-A22B ist ein MoE-Modell mit einem hybriden Denkmodus, der es Nutzern ermöglicht, nahtlos zwischen Denk- und Nicht-Denk-Modus zu wechseln. Es unterstützt Verständnis und logisches Denken in 119 Sprachen und Dialekten und verfügt über starke Tool-Calling-Fähigkeiten. Es konkurriert mit führenden Modellen wie DeepSeek R1, OpenAI o1, o3-mini, Grok 3 und Google Gemini 2.5 Pro in Benchmarks zu allgemeinen Fähigkeiten, Programmierung, Mathematik, Mehrsprachigkeit und Wissensverarbeitung.",
  "Qwen3-32B.description": "Qwen3-32B ist ein dichtes Modell mit einem hybriden Denkmodus, der Nutzern erlaubt, zwischen Denk- und Nicht-Denk-Modus zu wechseln. Durch Verbesserungen in der Architektur, mehr Trainingsdaten und besseres Training erreicht es eine Leistung auf dem Niveau von Qwen2.5-72B.",
  "SenseChat-128K.description": "Basisversion V4 mit 128K Kontext, stark im Verständnis und der Generierung von Langtexten.",
  "SenseChat-32K.description": "Basisversion V4 mit 32K Kontext, flexibel einsetzbar in vielen Szenarien.",
  "SenseChat-5-1202.description": "Neueste Version basierend auf V5.5 mit deutlichen Verbesserungen in chinesischen/englischen Grundlagen, Konversation, MINT-Wissen, Geisteswissenschaften, Schreiben, Mathematik/Logik und Längenkontrolle.",
  "SenseChat-5-Cantonese.description": "Entwickelt für den Dialogstil, Slang und das lokale Wissen Hongkongs; übertrifft GPT-4 im Kantonesisch-Verständnis und erreicht GPT-4 Turbo-Niveau in Wissen, logischem Denken, Mathematik und Programmierung.",
  "SenseChat-5-beta.description": "Teilweise bessere Leistung als SenseChat-5-1202.",
  "SenseChat-5.description": "Neueste Version V5.5 mit 128K Kontext; große Fortschritte im mathematischen Denken, englischer Konversation, Befolgen von Anweisungen und Langtextverständnis, vergleichbar mit GPT-4o.",
  "SenseChat-Character-Pro.description": "Fortschrittliches Charakter-Chat-Modell mit 32K Kontext, verbesserter Leistung und Unterstützung für Chinesisch/Englisch.",
  "SenseChat-Character.description": "Standard-Charakter-Chat-Modell mit 8K Kontext und hoher Antwortgeschwindigkeit.",
  "SenseChat-Turbo-1202.description": "Neuestes Leichtgewichtsmodell mit über 90 % der Leistung des Vollmodells bei deutlich geringeren Inferenzkosten.",
  "SenseChat-Turbo.description": "Geeignet für schnelle Frage-Antwort-Szenarien und Modell-Feinabstimmung.",
  "SenseChat-Vision.description": "Neueste Version V5.5 mit Multi-Image-Eingabe und umfassenden Verbesserungen in Attributerkennung, räumlichen Beziehungen, Aktions-/Ereigniserkennung, Szenenverständnis, Emotionserkennung, Alltagslogik und Textverständnis/-generierung.",
  "SenseChat.description": "Basisversion V4 mit 4K Kontext und starker allgemeiner Leistungsfähigkeit.",
  "SenseNova-V6-5-Pro.description": "Mit umfassenden Updates in multimodalen, sprachlichen und logischen Daten sowie optimierter Trainingsstrategie verbessert das neue Modell das multimodale Denken und das allgemeine Befolgen von Anweisungen erheblich. Es unterstützt ein Kontextfenster von bis zu 128k und glänzt bei OCR- und Kultur-/Tourismus-IP-Erkennungsaufgaben.",
  "SenseNova-V6-5-Turbo.description": "Mit umfassenden Updates in multimodalen, sprachlichen und logischen Daten sowie optimierter Trainingsstrategie verbessert das neue Modell das multimodale Denken und das allgemeine Befolgen von Anweisungen erheblich. Es unterstützt ein Kontextfenster von bis zu 128k und glänzt bei OCR- und Kultur-/Tourismus-IP-Erkennungsaufgaben.",
  "SenseNova-V6-Pro.description": "Vereint Bild-, Text- und Videodaten nativ und überwindet traditionelle multimodale Grenzen; belegt Spitzenplätze bei OpenCompass und SuperCLUE.",
  "SenseNova-V6-Reasoner.description": "Kombiniert tiefes logisches Denken in Bild und Sprache, unterstützt langsames Denken und vollständige Gedankengänge.",
  "SenseNova-V6-Turbo.description": "Vereint Bild-, Text- und Videodaten nativ und überwindet traditionelle multimodale Grenzen. Führend in zentralen multimodalen und sprachlichen Fähigkeiten und rangiert in mehreren Bewertungen in der Spitzengruppe.",
  "Skylark2-lite-8k.description": "Skylark Modell der 2. Generation. Skylark2-lite bietet schnelle Antworten für Echtzeit- und kostensensitive Szenarien mit geringeren Genauigkeitsanforderungen und einem 8K-Kontextfenster.",
  "Skylark2-pro-32k.description": "Skylark Modell der 2. Generation. Skylark2-pro bietet höhere Genauigkeit für komplexe Textgenerierung wie professionelle Werbetexte, Romanerstellung und hochwertige Übersetzungen mit einem 32K-Kontextfenster.",
  "Skylark2-pro-4k.description": "Skylark Modell der 2. Generation. Skylark2-pro bietet höhere Genauigkeit für komplexe Textgenerierung wie professionelle Werbetexte, Romanerstellung und hochwertige Übersetzungen mit einem 4K-Kontextfenster.",
  "Skylark2-pro-character-4k.description": "Skylark Modell der 2. Generation. Skylark2-pro-character ist besonders gut für Rollenspiele und Chat geeignet, passt sich an verschiedene Persönlichkeitsstile an und bietet natürliche Dialoge für Chatbots, virtuelle Assistenten und Kundenservice mit schnellen Antworten.",
  "Skylark2-pro-turbo-8k.description": "Skylark Modell der 2. Generation. Skylark2-pro-turbo-8k bietet schnellere Inferenz bei geringeren Kosten mit einem 8K-Kontextfenster.",
  "THUDM/GLM-4-32B-0414.description": "GLM-4-32B-0414 ist ein Open-Source-GLM-Modell der nächsten Generation mit 32 Milliarden Parametern, das in seiner Leistung mit OpenAI GPT und der DeepSeek V3/R1-Serie vergleichbar ist.",
  "THUDM/GLM-4-9B-0414.description": "GLM-4-9B-0414 ist ein 9-Milliarden-Parameter-Modell, das auf den Techniken von GLM-4-32B basiert und eine leichtere Bereitstellung ermöglicht. Es überzeugt bei der Codegenerierung, Webdesign, SVG-Erstellung und suchbasiertem Schreiben.",
  "THUDM/GLM-4.1V-9B-Thinking.description": "GLM-4.1V-9B-Thinking ist ein quelloffenes VLM von Zhipu AI und dem KEG-Labor der Tsinghua-Universität, das für komplexe multimodale Kognition entwickelt wurde. Aufbauend auf GLM-4-9B-0414 integriert es Chain-of-Thought-Reasoning und Reinforcement Learning, um die modalübergreifende Argumentation und Stabilität deutlich zu verbessern.",
  "THUDM/GLM-Z1-32B-0414.description": "GLM-Z1-32B-0414 ist ein Modell für tiefgehende Argumentation, das auf GLM-4-32B-0414 basiert und mit Cold-Start-Daten sowie erweitertem Reinforcement Learning weitertrainiert wurde. Es wurde zusätzlich auf Mathematik, Code und Logik trainiert und verbessert die Fähigkeiten zur Lösung komplexer Aufgaben erheblich.",
  "THUDM/GLM-Z1-9B-0414.description": "GLM-Z1-9B-0414 ist ein kompaktes GLM-Modell mit 9 Milliarden Parametern, das die Stärken von Open-Source-Modellen beibehält und gleichzeitig eine beeindruckende Leistung bietet. Es überzeugt besonders bei mathematischer Argumentation und allgemeinen Aufgaben und ist führend in seiner Größenklasse unter offenen Modellen.",
  "THUDM/GLM-Z1-Rumination-32B-0414.description": "GLM-Z1-Rumination-32B-0414 ist ein Modell für tiefgehende Argumentation mit Ruminationsfähigkeit (verglichen mit OpenAI Deep Research). Im Gegensatz zu typischen Modellen für tiefes Denken widmet es der Problemlösung mehr Zeit, um offene und komplexe Fragestellungen besser zu bewältigen.",
  "THUDM/glm-4-9b-chat.description": "GLM-4-9B-Chat ist das quelloffene GLM-4-Modell von Zhipu AI. Es zeigt starke Leistungen in Semantik, Mathematik, Argumentation, Code und Wissen. Neben mehrstufigem Dialog unterstützt es Web-Browsing, Codeausführung, benutzerdefinierte Tool-Aufrufe und Langtext-Argumentation. Es unterstützt 26 Sprachen (darunter Chinesisch, Englisch, Japanisch, Koreanisch, Deutsch) und erzielt gute Ergebnisse bei AlignBench-v2, MT-Bench, MMLU und C-Eval. Es unterstützt Kontexte bis zu 128.000 Tokens für akademische und geschäftliche Anwendungen.",
  "Tongyi-Zhiwen/QwenLong-L1-32B.description": "QwenLong-L1-32B ist das erste Long-Context-Reasoning-Modell (LRM), das mit Reinforcement Learning trainiert wurde und für Langtext-Argumentation optimiert ist. Durch progressives Kontextwachstum im RL gelingt ein stabiler Übergang von kurzen zu langen Kontexten. Es übertrifft OpenAI-o3-mini und Qwen3-235B-A22B in sieben Benchmarks für Langkontext-Dokumentfragen und konkurriert mit Claude-3.7-Sonnet-Thinking. Besonders stark ist es in Mathematik, Logik und mehrstufiger Argumentation.",
  "Yi-34B-Chat.description": "Yi-1.5-34B bewahrt die starken allgemeinen Sprachfähigkeiten der Serie und verbessert durch inkrementelles Training mit 500 Milliarden hochwertigen Tokens die Leistungen in Mathematik, Logik und Programmierung deutlich.",
  "abab5.5-chat.description": "Entwickelt für produktive Szenarien mit komplexer Aufgabenverarbeitung und effizienter Textgenerierung für den professionellen Einsatz.",
  "abab5.5s-chat.description": "Optimiert für chinesische Persona-Chats und liefert hochwertige chinesische Dialoge für vielfältige Anwendungen.",
  "abab6.5g-chat.description": "Entwickelt für mehrsprachige Persona-Chats mit hochwertiger Dialoggenerierung in Englisch und anderen Sprachen.",
  "abab6.5s-chat.description": "Geeignet für eine Vielzahl von NLP-Aufgaben, einschließlich Textgenerierung und Dialogsysteme.",
  "abab6.5t-chat.description": "Optimiert für chinesische Persona-Chats mit flüssigen Dialogen, die den chinesischen Ausdrucksgewohnheiten entsprechen.",
  "accounts/fireworks/models/deepseek-r1.description": "DeepSeek-R1 ist ein hochmodernes Sprachmodell, das mit Reinforcement Learning und Cold-Start-Daten optimiert wurde und hervorragende Leistungen in Argumentation, Mathematik und Programmierung bietet.",
  "accounts/fireworks/models/deepseek-v3.description": "Ein leistungsstarkes Mixture-of-Experts (MoE) Sprachmodell von DeepSeek mit insgesamt 671 Milliarden Parametern und 37 Milliarden aktiven Parametern pro Token.",
  "accounts/fireworks/models/llama-v3-70b-instruct.description": "Meta hat die Meta Llama 3 LLM-Serie entwickelt und veröffentlicht, die vortrainierte und instruktionstunierte Textgenerierungsmodelle mit 8B und 70B umfasst. Die instruktionstunierten Llama 3-Modelle sind für Konversationen optimiert und übertreffen viele bestehende offene Chatmodelle in gängigen Benchmarks der Branche.",
  "accounts/fireworks/models/llama-v3-8b-instruct-hf.description": "Die instruktionstunierten Meta Llama 3-Modelle sind für Konversationen optimiert und übertreffen viele bestehende offene Chatmodelle in gängigen Benchmarks. Llama 3 8B Instruct (HF-Version) ist die ursprüngliche FP16-Version von Llama 3 8B Instruct und liefert Ergebnisse, die der offiziellen Hugging Face-Implementierung entsprechen.",
  "accounts/fireworks/models/llama-v3-8b-instruct.description": "Meta hat die Meta Llama 3 LLM-Serie entwickelt und veröffentlicht – eine Sammlung vortrainierter und instruktionstunierter Textgenerierungsmodelle mit 8B und 70B. Die instruktionstunierten Llama 3-Modelle sind für Konversationen optimiert und übertreffen viele bestehende offene Chatmodelle in gängigen Benchmarks der Branche.",
  "accounts/fireworks/models/llama-v3p1-405b-instruct.description": "Meta Llama 3.1 ist eine mehrsprachige LLM-Familie mit vortrainierten und instruktionstunierten Generierungsmodellen in den Größen 8B, 70B und 405B. Die instruktionstunierten Textmodelle sind für mehrsprachige Dialoge optimiert und übertreffen viele bestehende offene und geschlossene Chatmodelle in gängigen Benchmarks. 405B ist das leistungsstärkste Modell der Llama 3.1-Familie und verwendet FP8-Inferenz, die der Referenzimplementierung sehr nahekommt.",
  "accounts/fireworks/models/llama-v3p1-70b-instruct.description": "Meta Llama 3.1 ist eine mehrsprachige LLM-Familie mit vortrainierten und instruktionstunierten Generierungsmodellen in den Größen 8B, 70B und 405B. Die instruktionstunierten Textmodelle sind für mehrsprachige Dialoge optimiert und übertreffen viele bestehende offene und geschlossene Chatmodelle in gängigen Benchmarks.",
  "accounts/fireworks/models/llama-v3p1-8b-instruct.description": "Meta Llama 3.1 ist eine mehrsprachige LLM-Familie mit vortrainierten und instruktionstunierten Generierungsmodellen in den Größen 8B, 70B und 405B. Die instruktionstunierten Textmodelle sind für mehrsprachige Dialoge optimiert und übertreffen viele bestehende offene und geschlossene Chatmodelle in gängigen Benchmarks.",
  "accounts/fireworks/models/llama-v3p2-11b-vision-instruct.description": "Ein instruktionstuniertes Modell von Meta für visuelle Argumentation mit 11 Milliarden Parametern, optimiert für visuelle Erkennung, Bildverständnis, Bildbeschriftung und bildbezogene Fragen. Es versteht visuelle Daten wie Diagramme und Grafiken und verbindet Bild und Sprache durch die Generierung textlicher Beschreibungen von Bilddetails.",
  "accounts/fireworks/models/llama-v3p2-3b-instruct.description": "Llama 3.2 3B Instruct ist ein leichtgewichtiges, mehrsprachiges Modell von Meta, das für eine effiziente Laufzeit mit deutlichen Vorteilen bei Latenz und Kosten gegenüber größeren Modellen entwickelt wurde. Typische Anwendungsfälle sind das Umschreiben von Abfragen/Prompts und Schreibunterstützung.",
  "accounts/fireworks/models/llama-v3p2-90b-vision-instruct.description": "Ein instruktionstuniertes Modell von Meta für visuelle Argumentation mit 90 Milliarden Parametern, optimiert für visuelle Erkennung, Bildverständnis, Bildbeschriftung und bildbezogene Fragen. Es versteht visuelle Daten wie Diagramme und Grafiken und verbindet Bild und Sprache durch die Generierung textlicher Beschreibungen von Bilddetails. Hinweis: Dieses Modell wird derzeit experimentell als serverloses Modell bereitgestellt. Für den Produktionseinsatz beachten Sie bitte, dass Fireworks die Bereitstellung kurzfristig einstellen kann.",
  "accounts/fireworks/models/llama-v3p3-70b-instruct.description": "Llama 3.3 70B Instruct ist das Dezember-Update von Llama 3.1 70B. Es verbessert die Tool-Nutzung, den mehrsprachigen Textsupport, Mathematik und Programmierung gegenüber der Version vom Juli 2024. Es erreicht branchenführende Leistungen in Argumentation, Mathematik und Befolgen von Anweisungen und bietet eine Leistung vergleichbar mit 3.1 405B bei deutlich höherer Geschwindigkeit und geringeren Kosten.",
  "accounts/fireworks/models/mistral-small-24b-instruct-2501.description": "Ein Modell mit 24 Milliarden Parametern und modernster Leistung, vergleichbar mit größeren Modellen.",
  "accounts/fireworks/models/mixtral-8x22b-instruct.description": "Mixtral MoE 8x22B Instruct v0.1 ist die instruktionstunierte Version von Mixtral MoE 8x22B v0.1 mit aktivierter Chat-Completion-API.",
  "accounts/fireworks/models/mixtral-8x7b-instruct.description": "Mixtral MoE 8x7B Instruct ist die instruktionstunierte Version von Mixtral MoE 8x7B mit aktivierter Chat-Completion-API.",
  "accounts/fireworks/models/mythomax-l2-13b.description": "Eine verbesserte Variante von MythoMix, möglicherweise eine verfeinerte Form, die MythoLogic-L2 und Huginn mit einer experimentellen Tensor-Merge-Technik kombiniert. Aufgrund ihrer einzigartigen Natur eignet sie sich hervorragend für Storytelling und Rollenspiele.",
  "accounts/fireworks/models/phi-3-vision-128k-instruct.description": "Phi-3-Vision-128K-Instruct ist ein leichtgewichtiges, hochmodernes multimodales Modell, das auf synthetischen Daten und kuratierten öffentlichen Web-Datensätzen basiert. Es konzentriert sich auf qualitativ hochwertige, argumentationsintensive Text- und Bilddaten. Es gehört zur Phi-3-Familie und unterstützt eine Kontextlänge von 128.000 Tokens. Das Modell wurde durch Supervised Fine-Tuning und Direct Preference Optimization verbessert, um eine präzise Befolgung von Anweisungen und hohe Sicherheitsstandards zu gewährleisten.",
  "meta.llama3-8b-instruct-v1:0.description": "Meta Llama 3 ist ein offenes LLM für Entwickler, Forscher und Unternehmen. Es wurde entwickelt, um beim Aufbau, Experimentieren und verantwortungsvollen Skalieren generativer KI-Ideen zu unterstützen. Als Teil der Grundlage für globale Innovationsgemeinschaften eignet es sich besonders für Umgebungen mit begrenzten Rechenressourcen, Edge-Geräte und schnellere Trainingszeiten.",
  "meta/Llama-3.2-11B-Vision-Instruct.description": "Starke Bildverarbeitung bei hochauflösenden Bildern – ideal für visuelle Verständnisanwendungen.",
  "meta/Llama-3.2-90B-Vision-Instruct.description": "Fortschrittliche Bildverarbeitung für visuelle Agentenanwendungen.",
  "meta/Llama-3.3-70B-Instruct.description": "Llama 3.3 ist das fortschrittlichste mehrsprachige Open-Source-Llama-Modell mit nahezu 405B-Leistung bei sehr niedrigen Kosten. Es basiert auf Transformer-Architektur und wurde mit SFT und RLHF für Nützlichkeit und Sicherheit optimiert. Die instruktionstunierte Version ist für mehrsprachige Chats optimiert und übertrifft viele offene und geschlossene Chatmodelle in Branchenbenchmarks. Wissensstand: Dezember 2023.",
  "meta/Meta-Llama-3-70B-Instruct.description": "Ein leistungsstarkes Modell mit 70 Milliarden Parametern, das in den Bereichen logisches Denken, Programmierung und allgemeine Sprachverarbeitung überzeugt.",
  "meta/Meta-Llama-3-8B-Instruct.description": "Ein vielseitiges Modell mit 8 Milliarden Parametern, optimiert für Chat und Textgenerierung.",
  "meta/Meta-Llama-3.1-405B-Instruct.description": "Das instruktionstunierte Textmodell Llama 3.1 ist für mehrsprachige Chats optimiert und erzielt starke Ergebnisse in gängigen Branchenbenchmarks – sowohl im Vergleich zu offenen als auch geschlossenen Chatmodellen.",
  "meta/Meta-Llama-3.1-70B-Instruct.description": "Das instruktionstunierte Textmodell Llama 3.1 ist für mehrsprachige Chats optimiert und erzielt starke Ergebnisse in gängigen Branchenbenchmarks – sowohl im Vergleich zu offenen als auch geschlossenen Chatmodellen.",
  "meta/Meta-Llama-3.1-8B-Instruct.description": "Das instruktionstunierte Textmodell Llama 3.1 ist für mehrsprachige Chats optimiert und erzielt starke Ergebnisse in gängigen Branchenbenchmarks – sowohl im Vergleich zu offenen als auch geschlossenen Chatmodellen.",
  "meta/llama-3-70b.description": "Ein Open-Source-Modell mit 70 Milliarden Parametern, von Meta für das Befolgen von Anweisungen feinabgestimmt und auf Groq LPU-Hardware für schnelle, effiziente Inferenz bereitgestellt.",
  "meta/llama-3-8b.description": "Ein Open-Source-Modell mit 8 Milliarden Parametern, von Meta für das Befolgen von Anweisungen feinabgestimmt und auf Groq LPU-Hardware für schnelle, effiziente Inferenz bereitgestellt.",
  "meta/llama-3.1-405b-instruct.description": "Ein fortschrittliches LLM zur Unterstützung von synthetischer Datengenerierung, Wissensdestillation und logischem Denken für Chatbots, Programmierung und domänenspezifische Aufgaben.",
  "meta/llama-3.1-70b-instruct.description": "Entwickelt für komplexe Dialoge mit exzellentem Kontextverständnis, logischem Denken und Textgenerierung.",
  "meta/llama-3.1-70b.description": "Ein aktualisiertes Meta Llama 3 70B Instruct mit 128K Kontext, mehrsprachiger Unterstützung und verbessertem logischen Denken.",
  "meta/llama-3.1-8b-instruct.description": "Ein hochmodernes Modell mit starker Sprachverarbeitung, logischem Denken und Textgenerierung.",
  "meta/llama-3.1-8b.description": "Llama 3.1 8B unterstützt ein 128K-Kontextfenster – ideal für Echtzeit-Chats und Datenanalysen – und bietet erhebliche Kostenvorteile gegenüber größeren Modellen. Bereitgestellt auf Groq LPU-Hardware für schnelle, effiziente Inferenz.",
  "meta/llama-3.2-11b-vision-instruct.description": "Ein fortschrittliches Vision-Language-Modell, das sich durch hochwertige Bildverarbeitung auszeichnet.",
  "meta/llama-3.2-11b.description": "Ein instruktionstuniertes Modell zur Bildverarbeitung (Text+Bild-Eingabe, Text-Ausgabe), optimiert für visuelle Erkennung, Bildverständnis, Bildbeschriftung und allgemeine Bildfragen.",
  "meta/llama-3.2-1b-instruct.description": "Ein hochmodernes kleines Sprachmodell mit starker Sprachverarbeitung, logischem Denken und Textgenerierung.",
  "meta/llama-3.2-1b.description": "Textbasiertes Modell für On-Device-Anwendungen wie mehrsprachige lokale Suche, Zusammenfassungen und Umschreibungen.",
  "meta/llama-3.2-3b-instruct.description": "Ein hochmodernes kleines Sprachmodell mit starker Sprachverarbeitung, logischem Denken und Textgenerierung.",
  "meta/llama-3.2-3b.description": "Textbasiertes Modell, feinabgestimmt für On-Device-Anwendungen wie mehrsprachige lokale Suche, Zusammenfassungen und Umschreibungen.",
  "meta/llama-3.2-90b-vision-instruct.description": "Ein fortschrittliches Vision-Language-Modell, das sich durch hochwertige Bildverarbeitung auszeichnet.",
  "meta/llama-3.2-90b.description": "Ein instruktionstuniertes Modell zur Bildverarbeitung (Text+Bild-Eingabe, Text-Ausgabe), optimiert für visuelle Erkennung, Bildverständnis, Bildbeschriftung und allgemeine Bildfragen.",
  "meta/llama-3.3-70b-instruct.description": "Ein fortschrittliches LLM mit Stärken in logischem Denken, Mathematik, Alltagswissen und Funktionsaufrufen.",
  "meta/llama-3.3-70b.description": "Ein perfektes Gleichgewicht zwischen Leistung und Effizienz. Entwickelt für leistungsstarke Konversations-KI in der Inhaltserstellung, Unternehmensanwendungen und Forschung – mit starker Sprachverarbeitung für Zusammenfassungen, Klassifikation, Sentimentanalyse und Codegenerierung.",
  "meta/llama-4-maverick.description": "Die Llama-4-Familie ist eine native multimodale KI-Modellreihe, die Text- und Multimodalerlebnisse unterstützt. Sie nutzt MoE für führendes Text- und Bildverständnis. Llama 4 Maverick ist ein 17B-Modell mit 128 Experten, bereitgestellt von DeepInfra.",
  "meta/llama-4-scout.description": "Die Llama-4-Familie ist eine native multimodale KI-Modellreihe, die Text- und Multimodalerlebnisse unterstützt. Sie nutzt MoE für führendes Text- und Bildverständnis. Llama 4 Scout ist ein 17B-Modell mit 16 Experten, bereitgestellt von DeepInfra.",
  "moonshot-v1-128k-vision-preview.description": "Kimi Vision-Modelle (einschließlich moonshot-v1-8k-vision-preview/moonshot-v1-32k-vision-preview/moonshot-v1-128k-vision-preview) können Bildinhalte wie Text, Farben und Objektformen verstehen.",
  "moonshot-v1-128k.description": "Moonshot V1 128K bietet einen extrem langen Kontext für die Generierung sehr langer Texte und verarbeitet bis zu 128.000 Tokens – ideal für Forschung, akademische Arbeiten und Szenarien mit umfangreichen Dokumenten.",
  "moonshot-v1-32k-vision-preview.description": "Kimi Vision-Modelle (einschließlich moonshot-v1-8k-vision-preview/moonshot-v1-32k-vision-preview/moonshot-v1-128k-vision-preview) können Bildinhalte wie Text, Farben und Objektformen verstehen.",
  "moonshot-v1-32k.description": "Moonshot V1 32K unterstützt 32.768 Tokens für mittellange Kontexte – ideal für lange Dokumente und komplexe Dialoge in der Inhaltserstellung, Berichterstattung und Chat-Systemen.",
  "moonshot-v1-8k-vision-preview.description": "Kimi Vision-Modelle (einschließlich moonshot-v1-8k-vision-preview/moonshot-v1-32k-vision-preview/moonshot-v1-128k-vision-preview) können Bildinhalte wie Text, Farben und Objektformen verstehen.",
  "moonshot-v1-8k.description": "Moonshot V1 8K ist für die Generierung kurzer Texte mit effizienter Leistung optimiert und verarbeitet 8.192 Tokens – ideal für kurze Chats, Notizen und schnelle Inhalte.",
  "moonshot-v1-auto.description": "Moonshot V1 Auto wählt automatisch das passende Modell basierend auf der aktuellen Token-Nutzung im Kontext aus.",
  "moonshotai/Kimi-Dev-72B.description": "Kimi-Dev-72B ist ein quelloffenes Code-LLM, das mit großflächigem RL optimiert wurde, um robuste, produktionsreife Patches zu erzeugen. Es erreicht 60,4 % auf SWE-bench Verified und setzt damit einen neuen Rekord für Open-Modelle bei automatisierten Softwareentwicklungsaufgaben wie Bugfixing und Code-Review.",
  "moonshotai/Kimi-K2-Instruct-0905.description": "Kimi K2-Instruct-0905 ist das neueste und leistungsstärkste Modell der Kimi K2-Reihe. Es handelt sich um ein MoE-Spitzenmodell mit insgesamt 1T und 32B aktiven Parametern. Zu den Hauptmerkmalen gehören eine stärkere agentenbasierte Codierungsintelligenz mit deutlichen Verbesserungen bei Benchmarks und realen Agentenaufgaben sowie eine verbesserte Ästhetik und Benutzerfreundlichkeit im Frontend-Code.",
  "moonshotai/Kimi-K2-Thinking.description": "Kimi K2 Thinking ist das neueste und leistungsstärkste quelloffene Modell für Denkprozesse. Es erweitert die Tiefe des mehrstufigen Denkens erheblich und ermöglicht eine stabile Werkzeugnutzung über 200–300 aufeinanderfolgende Aufrufe hinweg. Es setzt neue Maßstäbe bei Humanity's Last Exam (HLE), BrowseComp und anderen Benchmarks. Es glänzt in den Bereichen Programmierung, Mathematik, Logik und Agentenszenarien. Basierend auf einer MoE-Architektur mit ~1T Gesamtparametern unterstützt es ein Kontextfenster von 256K und Tool-Aufrufe.",
  "moonshotai/kimi-k2-0711.description": "Kimi K2 0711 ist die Instruct-Variante der Kimi-Serie, geeignet für hochwertigen Code und Werkzeugnutzung.",
  "moonshotai/kimi-k2-0905.description": "Kimi K2 0905 ist ein Update mit erweitertem Kontext und verbesserter Denkfähigkeit sowie Optimierungen für die Programmierung.",
  "moonshotai/kimi-k2-instruct-0905.description": "Das Modell kimi-k2-0905-preview unterstützt ein Kontextfenster von 256K, bietet stärkere agentenbasierte Codierung, ausgereifteren und praxisnahen Frontend-Code sowie ein besseres Kontextverständnis.",
  "moonshotai/kimi-k2-thinking-turbo.description": "Kimi K2 Thinking Turbo ist eine Hochgeschwindigkeitsversion von Kimi K2 Thinking mit deutlich reduzierter Latenz bei gleichbleibender Tiefe im Denkprozess.",
  "moonshotai/kimi-k2-thinking.description": "Kimi K2 Thinking ist Moonshots Modell für Denkprozesse, optimiert für tiefgehende Aufgaben mit allgemeinen Agentenfähigkeiten.",
  "moonshotai/kimi-k2.description": "Kimi K2 ist ein großes MoE-Modell von Moonshot AI mit 1T Gesamtparametern und 32B aktiven Parametern pro Durchlauf. Es ist optimiert für Agentenfähigkeiten wie fortgeschrittene Werkzeugnutzung, logisches Denken und Code-Synthese.",
  "morph/morph-v3-fast.description": "Morph bietet ein spezialisiertes Modell, um Codeänderungen anzuwenden, die von fortschrittlichen Modellen (z. B. Claude oder GPT-4o) vorgeschlagen wurden – mit über 4500 Tokens/Sek. Es ist der letzte Schritt in einem KI-Coding-Workflow und unterstützt 16k Eingabe-/Ausgabe-Tokens.",
  "morph/morph-v3-large.description": "Morph bietet ein spezialisiertes Modell, um Codeänderungen anzuwenden, die von fortschrittlichen Modellen (z. B. Claude oder GPT-4o) vorgeschlagen wurden – mit über 2500 Tokens/Sek. Es ist der letzte Schritt in einem KI-Coding-Workflow und unterstützt 16k Eingabe-/Ausgabe-Tokens.",
  "nousresearch/hermes-2-pro-llama-3-8b.description": "Hermes 2 Pro Llama 3 8B ist eine aktualisierte Version von Nous Hermes 2 mit den neuesten intern entwickelten Datensätzen.",
  "nvidia/Llama-3.1-Nemotron-70B-Instruct-HF.description": "Llama 3.1 Nemotron 70B ist ein von NVIDIA angepasstes LLM zur Verbesserung der Nützlichkeit. Es erzielt Spitzenwerte bei Arena Hard, AlpacaEval 2 LC und GPT-4-Turbo MT-Bench und belegt am 1. Oktober 2024 Platz 1 in allen drei Auto-Alignment-Benchmarks. Es wurde aus Llama-3.1-70B-Instruct mithilfe von RLHF (REINFORCE), Llama-3.1-Nemotron-70B-Reward und HelpSteer2-Preference-Prompts trainiert.",
  "nvidia/llama-3.1-nemotron-51b-instruct.description": "Ein einzigartiges Sprachmodell mit außergewöhnlicher Genauigkeit und Effizienz.",
  "nvidia/llama-3.1-nemotron-70b-instruct.description": "Llama-3.1-Nemotron-70B-Instruct ist ein von NVIDIA entwickeltes Modell zur Verbesserung der Nützlichkeit von LLM-Antworten.",
  "o1-mini.description": "Kleiner und schneller als o1-preview, 80 % geringere Kosten, stark bei Codegenerierung und Aufgaben mit kurzem Kontext.",
  "o1-preview.description": "Fokussiert auf fortgeschrittenes Denken und komplexe Problemlösung, einschließlich Mathematik und Naturwissenschaften. Ideal für Anwendungen mit tiefem Kontextverständnis und autonomen Workflows.",
  "o1-pro.description": "Die o1-Serie wurde mit Reinforcement Learning trainiert, um vor der Antwort zu denken und komplexe Denkprozesse zu bewältigen. o1-pro nutzt mehr Rechenleistung für tiefere Überlegungen und liefert konsistent hochwertigere Antworten.",
  "o1.description": "o1 ist OpenAIs neues Modell für Denkprozesse mit Text- und Bildeingabe sowie Textausgabe – geeignet für komplexe Aufgaben mit breitem Wissen. Es verfügt über ein Kontextfenster von 200K und einen Wissensstand von Oktober 2023.",
  "phi3:14b.description": "Phi-3 ist Microsofts leichtgewichtiges Open-Model für effiziente Integration und groß angelegte Schlussfolgerungen.",
  "pixtral-12b-2409.description": "Pixtral überzeugt bei der Analyse von Diagrammen/Bildern, Dokumenten-QA, multimodaler Schlussfolgerung und Befolgen von Anweisungen. Es verarbeitet Bilder in nativer Auflösung und Seitenverhältnis und unterstützt beliebig viele Bilder im 128K-Kontextfenster.",
  "pixtral-large-latest.description": "Pixtral Large ist ein multimodales Open-Model mit 124 Milliarden Parametern, basierend auf Mistral Large 2 – dem zweiten Modell unserer multimodalen Familie mit fortschrittlichem Bildverständnis.",
  "pro-128k.description": "Spark Pro 128K bietet eine sehr große Kontextkapazität mit bis zu 128K Kontext – ideal für Langform-Dokumente, die eine vollständige Textanalyse und kohärente Logik über große Distanzen erfordern, mit flüssiger Argumentation und vielfältiger Zitatunterstützung in komplexen Diskussionen.",
  "pro-deepseek-r1.description": "Dediziertes Enterprise-Service-Modell mit gebündelter Parallelverarbeitung.",
  "pro-deepseek-v3.description": "Dediziertes Enterprise-Service-Modell mit gebündelter Parallelverarbeitung.",
  "qianfan-70b.description": "Qianfan 70B ist ein großes chinesisches Modell für hochwertige Textgenerierung und komplexe Schlussfolgerungen.",
  "qianfan-8b.description": "Qianfan 8B ist ein mittelgroßes Allzweckmodell, das Kosten und Qualität bei Textgenerierung und QA ausbalanciert.",
  "qianfan-agent-intent-32k.description": "Qianfan Agent Intent 32K ist auf Absichtserkennung und Agentenkoordination mit Unterstützung für langen Kontext ausgelegt.",
  "qianfan-agent-lite-8k.description": "Qianfan Agent Lite 8K ist ein leichtgewichtiges Agentenmodell für kostengünstige Mehrfachdialoge und Workflows.",
  "qianfan-agent-speed-32k.description": "Qianfan Agent Speed 32K ist ein leistungsstarkes Agentenmodell für groß angelegte, mehrstufige Agentenanwendungen.",
  "qianfan-agent-speed-8k.description": "Qianfan Agent Speed 8K ist ein hochgradig paralleles Agentenmodell für kurze bis mittellange Gespräche mit schneller Reaktion.",
  "qianfan-check-vl.description": "Qianfan Check VL ist ein multimodales Modell zur Inhaltsprüfung für Bild-Text-Konformität und Erkennungsaufgaben.",
  "qianfan-composition.description": "Qianfan Composition ist ein multimodales Kreativmodell für gemischtes Bild-Text-Verständnis und -Generierung.",
  "qianfan-engcard-vl.description": "Qianfan EngCard VL ist ein multimodales Erkennungsmodell mit Fokus auf englischsprachige Szenarien.",
  "qianfan-lightning-128b-a19b.description": "Qianfan Lightning 128B A19B ist ein leistungsstarkes chinesisches Allzweckmodell für komplexe QA und groß angelegte Schlussfolgerungen.",
  "qianfan-llama-vl-8b.description": "Qianfan Llama VL 8B ist ein auf Llama basierendes multimodales Modell für allgemeines Bild-Text-Verständnis.",
  "qianfan-multipicocr.description": "Qianfan MultiPicOCR ist ein OCR-Modell für mehrere Bilder zur Texterkennung und -extraktion über verschiedene Bilder hinweg.",
  "qianfan-qi-vl.description": "Qianfan QI VL ist ein multimodales QA-Modell für präzise Informationsabfrage und QA in komplexen Bild-Text-Szenarien.",
  "qianfan-singlepicocr.description": "Qianfan SinglePicOCR ist ein OCR-Modell für Einzelbilder mit hochpräziser Zeichenerkennung.",
  "qianfan-vl-70b.description": "Qianfan VL 70B ist ein großes VLM für komplexes Bild-Text-Verständnis.",
  "qianfan-vl-8b.description": "Qianfan VL 8B ist ein leichtgewichtiges VLM für alltägliche Bild-Text-QA und -Analyse.",
  "qvq-72b-preview.description": "QVQ-72B-Preview ist ein experimentelles Forschungsmodell von Qwen mit Fokus auf verbesserte visuelle Schlussfolgerung.",
  "qvq-max.description": "Qwen QVQ ist ein Modell für visuelle Schlussfolgerung mit Bildinput und Chain-of-Thought-Ausgabe, mit starker Leistung in Mathematik, Programmierung, visueller Analyse, Kreativität und allgemeinen Aufgaben.",
  "qvq-plus.description": "Modell für visuelle Schlussfolgerung mit Bildinput und Chain-of-Thought-Ausgabe. Die qvq-plus-Serie folgt auf qvq-max und bietet schnellere Schlussfolgerung bei besserem Verhältnis von Qualität zu Kosten.",
  "qwen-3-32b.description": "Qwen 3 32B: stark in mehrsprachigen und Programmieraufgaben, geeignet für mittlere Produktionsszenarien.",
  "qwen-coder-plus.description": "Qwen-Code-Modell.",
  "qwen-coder-turbo-latest.description": "Qwen-Code-Modell.",
  "qwen-coder-turbo.description": "Qwen-Code-Modell.",
  "qwen-flash.description": "Schnellstes und kostengünstigstes Qwen-Modell, ideal für einfache Aufgaben.",
  "qwen-image-edit.description": "Qwen Image Edit ist ein Bild-zu-Bild-Modell, das Bilder basierend auf Eingabebildern und Textanweisungen bearbeitet – für präzise Anpassungen und kreative Transformationen.",
  "qwen-image.description": "Qwen-Image ist ein allgemeines Bildgenerierungsmodell mit Unterstützung für verschiedene Kunststile und starker Textdarstellung, insbesondere in Chinesisch und Englisch. Es unterstützt mehrzeilige Layouts, Absatztexte und feine Details für komplexe Text-Bild-Layouts.",
  "qwen-long.description": "Ultragroßes Qwen-Modell mit langem Kontext und Chat über lange und mehrteilige Dokumente hinweg.",
  "qwen-math-plus-latest.description": "Qwen Math ist ein Sprachmodell, das auf das Lösen mathematischer Probleme spezialisiert ist.",
  "qwen-math-plus.description": "Qwen Math ist ein Sprachmodell, das auf das Lösen mathematischer Probleme spezialisiert ist.",
  "qwen-math-turbo-latest.description": "Qwen Math ist ein Sprachmodell, das auf das Lösen mathematischer Probleme spezialisiert ist.",
  "qwen-math-turbo.description": "Qwen Math ist ein Sprachmodell, das auf das Lösen mathematischer Probleme spezialisiert ist.",
  "qwen-max.description": "Ultragroßes Qwen-Modell im Hundert-Milliarden-Bereich mit Unterstützung für Chinesisch, Englisch und weitere Sprachen; das API-Modell hinter den aktuellen Qwen2.5-Produkten.",
  "qwen-omni-turbo.description": "Qwen-Omni-Modelle unterstützen multimodale Eingaben (Video, Audio, Bilder, Text) und geben Audio und Text aus.",
  "qwen-plus.description": "Erweitertes ultragroßes Qwen-Modell mit Unterstützung für Chinesisch, Englisch und weitere Sprachen.",
  "qwen-turbo.description": "Qwen Turbo wird nicht mehr aktualisiert; bitte durch Qwen Flash ersetzen. Ultragroßes Qwen-Modell mit Unterstützung für Chinesisch, Englisch und weitere Sprachen.",
  "qwen-vl-chat-v1.description": "Qwen VL unterstützt flexible Interaktionen, darunter Mehrbild-Eingaben, mehrstufige QA und kreative Aufgaben.",
  "qwen-vl-max-latest.description": "Ultragroßes Qwen Vision-Language-Modell. Im Vergleich zur erweiterten Version verbessert es visuelle Schlussfolgerung und Befolgen von Anweisungen für stärkere Wahrnehmung und Kognition.",
  "qwen-vl-max.description": "Ultragroßes Qwen Vision-Language-Modell. Im Vergleich zur erweiterten Version verbessert es visuelle Schlussfolgerung und Befolgen von Anweisungen für stärkere visuelle Wahrnehmung und Kognition.",
  "qwen-vl-ocr.description": "Qwen OCR ist ein Modell zur Textextraktion aus Dokumenten, Tabellen, Prüfungsbildern und Handschrift. Es unterstützt Chinesisch, Englisch, Französisch, Japanisch, Koreanisch, Deutsch, Russisch, Italienisch, Vietnamesisch und Arabisch.",
  "qwen-vl-plus-latest.description": "Erweitertes großskaliges Qwen Vision-Language-Modell mit deutlichen Verbesserungen bei Detail- und Texterkennung, unterstützt Auflösungen über 1 Megapixel und beliebige Seitenverhältnisse.",
  "qwen-vl-plus.description": "Erweitertes großskaliges Qwen Vision-Language-Modell mit deutlichen Verbesserungen bei Detail- und Texterkennung, unterstützt Auflösungen über 1 Megapixel und beliebige Seitenverhältnisse.",
  "qwen-vl-v1.description": "Vortrainiertes Modell, initialisiert von Qwen-7B mit zusätzlichem Vision-Modul und 448er Bildauflösung.",
  "qwen/qwen-2-7b-instruct.description": "Qwen2 ist die neue Qwen-LLM-Serie. Qwen2 7B ist ein Transformer-basiertes Modell, das in Sprachverständnis, Mehrsprachigkeit, Programmierung, Mathematik und Schlussfolgerung überzeugt.",
  "qwen/qwen-2-7b-instruct:free.description": "Qwen2 ist eine neue Familie großer Sprachmodelle mit verbessertem Verständnis und Generierung.",
  "qwen2.5-14b-instruct-1m.description": "Qwen2.5 Open-Source-Modell mit 72 Milliarden Parametern.",
  "qwen2.5-14b-instruct.description": "Qwen2.5 Open-Source-Modell mit 14 Milliarden Parametern.",
  "qwen2.5-32b-instruct.description": "Qwen2.5 Open-Source-Modell mit 32 Milliarden Parametern.",
  "qwen2.5-72b-instruct.description": "Qwen2.5 Open-Source-Modell mit 72 Milliarden Parametern.",
  "qwen2.5-7b-instruct.description": "Qwen2.5 7B Instruct ist ein ausgereiftes Open-Source-Instruct-Modell für Chat- und Generierungsaufgaben in verschiedenen Szenarien.",
  "qwen2.5-coder-1.5b-instruct.description": "Open-Source-Qwen-Code-Modell.",
  "qwen2.5-coder-14b-instruct.description": "Open-Source-Qwen-Code-Modell.",
  "qwen2.5-coder-32b-instruct.description": "Open-Source-Qwen-Code-Modell.",
  "qwen2.5-coder-7b-instruct.description": "Open-Source-Qwen-Code-Modell.",
  "qwen2.5-coder-instruct.description": "Qwen2.5-Coder ist das neueste codefokussierte LLM der Qwen-Familie (ehemals CodeQwen).",
  "qwen2.5-instruct.description": "Qwen2.5 ist die neueste LLM-Serie von Qwen mit Basis- und Instruct-Modellen von 0,5 bis 72 Milliarden Parametern.",
  "qwen2.5-math-1.5b-instruct.description": "Qwen-Math bietet starke Fähigkeiten zur Lösung mathematischer Probleme.",
  "qwen2.5-math-72b-instruct.description": "Qwen-Math bietet starke Fähigkeiten zur Lösung mathematischer Probleme.",
  "qwen2.5-math-7b-instruct.description": "Qwen-Math bietet starke Fähigkeiten zur Lösung mathematischer Probleme.",
  "qwen2.5-omni-7b.description": "Qwen-Omni-Modelle unterstützen multimodale Eingaben (Video, Audio, Bilder, Text) und geben Audio und Text aus.",
  "qwen2.5-vl-32b-instruct.description": "Qwen2.5 VL 32B Instruct ist ein Open-Source-Multimodalmodell, geeignet für private Bereitstellung und vielseitige Einsatzszenarien.",
  "qwen2.5-vl-72b-instruct.description": "Verbessertes Befolgen von Anweisungen, Mathematik, Problemlösung und Programmierung mit stärkerer Objekterkennung. Unterstützt präzise Lokalisierung visueller Elemente über Formate hinweg, Verständnis langer Videos (bis zu 10 Minuten) mit sekundengenauer Ereigniserkennung, zeitlicher Reihenfolge und Geschwindigkeitsverständnis sowie Agentensteuerung von Betriebssystemen oder Mobilgeräten durch Parsing und Lokalisierung. Starke Extraktion von Schlüsselinformationen und JSON-Ausgabe. Dies ist die 72B-Version, die leistungsstärkste der Serie.",
  "qwen2.5-vl-7b-instruct.description": "Qwen2.5 VL 7B Instruct ist ein leichtgewichtiges multimodales Modell mit ausgewogenem Verhältnis zwischen Bereitstellungskosten und Erkennungsleistung.",
  "qwen2.5-vl-instruct.description": "Qwen2.5-VL ist das neueste Vision-Language-Modell der Qwen-Familie.",
  "qwen2.5.description": "Qwen2.5 ist Alibabas nächste Generation eines großen Sprachmodells mit starker Leistung in vielfältigen Anwendungsfällen.",
  "qwen2.5:0.5b.description": "Qwen2.5 ist Alibabas nächste Generation eines großen Sprachmodells mit starker Leistung in vielfältigen Anwendungsfällen.",
  "qwen2.5:1.5b.description": "Qwen2.5 ist Alibabas nächste Generation eines großen Sprachmodells mit starker Leistung in vielfältigen Anwendungsfällen.",
  "qwen2.5:72b.description": "Qwen2.5 ist Alibabas nächste Generation eines großen Sprachmodells mit starker Leistung in vielfältigen Anwendungsfällen.",
  "qwen2.description": "Qwen2 ist Alibabas nächste Generation eines großen Sprachmodells mit starker Leistung in vielfältigen Anwendungsfällen.",
  "qwen2:0.5b.description": "Qwen2 ist Alibabas nächste Generation eines großen Sprachmodells mit starker Leistung in vielfältigen Anwendungsfällen.",
  "qwen2:1.5b.description": "Qwen2 ist Alibabas nächste Generation eines großen Sprachmodells mit starker Leistung in vielfältigen Anwendungsfällen.",
  "qwen2:72b.description": "Qwen2 ist Alibabas nächste Generation eines großen Sprachmodells mit starker Leistung in vielfältigen Anwendungsfällen.",
  "qwen3-0.6b.description": "Qwen3 0.6B ist ein Einstiegsmodell für einfache Schlussfolgerungen und stark eingeschränkte Umgebungen.",
  "qwen3-1.7b.description": "Qwen3 1.7B ist ein ultraleichtes Modell für Edge- und Gerätebereitstellungen.",
  "qwen3-14b.description": "Qwen3 14B ist ein mittelgroßes Modell für mehrsprachige Frage-Antwort-Systeme und Textgenerierung.",
  "qwen3-235b-a22b-instruct-2507.description": "Qwen3 235B A22B Instruct 2507 ist ein Flaggschiff-Instruct-Modell für eine Vielzahl von Generierungs- und Denkaufgaben.",
  "qwen3-235b-a22b-thinking-2507.description": "Qwen3 235B A22B Thinking 2507 ist ein ultragroßes Denkmodell für anspruchsvolle Schlussfolgerungen.",
  "qwen3-235b-a22b.description": "Qwen3 235B A22B ist ein allgemeines Großmodell für komplexe Aufgaben.",
  "qwen3-30b-a3b-instruct-2507.description": "Qwen3 30B A3B Instruct 2507 ist ein mittelgroßes Instruct-Modell für hochwertige Generierung und Frage-Antwort-Aufgaben.",
  "qwen3-30b-a3b-thinking-2507.description": "Qwen3 30B A3B Thinking 2507 ist ein mittelgroßes Denkmodell mit ausgewogenem Verhältnis zwischen Genauigkeit und Kosten.",
  "qwen3-30b-a3b.description": "Qwen3 30B A3B ist ein mittelgroßes allgemeines Modell mit ausgewogenem Verhältnis zwischen Kosten und Qualität.",
  "qwen3-32b.description": "Qwen3 32B eignet sich für allgemeine Aufgaben, die ein tieferes Verständnis erfordern.",
  "qwen3-4b.description": "Qwen3 4B eignet sich für kleine bis mittlere Anwendungen und lokale Inferenz.",
  "qwen3-8b.description": "Qwen3 8B ist ein leichtgewichtiges Modell mit flexibler Bereitstellung für hochparallele Arbeitslasten.",
  "qwen3-coder-30b-a3b-instruct.description": "Open-Source-Qwen-Code-Modell. Das neueste qwen3-coder-30b-a3b-instruct basiert auf Qwen3 und bietet starke Fähigkeiten für Coding-Agenten, Werkzeugnutzung und Interaktion mit Umgebungen für autonomes Programmieren, mit exzellenter Codeleistung und solider Allgemeinkompetenz.",
  "qwen3-coder-480b-a35b-instruct.description": "Qwen3 Coder 480B A35B Instruct ist ein Flaggschiff-Code-Modell für mehrsprachige Programmierung und komplexes Codeverständnis.",
  "qwen3-coder-flash.description": "Qwen-Code-Modell. Die neueste Qwen3-Coder-Serie basiert auf Qwen3 und bietet starke Fähigkeiten für Coding-Agenten, Werkzeugnutzung und Interaktion mit Umgebungen für autonomes Programmieren, mit exzellenter Codeleistung und solider Allgemeinkompetenz.",
  "qwen3-coder-plus.description": "Qwen-Code-Modell. Die neueste Qwen3-Coder-Serie basiert auf Qwen3 und bietet starke Fähigkeiten für Coding-Agenten, Werkzeugnutzung und Interaktion mit Umgebungen für autonomes Programmieren, mit exzellenter Codeleistung und solider Allgemeinkompetenz.",
  "qwen3-coder:480b.description": "Alibabas leistungsstarkes Langkontextmodell für Agenten- und Programmieraufgaben.",
  "qwen3-max-preview.description": "Leistungsstärkstes Qwen-Modell für komplexe, mehrstufige Aufgaben. Die Vorschau unterstützt Denkprozesse.",
  "qwen3-max.description": "Qwen3 Max-Modelle bieten große Fortschritte gegenüber der 2.5-Serie in allgemeiner Fähigkeit, chinesisch/englischem Verständnis, komplexer Anweisungsbefolgung, offenen subjektiven Aufgaben, Mehrsprachigkeit und Werkzeugnutzung bei weniger Halluzinationen. Das neueste qwen3-max verbessert agentisches Programmieren und Werkzeugnutzung gegenüber qwen3-max-preview. Diese Version erreicht SOTA-Niveau und zielt auf komplexere Agentenanforderungen.",
  "qwen3-next-80b-a3b-instruct.description": "Nächste Generation des Qwen3 Open-Source-Modells ohne Denkfunktion. Im Vergleich zur vorherigen Version (Qwen3-235B-A22B-Instruct-2507) bietet es besseres chinesisches Verständnis, stärkere logische Schlussfolgerung und verbesserte Textgenerierung.",
  "qwen3-next-80b-a3b-thinking.description": "Qwen3 Next 80B A3B Thinking ist die Flaggschiff-Denkversion für komplexe Aufgaben.",
  "qwen3-omni-flash.description": "Qwen-Omni akzeptiert kombinierte Eingaben aus Text, Bildern, Audio und Video und gibt Text oder Sprache aus. Es bietet mehrere natürliche Sprachstile, unterstützt mehrsprachige und dialektale Sprache und eignet sich für Anwendungsfälle wie Schreiben, visuelle Erkennung und Sprachassistenten.",
  "qwen3-vl-235b-a22b-instruct.description": "Qwen3 VL 235B A22B Instruct ist ein Flaggschiff-Multimodalmodell für anspruchsvolles Verständnis und kreative Aufgaben.",
  "qwen3-vl-235b-a22b-thinking.description": "Qwen3 VL 235B A22B Thinking ist die Flaggschiff-Denkversion für komplexes multimodales Denken und Planung.",
  "qwen3-vl-30b-a3b-instruct.description": "Qwen3 VL 30B A3B Instruct ist ein großes multimodales Modell mit ausgewogenem Verhältnis zwischen Genauigkeit und Denkleistung.",
  "qwen3-vl-30b-a3b-thinking.description": "Qwen3 VL 30B A3B Thinking ist eine tiefdenkende Version für komplexe multimodale Aufgaben.",
  "qwen3-vl-32b-instruct.description": "Qwen3 VL 32B Instruct ist ein multimodales Instruct-Modell für hochwertige Bild-Text-Fragen und -Generierung.",
  "qwen3-vl-32b-thinking.description": "Qwen3 VL 32B Thinking ist eine tiefdenkende multimodale Version für komplexe Schlussfolgerungen und Langkettenanalysen.",
  "qwen3-vl-8b-instruct.description": "Qwen3 VL 8B Instruct ist ein leichtgewichtiges multimodales Modell für alltägliche visuelle Fragen und App-Integration.",
  "qwen3-vl-8b-thinking.description": "Qwen3 VL 8B Thinking ist ein multimodales Chain-of-Thought-Modell für detailliertes visuelles Denken.",
  "qwen3-vl-flash.description": "Qwen3 VL Flash: leichtgewichtige, hochschnelle Denkversion für latenzempfindliche oder hochvolumige Anfragen.",
  "qwen3-vl-plus.description": "Qwen VL ist ein Textgenerierungsmodell mit Bildverständnis. Es kann OCR durchführen sowie zusammenfassen und schlussfolgern, z. B. Attribute aus Produktfotos extrahieren oder Probleme aus Bildern lösen.",
  "qwen3.description": "Qwen3 ist Alibabas nächste Generation eines großen Sprachmodells mit starker Leistung in vielfältigen Anwendungsfällen.",
  "taichu_llm.description": "Trainiert mit umfangreichen hochwertigen Daten, mit verbesserter Textverständnis, Inhaltserstellung und dialogbasierter Fragebeantwortung.",
  "taichu_o1.description": "taichu_o1 ist ein Next-Gen-Reasoning-Modell, das multimodale Interaktion und Reinforcement Learning nutzt, um menschenähnliches Denken in Ketten zu ermöglichen. Es unterstützt komplexe Entscheidungssimulationen, legt Denkpfade offen und liefert hochpräzise Ergebnisse – ideal für strategische Analysen und tiefgehendes Denken.",
  "taichu_vl.description": "Kombiniert Bildverständnis, Wissensübertragung und logische Zuordnung – herausragend bei Bild-Text-Fragen.",
  "tencent/Hunyuan-A13B-Instruct.description": "Hunyuan-A13B-Instruct nutzt insgesamt 80B Parameter, davon 13B aktiv, um mit größeren Modellen zu konkurrieren. Es unterstützt hybrides schnelles/langsames Denken, stabiles Langtextverständnis und führende Agentenfähigkeiten auf BFCL-v3 und τ-Bench. GQA- und Multi-Quant-Formate ermöglichen effiziente Inferenz.",
  "tencent/Hunyuan-MT-7B.description": "Das Hunyuan-Übersetzungsmodell umfasst Hunyuan-MT-7B und das Ensemble Hunyuan-MT-Chimera. Hunyuan-MT-7B ist ein leichtgewichtiges 7B-Modell, das 33 Sprachen sowie 5 chinesische Minderheitensprachen unterstützt. Bei WMT25 erzielte es 30 erste Plätze in 31 Sprachpaaren. Tencent Hunyuan verwendet eine vollständige Trainingspipeline von Pretraining über SFT bis hin zu RL für Übersetzung und Ensemble, und erreicht führende Leistung bei einfacher, effizienter Bereitstellung.",
  "text-embedding-3-large.description": "Das leistungsfähigste Embedding-Modell für englische und nicht-englische Aufgaben.",
  "text-embedding-3-small.description": "Ein effizientes, kostengünstiges Next-Gen-Embedding-Modell für Retrieval- und RAG-Szenarien.",
  "thudm/glm-4-32b.description": "GLM-4-32B-0414 ist ein 32B zweisprachiges (Chinesisch/Englisch) Open-Weights-Modell, optimiert für Codegenerierung, Funktionsaufrufe und Agentenaufgaben. Es wurde mit 15T hochwertigen, reasoning-intensiven Daten vortrainiert und durch menschliche Präferenzanpassung, Rejection Sampling und RL weiter verfeinert. Es überzeugt bei komplexem Denken, Artefakterstellung und strukturierten Ausgaben und erreicht GPT-4o- und DeepSeek-V3-0324-Niveau in mehreren Benchmarks.",
  "thudm/glm-4-32b:free.description": "GLM-4-32B-0414 ist ein 32B zweisprachiges (Chinesisch/Englisch) Open-Weights-Modell, optimiert für Codegenerierung, Funktionsaufrufe und Agentenaufgaben. Es wurde mit 15T hochwertigen, reasoning-intensiven Daten vortrainiert und durch menschliche Präferenzanpassung, Rejection Sampling und RL weiter verfeinert. Es überzeugt bei komplexem Denken, Artefakterstellung und strukturierten Ausgaben und erreicht GPT-4o- und DeepSeek-V3-0324-Niveau in mehreren Benchmarks.",
  "thudm/glm-4-9b-chat.description": "Die Open-Source-Version des neuesten GLM-4-Pretraining-Modells von Zhipu AI.",
  "thudm/glm-z1-32b.description": "GLM-Z1-32B-0414 ist eine erweiterte Reasoning-Variante von GLM-4-32B, entwickelt für tiefgehende Mathematik-, Logik- und Code-Problemlösungen. Es nutzt erweitertes RL (aufgabenbezogene und allgemeine paarweise Präferenzen), um komplexe mehrstufige Aufgaben zu verbessern. Im Vergleich zu GLM-4-32B verbessert Z1 strukturiertes Denken und formale Fähigkeiten deutlich.\n\nEs unterstützt das Erzwingen von „Denk“-Schritten durch Prompt Engineering, verbesserte Kohärenz bei langen Ausgaben und ist für Agenten-Workflows mit langem Kontext (via YaRN), JSON-Toolaufrufen und feingranularer Abtastung für stabiles Denken optimiert. Ideal für Anwendungsfälle, die sorgfältige mehrstufige oder formale Herleitungen erfordern.",
  "thudm/glm-z1-rumination-32b.description": "GLM Z1 Rumination 32B ist ein 32B Deep-Reasoning-Modell der GLM-4-Z1-Serie, optimiert für komplexe, offene Aufgaben, die langes Nachdenken erfordern. Basierend auf glm-4-32b-0414 fügt es zusätzliche RL-Stufen und mehrstufige Ausrichtung hinzu und führt eine „Rumination“-Fähigkeit ein, die erweitertes kognitives Denken simuliert. Dazu gehören iteratives Denken, Multi-Hop-Analyse und werkzeuggestützte Workflows wie Suche, Retrieval und zitierbewusste Synthese.\n\nEs überzeugt bei wissenschaftlichem Schreiben, vergleichender Analyse und komplexer QA. Es unterstützt Funktionsaufrufe für Such-/Navigationsprimitive (`search`, `click`, `open`, `finish`) für Agentenpipelines. Das Rumination-Verhalten wird durch mehrstufige Schleifen mit regelbasierter Belohnungsgestaltung und verzögerten Entscheidungsmechanismen gesteuert und an tiefgreifenden Forschungsframeworks wie OpenAIs internem Alignment-Stack gemessen. Diese Variante priorisiert Tiefe vor Geschwindigkeit.",
  "tngtech/deepseek-r1t-chimera:free.description": "DeepSeek-R1T-Chimera wurde durch die Kombination von DeepSeek-R1 und DeepSeek-V3 (0324) entwickelt und vereint R1-Reasoning mit V3-Token-Effizienz. Es basiert auf dem DeepSeek-MoE-Transformer und ist für allgemeine Textgenerierung optimiert.\n\nEs kombiniert vortrainierte Gewichte, um ein Gleichgewicht zwischen Denken, Effizienz und Befolgen von Anweisungen zu erreichen. Veröffentlicht unter der MIT-Lizenz für Forschung und kommerzielle Nutzung.",
  "togethercomputer/StripedHyena-Nous-7B.description": "StripedHyena Nous (7B) bietet durch seine Architektur und Strategie eine verbesserte Recheneffizienz.",
  "tts-1-hd.description": "Das neueste Text-to-Speech-Modell, optimiert für höchste Qualität.",
  "tts-1.description": "Das neueste Text-to-Speech-Modell, optimiert für Echtzeitgeschwindigkeit.",
  "upstage/SOLAR-10.7B-Instruct-v1.0.description": "Upstage SOLAR Instruct v1 (11B) ist auf präzise Anweisungsaufgaben abgestimmt und bietet starke Sprachleistung.",
  "us.anthropic.claude-3-5-sonnet-20241022-v2:0.description": "Claude 3.5 Sonnet setzt neue Branchenstandards, übertrifft Wettbewerber und Claude 3 Opus in umfassenden Bewertungen – bei gleichbleibender mittlerer Geschwindigkeit und Kosten.",
  "us.anthropic.claude-3-7-sonnet-20250219-v1:0.description": "Claude 3.7 Sonnet ist das schnellste Next-Gen-Modell von Anthropic. Im Vergleich zu Claude 3 Haiku verbessert es sich in allen Bereichen und übertrifft das bisherige Flaggschiff Claude 3 Opus in vielen Intelligenzbenchmarks.",
  "us.anthropic.claude-haiku-4-5-20251001-v1:0.description": "Claude Haiku 4.5 ist das schnellste und intelligenteste Haiku-Modell von Anthropic – mit blitzschneller Reaktion und erweitertem Denkvermögen.",
  "us.anthropic.claude-sonnet-4-5-20250929-v1:0.description": "Claude Sonnet 4.5 ist das bisher intelligenteste Modell von Anthropic.",
  "v0-1.0-md.description": "v0-1.0-md ist ein Legacy-Modell, das über die v0-API bereitgestellt wird.",
  "v0-1.5-lg.description": "v0-1.5-lg eignet sich für anspruchsvolle Denk- oder Reasoning-Aufgaben.",
  "v0-1.5-md.description": "v0-1.5-md eignet sich für alltägliche Aufgaben und UI-Generierung.",
  "vercel/v0-1.0-md.description": "Zugriff auf die Modelle hinter v0 zur Generierung, Fehlerbehebung und Optimierung moderner Webanwendungen mit frameworkspezifischem Denken und aktuellem Wissen.",
  "vercel/v0-1.5-md.description": "Zugriff auf die Modelle hinter v0 zur Generierung, Fehlerbehebung und Optimierung moderner Webanwendungen mit frameworkspezifischem Denken und aktuellem Wissen.",
  "volcengine/doubao-seed-code.description": "Doubao-Seed-Code ist das LLM der ByteDance Volcano Engine, optimiert für agentenbasiertes Programmieren. Es überzeugt bei Programmier- und Agentenbenchmarks mit Unterstützung für 256K-Kontext.",
  "wan2.2-t2i-flash.description": "Wanxiang 2.2 Speed ist das neueste Modell mit Verbesserungen in Kreativität, Stabilität und Realismus – für schnelle Generierung und hohen Mehrwert.",
  "wan2.2-t2i-plus.description": "Wanxiang 2.2 Pro ist das neueste Modell mit Verbesserungen in Kreativität, Stabilität und Realismus – mit reicheren Details.",
  "wanx-v1.description": "Basismodell für Text-zu-Bild. Entspricht Tongyi Wanxiang 1.0 General.",
  "wanx2.0-t2i-turbo.description": "Hervorragend bei texturierten Porträts mit moderater Geschwindigkeit und geringeren Kosten. Entspricht Tongyi Wanxiang 2.0 Speed.",
  "wanx2.1-t2i-plus.description": "Vollständig aktualisierte Version mit reicheren Bilddetails und etwas langsamerer Geschwindigkeit. Entspricht Tongyi Wanxiang 2.1 Pro.",
  "wanx2.1-t2i-turbo.description": "Vollständig aktualisierte Version mit schneller Generierung, starker Gesamtqualität und hohem Mehrwert. Entspricht Tongyi Wanxiang 2.1 Speed.",
  "whisper-1.description": "Ein allgemeines Spracherkennungsmodell mit Unterstützung für mehrsprachige ASR, Sprachübersetzung und Spracherkennung.",
  "wizardlm2.description": "WizardLM 2 ist ein Sprachmodell von Microsoft AI, das bei komplexen Dialogen, mehrsprachigen Aufgaben, Reasoning und Assistenzanwendungen überzeugt.",
  "wizardlm2:8x22b.description": "WizardLM 2 ist ein Sprachmodell von Microsoft AI, das bei komplexen Dialogen, mehrsprachigen Aufgaben, Reasoning und Assistenzanwendungen überzeugt.",
  "x-ai/grok-4-fast-non-reasoning.description": "Grok 4 Fast (Non-Reasoning) ist xAIs hochdurchsatzfähiges, kostengünstiges multimodales Modell (unterstützt 2M Kontextfenster) für latenz- und kostenempfindliche Szenarien ohne integriertes Reasoning. Es steht neben der Reasoning-Version von Grok 4 Fast, wobei Reasoning bei Bedarf über den API-Parameter aktiviert werden kann. Prompts und Ausgaben können von xAI oder OpenRouter zur Verbesserung zukünftiger Modelle verwendet werden.",
  "x-ai/grok-4-fast.description": "Grok 4 Fast ist xAIs hochdurchsatzfähiges, kostengünstiges Modell (unterstützt 2M Kontextfenster), ideal für hochparallele und langkontextuelle Anwendungsfälle.",
  "x-ai/grok-4.1-fast-non-reasoning.description": "Grok 4 Fast (Non-Reasoning) ist xAIs hochdurchsatzfähiges, kostengünstiges multimodales Modell (unterstützt 2M Kontextfenster) für latenz- und kostenempfindliche Szenarien ohne integriertes Reasoning. Es steht neben der Reasoning-Version von Grok 4 Fast, wobei Reasoning bei Bedarf über den API-Parameter aktiviert werden kann. Prompts und Ausgaben können von xAI oder OpenRouter zur Verbesserung zukünftiger Modelle verwendet werden.",
  "x-ai/grok-4.1-fast.description": "Grok 4 Fast ist xAIs hochdurchsatzfähiges, kostengünstiges Modell (unterstützt 2M Kontextfenster), ideal für hochparallele und langkontextuelle Anwendungsfälle.",
  "x-ai/grok-4.description": "Grok 4 ist xAIs Flaggschiff-Reasoning-Modell mit starker Denk- und Multimodal-Fähigkeit.",
  "x-ai/grok-code-fast-1.description": "Grok Code Fast 1 ist xAIs schnelles Codemodell mit lesbaren, entwicklerfreundlichen Ausgaben.",
  "xai/grok-2-vision.description": "Grok 2 Vision überzeugt bei visuellen Aufgaben mit SOTA-Leistung in visuellem Mathematik-Reasoning (MathVista) und Dokumenten-QA (DocVQA). Es verarbeitet Dokumente, Diagramme, Grafiken, Screenshots und Fotos.",
  "xai/grok-2.description": "Grok 2 ist ein Spitzenmodell mit modernstem Reasoning, starker Chat-, Coding- und Denkleistung und übertrifft Claude 3.5 Sonnet und GPT-4 Turbo auf LMSYS.",
  "xai/grok-3-fast.description": "xAIs Flaggschiffmodell überzeugt in Unternehmensanwendungen wie Datenextraktion, Codierung und Zusammenfassung – mit tiefem Fachwissen in Finanzen, Gesundheitswesen, Recht und Wissenschaft. Die schnelle Variante läuft auf schnellerer Infrastruktur für deutlich schnellere Antworten bei höheren Tokenkosten.",
  "xai/grok-3-mini-fast.description": "xAIs leichtgewichtiges Modell, das vor der Antwort nachdenkt – ideal für einfache oder logikbasierte Aufgaben ohne tiefes Fachwissen. Rohdaten des Denkprozesses sind verfügbar. Die schnelle Variante läuft auf schnellerer Infrastruktur für deutlich schnellere Antworten bei höheren Tokenkosten.",
  "xai/grok-3-mini.description": "xAIs leichtgewichtiges Modell, das vor der Antwort nachdenkt – ideal für einfache oder logikbasierte Aufgaben ohne tiefes Fachwissen. Rohdaten des Denkprozesses sind verfügbar.",
  "xai/grok-3.description": "xAIs Flaggschiffmodell überzeugt in Unternehmensanwendungen wie Datenextraktion, Codierung und Zusammenfassung – mit tiefem Fachwissen in Finanzen, Gesundheitswesen, Recht und Wissenschaft.",
  "xai/grok-4.description": "xAIs neuestes Flaggschiffmodell mit unübertroffener Leistung in natürlicher Sprache, Mathematik und Reasoning – ein idealer Allrounder.",
  "yi-large-fc.description": "Basierend auf yi-large mit erweitertem Tool-Calling – geeignet für Agenten- und Workflow-Szenarien.",
  "yi-large-preview.description": "Eine frühe Version; yi-large (neuere) wird empfohlen.",
  "yi-large-rag.description": "Ein fortschrittlicher Dienst basierend auf yi-large, der Retrieval und Generierung kombiniert für präzise Antworten mit Echtzeit-Websuche.",
  "yi-large-turbo.description": "Hervorragendes Preis-Leistungs-Verhältnis, abgestimmt auf ein starkes Gleichgewicht zwischen Qualität, Geschwindigkeit und Kosten.",
  "yi-large.description": "Ein neues 100B-Parameter-Modell mit starker Q&A- und Textgenerierungsleistung.",
  "yi-lightning-lite.description": "Eine leichtgewichtige Version; yi-lightning wird empfohlen.",
  "yi-lightning.description": "Ein aktuelles Hochleistungsmodell mit schneller Inferenz und hochwertiger Ausgabe.",
  "yi-medium-200k.description": "Ein 200K-Langkontextmodell für tiefes Verständnis und Generierung langer Inhalte.",
  "yi-medium.description": "Ein abgestimmtes Mid-Size-Modell mit ausgewogener Leistung und Wert, optimiert für Anweisungsbefolgung.",
  "yi-spark.description": "Ein kompaktes, schnelles Modell mit gestärkten Mathematik- und Codierungsfähigkeiten.",
  "yi-vision-v2.description": "Ein Vision-Modell für komplexe Aufgaben mit starker Multi-Image-Verständnis und Analyse.",
  "yi-vision.description": "Ein Vision-Modell für komplexe Aufgaben mit starkem Bildverständnis und Analyse.",
  "z-ai/glm-4.5-air.description": "GLM 4.5 Air ist eine leichtgewichtige Variante von GLM 4.5 für kostensensitive Szenarien bei gleichzeitig starker Reasoning-Leistung.",
  "z-ai/glm-4.5.description": "GLM 4.5 ist Z.AIs Flaggschiffmodell mit hybridem Reasoning, optimiert für Engineering- und Langkontextaufgaben.",
  "z-ai/glm-4.6.description": "GLM 4.6 ist Z.AIs Flaggschiffmodell mit erweitertem Kontextumfang und Codierungsfähigkeiten.",
  "zai-glm-4.6.description": "Leistungsstark bei Codierungs- und Reasoning-Aufgaben, unterstützt Streaming und Toolaufrufe – ideal für agentenbasiertes Codieren und komplexes Denken.",
  "zai-org/GLM-4.5-Air.description": "GLM-4.5-Air ist ein Basismodell für Agentenanwendungen mit Mixture-of-Experts-Architektur. Es ist optimiert für Toolnutzung, Web-Browsing, Softwareentwicklung und Frontend-Codierung und integriert sich mit Code-Agenten wie Claude Code und Roo Code. Es nutzt hybrides Reasoning für komplexe und alltägliche Szenarien.",
  "zai-org/GLM-4.5.description": "GLM-4.5 ist ein Basismodell für Agentenanwendungen mit Mixture-of-Experts-Architektur. Es ist tiefgreifend optimiert für Toolnutzung, Web-Browsing, Softwareentwicklung und Frontend-Codierung und integriert sich mit Code-Agenten wie Claude Code und Roo Code. Es nutzt hybrides Reasoning für komplexe und alltägliche Szenarien.",
  "zai-org/GLM-4.5V.description": "GLM-4.5V ist Zhipu AIs neuestes VLM, basierend auf dem GLM-4.5-Air-Textmodell (106B gesamt, 12B aktiv) mit MoE-Architektur für starke Leistung bei geringeren Kosten. Es folgt dem GLM-4.1V-Thinking-Ansatz und fügt 3D-RoPE zur Verbesserung des 3D-Räumlichkeitsdenkens hinzu. Optimiert durch Pretraining, SFT und RL, verarbeitet es Bilder, Videos und lange Dokumente und belegt Spitzenplätze unter offenen Modellen in 41 öffentlichen multimodalen Benchmarks. Ein Thinking-Modus-Schalter ermöglicht die Balance zwischen Geschwindigkeit und Tiefe.",
  "zai-org/GLM-4.6.description": "Im Vergleich zu GLM-4.5 erweitert GLM-4.6 den Kontext von 128K auf 200K für komplexere Agentenaufgaben. Es erzielt höhere Werte in Code-Benchmarks und zeigt stärkere reale Leistung in Apps wie Claude Code, Cline, Roo Code und Kilo Code – einschließlich besserer Frontend-Seitengenerierung. Reasoning wurde verbessert und Toolnutzung während des Denkens unterstützt, was die Gesamtleistung stärkt. Es integriert sich besser in Agentenframeworks, verbessert Tool-/Suchagenten und bietet einen menschenfreundlicheren Schreibstil und natürlichere Rollenspiele.",
  "zai/glm-4.5-air.description": "GLM-4.5 und GLM-4.5-Air sind unsere neuesten Flaggschiffe für Agentenanwendungen, beide mit MoE. GLM-4.5 hat 355B gesamt und 32B aktiv pro Forward-Pass; GLM-4.5-Air ist schlanker mit 106B gesamt und 12B aktiv.",
  "zai/glm-4.5.description": "Die GLM-4.5-Serie ist für Agenten konzipiert. Das Flaggschiff GLM-4.5 kombiniert Reasoning-, Coding- und Agentenfähigkeiten mit 355B Gesamtparametern (32B aktiv) und bietet zwei Betriebsmodi als hybrides Reasoning-System.",
  "zai/glm-4.5v.description": "GLM-4.5V baut auf GLM-4.5-Air auf, übernimmt bewährte GLM-4.1V-Thinking-Techniken und skaliert mit einer starken 106B-Parameter-MoE-Architektur.",
  "zenmux/auto.description": "ZenMux Auto-Routing wählt basierend auf Ihrer Anfrage das leistungsstärkste und kosteneffizienteste Modell aus den unterstützten Optionen aus."
}
