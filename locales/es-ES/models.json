{
  "01-ai/yi-1.5-34b-chat.description": "El modelo ajustado de código abierto más reciente de 01.AI con 34 mil millones de parámetros, compatible con múltiples escenarios de diálogo, entrenado con datos de alta calidad y alineado con las preferencias humanas.",
  "01-ai/yi-1.5-9b-chat.description": "El modelo ajustado de código abierto más reciente de 01.AI con 9 mil millones de parámetros, compatible con múltiples escenarios de diálogo, entrenado con datos de alta calidad y alineado con las preferencias humanas.",
  "360/deepseek-r1.description": "DeepSeek-R1, desplegado por 360, utiliza aprendizaje por refuerzo a gran escala en la etapa de postentrenamiento para mejorar significativamente el razonamiento con etiquetas mínimas. Igualando a OpenAI o1 en tareas de razonamiento matemático, de código y lenguaje natural.",
  "360gpt-pro-trans.description": "Modelo especializado en traducción, ajustado en profundidad para ofrecer una calidad de traducción líder.",
  "360gpt-pro.description": "360GPT Pro es un modelo clave de IA de 360 con procesamiento de texto eficiente para diversos escenarios de PLN, compatible con comprensión de textos largos y diálogos de múltiples turnos.",
  "360gpt-turbo-responsibility-8k.description": "360GPT Turbo Responsibility 8K enfatiza la seguridad semántica y la responsabilidad en aplicaciones sensibles al contenido, garantizando experiencias de usuario precisas y robustas.",
  "360gpt-turbo.description": "360GPT Turbo ofrece gran capacidad de cómputo y conversación con excelente comprensión semántica y eficiencia de generación, ideal para empresas y desarrolladores.",
  "360gpt2-o1.description": "360gpt2-o1 construye cadenas de pensamiento mediante búsqueda en árbol con un mecanismo de reflexión y entrenamiento por refuerzo, permitiendo autorreflexión y autocorrección.",
  "360gpt2-pro.description": "360GPT2 Pro es un modelo avanzado de PLN de 360 con excelente generación y comprensión de texto, especialmente para tareas creativas, capaz de manejar transformaciones complejas y juegos de rol.",
  "360zhinao2-o1.description": "360zhinao2-o1 construye cadenas de pensamiento mediante búsqueda en árbol con un mecanismo de reflexión y entrenamiento por refuerzo, permitiendo autorreflexión y autocorrección.",
  "4.0Ultra.description": "Spark Ultra es el modelo más potente de la serie Spark, mejorando la comprensión y resumen de texto mientras optimiza la búsqueda web. Es una solución integral para aumentar la productividad laboral y ofrecer respuestas precisas, posicionándose como un producto inteligente líder.",
  "AnimeSharp.description": "AnimeSharp (también conocido como \"4x-AnimeSharp\") es un modelo de superresolución de código abierto basado en ESRGAN de Kim2091, enfocado en escalar y afilar imágenes de estilo anime. Fue renombrado desde \"4x-TextSharpV1\" en febrero de 2022, originalmente también para imágenes de texto pero altamente optimizado para contenido anime.",
  "Baichuan2-Turbo.description": "Utiliza aumento por búsqueda para conectar el modelo con conocimiento de dominio y web. Admite cargas de archivos PDF/Word y entradas de URL para una recuperación oportuna y completa, con resultados profesionales y precisos.",
  "Baichuan3-Turbo-128k.description": "Con una ventana de contexto ultra larga de 128K, está optimizado para escenarios empresariales de alta frecuencia con grandes mejoras y alto valor. En comparación con Baichuan2, la creación de contenido mejora un 20 %, las preguntas y respuestas de conocimiento un 17 % y los juegos de rol un 40 %. El rendimiento general supera al de GPT-3.5.",
  "Baichuan3-Turbo.description": "Optimizado para escenarios empresariales de alta frecuencia con grandes mejoras y alto valor. En comparación con Baichuan2, la creación de contenido mejora un 20 %, las preguntas y respuestas de conocimiento un 17 % y los juegos de rol un 40 %. El rendimiento general supera al de GPT-3.5.",
  "Baichuan4-Air.description": "Modelo de alto rendimiento en China, superando a modelos extranjeros líderes en tareas en chino como conocimiento, texto largo y generación creativa. También cuenta con capacidades multimodales líderes en la industria con resultados sólidos en pruebas de referencia autorizadas.",
  "Baichuan4-Turbo.description": "Modelo de alto rendimiento en China, superando a modelos extranjeros líderes en tareas en chino como conocimiento, texto largo y generación creativa. También cuenta con capacidades multimodales líderes en la industria con resultados sólidos en pruebas de referencia autorizadas.",
  "Baichuan4.description": "Rendimiento nacional superior, superando a modelos extranjeros líderes en tareas en chino como conocimiento enciclopédico, texto largo y generación creativa. También ofrece capacidades multimodales líderes en la industria y resultados sólidos en pruebas de referencia.",
  "ByteDance-Seed/Seed-OSS-36B-Instruct.description": "Seed-OSS es una familia de modelos de lenguaje de código abierto de ByteDance Seed, diseñados para manejar contextos largos, razonamiento, agentes y habilidades generales. Seed-OSS-36B-Instruct es un modelo ajustado por instrucciones con 36 mil millones de parámetros y contexto ultra largo nativo para procesar documentos o bases de código extensas. Está optimizado para razonamiento, generación de código y tareas de agente (uso de herramientas), manteniendo una fuerte capacidad general. Una característica clave es el \"Presupuesto de Pensamiento\", que permite una longitud de razonamiento flexible para mejorar la eficiencia.",
  "DeepSeek-R1-Distill-Llama-70B.description": "DeepSeek R1, el modelo más grande e inteligente de la suite DeepSeek, ha sido destilado en la arquitectura Llama 70B. Las pruebas de referencia y evaluaciones humanas muestran que es más inteligente que el Llama 70B base, especialmente en tareas de matemáticas y precisión factual.",
  "DeepSeek-R1-Distill-Qwen-1.5B.description": "Modelo destilado de DeepSeek-R1 basado en Qwen2.5-Math-1.5B. El aprendizaje por refuerzo y los datos de arranque en frío optimizan el rendimiento del razonamiento, estableciendo nuevos estándares de referencia multitarea para modelos abiertos.",
  "DeepSeek-R1-Distill-Qwen-14B.description": "Los modelos DeepSeek-R1-Distill están ajustados a partir de modelos de código abierto utilizando datos de muestra generados por DeepSeek-R1.",
  "DeepSeek-R1-Distill-Qwen-32B.description": "Los modelos DeepSeek-R1-Distill están ajustados a partir de modelos de código abierto utilizando datos de muestra generados por DeepSeek-R1.",
  "DeepSeek-R1-Distill-Qwen-7B.description": "Modelo destilado de DeepSeek-R1 basado en Qwen2.5-Math-7B. El aprendizaje por refuerzo y los datos de arranque en frío optimizan el rendimiento del razonamiento, estableciendo nuevos estándares de referencia multitarea para modelos abiertos.",
  "DeepSeek-R1.description": "DeepSeek-R1 aplica aprendizaje por refuerzo a gran escala durante el postentrenamiento, mejorando significativamente el razonamiento con muy pocos datos etiquetados. Igualando al modelo de producción OpenAI o1 en tareas de matemáticas, código y razonamiento en lenguaje natural.",
  "DeepSeek-V3-1.description": "DeepSeek V3.1 es un modelo de razonamiento de próxima generación con razonamiento complejo mejorado y cadenas de pensamiento, adecuado para tareas de análisis profundo.",
  "DeepSeek-V3-Fast.description": "Proveedor: sophnet. DeepSeek V3 Fast es la versión de alta velocidad de DeepSeek V3 0324, de precisión completa (sin cuantización), con mejor rendimiento en código y matemáticas y respuestas más rápidas.",
  "DeepSeek-V3.1-Fast.description": "DeepSeek V3.1 Fast es la variante rápida de alta velocidad de DeepSeek V3.1. Modo de pensamiento híbrido: mediante plantillas de chat, un solo modelo admite modos de pensamiento y no pensamiento. Uso de herramientas más inteligente: el postentrenamiento mejora el rendimiento en tareas de herramientas y agentes.",
  "DeepSeek-V3.1-Think.description": "Modo de pensamiento de DeepSeek-V3.1: un nuevo modelo de razonamiento híbrido con modos de pensamiento y no pensamiento, más eficiente que DeepSeek-R1-0528. Las optimizaciones posteriores al entrenamiento mejoran significativamente el uso de herramientas de agente y el rendimiento en tareas de agente.",
  "DeepSeek-V3.description": "DeepSeek-V3 es un modelo MoE desarrollado por DeepSeek. Supera a otros modelos abiertos como Qwen2.5-72B y Llama-3.1-405B en muchas pruebas de referencia y compite con modelos cerrados líderes como GPT-4o y Claude 3.5 Sonnet.",
  "Doubao-lite-128k.description": "Doubao-lite ofrece respuestas ultra rápidas y mejor relación calidad-precio, con opciones flexibles para diversos escenarios. Admite contexto de 128K para inferencia y ajuste fino.",
  "Doubao-lite-32k.description": "Doubao-lite ofrece respuestas ultra rápidas y mejor relación calidad-precio, con opciones flexibles para diversos escenarios. Admite contexto de 32K para inferencia y ajuste fino.",
  "Doubao-lite-4k.description": "Doubao-lite ofrece respuestas ultra rápidas y mejor relación calidad-precio, con opciones flexibles para diversos escenarios. Admite contexto de 4K para inferencia y ajuste fino.",
  "Doubao-pro-128k.description": "Modelo insignia de mejor rendimiento para tareas complejas, fuerte en preguntas y respuestas con referencia, resumen, creación, clasificación y juegos de rol. Admite contexto de 128K para inferencia y ajuste fino.",
  "Doubao-pro-32k.description": "Modelo insignia de mejor rendimiento para tareas complejas, fuerte en preguntas y respuestas con referencia, resumen, creación, clasificación y juegos de rol. Admite contexto de 32K para inferencia y ajuste fino.",
  "Doubao-pro-4k.description": "Modelo insignia de mejor rendimiento para tareas complejas, fuerte en preguntas y respuestas con referencia, resumen, creación, clasificación y juegos de rol. Admite contexto de 4K para inferencia y ajuste fino.",
  "DreamO.description": "DreamO es un modelo de personalización de imágenes de código abierto desarrollado conjuntamente por ByteDance y la Universidad de Pekín, que utiliza una arquitectura unificada para admitir generación de imágenes multitarea. Emplea modelado composicional eficiente para generar imágenes altamente coherentes y personalizadas según identidad, tema, estilo, fondo y otras condiciones especificadas por el usuario.",
  "amazon/titan-embed-text-v2.description": "Amazon Titan Text Embeddings V2 es un modelo de incrustaciones multilingüe ligero y eficiente, compatible con dimensiones de 1024, 512 y 256.",
  "gemini-flash-latest.description": "Última versión de Gemini Flash",
  "gemini-flash-lite-latest.description": "Última versión de Gemini Flash-Lite",
  "gemini-pro-latest.description": "Última versión de Gemini Pro",
  "meta/Llama-3.2-90B-Vision-Instruct.description": "Razonamiento avanzado con imágenes para aplicaciones de agentes con comprensión visual.",
  "meta/Llama-3.3-70B-Instruct.description": "Llama 3.3 es el modelo Llama multilingüe de código abierto más avanzado, con un rendimiento cercano al de modelos de 405B a un costo muy bajo. Basado en Transformer y mejorado con SFT y RLHF para mayor utilidad y seguridad. La versión ajustada por instrucciones está optimizada para chat multilingüe y supera a muchos modelos abiertos y cerrados en los principales benchmarks de la industria. Fecha de corte de conocimiento: diciembre de 2023.",
  "meta/Meta-Llama-3-70B-Instruct.description": "Un potente modelo de 70 mil millones de parámetros que destaca en razonamiento, programación y tareas lingüísticas generales.",
  "meta/Meta-Llama-3-8B-Instruct.description": "Un modelo versátil de 8 mil millones de parámetros optimizado para chat y generación de texto.",
  "meta/Meta-Llama-3.1-405B-Instruct.description": "Modelo de texto Llama 3.1 ajustado por instrucciones, optimizado para chat multilingüe, con alto rendimiento en benchmarks comunes de la industria entre modelos abiertos y cerrados.",
  "meta/Meta-Llama-3.1-70B-Instruct.description": "Modelo de texto Llama 3.1 ajustado por instrucciones, optimizado para chat multilingüe, con alto rendimiento en benchmarks comunes de la industria entre modelos abiertos y cerrados.",
  "meta/Meta-Llama-3.1-8B-Instruct.description": "Modelo de texto Llama 3.1 ajustado por instrucciones, optimizado para chat multilingüe, con alto rendimiento en benchmarks comunes de la industria entre modelos abiertos y cerrados.",
  "meta/llama-3-70b.description": "Modelo de 70 mil millones de parámetros de código abierto ajustado por Meta para seguir instrucciones, servido por Groq en hardware LPU para inferencia rápida y eficiente.",
  "meta/llama-3-8b.description": "Modelo de 8 mil millones de parámetros de código abierto ajustado por Meta para seguir instrucciones, servido por Groq en hardware LPU para inferencia rápida y eficiente.",
  "meta/llama-3.1-405b-instruct.description": "Modelo de lenguaje avanzado que admite generación de datos sintéticos, destilación de conocimiento y razonamiento para chatbots, programación y tareas especializadas.",
  "meta/llama-3.1-70b-instruct.description": "Diseñado para diálogos complejos con excelente comprensión de contexto, razonamiento y generación de texto.",
  "meta/llama-3.1-70b.description": "Versión actualizada de Meta Llama 3 70B Instruct con contexto de 128K, soporte multilingüe y razonamiento mejorado.",
  "meta/llama-3.1-8b-instruct.description": "Modelo de vanguardia con sólida comprensión del lenguaje, razonamiento y generación de texto.",
  "meta/llama-3.1-8b.description": "Llama 3.1 8B admite una ventana de contexto de 128K, ideal para chat en tiempo real y análisis de datos, y ofrece un ahorro significativo frente a modelos más grandes. Servido por Groq en hardware LPU para inferencia rápida y eficiente.",
  "meta/llama-3.2-11b-vision-instruct.description": "Modelo de frontera en visión y lenguaje que destaca en razonamiento de alta calidad a partir de imágenes.",
  "meta/llama-3.2-11b.description": "Modelo de razonamiento con imágenes ajustado por instrucciones (entrada de texto+imagen, salida de texto) optimizado para reconocimiento visual, razonamiento con imágenes, subtitulado y preguntas y respuestas generales sobre imágenes.",
  "meta/llama-3.2-1b-instruct.description": "Modelo lingüístico pequeño de vanguardia con sólida comprensión, razonamiento y generación de texto.",
  "meta/llama-3.2-1b.description": "Modelo solo de texto para casos de uso en dispositivos como recuperación local multilingüe, resumen y reescritura.",
  "meta/llama-3.2-3b-instruct.description": "Modelo lingüístico pequeño de vanguardia con sólida comprensión, razonamiento y generación de texto.",
  "meta/llama-3.2-3b.description": "Modelo solo de texto ajustado para casos de uso en dispositivos como recuperación local multilingüe, resumen y reescritura.",
  "meta/llama-3.2-90b-vision-instruct.description": "Modelo de frontera en visión y lenguaje que destaca en razonamiento de alta calidad a partir de imágenes.",
  "meta/llama-3.2-90b.description": "Modelo de razonamiento con imágenes ajustado por instrucciones (entrada de texto+imagen, salida de texto) optimizado para reconocimiento visual, razonamiento con imágenes, subtitulado y preguntas y respuestas generales sobre imágenes.",
  "meta/llama-3.3-70b-instruct.description": "Modelo de lenguaje avanzado con gran capacidad de razonamiento, matemáticas, sentido común y llamadas a funciones.",
  "meta/llama-3.3-70b.description": "Equilibrio perfecto entre rendimiento y eficiencia. Diseñado para IA conversacional de alto rendimiento en creación de contenido, aplicaciones empresariales e investigación, con sólida comprensión del lenguaje para resumen, clasificación, análisis de sentimiento y generación de código.",
  "meta/llama-4-maverick.description": "La familia Llama 4 es un conjunto de modelos de IA multimodal nativos que admiten experiencias de texto e imagen, utilizando MoE para una comprensión líder de texto e imágenes. Llama 4 Maverick es un modelo de 17B con 128 expertos, servido por DeepInfra.",
  "meta/llama-4-scout.description": "La familia Llama 4 es un conjunto de modelos de IA multimodal nativos que admiten experiencias de texto e imagen, utilizando MoE para una comprensión líder de texto e imágenes. Llama 4 Scout es un modelo de 17B con 16 expertos, servido por DeepInfra."
}
