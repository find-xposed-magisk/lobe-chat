{
  "01-ai/yi-1.5-34b-chat.description": "جدیدترین مدل متن‌باز و بهینه‌سازی‌شده 01.AI با ۳۴ میلیارد پارامتر، پشتیبانی از سناریوهای مختلف گفت‌وگو، آموزش‌دیده با داده‌های باکیفیت و هم‌راستا با ترجیحات انسانی.",
  "01-ai/yi-1.5-9b-chat.description": "جدیدترین مدل متن‌باز و بهینه‌سازی‌شده 01.AI با ۹ میلیارد پارامتر، پشتیبانی از سناریوهای مختلف گفت‌وگو، آموزش‌دیده با داده‌های باکیفیت و هم‌راستا با ترجیحات انسانی.",
  "360/deepseek-r1.description": "مدل DeepSeek-R1 که توسط 360 پیاده‌سازی شده، از یادگیری تقویتی در مقیاس وسیع در مرحله پس‌آموزش استفاده می‌کند تا توانایی استدلال را با حداقل داده‌های برچسب‌خورده به‌طور چشمگیری افزایش دهد. این مدل در وظایف استدلال ریاضی، کدنویسی و زبان طبیعی با مدل OpenAI o1 برابری می‌کند.",
  "360gpt-pro-trans.description": "مدلی تخصصی در ترجمه که به‌طور عمیق برای دستیابی به کیفیت پیشرو در ترجمه بهینه‌سازی شده است.",
  "360gpt-pro.description": "360GPT Pro یکی از مدل‌های کلیدی هوش مصنوعی 360 است که پردازش متنی کارآمد را برای سناریوهای متنوع NLP ارائه می‌دهد و از درک متون بلند و گفت‌وگوی چندمرحله‌ای پشتیبانی می‌کند.",
  "360gpt-turbo-responsibility-8k.description": "360GPT Turbo Responsibility 8K بر ایمنی معنایی و مسئولیت‌پذیری در کاربردهای حساس به محتوا تأکید دارد و تجربه‌ای دقیق و پایدار برای کاربران فراهم می‌کند.",
  "360gpt-turbo.description": "360GPT Turbo توان پردازشی و گفت‌وگویی بالایی را با درک معنایی عالی و کارایی بالا در تولید متن ارائه می‌دهد و گزینه‌ای ایده‌آل برای کسب‌وکارها و توسعه‌دهندگان است.",
  "360gpt2-o1.description": "360gpt2-o1 با استفاده از جست‌وجوی درختی و مکانیزم بازتاب و آموزش با یادگیری تقویتی، زنجیره تفکر را ایجاد می‌کند و قابلیت بازاندیشی و اصلاح خودکار را فراهم می‌سازد.",
  "360gpt2-pro.description": "360GPT2 Pro یک مدل NLP پیشرفته از 360 است که در تولید و درک متن عملکردی عالی دارد، به‌ویژه در وظایف خلاقانه، تبدیل‌های پیچیده و ایفای نقش.",
  "360zhinao2-o1.description": "360zhinao2-o1 با استفاده از جست‌وجوی درختی و مکانیزم بازتاب و آموزش با یادگیری تقویتی، زنجیره تفکر را ایجاد می‌کند و قابلیت بازاندیشی و اصلاح خودکار را فراهم می‌سازد.",
  "4.0Ultra.description": "Spark Ultra قدرتمندترین مدل در سری Spark است که درک متن و خلاصه‌سازی را بهبود می‌بخشد و جست‌وجوی وب را ارتقا می‌دهد. این مدل راه‌حلی جامع برای افزایش بهره‌وری در محیط کار و ارائه پاسخ‌های دقیق است و به‌عنوان محصولی هوشمند پیشرو شناخته می‌شود.",
  "AnimeSharp.description": "AnimeSharp (با نام قبلی \"4x-TextSharpV1\") یک مدل متن‌باز برای افزایش وضوح تصاویر به سبک انیمه است که بر پایه ESRGAN توسط Kim2091 توسعه یافته است. این مدل در ابتدا برای تصاویر متنی نیز طراحی شده بود اما به‌طور ویژه برای محتوای انیمه بهینه‌سازی شده است.",
  "Baichuan2-Turbo.description": "با استفاده از تقویت جست‌وجو، این مدل به دانش دامنه‌ای و وب متصل می‌شود. از بارگذاری فایل‌های PDF/Word و ورودی URL پشتیبانی می‌کند تا بازیابی اطلاعات به‌موقع و جامع و خروجی‌های حرفه‌ای و دقیق را فراهم سازد.",
  "Baichuan3-Turbo-128k.description": "با پنجره متنی فوق‌العاده بلند ۱۲۸ هزار توکن، این مدل برای سناریوهای پرتکرار سازمانی بهینه‌سازی شده و ارزش بالایی ارائه می‌دهد. در مقایسه با Baichuan2، تولید محتوا ۲۰٪، پرسش‌وپاسخ دانشی ۱۷٪ و ایفای نقش ۴۰٪ بهبود یافته است. عملکرد کلی آن بهتر از GPT-3.5 است.",
  "Baichuan3-Turbo.description": "برای سناریوهای پرتکرار سازمانی بهینه‌سازی شده و ارزش بالایی ارائه می‌دهد. در مقایسه با Baichuan2، تولید محتوا ۲۰٪، پرسش‌وپاسخ دانشی ۱۷٪ و ایفای نقش ۴۰٪ بهبود یافته است. عملکرد کلی آن بهتر از GPT-3.5 است.",
  "Baichuan4-Air.description": "مدلی پیشرو در چین که در وظایف زبان چینی مانند دانش، متون بلند و تولید خلاقانه از مدل‌های مطرح خارجی پیشی می‌گیرد. همچنین دارای قابلیت‌های چندوجهی پیشرفته با نتایج قوی در آزمون‌های معتبر است.",
  "Baichuan4-Turbo.description": "مدلی پیشرو در چین که در وظایف زبان چینی مانند دانش، متون بلند و تولید خلاقانه از مدل‌های مطرح خارجی پیشی می‌گیرد. همچنین دارای قابلیت‌های چندوجهی پیشرفته با نتایج قوی در آزمون‌های معتبر است.",
  "Baichuan4.description": "عملکرد برتر داخلی که در وظایف زبان چینی مانند دانش دایره‌المعارفی، متون بلند و تولید خلاقانه از مدل‌های مطرح خارجی پیشی می‌گیرد. همچنین دارای قابلیت‌های چندوجهی پیشرفته و نتایج قوی در آزمون‌های معیار است.",
  "ByteDance-Seed/Seed-OSS-36B-Instruct.description": "Seed-OSS مجموعه‌ای از مدل‌های متن‌باز LLM از ByteDance Seed است که برای مدیریت زمینه‌های بلند، استدلال، عامل‌ها و توانایی‌های عمومی طراحی شده‌اند. Seed-OSS-36B-Instruct یک مدل ۳۶ میلیارد پارامتری با تنظیمات دستوری است که به‌طور بومی از زمینه‌های بسیار بلند برای پردازش اسناد یا پایگاه‌های کد پشتیبانی می‌کند. این مدل برای استدلال، تولید کد و وظایف عامل (استفاده از ابزار) بهینه‌سازی شده و در عین حال توانایی عمومی قوی خود را حفظ کرده است. ویژگی کلیدی آن «بودجه تفکر» است که امکان تنظیم طول استدلال برای افزایش کارایی را فراهم می‌سازد.",
  "DeepSeek-R1-Distill-Llama-70B.description": "مدل DeepSeek R1 که بزرگ‌تر و هوشمندتر است، در معماری Llama 70B تقطیر شده است. آزمون‌های معیار و ارزیابی‌های انسانی نشان می‌دهند که این مدل از نسخه پایه Llama 70B هوشمندتر است، به‌ویژه در وظایف ریاضی و دقت اطلاعات.",
  "DeepSeek-R1-Distill-Qwen-1.5B.description": "مدلی تقطیرشده از DeepSeek-R1 بر پایه Qwen2.5-Math-1.5B. با استفاده از یادگیری تقویتی و داده‌های شروع سرد، عملکرد استدلال را بهینه کرده و معیارهای جدیدی برای مدل‌های متن‌باز در وظایف چندگانه تعیین کرده است.",
  "DeepSeek-R1-Distill-Qwen-14B.description": "مدل‌های DeepSeek-R1-Distill از مدل‌های متن‌باز با استفاده از داده‌های نمونه تولیدشده توسط DeepSeek-R1 به‌صورت دقیق تنظیم شده‌اند.",
  "DeepSeek-R1-Distill-Qwen-32B.description": "مدل‌های DeepSeek-R1-Distill از مدل‌های متن‌باز با استفاده از داده‌های نمونه تولیدشده توسط DeepSeek-R1 به‌صورت دقیق تنظیم شده‌اند.",
  "DeepSeek-R1-Distill-Qwen-7B.description": "مدلی تقطیرشده از DeepSeek-R1 بر پایه Qwen2.5-Math-7B. با استفاده از یادگیری تقویتی و داده‌های شروع سرد، عملکرد استدلال را بهینه کرده و معیارهای جدیدی برای مدل‌های متن‌باز در وظایف چندگانه تعیین کرده است.",
  "DeepSeek-R1.description": "DeepSeek-R1 در مرحله پس‌آموزش از یادگیری تقویتی در مقیاس وسیع استفاده می‌کند تا توانایی استدلال را با داده‌های بسیار کم برچسب‌خورده به‌طور چشمگیری افزایش دهد. این مدل در وظایف استدلال ریاضی، کدنویسی و زبان طبیعی با مدل تولیدی OpenAI o1 برابری می‌کند.",
  "DeepSeek-V3-1.description": "DeepSeek V3.1 یک مدل نسل جدید استدلال با بهبود در استدلال پیچیده و زنجیره تفکر است که برای وظایف تحلیلی عمیق مناسب است.",
  "DeepSeek-V3-Fast.description": "ارائه‌دهنده: sophnet. DeepSeek V3 Fast نسخه با نرخ پردازش بالا از DeepSeek V3 0324 است که با دقت کامل (بدون کوانتیزه‌سازی) عملکرد قوی‌تری در کدنویسی و ریاضی دارد و پاسخ‌های سریع‌تری ارائه می‌دهد.",
  "DeepSeek-V3.1-Fast.description": "DeepSeek V3.1 Fast نسخه سریع با نرخ پردازش بالا از DeepSeek V3.1 است. حالت تفکر ترکیبی: از طریق قالب‌های چت، یک مدل از هر دو حالت تفکر و غیرتفکر پشتیبانی می‌کند. استفاده هوشمندانه‌تر از ابزار: پس‌آموزش عملکرد وظایف ابزار و عامل را بهبود می‌بخشد.",
  "DeepSeek-V3.1-Think.description": "حالت تفکر DeepSeek-V3.1: یک مدل استدلال ترکیبی جدید با حالت‌های تفکر و غیرتفکر که کارآمدتر از DeepSeek-R1-0528 است. بهینه‌سازی‌های پس‌آموزش عملکرد استفاده از ابزار عامل و وظایف عامل را به‌طور قابل‌توجهی بهبود می‌بخشد.",
  "DeepSeek-V3.description": "DeepSeek-V3 یک مدل MoE توسعه‌یافته توسط DeepSeek است. این مدل در بسیاری از آزمون‌های معیار از مدل‌های متن‌باز دیگر مانند Qwen2.5-72B و Llama-3.1-405B پیشی می‌گیرد و با مدل‌های بسته پیشرو مانند GPT-4o و Claude 3.5 Sonnet رقابت می‌کند.",
  "Doubao-lite-128k.description": "Doubao-lite پاسخ‌های فوق‌العاده سریع و ارزش بالاتری ارائه می‌دهد و گزینه‌های انعطاف‌پذیری را در سناریوهای مختلف فراهم می‌سازد. از زمینه ۱۲۸ هزار توکن برای استنتاج و تنظیم دقیق پشتیبانی می‌کند.",
  "Doubao-lite-32k.description": "Doubao-lite پاسخ‌های فوق‌العاده سریع و ارزش بالاتری ارائه می‌دهد و گزینه‌های انعطاف‌پذیری را در سناریوهای مختلف فراهم می‌سازد. از زمینه ۳۲ هزار توکن برای استنتاج و تنظیم دقیق پشتیبانی می‌کند.",
  "Doubao-lite-4k.description": "Doubao-lite پاسخ‌های فوق‌العاده سریع و ارزش بالاتری ارائه می‌دهد و گزینه‌های انعطاف‌پذیری را در سناریوهای مختلف فراهم می‌سازد. از زمینه ۴ هزار توکن برای استنتاج و تنظیم دقیق پشتیبانی می‌کند.",
  "Doubao-pro-128k.description": "بهترین مدل پرچم‌دار برای وظایف پیچیده با عملکرد قوی در پرسش‌وپاسخ مرجع، خلاصه‌سازی، تولید محتوا، طبقه‌بندی و ایفای نقش. از زمینه ۱۲۸ هزار توکن برای استنتاج و تنظیم دقیق پشتیبانی می‌کند.",
  "Doubao-pro-32k.description": "بهترین مدل پرچم‌دار برای وظایف پیچیده با عملکرد قوی در پرسش‌وپاسخ مرجع، خلاصه‌سازی، تولید محتوا، طبقه‌بندی و ایفای نقش. از زمینه ۳۲ هزار توکن برای استنتاج و تنظیم دقیق پشتیبانی می‌کند.",
  "Doubao-pro-4k.description": "بهترین مدل پرچم‌دار برای وظایف پیچیده با عملکرد قوی در پرسش‌وپاسخ مرجع، خلاصه‌سازی، تولید محتوا، طبقه‌بندی و ایفای نقش. از زمینه ۴ هزار توکن برای استنتاج و تنظیم دقیق پشتیبانی می‌کند.",
  "DreamO.description": "DreamO یک مدل متن‌باز برای سفارشی‌سازی تصویر است که به‌طور مشترک توسط ByteDance و دانشگاه پکن توسعه یافته و از معماری یکپارچه برای پشتیبانی از تولید چندوظیفه‌ای تصویر استفاده می‌کند. این مدل با مدل‌سازی ترکیبی کارآمد، تصاویر سفارشی و منسجم را بر اساس هویت، موضوع، سبک، پس‌زمینه و شرایط دیگر مشخص‌شده توسط کاربر تولید می‌کند.",
  "ERNIE-3.5-128K.description": "مدل زبان بزرگ پرچم‌دار بایدو که با استفاده از حجم عظیمی از متون چینی و انگلیسی آموزش دیده و توانایی بالایی در گفتگو، تولید محتوا و استفاده از افزونه‌ها دارد؛ از ادغام خودکار افزونه جستجوی بایدو برای ارائه پاسخ‌های به‌روز پشتیبانی می‌کند.",
  "ERNIE-3.5-8K-Preview.description": "مدل زبان بزرگ پرچم‌دار بایدو که با استفاده از حجم عظیمی از متون چینی و انگلیسی آموزش دیده و توانایی بالایی در گفتگو، تولید محتوا و استفاده از افزونه‌ها دارد؛ از ادغام خودکار افزونه جستجوی بایدو برای ارائه پاسخ‌های به‌روز پشتیبانی می‌کند.",
  "ERNIE-3.5-8K.description": "مدل زبان بزرگ پرچم‌دار بایدو که با استفاده از حجم عظیمی از متون چینی و انگلیسی آموزش دیده و توانایی بالایی در گفتگو، تولید محتوا و استفاده از افزونه‌ها دارد؛ از ادغام خودکار افزونه جستجوی بایدو برای ارائه پاسخ‌های به‌روز پشتیبانی می‌کند.",
  "ERNIE-4.0-8K-Latest.description": "مدل زبان بسیار بزرگ پرچم‌دار بایدو با ارتقاءهای جامع نسبت به ERNIE 3.5، مناسب برای انجام وظایف پیچیده در حوزه‌های مختلف؛ از ادغام افزونه جستجوی بایدو برای ارائه پاسخ‌های به‌روز پشتیبانی می‌کند.",
  "ERNIE-4.0-8K-Preview.description": "مدل زبان بسیار بزرگ پرچم‌دار بایدو با ارتقاءهای جامع نسبت به ERNIE 3.5، مناسب برای انجام وظایف پیچیده در حوزه‌های مختلف؛ از ادغام افزونه جستجوی بایدو برای ارائه پاسخ‌های به‌روز پشتیبانی می‌کند.",
  "ERNIE-4.0-Turbo-8K-Latest.description": "مدل زبان بسیار بزرگ پرچم‌دار بایدو با عملکرد کلی قدرتمند برای وظایف پیچیده، همراه با ادغام افزونه جستجوی بایدو برای پاسخ‌های به‌روز. عملکرد آن از ERNIE 4.0 بهتر است.",
  "ERNIE-4.0-Turbo-8K-Preview.description": "مدل زبان بسیار بزرگ پرچم‌دار بایدو با عملکرد کلی قدرتمند برای وظایف پیچیده، همراه با ادغام افزونه جستجوی بایدو برای پاسخ‌های به‌روز. عملکرد آن از ERNIE 4.0 بهتر است.",
  "ERNIE-Character-8K.description": "مدل زبان تخصصی بایدو برای شخصیت‌های بازی، خدمات مشتری و نقش‌آفرینی، با ثبات بیشتر در شخصیت، پیروی بهتر از دستورات و استدلال قوی‌تر.",
  "ERNIE-Lite-Pro-128K.description": "مدل سبک بایدو با تعادل بین کیفیت و عملکرد استنتاج، بهتر از ERNIE Lite و مناسب برای شتاب‌دهنده‌های کم‌مصرف.",
  "ERNIE-Speed-128K.description": "جدیدترین مدل زبان با عملکرد بالا از بایدو (۲۰۲۴) با توانایی عمومی قوی، مناسب برای تنظیم دقیق در سناریوهای خاص، با عملکرد استدلال عالی.",
  "ERNIE-Speed-Pro-128K.description": "جدیدترین مدل زبان با عملکرد بالا از بایدو (۲۰۲۴) با توانایی عمومی قوی، بهتر از ERNIE Speed، مناسب برای تنظیم دقیق با عملکرد استدلال عالی.",
  "FLUX-1.1-pro.description": "FLUX.1.1 Pro",
  "FLUX.1-Kontext-dev.description": "FLUX.1-Kontext-dev یک مدل چندوجهی برای تولید و ویرایش تصویر از آزمایشگاه Black Forest است که بر پایه معماری Rectified Flow Transformer با ۱۲ میلیارد پارامتر ساخته شده است. این مدل بر تولید، بازسازی، بهبود یا ویرایش تصاویر در شرایط زمینه‌ای مشخص تمرکز دارد. با ترکیب قدرت تولید قابل کنترل مدل‌های انتشار با مدل‌سازی زمینه‌ای ترنسفورمر، خروجی‌های باکیفیتی برای وظایفی مانند inpainting، outpainting و بازسازی صحنه‌های بصری ارائه می‌دهد.",
  "FLUX.1-Kontext-pro.description": "FLUX.1 Kontext [pro]",
  "FLUX.1-dev.description": "FLUX.1-dev یک مدل زبان چندوجهی متن-تصویر متن‌باز از آزمایشگاه Black Forest است که برای وظایف درک و تولید تصویر/متن بهینه‌سازی شده است. این مدل بر پایه LLMهای پیشرفته (مانند Mistral-7B) ساخته شده و از رمزگذار بینایی طراحی‌شده و تنظیمات چندمرحله‌ای دستورالعمل بهره می‌برد تا هماهنگی چندوجهی و استدلال پیچیده را ممکن سازد.",
  "Gryphe/MythoMax-L2-13b.description": "MythoMax-L2 (13B) مدلی نوآورانه برای حوزه‌های متنوع و وظایف پیچیده است.",
  "HelloMeme.description": "HelloMeme یک ابزار هوش مصنوعی برای تولید میم، گیف یا ویدیوهای کوتاه از تصاویر یا حرکاتی است که ارائه می‌دهید. بدون نیاز به مهارت طراحی یا کدنویسی، تنها با یک تصویر مرجع، محتوایی سرگرم‌کننده، جذاب و از نظر سبک هماهنگ تولید می‌کند.",
  "HiDream-I1-Full.description": "HiDream-E1-Full یک مدل متن‌باز ویرایش تصویر چندوجهی از HiDream.ai است که بر پایه معماری پیشرفته Diffusion Transformer و درک زبانی قوی (با LLaMA 3.1-8B-Instruct داخلی) ساخته شده است. این مدل از تولید تصویر با زبان طبیعی، انتقال سبک، ویرایش‌های محلی و بازسازی پشتیبانی می‌کند و در درک و اجرای متن-تصویر عملکرد عالی دارد.",
  "HunyuanDiT-v1.2-Diffusers-Distilled.description": "hunyuandit-v1.2-distilled یک مدل سبک تبدیل متن به تصویر است که با استفاده از تقطیر بهینه‌سازی شده تا تصاویر باکیفیت را به‌سرعت تولید کند، به‌ویژه مناسب برای محیط‌های کم‌منبع و تولید بلادرنگ.",
  "InstantCharacter.description": "InstantCharacter مدلی برای تولید شخصیت شخصی‌سازی‌شده بدون نیاز به تنظیم است که توسط Tencent AI در سال ۲۰۲۵ عرضه شده است. این مدل با هدف تولید شخصیت‌هایی با دقت بالا و سازگاری در سناریوهای مختلف طراحی شده و می‌تواند تنها با یک تصویر مرجع، شخصیت را مدل‌سازی کرده و آن را در سبک‌ها، حرکات و پس‌زمینه‌های مختلف منتقل کند.",
  "InternVL2-8B.description": "InternVL2-8B یک مدل قدرتمند بینایی-زبان است که از پردازش چندوجهی تصویر-متن پشتیبانی می‌کند و محتوای تصویر را با دقت شناسایی کرده و توضیحات یا پاسخ‌های مرتبط تولید می‌کند.",
  "InternVL2.5-26B.description": "InternVL2.5-26B یک مدل قدرتمند بینایی-زبان است که از پردازش چندوجهی تصویر-متن پشتیبانی می‌کند و محتوای تصویر را با دقت شناسایی کرده و توضیحات یا پاسخ‌های مرتبط تولید می‌کند.",
  "Kolors.description": "Kolors یک مدل تبدیل متن به تصویر است که توسط تیم Kolors در Kuaishou توسعه یافته است. این مدل با میلیاردها پارامتر آموزش دیده و در کیفیت بصری، درک معنایی چینی و رندر متن عملکرد برجسته‌ای دارد.",
  "Kwai-Kolors/Kolors.description": "Kolors یک مدل بزرگ تبدیل متن به تصویر با انتشار نهفته است که توسط تیم Kolors در Kuaishou توسعه یافته است. این مدل با میلیاردها جفت متن-تصویر آموزش دیده و در کیفیت بصری، دقت معنایی پیچیده و رندر متن چینی/انگلیسی عملکرد عالی دارد و در درک و تولید محتوای چینی بسیار قوی است.",
  "Kwaipilot/KAT-Dev.description": "KAT-Dev (32B) یک مدل متن‌باز برای وظایف مهندسی نرم‌افزار است. این مدل با نرخ حل ۶۲.۴٪ در SWE-Bench Verified، در میان مدل‌های متن‌باز رتبه پنجم را دارد. با آموزش میانی، تنظیم با نظارت (SFT) و یادگیری تقویتی (RL) برای تکمیل کد، رفع اشکال و بازبینی کد بهینه‌سازی شده است.",
  "Llama-3.2-11B-Vision-Instruct.description": "استدلال تصویری قوی روی تصاویر با وضوح بالا، مناسب برای کاربردهای درک بصری.",
  "Llama-3.2-90B-Vision-Instruct\t.description": "استدلال تصویری پیشرفته برای کاربردهای عامل‌های درک بصری.",
  "Meta-Llama-3-3-70B-Instruct.description": "Llama 3.3 70B یک مدل ترنسفورمر همه‌کاره برای گفتگو و تولید محتوا است.",
  "Meta-Llama-3.1-405B-Instruct.description": "مدل متنی تنظیم‌شده Llama 3.1 برای دستورالعمل‌ها که برای گفتگوهای چندزبانه بهینه‌سازی شده و در میان مدل‌های باز و بسته در ارزیابی‌های صنعتی عملکرد قوی دارد.",
  "Meta-Llama-3.1-70B-Instruct.description": "مدل متنی تنظیم‌شده Llama 3.1 برای دستورالعمل‌ها که برای گفتگوهای چندزبانه بهینه‌سازی شده و در میان مدل‌های باز و بسته در ارزیابی‌های صنعتی عملکرد قوی دارد.",
  "Meta-Llama-3.1-8B-Instruct.description": "مدل متنی تنظیم‌شده Llama 3.1 برای دستورالعمل‌ها که برای گفتگوهای چندزبانه بهینه‌سازی شده و در میان مدل‌های باز و بسته در ارزیابی‌های صنعتی عملکرد قوی دارد.",
  "Meta-Llama-3.2-1B-Instruct.description": "مدل زبان کوچک پیشرفته با درک زبانی قوی، استدلال عالی و تولید متن باکیفیت.",
  "Meta-Llama-3.2-3B-Instruct.description": "مدل زبان کوچک پیشرفته با درک زبانی قوی، استدلال عالی و تولید متن باکیفیت.",
  "Meta-Llama-3.3-70B-Instruct.description": "Llama 3.3 پیشرفته‌ترین مدل چندزبانه متن‌باز Llama است که عملکردی نزدیک به مدل‌های ۴۰۵B با هزینه بسیار پایین ارائه می‌دهد. این مدل بر پایه ترنسفورمر ساخته شده و با SFT و RLHF برای کاربردپذیری و ایمنی بهبود یافته است. نسخه تنظیم‌شده برای گفتگوهای چندزبانه بهینه شده و در ارزیابی‌های صنعتی بسیاری از مدل‌های باز و بسته را پشت سر گذاشته است. تاریخ قطع دانش: دسامبر ۲۰۲۳.",
  "Meta-Llama-4-Maverick-17B-128E-Instruct-FP8.description": "Llama 4 Maverick یک مدل MoE بزرگ با فعال‌سازی کارآمد متخصصان برای عملکرد استدلالی قوی است.",
  "MiniMax-M1.description": "یک مدل استدلالی داخلی جدید با ۸۰ هزار زنجیره تفکر و ورودی ۱ میلیون توکن، با عملکردی در سطح مدل‌های برتر جهانی.",
  "MiniMax-M2-Stable.description": "طراحی‌شده برای کدنویسی کارآمد و جریان‌های کاری عامل‌محور، با هم‌زمانی بالاتر برای استفاده تجاری.",
  "MiniMax-M2.1-Lightning.description": "قابلیت‌های قدرتمند برنامه‌نویسی چندزبانه با تجربه‌ای کاملاً ارتقاء‌یافته. سریع‌تر و کارآمدتر.",
  "MiniMax-M2.1.description": "MiniMax-M2.1 یک مدل بزرگ متن‌باز پیشرفته از MiniMax است که بر حل وظایف پیچیده دنیای واقعی تمرکز دارد. نقاط قوت اصلی آن شامل توانایی برنامه‌نویسی چندزبانه و قابلیت عمل به‌عنوان یک عامل هوشمند برای حل مسائل پیچیده است.",
  "MiniMax-M2.description": "طراحی‌شده به‌طور خاص برای کدنویسی کارآمد و جریان‌های کاری عامل‌محور.",
  "MiniMax-Text-01.description": "MiniMax-01 توجه خطی در مقیاس بزرگ را فراتر از ترنسفورمرهای کلاسیک معرفی می‌کند، با ۴۵۶ میلیارد پارامتر و ۴۵.۹ میلیارد پارامتر فعال در هر عبور. این مدل عملکردی در سطح برتر ارائه می‌دهد و تا ۴ میلیون توکن زمینه را پشتیبانی می‌کند (۳۲ برابر GPT-4o، ۲۰ برابر Claude-3.5-Sonnet).",
  "MiniMaxAI/MiniMax-M1-80k.description": "MiniMax-M1 یک مدل استدلالی با وزن‌های باز و معماری توجه ترکیبی در مقیاس بزرگ است با ۴۵۶ میلیارد پارامتر کل و حدود ۴۵.۹ میلیارد پارامتر فعال در هر توکن. این مدل به‌صورت بومی از زمینه ۱ میلیون توکن پشتیبانی می‌کند و با استفاده از Flash Attention، مصرف FLOPs را در تولید ۱۰۰ هزار توکن تا ۷۵٪ نسبت به DeepSeek R1 کاهش می‌دهد. با معماری MoE به‌همراه CISPO و آموزش تقویتی با توجه ترکیبی، عملکردی پیشرو در استدلال ورودی‌های طولانی و وظایف واقعی مهندسی نرم‌افزار ارائه می‌دهد.",
  "MiniMaxAI/MiniMax-M2.description": "MiniMax-M2 کارایی عامل‌ها را بازتعریف می‌کند. این مدل MoE فشرده، سریع و مقرون‌به‌صرفه با ۲۳۰ میلیارد پارامتر کل و ۱۰ میلیارد پارامتر فعال است که برای وظایف کدنویسی و عامل‌های سطح بالا طراحی شده و در عین حال هوش عمومی قوی را حفظ می‌کند. با تنها ۱۰ میلیارد پارامتر فعال، با مدل‌های بسیار بزرگ‌تر رقابت می‌کند و برای کاربردهای با کارایی بالا ایده‌آل است.",
  "Moonshot-Kimi-K2-Instruct.description": "با ۱ تریلیون پارامتر کل و ۳۲ میلیارد فعال، در میان مدل‌های غیرتفکری، در دانش پیشرفته، ریاضی و کدنویسی در سطح برتر قرار دارد و در وظایف عمومی عامل‌ها نیز قوی‌تر است. برای بارهای کاری عامل‌ها بهینه شده و می‌تواند اقدام کند، نه فقط پاسخ دهد. برای چت عمومی، بداهه‌گویی و تجربه‌های عامل‌محور در سطح واکنشی بدون تفکر طولانی بهترین گزینه است.",
  "NousResearch/Nous-Hermes-2-Mixtral-8x7B-DPO.description": "Nous Hermes 2 - Mixtral 8x7B-DPO (۴۶.۷ میلیارد) یک مدل دستورالعمل‌محور با دقت بالا برای محاسبات پیچیده است.",
  "OmniConsistency.description": "OmniConsistency با معرفی ترنسفورمرهای انتشار در مقیاس بزرگ (DiTs) و داده‌های سبک‌دهی‌شده جفت‌شده، ثبات سبک و تعمیم‌پذیری را در وظایف تصویر به تصویر بهبود می‌بخشد و از تخریب سبک جلوگیری می‌کند.",
  "PaddlePaddle/PaddleOCR-VL-1.5.description": "PaddleOCR-VL-1.5 نسخه ارتقاءیافته‌ای از سری PaddleOCR-VL است که با دقت ۹۴.۵٪ در معیار OmniDocBench v1.5 برای تجزیه و تحلیل اسناد، از مدل‌های بزرگ عمومی و مدل‌های تخصصی تجزیه اسناد پیشی گرفته است. این مدل به‌صورت نوآورانه از مکان‌یابی جعبه‌های نامنظم برای عناصر سند پشتیبانی می‌کند و تصاویر اسکن‌شده، کج‌شده و گرفته‌شده از صفحه‌نمایش را به‌خوبی پردازش می‌کند.",
  "Phi-3-medium-128k-instruct.description": "همان مدل Phi-3-medium با پنجره زمینه بزرگ‌تر برای RAG یا نمونه‌های چندگانه.",
  "Phi-3-medium-4k-instruct.description": "مدلی با ۱۴ میلیارد پارامتر و کیفیت بالاتر نسبت به Phi-3-mini، متمرکز بر داده‌های با کیفیت و نیازمند استدلال.",
  "Phi-3-mini-128k-instruct.description": "همان مدل Phi-3-mini با پنجره زمینه بزرگ‌تر برای RAG یا نمونه‌های چندگانه.",
  "Phi-3-mini-4k-instruct.description": "کوچک‌ترین عضو خانواده Phi-3، بهینه‌شده برای کیفیت و تأخیر پایین.",
  "Phi-3-small-128k-instruct.description": "همان مدل Phi-3-small با پنجره زمینه بزرگ‌تر برای RAG یا نمونه‌های چندگانه.",
  "Phi-3-small-8k-instruct.description": "مدلی با ۷ میلیارد پارامتر و کیفیت بالاتر نسبت به Phi-3-mini، متمرکز بر داده‌های با کیفیت و نیازمند استدلال.",
  "Phi-3.5-mini-instruct.description": "نسخه به‌روزشده مدل Phi-3-mini.",
  "Phi-3.5-vision-instrust.description": "نسخه به‌روزشده مدل Phi-3-vision.",
  "Pro/MiniMaxAI/MiniMax-M2.1.description": "MiniMax-M2.1 یک مدل زبان بزرگ متن‌باز است که برای قابلیت‌های عامل بهینه‌سازی شده و در برنامه‌نویسی، استفاده از ابزارها، پیروی از دستورالعمل‌ها و برنامه‌ریزی بلندمدت عملکرد برجسته‌ای دارد. این مدل از توسعه نرم‌افزار چندزبانه و اجرای جریان‌های کاری پیچیده چندمرحله‌ای پشتیبانی می‌کند و با کسب امتیاز ۷۴.۰ در SWE-bench Verified، در سناریوهای چندزبانه از Claude Sonnet 4.5 پیشی گرفته است.",
  "Pro/Qwen/Qwen2-7B-Instruct.description": "Qwen2-7B-Instruct یک مدل LLM با ۷ میلیارد پارامتر در سری Qwen2 است که با معماری ترنسفورمر، SwiGLU، بایاس QKV توجه و توجه گروهی طراحی شده و ورودی‌های بزرگ را مدیریت می‌کند. این مدل در درک زبان، تولید، وظایف چندزبانه، کدنویسی، ریاضی و استدلال عملکرد قوی دارد و از بسیاری از مدل‌های باز پیشی می‌گیرد و با مدل‌های اختصاصی رقابت می‌کند. در چندین معیار از Qwen1.5-7B-Chat بهتر عمل می‌کند.",
  "Pro/Qwen/Qwen2.5-7B-Instruct.description": "Qwen2.5-7B-Instruct بخشی از جدیدترین سری LLM علی‌بابا کلود است. این مدل ۷ میلیاردی پیشرفت‌های قابل توجهی در کدنویسی و ریاضی دارد، از بیش از ۲۹ زبان پشتیبانی می‌کند و در پیروی از دستورالعمل‌ها، درک داده‌های ساختاریافته و تولید خروجی ساختاریافته (به‌ویژه JSON) بهبود یافته است.",
  "Pro/Qwen/Qwen2.5-Coder-7B-Instruct.description": "Qwen2.5-Coder-7B-Instruct جدیدترین مدل LLM متمرکز بر کد از علی‌بابا کلود است. بر پایه Qwen2.5 ساخته شده و با ۵.۵ تریلیون توکن آموزش دیده، تولید کد، استدلال و اصلاح را به‌طور قابل توجهی بهبود می‌بخشد و در عین حال توانایی‌های ریاضی و عمومی را حفظ می‌کند، و پایه‌ای قوی برای عامل‌های کدنویسی فراهم می‌کند.",
  "Pro/Qwen/Qwen2.5-VL-7B-Instruct.description": "Qwen2.5-VL یک مدل جدید زبان-بینایی از سری Qwen با درک بصری قوی است. این مدل متن، نمودارها و چیدمان‌ها را در تصاویر تحلیل می‌کند، ویدیوهای طولانی و رویدادها را درک می‌کند، از استدلال و استفاده از ابزار پشتیبانی می‌کند، اشیاء را در قالب‌های مختلف مکان‌یابی می‌کند و خروجی‌های ساختاریافته تولید می‌کند. همچنین وضوح پویا و نرخ فریم را برای درک ویدیو بهبود می‌بخشد و کارایی رمزگذار بینایی را افزایش می‌دهد.",
  "Pro/THUDM/GLM-4.1V-9B-Thinking.description": "GLM-4.1V-9B-Thinking یک مدل VLM متن‌باز از Zhipu AI و آزمایشگاه KEG دانشگاه Tsinghua است که برای شناخت چندوجهی پیچیده طراحی شده است. بر پایه GLM-4-9B-0414 ساخته شده و با افزودن زنجیره تفکر و یادگیری تقویتی، استدلال میان‌وجهی و پایداری را به‌طور قابل توجهی بهبود می‌بخشد.",
  "Pro/THUDM/glm-4-9b-chat.description": "GLM-4-9B-Chat مدل متن‌باز GLM-4 از Zhipu AI است. این مدل در معناشناسی، ریاضی، استدلال، کدنویسی و دانش عملکرد قوی دارد. فراتر از چت چندنوبتی، از مرور وب، اجرای کد، فراخوانی ابزارهای سفارشی و استدلال متون طولانی پشتیبانی می‌کند. از ۲۶ زبان (از جمله چینی، انگلیسی، ژاپنی، کره‌ای، آلمانی) پشتیبانی می‌کند. در معیارهایی مانند AlignBench-v2، MT-Bench، MMLU و C-Eval عملکرد خوبی دارد و تا ۱۲۸ هزار توکن زمینه را برای استفاده‌های علمی و تجاری پشتیبانی می‌کند.",
  "Pro/deepseek-ai/DeepSeek-R1-Distill-Qwen-7B.description": "DeepSeek-R1-Distill-Qwen-7B از Qwen2.5-Math-7B استخراج شده و بر روی ۸۰۰ هزار نمونه منتخب DeepSeek-R1 تنظیم دقیق شده است. این مدل عملکرد قوی دارد: ۹۲.۸٪ در MATH-500، ۵۵.۵٪ در AIME 2024 و امتیاز ۱۱۸۹ در CodeForces برای یک مدل ۷ میلیاردی.",
  "Pro/deepseek-ai/DeepSeek-R1.description": "DeepSeek-R1 یک مدل استدلالی مبتنی بر یادگیری تقویتی است که تکرار را کاهش داده و خوانایی را بهبود می‌بخشد. با استفاده از داده‌های شروع سرد پیش از RL، استدلال را بیشتر تقویت می‌کند، در وظایف ریاضی، کدنویسی و استدلال با OpenAI-o1 برابری می‌کند و با آموزش دقیق، نتایج کلی را بهبود می‌بخشد.",
  "Pro/deepseek-ai/DeepSeek-V3.1-Terminus.description": "DeepSeek-V3.1-Terminus نسخه به‌روزشده مدل V3.1 است که به‌عنوان یک LLM عامل ترکیبی طراحی شده است. مشکلات گزارش‌شده کاربران را رفع کرده، پایداری و سازگاری زبانی را بهبود داده و نویسه‌های غیرعادی و ترکیب چینی/انگلیسی را کاهش داده است. حالت‌های تفکری و غیرتفکری را با قالب‌های چت یکپارچه می‌کند تا امکان جابجایی انعطاف‌پذیر فراهم شود. همچنین عملکرد عامل کد و عامل جستجو را برای استفاده مطمئن‌تر از ابزارها و وظایف چندمرحله‌ای بهبود می‌بخشد.",
  "Pro/deepseek-ai/DeepSeek-V3.2-Exp.description": "DeepSeek-V3.2-Exp یک نسخه آزمایشی از V3.2 است که پلی به سوی معماری بعدی ایجاد می‌کند. با افزودن DeepSeek Sparse Attention (DSA) بر پایه V3.1-Terminus، کارایی آموزش و استنتاج در زمینه‌های طولانی را بهبود می‌بخشد و برای استفاده از ابزارها، درک اسناد طولانی و استدلال چندمرحله‌ای بهینه شده است. برای بررسی کارایی بالاتر استدلال با بودجه زمینه بزرگ ایده‌آل است.",
  "Pro/deepseek-ai/DeepSeek-V3.description": "DeepSeek-V3 یک مدل MoE با ۶۷۱ میلیارد پارامتر است که از MLA و DeepSeekMoE با تعادل بار بدون اتلاف برای استنتاج و آموزش کارآمد استفاده می‌کند. با پیش‌آموزش بر روی ۱۴.۸ تریلیون توکن با کیفیت بالا و تنظیم بیشتر با SFT و RL، از سایر مدل‌های باز پیشی می‌گیرد و به مدل‌های بسته پیشرو نزدیک می‌شود.",
  "Pro/moonshotai/Kimi-K2-Instruct-0905.description": "Kimi K2-Instruct-0905 جدیدترین و قدرتمندترین نسخه Kimi K2 است. این مدل MoE سطح بالا با ۱ تریلیون پارامتر کل و ۳۲ میلیارد پارامتر فعال است. ویژگی‌های کلیدی شامل هوش کدنویسی عامل‌محور قوی‌تر با پیشرفت‌های قابل توجه در معیارها و وظایف واقعی عامل‌ها، به‌علاوه زیبایی‌شناسی و قابلیت استفاده بهتر در کدنویسی رابط کاربری است.",
  "Pro/moonshotai/Kimi-K2-Thinking.description": "Kimi K2 Thinking Turbo نسخه توربو بهینه‌شده برای سرعت استدلال و توان عملیاتی است، در حالی که استدلال چندمرحله‌ای و استفاده از ابزار K2 Thinking را حفظ می‌کند. این مدل MoE با حدود ۱ تریلیون پارامتر کل، زمینه بومی ۲۵۶ هزار توکن و فراخوانی ابزار در مقیاس بزرگ پایدار برای سناریوهای تولیدی با نیازهای سخت‌گیرانه‌تر در تأخیر و هم‌زمانی است.",
  "Pro/moonshotai/Kimi-K2.5.description": "Kimi K2.5 یک مدل عامل چندوجهی بومی متن‌باز است که بر پایه Kimi-K2-Base ساخته شده و با حدود ۱.۵ تریلیون توکن ترکیبی بینایی و متنی آموزش دیده است. این مدل از معماری MoE با ۱ تریلیون پارامتر کل و ۳۲ میلیارد پارامتر فعال بهره می‌برد و از پنجره متنی ۲۵۶ هزار توکن پشتیبانی می‌کند و درک زبان و تصویر را به‌صورت یکپارچه ارائه می‌دهد.",
  "Pro/zai-org/glm-4.7.description": "GLM-4.7 مدل پرچم‌دار نسل جدید Zhipu با ۳۵۵ میلیارد پارامتر کل و ۳۲ میلیارد پارامتر فعال است که به‌طور کامل در زمینه‌های گفت‌وگوی عمومی، استدلال و توانایی‌های عامل به‌روزرسانی شده است. GLM-4.7 تفکر درهم‌تنیده را بهبود می‌بخشد و مفاهیم تفکر حفظ‌شده و تفکر در سطح نوبت را معرفی می‌کند.",
  "QwQ-32B-Preview.description": "Qwen QwQ یک مدل تحقیقاتی آزمایشی است که بر بهبود توانایی استدلال تمرکز دارد.",
  "Qwen/QVQ-72B-Preview.description": "QVQ-72B-Preview یک مدل تحقیقاتی از Qwen است که بر استدلال بصری تمرکز دارد و در درک صحنه‌های پیچیده و حل مسائل ریاضی بصری توانمند است.",
  "Qwen/QwQ-32B-Preview.description": "Qwen QwQ یک مدل تحقیقاتی آزمایشی است که بر بهبود استدلال هوش مصنوعی تمرکز دارد.",
  "Qwen/QwQ-32B.description": "QwQ یک مدل استدلال از خانواده Qwen است. در مقایسه با مدل‌های استاندارد تنظیم‌شده با دستورالعمل، این مدل تفکر و استدلال را اضافه می‌کند که عملکرد مدل را در وظایف دشوار به‌طور قابل توجهی بهبود می‌بخشد. QwQ-32B یک مدل استدلال میان‌رده است که با مدل‌های برتر مانند DeepSeek-R1 و o1-mini رقابت می‌کند. این مدل از RoPE، SwiGLU، RMSNorm و بایاس QKV در توجه استفاده می‌کند و دارای ۶۴ لایه و ۴۰ سر توجه Q (با ۸ KV در GQA) است.",
  "Qwen/Qwen-Image-Edit-2509.description": "Qwen-Image-Edit-2509 جدیدترین نسخه ویرایش مدل Qwen-Image از تیم Qwen است. این مدل بر پایه Qwen-Image با ۲۰ میلیارد پارامتر ساخته شده و قابلیت رندر دقیق متن را به ویرایش تصویر گسترش می‌دهد. با استفاده از معماری کنترل دوگانه، ورودی‌ها را به Qwen2.5-VL برای کنترل معنایی و به رمزگذار VAE برای کنترل ظاهر ارسال می‌کند و امکان ویرایش در سطح معنا و ظاهر را فراهم می‌سازد. این مدل از ویرایش‌های محلی (افزودن/حذف/تغییر) و ویرایش‌های معنایی سطح بالا مانند خلق IP و انتقال سبک پشتیبانی می‌کند و در عین حال معنا را حفظ می‌نماید. این مدل در چندین معیار عملکرد پیشرفته‌ای (SOTA) دارد.",
  "Qwen/Qwen-Image.description": "Qwen-Image یک مدل پایه تولید تصویر با ۲۰ میلیارد پارامتر از تیم Qwen است. این مدل در رندر متن‌های پیچیده و ویرایش دقیق تصویر، به‌ویژه برای متون چینی/انگلیسی با وفاداری بالا، پیشرفت چشمگیری دارد. از چیدمان‌های چندخطی و پاراگرافی پشتیبانی می‌کند و انسجام تایپوگرافی را حفظ می‌نماید. فراتر از رندر متن، از سبک‌های متنوعی از واقع‌گرایانه تا انیمه پشتیبانی می‌کند و قابلیت‌هایی مانند انتقال سبک، افزودن/حذف اشیاء، افزایش جزئیات، ویرایش متن و کنترل حالت را ارائه می‌دهد و هدف آن تبدیل شدن به یک مدل پایه جامع برای خلق بصری است.",
  "Qwen/Qwen2-72B-Instruct.description": "Qwen 2 Instruct (72B) دستورالعمل‌ها را با دقت بالا برای بارهای کاری سازمانی دنبال می‌کند.",
  "Qwen/Qwen2-7B-Instruct.description": "Qwen2-7B-Instruct یک مدل ۷ میلیارد پارامتری تنظیم‌شده با دستورالعمل در سری Qwen2 است که از Transformer، SwiGLU، بایاس QKV و توجه با پرس‌وجوی گروهی استفاده می‌کند. این مدل ورودی‌های بزرگ را پردازش می‌کند و در معیارهای درک، تولید، چندزبانه، کدنویسی، ریاضی و استدلال عملکرد قوی دارد و از بیشتر مدل‌های باز پیشی می‌گیرد و در چندین ارزیابی از Qwen1.5-7B-Chat بهتر عمل می‌کند.",
  "Qwen/Qwen2-VL-72B-Instruct.description": "Qwen2-VL جدیدترین مدل Qwen-VL است که در معیارهای بینایی مانند MathVista، DocVQA، RealWorldQA و MTVQA به سطح پیشرفته (SOTA) رسیده است. این مدل توانایی درک ویدیوهای بیش از ۲۰ دقیقه را برای پرسش و پاسخ ویدیویی، گفت‌وگو و تولید محتوا دارد. همچنین از استدلال پیچیده و تصمیم‌گیری پشتیبانی می‌کند و با دستگاه‌ها/ربات‌ها برای اقدامات مبتنی بر بینایی یکپارچه می‌شود. فراتر از زبان‌های انگلیسی و چینی، این مدل می‌تواند متون را به زبان‌های مختلف از جمله بیشتر زبان‌های اروپایی، ژاپنی، کره‌ای، عربی و ویتنامی بخواند.",
  "Qwen/Qwen2.5-14B-Instruct.description": "Qwen2.5-14B-Instruct بخشی از جدیدترین سری مدل‌های زبانی بزرگ (LLM) علی‌بابا کلود است. این مدل ۱۴ میلیارد پارامتری پیشرفت‌های قابل توجهی در کدنویسی و ریاضی دارد، از بیش از ۲۹ زبان پشتیبانی می‌کند و در دنبال کردن دستورالعمل‌ها، درک داده‌های ساختاریافته و تولید خروجی ساختاریافته (به‌ویژه JSON) بهبود یافته است.",
  "Qwen/Qwen2.5-32B-Instruct.description": "Qwen2.5-32B-Instruct بخشی از جدیدترین سری مدل‌های زبانی بزرگ (LLM) علی‌بابا کلود است. این مدل ۳۲ میلیارد پارامتری پیشرفت‌های قابل توجهی در کدنویسی و ریاضی دارد، از بیش از ۲۹ زبان پشتیبانی می‌کند و در دنبال کردن دستورالعمل‌ها، درک داده‌های ساختاریافته و تولید خروجی ساختاریافته (به‌ویژه JSON) بهبود یافته است.",
  "Qwen/Qwen2.5-72B-Instruct-128K.description": "Qwen2.5-72B-Instruct بخشی از جدیدترین سری مدل‌های زبانی بزرگ (LLM) علی‌بابا کلود است. این مدل ۷۲ میلیارد پارامتری در کدنویسی و ریاضی بهبود یافته، از ورودی تا ۱۲۸ هزار توکن و خروجی بیش از ۸ هزار توکن پشتیبانی می‌کند، بیش از ۲۹ زبان را پوشش می‌دهد و در دنبال کردن دستورالعمل‌ها و تولید خروجی ساختاریافته (به‌ویژه JSON) عملکرد بهتری دارد.",
  "Qwen/Qwen2.5-72B-Instruct-Turbo.description": "Qwen2.5 یک خانواده جدید از مدل‌های زبانی بزرگ است که برای وظایف مبتنی بر دستورالعمل بهینه‌سازی شده است.",
  "Qwen/Qwen2.5-72B-Instruct.description": "Qwen2.5-72B-Instruct بخشی از جدیدترین سری مدل‌های زبانی بزرگ (LLM) علی‌بابا کلود است. این مدل ۷۲ میلیارد پارامتری پیشرفت‌های قابل توجهی در کدنویسی و ریاضی دارد، از بیش از ۲۹ زبان پشتیبانی می‌کند و در دنبال کردن دستورالعمل‌ها، درک داده‌های ساختاریافته و تولید خروجی ساختاریافته (به‌ویژه JSON) بهبود یافته است.",
  "Qwen/Qwen2.5-7B-Instruct-Turbo.description": "Qwen2.5 یک خانواده جدید از مدل‌های زبانی بزرگ است که برای وظایف مبتنی بر دستورالعمل بهینه‌سازی شده است.",
  "Qwen/Qwen2.5-7B-Instruct.description": "Qwen2.5-7B-Instruct بخشی از جدیدترین سری مدل‌های زبانی بزرگ (LLM) علی‌بابا کلود است. این مدل ۷ میلیارد پارامتری پیشرفت‌های قابل توجهی در کدنویسی و ریاضی دارد، از بیش از ۲۹ زبان پشتیبانی می‌کند و در دنبال کردن دستورالعمل‌ها، درک داده‌های ساختاریافته و تولید خروجی ساختاریافته (به‌ویژه JSON) بهبود یافته است.",
  "Qwen/Qwen2.5-Coder-32B-Instruct.description": "Qwen2.5 Coder 32B Instruct جدیدترین مدل کدنویسی علی‌بابا کلود است. این مدل بر پایه Qwen2.5 ساخته شده و با ۵.۵ تریلیون توکن آموزش دیده است. این مدل به‌طور قابل توجهی در تولید کد، استدلال و اصلاح کد بهبود یافته و در عین حال توانایی‌های ریاضی و عمومی خود را حفظ کرده است و پایه‌ای قوی برای عامل‌های کدنویسی فراهم می‌کند.",
  "Qwen/Qwen2.5-Coder-7B-Instruct.description": "Qwen2.5-Coder-7B-Instruct جدیدترین مدل کدنویسی علی‌بابا کلود است. این مدل بر پایه Qwen2.5 ساخته شده و با ۵.۵ تریلیون توکن آموزش دیده است. این مدل به‌طور قابل توجهی در تولید کد، استدلال و اصلاح کد بهبود یافته و در عین حال توانایی‌های ریاضی و عمومی خود را حفظ کرده است و پایه‌ای محکم برای عامل‌های کدنویسی فراهم می‌کند.",
  "Qwen/Qwen2.5-VL-32B-Instruct.description": "Qwen2.5-VL-32B-Instruct یک مدل چندوجهی از تیم Qwen است. این مدل اشیاء رایج را شناسایی کرده و متن، نمودارها، آیکون‌ها، گرافیک‌ها و چیدمان‌ها را تحلیل می‌کند. به‌عنوان یک عامل بصری، می‌تواند استدلال کند و ابزارها را به‌صورت پویا کنترل نماید، از جمله استفاده از رایانه و تلفن. این مدل اشیاء را با دقت مکان‌یابی کرده و خروجی‌های ساختاریافته برای فاکتورها و جداول تولید می‌کند. در مقایسه با Qwen2-VL، نسخه RL در ریاضی و حل مسئله بهبود یافته و پاسخ‌هایی با ترجیح انسانی بیشتری ارائه می‌دهد.",
  "Qwen/Qwen2.5-VL-72B-Instruct.description": "Qwen2.5-VL مدل بینایی-زبان در سری Qwen2.5 است که با ارتقاءهای عمده همراه است: درک بصری قوی‌تر برای اشیاء، متن، نمودارها و چیدمان‌ها؛ استدلال به‌عنوان یک عامل بصری با استفاده پویا از ابزارها؛ درک ویدیوهای بیش از ۱ ساعت و ثبت رویدادهای کلیدی؛ مکان‌یابی دقیق اشیاء از طریق جعبه‌ها یا نقاط؛ و خروجی‌های ساختاریافته برای داده‌های اسکن‌شده مانند فاکتورها و جداول.",
  "Qwen/Qwen3-14B.description": "Qwen3 یک مدل نسل جدید از خانواده Tongyi Qwen است که پیشرفت‌های چشمگیری در استدلال، توانایی عمومی، قابلیت‌های عامل‌محور و عملکرد چندزبانه دارد و از تغییر حالت‌های تفکر پشتیبانی می‌کند.",
  "Qwen/Qwen3-235B-A22B-Instruct-2507.description": "Qwen3-235B-A22B-Instruct-2507 یک مدل پرچم‌دار MoE از سری Qwen3 با ۲۳۵ میلیارد پارامتر کل و ۲۲ میلیارد پارامتر فعال است. این نسخه غیرتفکری به‌روزرسانی شده، بر بهبود پیروی از دستورالعمل‌ها، استدلال منطقی، درک متن، ریاضیات، علوم، برنامه‌نویسی و استفاده از ابزار تمرکز دارد. همچنین دانش چندزبانه در حوزه‌های کم‌کاربرد را گسترش داده و با ترجیحات کاربران در وظایف ذهنی و باز بهتر هم‌راستا می‌شود.",
  "Qwen/Qwen3-235B-A22B-Thinking-2507.description": "Qwen3-235B-A22B-Thinking-2507 یک مدل Qwen3 متمرکز بر استدلال پیچیده و دشوار است. این مدل از معماری MoE با ۲۳۵ میلیارد پارامتر کل و حدود ۲۲ میلیارد پارامتر فعال در هر توکن استفاده می‌کند تا بهره‌وری را افزایش دهد. به‌عنوان یک مدل تفکری اختصاصی، پیشرفت‌های چشمگیری در منطق، ریاضیات، علوم، برنامه‌نویسی و معیارهای دانشگاهی نشان می‌دهد و به عملکردی در سطح برتر در تفکر باز می‌رسد. همچنین پیروی از دستورالعمل‌ها، استفاده از ابزار و تولید متن را بهبود می‌بخشد و به‌صورت بومی از زمینه ۲۵۶ هزار توکن برای استدلال عمیق و اسناد طولانی پشتیبانی می‌کند.",
  "Qwen/Qwen3-235B-A22B.description": "Qwen3 یک مدل نسل جدید از خانواده Tongyi Qwen است که پیشرفت‌های چشمگیری در استدلال، توانایی عمومی، قابلیت‌های عامل‌محور و عملکرد چندزبانه دارد و از تغییر حالت‌های تفکر پشتیبانی می‌کند.",
  "Qwen/Qwen3-30B-A3B-Instruct-2507.description": "Qwen3-30B-A3B-Instruct-2507 نسخه غیرتفکری به‌روزرسانی‌شده Qwen3-30B-A3B است. این مدل MoE دارای ۳۰.۵ میلیارد پارامتر کل و ۳.۳ میلیارد پارامتر فعال است. این مدل به‌طور قابل‌توجهی پیروی از دستورالعمل‌ها، استدلال منطقی، درک متن، ریاضیات، علوم، برنامه‌نویسی و استفاده از ابزار را بهبود می‌بخشد، دانش چندزبانه در حوزه‌های کم‌کاربرد را گسترش می‌دهد و با ترجیحات کاربران در وظایف ذهنی باز بهتر هم‌راستا می‌شود. از زمینه ۲۵۶ هزار توکن پشتیبانی می‌کند. این مدل فقط در حالت غیرتفکری عمل می‌کند و تگ‌های `<think></think>` تولید نمی‌کند.",
  "Qwen/Qwen3-30B-A3B-Thinking-2507.description": "Qwen3-30B-A3B-Thinking-2507 جدیدترین مدل تفکری در سری Qwen3 است. این مدل MoE با ۳۰.۵ میلیارد پارامتر کل و ۳.۳ میلیارد پارامتر فعال، بر وظایف پیچیده تمرکز دارد. پیشرفت‌های قابل‌توجهی در منطق، ریاضیات، علوم، برنامه‌نویسی و معیارهای دانشگاهی نشان می‌دهد و پیروی از دستورالعمل‌ها، استفاده از ابزار، تولید متن و هم‌راستایی با ترجیحات را بهبود می‌بخشد. به‌صورت بومی از زمینه ۲۵۶ هزار توکن پشتیبانی می‌کند و قابلیت گسترش تا ۱ میلیون توکن را دارد. این نسخه برای حالت تفکری طراحی شده و استدلال گام‌به‌گام دقیق و قابلیت‌های قوی عامل‌محور ارائه می‌دهد.",
  "Qwen/Qwen3-30B-A3B.description": "Qwen3 یک مدل نسل جدید از خانواده Tongyi Qwen است که پیشرفت‌های چشمگیری در استدلال، توانایی عمومی، قابلیت‌های عامل‌محور و عملکرد چندزبانه دارد و از تغییر حالت‌های تفکر پشتیبانی می‌کند.",
  "Qwen/Qwen3-32B.description": "Qwen3 یک مدل نسل جدید از خانواده Tongyi Qwen است که پیشرفت‌های چشمگیری در استدلال، توانایی عمومی، قابلیت‌های عامل‌محور و عملکرد چندزبانه دارد و از تغییر حالت‌های تفکر پشتیبانی می‌کند.",
  "Qwen/Qwen3-8B.description": "Qwen3 یک مدل نسل جدید از خانواده Tongyi Qwen است که پیشرفت‌های چشمگیری در استدلال، توانایی عمومی، قابلیت‌های عامل‌محور و عملکرد چندزبانه دارد و از تغییر حالت‌های تفکر پشتیبانی می‌کند.",
  "Qwen/Qwen3-Coder-30B-A3B-Instruct.description": "Qwen3-Coder-30B-A3B-Instruct یک مدل کدنویسی از تیم Qwen است. این مدل برای عملکرد بالا و بهره‌وری بهینه‌سازی شده و توانایی‌های کدنویسی را تقویت می‌کند. در کدنویسی عامل‌محور، عملیات خودکار مرورگر و استفاده از ابزار در میان مدل‌های باز عملکرد برجسته‌ای دارد. به‌صورت بومی از زمینه ۲۵۶ هزار توکن پشتیبانی می‌کند و می‌تواند تا ۱ میلیون توکن برای درک در سطح پایگاه کد گسترش یابد. این مدل کدنویسی عامل‌محور را در پلتفرم‌هایی مانند Qwen Code و CLINE با فرمت فراخوانی تابع اختصاصی پشتیبانی می‌کند.",
  "Qwen/Qwen3-Coder-480B-A35B-Instruct.description": "Qwen3-Coder-480B-A35B-Instruct پیشرفته‌ترین مدل کدنویسی عامل‌محور علی‌بابا تا به امروز است. این مدل MoE با ۴۸۰ میلیارد پارامتر کل و ۳۵ میلیارد پارامتر فعال، تعادلی بین بهره‌وری و عملکرد برقرار می‌کند. به‌صورت بومی از زمینه ۲۵۶ هزار توکن پشتیبانی می‌کند و از طریق YaRN تا ۱ میلیون توکن گسترش می‌یابد و امکان پردازش پایگاه‌های کد بزرگ را فراهم می‌سازد. برای جریان‌های کاری کدنویسی عامل‌محور طراحی شده و می‌تواند با ابزارها و محیط‌ها تعامل داشته باشد تا وظایف پیچیده برنامه‌نویسی را حل کند. در معیارهای کدنویسی و عامل‌محور در میان مدل‌های باز نتایج برتری دارد و با مدل‌های پیشرو مانند Claude Sonnet 4 قابل مقایسه است.",
  "Qwen/Qwen3-Next-80B-A3B-Instruct.description": "Qwen3-Next-80B-A3B-Instruct یک مدل پایه نسل جدید است که از معماری Qwen3-Next برای بهره‌وری شدید در آموزش و استنتاج استفاده می‌کند. این مدل ترکیبی از توجه ترکیبی (Gated DeltaNet + Gated Attention)، MoE بسیار پراکنده و بهینه‌سازی‌های پایداری آموزش را به‌کار می‌گیرد. با ۸۰ میلیارد پارامتر کل اما حدود ۳ میلیارد پارامتر فعال در زمان استنتاج، مصرف محاسباتی را کاهش داده و بیش از ۱۰ برابر بازدهی نسبت به Qwen3-32B در زمینه‌های بالای ۳۲ هزار توکن ارائه می‌دهد. این نسخه تنظیم‌شده برای دستورالعمل‌ها، وظایف عمومی را هدف قرار می‌دهد (بدون حالت تفکری). در برخی معیارها عملکردی مشابه Qwen3-235B دارد و در وظایف با زمینه بسیار طولانی مزایای قابل‌توجهی نشان می‌دهد.",
  "Qwen/Qwen3-Next-80B-A3B-Thinking.description": "Qwen3-Next-80B-A3B-Thinking یک مدل پایه نسل جدید برای استدلال پیچیده است. این مدل از معماری Qwen3-Next با توجه ترکیبی (Gated DeltaNet + Gated Attention) و MoE بسیار پراکنده برای بهره‌وری شدید در آموزش و استنتاج استفاده می‌کند. با ۸۰ میلیارد پارامتر کل اما حدود ۳ میلیارد پارامتر فعال در زمان استنتاج، مصرف محاسباتی را کاهش داده و بیش از ۱۰ برابر بازدهی نسبت به Qwen3-32B در زمینه‌های بالای ۳۲ هزار توکن ارائه می‌دهد. این نسخه تفکری وظایف چندمرحله‌ای مانند اثبات‌ها، ترکیب کد، تحلیل منطقی و برنامه‌ریزی را هدف قرار می‌دهد و زنجیره‌ای ساختاریافته از تفکر تولید می‌کند. از Qwen3-32B-Thinking عملکرد بهتری دارد و در چندین معیار از Gemini-2.5-Flash-Thinking پیشی می‌گیرد.",
  "Qwen/Qwen3-Omni-30B-A3B-Captioner.description": "Qwen3-Omni-30B-A3B-Captioner یک مدل VLM از سری Qwen3 است که برای تولید کپشن‌های تصویری با کیفیت بالا، دقیق و جزئی طراحی شده است. این مدل از معماری MoE با ۳۰ میلیارد پارامتر استفاده می‌کند تا تصاویر را به‌طور عمیق درک کرده و توصیف‌های روان تولید کند. در ثبت جزئیات، درک صحنه، شناسایی اشیاء و استدلال رابطه‌ای عملکرد برجسته‌ای دارد.",
  "Qwen/Qwen3-Omni-30B-A3B-Instruct.description": "Qwen3-Omni-30B-A3B-Instruct یک مدل MoE از سری Qwen3 با ۳۰ میلیارد پارامتر کل و ۳ میلیارد پارامتر فعال است که عملکرد قوی را با هزینه استنتاج پایین ارائه می‌دهد. این مدل با داده‌های چندمنبعی و چندزبانه با کیفیت بالا آموزش دیده و از ورودی‌های تمام‌مدال (متن، تصویر، صدا، ویدیو) و درک و تولید میان‌مدال پشتیبانی می‌کند.",
  "Qwen/Qwen3-Omni-30B-A3B-Thinking.description": "Qwen3-Omni-30B-A3B-Thinking هسته تفکری Qwen3-Omni است. این مدل ورودی‌های چندمدال (متن، صدا، تصویر، ویدیو) را پردازش کرده و استدلال زنجیره‌ای پیچیده انجام می‌دهد و ورودی‌ها را به نمایش مشترک برای درک عمیق میان‌مدال تبدیل می‌کند. این مدل MoE با ۳۰ میلیارد پارامتر کل و ۳ میلیارد پارامتر فعال است که تعادلی بین استدلال قوی و بهره‌وری محاسباتی برقرار می‌کند.",
  "Qwen/Qwen3-VL-235B-A22B-Instruct.description": "Qwen3-VL-235B-A22B-Instruct یک مدل بزرگ تنظیم‌شده با دستورالعمل از سری Qwen3-VL است که بر پایه MoE ساخته شده و درک و تولید چندمدال عالی ارائه می‌دهد. به‌صورت بومی از زمینه ۲۵۶ هزار توکن پشتیبانی می‌کند و برای خدمات تولیدی چندمدال با هم‌زمانی بالا مناسب است.",
  "Qwen/Qwen3-VL-235B-A22B-Thinking.description": "Qwen3-VL-235B-A22B-Thinking نسخه تفکری پرچم‌دار Qwen3-VL است که برای استدلال پیچیده چندمدال، استدلال با زمینه طولانی و تعامل عامل‌محور در سناریوهای سازمانی بهینه‌سازی شده است.",
  "Qwen/Qwen3-VL-30B-A3B-Instruct.description": "Qwen3-VL-30B-A3B-Instruct نسخه تنظیم‌شده با دستورالعمل از مدل Qwen3-VL است که درک و تولید زبان-تصویر قوی دارد. به‌صورت بومی از زمینه ۲۵۶ هزار توکن برای چت چندمدال و تولید مشروط بر تصویر پشتیبانی می‌کند.",
  "Qwen/Qwen3-VL-30B-A3B-Thinking.description": "Qwen3-VL-30B-A3B-Thinking نسخه تقویت‌شده برای استدلال از Qwen3-VL است که برای استدلال چندمدال، تبدیل تصویر به کد و درک بصری پیچیده بهینه‌سازی شده است. از زمینه ۲۵۶ هزار توکن با توانایی قوی در زنجیره تفکر پشتیبانی می‌کند.",
  "Qwen/Qwen3-VL-32B-Instruct.description": "Qwen3-VL-32B-Instruct یک مدل زبان-تصویر از تیم Qwen است که نتایج پیشرفته‌ای در چندین معیار VL دارد. از تصاویر با وضوح مگاپیکسل پشتیبانی می‌کند و درک بصری قوی، OCR چندزبانه، مکان‌یابی بصری دقیق و گفت‌وگوی تصویری ارائه می‌دهد. وظایف پیچیده چندمدال را مدیریت کرده و از فراخوانی ابزار و تکمیل پیشوند پشتیبانی می‌کند.",
  "Qwen/Qwen3-VL-32B-Thinking.description": "Qwen3-VL-32B-Thinking برای استدلال بصری پیچیده بهینه‌سازی شده است. این مدل دارای حالت تفکری داخلی است که مراحل استدلال میانی را قبل از پاسخ تولید می‌کند و منطق چندمرحله‌ای، برنامه‌ریزی و استدلال پیچیده را تقویت می‌کند. از تصاویر مگاپیکسلی، درک بصری قوی، OCR چندزبانه، مکان‌یابی دقیق، گفت‌وگوی تصویری، فراخوانی ابزار و تکمیل پیشوند پشتیبانی می‌کند.",
  "Qwen/Qwen3-VL-8B-Instruct.description": "Qwen3-VL-8B-Instruct یک مدل زبان-تصویر از سری Qwen3 است که بر پایه Qwen3-8B-Instruct ساخته شده و با داده‌های بزرگ تصویر-متن آموزش دیده است. در درک بصری عمومی، گفت‌وگوی متمرکز بر تصویر و شناسایی متن چندزبانه در تصاویر عملکرد برجسته‌ای دارد و برای پرسش‌وپاسخ بصری، کپشن‌نویسی، پیروی از دستورالعمل چندمدال و استفاده از ابزار مناسب است.",
  "Qwen/Qwen3-VL-8B-Thinking.description": "Qwen3-VL-8B-Thinking نسخه تفکری بصری Qwen3 است که برای استدلال پیچیده چندمرحله‌ای بهینه‌سازی شده است. این مدل زنجیره تفکر را قبل از پاسخ تولید می‌کند تا دقت را افزایش دهد و برای پرسش‌وپاسخ بصری عمیق و تحلیل دقیق تصویر ایده‌آل است.",
  "Qwen2-72B-Instruct.description": "Qwen2 جدیدترین مدل از سری Qwen است که از پنجره متنی ۱۲۸ هزار توکن پشتیبانی می‌کند. در مقایسه با بهترین مدل‌های متن‌باز امروزی، Qwen2-72B درک زبان طبیعی، دانش، کدنویسی، ریاضیات و توانایی‌های چندزبانه را به‌طور چشمگیری بهبود می‌بخشد.",
  "Qwen2-7B-Instruct.description": "Qwen2 جدیدترین مدل از سری Qwen است که از بهترین مدل‌های متن‌باز هم‌رده و حتی مدل‌های بزرگ‌تر پیشی می‌گیرد. Qwen2 7B در آزمون‌های مختلف، به‌ویژه در زمینه کدنویسی و درک زبان چینی، برتری قابل‌توجهی نشان می‌دهد.",
  "Qwen2-VL-72B.description": "Qwen2-VL-72B یک مدل قدرتمند بینایی-زبان است که از پردازش چندوجهی تصویر-متن پشتیبانی می‌کند و می‌تواند محتوای تصویر را با دقت تشخیص داده و توصیف‌ها یا پاسخ‌های مرتبط تولید کند.",
  "Qwen2.5-14B-Instruct.description": "Qwen2.5-14B-Instruct یک مدل زبانی با ۱۴ میلیارد پارامتر است که عملکرد بالایی دارد و برای سناریوهای چینی و چندزبانه بهینه‌سازی شده است. این مدل از پرسش‌وپاسخ هوشمند و تولید محتوا پشتیبانی می‌کند.",
  "Qwen2.5-32B-Instruct.description": "Qwen2.5-32B-Instruct یک مدل زبانی با ۳۲ میلیارد پارامتر است که عملکردی متعادل دارد و برای سناریوهای چینی و چندزبانه بهینه‌سازی شده است. این مدل از پرسش‌وپاسخ هوشمند و تولید محتوا پشتیبانی می‌کند.",
  "Qwen2.5-72B-Instruct.description": "مدل زبانی برای زبان‌های چینی و انگلیسی، تنظیم‌شده برای زبان، کدنویسی، ریاضیات و استدلال.",
  "Qwen2.5-7B-Instruct.description": "Qwen2.5-7B-Instruct یک مدل زبانی با ۷ میلیارد پارامتر است که از فراخوانی توابع و یکپارچه‌سازی با سیستم‌های خارجی پشتیبانی می‌کند و انعطاف‌پذیری و قابلیت گسترش را به‌طور چشمگیری افزایش می‌دهد. این مدل برای سناریوهای چینی و چندزبانه بهینه‌سازی شده و از پرسش‌وپاسخ هوشمند و تولید محتوا پشتیبانی می‌کند.",
  "Qwen2.5-Coder-14B-Instruct.description": "Qwen2.5-Coder-14B-Instruct یک مدل بزرگ آموزش‌دیده برای دستورالعمل‌های کدنویسی است که در درک و تولید کد عملکرد بالایی دارد. این مدل به‌طور مؤثر طیف گسترده‌ای از وظایف برنامه‌نویسی را انجام می‌دهد و برای کدنویسی هوشمند، تولید خودکار اسکریپت و پرسش‌وپاسخ برنامه‌نویسی ایده‌آل است.",
  "Qwen2.5-Coder-32B-Instruct.description": "مدل پیشرفته زبانی برای تولید کد، استدلال و رفع اشکال در زبان‌های برنامه‌نویسی اصلی.",
  "Qwen3-235B-A22B-Instruct-2507-FP8.description": "Qwen3 235B A22B Instruct 2507 برای استدلال پیشرفته و پیروی از دستورالعمل‌ها بهینه‌سازی شده است و با استفاده از معماری MoE، استدلال را در مقیاس بالا به‌صورت کارآمد انجام می‌دهد.",
  "Qwen3-235B.description": "Qwen3-235B-A22B یک مدل MoE است که حالت استدلال ترکیبی را معرفی می‌کند و به کاربران اجازه می‌دهد به‌صورت یکپارچه بین حالت‌های تفکر و غیرتفکر جابجا شوند. این مدل از درک و استدلال در ۱۱۹ زبان و گویش پشتیبانی می‌کند و توانایی بالایی در فراخوانی ابزارها دارد. در آزمون‌های توانایی عمومی، کدنویسی و ریاضی، قابلیت چندزبانه و استدلال دانشی با مدل‌های پیشرو مانند DeepSeek R1، OpenAI o1، o3-mini، Grok 3 و Google Gemini 2.5 Pro رقابت می‌کند.",
  "Qwen3-32B.description": "Qwen3-32B یک مدل متراکم است که حالت استدلال ترکیبی را معرفی می‌کند و به کاربران اجازه می‌دهد بین تفکر و غیرتفکر جابجا شوند. با بهبود معماری، داده‌های بیشتر و آموزش بهتر، عملکردی هم‌سطح با Qwen2.5-72B دارد.",
  "SenseChat-128K.description": "نسخه پایه V4 با پنجره متنی ۱۲۸ هزار توکن، قوی در درک و تولید متون بلند.",
  "SenseChat-32K.description": "نسخه پایه V4 با پنجره متنی ۳۲ هزار توکن، انعطاف‌پذیر برای سناریوهای مختلف.",
  "SenseChat-5-1202.description": "جدیدترین نسخه مبتنی بر V5.5 با پیشرفت‌های چشمگیر در مبانی چینی/انگلیسی، گفت‌وگو، دانش علوم پایه، علوم انسانی، نگارش، ریاضی/منطق و کنترل طول متن.",
  "SenseChat-5-Cantonese.description": "طراحی‌شده بر اساس عادات گفتاری، اصطلاحات عامیانه و دانش محلی هنگ‌کنگ؛ در درک زبان کانتونی از GPT-4 پیشی می‌گیرد و در دانش، استدلال، ریاضی و کدنویسی با GPT-4 Turbo رقابت می‌کند.",
  "SenseChat-5-beta.description": "در برخی عملکردها از SenseChat-5-1202 پیشی می‌گیرد.",
  "SenseChat-5.description": "نسخه V5.5 با پنجره متنی ۱۲۸ هزار توکن؛ پیشرفت‌های عمده در استدلال ریاضی، گفت‌وگوی انگلیسی، پیروی از دستورالعمل‌ها و درک متون بلند، قابل مقایسه با GPT-4o.",
  "SenseChat-Character-Pro.description": "مدل پیشرفته گفت‌وگوی شخصیتی با پنجره متنی ۳۲ هزار توکن، قابلیت‌های بهبود یافته و پشتیبانی از زبان‌های چینی و انگلیسی.",
  "SenseChat-Character.description": "مدل استاندارد گفت‌وگوی شخصیتی با پنجره متنی ۸ هزار توکن و سرعت پاسخ‌دهی بالا.",
  "SenseChat-Turbo-1202.description": "جدیدترین مدل سبک‌وزن که با هزینه استنتاج بسیار کمتر، به بیش از ۹۰٪ از توانایی مدل کامل دست می‌یابد.",
  "SenseChat-Turbo.description": "مناسب برای سناریوهای پرسش‌وپاسخ سریع و تنظیم دقیق مدل.",
  "SenseChat-Vision.description": "نسخه V5.5 با ورودی چندتصویری و بهبودهای گسترده در تشخیص ویژگی‌ها، روابط فضایی، شناسایی رویداد/عمل، درک صحنه، تشخیص احساسات، استدلال عقل سلیم و درک/تولید متن.",
  "SenseChat.description": "نسخه پایه V4 با پنجره متنی ۴ هزار توکن و توانایی عمومی قوی.",
  "SenseNova-V6-5-Pro.description": "با به‌روزرسانی‌های جامع در داده‌های چندوجهی، زبانی و استدلالی و بهینه‌سازی استراتژی آموزش، این مدل به‌طور چشمگیری استدلال چندوجهی و پیروی از دستورالعمل‌های عمومی را بهبود می‌بخشد، از پنجره متنی تا ۱۲۸ هزار توکن پشتیبانی می‌کند و در وظایف OCR و شناسایی IP گردشگری فرهنگی عملکرد برجسته‌ای دارد.",
  "SenseNova-V6-5-Turbo.description": "با به‌روزرسانی‌های جامع در داده‌های چندوجهی، زبانی و استدلالی و بهینه‌سازی استراتژی آموزش، این مدل به‌طور چشمگیری استدلال چندوجهی و پیروی از دستورالعمل‌های عمومی را بهبود می‌بخشد، از پنجره متنی تا ۱۲۸ هزار توکن پشتیبانی می‌کند و در وظایف OCR و شناسایی IP گردشگری فرهنگی عملکرد برجسته‌ای دارد.",
  "SenseNova-V6-Pro.description": "به‌صورت بومی تصویر، متن و ویدیو را یکپارچه می‌کند و مرزهای سنتی چندوجهی را می‌شکند؛ در OpenCompass و SuperCLUE رتبه‌های برتر را کسب کرده است.",
  "SenseNova-V6-Reasoner.description": "ترکیبی از استدلال عمیق بینایی و زبان، پشتیبانی از تفکر آهسته و زنجیره کامل تفکر.",
  "SenseNova-V6-Turbo.description": "به‌صورت بومی تصویر، متن و ویدیو را یکپارچه می‌کند و مرزهای سنتی چندوجهی را می‌شکند. در قابلیت‌های اصلی چندوجهی و زبانی پیشتاز است و در ارزیابی‌های متعدد در رده برتر قرار دارد.",
  "Skylark2-lite-8k.description": "مدل نسل دوم Skylark. نسخه Skylark2-lite پاسخ‌های سریعی برای سناریوهای بلادرنگ و حساس به هزینه با نیازهای دقت پایین‌تر ارائه می‌دهد و از پنجره متنی ۸ هزار توکن پشتیبانی می‌کند.",
  "Skylark2-pro-32k.description": "مدل نسل دوم Skylark. نسخه Skylark2-pro دقت بالاتری برای تولید متون پیچیده مانند نگارش حرفه‌ای، رمان‌نویسی و ترجمه با کیفیت بالا ارائه می‌دهد و از پنجره متنی ۳۲ هزار توکن پشتیبانی می‌کند.",
  "Skylark2-pro-4k.description": "مدل نسل دوم Skylark. نسخه Skylark2-pro دقت بالاتری برای تولید متون پیچیده مانند نگارش حرفه‌ای، رمان‌نویسی و ترجمه با کیفیت بالا ارائه می‌دهد و از پنجره متنی ۴ هزار توکن پشتیبانی می‌کند.",
  "Skylark2-pro-character-4k.description": "مدل نسل دوم Skylark. نسخه Skylark2-pro-character در ایفای نقش و گفت‌وگو عملکرد برجسته‌ای دارد و سبک‌های شخصیتی متمایز و گفت‌وگوی طبیعی را برای چت‌بات‌ها، دستیارهای مجازی و خدمات مشتری ارائه می‌دهد، با پاسخ‌دهی سریع.",
  "Skylark2-pro-turbo-8k.description": "مدل نسل دوم Skylark. نسخه Skylark2-pro-turbo-8k استنتاج سریع‌تری با هزینه کمتر ارائه می‌دهد و از پنجره متنی ۸ هزار توکن پشتیبانی می‌کند.",
  "THUDM/GLM-4-32B-0414.description": "GLM-4-32B-0414 یک مدل نسل جدید GLM با ۳۲ میلیارد پارامتر است که از نظر عملکرد با مدل‌های OpenAI GPT و سری DeepSeek V3/R1 قابل مقایسه است.",
  "THUDM/GLM-4-9B-0414.description": "GLM-4-9B-0414 یک مدل ۹ میلیاردی GLM است که تکنیک‌های GLM-4-32B را به ارث برده و در عین حال استقرار سبک‌تری را ارائه می‌دهد. این مدل در تولید کد، طراحی وب، تولید SVG و نگارش مبتنی بر جستجو عملکرد خوبی دارد.",
  "THUDM/GLM-4.1V-9B-Thinking.description": "GLM-4.1V-9B-Thinking یک مدل VLM متن‌باز از Zhipu AI و آزمایشگاه KEG دانشگاه Tsinghua است که برای درک پیچیده چندرسانه‌ای طراحی شده است. این مدل بر پایه GLM-4-9B-0414 ساخته شده و با افزودن زنجیره تفکر و یادگیری تقویتی، توانایی استدلال میان‌وجهی و پایداری را به‌طور قابل توجهی بهبود می‌بخشد.",
  "THUDM/GLM-Z1-32B-0414.description": "GLM-Z1-32B-0414 یک مدل استدلال عمیق است که بر پایه GLM-4-32B-0414 با داده‌های شروع سرد و یادگیری تقویتی گسترده ساخته شده و آموزش بیشتری در زمینه ریاضی، کدنویسی و منطق دیده است. این مدل توانایی حل مسائل پیچیده و ریاضی را نسبت به مدل پایه به‌طور چشمگیری افزایش می‌دهد.",
  "THUDM/GLM-Z1-9B-0414.description": "GLM-Z1-9B-0414 یک مدل GLM کوچک با ۹ میلیارد پارامتر است که در عین حفظ مزایای متن‌باز، عملکرد چشمگیری ارائه می‌دهد. این مدل در استدلال ریاضی و وظایف عمومی بسیار قوی عمل کرده و در میان مدل‌های هم‌رده خود پیشتاز است.",
  "THUDM/GLM-Z1-Rumination-32B-0414.description": "GLM-Z1-Rumination-32B-0414 یک مدل استدلال عمیق با قابلیت تفکر تأملی است (با مدل‌های تحقیق عمیق OpenAI مقایسه شده است). برخلاف مدل‌های معمول تفکر عمیق، این مدل زمان بیشتری را صرف تأمل می‌کند تا مسائل باز و پیچیده‌تری را حل کند.",
  "THUDM/glm-4-9b-chat.description": "GLM-4-9B-Chat مدل متن‌باز GLM-4 از Zhipu AI است. این مدل در زمینه‌های معناشناسی، ریاضی، استدلال، کدنویسی و دانش عملکرد قوی دارد. علاوه بر گفت‌وگوی چندمرحله‌ای، از مرور وب، اجرای کد، فراخوانی ابزارهای سفارشی و استدلال متون بلند پشتیبانی می‌کند. این مدل از ۲۶ زبان (از جمله چینی، انگلیسی، ژاپنی، کره‌ای و آلمانی) پشتیبانی می‌کند و در آزمون‌هایی مانند AlignBench-v2، MT-Bench، MMLU و C-Eval عملکرد خوبی دارد. همچنین تا ۱۲۸ هزار توکن زمینه را برای کاربردهای علمی و تجاری پشتیبانی می‌کند.",
  "Tongyi-Zhiwen/QwenLong-L1-32B.description": "QwenLong-L1-32B نخستین مدل استدلال با زمینه بلند (LRM) است که با یادگیری تقویتی آموزش دیده و برای استدلال متون بلند بهینه‌سازی شده است. یادگیری تقویتی با گسترش تدریجی زمینه، انتقال پایدار از زمینه‌های کوتاه به بلند را ممکن می‌سازد. این مدل در هفت معیار پرسش‌وپاسخ اسناد بلند از مدل‌هایی مانند OpenAI-o3-mini و Qwen3-235B-A22B پیشی گرفته و با Claude-3.7-Sonnet-Thinking رقابت می‌کند. در زمینه ریاضی، منطق و استدلال چندمرحله‌ای بسیار قوی عمل می‌کند.",
  "Yi-34B-Chat.description": "Yi-1.5-34B ضمن حفظ توانایی‌های زبانی قوی سری Yi، با آموزش افزایشی بر روی ۵۰۰ میلیارد توکن با کیفیت، توانایی‌های منطق ریاضی و کدنویسی را به‌طور قابل توجهی بهبود داده است.",
  "abab5.5-chat.description": "برای سناریوهای بهره‌وری طراحی شده است و توانایی انجام وظایف پیچیده و تولید متن کارآمد برای استفاده حرفه‌ای را دارد.",
  "abab5.5s-chat.description": "برای گفت‌وگوی شخصیت‌محور به زبان چینی طراحی شده و گفت‌وگوی با کیفیت بالا به زبان چینی را در کاربردهای مختلف ارائه می‌دهد.",
  "abab6.5g-chat.description": "برای گفت‌وگوی شخصیت‌محور چندزبانه طراحی شده و تولید گفت‌وگوی با کیفیت به زبان انگلیسی و سایر زبان‌ها را پشتیبانی می‌کند.",
  "abab6.5s-chat.description": "برای طیف گسترده‌ای از وظایف پردازش زبان طبیعی مناسب است، از جمله تولید متن و سیستم‌های گفت‌وگو.",
  "abab6.5t-chat.description": "برای گفت‌وگوی شخصیت‌محور به زبان چینی بهینه‌سازی شده و گفت‌وگویی روان و منطبق با عادات بیانی زبان چینی ارائه می‌دهد.",
  "accounts/fireworks/models/deepseek-r1.description": "DeepSeek-R1 یک مدل زبان بزرگ پیشرفته است که با یادگیری تقویتی و داده‌های شروع سرد بهینه‌سازی شده و عملکرد عالی در استدلال، ریاضی و کدنویسی دارد.",
  "accounts/fireworks/models/deepseek-v3.description": "مدلی قدرتمند از نوع Mixture-of-Experts (MoE) از DeepSeek با ۶۷۱ میلیارد پارامتر کل و ۳۷ میلیارد پارامتر فعال در هر توکن.",
  "accounts/fireworks/models/llama-v3-70b-instruct.description": "Meta سری مدل‌های Meta Llama 3 را توسعه داده و منتشر کرده است که شامل مدل‌های تولید متن پیش‌آموزش‌دیده و تنظیم‌شده برای دستورالعمل در اندازه‌های ۸B و ۷۰B می‌باشد. مدل‌های تنظیم‌شده برای دستورالعمل Llama 3 برای استفاده در گفت‌وگو بهینه‌سازی شده‌اند و در بسیاری از معیارهای صنعتی از مدل‌های متن‌باز موجود پیشی می‌گیرند.",
  "accounts/fireworks/models/llama-v3-8b-instruct-hf.description": "مدل‌های تنظیم‌شده برای دستورالعمل Meta Llama 3 برای استفاده در گفت‌وگو بهینه‌سازی شده‌اند و در بسیاری از معیارهای صنعتی از مدل‌های متن‌باز موجود پیشی می‌گیرند. Llama 3 8B Instruct (نسخه HF) نسخه اصلی FP16 از Llama 3 8B Instruct است و نتایج آن با پیاده‌سازی رسمی Hugging Face مطابقت دارد.",
  "accounts/fireworks/models/llama-v3-8b-instruct.description": "Meta سری مدل‌های Meta Llama 3 را توسعه داده و منتشر کرده است که شامل مدل‌های تولید متن پیش‌آموزش‌دیده و تنظیم‌شده برای دستورالعمل در اندازه‌های ۸B و ۷۰B می‌باشد. مدل‌های تنظیم‌شده برای دستورالعمل Llama 3 برای استفاده در گفت‌وگو بهینه‌سازی شده‌اند و در بسیاری از معیارهای صنعتی از مدل‌های متن‌باز موجود پیشی می‌گیرند.",
  "accounts/fireworks/models/llama-v3p1-405b-instruct.description": "Meta Llama 3.1 یک خانواده چندزبانه از مدل‌های زبان بزرگ است که شامل مدل‌های تولید متن پیش‌آموزش‌دیده و تنظیم‌شده برای دستورالعمل در اندازه‌های ۸B، ۷۰B و ۴۰۵B می‌باشد. مدل‌های تنظیم‌شده برای دستورالعمل برای گفت‌وگوی چندزبانه بهینه‌سازی شده‌اند و در بسیاری از معیارهای صنعتی از مدل‌های متن‌باز و بسته پیشی می‌گیرند. مدل ۴۰۵B قدرتمندترین مدل در خانواده Llama 3.1 است و از استنتاج FP8 استفاده می‌کند که با پیاده‌سازی مرجع مطابقت دارد.",
  "accounts/fireworks/models/llama-v3p1-70b-instruct.description": "Meta Llama 3.1 یک خانواده چندزبانه از مدل‌های زبان بزرگ است که شامل مدل‌های تولید متن پیش‌آموزش‌دیده و تنظیم‌شده برای دستورالعمل در اندازه‌های ۸B، ۷۰B و ۴۰۵B می‌باشد. مدل‌های تنظیم‌شده برای دستورالعمل برای گفت‌وگوی چندزبانه بهینه‌سازی شده‌اند و در بسیاری از معیارهای صنعتی از مدل‌های متن‌باز و بسته پیشی می‌گیرند.",
  "accounts/fireworks/models/llama-v3p1-8b-instruct.description": "Meta Llama 3.1 یک خانواده چندزبانه از مدل‌های زبان بزرگ است که شامل مدل‌های تولید متن پیش‌آموزش‌دیده و تنظیم‌شده برای دستورالعمل در اندازه‌های ۸B، ۷۰B و ۴۰۵B می‌باشد. مدل‌های تنظیم‌شده برای دستورالعمل برای گفت‌وگوی چندزبانه بهینه‌سازی شده‌اند و در بسیاری از معیارهای صنعتی از مدل‌های متن‌باز و بسته پیشی می‌گیرند.",
  "accounts/fireworks/models/llama-v3p2-11b-vision-instruct.description": "مدل استدلال تصویری تنظیم‌شده برای دستورالعمل از Meta با ۱۱ میلیارد پارامتر، بهینه‌سازی‌شده برای شناسایی بصری، استدلال تصویری، تولید کپشن و پرسش‌وپاسخ مرتبط با تصویر. این مدل داده‌های بصری مانند نمودارها و گراف‌ها را درک می‌کند و با تولید توصیف‌های متنی از جزئیات تصویر، بینایی و زبان را به هم پیوند می‌دهد.",
  "accounts/fireworks/models/llama-v3p2-3b-instruct.description": "Llama 3.2 3B Instruct یک مدل چندزبانه سبک از Meta است که برای زمان اجرای کارآمد طراحی شده و نسبت به مدل‌های بزرگ‌تر تأخیر و هزینه کمتری دارد. موارد استفاده معمول شامل بازنویسی پرس‌وجو/پرامپت و کمک به نگارش است.",
  "accounts/fireworks/models/llama-v3p2-90b-vision-instruct.description": "مدل استدلال تصویری تنظیم‌شده برای دستورالعمل از Meta با ۹۰ میلیارد پارامتر، بهینه‌سازی‌شده برای شناسایی بصری، استدلال تصویری، تولید کپشن و پرسش‌وپاسخ مرتبط با تصویر. این مدل داده‌های بصری مانند نمودارها و گراف‌ها را درک می‌کند و با تولید توصیف‌های متنی از جزئیات تصویر، بینایی و زبان را به هم پیوند می‌دهد. توجه: این مدل در حال حاضر به‌صورت آزمایشی به‌عنوان مدل بدون سرور ارائه می‌شود. برای استفاده در تولید، توجه داشته باشید که Fireworks ممکن است استقرار آن را به‌زودی متوقف کند.",
  "accounts/fireworks/models/llama-v3p3-70b-instruct.description": "Llama 3.3 70B Instruct به‌روزرسانی دسامبر برای Llama 3.1 70B است. این مدل استفاده از ابزار، پشتیبانی از متن چندزبانه، ریاضی و کدنویسی را نسبت به نسخه جولای ۲۰۲۴ بهبود می‌بخشد. عملکردی در سطح پیشرو در صنعت در استدلال، ریاضی و پیروی از دستورالعمل ارائه می‌دهد و عملکردی قابل مقایسه با 3.1 405B با مزایای قابل توجه در سرعت و هزینه دارد.",
  "accounts/fireworks/models/mistral-small-24b-instruct-2501.description": "مدلی با ۲۴ میلیارد پارامتر و توانایی پیشرفته که با مدل‌های بزرگ‌تر قابل مقایسه است.",
  "accounts/fireworks/models/mixtral-8x22b-instruct.description": "Mixtral MoE 8x22B Instruct v0.1 نسخه تنظیم‌شده برای دستورالعمل از Mixtral MoE 8x22B v0.1 است که API تکمیل گفت‌وگو در آن فعال شده است.",
  "accounts/fireworks/models/mixtral-8x7b-instruct.description": "Mixtral MoE 8x7B Instruct نسخه تنظیم‌شده برای دستورالعمل از Mixtral MoE 8x7B است که API تکمیل گفت‌وگو در آن فعال شده است.",
  "accounts/fireworks/models/mythomax-l2-13b.description": "نسخه بهبودیافته‌ای از MythoMix که احتمالاً شکل پالایش‌شده‌تری از آن است و با ترکیب MythoLogic-L2 و Huginn با تکنیک ادغام تنسور بسیار تجربی ساخته شده است. ماهیت منحصربه‌فرد آن را برای داستان‌سرایی و ایفای نقش عالی می‌سازد.",
  "accounts/fireworks/models/phi-3-vision-128k-instruct.description": "Phi-3-Vision-128K-Instruct یک مدل چندرسانه‌ای سبک و پیشرفته است که از داده‌های مصنوعی و مجموعه داده‌های عمومی وب انتخاب‌شده ساخته شده و بر داده‌های متنی و تصویری با کیفیت بالا و نیازمند استدلال تمرکز دارد. این مدل متعلق به خانواده Phi-3 است و نسخه چندرسانه‌ای آن از طول زمینه ۱۲۸ هزار توکن پشتیبانی می‌کند. این مدل تحت بهبودهای دقیق از جمله تنظیم نظارت‌شده و بهینه‌سازی مستقیم ترجیح قرار گرفته تا پیروی دقیق از دستورالعمل و اقدامات ایمنی قوی را تضمین کند.",
  "accounts/fireworks/models/qwen-qwq-32b-preview.description": "مدل Qwen QwQ بر پیشرفت در استدلال هوش مصنوعی تمرکز دارد و نشان می‌دهد که مدل‌های باز می‌توانند در استدلال با مدل‌های پیشرفته بسته رقابت کنند. QwQ-32B-Preview یک نسخه آزمایشی است که با o1 برابری می‌کند و در استدلال و تحلیل در آزمون‌های GPQA، AIME، MATH-500 و LiveCodeBench از GPT-4o و Claude 3.5 Sonnet پیشی می‌گیرد. توجه: این مدل در حال حاضر به‌صورت آزمایشی و بدون سرور ارائه می‌شود. برای استفاده در محیط تولید، توجه داشته باشید که Fireworks ممکن است این استقرار را بدون اطلاع قبلی متوقف کند.",
  "accounts/fireworks/models/qwen2-vl-72b-instruct.description": "مدل ۷۲B Qwen-VL جدیدترین نسخه از سوی علی‌بابا است که حاصل نزدیک به یک سال نوآوری می‌باشد.",
  "accounts/fireworks/models/qwen2p5-72b-instruct.description": "Qwen2.5 یک سری مدل زبانی بزرگ فقط رمزگشا است که توسط تیم Qwen و علی‌بابا کلاد توسعه یافته و در اندازه‌های 0.5B، 1.5B، 3B، 7B، 14B، 32B و 72B با نسخه‌های پایه و تنظیم‌شده برای دستورالعمل‌ها ارائه می‌شود.",
  "accounts/fireworks/models/qwen2p5-coder-32b-instruct.description": "Qwen2.5-Coder جدیدترین مدل زبانی بزرگ Qwen برای برنامه‌نویسی است (قبلاً با نام CodeQwen شناخته می‌شد). توجه: این مدل در حال حاضر به‌صورت آزمایشی و بدون سرور ارائه می‌شود. برای استفاده در محیط تولید، توجه داشته باشید که Fireworks ممکن است این استقرار را بدون اطلاع قبلی متوقف کند.",
  "accounts/yi-01-ai/models/yi-large.description": "Yi-Large یک مدل زبانی سطح بالا است که در رتبه‌بندی LMSYS درست پس از GPT-4، Gemini 1.5 Pro و Claude 3 Opus قرار دارد. این مدل در پشتیبانی از زبان‌های چندگانه، به‌ویژه اسپانیایی، چینی، ژاپنی، آلمانی و فرانسوی، عملکرد برجسته‌ای دارد. Yi-Large همچنین برای توسعه‌دهندگان مناسب است و از همان ساختار API مشابه OpenAI برای یکپارچه‌سازی آسان استفاده می‌کند.",
  "ai21-jamba-1.5-large.description": "مدلی چندزبانه با ۳۹۸ میلیارد پارامتر (۹۴ میلیارد فعال) با پنجره متنی ۲۵۶ هزار توکن، قابلیت فراخوانی توابع، خروجی ساختاریافته و تولید مبتنی بر داده‌های واقعی.",
  "ai21-jamba-1.5-mini.description": "مدلی چندزبانه با ۵۲ میلیارد پارامتر (۱۲ میلیارد فعال) با پنجره متنی ۲۵۶ هزار توکن، قابلیت فراخوانی توابع، خروجی ساختاریافته و تولید مبتنی بر داده‌های واقعی.",
  "ai21-labs/AI21-Jamba-1.5-Large.description": "مدلی چندزبانه با ۳۹۸ میلیارد پارامتر (۹۴ میلیارد فعال) با پنجره متنی ۲۵۶ هزار توکن، قابلیت فراخوانی توابع، خروجی ساختاریافته و تولید مبتنی بر داده‌های واقعی.",
  "ai21-labs/AI21-Jamba-1.5-Mini.description": "مدلی چندزبانه با ۵۲ میلیارد پارامتر (۱۲ میلیارد فعال) با پنجره متنی ۲۵۶ هزار توکن، قابلیت فراخوانی توابع، خروجی ساختاریافته و تولید مبتنی بر داده‌های واقعی.",
  "alibaba/qwen-3-14b.description": "Qwen3 جدیدترین نسل از سری Qwen است که مجموعه‌ای جامع از مدل‌های متراکم و MoE را ارائه می‌دهد. این مدل بر پایه آموزش گسترده ساخته شده و در زمینه‌های استدلال، پیروی از دستورالعمل‌ها، قابلیت‌های عامل‌محور و پشتیبانی چندزبانه پیشرفت‌های چشمگیری دارد.",
  "alibaba/qwen-3-235b.description": "Qwen3 جدیدترین نسل از سری Qwen است که مجموعه‌ای جامع از مدل‌های متراکم و MoE را ارائه می‌دهد. این مدل بر پایه آموزش گسترده ساخته شده و در زمینه‌های استدلال، پیروی از دستورالعمل‌ها، قابلیت‌های عامل‌محور و پشتیبانی چندزبانه پیشرفت‌های چشمگیری دارد.",
  "alibaba/qwen-3-30b.description": "Qwen3 جدیدترین نسل از سری Qwen است که مجموعه‌ای جامع از مدل‌های متراکم و MoE را ارائه می‌دهد. این مدل بر پایه آموزش گسترده ساخته شده و در زمینه‌های استدلال، پیروی از دستورالعمل‌ها، قابلیت‌های عامل‌محور و پشتیبانی چندزبانه پیشرفت‌های چشمگیری دارد.",
  "alibaba/qwen-3-32b.description": "Qwen3 جدیدترین نسل از سری Qwen است که مجموعه‌ای جامع از مدل‌های متراکم و MoE را ارائه می‌دهد. این مدل بر پایه آموزش گسترده ساخته شده و در زمینه‌های استدلال، پیروی از دستورالعمل‌ها، قابلیت‌های عامل‌محور و پشتیبانی چندزبانه پیشرفت‌های چشمگیری دارد.",
  "alibaba/qwen3-coder.description": "Qwen3-Coder-480B-A35B-Instruct پیشرفته‌ترین مدل برنامه‌نویسی Qwen است که در وظایف کدنویسی عامل‌محور، استفاده از مرورگر توسط عامل و سایر وظایف اصلی برنامه‌نویسی عملکردی قوی دارد و نتایجی در سطح Claude Sonnet ارائه می‌دهد.",
  "amazon/nova-lite.description": "مدلی چندوجهی با هزینه بسیار پایین که ورودی‌های تصویر، ویدیو و متن را با سرعت بسیار بالا پردازش می‌کند.",
  "amazon/nova-micro.description": "مدلی فقط متنی با تأخیر بسیار پایین و هزینه بسیار کم.",
  "amazon/nova-pro.description": "مدلی چندوجهی با قابلیت بالا که بهترین تعادل بین دقت، سرعت و هزینه را برای طیف گسترده‌ای از وظایف ارائه می‌دهد.",
  "amazon/titan-embed-text-v2.description": "Amazon Titan Text Embeddings V2 یک مدل جاسازی چندزبانه سبک و کارآمد است که از ابعاد ۱۰۲۴، ۵۱۲ و ۲۵۶ پشتیبانی می‌کند.",
  "anthropic.claude-3-5-sonnet-20240620-v1:0.description": "Claude 3.5 Sonnet استاندارد صنعت را ارتقا داده و در ارزیابی‌های گسترده از رقبا و Claude 3 Opus پیشی می‌گیرد، در حالی که سرعت و هزینه متوسط را حفظ می‌کند.",
  "anthropic.claude-3-5-sonnet-20241022-v2:0.description": "Claude 3.5 Sonnet استاندارد صنعت را ارتقا داده و در ارزیابی‌های گسترده از رقبا و Claude 3 Opus پیشی می‌گیرد، در حالی که سرعت و هزینه متوسط را حفظ می‌کند.",
  "anthropic.claude-3-haiku-20240307-v1:0.description": "Claude 3 Haiku سریع‌ترین و فشرده‌ترین مدل Anthropic است که پاسخ‌های تقریباً فوری برای پرسش‌های ساده ارائه می‌دهد. این مدل تجربه‌ای روان و شبیه انسان را فراهم کرده و از ورودی تصویری با پنجره متنی ۲۰۰ هزار توکن پشتیبانی می‌کند.",
  "anthropic.claude-3-opus-20240229-v1:0.description": "Claude 3 Opus قدرتمندترین مدل هوش مصنوعی Anthropic است که در وظایف بسیار پیچیده عملکردی در سطح پیشرفته دارد. این مدل درخواست‌های باز و سناریوهای جدید را با روانی و درک انسانی استثنایی مدیریت می‌کند و از ورودی تصویری با پنجره متنی ۲۰۰ هزار توکن پشتیبانی می‌کند.",
  "anthropic.claude-3-sonnet-20240229-v1:0.description": "Claude 3 Sonnet تعادلی بین هوش و سرعت برای بارهای کاری سازمانی فراهم می‌کند و ارزش بالایی را با هزینه کمتر ارائه می‌دهد. این مدل برای استقرار گسترده هوش مصنوعی طراحی شده و از ورودی تصویری با پنجره متنی ۲۰۰ هزار توکن پشتیبانی می‌کند.",
  "anthropic.claude-instant-v1.description": "مدلی سریع، اقتصادی و در عین حال توانمند برای چت روزمره، تحلیل متن، خلاصه‌سازی و پرسش و پاسخ اسناد.",
  "anthropic.claude-v2.description": "مدلی بسیار توانمند برای وظایف مختلف از گفت‌وگوی پیچیده و تولید خلاقانه تا پیروی دقیق از دستورالعمل‌ها.",
  "anthropic.claude-v2:1.description": "نسخه به‌روزشده Claude 2 با دو برابر پنجره متنی و بهبود در قابلیت اطمینان، کاهش توهمات و دقت مبتنی بر شواهد برای اسناد طولانی و بازیابی اطلاعات.",
  "anthropic/claude-3-haiku.description": "Claude 3 Haiku سریع‌ترین مدل Anthropic است که برای بارهای کاری سازمانی با درخواست‌های طولانی طراحی شده است. این مدل می‌تواند اسناد بزرگ مانند گزارش‌های فصلی، قراردادها یا پرونده‌های حقوقی را با نیمی از هزینه رقبا تحلیل کند.",
  "anthropic/claude-3-opus.description": "Claude 3 Opus هوشمندترین مدل Anthropic است که در وظایف بسیار پیچیده عملکردی در سطح بازار دارد و درخواست‌های باز و سناریوهای جدید را با روانی و درک انسانی استثنایی مدیریت می‌کند.",
  "anthropic/claude-3.5-haiku.description": "Claude 3.5 Haiku دارای سرعت بیشتر، دقت بالاتر در کدنویسی و استفاده از ابزارها است و برای سناریوهایی با نیازهای بالا به سرعت و تعامل با ابزارها مناسب است.",
  "anthropic/claude-3.5-sonnet.description": "Claude 3.5 Sonnet مدل سریع و کارآمد خانواده Sonnet است که عملکرد بهتری در کدنویسی و استدلال ارائه می‌دهد و برخی نسخه‌های آن به تدریج با Sonnet 3.7 و نسخه‌های بعدی جایگزین می‌شوند.",
  "anthropic/claude-3.7-sonnet.description": "Claude 3.7 Sonnet نسخه ارتقایافته مدل Sonnet با استدلال و کدنویسی قوی‌تر است که برای وظایف پیچیده در سطح سازمانی مناسب می‌باشد.",
  "anthropic/claude-haiku-4.5.description": "Claude Haiku 4.5 مدل سریع با عملکرد بالا از Anthropic است که تأخیر بسیار کم را در کنار دقت بالا ارائه می‌دهد.",
  "anthropic/claude-opus-4.1.description": "Opus 4.1 مدل سطح بالای Anthropic است که برای برنامه‌نویسی، استدلال پیچیده و وظایف طولانی بهینه‌سازی شده است.",
  "anthropic/claude-opus-4.5.description": "Claude Opus 4.5 مدل پرچم‌دار Anthropic است که هوش سطح بالا را با عملکرد مقیاس‌پذیر برای وظایف پیچیده و استدلال با کیفیت بالا ترکیب می‌کند.",
  "anthropic/claude-opus-4.description": "Opus 4 مدل پرچم‌دار Anthropic است که برای وظایف پیچیده و کاربردهای سازمانی طراحی شده است.",
  "anthropic/claude-sonnet-4.5.description": "Claude Sonnet 4.5 جدیدترین مدل استدلال ترکیبی Anthropic است که برای استدلال پیچیده و کدنویسی بهینه‌سازی شده است.",
  "anthropic/claude-sonnet-4.description": "Claude Sonnet 4 مدل استدلال ترکیبی Anthropic است که قابلیت تفکر و عدم تفکر را با هم ترکیب می‌کند.",
  "ascend-tribe/pangu-pro-moe.description": "Pangu-Pro-MoE 72B-A16B یک مدل زبانی پراکنده با ۷۲ میلیارد پارامتر کل و ۱۶ میلیارد پارامتر فعال است که بر پایه معماری MoE گروه‌بندی‌شده (MoGE) ساخته شده است. این مدل با گروه‌بندی متخصصان در زمان انتخاب و محدود کردن فعال‌سازی توکن‌ها به تعداد مساوی متخصص در هر گروه، تعادل بار را حفظ کرده و بهره‌وری استقرار را در پلتفرم Ascend بهبود می‌بخشد.",
  "aya.description": "Aya 23 مدل چندزبانه شرکت Cohere است که از ۲۳ زبان برای کاربردهای متنوع پشتیبانی می‌کند.",
  "aya:35b.description": "Aya 23 مدل چندزبانه شرکت Cohere است که از ۲۳ زبان برای کاربردهای متنوع پشتیبانی می‌کند.",
  "azure-DeepSeek-R1-0528.description": "این مدل توسط مایکروسافت استقرار یافته است؛ DeepSeek R1 به نسخه DeepSeek-R1-0528 ارتقا یافته است. این به‌روزرسانی با افزایش توان محاسباتی و بهینه‌سازی الگوریتم‌های پس‌آموزش، عمق استدلال و استنتاج را به‌طور چشمگیری بهبود می‌بخشد. عملکرد آن در آزمون‌های ریاضی، برنامه‌نویسی و منطق عمومی بسیار قوی است و به مدل‌های پیشرو مانند O3 و Gemini 2.5 Pro نزدیک می‌شود.",
  "baichuan-m2-32b.description": "Baichuan M2 32B یک مدل MoE از شرکت Baichuan Intelligence است که در استدلال عملکرد قدرتمندی دارد.",
  "baichuan/baichuan2-13b-chat.description": "Baichuan-13B یک مدل زبانی منبع‌باز با ۱۳ میلیارد پارامتر است که برای استفاده تجاری نیز مجاز است. این مدل در آزمون‌های معتبر چینی و انگلیسی، بهترین نتایج را در میان مدل‌های هم‌رده خود کسب کرده است.",
  "baidu/ERNIE-4.5-300B-A47B.description": "ERNIE-4.5-300B-A47B یک مدل MoE از شرکت Baidu با ۳۰۰ میلیارد پارامتر کل و ۴۷ میلیارد پارامتر فعال به ازای هر توکن است که تعادل بین عملکرد قوی و بهره‌وری محاسباتی را برقرار می‌کند. این مدل به‌عنوان هسته اصلی ERNIE 4.5 در درک، تولید، استدلال و برنامه‌نویسی بسیار توانمند است. با استفاده از روش پیش‌آموزش چندوجهی ناهمگن MoE و آموزش مشترک متن-تصویر، توانایی کلی خود را به‌ویژه در پیروی از دستورالعمل‌ها و دانش عمومی افزایش داده است.",
  "baidu/ernie-5.0-thinking-preview.description": "پیش‌نمایش مدل ERNIE 5.0 Thinking نسل بعدی مدل چندوجهی بومی شرکت Baidu است که در درک چندوجهی، پیروی از دستورالعمل‌ها، تولید محتوا، پرسش و پاسخ واقعی و استفاده از ابزارها عملکرد بسیار خوبی دارد.",
  "black-forest-labs/flux-1.1-pro.description": "FLUX 1.1 Pro نسخه سریع‌تر و بهبودیافته FLUX Pro است که کیفیت تصویر عالی و تبعیت دقیق از دستورات را ارائه می‌دهد.",
  "black-forest-labs/flux-dev.description": "FLUX Dev نسخه توسعه‌ای مدل FLUX برای استفاده غیرتجاری است.",
  "black-forest-labs/flux-pro.description": "FLUX Pro مدل حرفه‌ای FLUX برای تولید تصاویر با کیفیت بالا است.",
  "black-forest-labs/flux-schnell.description": "FLUX Schnell یک مدل تولید تصویر سریع است که برای سرعت بهینه‌سازی شده است.",
  "c4ai-aya-expanse-32b.description": "Aya Expanse یک مدل چندزبانه قدرتمند با ۳۲ میلیارد پارامتر است که با استفاده از تنظیمات دستوری، انتخاب داده، آموزش ترجیحی و ادغام مدل‌ها، عملکردی در حد مدل‌های تک‌زبانه ارائه می‌دهد. این مدل از ۲۳ زبان پشتیبانی می‌کند.",
  "c4ai-aya-expanse-8b.description": "Aya Expanse یک مدل چندزبانه قدرتمند با ۸ میلیارد پارامتر است که با استفاده از تنظیمات دستوری، انتخاب داده، آموزش ترجیحی و ادغام مدل‌ها، عملکردی در حد مدل‌های تک‌زبانه ارائه می‌دهد. این مدل از ۲۳ زبان پشتیبانی می‌کند.",
  "c4ai-aya-vision-32b.description": "Aya Vision یک مدل چندوجهی پیشرفته است که در آزمون‌های کلیدی زبان، متن و تصویر عملکرد بسیار خوبی دارد. این نسخه ۳۲ میلیاردی بر عملکرد چندزبانه سطح بالا تمرکز دارد و از ۲۳ زبان پشتیبانی می‌کند.",
  "c4ai-aya-vision-8b.description": "Aya Vision یک مدل چندوجهی پیشرفته است که در آزمون‌های کلیدی زبان، متن و تصویر عملکرد بسیار خوبی دارد. این نسخه ۸ میلیاردی بر تأخیر کم و عملکرد قوی تمرکز دارد.",
  "charglm-3.description": "CharGLM-3 برای نقش‌آفرینی و همراهی احساسی طراحی شده است و از حافظه چندنوبتی بسیار طولانی و گفت‌وگوی شخصی‌سازی‌شده پشتیبانی می‌کند.",
  "charglm-4.description": "CharGLM-4 برای نقش‌آفرینی و همراهی احساسی طراحی شده است و از حافظه چندنوبتی بسیار طولانی و گفت‌وگوی شخصی‌سازی‌شده پشتیبانی می‌کند.",
  "chatgpt-4o-latest.description": "ChatGPT-4o یک مدل پویا است که به‌صورت بلادرنگ به‌روزرسانی می‌شود و درک و تولید قوی را برای کاربردهای وسیع مانند پشتیبانی مشتری، آموزش و پشتیبانی فنی ترکیب می‌کند.",
  "claude-2.0.description": "Claude 2 بهبودهای کلیدی برای سازمان‌ها ارائه می‌دهد، از جمله زمینه ۲۰۰ هزار توکنی پیشرو، کاهش توهمات، دستورات سیستمی و ویژگی آزمایشی جدید: فراخوانی ابزار.",
  "claude-2.1.description": "Claude 2 بهبودهای کلیدی برای سازمان‌ها ارائه می‌دهد، از جمله زمینه ۲۰۰ هزار توکنی پیشرو، کاهش توهمات، دستورات سیستمی و ویژگی آزمایشی جدید: فراخوانی ابزار.",
  "claude-3-5-haiku-20241022.description": "Claude 3.5 Haiku سریع‌ترین مدل نسل جدید Anthropic است که در مهارت‌های مختلف بهبود یافته و در بسیاری از معیارها از مدل پرچم‌دار قبلی Claude 3 Opus پیشی گرفته است.",
  "claude-3-5-haiku-latest.description": "Claude 3.5 Haiku پاسخ‌های سریع برای وظایف سبک ارائه می‌دهد.",
  "claude-3-7-sonnet-20250219.description": "Claude Sonnet 3.7 هوشمندترین مدل Anthropic و نخستین مدل استدلال ترکیبی در بازار است که پاسخ‌های تقریباً فوری یا تفکر گام‌به‌گام با کنترل دقیق را ارائه می‌دهد.",
  "claude-3-7-sonnet-latest.description": "Claude 3.7 Sonnet جدیدترین و توانمندترین مدل Anthropic برای وظایف بسیار پیچیده است که در عملکرد، هوش، روانی و درک زبان برتری دارد.",
  "claude-3-haiku-20240307.description": "Claude 3 Haiku سریع‌ترین و فشرده‌ترین مدل Anthropic است که برای پاسخ‌های تقریباً فوری با عملکرد سریع و دقیق طراحی شده است.",
  "claude-3-opus-20240229.description": "Claude 3 Opus قدرتمندترین مدل Anthropic برای وظایف بسیار پیچیده است که در عملکرد، هوش، روانی و درک زبان برتری دارد.",
  "claude-3-sonnet-20240229.description": "Claude 3 Sonnet تعادل بین هوش و سرعت را برای بارهای کاری سازمانی برقرار می‌کند و با هزینه کمتر، بهره‌وری بالا و استقرار قابل اعتماد در مقیاس وسیع را ارائه می‌دهد.",
  "claude-haiku-4-5-20251001.description": "Claude Haiku 4.5 سریع‌ترین و هوشمندترین مدل Haiku از Anthropic است که با سرعتی برق‌آسا و توانایی تفکر گسترده ارائه می‌شود.",
  "claude-opus-4-1-20250805-thinking.description": "Claude Opus 4.1 Thinking یک نسخه پیشرفته است که می‌تواند فرآیند استدلال خود را آشکار کند.",
  "claude-opus-4-1-20250805.description": "Claude Opus 4.1 جدیدترین و توانمندترین مدل Anthropic برای وظایف بسیار پیچیده است که در عملکرد، هوش، روانی و درک زبان برتری دارد.",
  "claude-opus-4-20250514.description": "Claude Opus 4 قدرتمندترین مدل Anthropic برای وظایف بسیار پیچیده است که در عملکرد، هوش، روانی و درک زبان برتری دارد.",
  "claude-opus-4-5-20251101.description": "Claude Opus 4.5 مدل پرچم‌دار Anthropic است که هوش برجسته را با عملکرد مقیاس‌پذیر ترکیب می‌کند و برای وظایف پیچیده‌ای که نیاز به پاسخ‌های باکیفیت و استدلال دارند، ایده‌آل است.",
  "claude-opus-4-6.description": "Claude Opus 4.6 هوشمندترین مدل Anthropic برای ساخت عامل‌ها و برنامه‌نویسی است.",
  "claude-sonnet-4-20250514-thinking.description": "Claude Sonnet 4 Thinking می‌تواند پاسخ‌های تقریباً فوری یا تفکر گام‌به‌گام طولانی با فرآیند قابل مشاهده تولید کند.",
  "claude-sonnet-4-20250514.description": "Claude Sonnet 4 هوشمندترین مدل Anthropic تا به امروز است که پاسخ‌های تقریباً فوری یا تفکر گام‌به‌گام با کنترل دقیق برای کاربران API ارائه می‌دهد.",
  "claude-sonnet-4-5-20250929.description": "Claude Sonnet 4.5 هوشمندترین مدل Anthropic تا به امروز است.",
  "codegeex-4.description": "CodeGeeX-4 یک دستیار هوش مصنوعی قدرتمند برای برنامه‌نویسی است که از پرسش و پاسخ چندزبانه و تکمیل کد پشتیبانی می‌کند تا بهره‌وری توسعه‌دهندگان را افزایش دهد.",
  "codegeex4-all-9b.description": "CodeGeeX4-ALL-9B یک مدل تولید کد چندزبانه است که از تکمیل و تولید کد، مفسر کد، جستجوی وب، فراخوانی توابع و پرسش و پاسخ در سطح مخزن پشتیبانی می‌کند و طیف گسترده‌ای از سناریوهای توسعه نرم‌افزار را پوشش می‌دهد. این مدل یکی از بهترین مدل‌های کد زیر ۱۰ میلیارد پارامتر است.",
  "codegemma.description": "CodeGemma یک مدل سبک برای وظایف متنوع برنامه‌نویسی است که امکان تکرار سریع و یکپارچه‌سازی آسان را فراهم می‌کند.",
  "codegemma:2b.description": "CodeGemma یک مدل سبک برای وظایف متنوع برنامه‌نویسی است که امکان تکرار سریع و یکپارچه‌سازی آسان را فراهم می‌کند.",
  "codellama.description": "Code Llama یک مدل زبانی بزرگ متمرکز بر تولید و بحث در مورد کد است که از زبان‌های مختلف برای جریان‌های کاری توسعه‌دهندگان پشتیبانی می‌کند.",
  "codellama/CodeLlama-34b-Instruct-hf.description": "Code Llama یک مدل زبانی بزرگ متمرکز بر تولید و بحث در مورد کد است که از زبان‌های مختلف برای جریان‌های کاری توسعه‌دهندگان پشتیبانی می‌کند.",
  "codellama:13b.description": "Code Llama یک مدل زبانی بزرگ متمرکز بر تولید و بحث در مورد کد است که از زبان‌های مختلف برای جریان‌های کاری توسعه‌دهندگان پشتیبانی می‌کند.",
  "codellama:34b.description": "Code Llama یک مدل زبانی بزرگ متمرکز بر تولید و بحث در مورد کد است که از زبان‌های مختلف برای جریان‌های کاری توسعه‌دهندگان پشتیبانی می‌کند.",
  "codellama:70b.description": "Code Llama یک مدل زبانی بزرگ متمرکز بر تولید و بحث در مورد کد است که از زبان‌های مختلف برای جریان‌های کاری توسعه‌دهندگان پشتیبانی می‌کند.",
  "codeqwen.description": "CodeQwen1.5 یک مدل زبانی بزرگ است که بر پایه داده‌های گسترده کد آموزش دیده و برای وظایف پیچیده برنامه‌نویسی طراحی شده است.",
  "codestral-latest.description": "Codestral پیشرفته‌ترین مدل کدنویسی ماست؛ نسخه v2 (ژانویه ۲۰۲۵) برای وظایف با تأخیر کم و فرکانس بالا مانند FIM، اصلاح کد و تولید تست بهینه شده است.",
  "codestral.description": "Codestral اولین مدل کدنویسی از Mistral AI است که پشتیبانی قوی برای تولید کد ارائه می‌دهد.",
  "codex-mini-latest.description": "codex-mini-latest نسخه تنظیم‌شده مدل o4-mini برای رابط خط فرمان Codex است. برای استفاده مستقیم از API، توصیه می‌شود با gpt-4.1 شروع کنید.",
  "cogito-2.1:671b.description": "Cogito v2.1 671B یک مدل زبان بازمتن آمریکایی است که برای استفاده تجاری رایگان است. این مدل عملکردی در حد مدل‌های برتر دارد، بازدهی بالای استدلال با توکن، زمینه طولانی ۱۲۸هزار توکنی و توانایی کلی قوی ارائه می‌دهد.",
  "cogview-4.description": "CogView-4 نخستین مدل متن به تصویر بازمتن Zhipu است که توانایی تولید نویسه‌های چینی را دارد. این مدل درک معنایی، کیفیت تصویر و رندر متن چینی/انگلیسی را بهبود می‌بخشد، از دستورات دو زبانه با طول دلخواه پشتیبانی می‌کند و می‌تواند تصاویر را در هر وضوحی در محدوده مشخص تولید کند.",
  "cohere-command-r-plus.description": "Command R+ یک مدل پیشرفته بهینه‌شده برای RAG است که برای بارهای کاری سازمانی طراحی شده است.",
  "cohere-command-r.description": "Command R یک مدل مولد مقیاس‌پذیر است که برای استفاده در RAG و ابزارها طراحی شده و هوش مصنوعی در سطح تولید را ممکن می‌سازد.",
  "cohere/Cohere-command-r-plus.description": "Command R+ یک مدل پیشرفته بهینه‌شده برای RAG است که برای بارهای کاری سازمانی طراحی شده است.",
  "cohere/Cohere-command-r.description": "Command R یک مدل مولد مقیاس‌پذیر است که برای استفاده در RAG و ابزارها طراحی شده و هوش مصنوعی در سطح تولید را ممکن می‌سازد.",
  "cohere/command-a.description": "Command A قوی‌ترین مدل Cohere تا به امروز است که در استفاده از ابزارها، عامل‌ها، RAG و کاربردهای چندزبانه برتری دارد. این مدل دارای طول زمینه ۲۵۶هزار توکن است، تنها با دو GPU اجرا می‌شود و ۱۵۰٪ بازدهی بالاتری نسبت به Command R+ 08-2024 دارد.",
  "cohere/command-r-plus.description": "Command R+ جدیدترین مدل زبان بزرگ Cohere است که برای چت و زمینه طولانی بهینه شده و عملکردی استثنایی ارائه می‌دهد تا شرکت‌ها بتوانند از نمونه‌سازی فراتر روند.",
  "cohere/command-r.description": "Command R برای وظایف چت و زمینه طولانی بهینه شده و به عنوان مدلی «مقیاس‌پذیر» معرفی می‌شود که تعادل بین عملکرد بالا و دقت را برقرار می‌کند تا شرکت‌ها بتوانند از نمونه‌سازی فراتر روند.",
  "cohere/embed-v4.0.description": "مدلی برای طبقه‌بندی یا تبدیل متن، تصویر یا محتوای ترکیبی به بردارهای تعبیه‌شده.",
  "comfyui/flux-dev.description": "FLUX.1 Dev یک مدل متن به تصویر با کیفیت بالا (۱۰ تا ۵۰ مرحله) است که برای خروجی‌های خلاقانه و هنری ممتاز ایده‌آل است.",
  "comfyui/flux-kontext-dev.description": "FLUX.1 Kontext-dev یک مدل ویرایش تصویر است که از ویرایش‌های هدایت‌شده با متن، از جمله ویرایش‌های محلی و انتقال سبک پشتیبانی می‌کند.",
  "comfyui/flux-krea-dev.description": "FLUX.1 Krea-dev یک مدل متن به تصویر با فیلترهای ایمنی داخلی است که با همکاری Krea توسعه یافته است.",
  "comfyui/flux-schnell.description": "FLUX.1 Schnell یک مدل متن به تصویر فوق‌سریع است که تصاویر با کیفیت بالا را در ۱ تا ۴ مرحله تولید می‌کند و برای استفاده بلادرنگ و نمونه‌سازی سریع ایده‌آل است.",
  "comfyui/stable-diffusion-15.description": "Stable Diffusion 1.5 یک مدل کلاسیک متن به تصویر با وضوح ۵۱۲x۵۱۲ است که برای نمونه‌سازی سریع و آزمایش‌های خلاقانه مناسب است.",
  "comfyui/stable-diffusion-35-inclclip.description": "Stable Diffusion 3.5 با رمزگذارهای داخلی CLIP/T5 نیازی به فایل‌های رمزگذار خارجی ندارد و برای مدل‌هایی مانند sd3.5_medium_incl_clips با مصرف منابع کمتر مناسب است.",
  "comfyui/stable-diffusion-35.description": "Stable Diffusion 3.5 یک مدل نسل جدید متن به تصویر است که در دو نسخه بزرگ و متوسط ارائه می‌شود. این مدل به فایل‌های رمزگذار CLIP خارجی نیاز دارد و کیفیت تصویر عالی و تبعیت دقیق از دستورات را ارائه می‌دهد.",
  "comfyui/stable-diffusion-custom-refiner.description": "مدل تصویر به تصویر SDXL سفارشی. از custom_sd_lobe.safetensors به عنوان نام فایل مدل استفاده کنید؛ اگر VAE دارید، از custom_sd_vae_lobe.safetensors استفاده کنید. فایل‌های مدل را در پوشه‌های مورد نیاز Comfy قرار دهید.",
  "comfyui/stable-diffusion-custom.description": "مدل متن به تصویر SD سفارشی. از custom_sd_lobe.safetensors به عنوان نام فایل مدل استفاده کنید؛ اگر VAE دارید، از custom_sd_vae_lobe.safetensors استفاده کنید. فایل‌های مدل را در پوشه‌های مورد نیاز Comfy قرار دهید.",
  "comfyui/stable-diffusion-refiner.description": "مدل تصویر به تصویر SDXL که تبدیل‌های با کیفیت بالا از تصاویر ورودی انجام می‌دهد و از انتقال سبک، بازسازی و تغییرات خلاقانه پشتیبانی می‌کند.",
  "comfyui/stable-diffusion-xl.description": "SDXL یک مدل متن به تصویر است که از تولید تصاویر با وضوح بالا ۱۰۲۴x۱۰۲۴ پشتیبانی می‌کند و کیفیت و جزئیات تصویر بهتری ارائه می‌دهد.",
  "command-a-03-2025.description": "Command A توانمندترین مدل ما تا به امروز است که در استفاده از ابزارها، عامل‌ها، RAG و سناریوهای چندزبانه برتری دارد. این مدل دارای پنجره زمینه ۲۵۶هزار توکن است، تنها با دو GPU اجرا می‌شود و ۱۵۰٪ بازدهی بالاتری نسبت به Command R+ 08-2024 دارد.",
  "command-light-nightly.description": "برای کاهش فاصله بین نسخه‌های اصلی، نسخه‌های شبانه Command را ارائه می‌دهیم. برای سری command-light، این نسخه command-light-nightly نام دارد. این نسخه جدیدترین و آزمایشی‌ترین (و احتمالاً ناپایدارترین) نسخه است که به‌طور منظم و بدون اطلاع به‌روزرسانی می‌شود، بنابراین برای استفاده در تولید توصیه نمی‌شود.",
  "command-light.description": "نسخه‌ای کوچک‌تر و سریع‌تر از Command که تقریباً به همان اندازه توانمند است اما سریع‌تر عمل می‌کند.",
  "command-nightly.description": "برای کاهش فاصله بین نسخه‌های اصلی، نسخه‌های شبانه Command را ارائه می‌دهیم. برای سری Command، این نسخه command-nightly نام دارد. این نسخه جدیدترین و آزمایشی‌ترین (و احتمالاً ناپایدارترین) نسخه است که به‌طور منظم و بدون اطلاع به‌روزرسانی می‌شود، بنابراین برای استفاده در تولید توصیه نمی‌شود.",
  "command-r-03-2024.description": "Command R یک مدل چت پیرو دستورالعمل است که کیفیت بالاتر، قابلیت اطمینان بیشتر و پنجره زمینه طولانی‌تری نسبت به مدل‌های قبلی دارد. این مدل از جریان‌های کاری پیچیده مانند تولید کد، RAG، استفاده از ابزار و عامل‌ها پشتیبانی می‌کند.",
  "command-r-08-2024.description": "command-r-08-2024 نسخه به‌روزرسانی‌شده مدل Command R است که در آگوست ۲۰۲۴ منتشر شده است.",
  "command-r-plus-04-2024.description": "command-r-plus نام مستعار command-r-plus-04-2024 است، بنابراین استفاده از command-r-plus در API به آن مدل اشاره دارد.",
  "command-r-plus-08-2024.description": "Command R+ یک مدل چت پیرو دستورالعمل است که کیفیت بالاتر، قابلیت اطمینان بیشتر و پنجره زمینه طولانی‌تری نسبت به مدل‌های قبلی دارد. این مدل برای جریان‌های کاری پیچیده RAG و استفاده چندمرحله‌ای از ابزارها بهترین گزینه است.",
  "command-r-plus.description": "Command R+ یک مدل زبان بزرگ با عملکرد بالا است که برای سناریوهای واقعی سازمانی و برنامه‌های پیچیده طراحی شده است.",
  "command-r.description": "Command R یک مدل زبان بزرگ بهینه‌شده برای چت و وظایف با زمینه طولانی است که برای تعامل پویا و مدیریت دانش ایده‌آل است.",
  "command-r7b-12-2024.description": "command-r7b-12-2024 یک به‌روزرسانی کوچک و کارآمد است که در دسامبر ۲۰۲۴ منتشر شده است. این مدل در RAG، استفاده از ابزار و وظایف عامل‌ها که نیاز به استدلال پیچیده و چندمرحله‌ای دارند، عملکرد عالی دارد.",
  "command.description": "مدل چت پیرو دستورالعمل که کیفیت و قابلیت اطمینان بالاتری در وظایف زبانی ارائه می‌دهد و پنجره زمینه طولانی‌تری نسبت به مدل‌های مولد پایه ما دارد.",
  "computer-use-preview.description": "computer-use-preview یک مدل تخصصی برای ابزار «استفاده از رایانه» است که برای درک و اجرای وظایف مرتبط با رایانه آموزش دیده است.",
  "dall-e-2.description": "مدل نسل دوم DALL·E با تولید تصاویر واقع‌گرایانه‌تر، دقیق‌تر و وضوحی ۴ برابر بیشتر از نسل اول.",
  "dall-e-3.description": "جدیدترین مدل DALL·E که در نوامبر ۲۰۲۳ منتشر شد و از تولید تصاویر واقع‌گرایانه‌تر، دقیق‌تر و با جزئیات قوی‌تر پشتیبانی می‌کند.",
  "databricks/dbrx-instruct.description": "DBRX Instruct مدیریت دستورالعمل‌ها را با قابلیت اطمینان بالا در صنایع مختلف ارائه می‌دهد.",
  "deepseek-ai/DeepSeek-OCR.description": "DeepSeek-OCR یک مدل بینایی-زبانی از DeepSeek AI است که بر OCR و «فشرده‌سازی نوری متنی» تمرکز دارد. این مدل با فشرده‌سازی اطلاعات متنی از تصاویر، اسناد را به‌طور کارآمد پردازش کرده و به متن ساختاریافته (مانند Markdown) تبدیل می‌کند. این مدل در شناسایی دقیق متن در تصاویر عملکرد بالایی دارد و برای دیجیتالی‌سازی اسناد، استخراج متن و پردازش ساختاریافته مناسب است.",
  "deepseek-ai/DeepSeek-R1-0528-Qwen3-8B.description": "DeepSeek-R1-0528-Qwen3-8B زنجیره تفکر را از DeepSeek-R1-0528 به Qwen3 8B Base منتقل می‌کند. این مدل در میان مدل‌های متن‌باز به SOTA رسیده، در AIME 2024 نسبت به Qwen3 8B ده درصد بهتر عمل کرده و عملکردی هم‌سطح با Qwen3-235B-thinking دارد. در استدلال ریاضی، برنامه‌نویسی و منطق عمومی عملکرد درخشانی دارد. معماری آن مشابه Qwen3-8B است اما از توکنایزر DeepSeek-R1-0528 استفاده می‌کند.",
  "deepseek-ai/DeepSeek-R1-0528.description": "DeepSeek R1 با استفاده از منابع محاسباتی بیشتر و بهینه‌سازی‌های الگوریتمی پس از آموزش، توانایی استدلال را تعمیق می‌بخشد. این مدل در معیارهای ریاضی، برنامه‌نویسی و منطق عمومی عملکرد قوی دارد و به سطح مدل‌های پیشرو مانند o3 و Gemini 2.5 Pro نزدیک می‌شود.",
  "deepseek-ai/DeepSeek-R1-Distill-Llama-70B.description": "مدل‌های تقطیرشده DeepSeek-R1 با استفاده از یادگیری تقویتی و داده‌های شروع سرد، توانایی استدلال را بهبود داده و معیارهای چندوظیفه‌ای جدیدی را در مدل‌های متن‌باز ثبت می‌کنند.",
  "deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B.description": "مدل‌های تقطیرشده DeepSeek-R1 با استفاده از یادگیری تقویتی و داده‌های شروع سرد، توانایی استدلال را بهبود داده و معیارهای چندوظیفه‌ای جدیدی را در مدل‌های متن‌باز ثبت می‌کنند.",
  "deepseek-ai/DeepSeek-R1-Distill-Qwen-14B.description": "مدل‌های تقطیرشده DeepSeek-R1 با استفاده از یادگیری تقویتی و داده‌های شروع سرد، توانایی استدلال را بهبود داده و معیارهای چندوظیفه‌ای جدیدی را در مدل‌های متن‌باز ثبت می‌کنند.",
  "deepseek-ai/DeepSeek-R1-Distill-Qwen-32B.description": "DeepSeek-R1-Distill-Qwen-32B از Qwen2.5-32B تقطیر شده و با ۸۰۰ هزار نمونه انتخاب‌شده از DeepSeek-R1 آموزش دیده است. این مدل در ریاضی، برنامه‌نویسی و استدلال عملکرد درخشانی دارد و نتایج قوی‌ای در AIME 2024، MATH-500 (با دقت ۹۴.۳٪) و GPQA Diamond کسب کرده است.",
  "deepseek-ai/DeepSeek-R1-Distill-Qwen-7B.description": "DeepSeek-R1-Distill-Qwen-7B از Qwen2.5-Math-7B تقطیر شده و با ۸۰۰ هزار نمونه انتخاب‌شده از DeepSeek-R1 آموزش دیده است. این مدل عملکرد قوی‌ای دارد: ۹۲.۸٪ در MATH-500، ۵۵.۵٪ در AIME 2024 و امتیاز ۱۱۸۹ در CodeForces برای یک مدل ۷B.",
  "deepseek-ai/DeepSeek-R1.description": "DeepSeek-R1 با استفاده از داده‌های شروع سرد پیش از یادگیری تقویتی، توانایی استدلال را بهبود داده و معیارهای چندوظیفه‌ای جدیدی را در مدل‌های متن‌باز ثبت کرده و از OpenAI-o1-mini پیشی گرفته است.",
  "deepseek-ai/DeepSeek-V2.5.description": "DeepSeek-V2.5 نسخه ارتقاءیافته DeepSeek-V2-Chat و DeepSeek-Coder-V2-Instruct است که توانایی‌های عمومی و برنامه‌نویسی را ترکیب می‌کند. این مدل در نوشتن و پیروی از دستورالعمل‌ها بهبود یافته و در معیارهایی مانند AlpacaEval 2.0، ArenaHard، AlignBench و MT-Bench پیشرفت چشمگیری نشان داده است.",
  "deepseek-ai/DeepSeek-V3.1-Terminus.description": "DeepSeek-V3.1-Terminus نسخه به‌روزشده مدل V3.1 است که به‌عنوان یک عامل ترکیبی LLM طراحی شده است. این مدل مشکلات گزارش‌شده کاربران را رفع کرده، ثبات و سازگاری زبانی را بهبود بخشیده و نویسه‌های غیرعادی و ترکیب چینی/انگلیسی را کاهش داده است. این مدل حالت‌های تفکر و غیرتفکر را با قالب‌های چت ترکیب کرده و امکان جابجایی انعطاف‌پذیر را فراهم می‌کند. همچنین عملکرد عامل کدنویسی و جستجو را برای استفاده مطمئن‌تر از ابزارها و انجام وظایف چندمرحله‌ای بهبود داده است.",
  "deepseek-ai/DeepSeek-V3.1.description": "DeepSeek V3.1 از معماری استدلال ترکیبی استفاده می‌کند و از هر دو حالت تفکر و غیرتفکر پشتیبانی می‌کند.",
  "deepseek-ai/DeepSeek-V3.2-Exp.description": "DeepSeek-V3.2-Exp نسخه آزمایشی V3.2 است که به معماری بعدی پل می‌زند. این مدل با افزودن DeepSeek Sparse Attention (DSA) بر پایه V3.1-Terminus، کارایی آموزش و استنتاج در زمینه‌های طولانی را بهبود می‌بخشد و برای استفاده از ابزارها، درک اسناد طولانی و استدلال چندمرحله‌ای بهینه شده است. این مدل برای بررسی بهره‌وری بالاتر در استدلال با بودجه متنی بزرگ ایده‌آل است.",
  "deepseek-ai/DeepSeek-V3.description": "DeepSeek-V3 یک مدل MoE با ۶۷۱ میلیارد پارامتر است که از MLA و DeepSeekMoE با تعادل بار بدون اتلاف برای آموزش و استنتاج کارآمد استفاده می‌کند. این مدل با استفاده از ۱۴.۸ تریلیون توکن با کیفیت بالا و آموزش با SFT و RL، از سایر مدل‌های متن‌باز پیشی گرفته و به مدل‌های بسته پیشرو نزدیک شده است.",
  "deepseek-ai/deepseek-llm-67b-chat.description": "DeepSeek LLM Chat (67B) یک مدل نوآورانه با درک عمیق زبان و تعامل است.",
  "deepseek-ai/deepseek-v3.1-terminus.description": "DeepSeek V3.1 یک مدل استدلال نسل بعدی با توانایی استدلال پیچیده و زنجیره تفکر برای وظایف تحلیلی عمیق است.",
  "deepseek-ai/deepseek-v3.1.description": "DeepSeek V3.1 یک مدل استدلال نسل بعدی با توانایی استدلال پیچیده و زنجیره تفکر برای وظایف تحلیلی عمیق است.",
  "deepseek-ai/deepseek-vl2.description": "DeepSeek-VL2 یک مدل بینایی-زبانی MoE مبتنی بر DeepSeekMoE-27B با فعال‌سازی پراکنده است که تنها با ۴.۵ میلیارد پارامتر فعال عملکرد قوی‌ای دارد. این مدل در پاسخ به سوالات بصری، OCR، درک اسناد/جداول/نمودارها و پایه‌گذاری بصری عملکرد درخشانی دارد.",
  "deepseek-chat.description": "DeepSeek V3.2 تعادلی میان استدلال و طول خروجی برای پرسش‌وپاسخ روزمره و وظایف عامل‌ها برقرار می‌کند. در معیارهای عمومی به سطح GPT-5 می‌رسد و نخستین مدلی است که تفکر را در استفاده از ابزارها ادغام کرده و در ارزیابی‌های عامل‌های متن‌باز پیشتاز است.",
  "deepseek-coder-33B-instruct.description": "DeepSeek Coder 33B یک مدل زبان برنامه‌نویسی است که با ۲ تریلیون توکن (۸۷٪ کد، ۱۳٪ متن چینی/انگلیسی) آموزش دیده است. این مدل دارای پنجره متنی ۱۶K و وظایف تکمیل در میانه است که تکمیل کد در سطح پروژه و پر کردن قطعات کد را فراهم می‌کند.",
  "deepseek-coder-v2.description": "DeepSeek Coder V2 یک مدل کدنویسی MoE متن‌باز است که در وظایف برنامه‌نویسی عملکردی هم‌سطح با GPT-4 Turbo دارد.",
  "deepseek-coder-v2:236b.description": "DeepSeek Coder V2 یک مدل کدنویسی MoE متن‌باز است که در وظایف برنامه‌نویسی عملکردی هم‌سطح با GPT-4 Turbo دارد.",
  "deepseek-ocr.description": "DeepSeek-OCR یک مدل بینایی-زبانی از DeepSeek AI است که بر OCR و «فشرده‌سازی نوری متنی» تمرکز دارد. این مدل با فشرده‌سازی اطلاعات متنی از تصاویر، اسناد را به‌طور کارآمد پردازش کرده و به فرمت‌های متنی ساختاریافته مانند Markdown تبدیل می‌کند. این مدل در شناسایی دقیق متن در تصاویر عملکرد بالایی دارد و برای دیجیتالی‌سازی اسناد، استخراج متن و پردازش ساختاریافته مناسب است.",
  "deepseek-r1-0528.description": "مدل کامل ۶۸۵ میلیارد پارامتری منتشرشده در ۲۸ مه ۲۰۲۵. DeepSeek-R1 از یادگیری تقویتی در مقیاس بزرگ در مرحله پس‌آموزش استفاده می‌کند که توانایی استدلال را با حداقل داده‌های برچسب‌خورده به‌طور چشمگیری بهبود می‌بخشد و در ریاضی، کدنویسی و استدلال زبان طبیعی عملکرد قوی‌ای دارد.",
  "deepseek-r1-250528.description": "DeepSeek R1 250528 نسخه کامل مدل استدلال DeepSeek-R1 برای وظایف سخت ریاضی و منطقی است.",
  "deepseek-r1-70b-fast-online.description": "نسخه سریع DeepSeek R1 70B با جستجوی وب در زمان واقعی که پاسخ‌های سریع‌تری را با حفظ عملکرد ارائه می‌دهد.",
  "deepseek-r1-70b-online.description": "نسخه استاندارد DeepSeek R1 70B با جستجوی وب در زمان واقعی، مناسب برای چت و وظایف متنی به‌روز.",
  "deepseek-r1-distill-llama-70b.description": "DeepSeek R1 Distill Llama 70B ترکیبی از استدلال R1 با اکوسیستم Llama است.",
  "deepseek-r1-distill-llama-8b.description": "DeepSeek-R1-Distill-Llama-8B از Llama-3.1-8B با استفاده از خروجی‌های DeepSeek R1 تقطیر شده است.",
  "deepseek-r1-distill-llama.description": "deepseek-r1-distill-llama از DeepSeek-R1 بر پایه Llama تقطیر شده است.",
  "deepseek-r1-distill-qianfan-70b.description": "DeepSeek R1 Distill Qianfan 70B یک مدل تقطیر R1 بر پایه Qianfan-70B با ارزش بالا است.",
  "deepseek-r1-distill-qianfan-8b.description": "DeepSeek R1 Distill Qianfan 8B یک مدل تقطیر R1 بر پایه Qianfan-8B برای برنامه‌های کوچک و متوسط است.",
  "deepseek-r1-distill-qianfan-llama-70b.description": "DeepSeek R1 Distill Qianfan Llama 70B یک مدل تقطیر R1 بر پایه Llama-70B است.",
  "deepseek-r1-distill-qwen-1.5b.description": "DeepSeek R1 Distill Qwen 1.5B یک مدل تقطیر فوق‌سبک برای محیط‌های بسیار کم‌منبع است.",
  "deepseek-r1-distill-qwen-14b.description": "DeepSeek R1 Distill Qwen 14B یک مدل تقطیر میان‌رده برای استقرار در سناریوهای چندگانه است.",
  "deepseek-r1-distill-qwen-32b.description": "DeepSeek R1 Distill Qwen 32B یک مدل تقطیر R1 بر پایه Qwen-32B است که بین عملکرد و هزینه تعادل برقرار می‌کند.",
  "deepseek-r1-distill-qwen-7b.description": "DeepSeek R1 Distill Qwen 7B یک مدل تقطیر سبک برای محیط‌های لبه‌ای و سازمانی خصوصی است.",
  "deepseek-r1-distill-qwen.description": "deepseek-r1-distill-qwen از DeepSeek-R1 بر پایه Qwen تقطیر شده است.",
  "deepseek-r1-fast-online.description": "نسخه کامل سریع DeepSeek R1 با جستجوی وب در زمان واقعی که توانایی در مقیاس ۶۷۱B را با پاسخ‌دهی سریع‌تر ترکیب می‌کند.",
  "deepseek-r1-online.description": "نسخه کامل DeepSeek R1 با ۶۷۱ میلیارد پارامتر و جستجوی وب در زمان واقعی که درک و تولید قوی‌تری را ارائه می‌دهد.",
  "deepseek-r1.description": "DeepSeek-R1 پیش از یادگیری تقویتی از داده‌های شروع سرد استفاده می‌کند و در وظایف ریاضی، کدنویسی و استدلال عملکردی هم‌سطح با OpenAI-o1 دارد.",
  "deepseek-reasoner.description": "DeepSeek V3.2 Thinking یک مدل استدلال عمیق است که پیش از تولید خروجی، زنجیره‌ای از تفکر ایجاد می‌کند تا دقت بالاتری داشته باشد. این مدل در رقابت‌ها نتایج برتری کسب کرده و استدلالی در سطح Gemini-3.0-Pro ارائه می‌دهد.",
  "deepseek-v2.description": "DeepSeek V2 یک مدل MoE کارآمد است که پردازش مقرون‌به‌صرفه را امکان‌پذیر می‌سازد.",
  "deepseek-v2:236b.description": "DeepSeek V2 236B مدل متمرکز بر کدنویسی DeepSeek است که توانایی بالایی در تولید کد دارد.",
  "deepseek-v3-0324.description": "DeepSeek-V3-0324 یک مدل MoE با ۶۷۱ میلیارد پارامتر است که در برنامه‌نویسی، توانایی‌های فنی، درک زمینه و پردازش متون بلند عملکرد برجسته‌ای دارد.",
  "deepseek-v3.1-terminus.description": "DeepSeek-V3.1-Terminus یک مدل زبان بزرگ بهینه‌شده برای دستگاه‌های ترمینال است که توسط DeepSeek توسعه یافته است.",
  "deepseek-v3.1-think-250821.description": "DeepSeek V3.1 Think 250821 نسخه تفکر عمیق مدل Terminus است که برای استدلال با عملکرد بالا طراحی شده است.",
  "deepseek-v3.1.description": "DeepSeek-V3.1 یک مدل استدلال ترکیبی جدید از DeepSeek است که از هر دو حالت تفکر و بدون تفکر پشتیبانی می‌کند و بهره‌وری تفکر بالاتری نسبت به DeepSeek-R1-0528 دارد. بهینه‌سازی‌های پس از آموزش، استفاده از ابزارها و عملکرد وظایف نماینده را به‌طور قابل توجهی بهبود می‌بخشد. این مدل از پنجره متنی ۱۲۸ هزار توکن و خروجی تا ۶۴ هزار توکن پشتیبانی می‌کند.",
  "deepseek-v3.1:671b.description": "DeepSeek V3.1 یک مدل استدلال نسل بعدی با توانایی استدلال پیچیده و زنجیره‌ای بهبود یافته است که برای وظایف نیازمند تحلیل عمیق مناسب است.",
  "deepseek-v3.2-exp.description": "مدل deepseek-v3.2-exp با معرفی توجه پراکنده، کارایی آموزش و استنتاج در متون بلند را بهبود می‌بخشد و نسبت به deepseek-v3.1 قیمت پایین‌تری دارد.",
  "deepseek-v3.2-think.description": "DeepSeek V3.2 Think یک مدل تفکر عمیق کامل است که توانایی استدلال زنجیره‌ای بلندتری دارد.",
  "deepseek-v3.2.description": "DeepSeek-V3.2 نخستین مدل استدلال ترکیبی از DeepSeek است که تفکر را با استفاده از ابزارها ادغام می‌کند. این مدل با معماری کارآمد برای صرفه‌جویی در محاسبات، یادگیری تقویتی در مقیاس بزرگ برای افزایش توانایی‌ها، و داده‌های مصنوعی در مقیاس وسیع برای تقویت تعمیم‌پذیری آموزش دیده است. ترکیب این سه عامل عملکردی هم‌تراز با GPT-5-High ارائه می‌دهد، در حالی که طول خروجی را به‌طور قابل توجهی کاهش داده و سربار محاسباتی و زمان انتظار کاربر را کم می‌کند.",
  "deepseek-v3.description": "DeepSeek-V3 یک مدل MoE قدرتمند با ۶۷۱ میلیارد پارامتر کل و ۳۷ میلیارد پارامتر فعال در هر توکن است.",
  "deepseek-vl2-small.description": "DeepSeek VL2 Small نسخه چندوجهی سبک‌وزن برای استفاده در شرایط محدود منابع و هم‌زمانی بالا است.",
  "deepseek-vl2.description": "DeepSeek VL2 یک مدل چندوجهی برای درک تصویر-متن و پاسخ‌گویی دقیق بصری است.",
  "deepseek/deepseek-chat-v3-0324.description": "DeepSeek V3 یک مدل MoE با ۶۸۵ میلیارد پارامتر است و جدیدترین نسخه از سری چت پرچم‌دار DeepSeek محسوب می‌شود.\n\nاین مدل بر پایه [DeepSeek V3](/deepseek/deepseek-chat-v3) ساخته شده و در انجام وظایف مختلف عملکرد قوی دارد.",
  "deepseek/deepseek-chat-v3-0324:free.description": "DeepSeek V3 یک مدل MoE با ۶۸۵ میلیارد پارامتر است و جدیدترین نسخه از سری چت پرچم‌دار DeepSeek محسوب می‌شود.\n\nاین مدل بر پایه [DeepSeek V3](/deepseek/deepseek-chat-v3) ساخته شده و در انجام وظایف مختلف عملکرد قوی دارد.",
  "deepseek/deepseek-chat-v3.1.description": "DeepSeek-V3.1 مدل استدلال ترکیبی با زمینه بلند از DeepSeek است که از حالت‌های تفکر/بدون تفکر و ادغام ابزارها پشتیبانی می‌کند.",
  "deepseek/deepseek-chat.description": "DeepSeek-V3 مدل استدلال ترکیبی با عملکرد بالا از DeepSeek برای وظایف پیچیده و ادغام ابزارها است.",
  "deepseek/deepseek-math-v2.description": "نسخه دوم DeepSeek Math یک مدل با پیشرفت‌های چشمگیر در توانایی استدلال ریاضی است. نوآوری اصلی آن در مکانیزم آموزش «خود-بازبینی» نهفته است و در چندین رقابت برتر ریاضی به سطح مدال طلا دست یافته است.",
  "deepseek/deepseek-r1-0528.description": "DeepSeek R1 0528 نسخه به‌روزرسانی‌شده‌ای است که بر در دسترس بودن آزاد و استدلال عمیق تمرکز دارد.",
  "deepseek/deepseek-r1-0528:free.description": "DeepSeek-R1 با استفاده از داده‌های برچسب‌خورده حداقلی، توانایی استدلال را به‌طور چشمگیری بهبود می‌بخشد و پیش از پاسخ نهایی، زنجیره‌ای از افکار تولید می‌کند تا دقت را افزایش دهد.",
  "deepseek/deepseek-r1-distill-llama-70b.description": "DeepSeek R1 Distill Llama 70B یک مدل تقطیرشده بر پایه Llama 3.3 70B است که با استفاده از خروجی‌های DeepSeek R1 تنظیم دقیق شده و عملکردی رقابتی با مدل‌های پیشرفته بزرگ دارد.",
  "deepseek/deepseek-r1-distill-llama-8b.description": "DeepSeek R1 Distill Llama 8B یک مدل تقطیرشده بر پایه Llama-3.1-8B-Instruct است که با استفاده از خروجی‌های DeepSeek R1 آموزش دیده است.",
  "deepseek/deepseek-r1-distill-qwen-14b.description": "DeepSeek R1 Distill Qwen 14B یک مدل تقطیرشده بر پایه Qwen 2.5 14B است که با استفاده از خروجی‌های DeepSeek R1 آموزش دیده است. این مدل در چندین معیار از OpenAI o1-mini پیشی گرفته و در میان مدل‌های متراکم نتایج پیشرفته‌ای ارائه می‌دهد. نکات برجسته:\nAIME 2024 pass@1: 69.7\nMATH-500 pass@1: 93.9\nرتبه CodeForces: 1481\nتنظیم دقیق با خروجی‌های DeepSeek R1 عملکردی رقابتی با مدل‌های پیشرفته بزرگ ارائه می‌دهد.",
  "deepseek/deepseek-r1-distill-qwen-32b.description": "DeepSeek R1 Distill Qwen 32B یک مدل تقطیرشده بر پایه Qwen 2.5 32B است که با استفاده از خروجی‌های DeepSeek R1 آموزش دیده است. این مدل در چندین معیار از OpenAI o1-mini پیشی گرفته و در میان مدل‌های متراکم نتایج پیشرفته‌ای ارائه می‌دهد. نکات برجسته:\nAIME 2024 pass@1: 72.6\nMATH-500 pass@1: 94.3\nرتبه CodeForces: 1691\nتنظیم دقیق با خروجی‌های DeepSeek R1 عملکردی رقابتی با مدل‌های پیشرفته بزرگ ارائه می‌دهد.",
  "deepseek/deepseek-r1.description": "DeepSeek R1 به نسخه DeepSeek-R1-0528 به‌روزرسانی شده است. با استفاده از محاسبات بیشتر و بهینه‌سازی‌های الگوریتمی پس از آموزش، عمق و توانایی استدلال را به‌طور قابل توجهی بهبود می‌بخشد. این مدل در معیارهای ریاضی، برنامه‌نویسی و منطق عمومی عملکرد قوی دارد و به سطح مدل‌هایی مانند o3 و Gemini 2.5 Pro نزدیک می‌شود.",
  "deepseek/deepseek-r1/community.description": "DeepSeek R1 جدیدترین مدل متن‌باز منتشرشده توسط تیم DeepSeek است که عملکرد استدلالی بسیار قوی، به‌ویژه در ریاضی، کدنویسی و وظایف استدلالی دارد و با OpenAI o1 قابل مقایسه است.",
  "deepseek/deepseek-r1:free.description": "DeepSeek-R1 با استفاده از داده‌های برچسب‌خورده حداقلی، توانایی استدلال را به‌طور چشمگیری بهبود می‌بخشد و پیش از پاسخ نهایی، زنجیره‌ای از افکار تولید می‌کند تا دقت را افزایش دهد.",
  "deepseek/deepseek-reasoner.description": "DeepSeek-V3 Thinking (reasoner) مدل آزمایشی استدلالی DeepSeek است که برای وظایف استدلالی با پیچیدگی بالا مناسب است.",
  "deepseek/deepseek-v3.1-base.description": "DeepSeek V3.1 Base نسخه بهبود یافته مدل DeepSeek V3 است.",
  "deepseek/deepseek-v3.description": "یک مدل زبان بزرگ سریع و عمومی با توانایی استدلال تقویت‌شده.",
  "deepseek/deepseek-v3/community.description": "DeepSeek-V3 پیشرفتی بزرگ در سرعت استدلال نسبت به مدل‌های قبلی ارائه می‌دهد. این مدل در میان مدل‌های متن‌باز رتبه اول را دارد و با مدل‌های بسته پیشرفته رقابت می‌کند. DeepSeek-V3 از معماری Multi-Head Latent Attention (MLA) و DeepSeekMoE استفاده می‌کند که در DeepSeek-V2 به‌طور کامل اعتبارسنجی شده‌اند. همچنین از استراتژی کمکی بدون اتلاف برای تعادل بار و هدف آموزشی پیش‌بینی چندتوکنی برای عملکرد قوی‌تر بهره می‌برد.",
  "deepseek_r1.description": "DeepSeek-R1 یک مدل استدلالی مبتنی بر یادگیری تقویتی است که مشکلات تکرار و خوانایی را برطرف می‌کند. پیش از یادگیری تقویتی، از داده‌های شروع سرد برای بهبود بیشتر عملکرد استدلال استفاده می‌کند. این مدل در وظایف ریاضی، کدنویسی و استدلال با OpenAI-o1 برابری می‌کند و با طراحی دقیق آموزش، نتایج کلی را بهبود می‌بخشد.",
  "deepseek_r1_distill_llama_70b.description": "DeepSeek-R1-Distill-Llama-70B از Llama-3.3-70B-Instruct تقطیر شده است. به‌عنوان بخشی از سری DeepSeek-R1، با استفاده از نمونه‌های تولیدشده توسط DeepSeek-R1 تنظیم دقیق شده و در ریاضی، کدنویسی و استدلال عملکرد قوی دارد.",
  "deepseek_r1_distill_qwen_14b.description": "DeepSeek-R1-Distill-Qwen-14B از Qwen2.5-14B تقطیر شده و با استفاده از ۸۰۰ هزار نمونه منتخب تولیدشده توسط DeepSeek-R1 تنظیم دقیق شده است و عملکرد استدلالی قوی ارائه می‌دهد.",
  "deepseek_r1_distill_qwen_32b.description": "DeepSeek-R1-Distill-Qwen-32B از Qwen2.5-32B تقطیر شده و با استفاده از ۸۰۰ هزار نمونه منتخب تولیدشده توسط DeepSeek-R1 تنظیم دقیق شده است و در ریاضی، کدنویسی و استدلال عملکرد برجسته‌ای دارد.",
  "devstral-2:123b.description": "Devstral 2 123B در استفاده از ابزارها برای بررسی پایگاه‌های کد، ویرایش چندین فایل و پشتیبانی از عامل‌های مهندسی نرم‌افزار عملکرد برجسته‌ای دارد.",
  "doubao-1.5-lite-32k.description": "Doubao-1.5-lite یک مدل سبک و جدید با پاسخ‌دهی فوق‌العاده سریع است که کیفیت و تأخیر سطح بالا را ارائه می‌دهد.",
  "doubao-1.5-pro-256k.description": "Doubao-1.5-pro-256k ارتقایی جامع از Doubao-1.5-Pro است که عملکرد کلی را ۱۰٪ بهبود می‌بخشد. این مدل از پنجره متنی ۲۵۶هزار توکن و خروجی تا ۱۲هزار توکن پشتیبانی می‌کند و عملکرد بالاتر، پنجره بزرگ‌تر و ارزش قوی‌تری برای کاربردهای گسترده‌تر ارائه می‌دهد.",
  "doubao-1.5-pro-32k.description": "Doubao-1.5-pro یک مدل پرچم‌دار نسل جدید با ارتقاهای همه‌جانبه است که در دانش، کدنویسی و استدلال عملکرد درخشانی دارد.",
  "doubao-1.5-thinking-pro-m.description": "Doubao-1.5 یک مدل جدید با استدلال عمیق است (نسخه m شامل استدلال عمیق چندوجهی بومی است) که در ریاضیات، کدنویسی، استدلال علمی و وظایف عمومی مانند نوشتن خلاقانه عملکرد برجسته‌ای دارد. این مدل به نتایج سطح بالا در معیارهایی مانند AIME 2024، Codeforces و GPQA دست یافته یا نزدیک شده است. از پنجره متنی ۱۲۸هزار توکن و خروجی تا ۱۶هزار توکن پشتیبانی می‌کند.",
  "doubao-1.5-thinking-pro.description": "Doubao-1.5 یک مدل جدید با استدلال عمیق است که در ریاضیات، کدنویسی، استدلال علمی و وظایف عمومی مانند نوشتن خلاقانه عملکرد برجسته‌ای دارد. این مدل به نتایج سطح بالا در معیارهایی مانند AIME 2024، Codeforces و GPQA دست یافته یا نزدیک شده است. از پنجره متنی ۱۲۸هزار توکن و خروجی تا ۱۶هزار توکن پشتیبانی می‌کند.",
  "doubao-1.5-thinking-vision-pro.description": "مدلی جدید با استدلال بصری عمیق و درک و استدلال چندوجهی قوی‌تر که در ۳۷ از ۵۹ معیار عمومی به نتایج SOTA دست یافته است.",
  "doubao-1.5-ui-tars.description": "Doubao-1.5-UI-TARS یک مدل عامل بومی متمرکز بر رابط گرافیکی است که با ادراک، استدلال و اقدام شبیه انسان به‌طور یکپارچه با رابط‌ها تعامل دارد.",
  "doubao-1.5-vision-lite.description": "Doubao-1.5-vision-lite یک مدل چندوجهی ارتقایافته است که از تصاویر با هر وضوح و نسبت تصویر پشتیبانی می‌کند و استدلال بصری، شناسایی اسناد، درک جزئیات و پیروی از دستورالعمل‌ها را بهبود می‌بخشد. از پنجره متنی ۱۲۸هزار توکن و خروجی تا ۱۶هزار توکن پشتیبانی می‌کند.",
  "doubao-1.5-vision-pro-32k.description": "Doubao-1.5-vision-pro یک مدل چندوجهی ارتقایافته است که از تصاویر با هر وضوح و نسبت تصویر پشتیبانی می‌کند و استدلال بصری، شناسایی اسناد، درک جزئیات و پیروی از دستورالعمل‌ها را بهبود می‌بخشد.",
  "doubao-1.5-vision-pro.description": "Doubao-1.5-vision-pro یک مدل چندوجهی ارتقایافته است که از تصاویر با هر وضوح و نسبت تصویر پشتیبانی می‌کند و استدلال بصری، شناسایی اسناد، درک جزئیات و پیروی از دستورالعمل‌ها را بهبود می‌بخشد.",
  "doubao-lite-128k.description": "پاسخ‌دهی فوق‌العاده سریع با ارزش بهتر، ارائه گزینه‌های انعطاف‌پذیرتر در سناریوهای مختلف. از استدلال و تنظیم دقیق با پنجره متنی ۱۲۸هزار توکن پشتیبانی می‌کند.",
  "doubao-lite-32k.description": "پاسخ‌دهی فوق‌العاده سریع با ارزش بهتر، ارائه گزینه‌های انعطاف‌پذیرتر در سناریوهای مختلف. از استدلال و تنظیم دقیق با پنجره متنی ۳۲هزار توکن پشتیبانی می‌کند.",
  "doubao-lite-4k.description": "پاسخ‌دهی فوق‌العاده سریع با ارزش بهتر، ارائه گزینه‌های انعطاف‌پذیرتر در سناریوهای مختلف. از استدلال و تنظیم دقیق با پنجره متنی ۴هزار توکن پشتیبانی می‌کند.",
  "doubao-pro-256k.description": "بهترین مدل پرچم‌دار برای وظایف پیچیده با نتایج قوی در پرسش و پاسخ مرجع، خلاصه‌سازی، تولید محتوا، طبقه‌بندی متنی و نقش‌آفرینی. از استدلال و تنظیم دقیق با پنجره متنی ۲۵۶هزار توکن پشتیبانی می‌کند.",
  "doubao-pro-32k.description": "بهترین مدل پرچم‌دار برای وظایف پیچیده با نتایج قوی در پرسش و پاسخ مرجع، خلاصه‌سازی، تولید محتوا، طبقه‌بندی متنی و نقش‌آفرینی. از استدلال و تنظیم دقیق با پنجره متنی ۳۲هزار توکن پشتیبانی می‌کند.",
  "doubao-seed-1.6-flash.description": "Doubao-Seed-1.6-flash یک مدل چندوجهی با استدلال عمیق و پاسخ‌دهی فوق‌العاده سریع با TPOT تا ۱۰ میلی‌ثانیه است. از متن و تصویر پشتیبانی می‌کند، در درک متن از مدل lite قبلی پیشی می‌گیرد و در درک تصویر با مدل‌های pro رقابت می‌کند. از پنجره متنی ۲۵۶هزار توکن و خروجی تا ۱۶هزار توکن پشتیبانی می‌کند.",
  "doubao-seed-1.6-lite.description": "Doubao-Seed-1.6-lite یک مدل جدید چندوجهی با استدلال عمیق است که تلاش استدلالی قابل تنظیم (حداقل، کم، متوسط، زیاد) را ارائه می‌دهد و گزینه‌ای با ارزش بالا برای وظایف رایج است. از پنجره متنی تا ۲۵۶هزار توکن پشتیبانی می‌کند.",
  "doubao-seed-1.6-thinking.description": "Doubao-Seed-1.6-thinking استدلال را به‌طور قابل توجهی تقویت کرده و توانایی‌های اصلی در کدنویسی، ریاضیات و استدلال منطقی را نسبت به Doubao-1.5-thinking-pro بهبود می‌بخشد و درک تصویر را نیز اضافه می‌کند. از پنجره متنی ۲۵۶هزار توکن و خروجی تا ۱۶هزار توکن پشتیبانی می‌کند.",
  "doubao-seed-1.6-vision.description": "Doubao-Seed-1.6-vision یک مدل استدلال بصری است که درک و استدلال چندوجهی قوی‌تری را برای آموزش، بررسی تصویر، بازرسی/امنیت و پرسش و پاسخ هوش مصنوعی ارائه می‌دهد. از پنجره متنی ۲۵۶هزار توکن و خروجی تا ۶۴هزار توکن پشتیبانی می‌کند.",
  "doubao-seed-1.6.description": "Doubao-Seed-1.6 یک مدل جدید چندوجهی با استدلال عمیق است که از حالت‌های خودکار، تفکری و غیرتفکری پشتیبانی می‌کند. در حالت غیرتفکری، عملکرد آن به‌طور قابل توجهی از Doubao-1.5-pro/250115 بهتر است. از پنجره متنی ۲۵۶هزار توکن و خروجی تا ۱۶هزار توکن پشتیبانی می‌کند.",
  "doubao-seed-1.8.description": "Doubao-Seed-1.8 دارای درک چندوجهی قوی‌تر و توانایی‌های عامل پیشرفته‌تری است، از ورودی متن/تصویر/ویدیو و ذخیره‌سازی زمینه پشتیبانی می‌کند و در انجام وظایف پیچیده عملکردی عالی ارائه می‌دهد.",
  "doubao-seed-code.description": "Doubao-Seed-Code برای کدنویسی عامل‌محور بهینه‌سازی عمیقی شده است، از ورودی‌های چندوجهی (متن/تصویر/ویدیو) و پنجره متنی ۲۵۶هزار توکن پشتیبانی می‌کند، با API شرکت Anthropic سازگار است و برای کدنویسی، درک تصویر و جریان‌های کاری عامل مناسب است.",
  "doubao-seededit-3-0-i2i-250628.description": "مدل تصویر Doubao از ByteDance Seed از ورودی‌های متن و تصویر پشتیبانی می‌کند و تولید تصویر با کیفیت بالا و قابل کنترل را ارائه می‌دهد. از ویرایش تصویر با راهنمایی متن پشتیبانی می‌کند و اندازه خروجی بین ۵۱۲ تا ۱۵۳۶ در ضلع بلندتر است.",
  "doubao-seedream-3-0-t2i-250415.description": "Seedream 3.0 یک مدل تولید تصویر از ByteDance Seed است که از ورودی‌های متن و تصویر پشتیبانی می‌کند و تولید تصویر با کیفیت بالا و قابل کنترل را ارائه می‌دهد. این مدل تصاویر را از دستورات متنی تولید می‌کند.",
  "doubao-seedream-4-0-250828.description": "Seedream 4.0 یک مدل تولید تصویر از ByteDance Seed است که از ورودی‌های متن و تصویر پشتیبانی می‌کند و تولید تصویر با کیفیت بالا و قابل کنترل را ارائه می‌دهد. این مدل تصاویر را از دستورات متنی تولید می‌کند.",
  "doubao-vision-lite-32k.description": "Doubao-vision یک مدل چندوجهی از Doubao است که درک تصویر و استدلال قوی به همراه پیروی دقیق از دستورالعمل‌ها را ارائه می‌دهد. در استخراج متن از تصویر و وظایف استدلال مبتنی بر تصویر عملکرد خوبی دارد و سناریوهای پیچیده‌تر و گسترده‌تری برای پرسش و پاسخ بصری را ممکن می‌سازد.",
  "doubao-vision-pro-32k.description": "Doubao-vision یک مدل چندوجهی از Doubao است که درک تصویر و استدلال قوی به همراه پیروی دقیق از دستورالعمل‌ها را ارائه می‌دهد. در استخراج متن از تصویر و وظایف استدلال مبتنی بر تصویر عملکرد خوبی دارد و سناریوهای پیچیده‌تر و گسترده‌تری برای پرسش و پاسخ بصری را ممکن می‌سازد.",
  "emohaa.description": "Emohaa یک مدل سلامت روان با توانایی مشاوره حرفه‌ای است که به کاربران در درک مسائل احساسی کمک می‌کند.",
  "ernie-4.5-0.3b.description": "ERNIE 4.5 0.3B یک مدل سبک متن‌باز برای استقرار محلی و سفارشی‌سازی شده است.",
  "ernie-4.5-21b-a3b.description": "ERNIE 4.5 21B A3B یک مدل متن‌باز با پارامترهای زیاد و توانایی درک و تولید قوی‌تر است.",
  "ernie-4.5-300b-a47b.description": "ERNIE 4.5 300B A47B مدل MoE بسیار بزرگ Baidu ERNIE با توانایی استدلال عالی است.",
  "ernie-4.5-8k-preview.description": "پیش‌نمایش مدل با پنجره متنی ۸هزار توکن برای ارزیابی ERNIE 4.5.",
  "ernie-4.5-turbo-128k-preview.description": "پیش‌نمایش ERNIE 4.5 Turbo 128K با قابلیت‌های سطح انتشار، مناسب برای یکپارچه‌سازی و تست‌های مقدماتی.",
  "ernie-4.5-turbo-128k.description": "ERNIE 4.5 Turbo 128K یک مدل عمومی با عملکرد بالا است که از تقویت جستجو و فراخوانی ابزار برای پرسش و پاسخ، کدنویسی و سناریوهای عامل پشتیبانی می‌کند.",
  "ernie-4.5-turbo-32k.description": "ERNIE 4.5 Turbo 32K نسخه‌ای با طول زمینه متوسط برای پرسش و پاسخ، بازیابی از پایگاه دانش و گفت‌وگوی چندمرحله‌ای است.",
  "ernie-4.5-turbo-latest.description": "جدیدترین نسخه ERNIE 4.5 Turbo با عملکرد کلی بهینه‌شده، ایده‌آل برای استفاده در تولید اصلی است.",
  "ernie-4.5-turbo-vl-32k-preview.description": "پیش‌نمایش چندوجهی ERNIE 4.5 Turbo VL 32K برای ارزیابی توانایی دید در زمینه‌های طولانی.",
  "ernie-4.5-turbo-vl-32k.description": "ERNIE 4.5 Turbo VL 32K نسخه‌ای چندوجهی با طول زمینه متوسط برای درک ترکیبی اسناد بلند و تصاویر است.",
  "ernie-4.5-turbo-vl-latest.description": "جدیدترین نسخه چندوجهی ERNIE 4.5 Turbo VL با درک و استدلال بهتر تصویر-متن.",
  "ernie-4.5-turbo-vl-preview.description": "پیش‌نمایش مدل چندوجهی ERNIE 4.5 Turbo VL برای درک و تولید تصویر-متن، مناسب برای پرسش و پاسخ بصری و درک محتوا.",
  "ernie-4.5-turbo-vl.description": "ERNIE 4.5 Turbo VL یک مدل چندوجهی بالغ برای درک و شناسایی تصویر-متن در محیط‌های تولیدی است.",
  "ernie-4.5-vl-28b-a3b.description": "ERNIE 4.5 VL 28B A3B یک مدل چندوجهی متن‌باز برای درک و استدلال تصویر-متن است.",
  "ernie-5.0-thinking-latest.description": "Wenxin 5.0 Thinking یک مدل پرچم‌دار بومی تمام‌وجهی است که مدل‌سازی متن، تصویر، صدا و ویدیو را یکپارچه می‌کند. این مدل ارتقاهای گسترده‌ای در توانایی برای پرسش و پاسخ پیچیده، تولید محتوا و سناریوهای عامل ارائه می‌دهد.",
  "ernie-5.0-thinking-preview.description": "پیش‌نمایش Wenxin 5.0 Thinking، یک مدل پرچم‌دار بومی تمام‌وجهی با مدل‌سازی یکپارچه متن، تصویر، صدا و ویدیو. این مدل ارتقاهای گسترده‌ای در توانایی برای پرسش و پاسخ پیچیده، تولید محتوا و سناریوهای عامل ارائه می‌دهد.",
  "ernie-char-8k.description": "ERNIE Character 8K یک مدل گفت‌وگوی شخصیتی برای ساخت شخصیت‌های IP و چت همراه بلندمدت است.",
  "ernie-char-fiction-8k-preview.description": "پیش‌نمایش ERNIE Character Fiction 8K یک مدل ساخت شخصیت و داستان برای ارزیابی و آزمایش ویژگی‌ها است.",
  "ernie-char-fiction-8k.description": "ERNIE Character Fiction 8K یک مدل شخصیتی برای رمان‌نویسی و خلق داستان است که برای تولید داستان‌های بلند مناسب است.",
  "ernie-irag-edit.description": "ERNIE iRAG Edit یک مدل ویرایش تصویر است که از پاک‌کردن، بازنقاشی و تولید نسخه‌های جایگزین پشتیبانی می‌کند.",
  "ernie-lite-pro-128k.description": "ERNIE Lite Pro 128K یک مدل سبک و پرکاربرد برای سناریوهای حساس به تأخیر و هزینه است.",
  "ernie-novel-8k.description": "ERNIE Novel 8K برای رمان‌های بلند و داستان‌های IP با روایت چندشخصیتی طراحی شده است.",
  "ernie-speed-pro-128k.description": "ERNIE Speed Pro 128K یک مدل با ارزش بالا و هم‌زمانی بالا برای خدمات آنلاین گسترده و برنامه‌های سازمانی است.",
  "ernie-x1-turbo-32k.description": "ERNIE X1 Turbo 32K یک مدل تفکر سریع با زمینه ۳۲K برای استدلال پیچیده و گفت‌وگوی چندمرحله‌ای است.",
  "ernie-x1.1-preview.description": "پیش‌نمایش ERNIE X1.1 یک مدل تفکر برای ارزیابی و آزمایش است.",
  "fal-ai/bytedance/seedream/v4.5.description": "Seedream 4.5 که توسط تیم Seed شرکت ByteDance توسعه یافته، از ویرایش و ترکیب چندتصویری پشتیبانی می‌کند. این مدل دارای ثبات موضوعی بهبود یافته، پیروی دقیق از دستورالعمل‌ها، درک منطق فضایی، بیان زیبایی‌شناختی، طراحی پوستر و لوگو با رندر دقیق متن-تصویر است.",
  "fal-ai/bytedance/seedream/v4.description": "Seedream 4.0 که توسط تیم Seed شرکت ByteDance توسعه یافته، از ورودی‌های متنی و تصویری برای تولید تصاویر با کیفیت بالا و قابل کنترل پشتیبانی می‌کند.",
  "fal-ai/flux-kontext/dev.description": "مدل FLUX.1 با تمرکز بر ویرایش تصویر که از ورودی‌های متنی و تصویری پشتیبانی می‌کند.",
  "fal-ai/flux-pro/kontext.description": "FLUX.1 Kontext [pro] ورودی‌های متنی و تصاویر مرجع را می‌پذیرد و امکان ویرایش‌های محلی هدفمند و تغییرات پیچیده در صحنه کلی را فراهم می‌کند.",
  "fal-ai/flux/krea.description": "Flux Krea [dev] یک مدل تولید تصویر با تمایل زیبایی‌شناسی به تصاویر طبیعی و واقع‌گرایانه‌تر است.",
  "fal-ai/flux/schnell.description": "FLUX.1 [schnell] یک مدل تولید تصویر با ۱۲ میلیارد پارامتر است که برای خروجی سریع و با کیفیت بالا طراحی شده است.",
  "fal-ai/hunyuan-image/v3.description": "یک مدل قدرتمند بومی چندوجهی برای تولید تصویر.",
  "fal-ai/imagen4/preview.description": "مدل تولید تصویر با کیفیت بالا از گوگل.",
  "fal-ai/nano-banana.description": "Nano Banana جدیدترین، سریع‌ترین و کارآمدترین مدل چندوجهی بومی گوگل است که امکان تولید و ویرایش تصویر از طریق مکالمه را فراهم می‌کند.",
  "fal-ai/qwen-image-edit.description": "مدل ویرایش تصویر حرفه‌ای از تیم Qwen که از ویرایش معنایی و ظاهری، ویرایش دقیق متن چینی/انگلیسی، انتقال سبک، چرخش و موارد دیگر پشتیبانی می‌کند.",
  "fal-ai/qwen-image.description": "مدل قدرتمند تولید تصویر از تیم Qwen با رندر قوی متن چینی و سبک‌های بصری متنوع.",
  "flux-1-schnell.description": "مدل تبدیل متن به تصویر با ۱۲ میلیارد پارامتر از Black Forest Labs که از تقطیر انتشار تقابلی نهفته برای تولید تصاویر با کیفیت بالا در ۱ تا ۴ مرحله استفاده می‌کند. این مدل با جایگزین‌های بسته رقابت می‌کند و تحت مجوز Apache-2.0 برای استفاده شخصی، تحقیقاتی و تجاری منتشر شده است.",
  "flux-dev.description": "FLUX.1 [dev] یک مدل تقطیر شده با وزن‌های باز برای استفاده غیرتجاری است. این مدل کیفیت تصویر نزدیک به حرفه‌ای و پیروی از دستورالعمل را حفظ می‌کند و در عین حال کارآمدتر اجرا می‌شود و منابع را بهتر از مدل‌های استاندارد هم‌سایز استفاده می‌کند.",
  "flux-kontext-max.description": "تولید و ویرایش تصویر متنی-زمینه‌ای پیشرفته که متن و تصویر را برای نتایج دقیق و منسجم ترکیب می‌کند.",
  "flux-kontext-pro.description": "تولید و ویرایش تصویر متنی-زمینه‌ای پیشرفته که متن و تصویر را برای نتایج دقیق و منسجم ترکیب می‌کند.",
  "flux-merged.description": "FLUX.1-merged ویژگی‌های عمیق بررسی‌شده در «DEV» را با مزایای سرعت بالای «Schnell» ترکیب می‌کند و مرزهای عملکرد را گسترش داده و کاربردها را افزایش می‌دهد.",
  "flux-pro-1.1-ultra.description": "تولید تصویر با وضوح فوق‌العاده بالا با خروجی ۴ مگاپیکسلی، تولید تصاویر شفاف در ۱۰ ثانیه.",
  "flux-pro-1.1.description": "مدل ارتقاءیافته تولید تصویر حرفه‌ای با کیفیت تصویر عالی و پیروی دقیق از دستورات.",
  "flux-pro.description": "مدل تولید تصویر تجاری سطح بالا با کیفیت تصویر بی‌نظیر و خروجی‌های متنوع.",
  "flux-schnell.description": "FLUX.1 [schnell] پیشرفته‌ترین مدل متن‌باز چندمرحله‌ای است که از رقبای مشابه و حتی مدل‌های تقطیرنشده قوی مانند Midjourney v6.0 و DALL-E 3 (HD) پیشی می‌گیرد. این مدل به‌خوبی برای حفظ تنوع پیش‌آموزش تنظیم شده و کیفیت بصری، پیروی از دستورالعمل، تنوع اندازه/نسبت، مدیریت فونت و تنوع خروجی را به‌طور قابل توجهی بهبود می‌بخشد.",
  "flux.1-schnell.description": "FLUX.1-schnell یک مدل تولید تصویر با عملکرد بالا برای خروجی‌های سریع و چندسبکی است.",
  "gemini-1.0-pro-001.description": "Gemini 1.0 Pro 001 (تنظیم‌شده) عملکردی پایدار و قابل تنظیم برای وظایف پیچیده ارائه می‌دهد.",
  "gemini-1.0-pro-002.description": "Gemini 1.0 Pro 002 (تنظیم‌شده) پشتیبانی قوی چندوجهی برای وظایف پیچیده فراهم می‌کند.",
  "gemini-1.0-pro-latest.description": "Gemini 1.0 Pro مدل هوش مصنوعی با عملکرد بالای گوگل است که برای مقیاس‌پذیری گسترده وظایف طراحی شده است.",
  "gemini-1.5-flash-001.description": "Gemini 1.5 Flash 001 یک مدل چندوجهی کارآمد برای مقیاس‌پذیری گسترده کاربردها است.",
  "gemini-1.5-flash-002.description": "Gemini 1.5 Flash 002 یک مدل چندوجهی کارآمد است که برای استقرار گسترده طراحی شده است.",
  "gemini-1.5-flash-8b-exp-0924.description": "Gemini 1.5 Flash 8B 0924 جدیدترین مدل آزمایشی با پیشرفت‌های قابل توجه در کاربردهای متنی و چندوجهی است.",
  "gemini-1.5-flash-8b-latest.description": "Gemini 1.5 Flash 8B یک مدل چندوجهی کارآمد است که برای استقرار گسترده طراحی شده است.",
  "gemini-1.5-flash-8b.description": "Gemini 1.5 Flash 8B یک مدل چندوجهی کارآمد برای مقیاس‌پذیری گسترده کاربردها است.",
  "gemini-1.5-flash-exp-0827.description": "Gemini 1.5 Flash 0827 پردازش چندوجهی بهینه‌شده برای وظایف پیچیده ارائه می‌دهد.",
  "gemini-1.5-flash-latest.description": "Gemini 1.5 Flash جدیدترین مدل چندوجهی هوش مصنوعی گوگل است که از ورودی‌های متنی، تصویری و ویدیویی پشتیبانی می‌کند و پردازش سریع را برای مقیاس‌پذیری مؤثر در وظایف مختلف فراهم می‌سازد.",
  "gemini-1.5-pro-001.description": "Gemini 1.5 Pro 001 یک راهکار چندوجهی مقیاس‌پذیر برای وظایف پیچیده است.",
  "gemini-1.5-pro-002.description": "Gemini 1.5 Pro 002 جدیدترین مدل آماده تولید با خروجی با کیفیت بالاتر، به‌ویژه برای ریاضی، زمینه‌های طولانی و وظایف بصری است.",
  "gemini-1.5-pro-exp-0801.description": "Gemini 1.5 Pro 0801 پردازش چندوجهی قوی با انعطاف‌پذیری بیشتر برای توسعه برنامه‌ها ارائه می‌دهد.",
  "gemini-1.5-pro-exp-0827.description": "Gemini 1.5 Pro 0827 آخرین بهینه‌سازی‌ها را برای پردازش چندوجهی کارآمدتر اعمال می‌کند.",
  "gemini-1.5-pro-latest.description": "Gemini 1.5 Pro از حداکثر ۲ میلیون توکن پشتیبانی می‌کند و یک مدل چندوجهی میان‌رده ایده‌آل برای وظایف پیچیده است.",
  "gemini-2.0-flash-001.description": "Gemini 2.0 Flash ویژگی‌های نسل بعدی از جمله سرعت استثنایی، استفاده بومی از ابزارها، تولید چندوجهی و پنجره زمینه ۱ میلیون توکن را ارائه می‌دهد.",
  "gemini-2.0-flash-exp-image-generation.description": "مدل آزمایشی Gemini 2.0 Flash با پشتیبانی از تولید تصویر.",
  "gemini-2.0-flash-lite-001.description": "یک نسخه بهینه‌شده Gemini 2.0 Flash برای بهره‌وری هزینه و تأخیر کم.",
  "gemini-2.0-flash-lite.description": "یک نسخه بهینه‌شده Gemini 2.0 Flash برای بهره‌وری هزینه و تأخیر کم.",
  "gemini-2.0-flash.description": "Gemini 2.0 Flash ویژگی‌های نسل بعدی از جمله سرعت استثنایی، استفاده بومی از ابزارها، تولید چندوجهی و پنجره زمینه ۱ میلیون توکن را ارائه می‌دهد.",
  "gemini-2.5-flash-image-preview.description": "Nano Banana جدیدترین، سریع‌ترین و کارآمدترین مدل چندوجهی بومی گوگل است که تولید و ویرایش تصویری مکالمه‌ای را ممکن می‌سازد.",
  "gemini-2.5-flash-image-preview:image.description": "Nano Banana جدیدترین، سریع‌ترین و کارآمدترین مدل چندوجهی بومی گوگل است که تولید و ویرایش تصویری مکالمه‌ای را ممکن می‌سازد.",
  "gemini-2.5-flash-image.description": "Nano Banana جدیدترین، سریع‌ترین و کارآمدترین مدل چندوجهی بومی گوگل است که تولید و ویرایش تصویری مکالمه‌ای را ممکن می‌سازد.",
  "gemini-2.5-flash-image:image.description": "Nano Banana جدیدترین، سریع‌ترین و کارآمدترین مدل چندوجهی بومی گوگل است که تولید و ویرایش تصویری مکالمه‌ای را ممکن می‌سازد.",
  "gemini-2.5-flash-lite-preview-06-17.description": "نسخه پیش‌نمایش Gemini 2.5 Flash-Lite کوچک‌ترین و مقرون‌به‌صرفه‌ترین مدل گوگل است که برای استفاده در مقیاس وسیع طراحی شده است.",
  "gemini-2.5-flash-lite-preview-09-2025.description": "نسخه پیش‌نمایش (۲۵ سپتامبر ۲۰۲۵) از Gemini 2.5 Flash-Lite",
  "gemini-2.5-flash-lite.description": "Gemini 2.5 Flash-Lite کوچک‌ترین و مقرون‌به‌صرفه‌ترین مدل گوگل است که برای استفاده در مقیاس وسیع طراحی شده است.",
  "gemini-2.5-flash-preview-04-17.description": "Gemini 2.5 Flash Preview مقرون‌به‌صرفه‌ترین مدل گوگل با قابلیت‌های کامل است.",
  "gemini-2.5-flash-preview-09-2025.description": "نسخه پیش‌نمایش (۲۵ سپتامبر ۲۰۲۵) از Gemini 2.5 Flash",
  "gemini-2.5-flash.description": "Gemini 2.5 Flash مقرون‌به‌صرفه‌ترین مدل گوگل با قابلیت‌های کامل است.",
  "gemini-2.5-pro-preview-03-25.description": "Gemini 2.5 Pro Preview پیشرفته‌ترین مدل استدلالی گوگل است که توانایی استدلال در کد، ریاضی و مسائل STEM را دارد و می‌تواند مجموعه‌داده‌های بزرگ، پایگاه‌های کد و اسناد را با زمینه طولانی تحلیل کند.",
  "gemini-2.5-pro-preview-05-06.description": "Gemini 2.5 Pro Preview پیشرفته‌ترین مدل استدلالی گوگل است که توانایی استدلال در کد، ریاضی و مسائل STEM را دارد و می‌تواند مجموعه‌داده‌های بزرگ، پایگاه‌های کد و اسناد را با زمینه طولانی تحلیل کند.",
  "gemini-2.5-pro-preview-06-05.description": "Gemini 2.5 Pro Preview پیشرفته‌ترین مدل استدلالی گوگل است که توانایی استدلال در کد، ریاضی و مسائل STEM را دارد و می‌تواند مجموعه‌داده‌های بزرگ، پایگاه‌های کد و اسناد را با زمینه طولانی تحلیل کند.",
  "gemini-2.5-pro.description": "Gemini 2.5 Pro پرچم‌دار مدل‌های استدلالی گوگل است که از زمینه‌های طولانی برای انجام وظایف پیچیده پشتیبانی می‌کند.",
  "gemini-3-flash-preview.description": "Gemini 3 Flash هوشمندترین مدل طراحی‌شده برای سرعت است که هوش پیشرفته را با قابلیت جست‌وجوی دقیق ترکیب می‌کند.",
  "gemini-3-pro-image-preview.description": "Gemini 3 Pro Image (Nano Banana Pro) مدل تولید تصویر گوگل است که از گفت‌وگوی چندوجهی نیز پشتیبانی می‌کند.",
  "gemini-3-pro-image-preview:image.description": "Gemini 3 Pro Image (Nano Banana Pro) مدل تولید تصویر گوگل است که از چت چندوجهی نیز پشتیبانی می‌کند.",
  "gemini-3-pro-preview.description": "Gemini 3 Pro قدرتمندترین مدل عامل و کدنویسی احساسی گوگل است که تعاملات بصری غنی‌تر و تعامل عمیق‌تری را بر پایه استدلال پیشرفته ارائه می‌دهد.",
  "gemini-flash-latest.description": "آخرین نسخه منتشرشده از Gemini Flash",
  "gemini-flash-lite-latest.description": "آخرین نسخه منتشرشده از Gemini Flash-Lite",
  "gemini-pro-latest.description": "آخرین نسخه منتشرشده از Gemini Pro",
  "gemma-7b-it.description": "Gemma 7B برای وظایف کوچک تا متوسط مقرون‌به‌صرفه است.",
  "gemma2-9b-it.description": "Gemma 2 9B برای وظایف خاص و یکپارچه‌سازی ابزارها بهینه‌سازی شده است.",
  "gemma2.description": "Gemma 2 مدل کارآمد گوگل است که از برنامه‌های کوچک تا پردازش داده‌های پیچیده را پوشش می‌دهد.",
  "gemma2:27b.description": "Gemma 2 مدل کارآمد گوگل است که از برنامه‌های کوچک تا پردازش داده‌های پیچیده را پوشش می‌دهد.",
  "gemma2:2b.description": "Gemma 2 مدل کارآمد گوگل است که از برنامه‌های کوچک تا پردازش داده‌های پیچیده را پوشش می‌دهد.",
  "generalv3.5.description": "Spark Max کامل‌ترین نسخه است که از جستجوی وب و افزونه‌های داخلی متعددی پشتیبانی می‌کند. قابلیت‌های اصلی آن بهینه‌سازی شده‌اند و نقش‌های سیستمی و فراخوانی توابع عملکردی عالی در سناریوهای پیچیده ارائه می‌دهند.",
  "generalv3.description": "Spark Pro یک مدل LLM با عملکرد بالا است که برای حوزه‌های حرفه‌ای بهینه‌سازی شده و بر ریاضی، برنامه‌نویسی، سلامت و آموزش تمرکز دارد. این مدل از جستجوی وب و افزونه‌های داخلی مانند آب‌وهوا و تاریخ پشتیبانی می‌کند و در پرسش‌وپاسخ دانش پیچیده، درک زبان و تولید متن پیشرفته عملکرد قوی و کارآمدی دارد و گزینه‌ای ایده‌آل برای کاربردهای حرفه‌ای است.",
  "glm-4-0520.description": "GLM-4-0520 جدیدترین نسخه مدل است که برای وظایف بسیار پیچیده و متنوع با عملکرد عالی طراحی شده است.",
  "glm-4-7.description": "GLM-4.7 جدیدترین مدل پرچم‌دار Zhipu AI است. این مدل توانایی‌های برنامه‌نویسی، برنامه‌ریزی بلندمدت وظایف و همکاری با ابزارها را برای سناریوهای Agentic Coding بهبود می‌بخشد و در چندین معیار عمومی عملکردی پیشرو در میان مدل‌های متن‌باز دارد. پاسخ‌ها طبیعی‌تر و نوشتار غنی‌تر شده‌اند. در وظایف پیچیده عامل، پیروی از دستورالعمل‌ها در هنگام استفاده از ابزارها قوی‌تر است و زیبایی‌شناسی رابط و کارایی انجام وظایف بلندمدت نیز بهبود یافته است.",
  "glm-4-9b-chat.description": "GLM-4-9B-Chat در حوزه‌های معناشناسی، ریاضی، استدلال، کدنویسی و دانش عملکرد قوی دارد. همچنین از مرور وب، اجرای کد، فراخوانی ابزارهای سفارشی و استدلال متن‌های طولانی پشتیبانی می‌کند و از ۲۶ زبان از جمله ژاپنی، کره‌ای و آلمانی پشتیبانی می‌کند.",
  "glm-4-air-250414.description": "GLM-4-Air گزینه‌ای با ارزش بالا است که عملکردی نزدیک به GLM-4 دارد، سرعت بالایی دارد و هزینه کمتری دارد.",
  "glm-4-air.description": "GLM-4-Air گزینه‌ای با ارزش بالا است که عملکردی نزدیک به GLM-4 دارد، سرعت بالایی دارد و هزینه کمتری دارد.",
  "glm-4-airx.description": "GLM-4-AirX نسخه‌ای کارآمدتر از GLM-4-Air است که تا ۲.۶ برابر استدلال سریع‌تری دارد.",
  "glm-4-alltools.description": "GLM-4-AllTools یک مدل عامل چندمنظوره است که برای برنامه‌ریزی دستورالعمل‌های پیچیده و استفاده از ابزارهایی مانند مرور وب، توضیح کد و تولید متن بهینه‌سازی شده و برای اجرای چندوظیفه‌ای مناسب است.",
  "glm-4-flash-250414.description": "GLM-4-Flash برای وظایف ساده ایده‌آل است: سریع‌ترین و رایگان.",
  "glm-4-flash.description": "GLM-4-Flash برای وظایف ساده ایده‌آل است: سریع‌ترین و رایگان.",
  "glm-4-flashx.description": "GLM-4-FlashX نسخه پیشرفته Flash با استدلال فوق‌العاده سریع است.",
  "glm-4-long.description": "GLM-4-Long از ورودی‌های بسیار طولانی برای وظایف حافظه‌محور و پردازش اسناد در مقیاس بزرگ پشتیبانی می‌کند.",
  "glm-4-plus.description": "GLM-4-Plus پرچم‌دار با هوش بالا است که در مدیریت متن‌های طولانی و وظایف پیچیده قوی عمل می‌کند و عملکرد کلی ارتقاء یافته‌ای دارد.",
  "glm-4.1v-thinking-flash.description": "GLM-4.1V-Thinking قوی‌ترین مدل VLM شناخته‌شده با حدود ۱۰ میلیارد پارامتر است که وظایف پیشرفته‌ای مانند درک ویدیو، پرسش‌وپاسخ تصویری، حل مسائل موضوعی، OCR، خواندن اسناد و نمودارها، عامل‌های رابط کاربری، کدنویسی فرانت‌اند و اتصال به واقعیت را پوشش می‌دهد. این مدل حتی از Qwen2.5-VL-72B که ۸ برابر بزرگ‌تر است در بسیاری از وظایف پیشی می‌گیرد. با استفاده از یادگیری تقویتی پیشرفته، از استدلال زنجیره‌ای برای بهبود دقت و غنای پاسخ‌ها بهره می‌برد و در نتایج و قابلیت توضیح‌پذیری از مدل‌های سنتی بدون تفکر بهتر عمل می‌کند.",
  "glm-4.1v-thinking-flashx.description": "GLM-4.1V-Thinking قوی‌ترین مدل VLM شناخته‌شده با حدود ۱۰ میلیارد پارامتر است که وظایف پیشرفته‌ای مانند درک ویدیو، پرسش‌وپاسخ تصویری، حل مسائل موضوعی، OCR، خواندن اسناد و نمودارها، عامل‌های رابط کاربری، کدنویسی فرانت‌اند و اتصال به واقعیت را پوشش می‌دهد. این مدل حتی از Qwen2.5-VL-72B که ۸ برابر بزرگ‌تر است در بسیاری از وظایف پیشی می‌گیرد. با استفاده از یادگیری تقویتی پیشرفته، از استدلال زنجیره‌ای برای بهبود دقت و غنای پاسخ‌ها بهره می‌برد و در نتایج و قابلیت توضیح‌پذیری از مدل‌های سنتی بدون تفکر بهتر عمل می‌کند.",
  "glm-4.5-air.description": "نسخه سبک GLM-4.5 که بین عملکرد و هزینه تعادل برقرار می‌کند و از حالت‌های تفکر ترکیبی انعطاف‌پذیر پشتیبانی می‌کند.",
  "glm-4.5-airx.description": "نسخه سریع GLM-4.5-Air با پاسخ‌دهی سریع‌تر برای استفاده در مقیاس بالا و سرعت بالا.",
  "glm-4.5-x.description": "نسخه سریع GLM-4.5 با عملکرد قوی و سرعت تولید تا ۱۰۰ توکن در ثانیه.",
  "glm-4.5.description": "مدل پرچم‌دار Zhipu با حالت تفکر قابل تغییر، ارائه‌دهنده بهترین عملکرد متن‌باز و پشتیبانی از زمینه تا ۱۲۸ هزار توکن.",
  "glm-4.5v.description": "مدل نسل بعدی بینایی و استدلال Zhipu با معماری MoE، دارای ۱۰۶ میلیارد پارامتر کل و ۱۲ میلیارد فعال، که در میان مدل‌های چندوجهی متن‌باز هم‌رده خود درک تصویر، ویدیو، اسناد و رابط‌های گرافیکی را به سطح SOTA می‌رساند.",
  "glm-4.6.description": "مدل پرچم‌دار جدید Zhipu با نام GLM-4.6 (۳۵۵ میلیارد پارامتر) در زمینه‌های برنامه‌نویسی پیشرفته، پردازش متون بلند، استدلال و توانایی‌های عامل از نسخه‌های قبلی خود فراتر رفته است. این مدل به‌ویژه در توانایی برنامه‌نویسی با Claude Sonnet 4 هم‌تراز است و به عنوان برترین مدل برنامه‌نویسی در چین شناخته می‌شود.",
  "glm-4.7-flash.description": "GLM-4.7-Flash به‌عنوان یک مدل سطح ۳۰ میلیاردی SOTA، گزینه‌ای جدید برای تعادل بین عملکرد و کارایی ارائه می‌دهد. این مدل توانایی‌های برنامه‌نویسی، برنامه‌ریزی بلندمدت وظایف و همکاری با ابزارها را برای سناریوهای Agentic Coding بهبود می‌بخشد و در معیارهای فعلی در میان مدل‌های متن‌باز هم‌رده عملکردی پیشرو دارد.",
  "glm-4.7-flashx.description": "GLM-4.7-Flash به‌عنوان یک مدل سطح ۳۰ میلیاردی SOTA، گزینه‌ای جدید برای تعادل بین عملکرد و کارایی ارائه می‌دهد. این مدل توانایی‌های برنامه‌نویسی، برنامه‌ریزی بلندمدت وظایف و همکاری با ابزارها را برای سناریوهای Agentic Coding بهبود می‌بخشد و در معیارهای فعلی در میان مدل‌های متن‌باز هم‌رده عملکردی پیشرو دارد.",
  "glm-4.7.description": "GLM-4.7 جدیدترین مدل پرچم‌دار Zhipu است که برای سناریوهای برنامه‌نویسی عامل‌محور بهینه‌سازی شده و دارای توانایی‌های برنامه‌نویسی پیشرفته‌تر، برنامه‌ریزی وظایف بلندمدت و همکاری با ابزارها است. این مدل در چندین معیار عمومی عملکردی پیشرو در میان مدل‌های متن‌باز دارد. توانایی‌های عمومی آن با پاسخ‌های طبیعی‌تر و مختصرتر و نوشتاری جذاب‌تر بهبود یافته است. در وظایف پیچیده عامل‌محور، پیروی از دستورالعمل‌ها هنگام استفاده از ابزارها قوی‌تر شده و زیبایی ظاهری رابط کاربری و کارایی انجام وظایف بلندمدت در Artifacts و برنامه‌نویسی عامل‌محور ارتقا یافته است.",
  "glm-4.description": "GLM-4 پرچم‌دار قدیمی است که در ژانویه ۲۰۲۴ منتشر شد و اکنون با GLM-4-0520 قوی‌تر جایگزین شده است.",
  "glm-4v-flash.description": "GLM-4V-Flash بر درک کارآمد تصویر تکی تمرکز دارد و برای سناریوهای تحلیلی سریع مانند پردازش تصویر بلادرنگ یا دسته‌ای مناسب است.",
  "glm-4v-plus-0111.description": "GLM-4V-Plus توانایی درک ویدیو و چند تصویر را دارد و برای وظایف چندوجهی مناسب است.",
  "glm-4v-plus.description": "GLM-4V-Plus توانایی درک ویدیو و چند تصویر را دارد و برای وظایف چندوجهی مناسب است.",
  "glm-4v.description": "GLM-4V درک تصویر و استدلال قوی در وظایف بصری را ارائه می‌دهد.",
  "glm-z1-air.description": "مدل استدلال با توانایی قوی در استنتاج عمیق برای وظایف پیچیده.",
  "glm-z1-airx.description": "استدلال فوق‌سریع با کیفیت بالای استدلال.",
  "glm-z1-flash.description": "سری GLM-Z1 استدلال پیچیده قوی را ارائه می‌دهد و در منطق، ریاضی و برنامه‌نویسی برتری دارد.",
  "glm-z1-flashx.description": "سریع و کم‌هزینه: نسخه Flash با استدلال فوق‌سریع و هم‌زمانی بیشتر.",
  "glm-zero-preview.description": "GLM-Zero-Preview استدلال پیچیده قوی را ارائه می‌دهد و در منطق، ریاضی و برنامه‌نویسی برتری دارد.",
  "global.anthropic.claude-opus-4-5-20251101-v1:0.description": "Claude Opus 4.5 مدل پرچم‌دار Anthropic است که هوش استثنایی و عملکرد مقیاس‌پذیر را برای وظایف پیچیده با نیاز به پاسخ‌های باکیفیت و استدلال قوی ترکیب می‌کند.",
  "google/gemini-2.0-flash-001.description": "Gemini 2.0 Flash قابلیت‌های نسل بعدی را ارائه می‌دهد، از جمله سرعت عالی، استفاده بومی از ابزارها، تولید چندوجهی و پنجره زمینه‌ای ۱ میلیون توکن.",
  "google/gemini-2.0-flash-lite-001.description": "Gemini 2.0 Flash Lite نسخه سبک Gemini است که به‌طور پیش‌فرض تفکر را غیرفعال کرده تا تأخیر و هزینه را کاهش دهد، اما می‌توان آن را از طریق پارامترها فعال کرد.",
  "google/gemini-2.0-flash-lite.description": "Gemini 2.0 Flash Lite ویژگی‌های نسل بعدی را ارائه می‌دهد، از جمله سرعت بالا، استفاده داخلی از ابزارها، تولید چندوجهی و پنجره زمینه‌ای ۱ میلیون توکن.",
  "google/gemini-2.0-flash.description": "Gemini 2.0 Flash مدل استدلال با عملکرد بالای گوگل برای وظایف چندوجهی گسترده است.",
  "google/gemini-2.5-flash-image-free.description": "نسخه رایگان Gemini 2.5 Flash Image با سهمیه محدود برای تولید چندوجهی.",
  "google/gemini-2.5-flash-image-preview.description": "مدل آزمایشی Gemini 2.5 Flash با پشتیبانی از تولید تصویر.",
  "google/gemini-2.5-flash-image.description": "Gemini 2.5 Flash Image (Nano Banana) مدل تولید تصویر گوگل با پشتیبانی از گفت‌وگوی چندوجهی است.",
  "google/gemini-2.5-flash-lite.description": "Gemini 2.5 Flash Lite نسخه سبک Gemini 2.5 است که برای تأخیر کم و هزینه پایین بهینه شده و برای سناریوهای با حجم بالا مناسب است.",
  "google/gemini-2.5-flash-preview.description": "Gemini 2.5 Flash پیشرفته‌ترین مدل پرچم‌دار گوگل است که برای استدلال پیشرفته، برنامه‌نویسی، ریاضی و علوم طراحی شده است. این مدل دارای قابلیت تفکر داخلی است تا پاسخ‌هایی با دقت بالاتر و پردازش زمینه‌ای دقیق‌تر ارائه دهد.",
  "google/gemini-2.5-flash-preview:thinking.description": "Gemini 2.5 Flash پیشرفته‌ترین مدل پرچم‌دار گوگل است که برای وظایف استدلالی، برنامه‌نویسی، ریاضی و علمی طراحی شده است. این مدل دارای قابلیت «تفکر» داخلی است که پاسخ‌هایی با دقت بالاتر و پردازش زمینه‌ای دقیق‌تر ارائه می‌دهد.\n\nتوجه: این مدل دو نسخه دارد — با تفکر و بدون تفکر. قیمت‌گذاری خروجی به‌طور قابل توجهی بسته به فعال بودن تفکر متفاوت است. اگر نسخه استاندارد (بدون پسوند “:thinking”) را انتخاب کنید، مدل به‌طور صریح از تولید توکن‌های تفکر خودداری می‌کند.\n\nبرای استفاده از تفکر و دریافت توکن‌های تفکر، باید نسخه “:thinking” را انتخاب کنید که هزینه بیشتری دارد.\n\nGemini 2.5 Flash همچنین می‌تواند از طریق پارامتر “max reasoning tokens” پیکربندی شود (https://openrouter.ai/docs/use-cases/reasoning-tokens#max-tokens-for-reasoning).",
  "google/gemini-2.5-flash.description": "Gemini 2.5 Flash (Lite/Pro/Flash) خانواده‌ای از مدل‌های گوگل است که از تأخیر کم تا استدلال با عملکرد بالا را پوشش می‌دهد.",
  "google/gemini-2.5-pro-free.description": "نسخه رایگان Gemini 2.5 Pro با سهمیه محدود، پشتیبانی از ورودی چندحالته و زمینه طولانی، مناسب برای آزمایش و جریان‌های کاری سبک.",
  "google/gemini-2.5-pro-preview.description": "Gemini 2.5 Pro Preview پیشرفته‌ترین مدل تفکر گوگل برای استدلال در مسائل پیچیده کد، ریاضی و علوم است و برای تحلیل مجموعه داده‌های بزرگ، پایگاه‌های کد و اسناد با زمینه طولانی مناسب است.",
  "google/gemini-2.5-pro.description": "Gemini 2.5 Pro مدل پرچم‌دار استدلالی گوگل با پشتیبانی از زمینه طولانی برای وظایف پیچیده است.",
  "google/gemini-3-pro-image-preview-free.description": "نسخه رایگان Gemini 3 Pro Image با سهمیه محدود برای تولید چندحالته.",
  "google/gemini-3-pro-image-preview.description": "Gemini 3 Pro Image (Nano Banana Pro) مدل تولید تصویر گوگل با پشتیبانی از مکالمه چندحالته است.",
  "google/gemini-3-pro-preview-free.description": "نسخه رایگان Gemini 3 Pro Preview همان درک و استدلال چندحالته نسخه استاندارد را ارائه می‌دهد، اما با محدودیت سهمیه و نرخ، مناسب برای آزمایش و استفاده کم‌تکرار است.",
  "google/gemini-3-pro-preview.description": "Gemini 3 Pro نسل بعدی مدل استدلال چندحالته در خانواده Gemini است که متن، صدا، تصویر و ویدیو را درک می‌کند و وظایف پیچیده و پایگاه‌های کد بزرگ را مدیریت می‌کند.",
  "google/gemini-embedding-001.description": "مدل جاسازی پیشرفته با عملکرد قوی در وظایف انگلیسی، چندزبانه و کدنویسی.",
  "google/gemini-flash-1.5.description": "Gemini 1.5 Flash پردازش چندحالته بهینه‌شده برای طیف وسیعی از وظایف پیچیده را ارائه می‌دهد.",
  "google/gemini-pro-1.5.description": "Gemini 1.5 Pro آخرین بهینه‌سازی‌ها را برای پردازش کارآمدتر داده‌های چندحالته ترکیب می‌کند.",
  "google/gemma-2-27b-it.description": "Gemma 2 27B یک مدل زبان عمومی با عملکرد قوی در سناریوهای مختلف است.",
  "google/gemma-2-27b.description": "Gemma 2 خانواده مدل‌های کارآمد گوگل برای استفاده از برنامه‌های کوچک تا پردازش داده‌های پیچیده است.",
  "google/gemma-2-2b-it.description": "مدل زبان کوچک پیشرفته طراحی‌شده برای برنامه‌های لبه‌ای.",
  "google/gemma-2-9b-it.description": "Gemma 2 9B، توسعه‌یافته توسط گوگل، پیروی مؤثر از دستورالعمل‌ها و توانایی کلی قوی را ارائه می‌دهد.",
  "google/gemma-2-9b-it:free.description": "Gemma 2 خانواده مدل‌های متن سبک و متن‌باز گوگل است.",
  "google/gemma-2-9b.description": "Gemma 2 خانواده مدل‌های کارآمد گوگل برای استفاده از برنامه‌های کوچک تا پردازش داده‌های پیچیده است.",
  "google/gemma-2b-it.description": "Gemma Instruct (2B) مدیریت پایه‌ای دستورالعمل‌ها را برای برنامه‌های سبک ارائه می‌دهد.",
  "google/gemma-3-12b-it.description": "Gemma 3 12B یک مدل زبان متن‌باز گوگل است که استاندارد جدیدی برای کارایی و عملکرد تعیین می‌کند.",
  "google/gemma-3-27b-it.description": "Gemma 3 27B یک مدل زبان متن‌باز گوگل است که استاندارد جدیدی برای کارایی و عملکرد تعیین می‌کند.",
  "google/text-embedding-005.description": "مدل جاسازی متن متمرکز بر زبان انگلیسی که برای وظایف کد و زبان انگلیسی بهینه شده است.",
  "google/text-multilingual-embedding-002.description": "مدل جاسازی متن چندزبانه بهینه‌شده برای وظایف میان‌زبانی در زبان‌های مختلف.",
  "gpt-3.5-turbo-0125.description": "GPT 3.5 Turbo برای تولید و درک متن؛ در حال حاضر به gpt-3.5-turbo-0125 اشاره دارد.",
  "gpt-3.5-turbo-1106.description": "GPT 3.5 Turbo برای تولید و درک متن؛ در حال حاضر به gpt-3.5-turbo-0125 اشاره دارد.",
  "gpt-3.5-turbo-instruct.description": "GPT 3.5 Turbo برای وظایف تولید و درک متن، بهینه‌شده برای پیروی از دستورالعمل‌ها.",
  "gpt-3.5-turbo.description": "GPT 3.5 Turbo برای تولید و درک متن؛ در حال حاضر به gpt-3.5-turbo-0125 اشاره دارد.",
  "gpt-35-turbo-16k.description": "GPT-3.5 Turbo 16k یک مدل تولید متن با ظرفیت بالا برای وظایف پیچیده است.",
  "gpt-35-turbo.description": "GPT-3.5 Turbo مدل کارآمد OpenAI برای چت و تولید متن است که از فراخوانی توابع به‌صورت موازی پشتیبانی می‌کند.",
  "gpt-4-0125-preview.description": "جدیدترین GPT-4 Turbo با قابلیت بینایی همراه است. درخواست‌های تصویری از حالت JSON و فراخوانی توابع پشتیبانی می‌کنند. این مدل چندوجهی مقرون‌به‌صرفه، تعادلی میان دقت و کارایی برای کاربردهای بلادرنگ ارائه می‌دهد.",
  "gpt-4-0613.description": "GPT-4 پنجره متنی بزرگ‌تری برای مدیریت ورودی‌های طولانی فراهم می‌کند و برای ترکیب گسترده اطلاعات و تحلیل داده‌ها مناسب است.",
  "gpt-4-1106-preview.description": "جدیدترین GPT-4 Turbo با قابلیت بینایی همراه است. درخواست‌های تصویری از حالت JSON و فراخوانی توابع پشتیبانی می‌کنند. این مدل چندوجهی مقرون‌به‌صرفه، تعادلی میان دقت و کارایی برای کاربردهای بلادرنگ ارائه می‌دهد.",
  "gpt-4-32k-0613.description": "GPT-4 پنجره متنی بزرگ‌تری برای مدیریت ورودی‌های طولانی فراهم می‌کند و برای سناریوهایی که نیاز به ادغام گسترده اطلاعات و تحلیل داده دارند مناسب است.",
  "gpt-4-32k.description": "GPT-4 پنجره متنی بزرگ‌تری برای مدیریت ورودی‌های طولانی فراهم می‌کند و برای سناریوهایی که نیاز به ادغام گسترده اطلاعات و تحلیل داده دارند مناسب است.",
  "gpt-4-turbo-2024-04-09.description": "جدیدترین GPT-4 Turbo با قابلیت بینایی همراه است. درخواست‌های تصویری از حالت JSON و فراخوانی توابع پشتیبانی می‌کنند. این مدل چندوجهی مقرون‌به‌صرفه، تعادلی میان دقت و کارایی برای کاربردهای بلادرنگ ارائه می‌دهد.",
  "gpt-4-turbo-preview.description": "جدیدترین GPT-4 Turbo با قابلیت بینایی همراه است. درخواست‌های تصویری از حالت JSON و فراخوانی توابع پشتیبانی می‌کنند. این مدل چندوجهی مقرون‌به‌صرفه، تعادلی میان دقت و کارایی برای کاربردهای بلادرنگ ارائه می‌دهد.",
  "gpt-4-turbo.description": "جدیدترین GPT-4 Turbo با قابلیت بینایی همراه است. درخواست‌های تصویری از حالت JSON و فراخوانی توابع پشتیبانی می‌کنند. این مدل چندوجهی مقرون‌به‌صرفه، تعادلی میان دقت و کارایی برای کاربردهای بلادرنگ ارائه می‌دهد.",
  "gpt-4-vision-preview.description": "پیش‌نمایش GPT-4 Vision، طراحی‌شده برای وظایف تحلیل و پردازش تصویر.",
  "gpt-4.1-mini.description": "GPT-4.1 mini تعادلی میان هوش، سرعت و هزینه برقرار می‌کند و برای بسیاری از کاربردها جذاب است.",
  "gpt-4.1-nano.description": "GPT-4.1 nano سریع‌ترین و مقرون‌به‌صرفه‌ترین مدل GPT-4.1 است.",
  "gpt-4.1.description": "GPT-4.1 مدل پرچم‌دار ما برای وظایف پیچیده و حل مسائل میان‌دامنه‌ای است.",
  "gpt-4.5-preview.description": "GPT-4.5-preview جدیدترین مدل عمومی با دانش عمیق از جهان و درک بهتر از نیت کاربر است که در وظایف خلاقانه و برنامه‌ریزی عامل‌ها بسیار قوی عمل می‌کند. تاریخ قطع دانش آن اکتبر ۲۰۲۳ است.",
  "gpt-4.description": "GPT-4 پنجره متنی بزرگ‌تری برای مدیریت ورودی‌های طولانی فراهم می‌کند و برای ترکیب گسترده اطلاعات و تحلیل داده‌ها مناسب است.",
  "gpt-4o-2024-05-13.description": "ChatGPT-4o مدلی پویا است که به‌صورت بلادرنگ به‌روزرسانی می‌شود و درک و تولید قوی را برای کاربردهای وسیع مانند پشتیبانی مشتری، آموزش و پشتیبانی فنی ترکیب می‌کند.",
  "gpt-4o-2024-08-06.description": "ChatGPT-4o مدلی پویا است که به‌صورت بلادرنگ به‌روزرسانی می‌شود و درک و تولید قوی را برای کاربردهای وسیع مانند پشتیبانی مشتری، آموزش و پشتیبانی فنی ترکیب می‌کند.",
  "gpt-4o-2024-11-20.description": "ChatGPT-4o مدلی پویا است که به‌صورت بلادرنگ به‌روزرسانی می‌شود و درک و تولید قوی را برای کاربردهای وسیع مانند پشتیبانی مشتری، آموزش و پشتیبانی فنی ترکیب می‌کند.",
  "gpt-4o-audio-preview.description": "مدل پیش‌نمایش صوتی GPT-4o با ورودی و خروجی صوتی.",
  "gpt-4o-mini-audio-preview.description": "مدل صوتی کوچک GPT-4o با ورودی و خروجی صوتی.",
  "gpt-4o-mini-realtime-preview.description": "نسخه بلادرنگ GPT-4o-mini با ورودی/خروجی بلادرنگ صوتی و متنی.",
  "gpt-4o-mini-search-preview.description": "پیش‌نمایش جست‌وجوی GPT-4o mini برای درک و اجرای پرس‌وجوهای جست‌وجوی وب از طریق API تکمیل چت. جست‌وجوی وب به ازای هر فراخوانی ابزار، علاوه بر هزینه توکن، محاسبه می‌شود.",
  "gpt-4o-mini-transcribe.description": "GPT-4o Mini Transcribe مدلی برای تبدیل گفتار به متن است که با استفاده از GPT-4o دقت شناسایی کلمات، تشخیص زبان و صحت را نسبت به مدل Whisper اصلی بهبود می‌بخشد.",
  "gpt-4o-mini-tts.description": "GPT-4o mini TTS مدلی برای تبدیل متن به گفتار است که بر پایه GPT-4o mini ساخته شده و متن را به گفتاری طبیعی تبدیل می‌کند (حداکثر ورودی ۲۰۰۰ توکن).",
  "gpt-4o-mini.description": "GPT-4o mini جدیدترین مدل OpenAI پس از GPT-4 Omni است که از ورودی متن+تصویر و خروجی متنی پشتیبانی می‌کند. این مدل پیشرفته‌ترین مدل کوچک آن‌هاست، بسیار ارزان‌تر از مدل‌های پیشرفته اخیر و بیش از ۶۰٪ ارزان‌تر از GPT-3.5 Turbo، در حالی که هوش سطح بالا (۸۲٪ MMLU) را حفظ می‌کند.",
  "gpt-4o-realtime-preview-2024-10-01.description": "نسخه بلادرنگ GPT-4o با ورودی/خروجی بلادرنگ صوتی و متنی.",
  "gpt-4o-realtime-preview-2025-06-03.description": "نسخه بلادرنگ GPT-4o با ورودی/خروجی بلادرنگ صوتی و متنی.",
  "gpt-4o-realtime-preview.description": "نسخه بلادرنگ GPT-4o با ورودی/خروجی بلادرنگ صوتی و متنی.",
  "gpt-4o-search-preview.description": "پیش‌نمایش جست‌وجوی GPT-4o برای درک و اجرای پرس‌وجوهای جست‌وجوی وب از طریق API تکمیل چت. جست‌وجوی وب به ازای هر فراخوانی ابزار، علاوه بر هزینه توکن، محاسبه می‌شود.",
  "gpt-4o-transcribe.description": "GPT-4o Transcribe مدلی برای تبدیل گفتار به متن است که با استفاده از GPT-4o دقت شناسایی کلمات، تشخیص زبان و صحت را نسبت به مدل Whisper اصلی بهبود می‌بخشد.",
  "gpt-4o.description": "ChatGPT-4o مدلی پویا و به‌روزرسانی‌شونده در زمان واقعی است که درک و تولید قوی را برای کاربردهای وسیع مانند پشتیبانی مشتری، آموزش و پشتیبانی فنی ترکیب می‌کند.",
  "gpt-5-chat-latest.description": "مدل GPT-5 مورد استفاده در ChatGPT که درک و تولید قوی را برای کاربردهای مکالمه‌ای ترکیب می‌کند.",
  "gpt-5-chat.description": "GPT-5 Chat یک مدل پیش‌نمایش بهینه‌شده برای سناریوهای مکالمه‌ای است. از ورودی متن و تصویر پشتیبانی می‌کند، فقط خروجی متنی دارد و برای چت‌بات‌ها و برنامه‌های هوش مصنوعی مکالمه‌ای مناسب است.",
  "gpt-5-codex.description": "GPT-5 Codex نسخه‌ای از GPT-5 است که برای وظایف برنامه‌نویسی عامل‌محور در محیط‌های مشابه Codex بهینه‌سازی شده است.",
  "gpt-5-mini.description": "نسخه‌ای سریع‌تر و مقرون‌به‌صرفه‌تر از GPT-5 برای وظایف مشخص، با پاسخ‌های سریع‌تر در عین حفظ کیفیت.",
  "gpt-5-nano.description": "سریع‌ترین و مقرون‌به‌صرفه‌ترین نسخه GPT-5، مناسب برای برنامه‌هایی با حساسیت بالا به تأخیر و هزینه.",
  "gpt-5-pro.description": "GPT-5 pro از منابع محاسباتی بیشتر برای تفکر عمیق‌تر استفاده می‌کند و به‌طور مداوم پاسخ‌های بهتری ارائه می‌دهد.",
  "gpt-5.1-chat-latest.description": "GPT-5.1 Chat: نسخه ChatGPT از GPT-5.1، ساخته‌شده برای سناریوهای چت.",
  "gpt-5.1-codex-mini.description": "GPT-5.1 Codex mini: نسخه کوچک‌تر و کم‌هزینه‌تر Codex بهینه‌شده برای وظایف برنامه‌نویسی عامل‌محور.",
  "gpt-5.1-codex.description": "GPT-5.1 Codex: نسخه‌ای از GPT-5.1 بهینه‌شده برای وظایف برنامه‌نویسی عامل‌محور، مناسب برای گردش‌کارهای پیچیده کد/عامل در API پاسخ‌ها.",
  "gpt-5.1.description": "GPT-5.1 — یک مدل پرچم‌دار بهینه‌شده برای برنامه‌نویسی و وظایف عامل با تلاش استدلال قابل تنظیم و زمینه طولانی‌تر.",
  "gpt-5.2-chat-latest.description": "GPT-5.2 Chat نسخه ChatGPT برای تجربه آخرین بهبودهای مکالمه‌ای است.",
  "gpt-5.2-pro.description": "GPT-5.2 Pro: نسخه‌ای هوشمندتر و دقیق‌تر از GPT-5.2 (فقط از طریق API پاسخ‌ها)، مناسب برای مسائل دشوار و استدلال چندمرحله‌ای طولانی.",
  "gpt-5.2.description": "GPT-5.2 یک مدل پرچم‌دار برای گردش‌کارهای برنامه‌نویسی و عامل‌محور با استدلال قوی‌تر و عملکرد بهتر در زمینه‌های طولانی است.",
  "gpt-5.description": "بهترین مدل برای برنامه‌نویسی میان‌رشته‌ای و وظایف عامل. GPT-5 جهشی در دقت، سرعت، استدلال، آگاهی زمینه‌ای، تفکر ساختاریافته و حل مسئله دارد.",
  "gpt-audio.description": "GPT Audio یک مدل چت عمومی برای ورودی/خروجی صوتی است که در API تکمیل چت پشتیبانی می‌شود.",
  "gpt-image-1-mini.description": "نسخه کم‌هزینه‌تر GPT Image 1 با ورودی بومی متن و تصویر و خروجی تصویری.",
  "gpt-image-1.5.description": "مدل بهبودیافته GPT Image 1 با تولید ۴ برابر سریع‌تر، ویرایش دقیق‌تر و رندر بهتر متن.",
  "gpt-image-1.description": "مدل تولید تصویر چندوجهی بومی ChatGPT.",
  "gpt-oss-120b.description": "دسترسی نیاز به درخواست دارد. GPT-OSS-120B یک مدل زبان بزرگ متن‌باز از OpenAI با توانایی قوی در تولید متن است.",
  "gpt-oss-20b.description": "دسترسی نیاز به درخواست دارد. GPT-OSS-20B یک مدل زبان میان‌رده متن‌باز از OpenAI با تولید متن کارآمد است.",
  "gpt-oss:120b.description": "GPT-OSS 120B مدل LLM بزرگ متن‌باز OpenAI با کوانتیزاسیون MXFP4 است که به عنوان مدل پرچم‌دار معرفی شده. نیازمند محیط چند GPU یا ایستگاه کاری پیشرفته است و در استدلال پیچیده، تولید کد و پردازش چندزبانه عملکرد عالی دارد، با قابلیت فراخوانی توابع پیشرفته و ادغام ابزارها.",
  "gpt-oss:20b.description": "GPT-OSS 20B یک LLM متن‌باز از OpenAI با کوانتیزاسیون MXFP4 است که برای GPUهای مصرفی پیشرفته یا مک‌های Apple Silicon مناسب است. در تولید گفت‌وگو، برنامه‌نویسی و وظایف استدلالی عملکرد خوبی دارد و از فراخوانی توابع و استفاده از ابزارها پشتیبانی می‌کند.",
  "gpt-realtime.description": "مدل بلادرنگ عمومی با پشتیبانی از ورودی/خروجی بلادرنگ متن و صوت، به‌علاوه ورودی تصویری.",
  "grok-2-image-1212.description": "جدیدترین مدل تولید تصویر ما، تصاویر زنده و واقع‌گرایانه‌ای را از دستورات تولید می‌کند و در کاربردهای بازاریابی، شبکه‌های اجتماعی و سرگرمی عملکرد درخشانی دارد.",
  "grok-2-vision-1212.description": "دقت بهبود یافته، پیروی بهتر از دستورالعمل‌ها و پشتیبانی چندزبانه.",
  "grok-3-mini.description": "مدلی سبک‌وزن که پیش از پاسخ‌دهی فکر می‌کند. برای وظایف منطقی که نیاز به دانش تخصصی عمیق ندارند، سریع و هوشمند است و به ردپای استدلال خام دسترسی دارد.",
  "grok-3.description": "مدل پرچم‌دار که در کاربردهای سازمانی مانند استخراج داده، برنامه‌نویسی و خلاصه‌سازی برتری دارد و دارای دانش عمیق در حوزه‌های مالی، سلامت، حقوق و علوم است.",
  "grok-4-0709.description": "Grok 4 از xAI با توانایی استدلال قوی.",
  "grok-4-1-fast-non-reasoning.description": "مدل چندوجهی پیشرفته‌ای که برای استفاده از ابزارهای عامل با عملکرد بالا بهینه‌سازی شده است.",
  "grok-4-1-fast-reasoning.description": "مدل چندوجهی پیشرفته‌ای که برای استفاده از ابزارهای عامل با عملکرد بالا بهینه‌سازی شده است.",
  "grok-4-fast-non-reasoning.description": "با افتخار Grok 4 Fast را معرفی می‌کنیم، جدیدترین پیشرفت ما در مدل‌های استدلال مقرون‌به‌صرفه.",
  "grok-4-fast-reasoning.description": "با افتخار Grok 4 Fast را معرفی می‌کنیم، جدیدترین پیشرفت ما در مدل‌های استدلال مقرون‌به‌صرفه.",
  "grok-4.description": "جدیدترین و قدرتمندترین مدل پرچم‌دار ما که در پردازش زبان طبیعی، ریاضی و استدلال برتری دارد—یک مدل همه‌کاره ایده‌آل.",
  "grok-code-fast-1.description": "با افتخار grok-code-fast-1 را معرفی می‌کنیم، مدلی سریع و مقرون‌به‌صرفه برای استدلال که در برنامه‌نویسی عامل‌محور عملکرد درخشانی دارد.",
  "groq/compound-mini.description": "Compound-mini یک سیستم هوش مصنوعی ترکیبی است که با مدل‌های عمومی پشتیبانی‌شده در GroqCloud کار می‌کند و به‌صورت هوشمندانه و انتخابی از ابزارها برای پاسخ به پرسش‌های کاربران استفاده می‌کند.",
  "groq/compound.description": "Compound یک سیستم هوش مصنوعی ترکیبی است که با چندین مدل عمومی پشتیبانی‌شده در GroqCloud کار می‌کند و به‌صورت هوشمندانه و انتخابی از ابزارها برای پاسخ به پرسش‌های کاربران استفاده می‌کند.",
  "gryphe/mythomax-l2-13b.description": "MythoMax L2 13B یک مدل زبانی خلاق و هوشمند است که از ترکیب چندین مدل برتر ساخته شده است.",
  "hunyuan-a13b.description": "اولین مدل استدلال ترکیبی از Hunyuan، ارتقاءیافته از hunyuan-standard-256K (در مجموع ۸۰ میلیارد، ۱۳ میلیارد فعال). به‌طور پیش‌فرض با تفکر آهسته کار می‌کند و از طریق پارامترها یا پیشوند /no_think قابلیت تغییر بین تفکر سریع و آهسته را دارد. توانایی کلی آن نسبت به نسل قبلی به‌ویژه در ریاضی، علوم، درک متون بلند و وظایف عامل بهبود یافته است.",
  "hunyuan-code.description": "جدیدترین مدل تولید کد که با ۲۰۰ میلیارد کد باکیفیت و شش ماه آموزش SFT آموزش دیده است؛ ظرفیت زمینه به ۸ هزار افزایش یافته. در ارزیابی‌های خودکار برای پنج زبان و در ارزیابی‌های انسانی در ده معیار برتر قرار دارد.",
  "hunyuan-functioncall.description": "جدیدترین مدل MoE FunctionCall که با داده‌های باکیفیت تماس تابع آموزش دیده، دارای پنجره زمینه ۳۲ هزار و نتایج پیشرو در ارزیابی‌های مختلف است.",
  "hunyuan-large-longcontext.description": "در وظایف اسناد بلند مانند خلاصه‌سازی و پرسش‌وپاسخ عملکرد درخشانی دارد و همچنین در تولید عمومی نیز توانمند است. در تحلیل و تولید متون بلند و پیچیده بسیار قوی است.",
  "hunyuan-large-vision.description": "مدل زبان-بینایی آموزش‌دیده از Hunyuan Large برای درک تصویر و متن. از ورودی چندتصویر + متن با هر وضوحی پشتیبانی می‌کند و درک بصری چندزبانه را بهبود می‌بخشد.",
  "hunyuan-large.description": "Hunyuan-large دارای حدود ۳۸۹ میلیارد پارامتر کل و حدود ۵۲ میلیارد فعال است، بزرگ‌ترین و قوی‌ترین مدل MoE باز در معماری ترنسفورمر.",
  "hunyuan-lite-vision.description": "جدیدترین مدل چندوجهی ۷ میلیاردی با پنجره زمینه ۳۲ هزار، پشتیبانی از چت چندوجهی چینی/انگلیسی، شناسایی اشیاء، درک جداول اسناد و ریاضی چندوجهی، و عملکرد بهتر نسبت به مدل‌های ۷ میلیاردی مشابه در چندین معیار.",
  "hunyuan-lite.description": "ارتقاءیافته به معماری MoE با پنجره زمینه ۲۵۶ هزار، پیشتاز در میان بسیاری از مدل‌های باز در حوزه‌های NLP، کد، ریاضی و معیارهای صنعتی.",
  "hunyuan-pro.description": "مدل MoE با تریلیون پارامتر و پنجره زمینه ۳۲ هزار که در ارزیابی‌ها پیشتاز است، در دستورالعمل‌های پیچیده و استدلال، ریاضی پیشرفته، تماس تابع و ترجمه چندزبانه، مالی، حقوقی و پزشکی عملکرد قوی دارد.",
  "hunyuan-role.description": "جدیدترین مدل نقش‌آفرینی که به‌طور رسمی با داده‌های نقش‌آفرینی تنظیم دقیق شده و عملکرد پایه‌ای قوی‌تری را در سناریوهای نقش‌آفرینی ارائه می‌دهد.",
  "hunyuan-standard-256K.description": "با استفاده از مسیریابی بهبودیافته برای کاهش عدم تعادل بار و فروپاشی متخصصان. در زمینه‌های بلند به دقت ۹۹.۹٪ در آزمون سوزن در انبار کاه دست یافته است. MOE-256K طول و کیفیت زمینه را بیشتر گسترش می‌دهد.",
  "hunyuan-standard-vision.description": "جدیدترین مدل چندوجهی با پاسخ‌های چندزبانه و توانایی متعادل در زبان چینی/انگلیسی.",
  "hunyuan-standard.description": "با استفاده از مسیریابی بهبودیافته برای کاهش عدم تعادل بار و فروپاشی متخصصان. در زمینه‌های بلند به دقت ۹۹.۹٪ در آزمون سوزن در انبار کاه دست یافته است. MOE-32K ارزش بالایی را در پردازش ورودی‌های بلند ارائه می‌دهد.",
  "hunyuan-t1-20250321.description": "توانایی‌های متعادل در هنر و علوم پایه را با درک قوی اطلاعات متون بلند ایجاد می‌کند. از پاسخ‌های استدلالی برای مسائل ریاضی، منطقی، علمی و کدنویسی در سطوح مختلف پشتیبانی می‌کند.",
  "hunyuan-t1-20250403.description": "تولید کد در سطح پروژه و کیفیت نوشتار را بهبود می‌بخشد، درک موضوعات چندمرحله‌ای و پیروی از دستورالعمل‌های ToB را تقویت می‌کند، درک در سطح واژه را بهبود می‌دهد و مشکلات خروجی ترکیبی ساده/سنتی و چینی/انگلیسی را کاهش می‌دهد.",
  "hunyuan-t1-20250529.description": "نوشتار خلاقانه و ترکیب‌بندی را بهبود می‌بخشد، کدنویسی فرانت‌اند، ریاضی و استدلال منطقی را تقویت می‌کند و پیروی از دستورالعمل‌ها را ارتقاء می‌دهد.",
  "hunyuan-t1-20250711.description": "ریاضی سخت، منطق و کدنویسی را به‌طور چشمگیری بهبود می‌بخشد، پایداری خروجی را افزایش می‌دهد و توانایی در متون بلند را ارتقاء می‌دهد.",
  "hunyuan-t1-latest.description": "مدل تفکر آهسته را در ریاضی سخت، استدلال پیچیده، کدنویسی دشوار، پیروی از دستورالعمل‌ها و کیفیت نوشتار خلاقانه به‌طور قابل توجهی بهبود می‌بخشد.",
  "hunyuan-t1-vision-20250619.description": "جدیدترین مدل استدلال عمیق چندوجهی t1-vision با زنجیره تفکر بومی، به‌طور قابل توجهی نسبت به نسخه پیش‌فرض قبلی بهبود یافته است.",
  "hunyuan-t1-vision-20250916.description": "جدیدترین مدل استدلال عمیق t1-vision با بهبودهای عمده در VQA، اتصال بصری، OCR، نمودارها، حل مسائل تصویری و تولید مبتنی بر تصویر، به‌علاوه پشتیبانی قوی‌تر از زبان انگلیسی و زبان‌های کم‌منبع.",
  "hunyuan-turbo-20241223.description": "این نسخه مقیاس‌پذیری دستورالعمل را برای تعمیم بهتر افزایش می‌دهد، استدلال در ریاضی/کد/منطق را به‌طور قابل توجهی بهبود می‌بخشد، درک در سطح واژه را ارتقاء می‌دهد و کیفیت نوشتار را بهبود می‌بخشد.",
  "hunyuan-turbo-latest.description": "بهبودهای کلی در تجربه کاربری در درک NLP، نوشتار، چت، پرسش‌وپاسخ، ترجمه و حوزه‌های تخصصی؛ پاسخ‌هایی شبیه‌تر به انسان، وضوح بهتر در نیت‌های مبهم، تجزیه واژه‌ای بهتر، کیفیت خلاقانه بالاتر و تعامل‌پذیری بیشتر، و مکالمات چندمرحله‌ای قوی‌تر.",
  "hunyuan-turbo-vision.description": "مدل پرچم‌دار نسل بعدی زبان-بینایی با استفاده از معماری جدید MoE، با بهبودهای گسترده در شناسایی، تولید محتوا، پرسش‌وپاسخ دانشی و استدلال تحلیلی.",
  "hunyuan-turbo.description": "پیش‌نمایشی از مدل LLM نسل بعدی Hunyuan با معماری جدید MoE، ارائه‌دهنده استدلال سریع‌تر و نتایج قوی‌تر نسبت به hunyuan-pro.",
  "hunyuan-turbos-20250313.description": "سبک حل مسائل ریاضی را یکپارچه کرده و توانایی پاسخ‌گویی چندمرحله‌ای در ریاضی را تقویت می‌کند. سبک نگارش بهبود یافته تا لحن مصنوعی کاهش یابد و متن صیقل‌خورده‌تری ارائه شود.",
  "hunyuan-turbos-20250416.description": "پایه پیش‌آموزشی ارتقاء یافته برای درک بهتر دستورالعمل‌ها و پیروی از آن‌ها؛ هم‌راستایی بهبود یافته در ریاضی، کدنویسی، منطق و علوم؛ بهبود کیفیت نگارش، درک مطلب، دقت ترجمه و پاسخ‌گویی به سؤالات دانشی؛ تقویت توانایی‌های عامل، به‌ویژه درک چندمرحله‌ای.",
  "hunyuan-turbos-20250604.description": "پایه پیش‌آموزشی ارتقاء یافته با بهبود در نگارش و درک مطلب، پیشرفت چشمگیر در کدنویسی و علوم پایه، و پیروی بهتر از دستورالعمل‌های پیچیده.",
  "hunyuan-turbos-20250926.description": "کیفیت داده‌های پیش‌آموزشی و استراتژی پس‌آموزشی ارتقاء یافته، با بهبود در عملکرد عامل‌ها، زبان انگلیسی و زبان‌های کم‌منبع، پیروی از دستورالعمل‌ها، کدنویسی و توانایی‌های STEM.",
  "hunyuan-turbos-latest.description": "جدیدترین مدل پرچم‌دار Hunyuan TurboS با استدلال قوی‌تر و تجربه‌ای کلی بهتر.",
  "hunyuan-turbos-longtext-128k-20250325.description": "در انجام وظایف متنی طولانی مانند خلاصه‌سازی و پاسخ به سؤالات عملکرد عالی دارد و همچنین در تولید محتوای عمومی توانمند است. در تحلیل و تولید متون بلند و پیچیده بسیار قوی است.",
  "hunyuan-turbos-role-plus.description": "جدیدترین مدل نقش‌آفرینی، به‌طور رسمی با داده‌های نقش‌آفرینی تنظیم دقیق شده و عملکرد پایه‌ای قوی‌تری در سناریوهای نقش‌آفرینی ارائه می‌دهد.",
  "hunyuan-turbos-vision-20250619.description": "جدیدترین مدل پرچم‌دار TurboS در حوزه بینایی-زبان با پیشرفت‌های چشمگیر در وظایف تصویر-متن مانند شناسایی موجودیت‌ها، پاسخ به سؤالات دانشی، نگارش تبلیغاتی و حل مسائل مبتنی بر عکس.",
  "hunyuan-turbos-vision.description": "مدل پرچم‌دار نسل جدید بینایی-زبان مبتنی بر TurboS جدید، متمرکز بر درک وظایف تصویر-متن مانند شناسایی موجودیت‌ها، پاسخ به سؤالات دانشی، نگارش تبلیغاتی و حل مسائل تصویری.",
  "hunyuan-vision-1.5-instruct.description": "مدلی برای تولید متن از تصویر با تفکر سریع، مبتنی بر پایه TurboS متنی، که نسبت به نسخه قبلی در شناسایی پایه‌ای تصویر و استدلال تحلیلی تصویری بهبود قابل‌توجهی دارد.",
  "hunyuan-vision.description": "جدیدترین مدل چندوجهی با پشتیبانی از ورودی تصویر + متن برای تولید متن.",
  "image-01-live.description": "مدل تولید تصویر با جزئیات دقیق، پشتیبانی از تبدیل متن به تصویر و تنظیمات سبک قابل کنترل.",
  "image-01.description": "مدل جدید تولید تصویر با جزئیات دقیق، پشتیبانی از تبدیل متن به تصویر و تصویر به تصویر.",
  "imagen-4.0-fast-generate-001.description": "نسخه سریع از سری مدل‌های تبدیل متن به تصویر نسل چهارم Imagen",
  "imagen-4.0-generate-001.description": "سری مدل‌های تبدیل متن به تصویر نسل چهارم Imagen",
  "imagen-4.0-generate-preview-06-06.description": "خانواده مدل‌های تبدیل متن به تصویر نسل چهارم Imagen.",
  "imagen-4.0-ultra-generate-001.description": "نسخه Ultra از سری مدل‌های تبدیل متن به تصویر نسل چهارم Imagen",
  "imagen-4.0-ultra-generate-preview-06-06.description": "گونه Ultra از مدل‌های تبدیل متن به تصویر نسل چهارم Imagen.",
  "inception/mercury-coder-small.description": "Mercury Coder Small برای تولید کد، اشکال‌زدایی و بازسازی کد با کمترین تأخیر ایده‌آل است.",
  "inclusionAI/Ling-flash-2.0.description": "Ling-flash-2.0 سومین مدل معماری Ling 2.0 از تیم Bailing گروه Ant است. این مدل MoE با ۱۰۰ میلیارد پارامتر کل و تنها ۶.۱ میلیارد فعال در هر توکن (۴.۸ میلیارد بدون جاسازی) است. با وجود پیکربندی سبک، عملکردی برابر یا بهتر از مدل‌های چگال ۴۰B و حتی MoEهای بزرگ‌تر در چندین معیار دارد و کارایی بالا را از طریق معماری و استراتژی آموزش بررسی می‌کند.",
  "inclusionAI/Ling-mini-2.0.description": "Ling-mini-2.0 یک مدل MoE کوچک و با عملکرد بالا با ۱۶ میلیارد پارامتر کل و تنها ۱.۴ میلیارد فعال در هر توکن (۷۸۹ میلیون بدون جاسازی) است که تولید بسیار سریعی دارد. با طراحی کارآمد MoE و داده‌های آموزشی با کیفیت بالا، عملکردی در سطح بالا ارائه می‌دهد که با مدل‌های چگال زیر ۱۰B و MoEهای بزرگ‌تر قابل مقایسه است.",
  "inclusionAI/Ring-flash-2.0.description": "Ring-flash-2.0 یک مدل تفکر با عملکرد بالا است که از Ling-flash-2.0-base بهینه‌سازی شده است. از معماری MoE با ۱۰۰ میلیارد پارامتر کل و تنها ۶.۱ میلیارد فعال در هر استنتاج استفاده می‌کند. الگوریتم icepop آموزش RL را برای مدل‌های MoE پایدار می‌سازد و امکان پیشرفت در استدلال پیچیده را فراهم می‌کند. در معیارهای دشوار (مسابقات ریاضی، تولید کد، استدلال منطقی) پیشرفت‌های بزرگی دارد و از مدل‌های چگال برتر زیر ۴۰B پیشی می‌گیرد و با مدل‌های MoE باز و بسته بزرگ‌تر رقابت می‌کند. همچنین در نوشتن خلاقانه عملکرد خوبی دارد و معماری کارآمد آن استنتاج سریع با هزینه کمتر برای هم‌زمانی بالا را ارائه می‌دهد.",
  "inclusionai/ling-1t.description": "Ling-1T مدل MoE با ۱ تریلیون پارامتر از inclusionAI است که برای وظایف استدلال شدید و بارهای کاری با زمینه بزرگ بهینه شده است.",
  "inclusionai/ling-flash-2.0.description": "Ling-flash-2.0 مدل MoE از inclusionAI است که برای کارایی و عملکرد استدلال بهینه شده و برای وظایف متوسط تا بزرگ مناسب است.",
  "inclusionai/ling-mini-2.0.description": "Ling-mini-2.0 مدل MoE سبک از inclusionAI است که هزینه را به‌طور قابل توجهی کاهش می‌دهد در حالی که توانایی استدلال را حفظ می‌کند.",
  "inclusionai/ming-flash-omini-preview.description": "Ming-flash-omni Preview مدل چندوجهی inclusionAI است که از ورودی‌های صوتی، تصویری و ویدیویی پشتیبانی می‌کند و رندر تصویر و تشخیص گفتار را بهبود می‌بخشد.",
  "inclusionai/ring-1t.description": "Ring-1T مدل MoE با یک تریلیون پارامتر از inclusionAI برای وظایف استدلال در مقیاس بزرگ و تحقیقات مناسب است.",
  "inclusionai/ring-flash-2.0.description": "Ring-flash-2.0 گونه‌ای از مدل Ring از inclusionAI برای سناریوهای با توان بالا است که بر سرعت و کارایی هزینه تأکید دارد.",
  "inclusionai/ring-mini-2.0.description": "Ring-mini-2.0 مدل MoE سبک و با توان بالا از inclusionAI است که برای هم‌زمانی طراحی شده است.",
  "internlm/internlm2_5-7b-chat.description": "InternLM2.5-7B-Chat یک مدل چت متن‌باز بر پایه معماری InternLM2 است. این مدل ۷B بر تولید گفت‌وگو تمرکز دارد و از زبان‌های چینی و انگلیسی پشتیبانی می‌کند و با آموزش مدرن، گفت‌وگویی روان و هوشمند ارائه می‌دهد. برای بسیاری از سناریوهای چت مانند پشتیبانی مشتری و دستیار شخصی مناسب است.",
  "internlm2.5-latest.description": "مدل‌های قدیمی که همچنان با عملکرد عالی و پایدار پس از چندین تکرار نگهداری می‌شوند. در اندازه‌های ۷B و ۲۰B موجود هستند، از زمینه ۱M پشتیبانی می‌کنند و در پیروی از دستورالعمل و استفاده از ابزار قوی‌تر هستند. به‌طور پیش‌فرض به جدیدترین سری InternLM2.5 (در حال حاضر internlm2.5-20b-chat) اشاره دارد.",
  "internlm3-latest.description": "جدیدترین سری مدل‌های ما با عملکرد استدلال عالی که در کلاس اندازه خود در میان مدل‌های متن‌باز پیشرو هستند. به‌طور پیش‌فرض به جدیدترین سری InternLM3 (در حال حاضر internlm3-8b-instruct) اشاره دارد.",
  "internvl2.5-38b-mpo.description": "InternVL2.5 38B MPO یک مدل پیش‌آموزش چندوجهی برای استدلال پیچیده تصویر-متن است.",
  "internvl2.5-latest.description": "InternVL2.5 همچنان با عملکرد قوی و پایدار نگهداری می‌شود. به‌طور پیش‌فرض به جدیدترین سری InternVL2.5 (در حال حاضر internvl2.5-78b) اشاره دارد.",
  "internvl3-14b.description": "InternVL3 14B یک مدل چندوجهی با اندازه متوسط است که بین عملکرد و هزینه تعادل برقرار می‌کند.",
  "internvl3-1b.description": "InternVL3 1B یک مدل چندوجهی سبک برای استقرار در محیط‌های با منابع محدود است.",
  "internvl3-38b.description": "InternVL3 38B یک مدل چندوجهی متن‌باز بزرگ برای درک دقیق تصویر-متن است.",
  "internvl3-latest.description": "جدیدترین مدل چندوجهی ما با درک قوی‌تر تصویر-متن و درک توالی‌های تصویری بلند، قابل مقایسه با مدل‌های بسته برتر. به‌طور پیش‌فرض به جدیدترین سری InternVL (در حال حاضر internvl3-78b) اشاره دارد.",
  "irag-1.0.description": "ERNIE iRAG یک مدل تولید تقویت‌شده با بازیابی تصویر برای جستجوی تصویر، بازیابی تصویر-متن و تولید محتوا است.",
  "jamba-large.description": "پیشرفته‌ترین و قدرتمندترین مدل ما، طراحی‌شده برای وظایف پیچیده سازمانی با عملکرد برجسته.",
  "jamba-mini.description": "کارآمدترین مدل در کلاس خود، با تعادل بین سرعت و کیفیت و ردپای کوچک‌تر.",
  "jina-deepsearch-v1.description": "DeepSearch جستجوی وب، خواندن و استدلال را برای تحقیقات جامع ترکیب می‌کند. آن را مانند عاملی تصور کنید که وظیفه تحقیق شما را می‌گیرد، جستجوهای گسترده‌ای با تکرارهای متعدد انجام می‌دهد و سپس پاسخ تولید می‌کند. این فرآیند شامل تحقیق مداوم، استدلال و حل مسئله از زوایای مختلف است و اساساً با مدل‌های زبانی استاندارد یا سیستم‌های RAG سنتی متفاوت است.",
  "kimi-k2-0711-preview.description": "kimi-k2 یک مدل پایه MoE با قابلیت‌های قوی در برنامه‌نویسی و عامل‌سازی است (۱ تریلیون پارامتر کل، ۳۲ میلیارد فعال) که در معیارهای استدلال، برنامه‌نویسی، ریاضی و عامل از سایر مدل‌های متن‌باز پیشی می‌گیرد.",
  "kimi-k2-0905-preview.description": "kimi-k2-0905-preview دارای پنجره متنی ۲۵۶هزار توکن، برنامه‌نویسی عامل‌محور قوی‌تر، کیفیت بهتر کد فرانت‌اند و درک بهتر از زمینه است.",
  "kimi-k2-instruct.description": "Kimi K2 Instruct مدل رسمی استدلال Kimi با پشتیبانی از زمینه طولانی برای کدنویسی، پرسش‌وپاسخ و موارد دیگر است.",
  "kimi-k2-thinking-turbo.description": "نسخه سریع K2 با تفکر طولانی، دارای پنجره متنی ۲۵۶هزار توکن، استدلال عمیق قوی و خروجی ۶۰ تا ۱۰۰ توکن در ثانیه.",
  "kimi-k2-thinking.description": "kimi-k2-thinking مدل تفکر Moonshot AI با توانایی‌های عمومی در عامل‌سازی و استدلال است. این مدل در استدلال عمیق برتری دارد و می‌تواند مسائل دشوار را از طریق استفاده چندمرحله‌ای از ابزارها حل کند.",
  "kimi-k2-turbo-preview.description": "kimi-k2 یک مدل پایه MoE با قابلیت‌های قوی در برنامه‌نویسی و عامل‌سازی است (۱ تریلیون پارامتر کل، ۳۲ میلیارد فعال) که در معیارهای استدلال، برنامه‌نویسی، ریاضی و عامل از سایر مدل‌های متن‌باز پیشی می‌گیرد.",
  "kimi-k2.5.description": "Kimi K2.5 توانمندترین مدل Kimi است که در وظایف عامل، برنامه‌نویسی و درک بینایی عملکرد SOTA متن‌باز ارائه می‌دهد. این مدل از ورودی‌های چندوجهی و حالت‌های تفکر و بدون تفکر پشتیبانی می‌کند.",
  "kimi-k2.description": "Kimi-K2 یک مدل پایه MoE از Moonshot AI با قابلیت‌های قوی در برنامه‌نویسی و عامل‌سازی است که در مجموع دارای ۱ تریلیون پارامتر و ۳۲ میلیارد فعال است. در معیارهای استدلال عمومی، برنامه‌نویسی، ریاضی و وظایف عامل از سایر مدل‌های متن‌باز پیشی می‌گیرد.",
  "kimi-k2:1t.description": "Kimi K2 یک مدل زبانی بزرگ MoE از Moonshot AI با ۱ تریلیون پارامتر کل و ۳۲ میلیارد فعال در هر عبور است. این مدل برای قابلیت‌های عامل از جمله استفاده پیشرفته از ابزار، استدلال و ترکیب کد بهینه‌سازی شده است.",
  "kimi-latest.description": "Kimi Latest از جدیدترین مدل Kimi استفاده می‌کند و ممکن است شامل ویژگی‌های آزمایشی باشد. این مدل از درک تصویر پشتیبانی می‌کند و به‌طور خودکار مدل‌های ۸k/32k/128k را بر اساس طول زمینه انتخاب می‌کند.",
  "kuaishou/kat-coder-pro-v1.description": "KAT-Coder-Pro-V1 (رایگان برای مدت محدود) بر درک کد و خودکارسازی برای عامل‌های برنامه‌نویسی کارآمد تمرکز دارد.",
  "learnlm-1.5-pro-experimental.description": "LearnLM یک مدل آزمایشی و وظیفه‌محور است که بر اساس اصول علوم یادگیری آموزش دیده تا در سناریوهای آموزش/یادگیری به‌عنوان یک معلم خبره عمل کند و از دستورالعمل‌های سیستمی پیروی کند.",
  "learnlm-2.0-flash-experimental.description": "LearnLM یک مدل آزمایشی و وظیفه‌محور است که بر اساس اصول علوم یادگیری آموزش دیده تا در سناریوهای آموزش/یادگیری به‌عنوان یک معلم خبره عمل کند و از دستورالعمل‌های سیستمی پیروی کند.",
  "lite.description": "Spark Lite یک مدل زبانی سبک با تأخیر بسیار پایین و پردازش کارآمد است. این مدل کاملاً رایگان است و از جستجوی وب در زمان واقعی پشتیبانی می‌کند. پاسخ‌های سریع آن در دستگاه‌های با توان محاسباتی پایین و برای تنظیم دقیق مدل عملکرد خوبی دارد و تجربه‌ای هوشمندانه و مقرون‌به‌صرفه، به‌ویژه برای پرسش‌وپاسخ دانشی، تولید محتوا و سناریوهای جستجو ارائه می‌دهد.",
  "llama-3.1-70b-versatile.description": "Llama 3.1 70B استدلال هوش مصنوعی قوی‌تری را برای کاربردهای پیچیده ارائه می‌دهد و از محاسبات سنگین با کارایی و دقت بالا پشتیبانی می‌کند.",
  "llama-3.1-8b-instant.description": "Llama 3.1 8B یک مدل کارآمد با تولید سریع متن است که برای کاربردهای گسترده و مقرون‌به‌صرفه ایده‌آل است.",
  "llama-3.1-instruct.description": "مدل Llama 3.1 تنظیم‌شده برای دستورالعمل‌ها برای چت بهینه‌سازی شده و در بسیاری از معیارهای صنعتی از مدل‌های چت متن‌باز پیشی می‌گیرد.",
  "llama-3.2-11b-vision-instruct.description": "استدلال تصویری قوی بر روی تصاویر با وضوح بالا، مناسب برای برنامه‌های درک بصری.",
  "llama-3.2-11b-vision-preview.description": "Llama 3.2 برای وظایف ترکیبی بین تصویر و متن طراحی شده و در تولید کپشن تصویر و پرسش‌وپاسخ بصری برتری دارد و شکاف بین تولید زبان و استدلال بصری را پر می‌کند.",
  "llama-3.2-90b-vision-instruct.description": "استدلال تصویری پیشرفته برای برنامه‌های عامل درک بصری.",
  "llama-3.2-90b-vision-preview.description": "Llama 3.2 برای وظایف ترکیبی بین تصویر و متن طراحی شده و در تولید کپشن تصویر و پرسش‌وپاسخ بصری برتری دارد و شکاف بین تولید زبان و استدلال بصری را پر می‌کند.",
  "llama-3.2-vision-instruct.description": "مدل تنظیم‌شده Llama 3.2-Vision برای تشخیص بصری، استدلال تصویری، تولید کپشن و پرسش‌وپاسخ عمومی تصویری بهینه‌سازی شده است.",
  "llama-3.3-70b-versatile.description": "Meta Llama 3.3 یک مدل زبانی چندزبانه با ۷۰ میلیارد پارامتر (ورودی/خروجی متنی) است که نسخه‌های پیش‌آموزش‌دیده و تنظیم‌شده برای دستورالعمل دارد. نسخه تنظیم‌شده فقط متنی برای چت چندزبانه بهینه شده و در بسیاری از معیارهای صنعتی از مدل‌های چت متن‌باز و بسته پیشی می‌گیرد.",
  "llama-3.3-70b.description": "Llama 3.3 70B: یک مدل Llama متوسط تا بزرگ که تعادلی بین استدلال و بازدهی برقرار می‌کند.",
  "llama-3.3-instruct.description": "مدل تنظیم‌شده Llama 3.3 برای چت بهینه شده و در بسیاری از معیارهای صنعتی از مدل‌های چت متن‌باز پیشی می‌گیرد.",
  "llama3-70b-8192.description": "Meta Llama 3 70B توانایی بی‌نظیری در مدیریت پیچیدگی برای پروژه‌های پرچالش ارائه می‌دهد.",
  "llama3-8b-8192.description": "Meta Llama 3 8B عملکرد استدلالی قوی را در سناریوهای متنوع ارائه می‌دهد.",
  "llama3-groq-70b-8192-tool-use-preview.description": "Llama 3 Groq 70B Tool Use قابلیت فراخوانی ابزار قدرتمندی برای مدیریت مؤثر وظایف پیچیده فراهم می‌کند.",
  "llama3-groq-8b-8192-tool-use-preview.description": "Llama 3 Groq 8B Tool Use برای استفاده مؤثر از ابزار با محاسبات موازی سریع بهینه‌سازی شده است.",
  "llama3.1-8b.description": "Llama 3.1 8B: نسخه‌ای کوچک و کم‌تاخیر از Llama برای استنتاج آنلاین سبک و گفتگو.",
  "llama3.1.description": "Llama 3.1 پیشرفته‌ترین مدل Meta است که تا 405 میلیارد پارامتر مقیاس‌پذیر است و برای گفتگوهای پیچیده، ترجمه چندزبانه و تحلیل داده‌ها طراحی شده است.",
  "llama3.1:405b.description": "Llama 3.1 پیشرفته‌ترین مدل Meta است که تا 405 میلیارد پارامتر مقیاس‌پذیر است و برای گفتگوهای پیچیده، ترجمه چندزبانه و تحلیل داده‌ها طراحی شده است.",
  "llama3.1:70b.description": "Llama 3.1 پیشرفته‌ترین مدل Meta است که تا 405 میلیارد پارامتر مقیاس‌پذیر است و برای گفتگوهای پیچیده، ترجمه چندزبانه و تحلیل داده‌ها طراحی شده است.",
  "llava-v1.5-7b-4096-preview.description": "LLaVA 1.5 7B پردازش بصری را با تولید خروجی‌های پیچیده از ورودی‌های تصویری ترکیب می‌کند.",
  "llava.description": "LLaVA یک مدل چندوجهی است که رمزگذار بینایی را با Vicuna ترکیب می‌کند تا درک قوی زبان-تصویر را فراهم آورد.",
  "llava:13b.description": "LLaVA یک مدل چندوجهی است که رمزگذار بینایی را با Vicuna ترکیب می‌کند تا درک قوی زبان-تصویر را فراهم آورد.",
  "llava:34b.description": "LLaVA یک مدل چندوجهی است که رمزگذار بینایی را با Vicuna ترکیب می‌کند تا درک قوی زبان-تصویر را فراهم آورد.",
  "magistral-medium-latest.description": "Magistral Medium 1.2 یک مدل پیشرفته استدلال از Mistral AI (سپتامبر ۲۰۲۵) با پشتیبانی از بینایی است.",
  "magistral-small-2509.description": "Magistral Small 1.2 یک مدل استدلال کوچک و متن‌باز از Mistral AI (سپتامبر ۲۰۲۵) با پشتیبانی از بینایی است.",
  "mathstral.description": "MathΣtral برای پژوهش علمی و استدلال ریاضی ساخته شده و توانایی بالایی در محاسبه و توضیح دارد.",
  "max-32k.description": "Spark Max 32K پردازش با زمینه وسیع را با درک قوی‌تر زمینه و استدلال منطقی ارائه می‌دهد و از ورودی‌های ۳۲ هزار توکنی برای خواندن اسناد طولانی و پرسش و پاسخ دانش خصوصی پشتیبانی می‌کند.",
  "megrez-3b-instruct.description": "Megrez 3B Instruct یک مدل کوچک و کارآمد از Wuwen Xinqiong است.",
  "meituan/longcat-flash-chat.description": "مدلی پایه و متن‌باز از Meituan که برای گفتگو و وظایف عامل بهینه‌سازی شده و در استفاده از ابزار و تعاملات چندمرحله‌ای پیچیده قوی است.",
  "meta-llama-3-70b-instruct.description": "مدلی قدرتمند با ۷۰ میلیارد پارامتر که در استدلال، برنامه‌نویسی و وظایف زبانی گسترده عملکرد بالایی دارد.",
  "meta-llama-3-8b-instruct.description": "مدلی همه‌کاره با ۸ میلیارد پارامتر که برای گفتگو و تولید متن بهینه‌سازی شده است.",
  "meta-llama-3.1-405b-instruct.description": "مدل متنی Llama 3.1 با تنظیمات دستورالعملی برای گفتگوهای چندزبانه بهینه شده و در ارزیابی‌های صنعتی در میان مدل‌های باز و بسته عملکرد بالایی دارد.",
  "meta-llama-3.1-70b-instruct.description": "مدل متنی Llama 3.1 با تنظیمات دستورالعملی برای گفتگوهای چندزبانه بهینه شده و در ارزیابی‌های صنعتی در میان مدل‌های باز و بسته عملکرد بالایی دارد.",
  "meta-llama-3.1-8b-instruct.description": "مدل متنی Llama 3.1 با تنظیمات دستورالعملی برای گفتگوهای چندزبانه بهینه شده و در ارزیابی‌های صنعتی در میان مدل‌های باز و بسته عملکرد بالایی دارد.",
  "meta-llama/Llama-2-13b-chat-hf.description": "LLaMA-2 Chat (13B) قابلیت‌های زبانی قوی و تجربه گفتگوی قابل‌اعتمادی ارائه می‌دهد.",
  "meta-llama/Llama-2-70b-hf.description": "LLaMA-2 قابلیت‌های زبانی قوی و تجربه تعاملی قابل‌اعتمادی ارائه می‌دهد.",
  "meta-llama/Llama-3-70b-chat-hf.description": "Llama 3 70B Instruct Reference یک مدل گفتگوی قدرتمند برای مکالمات پیچیده است.",
  "meta-llama/Llama-3-8b-chat-hf.description": "Llama 3 8B Instruct Reference از چندزبانگی پشتیبانی می‌کند و دانش گسترده‌ای در حوزه‌های مختلف دارد.",
  "meta-llama/Llama-3.2-11B-Vision-Instruct-Turbo.description": "LLaMA 3.2 برای وظایف ترکیبی بینایی و متن طراحی شده است. در توصیف تصویر و پرسش و پاسخ بصری عملکرد بالایی دارد و بین تولید زبان و استدلال بصری پل می‌زند.",
  "meta-llama/Llama-3.2-3B-Instruct-Turbo.description": "LLaMA 3.2 برای وظایف ترکیبی بینایی و متن طراحی شده است. در توصیف تصویر و پرسش و پاسخ بصری عملکرد بالایی دارد و بین تولید زبان و استدلال بصری پل می‌زند.",
  "meta-llama/Llama-3.2-90B-Vision-Instruct-Turbo.description": "LLaMA 3.2 برای وظایف ترکیبی بینایی و متن طراحی شده است. در توصیف تصویر و پرسش و پاسخ بصری عملکرد بالایی دارد و بین تولید زبان و استدلال بصری پل می‌زند.",
  "meta-llama/Llama-3.3-70B-Instruct-Turbo.description": "مدل چندزبانه Meta Llama 3.3 با ۷۰ میلیارد پارامتر (ورودی/خروجی متنی) آموزش دیده و با دستورالعمل تنظیم شده است. نسخه متنی تنظیم‌شده برای گفتگوهای چندزبانه بهینه شده و در ارزیابی‌های صنعتی از بسیاری از مدل‌های باز و بسته پیشی می‌گیرد.",
  "meta-llama/Llama-Vision-Free.description": "LLaMA 3.2 برای وظایف ترکیبی بینایی و متن طراحی شده است. در توصیف تصویر و پرسش و پاسخ بصری عملکرد بالایی دارد و بین تولید زبان و استدلال بصری پل می‌زند.",
  "meta-llama/Meta-Llama-3-70B-Instruct-Lite.description": "Llama 3 70B Instruct Lite برای عملکرد بالا با تاخیر کمتر طراحی شده است.",
  "meta-llama/Meta-Llama-3-70B-Instruct-Turbo.description": "Llama 3 70B Instruct Turbo درک و تولید قوی را برای بارهای کاری سنگین ارائه می‌دهد.",
  "meta-llama/Meta-Llama-3-8B-Instruct-Lite.description": "Llama 3 8B Instruct Lite تعادلی میان عملکرد و منابع محدود فراهم می‌کند.",
  "meta-llama/Meta-Llama-3-8B-Instruct-Turbo.description": "Llama 3 8B Instruct Turbo یک مدل زبانی با عملکرد بالا برای طیف وسیعی از کاربردها است.",
  "meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo.description": "مدل 405B Llama 3.1 Turbo ظرفیت زمینه‌ای عظیمی برای پردازش داده‌های بزرگ فراهم می‌کند و در کاربردهای هوش مصنوعی در مقیاس فوق‌العاده عملکرد بالایی دارد.",
  "meta-llama/Meta-Llama-3.1-405B-Instruct.description": "Llama 3.1 خانواده پیشرو مدل‌های Meta است که تا 405 میلیارد پارامتر مقیاس‌پذیر است و برای گفتگوهای پیچیده، ترجمه چندزبانه و تحلیل داده‌ها طراحی شده است.",
  "meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo.description": "Llama 3.1 70B برای کاربردهای سنگین به‌خوبی تنظیم شده است؛ کمیت‌سازی FP8 محاسبه کارآمد و دقت بالا را برای سناریوهای پیچیده فراهم می‌کند.",
  "meta-llama/Meta-Llama-3.1-70B.description": "Llama 3.1 خانواده پیشرو مدل‌های Meta است که تا 405 میلیارد پارامتر مقیاس‌پذیر است و برای گفتگوهای پیچیده، ترجمه چندزبانه و تحلیل داده‌ها طراحی شده است.",
  "meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo.description": "Llama 3.1 8B از کمیت‌سازی FP8 استفاده می‌کند، تا ۱۳۱٬۰۷۲ توکن زمینه را پشتیبانی می‌کند و در میان مدل‌های باز برتر برای وظایف پیچیده در بسیاری از معیارها قرار دارد.",
  "meta-llama/llama-3-70b-instruct.description": "Llama 3 70B Instruct برای گفتگوهای با کیفیت بالا بهینه شده و در ارزیابی‌های انسانی عملکرد قوی دارد.",
  "meta-llama/llama-3-8b-instruct.description": "Llama 3 8B Instruct برای گفتگوهای با کیفیت بالا بهینه شده و از بسیاری از مدل‌های بسته پیشی می‌گیرد.",
  "meta-llama/llama-3.1-70b-instruct.description": "جدیدترین سری Llama 3.1 از Meta، نسخه ۷۰B تنظیم‌شده با دستورالعمل برای گفتگوهای با کیفیت بالا بهینه شده است. در ارزیابی‌های صنعتی، عملکرد قوی در برابر مدل‌های بسته پیشرو نشان می‌دهد. (فقط برای نهادهای تأییدشده سازمانی در دسترس است.)",
  "meta-llama/llama-3.1-8b-instruct.description": "جدیدترین سری Llama 3.1 از Meta، نسخه ۸B تنظیم‌شده با دستورالعمل به‌ویژه سریع و کارآمد است. در ارزیابی‌های صنعتی، عملکرد قوی دارد و از بسیاری از مدل‌های بسته پیشرو پیشی می‌گیرد. (فقط برای نهادهای تأییدشده سازمانی در دسترس است.)",
  "meta-llama/llama-3.1-8b-instruct:free.description": "LLaMA 3.1 از چندزبانگی پشتیبانی می‌کند و یکی از مدل‌های پیشرو تولیدی است.",
  "meta-llama/llama-3.2-11b-vision-instruct.description": "LLaMA 3.2 برای وظایف ترکیبی بینایی و متن طراحی شده است. در توصیف تصویر و پرسش و پاسخ بصری عملکرد بالایی دارد و بین تولید زبان و استدلال بصری پل می‌زند.",
  "meta-llama/llama-3.2-3b-instruct.description": "meta-llama/llama-3.2-3b-instruct",
  "meta-llama/llama-3.2-90b-vision-instruct.description": "LLaMA 3.2 برای وظایف ترکیبی بینایی و متن طراحی شده است. در توصیف تصویر و پرسش و پاسخ بصری عملکرد بالایی دارد و بین تولید زبان و استدلال بصری پل می‌زند.",
  "meta-llama/llama-3.3-70b-instruct.description": "Llama 3.3 پیشرفته‌ترین مدل چندزبانه متن‌باز Llama است که عملکردی نزدیک به 405B را با هزینه بسیار پایین ارائه می‌دهد. این مدل مبتنی بر Transformer بوده و با SFT و RLHF برای مفید بودن و ایمنی بهبود یافته است. نسخه تنظیم‌شده با دستورالعمل برای گفتگوهای چندزبانه بهینه شده و در ارزیابی‌های صنعتی از بسیاری از مدل‌های باز و بسته پیشی می‌گیرد. تاریخ قطع دانش: دسامبر ۲۰۲۳.",
  "meta-llama/llama-3.3-70b-instruct:free.description": "Llama 3.3 پیشرفته‌ترین مدل چندزبانه متن‌باز Llama است که عملکردی نزدیک به 405B را با هزینه بسیار پایین ارائه می‌دهد. این مدل مبتنی بر Transformer بوده و با SFT و RLHF برای مفید بودن و ایمنی بهبود یافته است. نسخه تنظیم‌شده با دستورالعمل برای گفتگوهای چندزبانه بهینه شده و در ارزیابی‌های صنعتی از بسیاری از مدل‌های باز و بسته پیشی می‌گیرد. تاریخ قطع دانش: دسامبر ۲۰۲۳.",
  "meta.llama3-1-405b-instruct-v1:0.description": "Meta Llama 3.1 405B Instruct بزرگ‌ترین و قدرتمندترین مدل Llama 3.1 Instruct است؛ مدلی بسیار پیشرفته برای استدلال در گفت‌وگو و تولید داده‌های مصنوعی، و پایه‌ای قوی برای آموزش تکمیلی یا تنظیم دقیق در حوزه‌های خاص. مدل‌های چندزبانه Llama 3.1 مجموعه‌ای از مدل‌های تولیدی آموزش‌دیده و تنظیم‌شده با دستورالعمل در اندازه‌های 8B، 70B و 405B هستند (ورودی/خروجی متنی). این مدل‌ها برای گفت‌وگوهای چندزبانه بهینه شده‌اند و در بسیاری از معیارهای صنعتی از مدل‌های چت متن‌باز موجود بهتر عمل می‌کنند. Llama 3.1 برای استفاده تجاری و پژوهشی در زبان‌های مختلف طراحی شده است. مدل‌های تنظیم‌شده با دستورالعمل برای چت به سبک دستیار مناسب‌اند، در حالی که مدل‌های آموزش‌دیده برای وظایف گسترده‌تر تولید زبان طبیعی مناسب‌اند. خروجی‌های Llama 3.1 همچنین می‌توانند برای بهبود مدل‌های دیگر، از جمله تولید و پالایش داده‌های مصنوعی، استفاده شوند. Llama 3.1 یک مدل ترنسفورمر خودرگرسیو با معماری بهینه‌شده است. نسخه‌های تنظیم‌شده از آموزش نظارت‌شده (SFT) و یادگیری تقویتی از بازخورد انسانی (RLHF) برای هم‌راستایی با ترجیحات انسانی در مفید بودن و ایمنی استفاده می‌کنند.",
  "meta.llama3-1-70b-instruct-v1:0.description": "نسخه به‌روزشده Meta Llama 3.1 70B Instruct با پنجره متنی گسترده 128K، پشتیبانی چندزبانه و استدلال بهبودیافته. مدل‌های چندزبانه Llama 3.1 مجموعه‌ای از مدل‌های تولیدی آموزش‌دیده و تنظیم‌شده با دستورالعمل در اندازه‌های 8B، 70B و 405B هستند (ورودی/خروجی متنی). این مدل‌ها برای گفت‌وگوهای چندزبانه بهینه شده‌اند و در بسیاری از معیارهای صنعتی از مدل‌های چت متن‌باز موجود بهتر عمل می‌کنند. Llama 3.1 برای استفاده تجاری و پژوهشی در زبان‌های مختلف طراحی شده است. مدل‌های تنظیم‌شده با دستورالعمل برای چت به سبک دستیار مناسب‌اند، در حالی که مدل‌های آموزش‌دیده برای وظایف گسترده‌تر تولید زبان طبیعی مناسب‌اند. خروجی‌های Llama 3.1 همچنین می‌توانند برای بهبود مدل‌های دیگر، از جمله تولید و پالایش داده‌های مصنوعی، استفاده شوند. Llama 3.1 یک مدل ترنسفورمر خودرگرسیو با معماری بهینه‌شده است. نسخه‌های تنظیم‌شده از آموزش نظارت‌شده (SFT) و یادگیری تقویتی از بازخورد انسانی (RLHF) برای هم‌راستایی با ترجیحات انسانی در مفید بودن و ایمنی استفاده می‌کنند.",
  "meta.llama3-1-8b-instruct-v1:0.description": "نسخه به‌روزشده Meta Llama 3.1 8B Instruct با پنجره متنی 128K، پشتیبانی چندزبانه و استدلال بهبودیافته. خانواده Llama 3.1 شامل مدل‌های متنی تنظیم‌شده با دستورالعمل در اندازه‌های 8B، 70B و 405B است که برای چت چندزبانه و عملکرد قوی در معیارها بهینه شده‌اند. این مدل برای استفاده تجاری و پژوهشی در زبان‌های مختلف طراحی شده است؛ مدل‌های تنظیم‌شده با دستورالعمل برای چت به سبک دستیار مناسب‌اند، در حالی که مدل‌های آموزش‌دیده برای وظایف گسترده‌تر تولید مناسب‌اند. خروجی‌های Llama 3.1 همچنین می‌توانند برای بهبود مدل‌های دیگر (مانند داده‌های مصنوعی و پالایش) استفاده شوند. این مدل یک ترنسفورمر خودرگرسیو است که از SFT و RLHF برای هم‌راستایی با مفید بودن و ایمنی استفاده می‌کند.",
  "meta.llama3-70b-instruct-v1:0.description": "Meta Llama 3 یک مدل زبان باز برای توسعه‌دهندگان، پژوهشگران و شرکت‌ها است که برای کمک به ساخت، آزمایش و گسترش مسئولانه ایده‌های هوش مصنوعی مولد طراحی شده است. به‌عنوان بخشی از زیربنای نوآوری جامعه جهانی، برای تولید محتوا، هوش مصنوعی مکالمه‌ای، درک زبان، تحقیق و توسعه و کاربردهای سازمانی بسیار مناسب است.",
  "meta.llama3-8b-instruct-v1:0.description": "متا لاما ۳ یک مدل زبان باز برای توسعه‌دهندگان، پژوهشگران و شرکت‌ها است که برای کمک به ساخت، آزمایش و گسترش مسئولانه ایده‌های هوش مصنوعی مولد طراحی شده است. این مدل به‌عنوان بخشی از زیرساخت نوآوری جامعه جهانی، برای محیط‌هایی با منابع محدود، دستگاه‌های لبه و زمان‌های آموزش سریع مناسب است.",
  "meta/Llama-3.2-11B-Vision-Instruct.description": "استدلال تصویری قوی بر روی تصاویر با وضوح بالا، مناسب برای برنامه‌های درک بصری.",
  "meta/Llama-3.2-90B-Vision-Instruct.description": "استدلال تصویری پیشرفته برای برنامه‌های عامل با قابلیت درک بصری.",
  "meta/Llama-3.3-70B-Instruct.description": "لاما ۳.۳ پیشرفته‌ترین مدل چندزبانه متن‌باز لاما است که عملکردی نزدیک به مدل‌های ۴۰۵ میلیارد پارامتری را با هزینه بسیار پایین ارائه می‌دهد. این مدل مبتنی بر ترنسفورمر بوده و با SFT و RLHF برای افزایش کارایی و ایمنی بهبود یافته است. نسخه تنظیم‌شده برای دستورالعمل‌ها برای چت چندزبانه بهینه شده و در بسیاری از معیارهای صنعتی از مدل‌های باز و بسته پیشی می‌گیرد. تاریخ قطع دانش: دسامبر ۲۰۲۳.",
  "meta/Meta-Llama-3-70B-Instruct.description": "مدلی قدرتمند با ۷۰ میلیارد پارامتر که در استدلال، برنامه‌نویسی و وظایف زبانی گسترده عملکرد بالایی دارد.",
  "meta/Meta-Llama-3-8B-Instruct.description": "مدلی همه‌کاره با ۸ میلیارد پارامتر که برای چت و تولید متن بهینه شده است.",
  "meta/Meta-Llama-3.1-405B-Instruct.description": "مدل متنی تنظیم‌شده لاما ۳.۱ برای چت چندزبانه، با عملکرد قوی در معیارهای صنعتی رایج در میان مدل‌های چت باز و بسته.",
  "meta/Meta-Llama-3.1-70B-Instruct.description": "مدل متنی تنظیم‌شده لاما ۳.۱ برای چت چندزبانه، با عملکرد قوی در معیارهای صنعتی رایج در میان مدل‌های چت باز و بسته.",
  "meta/Meta-Llama-3.1-8B-Instruct.description": "مدل متنی تنظیم‌شده لاما ۳.۱ برای چت چندزبانه، با عملکرد قوی در معیارهای صنعتی رایج در میان مدل‌های چت باز و بسته.",
  "meta/llama-3-70b.description": "مدلی متن‌باز با ۷۰ میلیارد پارامتر که توسط متا برای پیروی از دستورالعمل‌ها تنظیم شده و توسط Groq بر روی سخت‌افزار LPU برای استنتاج سریع و کارآمد ارائه می‌شود.",
  "meta/llama-3-8b.description": "مدلی متن‌باز با ۸ میلیارد پارامتر که توسط متا برای پیروی از دستورالعمل‌ها تنظیم شده و توسط Groq بر روی سخت‌افزار LPU برای استنتاج سریع و کارآمد ارائه می‌شود.",
  "meta/llama-3.1-405b-instruct.description": "مدلی پیشرفته برای تولید داده مصنوعی، تقطیر دانش و استدلال در چت‌بات‌ها، برنامه‌نویسی و وظایف تخصصی.",
  "meta/llama-3.1-70b-instruct.description": "طراحی‌شده برای گفت‌وگوهای پیچیده با درک عالی از زمینه، استدلال و تولید متن.",
  "meta/llama-3.1-70b.description": "نسخه به‌روزشده لاما ۳.۱ با ۷۰ میلیارد پارامتر، پشتیبانی از زمینه ۱۲۸ هزار توکن، پشتیبانی چندزبانه و استدلال بهبود یافته.",
  "meta/llama-3.1-8b-instruct.description": "مدلی پیشرفته با درک زبانی قوی، توانایی استدلال و تولید متن.",
  "meta/llama-3.1-8b.description": "لاما ۳.۱ با ۸ میلیارد پارامتر از پنجره زمینه ۱۲۸ هزار توکن پشتیبانی می‌کند، برای چت بلادرنگ و تحلیل داده‌ها ایده‌آل است و در مقایسه با مدل‌های بزرگ‌تر صرفه‌جویی قابل‌توجهی در هزینه دارد. توسط Groq بر روی سخت‌افزار LPU برای استنتاج سریع و کارآمد ارائه می‌شود.",
  "meta/llama-3.2-11b-vision-instruct.description": "مدلی پیشرفته در حوزه بینایی-زبان که در استدلال با کیفیت بالا از تصاویر عملکرد درخشانی دارد.",
  "meta/llama-3.2-11b.description": "مدل استدلال تصویری تنظیم‌شده برای دستورالعمل‌ها (ورودی متن+تصویر، خروجی متن) که برای شناسایی بصری، استدلال تصویری، زیرنویس‌گذاری و پرسش‌وپاسخ عمومی تصویری بهینه شده است.",
  "meta/llama-3.2-1b-instruct.description": "مدل زبانی کوچک و پیشرفته با درک قوی، توانایی استدلال و تولید متن.",
  "meta/llama-3.2-1b.description": "مدل فقط متنی برای استفاده در دستگاه‌هایی مانند بازیابی محلی چندزبانه، خلاصه‌سازی و بازنویسی.",
  "meta/llama-3.2-3b-instruct.description": "مدل زبانی کوچک و پیشرفته با درک قوی، توانایی استدلال و تولید متن.",
  "meta/llama-3.2-3b.description": "مدل فقط متنی تنظیم‌شده برای استفاده در دستگاه‌هایی مانند بازیابی محلی چندزبانه، خلاصه‌سازی و بازنویسی.",
  "meta/llama-3.2-90b-vision-instruct.description": "مدلی پیشرفته در حوزه بینایی-زبان که در استدلال با کیفیت بالا از تصاویر عملکرد درخشانی دارد.",
  "meta/llama-3.2-90b.description": "مدل استدلال تصویری تنظیم‌شده برای دستورالعمل‌ها (ورودی متن+تصویر، خروجی متن) که برای شناسایی بصری، استدلال تصویری، زیرنویس‌گذاری و پرسش‌وپاسخ عمومی تصویری بهینه شده است.",
  "meta/llama-3.3-70b-instruct.description": "مدلی پیشرفته با توانایی بالا در استدلال، ریاضی، منطق عمومی و فراخوانی توابع.",
  "meta/llama-3.3-70b.description": "ترکیبی ایده‌آل از عملکرد و بهره‌وری. طراحی‌شده برای هوش مصنوعی مکالمه‌ای با عملکرد بالا در تولید محتوا، برنامه‌های سازمانی و پژوهش، با درک زبانی قوی برای خلاصه‌سازی، طبقه‌بندی، تحلیل احساسات و تولید کد.",
  "meta/llama-4-maverick.description": "خانواده لاما ۴ مجموعه‌ای از مدل‌های بومی چندوجهی است که از متن و ورودی‌های چندرسانه‌ای پشتیبانی می‌کند و با استفاده از MoE درک پیشرفته‌ای از متن و تصویر ارائه می‌دهد. لاما ۴ ماوریک یک مدل ۱۷ میلیاردی با ۱۲۸ متخصص است که توسط DeepInfra ارائه می‌شود.",
  "meta/llama-4-scout.description": "خانواده لاما ۴ مجموعه‌ای از مدل‌های بومی چندوجهی است که از متن و ورودی‌های چندرسانه‌ای پشتیبانی می‌کند و با استفاده از MoE درک پیشرفته‌ای از متن و تصویر ارائه می‌دهد. لاما ۴ اسکات یک مدل ۱۷ میلیاردی با ۱۶ متخصص است که توسط DeepInfra ارائه می‌شود.",
  "microsoft/Phi-3-medium-128k-instruct.description": "همان مدل Phi-3-medium با پنجره متنی بزرگ‌تر برای درخواست‌های RAG یا نمونه‌های کم‌تعداد.",
  "microsoft/Phi-3-medium-4k-instruct.description": "مدلی با ۱۴ میلیارد پارامتر و کیفیت بالاتر نسبت به Phi-3-mini، متمرکز بر داده‌های با کیفیت بالا و نیازمند استدلال.",
  "microsoft/Phi-3-mini-128k-instruct.description": "همان مدل Phi-3-mini با پنجره متنی بزرگ‌تر برای درخواست‌های RAG یا نمونه‌های کم‌تعداد.",
  "microsoft/Phi-3-mini-4k-instruct.description": "کوچک‌ترین عضو خانواده Phi-3، بهینه‌شده برای کیفیت بالا و تأخیر کم.",
  "microsoft/Phi-3-small-128k-instruct.description": "همان مدل Phi-3-small با پنجره متنی بزرگ‌تر برای درخواست‌های RAG یا نمونه‌های کم‌تعداد.",
  "microsoft/Phi-3-small-8k-instruct.description": "مدلی با ۷ میلیارد پارامتر و کیفیت بالاتر نسبت به Phi-3-mini، متمرکز بر داده‌های با کیفیت بالا و نیازمند استدلال.",
  "microsoft/Phi-3.5-mini-instruct.description": "نسخه به‌روزشده‌ای از مدل Phi-3-mini.",
  "microsoft/Phi-3.5-vision-instruct.description": "نسخه به‌روزشده‌ای از مدل Phi-3-vision.",
  "microsoft/WizardLM-2-8x22B.description": "WizardLM 2 یک مدل زبانی از Microsoft AI است که در گفت‌وگوی پیچیده، وظایف چندزبانه، استدلال و دستیارها عملکرد برجسته‌ای دارد.",
  "microsoft/wizardlm-2-8x22b.description": "WizardLM-2 8x22B پیشرفته‌ترین مدل Wizard از Microsoft AI با عملکردی بسیار رقابتی است.",
  "mimo-v2-flash.description": "MiMo-V2-Flash: مدلی کارآمد برای استدلال، برنامه‌نویسی و پایه‌گذاری عامل‌ها.",
  "minicpm-v.description": "MiniCPM-V مدل چندوجهی نسل بعدی OpenBMB با توانایی عالی در OCR و درک چندوجهی برای کاربردهای گسترده است.",
  "minimax-m2.1.description": "MiniMax-M2.1 جدیدترین نسخه از سری MiniMax است که برای برنامه‌نویسی چندزبانه و وظایف پیچیده دنیای واقعی بهینه شده است. به‌عنوان یک مدل بومی هوش مصنوعی، MiniMax-M2.1 پیشرفت‌های قابل‌توجهی در عملکرد مدل، پشتیبانی از چارچوب عامل و سازگاری با سناریوهای مختلف دارد و هدف آن کمک به شرکت‌ها و افراد برای یافتن سبک زندگی و کاری بومی هوش مصنوعی است.",
  "minimax-m2.description": "MiniMax M2 یک مدل زبانی بزرگ کارآمد است که به‌طور خاص برای برنامه‌نویسی و جریان‌های کاری عامل طراحی شده است.",
  "minimax/minimax-m2.1.description": "MiniMax-M2.1 یک مدل زبانی بزرگ سبک و پیشرفته است که برای برنامه‌نویسی، جریان‌های کاری نماینده و توسعه برنامه‌های مدرن بهینه شده و خروجی‌های تمیزتر، مختصرتر و پاسخ‌دهی سریع‌تری ارائه می‌دهد.",
  "minimax/minimax-m2.description": "MiniMax-M2 مدلی با ارزش بالا است که در برنامه‌نویسی و وظایف عامل در بسیاری از سناریوهای مهندسی عملکرد خوبی دارد.",
  "minimaxai/minimax-m2.description": "MiniMax-M2 یک مدل MoE فشرده، سریع و مقرون‌به‌صرفه (با ۲۳۰ میلیارد پارامتر کل و ۱۰ میلیارد فعال) است که برای عملکرد سطح بالا در برنامه‌نویسی و عامل‌ها طراحی شده و در عین حال هوش عمومی قوی را حفظ می‌کند. این مدل در ویرایش چندفایلی، حلقه‌های اجرای کد و اصلاح، اعتبارسنجی تست و زنجیره‌های ابزار پیچیده عملکرد برجسته‌ای دارد.",
  "ministral-3b-latest.description": "Ministral 3B پیشرفته‌ترین مدل لبه‌ای Mistral است.",
  "ministral-8b-latest.description": "Ministral 8B یک مدل لبه‌ای بسیار مقرون‌به‌صرفه از Mistral است.",
  "mistral-ai/Mistral-Large-2411.description": "مدل پرچم‌دار Mistral برای وظایف پیچیده که نیاز به استدلال در مقیاس بزرگ یا تخصص دارند (تولید متن مصنوعی، تولید کد، RAG یا عامل‌ها).",
  "mistral-ai/Mistral-Nemo.description": "Mistral Nemo یک مدل زبانی پیشرفته با استدلال پیشرفته، دانش جهانی و توانایی برنامه‌نویسی قوی نسبت به اندازه خود است.",
  "mistral-ai/mistral-small-2503.description": "Mistral Small برای هر وظیفه مبتنی بر زبان که نیاز به کارایی بالا و تأخیر کم دارد مناسب است.",
  "mistral-large-instruct.description": "Mistral-Large-Instruct-2407 یک مدل LLM متراکم پیشرفته با ۱۲۳ میلیارد پارامتر و استدلال، دانش و برنامه‌نویسی پیشرفته است.",
  "mistral-large-latest.description": "Mistral Large مدل پرچم‌دار است که در وظایف چندزبانه، استدلال پیچیده و تولید کد قوی است — ایده‌آل برای برنامه‌های سطح بالا.",
  "mistral-large.description": "Mixtral Large مدل پرچم‌دار Mistral است که تولید کد، ریاضی و استدلال را با پنجره متنی ۱۲۸ هزار ترکیب می‌کند.",
  "mistral-medium-latest.description": "Mistral Medium 3 عملکردی در سطح پیشرفته با هزینه‌ای ۸ برابر کمتر ارائه می‌دهد و استقرار سازمانی را ساده می‌کند.",
  "mistral-nemo-instruct.description": "Mistral-Nemo-Instruct-2407 نسخه تنظیم‌شده بر اساس دستورالعمل از Mistral-Nemo-Base-2407 است.",
  "mistral-nemo.description": "Mistral Nemo یک مدل ۱۲ میلیاردی با کارایی بالا از Mistral AI و NVIDIA است.",
  "mistral-small-latest.description": "Mistral Small گزینه‌ای مقرون‌به‌صرفه، سریع و قابل‌اعتماد برای ترجمه، خلاصه‌سازی و تحلیل احساسات است.",
  "mistral-small.description": "Mistral Small برای هر وظیفه مبتنی بر زبان که نیاز به کارایی بالا و تأخیر کم دارد مناسب است.",
  "mistral.description": "Mistral مدل ۷ میلیاردی Mistral AI است که برای وظایف زبانی متنوع مناسب است.",
  "mistral/codestral-embed.description": "مدل جاسازی کد برای جاسازی پایگاه‌های کد و مخازن به‌منظور پشتیبانی از دستیارهای برنامه‌نویسی.",
  "mistral/codestral.description": "Mistral Codestral 25.01 یک مدل برنامه‌نویسی پیشرفته است که برای تأخیر کم و استفاده مکرر بهینه شده است. از بیش از ۸۰ زبان پشتیبانی می‌کند و در FIM، اصلاح کد و تولید تست عملکرد عالی دارد.",
  "mistral/devstral-small.description": "Devstral یک مدل LLM عامل‌محور برای وظایف مهندسی نرم‌افزار است که آن را به گزینه‌ای قوی برای عامل‌های مهندسی نرم‌افزار تبدیل می‌کند.",
  "mistral/magistral-medium.description": "تفکر پیچیده با درک عمیق و استدلال شفاف که می‌توانید آن را دنبال و تأیید کنید. استدلال با دقت بالا را در زبان‌های مختلف حتی در میانه وظیفه حفظ می‌کند.",
  "mistral/magistral-small.description": "تفکر پیچیده با درک عمیق و استدلال شفاف که می‌توانید آن را دنبال و تأیید کنید. استدلال با دقت بالا را در زبان‌های مختلف حتی در میانه وظیفه حفظ می‌کند.",
  "mistral/ministral-3b.description": "مدلی فشرده و کارآمد برای وظایف روی دستگاه مانند دستیارها و تحلیل‌های محلی با عملکرد تأخیر پایین.",
  "mistral/ministral-8b.description": "مدلی قدرتمندتر با استنتاج سریع‌تر و بهینه در مصرف حافظه، ایده‌آل برای جریان‌های کاری پیچیده و برنامه‌های لبه‌ای پرتقاضا.",
  "mistral/mistral-embed.description": "مدل جاسازی متن عمومی برای جستجوی معنایی، شباهت، خوشه‌بندی و جریان‌های کاری RAG.",
  "mistral/mistral-large.description": "Mistral Large برای وظایف پیچیده‌ای که نیاز به استدلال قوی یا تخصص دارند ایده‌آل است — تولید متن مصنوعی، تولید کد، RAG یا عامل‌ها.",
  "mistral/mistral-small.description": "Mistral Small برای وظایف ساده و قابل دسته‌بندی مانند طبقه‌بندی، پشتیبانی مشتری یا تولید متن مناسب است و عملکرد عالی را با قیمتی مناسب ارائه می‌دهد.",
  "mistral/mixtral-8x22b-instruct.description": "مدل Instruct با 8x22B. این مدل MoE باز توسط Mistral ارائه می‌شود.",
  "mistral/pixtral-12b.description": "مدلی با ۱۲ میلیارد پارامتر با درک تصویر و متن.",
  "mistral/pixtral-large.description": "Pixtral Large دومین مدل در خانواده چندوجهی ما با درک تصویر در سطح پیشرفته است. اسناد، نمودارها و تصاویر طبیعی را پردازش می‌کند و درک متنی پیشرفته Mistral Large 2 را حفظ می‌کند.",
  "mistralai/Mistral-7B-Instruct-v0.1.description": "Mistral (7B) Instruct به دلیل عملکرد قوی در بسیاری از وظایف زبانی شناخته شده است.",
  "mistralai/Mistral-7B-Instruct-v0.2.description": "Mistral (7B) Instruct v0.2 در مدیریت دستورالعمل‌ها و دقت نتایج بهبود یافته است.",
  "mistralai/Mistral-7B-Instruct-v0.3.description": "Mistral (7B) Instruct v0.3 محاسبات کارآمد و درک زبانی قوی را برای بسیاری از کاربردها ارائه می‌دهد.",
  "mistralai/Mistral-7B-v0.1.description": "Mistral 7B فشرده اما با عملکرد بالا است، برای پردازش دسته‌ای و وظایف ساده مانند طبقه‌بندی و تولید متن با استدلال قوی مناسب است.",
  "mistralai/Mixtral-8x22B-Instruct-v0.1.description": "Mixtral-8x22B Instruct (۱۴۱ میلیارد) یک مدل LLM بسیار بزرگ برای بارهای کاری سنگین است.",
  "mistralai/Mixtral-8x7B-Instruct-v0.1.description": "Mixtral-8x7B Instruct (۴۶.۷ میلیارد) ظرفیت بالایی برای پردازش داده‌های در مقیاس بزرگ فراهم می‌کند.",
  "mistralai/Mixtral-8x7B-v0.1.description": "Mixtral 8x7B یک مدل MoE پراکنده است که سرعت استنتاج را افزایش می‌دهد و برای وظایف چندزبانه و تولید کد مناسب است.",
  "mistralai/mistral-nemo.description": "Mistral Nemo یک مدل ۷.۳ میلیاردی با پشتیبانی چندزبانه و عملکرد قوی در برنامه‌نویسی است.",
  "mixtral-8x7b-32768.description": "Mixtral 8x7B محاسبات موازی مقاوم در برابر خطا را برای وظایف پیچیده فراهم می‌کند.",
  "mixtral.description": "Mixtral مدل MoE از Mistral AI با وزن‌های باز است که از تولید کد و درک زبان پشتیبانی می‌کند.",
  "mixtral:8x22b.description": "Mixtral مدل MoE از Mistral AI با وزن‌های باز است که از تولید کد و درک زبان پشتیبانی می‌کند.",
  "moonshot-v1-128k-vision-preview.description": "مدل‌های بینایی Kimi (شامل moonshot-v1-8k-vision-preview/moonshot-v1-32k-vision-preview/moonshot-v1-128k-vision-preview) قادر به درک محتوای تصاویر مانند متن، رنگ‌ها و اشکال اشیاء هستند.",
  "moonshot-v1-128k.description": "Moonshot V1 128K با پشتیبانی از زمینه بسیار طولانی، امکان تولید متون بسیار بلند را فراهم می‌کند و تا ۱۲۸٬۰۰۰ توکن را برای سناریوهای پژوهشی، دانشگاهی و اسناد بزرگ مدیریت می‌کند.",
  "moonshot-v1-32k-vision-preview.description": "مدل‌های بینایی Kimi (شامل moonshot-v1-8k-vision-preview/moonshot-v1-32k-vision-preview/moonshot-v1-128k-vision-preview) قادر به درک محتوای تصاویر مانند متن، رنگ‌ها و اشکال اشیاء هستند.",
  "moonshot-v1-32k.description": "Moonshot V1 32K از ۳۲٬۷۶۸ توکن برای زمینه‌های متوسط پشتیبانی می‌کند و برای اسناد بلند و گفتگوهای پیچیده در تولید محتوا، گزارش‌ها و سامانه‌های چت ایده‌آل است.",
  "moonshot-v1-8k-vision-preview.description": "مدل‌های بینایی Kimi (شامل moonshot-v1-8k-vision-preview/moonshot-v1-32k-vision-preview/moonshot-v1-128k-vision-preview) قادر به درک محتوای تصاویر مانند متن، رنگ‌ها و اشکال اشیاء هستند.",
  "moonshot-v1-8k.description": "Moonshot V1 8K برای تولید متون کوتاه بهینه‌سازی شده و عملکردی کارآمد دارد. این مدل تا ۸٬۱۹۲ توکن را برای چت‌های کوتاه، یادداشت‌ها و محتوای سریع مدیریت می‌کند.",
  "moonshot-v1-auto.description": "Moonshot V1 Auto به‌طور خودکار مدل مناسب را بر اساس میزان استفاده از توکن‌های زمینه انتخاب می‌کند.",
  "moonshotai/Kimi-Dev-72B.description": "Kimi-Dev-72B یک مدل کد متن‌باز است که با یادگیری تقویتی در مقیاس بزرگ بهینه‌سازی شده و وصله‌های قابل‌اعتماد و آماده تولید ارائه می‌دهد. این مدل با امتیاز ۶۰.۴٪ در SWE-bench Verified، رکورد جدیدی را در میان مدل‌های متن‌باز برای وظایف مهندسی نرم‌افزار خودکار مانند رفع باگ و بازبینی کد ثبت کرده است.",
  "moonshotai/Kimi-K2-Instruct-0905.description": "Kimi K2-Instruct-0905 جدیدترین و قدرتمندترین نسخه Kimi K2 است. این مدل MoE سطح بالا با ۱ تریلیون پارامتر کل و ۳۲ میلیارد پارامتر فعال است. ویژگی‌های کلیدی آن شامل هوش برنامه‌نویسی عامل‌محور قوی‌تر، بهبود چشمگیر در آزمون‌ها و وظایف واقعی عامل‌ها، و کدنویسی ظاهری و کاربردی بهتر در رابط کاربری است.",
  "moonshotai/Kimi-K2-Thinking.description": "Kimi K2 Thinking جدیدترین و قدرتمندترین مدل متن‌باز برای تفکر است. این مدل عمق استدلال چندمرحله‌ای را به‌طور چشمگیری افزایش داده و استفاده پایدار از ابزارها را در ۲۰۰ تا ۳۰۰ فراخوانی متوالی حفظ می‌کند. این مدل در آزمون‌هایی مانند Humanity's Last Exam (HLE)، BrowseComp و سایر معیارها رکورد جدیدی ثبت کرده و در برنامه‌نویسی، ریاضی، منطق و سناریوهای عامل عملکرد درخشانی دارد. این مدل بر پایه معماری MoE با حدود ۱ تریلیون پارامتر ساخته شده و از پنجره زمینه ۲۵۶K و فراخوانی ابزار پشتیبانی می‌کند.",
  "moonshotai/kimi-k2-0711.description": "Kimi K2 0711 نسخه instruct از سری Kimi است که برای تولید کد با کیفیت بالا و استفاده از ابزارها مناسب است.",
  "moonshotai/kimi-k2-0905.description": "Kimi K2 0905 نسخه‌ای به‌روزشده است که عملکرد زمینه و استدلال را با بهینه‌سازی‌های برنامه‌نویسی گسترش می‌دهد.",
  "moonshotai/kimi-k2-instruct-0905.description": "مدل kimi-k2-0905-preview از پنجره زمینه ۲۵۶K پشتیبانی می‌کند و دارای برنامه‌نویسی عامل‌محور قوی‌تر، کد رابط کاربری زیباتر و کاربردی‌تر و درک بهتر زمینه است.",
  "moonshotai/kimi-k2-thinking-turbo.description": "Kimi K2 Thinking Turbo نسخه پرسرعت مدل Kimi K2 Thinking است که با حفظ عمق استدلال، تأخیر را به‌طور قابل‌توجهی کاهش می‌دهد.",
  "moonshotai/kimi-k2-thinking.description": "Kimi K2 Thinking مدل استدلال Moonshot است که برای وظایف استدلال عمیق بهینه‌سازی شده و قابلیت‌های عمومی عامل را داراست.",
  "moonshotai/kimi-k2.description": "Kimi K2 یک مدل بزرگ MoE از Moonshot AI با ۱ تریلیون پارامتر کل و ۳۲ میلیارد پارامتر فعال در هر عبور است که برای قابلیت‌های عامل از جمله استفاده پیشرفته از ابزار، استدلال و تولید کد بهینه‌سازی شده است.",
  "morph/morph-v3-fast.description": "Morph یک مدل تخصصی است که تغییرات کدی پیشنهادشده توسط مدل‌های پیشرفته (مانند Claude یا GPT-4o) را با سرعت بیش از ۴۵۰۰ توکن در ثانیه روی فایل‌های موجود شما اعمال می‌کند. این مدل مرحله نهایی در جریان کاری برنامه‌نویسی با هوش مصنوعی است و از ورودی/خروجی ۱۶K توکن پشتیبانی می‌کند.",
  "morph/morph-v3-large.description": "Morph یک مدل تخصصی است که تغییرات کدی پیشنهادشده توسط مدل‌های پیشرفته (مانند Claude یا GPT-4o) را با سرعت بیش از ۲۵۰۰ توکن در ثانیه روی فایل‌های موجود شما اعمال می‌کند. این مدل مرحله نهایی در جریان کاری برنامه‌نویسی با هوش مصنوعی است و از ورودی/خروجی ۱۶K توکن پشتیبانی می‌کند.",
  "nousresearch/hermes-2-pro-llama-3-8b.description": "Hermes 2 Pro Llama 3 8B نسخه به‌روزشده‌ای از Nous Hermes 2 است که با جدیدترین داده‌های داخلی توسعه یافته است.",
  "nvidia/Llama-3.1-Nemotron-70B-Instruct-HF.description": "Llama 3.1 Nemotron 70B یک مدل سفارشی‌شده توسط NVIDIA برای بهبود مفید بودن پاسخ‌های LLM است. این مدل در Arena Hard، AlpacaEval 2 LC و GPT-4-Turbo MT-Bench عملکرد قوی دارد و تا ۱ اکتبر ۲۰۲۴ در هر سه معیار هم‌ترازی خودکار رتبه اول را کسب کرده است. این مدل از Llama-3.1-70B-Instruct با استفاده از RLHF (REINFORCE)، Llama-3.1-Nemotron-70B-Reward و درخواست‌های HelpSteer2-Preference آموزش دیده است.",
  "nvidia/llama-3.1-nemotron-51b-instruct.description": "مدلی متمایز با دقت و کارایی استثنایی در پردازش زبان طبیعی.",
  "nvidia/llama-3.1-nemotron-70b-instruct.description": "Llama-3.1-Nemotron-70B-Instruct یک مدل سفارشی‌شده توسط NVIDIA است که برای بهبود مفید بودن پاسخ‌های LLM طراحی شده است.",
  "o1-mini.description": "کوچک‌تر و سریع‌تر از o1-preview، با ۸۰٪ هزینه کمتر، قوی در تولید کد و وظایف با زمینه کوتاه.",
  "o1-preview.description": "متمرکز بر استدلال پیشرفته و حل مسائل پیچیده، از جمله ریاضی و علوم. ایده‌آل برای برنامه‌هایی که نیاز به درک عمیق زمینه و جریان‌های کاری خودکار دارند.",
  "o1-pro.description": "سری o1 با یادگیری تقویتی آموزش دیده تا پیش از پاسخ‌دهی فکر کند و استدلال پیچیده را مدیریت کند. o1-pro از منابع محاسباتی بیشتری برای تفکر عمیق‌تر استفاده می‌کند و پاسخ‌هایی با کیفیت بالاتر به‌طور مداوم ارائه می‌دهد.",
  "o1.description": "o1 مدل جدید استدلال OpenAI با ورودی متن+تصویر و خروجی متنی است که برای وظایف پیچیده با نیاز به دانش گسترده مناسب است. این مدل دارای پنجره زمینه ۲۰۰K و تاریخ قطع دانش اکتبر ۲۰۲۳ است.",
  "o3-2025-04-16.description": "o3 مدل جدید استدلال OpenAI با ورودی متن+تصویر و خروجی متنی برای وظایف پیچیده با نیاز به دانش گسترده است.",
  "o3-deep-research.description": "o3-deep-research پیشرفته‌ترین مدل تحقیقاتی ما برای وظایف پیچیده چندمرحله‌ای است. این مدل می‌تواند در وب جستجو کند و به داده‌های شما از طریق اتصال‌دهنده‌های MCP دسترسی داشته باشد.",
  "o3-mini.description": "o3-mini جدیدترین مدل کوچک استدلال ماست که هوش بالاتری را با همان هزینه و تأخیر مدل o1-mini ارائه می‌دهد.",
  "o3-pro-2025-06-10.description": "o3 Pro مدل جدید استدلال OpenAI با ورودی متن+تصویر و خروجی متنی برای وظایف پیچیده با نیاز به دانش گسترده است.",
  "o3-pro.description": "o3-pro از منابع محاسباتی بیشتری برای تفکر عمیق‌تر استفاده می‌کند و به‌طور مداوم پاسخ‌های بهتری ارائه می‌دهد؛ فقط از طریق API پاسخ‌ها در دسترس است.",
  "o3.description": "o3 یک مدل قدرتمند همه‌جانبه است که استاندارد جدیدی در ریاضی، علوم، برنامه‌نویسی و استدلال بصری تعیین می‌کند. این مدل در نگارش فنی و پیروی از دستورالعمل‌ها عالی عمل می‌کند و می‌تواند متن، کد و تصاویر را برای حل مسائل چندمرحله‌ای تحلیل کند.",
  "o4-mini-2025-04-16.description": "o4-mini یک مدل استدلالی از OpenAI با ورودی متن+تصویر و خروجی متنی است که برای وظایف پیچیده با نیاز به دانش گسترده مناسب است و پنجره متنی ۲۰۰ هزار توکنی دارد.",
  "o4-mini-deep-research.description": "o4-mini-deep-research یک مدل تحقیق عمیق سریع‌تر و مقرون‌به‌صرفه‌تر برای پژوهش‌های چندمرحله‌ای پیچیده است. این مدل می‌تواند در وب جستجو کند و از طریق اتصال‌دهنده‌های MCP به داده‌های شما دسترسی یابد.",
  "o4-mini.description": "o4-mini جدیدترین مدل کوچک سری o است که برای استدلال سریع و مؤثر بهینه‌سازی شده و در وظایف کدنویسی و بینایی عملکرد بالایی دارد.",
  "open-codestral-mamba.description": "Codestral Mamba یک مدل زبانی Mamba 2 متمرکز بر تولید کد است که از وظایف پیشرفته کدنویسی و استدلال پشتیبانی می‌کند.",
  "open-mistral-7b.description": "Mistral 7B مدلی جمع‌وجور اما قدرتمند است که برای پردازش دسته‌ای و وظایف ساده مانند طبقه‌بندی و تولید متن مناسب بوده و استدلال خوبی دارد.",
  "open-mistral-nemo.description": "Mistral Nemo یک مدل ۱۲ میلیاردی است که با همکاری Nvidia توسعه یافته و عملکرد قوی در استدلال و کدنویسی با ادغام آسان دارد.",
  "open-mixtral-8x22b.description": "Mixtral 8x22B یک مدل MoE بزرگ برای وظایف پیچیده است که استدلال قوی و بازدهی بالاتری ارائه می‌دهد.",
  "open-mixtral-8x7b.description": "Mixtral 8x7B یک مدل MoE پراکنده است که سرعت استنتاج را افزایش داده و برای وظایف چندزبانه و تولید کد مناسب است.",
  "openai/gpt-3.5-turbo-instruct.description": "قابلیت‌هایی مشابه مدل‌های دوره GPT-3 دارد و با نقاط پایانی تکمیل قدیمی سازگار است، نه چت.",
  "openai/gpt-3.5-turbo.description": "قوی‌ترین و مقرون‌به‌صرفه‌ترین مدل GPT-3.5 از OpenAI که برای چت بهینه‌سازی شده اما در تکمیل‌های کلاسیک نیز عملکرد خوبی دارد.",
  "openai/gpt-4-turbo.description": "gpt-4-turbo از OpenAI دارای دانش عمومی گسترده و تخصص در حوزه‌های مختلف است، دستورالعمل‌های پیچیده زبان طبیعی را دنبال می‌کند و مسائل دشوار را با دقت حل می‌کند. تاریخ قطع دانش آن آوریل ۲۰۲۳ است و پنجره متنی ۱۲۸ هزار توکنی دارد.",
  "openai/gpt-4.1-mini.description": "GPT-4.1 Mini تأخیر کمتر و ارزش بهتری برای وظایف با زمینه متوسط ارائه می‌دهد.",
  "openai/gpt-4.1-nano.description": "GPT-4.1 Nano گزینه‌ای بسیار کم‌هزینه و با تأخیر پایین برای چت‌های کوتاه با فرکانس بالا یا طبقه‌بندی است.",
  "openai/gpt-4.1.description": "سری GPT-4.1 پنجره‌های متنی بزرگ‌تر و قابلیت‌های مهندسی و استدلال قوی‌تری ارائه می‌دهد.",
  "openai/gpt-4o-mini.description": "GPT-4o-mini نسخه‌ای سریع و کوچک از GPT-4o برای استفاده چندوجهی با تأخیر پایین است.",
  "openai/gpt-4o.description": "خانواده GPT-4o مدل Omni از OpenAI است که از ورودی متن + تصویر و خروجی متنی پشتیبانی می‌کند.",
  "openai/gpt-5-chat.description": "GPT-5 Chat نسخه‌ای از GPT-5 است که برای مکالمات بهینه‌سازی شده و تأخیر کمتری برای تعامل بهتر دارد.",
  "openai/gpt-5-codex.description": "GPT-5-Codex نسخه‌ای از GPT-5 است که برای کدنویسی و جریان‌های کاری کد در مقیاس بزرگ بهینه شده است.",
  "openai/gpt-5-mini.description": "GPT-5 Mini نسخه‌ای کوچک‌تر از GPT-5 برای سناریوهای کم‌هزینه و با تأخیر پایین است.",
  "openai/gpt-5-nano.description": "GPT-5 Nano نسخه‌ای فوق‌العاده کوچک برای سناریوهایی با محدودیت شدید هزینه و تأخیر است.",
  "openai/gpt-5-pro.description": "GPT-5 Pro مدل پرچم‌دار OpenAI است که استدلال قوی‌تر، تولید کد و ویژگی‌های سطح سازمانی را با مسیریابی در زمان اجرا و سیاست‌های ایمنی سخت‌گیرانه ارائه می‌دهد.",
  "openai/gpt-5.1-chat.description": "GPT-5.1 Chat عضو سبک‌وزن خانواده GPT-5.1 است که برای مکالمات با تأخیر پایین بهینه شده و همچنان استدلال قوی و اجرای دستورالعمل را حفظ می‌کند.",
  "openai/gpt-5.1-codex-mini.description": "GPT-5.1-Codex-Mini نسخه‌ای کوچک‌تر و سریع‌تر از GPT-5.1-Codex است که برای سناریوهای کدنویسی حساس به تأخیر و هزینه مناسب‌تر است.",
  "openai/gpt-5.1-codex.description": "GPT-5.1-Codex نسخه‌ای از GPT-5.1 است که برای مهندسی نرم‌افزار و جریان‌های کاری کدنویسی بهینه شده و برای بازسازی‌های بزرگ، اشکال‌زدایی پیچیده و وظایف خودکار طولانی مناسب است.",
  "openai/gpt-5.1.description": "GPT-5.1 جدیدترین مدل پرچم‌دار در سری GPT-5 است که بهبودهای قابل‌توجهی در استدلال عمومی، پیروی از دستورالعمل و طبیعی بودن مکالمه نسبت به GPT-5 دارد و برای وظایف گسترده مناسب است.",
  "openai/gpt-5.2-chat.description": "GPT-5.2 Chat نسخه ChatGPT برای تجربه بهبودهای جدید مکالمه‌ای است.",
  "openai/gpt-5.2-pro.description": "GPT-5.2 Pro: نسخه‌ای هوشمندتر و دقیق‌تر از GPT-5.2 (فقط از طریق API پاسخ‌ها)، مناسب برای مسائل دشوار و استدلال چندمرحله‌ای طولانی.",
  "openai/gpt-5.2.description": "GPT-5.2 یک مدل پرچم‌دار برای برنامه‌نویسی و جریان‌های کاری عامل‌محور با استدلال قوی‌تر و عملکرد بهتر در زمینه‌های طولانی است.",
  "openai/gpt-5.description": "GPT-5 مدل قدرتمند OpenAI برای طیف وسیعی از وظایف تولیدی و پژوهشی است.",
  "openai/gpt-oss-120b.description": "یک مدل زبانی بزرگ چندمنظوره با قابلیت استدلال قوی و قابل‌کنترل.",
  "openai/gpt-oss-20b.description": "مدلی جمع‌وجور با وزن‌های باز که برای تأخیر پایین و محیط‌های با منابع محدود، از جمله اجراهای محلی و لبه‌ای بهینه شده است.",
  "openai/o1-mini.description": "مدل o1-mini یک مدل استدلالی سریع و مقرون‌به‌صرفه است که برای برنامه‌نویسی، ریاضیات و علوم طراحی شده است. این مدل دارای حافظه متنی ۱۲۸ هزار توکن و دانش به‌روز تا اکتبر ۲۰۲۳ است.",
  "openai/o1-preview.description": "مدل o1 پیش‌نمایشی از مدل استدلالی جدید OpenAI برای انجام وظایف پیچیده با نیاز به دانش گسترده است. این مدل دارای حافظه متنی ۱۲۸ هزار توکن و دانش به‌روز تا اکتبر ۲۰۲۳ است.",
  "openai/o1.description": "مدل o1 پرچم‌دار OpenAI در حوزه استدلال است که برای حل مسائل پیچیده با نیاز به تفکر عمیق طراحی شده و دقت بالایی در انجام وظایف چندمرحله‌ای ارائه می‌دهد.",
  "openai/o3-mini-high.description": "مدل o3-mini (با توان استدلال بالا) هوشمندی بیشتری را با همان هزینه و تأخیر مدل o1-mini ارائه می‌دهد.",
  "openai/o3-mini.description": "مدل o3-mini جدیدترین مدل کوچک استدلالی OpenAI است که با همان هزینه و تأخیر مدل o1-mini، هوشمندی بیشتری ارائه می‌دهد.",
  "openai/o3.description": "مدل o3 قدرتمندترین مدل استدلالی OpenAI است که استاندارد جدیدی در برنامه‌نویسی، ریاضیات، علوم و درک بصری ایجاد کرده است. این مدل در پاسخ به پرسش‌های پیچیده و چندوجهی، به‌ویژه در تحلیل تصاویر، نمودارها و دیاگرام‌ها بسیار توانمند است.",
  "openai/o4-mini-high.description": "مدل o4-mini در سطح استدلال بالا، برای استدلال سریع و کارآمد با عملکرد قوی در برنامه‌نویسی و بینایی بهینه‌سازی شده است.",
  "openai/o4-mini.description": "مدل o4-mini یک مدل کوچک و کارآمد از OpenAI برای سناریوهای با تأخیر پایین است.",
  "openai/text-embedding-3-large.description": "قوی‌ترین مدل تعبیه متن OpenAI برای وظایف انگلیسی و غیرانگلیسی.",
  "openai/text-embedding-3-small.description": "نسخه بهبودیافته و با عملکرد بالاتر مدل تعبیه ada از OpenAI.",
  "openai/text-embedding-ada-002.description": "مدل تعبیه متن قدیمی OpenAI.",
  "openrouter/auto.description": "بر اساس طول متن، موضوع و پیچیدگی، درخواست شما به یکی از مدل‌های Llama 3 70B Instruct، Claude 3.5 Sonnet (با خودنظارتی) یا GPT-4o هدایت می‌شود.",
  "perplexity/sonar-pro.description": "محصول پرچم‌دار Perplexity با اتصال به جستجو، پشتیبانی از پرسش‌های پیشرفته و پیگیری‌های بعدی.",
  "perplexity/sonar-reasoning-pro.description": "مدلی پیشرفته با تمرکز بر استدلال که خروجی زنجیره تفکر (CoT) را با جستجوی تقویت‌شده و چند پرس‌وجو در هر درخواست ارائه می‌دهد.",
  "perplexity/sonar-reasoning.description": "مدلی با تمرکز بر استدلال که زنجیره تفکر (CoT) را با توضیحات دقیق و مبتنی بر جستجو تولید می‌کند.",
  "perplexity/sonar.description": "محصول سبک Perplexity با اتصال به جستجو، سریع‌تر و ارزان‌تر از Sonar Pro.",
  "phi3.description": "Phi-3 مدل سبک و متن‌باز مایکروسافت برای یکپارچه‌سازی کارآمد و استدلال در مقیاس بزرگ است.",
  "phi3:14b.description": "Phi-3 مدل سبک و متن‌باز مایکروسافت برای یکپارچه‌سازی کارآمد و استدلال در مقیاس بزرگ است.",
  "pixtral-12b-2409.description": "Pixtral در درک نمودار/تصویر، پاسخ به پرسش‌های اسنادی، استدلال چندوجهی و پیروی از دستورالعمل‌ها بسیار توانمند است. این مدل تصاویر را با وضوح و نسبت تصویر اصلی دریافت کرده و هر تعداد تصویر را در پنجره متنی ۱۲۸ هزار توکن پردازش می‌کند.",
  "pixtral-large-latest.description": "Pixtral Large یک مدل چندوجهی باز با ۱۲۴ میلیارد پارامتر است که بر پایه Mistral Large 2 ساخته شده و دومین مدل در خانواده چندوجهی ما با درک پیشرفته تصویر در سطح مرزی است.",
  "pro-128k.description": "Spark Pro 128K ظرفیت بسیار بالایی برای زمینه‌سازی دارد و تا ۱۲۸ هزار توکن را پشتیبانی می‌کند. این مدل برای اسناد بلند که نیاز به تحلیل کامل متن و انسجام بلندمدت دارند، ایده‌آل است و از منطق روان و ارجاع‌های متنوع در بحث‌های پیچیده پشتیبانی می‌کند.",
  "pro-deepseek-r1.description": "مدل خدمات اختصاصی سازمانی با هم‌زمانی بسته‌بندی‌شده.",
  "pro-deepseek-v3.description": "مدل خدمات اختصاصی سازمانی با هم‌زمانی بسته‌بندی‌شده.",
  "qianfan-70b.description": "Qianfan 70B یک مدل بزرگ چینی برای تولید با کیفیت بالا و استدلال پیچیده است.",
  "qianfan-8b.description": "Qianfan 8B یک مدل عمومی میان‌رده است که بین هزینه و کیفیت در تولید متن و پاسخ به پرسش‌ها تعادل برقرار می‌کند.",
  "qianfan-agent-intent-32k.description": "Qianfan Agent Intent 32K برای شناسایی نیت و هماهنگی عامل‌ها با پشتیبانی از زمینه طولانی طراحی شده است.",
  "qianfan-agent-lite-8k.description": "Qianfan Agent Lite 8K یک مدل سبک‌وزن برای گفت‌وگوی چندمرحله‌ای کم‌هزینه و جریان‌های کاری است.",
  "qianfan-check-vl.description": "Qianfan Check VL یک مدل بازبینی محتوای چندوجهی برای تطابق تصویر-متن و وظایف شناسایی است.",
  "qianfan-composition.description": "Qianfan Composition یک مدل تولید چندوجهی برای درک و تولید ترکیبی تصویر و متن است.",
  "qianfan-engcard-vl.description": "Qianfan EngCard VL یک مدل شناسایی چندوجهی متمرکز بر سناریوهای انگلیسی است.",
  "qianfan-lightning-128b-a19b.description": "Qianfan Lightning 128B A19B یک مدل عمومی چینی با عملکرد بالا برای پرسش‌وپاسخ پیچیده و استدلال در مقیاس بزرگ است.",
  "qianfan-llama-vl-8b.description": "Qianfan Llama VL 8B یک مدل چندوجهی مبتنی بر Llama برای درک عمومی تصویر و متن است.",
  "qianfan-multipicocr.description": "Qianfan MultiPicOCR یک مدل OCR چندتصویری برای شناسایی و استخراج متن از تصاویر مختلف است.",
  "qianfan-qi-vl.description": "Qianfan QI VL یک مدل پرسش‌وپاسخ چندوجهی برای بازیابی دقیق و پاسخ‌دهی در سناریوهای پیچیده تصویر-متن است.",
  "qianfan-singlepicocr.description": "Qianfan SinglePicOCR یک مدل OCR تک‌تصویری با دقت بالا در شناسایی کاراکترها است.",
  "qianfan-vl-70b.description": "Qianfan VL 70B یک مدل بزرگ زبان-بینایی برای درک پیچیده تصویر و متن است.",
  "qianfan-vl-8b.description": "Qianfan VL 8B یک مدل سبک‌وزن زبان-بینایی برای پرسش‌وپاسخ روزمره تصویر-متن و تحلیل است.",
  "qvq-72b-preview.description": "QVQ-72B-Preview یک مدل تحقیقاتی آزمایشی از Qwen است که بر بهبود استدلال بصری تمرکز دارد.",
  "qvq-max.description": "مدل استدلال بصری Qwen QVQ از ورودی تصویری و خروجی زنجیره‌ای پشتیبانی می‌کند و عملکرد قوی‌تری در ریاضی، کدنویسی، تحلیل بصری، خلاقیت و وظایف عمومی دارد.",
  "qvq-plus.description": "مدل استدلال بصری با ورودی تصویری و خروجی زنجیره‌ای. سری qvq-plus پس از qvq-max عرضه شده و استدلال سریع‌تر با تعادل بهتر کیفیت-هزینه ارائه می‌دهد.",
  "qwen-3-32b.description": "Qwen 3 32B: قدرتمند در وظایف چندزبانه و کدنویسی، مناسب برای استفاده در مقیاس متوسط تولیدی.",
  "qwen-coder-plus.description": "مدل کدنویسی Qwen.",
  "qwen-coder-turbo-latest.description": "مدل کدنویسی Qwen.",
  "qwen-coder-turbo.description": "مدل کدنویسی Qwen.",
  "qwen-flash.description": "سریع‌ترین و کم‌هزینه‌ترین مدل Qwen، ایده‌آل برای وظایف ساده.",
  "qwen-image-edit.description": "Qwen Image Edit یک مدل تصویر به تصویر است که تصاویر را بر اساس ورودی تصویری و دستورات متنی ویرایش می‌کند و امکان تنظیمات دقیق و تغییرات خلاقانه را فراهم می‌سازد.",
  "qwen-image.description": "Qwen-Image یک مدل عمومی تولید تصویر است که از سبک‌های هنری مختلف و رندر پیچیده متن (به‌ویژه چینی و انگلیسی) پشتیبانی می‌کند. از چیدمان چندخطی، متن در سطح پاراگراف و جزئیات دقیق برای ترکیب‌های پیچیده متن-تصویر پشتیبانی می‌کند.",
  "qwen-long.description": "مدل Qwen فوق‌العاده بزرگ با پشتیبانی از زمینه طولانی و گفت‌وگو در سناریوهای چندسندی و چندسندی بلند.",
  "qwen-math-plus-latest.description": "Qwen Math یک مدل زبانی تخصصی برای حل مسائل ریاضی است.",
  "qwen-math-plus.description": "Qwen Math یک مدل زبانی تخصصی برای حل مسائل ریاضی است.",
  "qwen-math-turbo-latest.description": "Qwen Math یک مدل زبانی تخصصی برای حل مسائل ریاضی است.",
  "qwen-math-turbo.description": "Qwen Math یک مدل زبانی تخصصی برای حل مسائل ریاضی است.",
  "qwen-max.description": "مدل فوق‌العاده بزرگ Qwen در مقیاس صد میلیارد پارامتر که از زبان‌های چینی، انگلیسی و دیگر زبان‌ها پشتیبانی می‌کند؛ مدل API پشت محصولات فعلی Qwen2.5 است.",
  "qwen-omni-turbo.description": "مدل‌های Qwen-Omni از ورودی‌های چندوجهی (ویدیو، صدا، تصویر، متن) پشتیبانی می‌کنند و خروجی صوتی و متنی تولید می‌کنند.",
  "qwen-plus.description": "مدل Qwen فوق‌العاده بزرگ تقویت‌شده با پشتیبانی از زبان‌های چینی، انگلیسی و دیگر زبان‌ها.",
  "qwen-turbo.description": "Qwen Turbo دیگر به‌روزرسانی نخواهد شد؛ لطفاً از Qwen Flash استفاده کنید. مدل فوق‌العاده بزرگ Qwen با پشتیبانی از زبان‌های چینی، انگلیسی و دیگر زبان‌ها.",
  "qwen-vl-chat-v1.description": "Qwen VL از تعاملات انعطاف‌پذیر شامل ورودی چندتصویری، پرسش‌وپاسخ چندمرحله‌ای و وظایف خلاقانه پشتیبانی می‌کند.",
  "qwen-vl-max-latest.description": "مدل فوق‌العاده بزرگ زبان-بینایی Qwen. در مقایسه با نسخه تقویت‌شده، استدلال بصری و پیروی از دستورالعمل‌ها را برای درک و شناخت قوی‌تر بهبود می‌بخشد.",
  "qwen-vl-max.description": "مدل فوق‌العاده بزرگ زبان-بینایی Qwen. در مقایسه با نسخه تقویت‌شده، استدلال بصری و پیروی از دستورالعمل‌ها را برای درک و شناخت بصری قوی‌تر بهبود می‌بخشد.",
  "qwen-vl-ocr.description": "Qwen OCR یک مدل استخراج متن از اسناد، جداول، تصاویر آزمون و دست‌خط است. از زبان‌های چینی، انگلیسی، فرانسوی، ژاپنی، کره‌ای، آلمانی، روسی، ایتالیایی، ویتنامی و عربی پشتیبانی می‌کند.",
  "qwen-vl-plus-latest.description": "مدل تقویت‌شده زبان-بینایی Qwen در مقیاس بزرگ با بهبودهای عمده در شناسایی جزئیات و متن، پشتیبانی از وضوح بیش از یک مگاپیکسل و نسبت‌های ابعاد دلخواه.",
  "qwen-vl-plus.description": "مدل تقویت‌شده زبان-بینایی Qwen در مقیاس بزرگ با بهبودهای عمده در شناسایی جزئیات و متن، پشتیبانی از وضوح بیش از یک مگاپیکسل و نسبت‌های ابعاد دلخواه.",
  "qwen-vl-v1.description": "مدل پیش‌آموزش‌شده مبتنی بر Qwen-7B با ماژول بینایی افزوده و ورودی تصویری با وضوح ۴۴۸.",
  "qwen/qwen-2-7b-instruct.description": "Qwen2 نسل جدید مدل‌های زبانی Qwen است. Qwen2 7B یک مدل مبتنی بر ترنسفورمر است که در درک زبان، توانایی چندزبانه، برنامه‌نویسی، ریاضی و استدلال عملکرد بالایی دارد.",
  "qwen/qwen-2-7b-instruct:free.description": "Qwen2 یک خانواده جدید از مدل‌های زبانی بزرگ با درک و تولید قوی‌تر است.",
  "qwen/qwen-2-vl-72b-instruct.description": "Qwen2-VL جدیدترین نسخه Qwen-VL است که به عملکرد پیشرفته در بنچمارک‌های بینایی مانند MathVista، DocVQA، RealWorldQA و MTVQA دست یافته است. این مدل می‌تواند بیش از ۲۰ دقیقه ویدیو را برای پرسش‌وپاسخ، گفت‌وگو و تولید محتوا با کیفیت بالا درک کند. همچنین استدلال و تصمیم‌گیری پیچیده را انجام می‌دهد و با دستگاه‌های همراه و ربات‌ها برای اقدام بر اساس زمینه بصری و دستور متنی یکپارچه می‌شود. فراتر از زبان‌های انگلیسی و چینی، متن در تصاویر را به زبان‌های مختلف از جمله بیشتر زبان‌های اروپایی، ژاپنی، کره‌ای، عربی و ویتنامی می‌خواند.",
  "qwen/qwen-2.5-72b-instruct.description": "Qwen2.5-72B-Instruct یکی از جدیدترین مدل‌های LLM شرکت Alibaba Cloud است. این مدل ۷۲ میلیارد پارامتری پیشرفت‌های قابل‌توجهی در برنامه‌نویسی و ریاضیات دارد، از بیش از ۲۹ زبان (از جمله چینی و انگلیسی) پشتیبانی می‌کند و در پیروی از دستورالعمل‌ها، درک داده‌های ساختاریافته و تولید خروجی ساختاریافته (به‌ویژه JSON) بسیار بهبود یافته است.",
  "qwen/qwen2.5-32b-instruct.description": "Qwen2.5-32B-Instruct یکی از جدیدترین مدل‌های LLM شرکت Alibaba Cloud است. این مدل ۳۲ میلیارد پارامتری پیشرفت‌های قابل‌توجهی در برنامه‌نویسی و ریاضیات دارد، از بیش از ۲۹ زبان (از جمله چینی و انگلیسی) پشتیبانی می‌کند و در پیروی از دستورالعمل‌ها، درک داده‌های ساختاریافته و تولید خروجی ساختاریافته (به‌ویژه JSON) بسیار بهبود یافته است.",
  "qwen/qwen2.5-7b-instruct.description": "یک مدل LLM دوزبانه برای زبان چینی و انگلیسی در حوزه‌های زبان، برنامه‌نویسی، ریاضیات و استدلال.",
  "qwen/qwen2.5-coder-32b-instruct.description": "مدلی پیشرفته برای تولید، استدلال و اصلاح کد در زبان‌های برنامه‌نویسی رایج.",
  "qwen/qwen2.5-coder-7b-instruct.description": "مدل کد میان‌رده قدرتمند با حافظه متنی ۳۲ هزار توکن، توانمند در برنامه‌نویسی چندزبانه.",
  "qwen/qwen3-14b.description": "Qwen3-14B نسخه ۱۴ میلیارد پارامتری برای استدلال عمومی و سناریوهای چت است.",
  "qwen/qwen3-14b:free.description": "Qwen3-14B یک مدل LLM علّی با ۱۴.۸ میلیارد پارامتر است که برای استدلال پیچیده و چت کارآمد طراحی شده است. این مدل بین حالت تفکر (برای ریاضی، کدنویسی و منطق) و حالت غیرتفکر (برای چت عمومی) جابجا می‌شود. برای پیروی از دستورالعمل‌ها، استفاده از ابزارهای عامل و نوشتن خلاقانه در بیش از ۱۰۰ زبان و گویش تنظیم شده است. به‌صورت بومی از حافظه متنی ۳۲ هزار توکن پشتیبانی می‌کند و با YaRN تا ۱۳۱ هزار توکن گسترش می‌یابد.",
  "qwen/qwen3-235b-a22b-2507.description": "Qwen3-235B-A22B-Instruct-2507 نسخه Instruct از سری Qwen3 است که بین استفاده چندزبانه از دستورالعمل‌ها و سناریوهای با حافظه بلند تعادل برقرار می‌کند.",
  "qwen/qwen3-235b-a22b-thinking-2507.description": "Qwen3-235B-A22B-Thinking-2507 نسخه تفکری Qwen3 است که برای وظایف پیچیده ریاضی و استدلال تقویت شده است.",
  "qwen/qwen3-235b-a22b.description": "Qwen3-235B-A22B یک مدل MoE با ۲۳۵ میلیارد پارامتر از Qwen است که در هر عبور رو به جلو ۲۲ میلیارد پارامتر فعال دارد. این مدل بین حالت تفکر (برای استدلال پیچیده، ریاضی و کدنویسی) و حالت غیرتفکر (برای چت کارآمد) جابجا می‌شود. از استدلال قوی، پشتیبانی چندزبانه (بیش از ۱۰۰ زبان/گویش)، پیروی پیشرفته از دستورالعمل‌ها و استفاده از ابزارهای عامل پشتیبانی می‌کند. به‌صورت بومی از حافظه متنی ۳۲ هزار توکن پشتیبانی می‌کند و با YaRN تا ۱۳۱ هزار توکن گسترش می‌یابد.",
  "qwen/qwen3-235b-a22b:free.description": "Qwen3-235B-A22B یک مدل MoE با ۲۳۵ میلیارد پارامتر از Qwen است که در هر عبور رو به جلو ۲۲ میلیارد پارامتر فعال دارد. این مدل بین حالت تفکر (برای استدلال پیچیده، ریاضی و کدنویسی) و حالت غیرتفکر (برای چت کارآمد) جابجا می‌شود. از استدلال قوی، پشتیبانی چندزبانه (بیش از ۱۰۰ زبان/گویش)، پیروی پیشرفته از دستورالعمل‌ها و استفاده از ابزارهای عامل پشتیبانی می‌کند. به‌صورت بومی از حافظه متنی ۳۲ هزار توکن پشتیبانی می‌کند و با YaRN تا ۱۳۱ هزار توکن گسترش می‌یابد.",
  "qwen/qwen3-30b-a3b.description": "Qwen3 جدیدترین نسل مدل‌های LLM Qwen با معماری‌های متراکم و MoE است که در استدلال، پشتیبانی چندزبانه و وظایف پیشرفته عامل بسیار توانمند است. توانایی منحصربه‌فرد آن در جابجایی بین حالت تفکر برای استدلال پیچیده و حالت غیرتفکر برای چت کارآمد، عملکردی همه‌جانبه و با کیفیت بالا را تضمین می‌کند.\n\nQwen3 به‌طور قابل‌توجهی از مدل‌های قبلی مانند QwQ و Qwen2.5 پیشی می‌گیرد و عملکردی عالی در ریاضی، برنامه‌نویسی، استدلال عقل سلیم، نوشتن خلاقانه و چت تعاملی ارائه می‌دهد. نسخه Qwen3-30B-A3B دارای ۳۰.۵ میلیارد پارامتر (۳.۳ میلیارد فعال)، ۴۸ لایه، ۱۲۸ متخصص (۸ فعال در هر وظیفه) است و از حافظه متنی تا ۱۳۱ هزار توکن با YaRN پشتیبانی می‌کند و استاندارد جدیدی برای مدل‌های متن‌باز تعیین می‌کند.",
  "qwen/qwen3-30b-a3b:free.description": "Qwen3 جدیدترین نسل مدل‌های زبانی Qwen با معماری‌های متراکم و MoE است که در استدلال، پشتیبانی چندزبانه و وظایف پیشرفته عامل‌ها عملکردی برجسته دارد. توانایی منحصربه‌فرد آن در جابجایی بین حالت تفکر برای استدلال پیچیده و حالت بدون تفکر برای گفت‌وگوی سریع، عملکردی همه‌جانبه و با کیفیت بالا را تضمین می‌کند.\n\nQwen3 به‌طور قابل‌توجهی از مدل‌های قبلی مانند QwQ و Qwen2.5 پیشی می‌گیرد و در ریاضیات، برنامه‌نویسی، استدلال عقل سلیم، نویسندگی خلاق و گفت‌وگوی تعاملی عملکردی عالی دارد. نسخه Qwen3-30B-A3B دارای ۳۰.۵ میلیارد پارامتر (۳.۳ میلیارد فعال)، ۴۸ لایه، ۱۲۸ کارشناس (۸ فعال در هر وظیفه) است و با پشتیبانی از زمینه تا ۱۳۱ هزار توکن با استفاده از YaRN، استاندارد جدیدی برای مدل‌های باز ایجاد کرده است.",
  "qwen/qwen3-32b.description": "Qwen3-32B یک مدل زبانی علّی متراکم با ۳۲.۸ میلیارد پارامتر است که برای استدلال پیچیده و گفت‌وگوی کارآمد بهینه‌سازی شده است. این مدل بین حالت تفکر برای ریاضی، برنامه‌نویسی و منطق و حالت بدون تفکر برای گفت‌وگوی عمومی سریع جابجا می‌شود. در پیروی از دستورالعمل‌ها، استفاده از ابزارهای عامل و نویسندگی خلاق در بیش از ۱۰۰ زبان و گویش عملکردی قوی دارد. به‌صورت بومی از زمینه ۳۲ هزار توکن پشتیبانی می‌کند و با YaRN تا ۱۳۱ هزار توکن گسترش می‌یابد.",
  "qwen/qwen3-32b:free.description": "Qwen3-32B یک مدل زبانی علّی متراکم با ۳۲.۸ میلیارد پارامتر است که برای استدلال پیچیده و گفت‌وگوی کارآمد بهینه‌سازی شده است. این مدل بین حالت تفکر برای ریاضی، برنامه‌نویسی و منطق و حالت بدون تفکر برای گفت‌وگوی عمومی سریع جابجا می‌شود. در پیروی از دستورالعمل‌ها، استفاده از ابزارهای عامل و نویسندگی خلاق در بیش از ۱۰۰ زبان و گویش عملکردی قوی دارد. به‌صورت بومی از زمینه ۳۲ هزار توکن پشتیبانی می‌کند و با YaRN تا ۱۳۱ هزار توکن گسترش می‌یابد.",
  "qwen/qwen3-8b:free.description": "Qwen3-8B یک مدل زبانی علّی متراکم با ۸.۲ میلیارد پارامتر است که برای وظایف مبتنی بر استدلال و گفت‌وگوی کارآمد طراحی شده است. این مدل بین حالت تفکر برای ریاضی، برنامه‌نویسی و منطق و حالت بدون تفکر برای گفت‌وگوی عمومی جابجا می‌شود. برای پیروی از دستورالعمل‌ها، یکپارچه‌سازی با عامل‌ها و نویسندگی خلاق در بیش از ۱۰۰ زبان و گویش به‌خوبی تنظیم شده است. به‌صورت بومی از زمینه ۳۲ هزار توکن پشتیبانی می‌کند و با YaRN تا ۱۳۱ هزار توکن گسترش می‌یابد.",
  "qwen/qwen3-coder-plus.description": "Qwen3-Coder-Plus یک مدل عامل برنامه‌نویسی از سری Qwen است که برای استفاده از ابزارهای پیچیده‌تر و جلسات طولانی بهینه‌سازی شده است.",
  "qwen/qwen3-coder.description": "Qwen3-Coder خانواده تولید کد Qwen3 است که در درک و تولید کد در اسناد طولانی عملکردی قوی دارد.",
  "qwen/qwen3-max-preview.description": "Qwen3 Max (پیش‌نمایش) نسخه Max برای استدلال پیشرفته و یکپارچه‌سازی ابزارها است.",
  "qwen/qwen3-max.description": "Qwen3 Max مدل استدلال سطح بالا در سری Qwen3 برای استدلال چندزبانه و یکپارچه‌سازی ابزارها است.",
  "qwen/qwen3-vl-plus.description": "Qwen3 VL-Plus نسخه تقویت‌شده Qwen3 با قابلیت‌های بینایی است که در استدلال چندوجهی و پردازش ویدئو بهبود یافته است.",
  "qwen2.5-14b-instruct-1m.description": "مدل متن‌باز Qwen2.5 با ۷۲ میلیارد پارامتر.",
  "qwen2.5-14b-instruct.description": "مدل متن‌باز Qwen2.5 با ۱۴ میلیارد پارامتر.",
  "qwen2.5-32b-instruct.description": "مدل متن‌باز Qwen2.5 با ۳۲ میلیارد پارامتر.",
  "qwen2.5-72b-instruct.description": "مدل متن‌باز Qwen2.5 با ۷۲ میلیارد پارامتر.",
  "qwen2.5-7b-instruct.description": "Qwen2.5 7B Instruct یک مدل متن‌باز بالغ برای گفت‌وگو و تولید در سناریوهای مختلف است.",
  "qwen2.5-coder-1.5b-instruct.description": "مدل برنامه‌نویسی متن‌باز Qwen.",
  "qwen2.5-coder-14b-instruct.description": "مدل برنامه‌نویسی متن‌باز Qwen.",
  "qwen2.5-coder-32b-instruct.description": "مدل برنامه‌نویسی متن‌باز Qwen.",
  "qwen2.5-coder-7b-instruct.description": "مدل برنامه‌نویسی متن‌باز Qwen.",
  "qwen2.5-coder-instruct.description": "Qwen2.5-Coder جدیدترین مدل متمرکز بر کدنویسی در خانواده Qwen (قبلاً با نام CodeQwen شناخته می‌شد) است.",
  "qwen2.5-instruct.description": "Qwen2.5 جدیدترین سری مدل‌های زبانی Qwen است که شامل مدل‌های پایه و تنظیم‌شده برای دستورالعمل‌ها با اندازه‌هایی از ۰.۵ تا ۷۲ میلیارد پارامتر می‌باشد.",
  "qwen2.5-math-1.5b-instruct.description": "Qwen-Math در حل مسائل ریاضی عملکردی قوی دارد.",
  "qwen2.5-math-72b-instruct.description": "Qwen-Math در حل مسائل ریاضی عملکردی قوی دارد.",
  "qwen2.5-math-7b-instruct.description": "Qwen-Math در حل مسائل ریاضی عملکردی قوی دارد.",
  "qwen2.5-omni-7b.description": "مدل‌های Qwen-Omni از ورودی‌های چندرسانه‌ای (ویدیو، صدا، تصویر، متن) پشتیبانی می‌کنند و خروجی آن‌ها به صورت صوتی و متنی است.",
  "qwen2.5-vl-32b-instruct.description": "Qwen2.5 VL 32B Instruct یک مدل چندرسانه‌ای متن‌باز است که برای استقرار خصوصی و استفاده در سناریوهای مختلف مناسب می‌باشد.",
  "qwen2.5-vl-72b-instruct.description": "بهبود در پیروی از دستورالعمل‌ها، ریاضیات، حل مسئله و برنامه‌نویسی، با توانایی قوی‌تر در شناسایی اشیاء عمومی. از مکان‌یابی دقیق عناصر بصری در قالب‌های مختلف، درک ویدیوهای طولانی (تا ۱۰ دقیقه) با زمان‌بندی رویداد در سطح ثانیه، ترتیب زمانی و درک سرعت، و عامل‌هایی که می‌توانند سیستم‌عامل یا موبایل را از طریق تجزیه و تحلیل و مکان‌یابی کنترل کنند، پشتیبانی می‌کند. استخراج اطلاعات کلیدی قوی و خروجی JSON. این نسخه ۷۲B، قوی‌ترین نسخه در این سری است.",
  "qwen2.5-vl-7b-instruct.description": "Qwen2.5 VL 7B Instruct یک مدل چندرسانه‌ای سبک است که بین هزینه استقرار و توانایی شناسایی تعادل برقرار می‌کند.",
  "qwen2.5-vl-instruct.description": "Qwen2.5-VL جدیدترین مدل زبان-بینایی در خانواده Qwen است.",
  "qwen2.5.description": "Qwen2.5 نسل بعدی مدل زبان بزرگ علی‌بابا است که عملکرد قدرتمندی در کاربردهای متنوع دارد.",
  "qwen2.5:0.5b.description": "Qwen2.5 نسل بعدی مدل زبان بزرگ علی‌بابا است که عملکرد قدرتمندی در کاربردهای متنوع دارد.",
  "qwen2.5:1.5b.description": "Qwen2.5 نسل بعدی مدل زبان بزرگ علی‌بابا است که عملکرد قدرتمندی در کاربردهای متنوع دارد.",
  "qwen2.5:72b.description": "Qwen2.5 نسل بعدی مدل زبان بزرگ علی‌بابا است که عملکرد قدرتمندی در کاربردهای متنوع دارد.",
  "qwen2.description": "Qwen2 نسل بعدی مدل زبان بزرگ علی‌بابا است که عملکرد قدرتمندی در کاربردهای متنوع دارد.",
  "qwen2:0.5b.description": "Qwen2 نسل بعدی مدل زبان بزرگ علی‌بابا است که عملکرد قدرتمندی در کاربردهای متنوع دارد.",
  "qwen2:1.5b.description": "Qwen2 نسل بعدی مدل زبان بزرگ علی‌بابا است که عملکرد قدرتمندی در کاربردهای متنوع دارد.",
  "qwen2:72b.description": "Qwen2 نسل بعدی مدل زبان بزرگ علی‌بابا است که عملکرد قدرتمندی در کاربردهای متنوع دارد.",
  "qwen3-0.6b.description": "Qwen3 0.6B یک مدل سطح ابتدایی برای استدلال ساده و محیط‌های بسیار محدود است.",
  "qwen3-1.7b.description": "Qwen3 1.7B یک مدل فوق‌سبک برای استقرار در لبه و دستگاه‌ها است.",
  "qwen3-14b.description": "Qwen3 14B یک مدل میان‌رده برای پرسش‌وپاسخ چندزبانه و تولید متن است.",
  "qwen3-235b-a22b-instruct-2507.description": "Qwen3 235B A22B Instruct یک مدل راهبردی برای طیف گسترده‌ای از وظایف تولید و استدلال است.",
  "qwen3-235b-a22b-thinking-2507.description": "Qwen3 235B A22B Thinking یک مدل بسیار بزرگ برای استدلال پیچیده است.",
  "qwen3-235b-a22b.description": "Qwen3 نسل جدید مدل Tongyi Qwen است که در استدلال، توانایی عمومی، قابلیت‌های عامل و عملکرد چندزبانه پیشرفت چشمگیری داشته و از تغییر حالت تفکر پشتیبانی می‌کند.",
  "qwen3-30b-a3b-instruct-2507.description": "Qwen3 30B A3B Instruct یک مدل میان‌تا‌بزرگ برای تولید با کیفیت بالا و پرسش‌وپاسخ است.",
  "qwen3-30b-a3b-thinking-2507.description": "Qwen3 30B A3B Thinking یک مدل میان‌تا‌بزرگ برای استدلال است که بین دقت و هزینه تعادل برقرار می‌کند.",
  "qwen3-30b-a3b.description": "Qwen3 30B A3B یک مدل عمومی میان‌تا‌بزرگ است که بین هزینه و کیفیت تعادل برقرار می‌کند.",
  "qwen3-32b.description": "Qwen3 32B برای وظایف عمومی که نیاز به درک قوی‌تری دارند مناسب است.",
  "qwen3-4b.description": "Qwen3 4B برای برنامه‌های کوچک تا متوسط و استنتاج محلی مناسب است.",
  "qwen3-8b.description": "Qwen3 8B یک مدل سبک با قابلیت استقرار انعطاف‌پذیر برای بارهای کاری با هم‌زمانی بالا است.",
  "qwen3-coder-30b-a3b-instruct.description": "مدل کدنویسی متن‌باز Qwen. نسخه جدید qwen3-coder-30b-a3b-instruct بر پایه Qwen3 ساخته شده و توانایی‌های قوی در عامل‌های کدنویس، استفاده از ابزارها و تعامل با محیط برای برنامه‌نویسی خودکار دارد، با عملکرد عالی در کد و توانایی عمومی قوی.",
  "qwen3-coder-480b-a35b-instruct.description": "Qwen3 Coder 480B A35B Instruct یک مدل کدنویسی پیشرفته برای برنامه‌نویسی چندزبانه و درک کد پیچیده است.",
  "qwen3-coder-flash.description": "مدل کدنویسی Qwen. سری جدید Qwen3-Coder بر پایه Qwen3 ساخته شده و توانایی‌های قوی در عامل‌های کدنویس، استفاده از ابزارها و تعامل با محیط برای برنامه‌نویسی خودکار دارد، با عملکرد عالی در کد و توانایی عمومی قوی.",
  "qwen3-coder-plus.description": "مدل کدنویسی Qwen. سری جدید Qwen3-Coder بر پایه Qwen3 ساخته شده و توانایی‌های قوی در عامل‌های کدنویس، استفاده از ابزارها و تعامل با محیط برای برنامه‌نویسی خودکار دارد، با عملکرد عالی در کد و توانایی عمومی قوی.",
  "qwen3-coder:480b.description": "مدل با عملکرد بالا از علی‌بابا برای وظایف عامل و کدنویسی با پشتیبانی از زمینه طولانی.",
  "qwen3-max-2026-01-23.description": "مدل‌های Qwen3 Max نسبت به سری ۲.۵ پیشرفت‌های بزرگی در توانایی عمومی، درک چینی/انگلیسی، پیروی از دستورالعمل‌های پیچیده، وظایف ذهنی باز، توانایی چندزبانه و استفاده از ابزار دارند و خطاهای توهمی کمتری دارند. نسخه جدید qwen3-max در برنامه‌نویسی عامل‌محور و استفاده از ابزار نسبت به نسخه پیش‌نمایش بهبود یافته و به سطح SOTA در حوزه خود رسیده و برای نیازهای پیچیده‌تر عامل‌ها طراحی شده است.",
  "qwen3-max-preview.description": "بهترین مدل Qwen برای وظایف پیچیده و چندمرحله‌ای. نسخه پیش‌نمایش از تفکر پشتیبانی می‌کند.",
  "qwen3-max.description": "مدل‌های Qwen3 Max نسبت به سری 2.5 پیشرفت‌های چشمگیری در توانایی عمومی، درک زبان چینی/انگلیسی، پیروی از دستورالعمل‌های پیچیده، وظایف باز ذهنی، توانایی چندزبانه و استفاده از ابزار دارند، با کاهش خطاهای توهمی. نسخه جدید qwen3-max توانایی برنامه‌نویسی عامل‌محور و استفاده از ابزار را نسبت به qwen3-max-preview بهبود داده است. این نسخه به سطح پیشرفته در حوزه خود رسیده و برای نیازهای پیچیده‌تر عامل‌ها طراحی شده است.",
  "qwen3-next-80b-a3b-instruct.description": "مدل متن‌باز نسل بعدی Qwen3 بدون قابلیت تفکر. نسبت به نسخه قبلی (Qwen3-235B-A22B-Instruct-2507)، درک زبان چینی بهتر، استدلال منطقی قوی‌تر و تولید متن بهبود یافته‌ای دارد.",
  "qwen3-next-80b-a3b-thinking.description": "Qwen3 Next 80B A3B Thinking نسخه پرچم‌دار مدل استدلال برای وظایف پیچیده است.",
  "qwen3-omni-flash.description": "Qwen-Omni ورودی‌های ترکیبی از متن، تصویر، صدا و ویدیو را می‌پذیرد و خروجی آن به صورت متن یا گفتار است. سبک‌های صوتی طبیعی متعددی ارائه می‌دهد، از گفتار چندزبانه و گویش‌ها پشتیبانی می‌کند و برای کاربردهایی مانند نوشتن، شناسایی بصری و دستیارهای صوتی مناسب است.",
  "qwen3-vl-235b-a22b-instruct.description": "Qwen3 VL 235B A22B Instruct یک مدل چندرسانه‌ای پرچم‌دار برای درک و تولید پیشرفته است.",
  "qwen3-vl-235b-a22b-thinking.description": "Qwen3 VL 235B A22B Thinking نسخه پرچم‌دار تفکر برای استدلال و برنامه‌ریزی چندرسانه‌ای پیچیده است.",
  "qwen3-vl-30b-a3b-instruct.description": "Qwen3 VL 30B A3B Instruct یک مدل چندرسانه‌ای بزرگ است که بین دقت و عملکرد استدلال تعادل برقرار می‌کند.",
  "qwen3-vl-30b-a3b-thinking.description": "Qwen3 VL 30B A3B Thinking نسخه تفکر عمیق برای وظایف چندرسانه‌ای پیچیده است.",
  "qwen3-vl-32b-instruct.description": "Qwen3 VL 32B Instruct یک مدل چندرسانه‌ای تنظیم‌شده با دستورالعمل برای پرسش‌وپاسخ تصویری-متنی با کیفیت بالا و تولید محتوا است.",
  "qwen3-vl-32b-thinking.description": "Qwen3 VL 32B Thinking نسخه تفکر عمیق چندرسانه‌ای برای استدلال پیچیده و تحلیل زنجیره‌ای طولانی است.",
  "qwen3-vl-8b-instruct.description": "Qwen3 VL 8B Instruct یک مدل چندرسانه‌ای سبک برای پرسش‌وپاسخ تصویری روزمره و یکپارچه‌سازی با برنامه‌ها است.",
  "qwen3-vl-8b-thinking.description": "Qwen3 VL 8B Thinking یک مدل زنجیره تفکر چندرسانه‌ای برای استدلال بصری دقیق است.",
  "qwen3-vl-flash.description": "Qwen3 VL Flash: نسخه سبک و پرسرعت برای استدلال در درخواست‌های حساس به تأخیر یا با حجم بالا.",
  "qwen3-vl-plus.description": "Qwen VL یک مدل تولید متن با درک بصری است. می‌تواند OCR انجام دهد و همچنین خلاصه‌سازی و استدلال کند، مانند استخراج ویژگی‌ها از عکس‌های محصول یا حل مسائل از روی تصاویر.",
  "qwen3.description": "Qwen3 نسل بعدی مدل زبان بزرگ علی‌بابا است که عملکرد قدرتمندی در کاربردهای متنوع دارد.",
  "qwq-32b-preview.description": "QwQ یک مدل تحقیقاتی آزمایشی از Qwen است که بر بهبود استدلال تمرکز دارد.",
  "qwq-32b.description": "QwQ یک مدل استدلال در خانواده Qwen است. در مقایسه با مدل‌های تنظیم‌شده با دستورالعمل استاندارد، توانایی تفکر و استدلال آن عملکرد پایین‌دستی را به‌ویژه در مسائل پیچیده به‌طور قابل توجهی بهبود می‌بخشد. QwQ-32B یک مدل استدلال میان‌رده است که با مدل‌های برتر مانند DeepSeek-R1 و o1-mini رقابت می‌کند.",
  "qwq-plus.description": "مدل استدلال QwQ که بر پایه Qwen2.5 آموزش دیده و با استفاده از یادگیری تقویتی (RL) توانایی استدلال را به‌طور چشمگیری بهبود داده است. در معیارهای اصلی ریاضی/کد (AIME 24/25، LiveCodeBench) و برخی معیارهای عمومی (IFEval، LiveBench) به سطح کامل DeepSeek-R1 رسیده است.",
  "qwq.description": "QwQ یک مدل استدلال در خانواده Qwen است. در مقایسه با مدل‌های تنظیم‌شده با دستورالعمل استاندارد، توانایی تفکر و استدلال آن عملکرد پایین‌دستی را به‌ویژه در مسائل دشوار به‌طور قابل توجهی بهبود می‌بخشد. QwQ-32B یک مدل استدلال میان‌رده است که با مدل‌های برتر مانند DeepSeek-R1 و o1-mini رقابت می‌کند.",
  "qwq_32b.description": "مدل استدلال میان‌رده در خانواده Qwen. در مقایسه با مدل‌های تنظیم‌شده با دستورالعمل استاندارد، توانایی تفکر و استدلال QwQ عملکرد پایین‌دستی را به‌ویژه در مسائل دشوار به‌طور قابل توجهی بهبود می‌بخشد.",
  "r1-1776.description": "R1-1776 نسخه پس‌آموزشی مدل DeepSeek R1 است که برای ارائه اطلاعات واقعی، بدون سانسور و بی‌طرف طراحی شده است.",
  "solar-mini-ja.description": "Solar Mini (ژاپنی) نسخه‌ای از Solar Mini با تمرکز بر زبان ژاپنی است که در عین حال عملکرد قوی و کارآمدی در زبان‌های انگلیسی و کره‌ای حفظ می‌کند.",
  "solar-mini.description": "Solar Mini یک مدل زبانی فشرده است که عملکردی بهتر از GPT-3.5 دارد و با پشتیبانی چندزبانه قوی از زبان‌های انگلیسی و کره‌ای، راه‌حلی کارآمد با حجم کم ارائه می‌دهد.",
  "solar-pro.description": "Solar Pro یک مدل زبانی هوشمند از Upstage است که برای پیروی از دستورالعمل‌ها روی یک GPU طراحی شده و امتیاز IFEval بالای ۸۰ دارد. در حال حاضر از زبان انگلیسی پشتیبانی می‌کند؛ انتشار کامل آن برای نوامبر ۲۰۲۴ با پشتیبانی زبانی گسترده‌تر و زمینه طولانی‌تر برنامه‌ریزی شده است.",
  "sonar-deep-research.description": "Deep Research پژوهشی جامع در سطح تخصصی انجام داده و آن را به گزارش‌هایی قابل‌فهم و قابل‌اقدام تبدیل می‌کند.",
  "sonar-pro.description": "یک محصول جستجوی پیشرفته با پشتیبانی از جستجوی مبتنی بر زمینه برای پرس‌وجوهای پیچیده و پیگیری‌ها.",
  "sonar-reasoning-pro.description": "یک محصول جستجوی پیشرفته با پشتیبانی از جستجوی مبتنی بر زمینه برای پرس‌وجوهای پیچیده و پیگیری‌ها.",
  "sonar-reasoning.description": "یک محصول جستجوی پیشرفته با پشتیبانی از جستجوی مبتنی بر زمینه برای پرس‌وجوهای پیچیده و پیگیری‌ها.",
  "sonar.description": "یک محصول سبک‌وزن با جستجوی مبتنی بر زمینه، سریع‌تر و ارزان‌تر از Sonar Pro.",
  "spark-x.description": "به‌روزرسانی‌های X1.5: (۱) افزودن حالت تفکر پویا با کنترل از طریق فیلد `thinking`؛ (۲) طول زمینه بزرگ‌تر با ورودی ۶۴K و خروجی ۶۴K؛ (۳) پشتیبانی از FunctionCall.",
  "stable-diffusion-3-medium.description": "جدیدترین مدل تبدیل متن به تصویر از Stability AI. این نسخه کیفیت تصویر، درک متن و تنوع سبک را به‌طور قابل‌توجهی بهبود می‌بخشد، دستورات زبان طبیعی پیچیده را دقیق‌تر تفسیر کرده و تصاویر متنوع‌تری تولید می‌کند.",
  "stable-diffusion-3.5-large-turbo.description": "stable-diffusion-3.5-large-turbo از تکنیک تقطیر انتشار خصمانه (ADD) برای افزایش سرعت در stable-diffusion-3.5-large استفاده می‌کند.",
  "stable-diffusion-3.5-large.description": "stable-diffusion-3.5-large یک مدل تبدیل متن به تصویر MMDiT با ۸۰۰ میلیون پارامتر است که کیفیت بالا و تطابق دقیق با دستورات را ارائه می‌دهد و از تصاویر ۱ مگاپیکسلی و اجرای کارآمد روی سخت‌افزار مصرفی پشتیبانی می‌کند.",
  "stable-diffusion-v1.5.description": "stable-diffusion-v1.5 از نقطه بازیابی v1.2 آغاز شده و به مدت ۵۹۵ هزار مرحله روی مجموعه «laion-aesthetics v2 5+» با وضوح ۵۱۲x۵۱۲ آموزش دیده است. با کاهش ۱۰٪ در شرط‌بندی متنی، نمونه‌گیری بدون طبقه‌بندی را بهبود می‌بخشد.",
  "stable-diffusion-xl-base-1.0.description": "یک مدل متن‌باز تبدیل متن به تصویر از Stability AI با قابلیت‌های خلاقانه پیشرو در صنعت. درک قوی از دستورالعمل‌ها دارد و از تعریف معکوس دستورات برای تولید دقیق پشتیبانی می‌کند.",
  "stable-diffusion-xl.description": "stable-diffusion-xl بهبودهای عمده‌ای نسبت به نسخه v1.5 دارد و با بهترین نتایج متن‌باز تبدیل متن به تصویر برابری می‌کند. بهبودها شامل ستون فقرات UNet سه برابر بزرگ‌تر، ماژول پالایش برای کیفیت بهتر تصویر و تکنیک‌های آموزشی کارآمدتر است.",
  "step-1-128k.description": "تعادل بین عملکرد و هزینه برای سناریوهای عمومی.",
  "step-1-256k.description": "پشتیبانی از زمینه‌های بسیار طولانی، ایده‌آل برای تحلیل اسناد بلند.",
  "step-1-32k.description": "پشتیبانی از مکالمات با طول متوسط برای طیف گسترده‌ای از کاربردها.",
  "step-1-8k.description": "مدلی کوچک مناسب برای وظایف سبک.",
  "step-1-flash.description": "مدلی پرسرعت مناسب برای چت بلادرنگ.",
  "step-1.5v-mini.description": "توانایی قوی در درک ویدیو.",
  "step-1o-turbo-vision.description": "درک قوی تصویر، عملکرد بهتر از 1o در ریاضی و کدنویسی. کوچکتر از 1o با خروجی سریع‌تر.",
  "step-1o-vision-32k.description": "درک قوی تصویر با عملکرد بصری بهتر نسبت به سری Step-1V.",
  "step-1v-32k.description": "پشتیبانی از ورودی‌های تصویری برای تعامل چندوجهی غنی‌تر.",
  "step-1v-8k.description": "مدل تصویری کوچک برای وظایف پایه تصویر و متن.",
  "step-1x-edit.description": "این مدل بر ویرایش تصویر تمرکز دارد و تصاویر را بر اساس ورودی‌های کاربر شامل متن و تصویر تغییر و بهبود می‌دهد. از فرمت‌های ورودی مختلف پشتیبانی می‌کند و ویرایش‌هایی مطابق با هدف کاربر تولید می‌کند.",
  "step-1x-medium.description": "این مدل تولید تصویر قوی با ورودی دستورات متنی ارائه می‌دهد. با پشتیبانی بومی از زبان چینی، توصیف‌های چینی را بهتر درک کرده و به ویژگی‌های بصری دقیق‌تری تبدیل می‌کند. تصاویر با کیفیت بالا و وضوح بالا تولید می‌کند و از انتقال سبک نیز پشتیبانی می‌کند.",
  "step-2-16k-exp.description": "نسخه آزمایشی Step-2 با ویژگی‌های جدید و به‌روزرسانی‌های پیوسته. برای استفاده در تولید توصیه نمی‌شود.",
  "step-2-16k.description": "پشتیبانی از تعاملات با زمینه بزرگ برای گفت‌وگوهای پیچیده.",
  "step-2-mini.description": "ساخته‌شده بر پایه معماری توجه MFA نسل بعدی داخلی، با نتایجی مشابه Step-1 اما با هزینه کمتر، توان عملیاتی بالاتر و تأخیر کمتر. وظایف عمومی را با توانایی قوی در کدنویسی انجام می‌دهد.",
  "step-2x-large.description": "مدل تصویری نسل جدید StepFun با تمرکز بر تولید تصویر، تولید تصاویر با کیفیت بالا از دستورات متنی. بافت واقعی‌تر و رندر بهتر متون چینی/انگلیسی ارائه می‌دهد.",
  "step-3.description": "این مدل دارای درک بصری قوی و استدلال پیچیده است و درک دانش میان‌رشته‌ای، تحلیل ریاضی-تصویری و طیف گسترده‌ای از وظایف تحلیل بصری روزمره را با دقت انجام می‌دهد.",
  "step-r1-v-mini.description": "مدل استدلال با درک قوی تصویر که می‌تواند تصاویر و متون را پردازش کرده و پس از استدلال عمیق، متن تولید کند. در استدلال بصری، ریاضی، کدنویسی و استدلال متنی عملکردی در سطح بالا دارد و از پنجره زمینه ۱۰۰ هزار توکن پشتیبانی می‌کند.",
  "stepfun-ai/step3.description": "Step3 یک مدل استدلال چندوجهی پیشرفته از StepFun است که بر پایه معماری MoE با ۳۲۱ میلیارد پارامتر کل و ۳۸ میلیارد فعال ساخته شده است. طراحی انتها به انتها هزینه رمزگشایی را کاهش داده و استدلال زبان-تصویر سطح بالا را ارائه می‌دهد. با طراحی MFA و AFD، در شتاب‌دهنده‌های پرچم‌دار و سطح پایین کارآمد باقی می‌ماند. پیش‌آموزش با بیش از ۲۰ تریلیون توکن متنی و ۴ تریلیون توکن تصویر-متن در زبان‌های مختلف انجام شده و در معیارهای ریاضی، کدنویسی و چندوجهی عملکردی پیشرو دارد.",
  "taichu_llm.description": "آموزش‌دیده بر داده‌های باکیفیت عظیم، با درک متنی قوی‌تر، تولید محتوا و پرسش‌وپاسخ مکالمه‌ای.",
  "taichu_o1.description": "taichu_o1 یک مدل استدلال نسل جدید است که با تعامل چندوجهی و یادگیری تقویتی، زنجیره تفکر انسانی‌مانند را ایجاد می‌کند، از شبیه‌سازی تصمیم‌گیری پیچیده پشتیبانی کرده و مسیرهای استدلال را در عین حفظ دقت بالا نمایش می‌دهد. مناسب برای تحلیل استراتژی و تفکر عمیق.",
  "taichu_vl.description": "ترکیبی از درک تصویر، انتقال دانش و استنتاج منطقی، با عملکرد عالی در پرسش‌وپاسخ تصویر-متن.",
  "tencent/Hunyuan-A13B-Instruct.description": "Hunyuan-A13B-Instruct با استفاده از ۸۰ میلیارد پارامتر کلی و ۱۳ میلیارد پارامتر فعال، عملکردی هم‌تراز با مدل‌های بزرگ‌تر ارائه می‌دهد. این مدل از استدلال ترکیبی سریع/کند، درک پایدار متون بلند و توانایی پیشرو در عامل‌ها در آزمون‌های BFCL-v3 و τ-Bench پشتیبانی می‌کند. فرمت‌های GQA و چندکوانتیزه‌سازی، استنتاج کارآمد را ممکن می‌سازند.",
  "tencent/Hunyuan-MT-7B.description": "مدل ترجمه Hunyuan شامل Hunyuan-MT-7B و مدل ترکیبی Hunyuan-MT-Chimera است. Hunyuan-MT-7B یک مدل ترجمه سبک با ۷ میلیارد پارامتر است که از ۳۳ زبان به‌علاوه ۵ زبان اقلیت چینی پشتیبانی می‌کند. در رقابت WMT25، در ۳۰ جفت‌زبان از ۳۱ مورد، رتبه اول را کسب کرد. Hunyuan از یک زنجیره کامل آموزش شامل پیش‌آموزش، SFT، تقویت یادگیری ترجمه و تقویت یادگیری ترکیبی استفاده می‌کند و با عملکردی پیشرو در اندازه خود، به‌راحتی قابل استقرار است.",
  "text-embedding-3-large.description": "قوی‌ترین مدل تعبیه‌سازی برای وظایف انگلیسی و غیرانگلیسی.",
  "text-embedding-3-small.description": "مدل تعبیه‌سازی نسل جدید با کارایی بالا و مقرون‌به‌صرفه برای بازیابی اطلاعات و سناریوهای RAG.",
  "thudm/glm-4-32b.description": "GLM-4-32B-0414 یک مدل ۳۲ میلیارد پارامتری دوزبانه (چینی/انگلیسی) با وزن‌های باز است که برای تولید کد، فراخوانی توابع و وظایف عامل بهینه‌سازی شده است. این مدل با ۱۵ ترابایت داده باکیفیت و متمرکز بر استدلال پیش‌آموزش دیده و با هم‌راستاسازی ترجیحات انسانی، نمونه‌گیری ردشده و یادگیری تقویتی بهبود یافته است. در استدلال پیچیده، تولید محتوای ساختاریافته و خروجی‌های منظم عملکردی در سطح GPT-4o و DeepSeek-V3-0324 دارد.",
  "thudm/glm-4-32b:free.description": "GLM-4-32B-0414 یک مدل ۳۲ میلیارد پارامتری دوزبانه (چینی/انگلیسی) با وزن‌های باز است که برای تولید کد، فراخوانی توابع و وظایف عامل بهینه‌سازی شده است. این مدل با ۱۵ ترابایت داده باکیفیت و متمرکز بر استدلال پیش‌آموزش دیده و با هم‌راستاسازی ترجیحات انسانی، نمونه‌گیری ردشده و یادگیری تقویتی بهبود یافته است. در استدلال پیچیده، تولید محتوای ساختاریافته و خروجی‌های منظم عملکردی در سطح GPT-4o و DeepSeek-V3-0324 دارد.",
  "thudm/glm-4-9b-chat.description": "انتشار متن‌باز جدیدترین مدل پیش‌آموزش GLM-4 از Zhipu AI.",
  "thudm/glm-z1-32b.description": "GLM-Z1-32B-0414 نسخه‌ای تقویت‌شده از GLM-4-32B برای استدلال عمیق در ریاضیات، منطق و حل مسائل کدنویسی است. این مدل با استفاده از یادگیری تقویتی گسترده (ترجیحات جفتی خاص وظیفه و عمومی) برای بهبود وظایف چندمرحله‌ای پیچیده طراحی شده است. نسبت به GLM-4-32B، Z1 در استدلال ساختاریافته و توانایی در حوزه‌های رسمی به‌طور قابل‌توجهی بهتر عمل می‌کند.\n\nاین مدل از مهندسی اعلان برای تحمیل مراحل «تفکر»، انسجام بهتر در خروجی‌های بلند، و بهینه‌سازی برای جریان‌های کاری عامل با زمینه طولانی (از طریق YaRN)، فراخوانی ابزار JSON و نمونه‌گیری دقیق برای استدلال پایدار پشتیبانی می‌کند. مناسب برای موارد استفاده‌ای است که نیاز به استنتاج چندمرحله‌ای دقیق یا استنتاج رسمی دارند.",
  "thudm/glm-z1-rumination-32b.description": "GLM Z1 Rumination 32B یک مدل استدلال عمیق ۳۲ میلیارد پارامتری از سری GLM-4-Z1 است که برای وظایف پیچیده و باز با نیاز به تفکر طولانی بهینه‌سازی شده است. این مدل بر پایه glm-4-32b-0414 ساخته شده و مراحل یادگیری تقویتی اضافی و هم‌راستاسازی چندمرحله‌ای را اضافه می‌کند تا قابلیت «تفکر عمیق» را شبیه‌سازی کند. این شامل استدلال تکراری، تحلیل چندمرحله‌ای و جریان‌های کاری تقویت‌شده با ابزار مانند جستجو، بازیابی و ترکیب آگاه از منابع است.\n\nدر نگارش پژوهشی، تحلیل مقایسه‌ای و پرسش‌وپاسخ پیچیده عملکردی عالی دارد. از فراخوانی توابع برای عملیات پایه جستجو/ناوبری (`search`، `click`، `open`، `finish`) در خطوط لوله عامل پشتیبانی می‌کند. رفتار تفکر عمیق از طریق حلقه‌های چندمرحله‌ای با شکل‌دهی پاداش مبتنی بر قواعد و مکانیزم‌های تصمیم‌گیری تأخیری کنترل می‌شود و در برابر چارچوب‌های پژوهشی عمیق مانند پشته هم‌راستاسازی داخلی OpenAI ارزیابی شده است. این نسخه برای عمق بیشتر نسبت به سرعت طراحی شده است.",
  "tngtech/deepseek-r1t-chimera:free.description": "DeepSeek-R1T-Chimera با ترکیب DeepSeek-R1 و DeepSeek-V3 (0324) ساخته شده و استدلال R1 را با کارایی توکنی V3 ترکیب می‌کند. این مدل بر پایه DeepSeek-MoE Transformer است و برای تولید متن عمومی بهینه‌سازی شده است.\n\nوزن‌های پیش‌آموزش‌یافته را برای تعادل بین استدلال، کارایی و پیروی از دستورالعمل‌ها ترکیب می‌کند. تحت مجوز MIT برای استفاده پژوهشی و تجاری منتشر شده است.",
  "togethercomputer/StripedHyena-Nous-7B.description": "StripedHyena Nous (7B) با بهره‌گیری از معماری و استراتژی خود، بهره‌وری محاسباتی بهبودیافته‌ای ارائه می‌دهد.",
  "tts-1-hd.description": "جدیدترین مدل تبدیل متن به گفتار با بهینه‌سازی برای کیفیت بالا.",
  "tts-1.description": "جدیدترین مدل تبدیل متن به گفتار با بهینه‌سازی برای سرعت در زمان واقعی.",
  "upstage/SOLAR-10.7B-Instruct-v1.0.description": "Upstage SOLAR Instruct v1 (11B) برای انجام دقیق وظایف دستوری با عملکرد زبانی قوی تنظیم شده است.",
  "us.anthropic.claude-3-5-sonnet-20241022-v2:0.description": "Claude 3.5 Sonnet استاندارد صنعت را ارتقا داده و در ارزیابی‌های گسترده از رقبا و Claude 3 Opus پیشی می‌گیرد، در حالی که سرعت و هزینه متوسط را حفظ می‌کند.",
  "us.anthropic.claude-3-7-sonnet-20250219-v1:0.description": "Claude 3.7 Sonnet سریع‌ترین مدل نسل جدید Anthropic است. در مقایسه با Claude 3 Haiku، در مهارت‌های مختلف بهبود یافته و در بسیاری از معیارهای هوش از مدل پرچم‌دار قبلی Claude 3 Opus پیشی گرفته است.",
  "us.anthropic.claude-haiku-4-5-20251001-v1:0.description": "Claude Haiku 4.5 سریع‌ترین و هوشمندترین مدل Haiku از Anthropic است که با سرعتی برق‌آسا و توانایی تفکر گسترده ارائه می‌شود.",
  "us.anthropic.claude-opus-4-6-v1.description": "Claude Opus 4.6 هوشمندترین مدل Anthropic برای ساخت عامل‌ها و برنامه‌نویسی است.",
  "us.anthropic.claude-sonnet-4-5-20250929-v1:0.description": "Claude Sonnet 4.5 هوشمندترین مدل Anthropic تا به امروز است.",
  "v0-1.0-md.description": "v0-1.0-md یک مدل قدیمی است که از طریق API نسخه v0 ارائه می‌شود.",
  "v0-1.5-lg.description": "v0-1.5-lg برای وظایف پیشرفته تفکر یا استدلال مناسب است.",
  "v0-1.5-md.description": "v0-1.5-md برای وظایف روزمره و تولید رابط کاربری مناسب است.",
  "vercel/v0-1.0-md.description": "به مدل‌های پشت v0 دسترسی پیدا کنید تا برنامه‌های وب مدرن را با استدلال خاص فریم‌ورک و دانش به‌روز تولید، اصلاح و بهینه‌سازی کنید.",
  "vercel/v0-1.5-md.description": "به مدل‌های پشت v0 دسترسی پیدا کنید تا برنامه‌های وب مدرن را با استدلال خاص فریم‌ورک و دانش به‌روز تولید، اصلاح و بهینه‌سازی کنید.",
  "volcengine/doubao-seed-code.description": "Doubao-Seed-Code مدل LLM شرکت ByteDance Volcano Engine است که برای برنامه‌نویسی عامل‌محور بهینه‌سازی شده و در معیارهای برنامه‌نویسی و عامل با پشتیبانی از زمینه ۲۵۶K عملکرد قوی دارد.",
  "wan2.2-t2i-flash.description": "Wanxiang 2.2 Speed جدیدترین مدل با ارتقاء در خلاقیت، پایداری و واقع‌گرایی است که تولید سریع و ارزش بالا را ارائه می‌دهد.",
  "wan2.2-t2i-plus.description": "Wanxiang 2.2 Pro جدیدترین مدل با ارتقاء در خلاقیت، پایداری و واقع‌گرایی است که جزئیات غنی‌تری تولید می‌کند.",
  "wanx-v1.description": "مدل پایه تبدیل متن به تصویر. معادل Tongyi Wanxiang 1.0 General.",
  "wanx2.0-t2i-turbo.description": "در پرتره‌های بافت‌دار با سرعت متوسط و هزینه کمتر عملکرد عالی دارد. معادل Tongyi Wanxiang 2.0 Speed.",
  "wanx2.1-t2i-plus.description": "نسخه کاملاً ارتقاءیافته با جزئیات تصویری غنی‌تر و سرعت کمی کمتر. معادل Tongyi Wanxiang 2.1 Pro.",
  "wanx2.1-t2i-turbo.description": "نسخه کاملاً ارتقاءیافته با تولید سریع، کیفیت کلی قوی و ارزش بالا. معادل Tongyi Wanxiang 2.1 Speed.",
  "whisper-1.description": "مدل عمومی تشخیص گفتار با پشتیبانی از ASR چندزبانه، ترجمه گفتار و شناسایی زبان.",
  "wizardlm2.description": "WizardLM 2 مدل زبانی از Microsoft AI است که در گفت‌وگوی پیچیده، وظایف چندزبانه، استدلال و دستیارها عملکرد عالی دارد.",
  "wizardlm2:8x22b.description": "WizardLM 2 مدل زبانی از Microsoft AI است که در گفت‌وگوی پیچیده، وظایف چندزبانه، استدلال و دستیارها عملکرد عالی دارد.",
  "x-ai/grok-4-fast-non-reasoning.description": "Grok 4 Fast (بدون استدلال) مدل چندوجهی با توان عملیاتی بالا و هزینه پایین از xAI است (با پشتیبانی از پنجره زمینه ۲ میلیون توکن) که برای سناریوهای حساس به تأخیر و هزینه طراحی شده و نیازی به استدلال درون‌مدلی ندارد. این مدل در کنار نسخه استدلالی Grok 4 Fast قرار دارد و می‌توان استدلال را از طریق پارامتر API فعال کرد. اعلان‌ها و تکمیل‌ها ممکن است توسط xAI یا OpenRouter برای بهبود مدل‌های آینده استفاده شوند.",
  "x-ai/grok-4-fast.description": "Grok 4 Fast مدل با توان عملیاتی بالا و هزینه پایین از xAI است (با پشتیبانی از پنجره زمینه ۲ میلیون توکن) که برای موارد استفاده با هم‌زمانی بالا و زمینه‌های طولانی ایده‌آل است.",
  "x-ai/grok-4.1-fast-non-reasoning.description": "Grok 4 Fast (بدون استدلال) مدل چندوجهی با توان عملیاتی بالا و هزینه پایین از xAI است (با پشتیبانی از پنجره زمینه ۲ میلیون توکن) که برای سناریوهای حساس به تأخیر و هزینه طراحی شده و نیازی به استدلال درون‌مدلی ندارد. این مدل در کنار نسخه استدلالی Grok 4 Fast قرار دارد و می‌توان استدلال را از طریق پارامتر API فعال کرد. اعلان‌ها و تکمیل‌ها ممکن است توسط xAI یا OpenRouter برای بهبود مدل‌های آینده استفاده شوند.",
  "x-ai/grok-4.1-fast.description": "Grok 4 Fast مدل با توان عملیاتی بالا و هزینه پایین از xAI است (با پشتیبانی از پنجره زمینه ۲ میلیون توکن) که برای موارد استفاده با هم‌زمانی بالا و زمینه‌های طولانی ایده‌آل است.",
  "x-ai/grok-4.description": "Grok 4 مدل پرچم‌دار xAI با توانایی استدلال قوی و قابلیت چندوجهی است.",
  "x-ai/grok-code-fast-1.description": "Grok Code Fast 1 مدل سریع کدنویسی از xAI است که خروجی‌هایی خوانا و مناسب برای مهندسی ارائه می‌دهد.",
  "xai/grok-2-vision.description": "Grok 2 Vision در وظایف بصری عملکردی عالی دارد و در استدلال ریاضی تصویری (MathVista) و پرسش‌وپاسخ اسناد (DocVQA) به سطح SOTA می‌رسد. این مدل اسناد، نمودارها، گراف‌ها، اسکرین‌شات‌ها و عکس‌ها را پردازش می‌کند.",
  "xai/grok-2.description": "Grok 2 یک مدل پیشرفته با استدلال پیشرفته، چت قوی، کدنویسی و عملکرد استدلالی عالی است که در رتبه‌بندی LMSYS بالاتر از Claude 3.5 Sonnet و GPT-4 Turbo قرار دارد.",
  "xai/grok-3-fast.description": "مدل پرچم‌دار xAI در کاربردهای سازمانی مانند استخراج داده، کدنویسی و خلاصه‌سازی برتری دارد و دانش عمیقی در حوزه‌های مالی، سلامت، حقوق و علوم دارد. نسخه سریع آن بر زیرساخت سریع‌تری اجرا می‌شود و پاسخ‌های بسیار سریع‌تری با هزینه بیشتر به ازای هر توکن ارائه می‌دهد.",
  "xai/grok-3-mini-fast.description": "مدل سبک xAI که پیش از پاسخ‌دهی فکر می‌کند، مناسب برای وظایف ساده یا مبتنی بر منطق بدون نیاز به دانش عمیق حوزه‌ای است. ردپای خام استدلال در دسترس است. نسخه سریع آن بر زیرساخت سریع‌تری اجرا می‌شود و پاسخ‌های بسیار سریع‌تری با هزینه بیشتر به ازای هر توکن ارائه می‌دهد.",
  "xai/grok-3-mini.description": "مدل سبک xAI که پیش از پاسخ‌دهی فکر می‌کند، مناسب برای وظایف ساده یا مبتنی بر منطق بدون نیاز به دانش عمیق حوزه‌ای است. ردپای خام استدلال در دسترس است.",
  "xai/grok-3.description": "مدل پرچم‌دار xAI در کاربردهای سازمانی مانند استخراج داده، کدنویسی و خلاصه‌سازی برتری دارد و دانش عمیقی در حوزه‌های مالی، سلامت، حقوق و علوم دارد.",
  "xai/grok-4.description": "جدیدترین مدل پرچم‌دار xAI با عملکرد بی‌نظیر در زبان طبیعی، ریاضی و استدلال — یک مدل همه‌کاره ایده‌آل.",
  "yi-large-fc.description": "بر پایه yi-large با قابلیت فراخوانی ابزار پیشرفته، مناسب برای سناریوهای عامل و جریان کاری.",
  "yi-large-preview.description": "نسخه اولیه؛ استفاده از yi-large (جدیدتر) توصیه می‌شود.",
  "yi-large-rag.description": "یک سرویس پیشرفته بر پایه yi-large که بازیابی و تولید را برای پاسخ‌های دقیق با جستجوی وب در زمان واقعی ترکیب می‌کند.",
  "yi-large-turbo.description": "ارزش و عملکرد استثنایی، تنظیم‌شده برای تعادل قوی میان کیفیت، سرعت و هزینه.",
  "yi-large.description": "مدلی جدید با ۱۰۰ میلیارد پارامتر و توانایی قوی در پرسش‌وپاسخ و تولید متن.",
  "yi-lightning-lite.description": "نسخه سبک؛ استفاده از yi-lightning توصیه می‌شود.",
  "yi-lightning.description": "مدل جدید با عملکرد بالا، استنتاج سریع‌تر و خروجی با کیفیت بالا.",
  "yi-medium-200k.description": "مدلی با زمینه طولانی ۲۰۰ هزار توکن برای درک و تولید عمیق متون بلند.",
  "yi-medium.description": "مدل میان‌رده تنظیم‌شده با توانایی و ارزش متعادل، بهینه‌شده برای پیروی از دستورالعمل‌ها.",
  "yi-spark.description": "مدلی جمع‌وجور و سریع با توانایی تقویت‌شده در ریاضی و برنامه‌نویسی.",
  "yi-vision-v2.description": "مدل بینایی برای وظایف پیچیده با درک و تحلیل قوی چندتصویری.",
  "yi-vision.description": "مدل بینایی برای وظایف پیچیده با درک و تحلیل قوی تصویر.",
  "z-ai/glm-4.5-air.description": "GLM 4.5 Air نسخه سبک GLM 4.5 برای سناریوهای حساس به هزینه است که در عین حال استدلال قوی را حفظ می‌کند.",
  "z-ai/glm-4.5.description": "GLM 4.5 مدل پرچم‌دار Z.AI با استدلال ترکیبی بهینه‌شده برای وظایف مهندسی و زمینه‌های طولانی است.",
  "z-ai/glm-4.6.description": "GLM 4.6 مدل پرچم‌دار Z.AI با طول زمینه گسترش‌یافته و قابلیت برنامه‌نویسی است.",
  "z-ai/glm-4.7.description": "GLM-4.7 جدیدترین مدل پرچم‌دار Zhipu است که توانایی‌های عمومی بهبود یافته، پاسخ‌های طبیعی‌تر و تجربه نوشتاری جذاب‌تری ارائه می‌دهد.",
  "zai-org/GLM-4.5-Air.description": "GLM-4.5-Air یک مدل پایه برای برنامه‌های عامل با معماری Mixture-of-Experts است. این مدل برای استفاده از ابزار، مرور وب، مهندسی نرم‌افزار و کدنویسی فرانت‌اند بهینه شده و با عامل‌های کد مانند Claude Code و Roo Code ادغام می‌شود. از استدلال ترکیبی برای مدیریت وظایف پیچیده و روزمره استفاده می‌کند.",
  "zai-org/GLM-4.5.description": "GLM-4.5 یک مدل پایه برای برنامه‌های عامل با معماری Mixture-of-Experts است. این مدل برای استفاده از ابزار، مرور وب، مهندسی نرم‌افزار و کدنویسی فرانت‌اند به‌طور عمیق بهینه شده و با عامل‌های کد مانند Claude Code و Roo Code ادغام می‌شود. از استدلال ترکیبی برای مدیریت وظایف پیچیده و روزمره استفاده می‌کند.",
  "zai-org/GLM-4.5V.description": "GLM-4.5V جدیدترین مدل VLM از Zhipu AI است که بر پایه مدل متنی پرچم‌دار GLM-4.5-Air (با ۱۰۶ میلیارد پارامتر کل و ۱۲ میلیارد فعال) ساخته شده و از معماری MoE برای عملکرد قوی با هزینه کمتر بهره می‌برد. این مدل مسیر GLM-4.1V-Thinking را دنبال کرده و با افزودن 3D-RoPE استدلال فضایی سه‌بعدی را بهبود می‌بخشد. با پیش‌آموزش، SFT و RL بهینه‌سازی شده و تصاویر، ویدیو و اسناد بلند را پردازش می‌کند و در ۴۱ معیار چندوجهی عمومی در میان مدل‌های متن‌باز رتبه برتر دارد. حالت تفکر قابل تنظیم به کاربران امکان می‌دهد بین سرعت و عمق تعادل برقرار کنند.",
  "zai-org/GLM-4.6.description": "در مقایسه با GLM-4.5، مدل GLM-4.6 زمینه را از ۱۲۸ هزار به ۲۰۰ هزار توکن گسترش می‌دهد تا وظایف عامل پیچیده‌تری را مدیریت کند. در معیارهای کد امتیاز بالاتری کسب کرده و عملکرد واقعی بهتری در برنامه‌هایی مانند Claude Code، Cline، Roo Code و Kilo Code دارد، از جمله تولید بهتر صفحات فرانت‌اند. استدلال بهبود یافته و استفاده از ابزار در حین استدلال پشتیبانی می‌شود که توانایی کلی را تقویت می‌کند. این مدل بهتر در چارچوب‌های عامل ادغام می‌شود، عامل‌های ابزار/جستجو را بهبود می‌بخشد و سبک نوشتاری و نقش‌آفرینی طبیعی‌تری دارد.",
  "zai/glm-4.5-air.description": "GLM-4.5 و GLM-4.5-Air جدیدترین مدل‌های پرچم‌دار ما برای برنامه‌های عامل هستند که هر دو از معماری MoE استفاده می‌کنند. GLM-4.5 دارای ۳۵۵ میلیارد پارامتر کل و ۳۲ میلیارد فعال در هر عبور است؛ GLM-4.5-Air نسخه سبک‌تر با ۱۰۶ میلیارد کل و ۱۲ میلیارد فعال است.",
  "zai/glm-4.5.description": "سری GLM-4.5 برای عامل‌ها طراحی شده است. مدل پرچم‌دار GLM-4.5 استدلال، کدنویسی و مهارت‌های عامل را با ۳۵۵ میلیارد پارامتر کل (۳۲ میلیارد فعال) ترکیب می‌کند و دو حالت عملیاتی به‌عنوان یک سیستم استدلال ترکیبی ارائه می‌دهد.",
  "zai/glm-4.5v.description": "GLM-4.5V بر پایه GLM-4.5-Air ساخته شده، تکنیک‌های اثبات‌شده GLM-4.1V-Thinking را به ارث برده و با معماری MoE قدرتمند ۱۰۶ میلیارد پارامتری مقیاس یافته است.",
  "zenmux/auto.description": "مسیریابی خودکار ZenMux بهترین مدل از نظر ارزش و عملکرد را بر اساس درخواست شما از میان گزینه‌های پشتیبانی‌شده انتخاب می‌کند."
}
