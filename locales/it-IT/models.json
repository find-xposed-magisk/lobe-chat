{
  "01-ai/yi-1.5-34b-chat.description": "Il più recente modello open-source di 01.AI, ottimizzato con 34 miliardi di parametri. Supporta molteplici scenari di dialogo, è addestrato su dati di alta qualità e allineato alle preferenze umane.",
  "01-ai/yi-1.5-9b-chat.description": "Il più recente modello open-source di 01.AI, ottimizzato con 9 miliardi di parametri. Supporta molteplici scenari di dialogo, è addestrato su dati di alta qualità e allineato alle preferenze umane.",
  "360/deepseek-r1.description": "DeepSeek-R1 distribuito su 360 utilizza l'apprendimento per rinforzo su larga scala nella fase di post-addestramento per migliorare notevolmente il ragionamento con un numero minimo di etichette. Raggiunge le prestazioni del modello OpenAI o1 nei compiti di matematica, programmazione e ragionamento in linguaggio naturale.",
  "360gpt-pro-trans.description": "Modello specializzato nella traduzione, ottimizzato in profondità per offrire una qualità di traduzione di livello superiore.",
  "360gpt-pro.description": "360GPT Pro è un modello chiave di 360 AI per l'elaborazione efficiente del testo in scenari NLP diversificati, con supporto per la comprensione di testi lunghi e dialoghi multi-turno.",
  "360gpt-turbo-responsibility-8k.description": "360GPT Turbo Responsibility 8K pone l'accento sulla sicurezza semantica e la responsabilità nei contesti sensibili, garantendo esperienze utente accurate e affidabili.",
  "360gpt-turbo.description": "360GPT Turbo offre elevate capacità di calcolo e conversazione, con eccellente comprensione semantica ed efficienza generativa, ideale per aziende e sviluppatori.",
  "360gpt2-o1.description": "360gpt2-o1 costruisce catene di pensiero tramite ricerca ad albero con meccanismo di riflessione e addestramento con RL, abilitando auto-riflessione e auto-correzione.",
  "360gpt2-pro.description": "360GPT2 Pro è un modello NLP avanzato di 360 con eccellenti capacità di generazione e comprensione del testo, particolarmente adatto a compiti creativi, trasformazioni complesse e simulazioni di ruolo.",
  "360zhinao2-o1.description": "360zhinao2-o1 costruisce catene di pensiero tramite ricerca ad albero con meccanismo di riflessione e addestramento con RL, abilitando auto-riflessione e auto-correzione.",
  "4.0Ultra.description": "Spark Ultra è il modello più potente della serie Spark, migliora la comprensione e il riassunto del testo e potenzia la ricerca web. È una soluzione completa per aumentare la produttività sul lavoro e fornire risposte accurate, posizionandosi come prodotto intelligente leader.",
  "AnimeSharp.description": "AnimeSharp (noto anche come \"4x-AnimeSharp\") è un modello open-source di super-risoluzione basato su ESRGAN di Kim2091, focalizzato sull'ingrandimento e la nitidezza delle immagini in stile anime. È stato rinominato da \"4x-TextSharpV1\" nel febbraio 2022, originariamente pensato anche per immagini testuali ma fortemente ottimizzato per contenuti anime.",
  "Baichuan2-Turbo.description": "Utilizza l'augmentazione tramite ricerca per collegare il modello alla conoscenza di dominio e del web. Supporta caricamenti PDF/Word e input tramite URL per un recupero tempestivo e completo, con output professionali e accurati.",
  "Baichuan3-Turbo-128k.description": "Con una finestra di contesto ultra-lunga da 128K, è ottimizzato per scenari aziendali ad alta frequenza, con miglioramenti significativi. Rispetto a Baichuan2, la creazione di contenuti migliora del 20%, le risposte a domande di conoscenza del 17% e le simulazioni di ruolo del 40%. Le prestazioni complessive superano GPT-3.5.",
  "Baichuan3-Turbo.description": "Ottimizzato per scenari aziendali ad alta frequenza, con miglioramenti significativi. Rispetto a Baichuan2, la creazione di contenuti migliora del 20%, le risposte a domande di conoscenza del 17% e le simulazioni di ruolo del 40%. Le prestazioni complessive superano GPT-3.5.",
  "Baichuan4-Air.description": "Modello di punta in Cina, supera i principali modelli esteri nei compiti in lingua cinese come conoscenza, testi lunghi e generazione creativa. Presenta anche capacità multimodali all'avanguardia con risultati eccellenti nei benchmark autorevoli.",
  "Baichuan4-Turbo.description": "Modello di punta in Cina, supera i principali modelli esteri nei compiti in lingua cinese come conoscenza, testi lunghi e generazione creativa. Presenta anche capacità multimodali all'avanguardia con risultati eccellenti nei benchmark autorevoli.",
  "Baichuan4.description": "Prestazioni nazionali al top, superiori ai principali modelli esteri nei compiti in lingua cinese come conoscenza enciclopedica, testi lunghi e generazione creativa. Offre anche capacità multimodali all'avanguardia e risultati eccellenti nei benchmark.",
  "ByteDance-Seed/Seed-OSS-36B-Instruct.description": "Seed-OSS è una famiglia di LLM open-source di ByteDance Seed, progettata per una gestione efficace di contesti lunghi, ragionamento, agenti e capacità generali. Seed-OSS-36B-Instruct è un modello da 36B ottimizzato per istruzioni, con contesto ultra-lungo nativo per elaborare documenti o basi di codice estesi. Ottimizzato per ragionamento, generazione di codice e compiti agentici (uso di strumenti), mantiene forti capacità generali. Una caratteristica chiave è il \"Thinking Budget\", che consente una lunghezza di ragionamento flessibile per migliorare l'efficienza.",
  "DeepSeek-R1-Distill-Llama-70B.description": "DeepSeek R1, il modello più grande e intelligente della suite DeepSeek, è stato distillato nell'architettura Llama 70B. I benchmark e le valutazioni umane dimostrano che è più intelligente del Llama 70B base, in particolare nei compiti di matematica e precisione dei fatti.",
  "DeepSeek-R1-Distill-Qwen-1.5B.description": "Un modello distillato DeepSeek-R1 basato su Qwen2.5-Math-1.5B. L'apprendimento per rinforzo e i dati di avvio a freddo ottimizzano le prestazioni di ragionamento, stabilendo nuovi benchmark multi-task per i modelli open-source.",
  "DeepSeek-R1-Distill-Qwen-14B.description": "I modelli DeepSeek-R1-Distill sono ottimizzati a partire da modelli open-source utilizzando dati campione generati da DeepSeek-R1.",
  "DeepSeek-R1-Distill-Qwen-32B.description": "I modelli DeepSeek-R1-Distill sono ottimizzati a partire da modelli open-source utilizzando dati campione generati da DeepSeek-R1.",
  "DeepSeek-R1-Distill-Qwen-7B.description": "Un modello distillato DeepSeek-R1 basato su Qwen2.5-Math-7B. L'apprendimento per rinforzo e i dati di avvio a freddo ottimizzano le prestazioni di ragionamento, stabilendo nuovi benchmark multi-task per i modelli open-source.",
  "DeepSeek-R1.description": "DeepSeek-R1 applica l'apprendimento per rinforzo su larga scala nella fase di post-addestramento, migliorando notevolmente il ragionamento con pochissimi dati etichettati. Raggiunge le prestazioni del modello OpenAI o1 nei compiti di matematica, programmazione e ragionamento in linguaggio naturale.",
  "DeepSeek-V3-1.description": "DeepSeek V3.1 è un modello di ragionamento di nuova generazione con miglioramenti nel ragionamento complesso e nella catena di pensiero, adatto ad attività di analisi approfondita.",
  "DeepSeek-V3-Fast.description": "Fornitore: sophnet. DeepSeek V3 Fast è la versione ad alta velocità di DeepSeek V3 0324, a precisione completa (non quantizzata), con prestazioni superiori in programmazione e matematica e risposte più rapide.",
  "DeepSeek-V3.1-Fast.description": "DeepSeek V3.1 Fast è la variante veloce ad alta velocità di DeepSeek V3.1. Modalità di pensiero ibrida: tramite template di chat, un solo modello supporta modalità con e senza pensiero. Uso più intelligente degli strumenti: il post-addestramento migliora le prestazioni nei compiti agentici e nell'uso degli strumenti.",
  "DeepSeek-V3.1-Think.description": "Modalità di pensiero DeepSeek-V3.1: un nuovo modello di ragionamento ibrido con modalità di pensiero e non-pensiero, più efficiente di DeepSeek-R1-0528. Le ottimizzazioni post-addestramento migliorano significativamente l'uso degli strumenti agentici e le prestazioni nei compiti agentici.",
  "DeepSeek-V3.description": "DeepSeek-V3 è un modello MoE sviluppato da DeepSeek. Supera altri modelli open-source come Qwen2.5-72B e Llama-3.1-405B in molti benchmark ed è competitivo con i principali modelli chiusi come GPT-4o e Claude 3.5 Sonnet.",
  "Doubao-lite-128k.description": "Doubao-lite offre risposte ultra-rapide e un ottimo rapporto qualità/prezzo, con opzioni flessibili per diversi scenari. Supporta un contesto di 128K per inferenza e fine-tuning.",
  "Doubao-lite-32k.description": "Doubao-lite offre risposte ultra-rapide e un ottimo rapporto qualità/prezzo, con opzioni flessibili per diversi scenari. Supporta un contesto di 32K per inferenza e fine-tuning.",
  "Doubao-lite-4k.description": "Doubao-lite offre risposte ultra-rapide e un ottimo rapporto qualità/prezzo, con opzioni flessibili per diversi scenari. Supporta un contesto di 4K per inferenza e fine-tuning.",
  "Doubao-pro-128k.description": "Modello di punta con le migliori prestazioni per compiti complessi, eccellente in QA con fonti, riassunti, creazione, classificazione e simulazioni di ruolo. Supporta un contesto di 128K per inferenza e fine-tuning.",
  "Doubao-pro-32k.description": "Modello di punta con le migliori prestazioni per compiti complessi, eccellente in QA con fonti, riassunti, creazione, classificazione e simulazioni di ruolo. Supporta un contesto di 32K per inferenza e fine-tuning.",
  "Doubao-pro-4k.description": "Modello di punta con le migliori prestazioni per compiti complessi, eccellente in QA con fonti, riassunti, creazione, classificazione e simulazioni di ruolo. Supporta un contesto di 4K per inferenza e fine-tuning.",
  "DreamO.description": "DreamO è un modello open-source per la personalizzazione delle immagini sviluppato congiuntamente da ByteDance e l'Università di Pechino, che utilizza un'architettura unificata per supportare la generazione di immagini multi-task. Impiega una modellazione compositiva efficiente per generare immagini altamente coerenti e personalizzate in base a identità, soggetto, stile, sfondo e altre condizioni specificate dall'utente.",
  "ERNIE-3.5-128K.description": "Modello LLM di punta di Baidu, addestrato su vasti corpora in cinese e inglese, con eccellenti capacità generali per chat, creazione e utilizzo di plugin; supporta l'integrazione automatica del plugin Baidu Search per risposte aggiornate.",
  "ERNIE-3.5-8K-Preview.description": "Modello LLM di punta di Baidu, addestrato su vasti corpora in cinese e inglese, con eccellenti capacità generali per chat, creazione e utilizzo di plugin; supporta l'integrazione automatica del plugin Baidu Search per risposte aggiornate.",
  "ERNIE-3.5-8K.description": "Modello LLM di punta di Baidu, addestrato su vasti corpora in cinese e inglese, con eccellenti capacità generali per chat, creazione e utilizzo di plugin; supporta l'integrazione automatica del plugin Baidu Search per risposte aggiornate.",
  "ERNIE-4.0-8K-Latest.description": "Modello LLM ultra-avanzato di Baidu con aggiornamenti completi rispetto a ERNIE 3.5, adatto a compiti complessi in diversi ambiti; supporta l'integrazione del plugin Baidu Search per risposte aggiornate.",
  "ERNIE-4.0-8K-Preview.description": "Modello LLM ultra-avanzato di Baidu con aggiornamenti completi rispetto a ERNIE 3.5, adatto a compiti complessi in diversi ambiti; supporta l'integrazione del plugin Baidu Search per risposte aggiornate.",
  "ERNIE-4.0-Turbo-8K-Latest.description": "Modello LLM ultra-avanzato di Baidu con prestazioni generali elevate per compiti complessi, con integrazione del plugin Baidu Search per risposte aggiornate. Supera le prestazioni di ERNIE 4.0.",
  "ERNIE-4.0-Turbo-8K-Preview.description": "Modello LLM ultra-avanzato di Baidu con prestazioni generali elevate per compiti complessi, con integrazione del plugin Baidu Search per risposte aggiornate. Supera le prestazioni di ERNIE 4.0.",
  "ERNIE-Character-8K.description": "Modello LLM di Baidu per domini verticali come NPC nei giochi, assistenza clienti e roleplay, con maggiore coerenza del personaggio, migliore comprensione delle istruzioni e capacità di ragionamento potenziate.",
  "ERNIE-Lite-Pro-128K.description": "Modello LLM leggero di Baidu che bilancia qualità e prestazioni di inferenza, superiore a ERNIE Lite e adatto ad acceleratori a bassa potenza.",
  "ERNIE-Speed-128K.description": "Ultimo modello LLM ad alte prestazioni di Baidu (2024) con forti capacità generali, ideale come base per il fine-tuning in scenari specifici, con eccellenti prestazioni di ragionamento.",
  "ERNIE-Speed-Pro-128K.description": "Ultimo modello LLM ad alte prestazioni di Baidu (2024) con forti capacità generali, superiore a ERNIE Speed, ideale come base per il fine-tuning con eccellenti prestazioni di ragionamento.",
  "FLUX-1.1-pro.description": "FLUX.1.1 Pro",
  "FLUX.1-Kontext-dev.description": "FLUX.1-Kontext-dev è un modello multimodale per generazione ed editing di immagini sviluppato da Black Forest Labs, basato su un'architettura Rectified Flow Transformer con 12 miliardi di parametri. Si concentra sulla generazione, ricostruzione, miglioramento o modifica di immagini in base a condizioni contestuali. Combina la generazione controllabile dei modelli di diffusione con la modellazione contestuale dei Transformer, supportando output di alta qualità per compiti come inpainting, outpainting e ricostruzione di scene visive.",
  "FLUX.1-Kontext-pro.description": "FLUX.1 Kontext [pro]",
  "FLUX.1-dev.description": "FLUX.1-dev è un modello linguistico multimodale open-source (MLLM) di Black Forest Labs, ottimizzato per compiti immagine-testo e in grado di comprendere e generare contenuti visivi e testuali. Basato su LLM avanzati (come Mistral-7B), utilizza un encoder visivo progettato con cura e un tuning a più stadi per abilitare il coordinamento multimodale e il ragionamento su compiti complessi.",
  "Gryphe/MythoMax-L2-13b.description": "MythoMax-L2 (13B) è un modello innovativo per domini diversificati e compiti complessi.",
  "HelloMeme.description": "HelloMeme è uno strumento AI che genera meme, GIF o brevi video a partire da immagini o movimenti forniti. Non richiede abilità di disegno o programmazione: basta un'immagine di riferimento per creare contenuti divertenti, accattivanti e stilisticamente coerenti.",
  "HiDream-I1-Full.description": "HiDream-E1-Full è un modello open-source per l'editing multimodale di immagini sviluppato da HiDream.ai, basato su un'architettura Diffusion Transformer avanzata e una solida comprensione linguistica (con LLaMA 3.1-8B-Instruct integrato). Supporta generazione di immagini guidata da linguaggio naturale, trasferimento di stile, modifiche locali e ritinteggiatura, con eccellente comprensione ed esecuzione immagine-testo.",
  "HunyuanDiT-v1.2-Diffusers-Distilled.description": "hunyuandit-v1.2-distilled è un modello leggero text-to-image ottimizzato tramite distillazione per generare immagini di alta qualità in modo rapido, particolarmente adatto ad ambienti con risorse limitate e generazione in tempo reale.",
  "InstantCharacter.description": "InstantCharacter è un modello di generazione di personaggi personalizzati senza tuning, rilasciato da Tencent AI nel 2025, progettato per una generazione fedele e coerente di personaggi in diversi scenari. Può modellare un personaggio da una singola immagine di riferimento e trasferirlo con flessibilità tra stili, azioni e sfondi.",
  "InternVL2-8B.description": "InternVL2-8B è un potente modello visione-linguaggio che supporta l'elaborazione multimodale immagine-testo, riconoscendo accuratamente i contenuti visivi e generando descrizioni o risposte pertinenti.",
  "InternVL2.5-26B.description": "InternVL2.5-26B è un potente modello visione-linguaggio che supporta l'elaborazione multimodale immagine-testo, riconoscendo accuratamente i contenuti visivi e generando descrizioni o risposte pertinenti.",
  "Kolors.description": "Kolors è un modello text-to-image sviluppato dal team Kuaishou Kolors. Addestrato con miliardi di parametri, offre vantaggi notevoli in qualità visiva, comprensione semantica del cinese e resa del testo.",
  "Kwai-Kolors/Kolors.description": "Kolors è un modello text-to-image a diffusione latente su larga scala sviluppato dal team Kuaishou Kolors. Addestrato su miliardi di coppie testo-immagine, eccelle in qualità visiva, accuratezza semantica complessa e resa del testo in cinese/inglese, con forte comprensione e generazione di contenuti in cinese.",
  "Kwaipilot/KAT-Dev.description": "KAT-Dev (32B) è un modello open-source da 32 miliardi di parametri per compiti di ingegneria del software. Raggiunge un tasso di risoluzione del 62,4% su SWE-Bench Verified, classificandosi al 5° posto tra i modelli open. È ottimizzato tramite mid-training, SFT e RL per completamento del codice, correzione di bug e revisione del codice.",
  "Llama-3.2-11B-Vision-Instruct.description": "Solido ragionamento visivo su immagini ad alta risoluzione, adatto ad applicazioni di comprensione visiva.",
  "Llama-3.2-90B-Vision-Instruct\t.description": "Ragionamento visivo avanzato per applicazioni di agenti con comprensione visiva.",
  "Meta-Llama-3-3-70B-Instruct.description": "Llama 3.3 70B è un modello Transformer versatile per compiti di chat e generazione.",
  "Meta-Llama-3.1-405B-Instruct.description": "Modello testuale Llama 3.1 ottimizzato per chat multilingue, con prestazioni elevate nei benchmark industriali tra modelli open e closed.",
  "Meta-Llama-3.1-70B-Instruct.description": "Modello testuale Llama 3.1 ottimizzato per chat multilingue, con prestazioni elevate nei benchmark industriali tra modelli open e closed.",
  "Meta-Llama-3.1-8B-Instruct.description": "Modello testuale Llama 3.1 ottimizzato per chat multilingue, con prestazioni elevate nei benchmark industriali tra modelli open e closed.",
  "Meta-Llama-3.2-1B-Instruct.description": "Modello linguistico compatto all'avanguardia con forte comprensione del linguaggio, eccellente ragionamento e generazione testuale.",
  "Meta-Llama-3.2-3B-Instruct.description": "Modello linguistico compatto all'avanguardia con forte comprensione del linguaggio, eccellente ragionamento e generazione testuale.",
  "Meta-Llama-3.3-70B-Instruct.description": "Llama 3.3 è il modello Llama open-source multilingue più avanzato, con prestazioni vicine a quelle del 405B a costi molto contenuti. Basato su Transformer, è migliorato con SFT e RLHF per utilità e sicurezza. La versione instruction-tuned è ottimizzata per chat multilingue e supera molti modelli open e closed nei benchmark industriali. Data di cutoff: dicembre 2023.",
  "Meta-Llama-4-Maverick-17B-128E-Instruct-FP8.description": "Llama 4 Maverick è un grande modello MoE con attivazione efficiente degli esperti per prestazioni di ragionamento elevate.",
  "MiniMax-M1.description": "Nuovo modello di ragionamento proprietario con 80K chain-of-thought e 1M di input, con prestazioni comparabili ai migliori modelli globali.",
  "MiniMax-M2-Stable.description": "Progettato per flussi di lavoro di codifica e agenti efficienti, con maggiore concorrenza per l'uso commerciale.",
  "MiniMax-M2.1-Lightning.description": "Potenti capacità di programmazione multilingue e un'esperienza di sviluppo completamente rinnovata. Più veloce ed efficiente.",
  "MiniMax-M2.1.description": "MiniMax-M2.1 è un modello open-source di punta di MiniMax, progettato per affrontare compiti complessi del mondo reale. I suoi punti di forza principali sono le capacità di programmazione multilingue e la risoluzione di compiti complessi come agente.",
  "MiniMax-M2.description": "Progettato specificamente per una programmazione efficiente e flussi di lavoro con agenti",
  "MiniMax-Text-01.description": "MiniMax-01 introduce l'attenzione lineare su larga scala oltre i Transformer classici, con 456B parametri e 45,9B attivati per passaggio. Raggiunge prestazioni di alto livello e supporta fino a 4M token di contesto (32× GPT-4o, 20× Claude-3.5-Sonnet).",
  "MiniMaxAI/MiniMax-M1-80k.description": "MiniMax-M1 è un modello di ragionamento ibrido su larga scala con pesi open, 456B parametri totali e ~45,9B attivi per token. Supporta nativamente 1M di contesto e utilizza Flash Attention per ridurre i FLOPs del 75% nella generazione di 100K token rispetto a DeepSeek R1. Con architettura MoE, CISPO e addestramento RL ibrido, raggiunge prestazioni leader su ragionamento con input lunghi e compiti reali di ingegneria del software.",
  "MiniMaxAI/MiniMax-M2.description": "MiniMax-M2 ridefinisce l'efficienza degli agenti. È un modello MoE compatto, veloce ed economico con 230B parametri totali e 10B attivi, progettato per compiti di codifica e agenti di alto livello mantenendo una forte intelligenza generale. Con soli 10B parametri attivi, rivaleggia con modelli molto più grandi, rendendolo ideale per applicazioni ad alta efficienza.",
  "Moonshot-Kimi-K2-Instruct.description": "1T parametri totali con 32B attivi. Tra i modelli non pensanti, è tra i migliori per conoscenze avanzate, matematica e programmazione, ed è più forte nei compiti generali da agente. Ottimizzato per carichi di lavoro da agente, può eseguire azioni, non solo rispondere a domande. Ideale per conversazioni improvvisate, chat generali e esperienze da agente, come modello reattivo senza riflessione prolungata.",
  "NousResearch/Nous-Hermes-2-Mixtral-8x7B-DPO.description": "Nous Hermes 2 - Mixtral 8x7B-DPO (46,7B) è un modello ad alta precisione per istruzioni complesse e calcoli avanzati.",
  "OmniConsistency.description": "OmniConsistency migliora la coerenza stilistica e la generalizzazione nei compiti immagine-a-immagine introducendo Diffusion Transformers (DiTs) su larga scala e dati stilizzati accoppiati, evitando il degrado dello stile.",
  "PaddlePaddle/PaddleOCR-VL-1.5.description": "PaddleOCR-VL-1.5 è una versione aggiornata della serie PaddleOCR-VL, che raggiunge un'accuratezza del 94,5% nel benchmark di parsing documentale OmniDocBench v1.5, superando i principali modelli generali e specializzati. Supporta in modo innovativo la localizzazione di riquadri irregolari per elementi documentali, gestendo efficacemente immagini scansionate, inclinate e catturate da schermo.",
  "Phi-3-medium-128k-instruct.description": "Lo stesso modello Phi-3-medium con una finestra contestuale più ampia per prompt RAG o few-shot.",
  "Phi-3-medium-4k-instruct.description": "Un modello da 14B parametri con qualità superiore rispetto a Phi-3-mini, focalizzato su dati di alta qualità e ad alta intensità di ragionamento.",
  "Phi-3-mini-128k-instruct.description": "Lo stesso modello Phi-3-mini con una finestra contestuale più ampia per prompt RAG o few-shot.",
  "Phi-3-mini-4k-instruct.description": "Il membro più piccolo della famiglia Phi-3, ottimizzato per qualità e bassa latenza.",
  "Phi-3-small-128k-instruct.description": "Lo stesso modello Phi-3-small con una finestra contestuale più ampia per prompt RAG o few-shot.",
  "Phi-3-small-8k-instruct.description": "Un modello da 7B parametri con qualità superiore rispetto a Phi-3-mini, focalizzato su dati di alta qualità e ad alta intensità di ragionamento.",
  "Phi-3.5-mini-instruct.description": "Una versione aggiornata del modello Phi-3-mini.",
  "Phi-3.5-vision-instrust.description": "Una versione aggiornata del modello Phi-3-vision.",
  "Pro/MiniMaxAI/MiniMax-M2.1.description": "MiniMax-M2.1 è un modello linguistico di grandi dimensioni open-source ottimizzato per capacità agentiche, eccellente nella programmazione, nell'uso di strumenti, nel seguire istruzioni e nella pianificazione a lungo termine. Supporta lo sviluppo software multilingue e l'esecuzione di flussi di lavoro complessi a più fasi, ottenendo un punteggio di 74,0 su SWE-bench Verified e superando Claude Sonnet 4.5 in scenari multilingue.",
  "Pro/Qwen/Qwen2-7B-Instruct.description": "Qwen2-7B-Instruct è un LLM da 7B parametri ottimizzato per istruzioni nella serie Qwen2. Utilizza un'architettura Transformer con SwiGLU, bias QKV per l'attenzione e grouped-query attention, ed è in grado di gestire input di grandi dimensioni. Eccelle in comprensione linguistica, generazione, compiti multilingue, programmazione, matematica e ragionamento, superando la maggior parte dei modelli open-source e competendo con quelli proprietari. Supera Qwen1.5-7B-Chat in diversi benchmark.",
  "Pro/Qwen/Qwen2.5-7B-Instruct.description": "Qwen2.5-7B-Instruct fa parte della nuova serie LLM di Alibaba Cloud. Il modello da 7B offre miglioramenti significativi in programmazione e matematica, supporta oltre 29 lingue e migliora il rispetto delle istruzioni, la comprensione dei dati strutturati e la generazione di output strutturati (in particolare JSON).",
  "Pro/Qwen/Qwen2.5-Coder-7B-Instruct.description": "Qwen2.5-Coder-7B-Instruct è l'ultimo LLM di Alibaba Cloud focalizzato sul codice. Basato su Qwen2.5 e addestrato su 5,5T token, migliora notevolmente la generazione, il ragionamento e la correzione del codice, mantenendo al contempo le capacità matematiche e generali, fornendo una solida base per agenti di programmazione.",
  "Pro/Qwen/Qwen2.5-VL-7B-Instruct.description": "Qwen2.5-VL è un nuovo modello visione-linguaggio della serie Qwen con forte comprensione visiva. Analizza testo, grafici e layout nelle immagini, comprende video lunghi ed eventi, supporta il ragionamento e l'uso di strumenti, l'ancoraggio multi-formato degli oggetti e output strutturati. Migliora la risoluzione dinamica e l'addestramento a frame-rate per la comprensione video e aumenta l'efficienza dell'encoder visivo.",
  "Pro/THUDM/GLM-4.1V-9B-Thinking.description": "GLM-4.1V-9B-Thinking è un modello VLM open-source sviluppato da Zhipu AI e dal laboratorio KEG della Tsinghua, progettato per la cognizione multimodale complessa. Basato su GLM-4-9B-0414, aggiunge ragionamento a catena e apprendimento per rinforzo (RL) per migliorare significativamente il ragionamento cross-modale e la stabilità.",
  "Pro/THUDM/glm-4-9b-chat.description": "GLM-4-9B-Chat è il modello open-source GLM-4 di Zhipu AI. Eccelle in semantica, matematica, ragionamento, codice e conoscenza. Oltre alla chat multi-turno, supporta la navigazione web, l'esecuzione di codice, chiamate a strumenti personalizzati e ragionamento su testi lunghi. Supporta 26 lingue (tra cui cinese, inglese, giapponese, coreano, tedesco). Ottiene buoni risultati su AlignBench-v2, MT-Bench, MMLU e C-Eval, e supporta fino a 128K di contesto per usi accademici e aziendali.",
  "Pro/deepseek-ai/DeepSeek-R1-Distill-Qwen-7B.description": "DeepSeek-R1-Distill-Qwen-7B è distillato da Qwen2.5-Math-7B e ottimizzato su 800K campioni curati DeepSeek-R1. Ottiene ottimi risultati: 92,8% su MATH-500, 55,5% su AIME 2024 e un punteggio CodeForces di 1189 per un modello da 7B.",
  "Pro/deepseek-ai/DeepSeek-R1.description": "DeepSeek-R1 è un modello di ragionamento guidato da RL che riduce la ripetizione e migliora la leggibilità. Utilizza dati cold-start prima del RL per potenziare ulteriormente il ragionamento, eguaglia OpenAI-o1 in compiti di matematica, codice e ragionamento, migliorando i risultati complessivi grazie a un addestramento accurato.",
  "Pro/deepseek-ai/DeepSeek-V3.1-Terminus.description": "DeepSeek-V3.1-Terminus è una versione aggiornata del modello V3.1, posizionato come LLM ibrido per agenti. Risolve problemi segnalati dagli utenti e migliora la stabilità, la coerenza linguistica e riduce caratteri anomali e misti cinese/inglese. Integra modalità di pensiero e non-pensiero con template di chat per passaggi flessibili. Migliora anche le prestazioni di Code Agent e Search Agent per un uso più affidabile degli strumenti e compiti multi-step.",
  "Pro/deepseek-ai/DeepSeek-V3.2-Exp.description": "DeepSeek-V3.2-Exp è una versione sperimentale della serie V3.2 che fa da ponte verso la prossima architettura. Aggiunge DeepSeek Sparse Attention (DSA) sopra V3.1-Terminus per migliorare l'efficienza nell'addestramento e inferenza su contesti lunghi, con ottimizzazioni per l'uso di strumenti, comprensione di documenti lunghi e ragionamento multi-step. Ideale per esplorare una maggiore efficienza di ragionamento con budget di contesto elevati.",
  "Pro/deepseek-ai/DeepSeek-V3.description": "DeepSeek-V3 è un modello MoE da 671B parametri che utilizza MLA e DeepSeekMoE con bilanciamento del carico senza perdite per un'inferenza e addestramento efficienti. Preaddestrato su 14,8T token di alta qualità e ulteriormente ottimizzato con SFT e RL, supera altri modelli open-source e si avvicina ai modelli chiusi leader.",
  "Pro/moonshotai/Kimi-K2-Instruct-0905.description": "Kimi K2-Instruct-0905 è la versione più recente e potente di Kimi K2. È un modello MoE di fascia alta con 1T di parametri totali e 32B attivi. Le caratteristiche principali includono un'intelligenza di codifica agentica più forte con miglioramenti significativi nei benchmark e nei compiti reali da agente, oltre a una migliore estetica e usabilità del codice frontend.",
  "Pro/moonshotai/Kimi-K2-Thinking.description": "Kimi K2 Thinking Turbo è la variante Turbo ottimizzata per velocità di ragionamento e throughput, mantenendo il ragionamento multi-step e l'uso di strumenti di K2 Thinking. È un modello MoE con ~1T parametri totali, contesto nativo da 256K e chiamata stabile di strumenti su larga scala per scenari di produzione con requisiti più severi di latenza e concorrenza.",
  "Pro/moonshotai/Kimi-K2.5.description": "Kimi K2.5 è un modello agente multimodale nativo open-source, basato su Kimi-K2-Base, addestrato su circa 1,5 trilioni di token misti visivi e testuali. Il modello adotta un'architettura MoE con 1T di parametri totali e 32B attivi, supporta una finestra di contesto di 256K e integra perfettamente le capacità di comprensione visiva e linguistica.",
  "Pro/zai-org/glm-4.7.description": "GLM-4.7 è il modello di punta di nuova generazione di Zhipu, con 355 miliardi di parametri totali e 32 miliardi di parametri attivi, completamente aggiornato nelle capacità di dialogo generale, ragionamento e agenti. GLM-4.7 migliora il Pensiero Intercalato e introduce il Pensiero Conservato e il Pensiero a Livello di Turno.",
  "QwQ-32B-Preview.description": "Qwen QwQ è un modello di ricerca sperimentale focalizzato sul miglioramento del ragionamento.",
  "Qwen/QVQ-72B-Preview.description": "QVQ-72B-Preview è un modello di ricerca del team Qwen focalizzato sul ragionamento visivo, con punti di forza nella comprensione di scene complesse e nella risoluzione di problemi visivi di matematica.",
  "Qwen/QwQ-32B-Preview.description": "Qwen QwQ è un modello di ricerca sperimentale focalizzato sul miglioramento del ragionamento dell'IA.",
  "Qwen/QwQ-32B.description": "QwQ è un modello di ragionamento della famiglia Qwen. Rispetto ai modelli standard ottimizzati per seguire istruzioni, integra capacità di pensiero e ragionamento che migliorano significativamente le prestazioni nei compiti complessi. QwQ-32B è un modello di medie dimensioni competitivo con i migliori modelli di ragionamento come DeepSeek-R1 e o1-mini. Utilizza RoPE, SwiGLU, RMSNorm e bias QKV nell'attenzione, con 64 layer e 40 teste di attenzione Q (8 KV in GQA).",
  "Qwen/Qwen-Image-Edit-2509.description": "Qwen-Image-Edit-2509 è l'ultima versione di editing dell'immagine sviluppata dal team Qwen. Basato sul modello Qwen-Image da 20B, estende le potenti capacità di rendering del testo all'editing delle immagini per modifiche testuali precise. Utilizza un'architettura a doppio controllo, inviando gli input a Qwen2.5-VL per il controllo semantico e a un encoder VAE per il controllo dell'aspetto, consentendo modifiche sia semantiche che visive. Supporta modifiche locali (aggiunta/rimozione/modifica) e modifiche semantiche di alto livello come la creazione di IP e il trasferimento di stile, preservando il significato originale. Ottiene risultati SOTA in numerosi benchmark.",
  "Qwen/Qwen-Image.description": "Qwen-Image è un modello di base per la generazione di immagini con 20 miliardi di parametri, sviluppato dal team Qwen. Offre miglioramenti significativi nel rendering di testo complesso e nell'editing preciso delle immagini, in particolare per testi in cinese e inglese ad alta fedeltà. Supporta layout multilinea e paragrafi mantenendo la coerenza tipografica. Oltre al rendering testuale, supporta una vasta gamma di stili, dal fotorealistico all'anime, e funzionalità avanzate come trasferimento di stile, aggiunta/rimozione di oggetti, miglioramento dei dettagli, modifica del testo e controllo della posa, con l'obiettivo di essere una base completa per la creazione visiva.",
  "Qwen/Qwen2-72B-Instruct.description": "Qwen 2 Instruct (72B) offre un'esecuzione precisa delle istruzioni per carichi di lavoro aziendali.",
  "Qwen/Qwen2-7B-Instruct.description": "Qwen2-7B-Instruct è un modello da 7B ottimizzato per seguire istruzioni nella serie Qwen2, basato su Transformer, SwiGLU, bias QKV e attenzione a query raggruppate. Gestisce input di grandi dimensioni e si comporta molto bene in benchmark di comprensione, generazione, multilingua, programmazione, matematica e ragionamento, superando la maggior parte dei modelli open source e Qwen1.5-7B-Chat in diverse valutazioni.",
  "Qwen/Qwen2-VL-72B-Instruct.description": "Qwen2-VL è l'ultima versione del modello Qwen-VL, che raggiunge risultati SOTA in benchmark visivi come MathVista, DocVQA, RealWorldQA e MTVQA. È in grado di comprendere video di oltre 20 minuti per domande su video, dialoghi e creazione di contenuti. Supporta anche ragionamento complesso e decisioni, integrandosi con dispositivi/robot per azioni guidate dalla visione. Oltre all'inglese e al cinese, può leggere testi in molte lingue, tra cui la maggior parte delle lingue europee, giapponese, coreano, arabo e vietnamita.",
  "Qwen/Qwen2.5-14B-Instruct.description": "Qwen2.5-14B-Instruct fa parte della nuova serie LLM di Alibaba Cloud. Il modello da 14B offre miglioramenti significativi nella programmazione e nella matematica, supporta oltre 29 lingue e migliora l'esecuzione delle istruzioni, la comprensione dei dati strutturati e la generazione di output strutturati (in particolare JSON).",
  "Qwen/Qwen2.5-32B-Instruct.description": "Qwen2.5-32B-Instruct fa parte della nuova serie LLM di Alibaba Cloud. Il modello da 32B offre miglioramenti significativi nella programmazione e nella matematica, supporta oltre 29 lingue e migliora l'esecuzione delle istruzioni, la comprensione dei dati strutturati e la generazione di output strutturati (in particolare JSON).",
  "Qwen/Qwen2.5-72B-Instruct-128K.description": "Qwen2.5-72B-Instruct fa parte della nuova serie LLM di Alibaba Cloud. Il modello da 72B migliora la programmazione e la matematica, supporta fino a 128K di input e oltre 8K di output, offre supporto per oltre 29 lingue e migliora l'esecuzione delle istruzioni e la generazione di output strutturati (in particolare JSON).",
  "Qwen/Qwen2.5-72B-Instruct-Turbo.description": "Qwen2.5 è una nuova famiglia di LLM ottimizzata per compiti basati su istruzioni.",
  "Qwen/Qwen2.5-72B-Instruct.description": "Qwen2.5-72B-Instruct fa parte della nuova serie LLM di Alibaba Cloud. Il modello da 72B offre miglioramenti significativi nella programmazione e nella matematica, supporta oltre 29 lingue e migliora l'esecuzione delle istruzioni, la comprensione dei dati strutturati e la generazione di output strutturati (in particolare JSON).",
  "Qwen/Qwen2.5-7B-Instruct-Turbo.description": "Qwen2.5 è una nuova famiglia di LLM ottimizzata per compiti basati su istruzioni.",
  "Qwen/Qwen2.5-7B-Instruct.description": "Qwen2.5-7B-Instruct fa parte della nuova serie LLM di Alibaba Cloud. Il modello da 7B offre miglioramenti significativi nella programmazione e nella matematica, supporta oltre 29 lingue e migliora l'esecuzione delle istruzioni, la comprensione dei dati strutturati e la generazione di output strutturati (in particolare JSON).",
  "Qwen/Qwen2.5-Coder-32B-Instruct.description": "Qwen2.5 Coder 32B Instruct è l'ultimo LLM di Alibaba Cloud focalizzato sul codice. Basato su Qwen2.5 e addestrato su 5,5T token, migliora significativamente la generazione di codice, il ragionamento e la correzione, mantenendo le capacità matematiche e generali, fornendo una solida base per agenti di programmazione.",
  "Qwen/Qwen2.5-Coder-7B-Instruct.description": "Qwen2.5-Coder-7B-Instruct è l'ultimo LLM di Alibaba Cloud focalizzato sul codice. Basato su Qwen2.5 e addestrato su 5,5T token, migliora significativamente la generazione di codice, il ragionamento e la correzione, mantenendo le capacità matematiche e generali, fornendo una base solida per agenti di programmazione.",
  "Qwen/Qwen2.5-VL-32B-Instruct.description": "Qwen2.5-VL-32B-Instruct è un modello multimodale del team Qwen. Riconosce oggetti comuni e analizza testo, grafici, icone, elementi visivi e layout. Come agente visivo, può ragionare e controllare dinamicamente strumenti, inclusi computer e telefoni. Localizza con precisione oggetti e genera output strutturati per fatture e tabelle. Rispetto a Qwen2-VL, RL migliora ulteriormente la matematica e la risoluzione di problemi, con risposte più preferite dagli utenti.",
  "Qwen/Qwen2.5-VL-72B-Instruct.description": "Qwen2.5-VL è il modello visione-linguaggio della serie Qwen2.5 con importanti aggiornamenti: comprensione visiva più forte per oggetti, testo, grafici e layout; ragionamento come agente visivo con uso dinamico di strumenti; comprensione di video oltre 1 ora e cattura di eventi chiave; localizzazione precisa di oggetti tramite riquadri o punti; e output strutturati per dati scansionati come fatture e tabelle.",
  "Qwen/Qwen3-14B.description": "Qwen3 è un modello Tongyi Qwen di nuova generazione con importanti miglioramenti nel ragionamento, nelle capacità generali, nelle funzionalità agentiche e nelle prestazioni multilingue, e supporta la commutazione tra modalità di pensiero.",
  "Qwen/Qwen3-235B-A22B-Instruct-2507.description": "Qwen3-235B-A22B-Instruct-2507 è un modello di punta della serie Qwen3 MoE con 235 miliardi di parametri totali e 22 miliardi attivi. È una versione aggiornata non pensante, focalizzata sul miglioramento del seguito delle istruzioni, del ragionamento logico, della comprensione del testo, della matematica, della scienza, della programmazione e dell'uso degli strumenti. Amplia inoltre la conoscenza multilingue di nicchia e si allinea meglio alle preferenze degli utenti nei compiti soggettivi e aperti.",
  "Qwen/Qwen3-235B-A22B-Thinking-2507.description": "Qwen3-235B-A22B-Thinking-2507 è un modello Qwen3 progettato per il ragionamento complesso e avanzato. Utilizza un'architettura MoE con 235 miliardi di parametri totali e circa 22 miliardi attivi per token, ottimizzando l'efficienza. In quanto modello dedicato al pensiero, mostra miglioramenti significativi in logica, matematica, scienza, programmazione e benchmark accademici, raggiungendo prestazioni di alto livello nel pensiero aperto. Migliora anche il seguito delle istruzioni, l'uso degli strumenti e la generazione di testo, supportando nativamente un contesto di 256K per ragionamenti profondi e documenti lunghi.",
  "Qwen/Qwen3-235B-A22B.description": "Qwen3 è un modello Tongyi Qwen di nuova generazione con importanti progressi nel ragionamento, nelle capacità generali, nelle funzionalità agentiche e nelle prestazioni multilingue, e supporta la commutazione tra modalità di pensiero.",
  "Qwen/Qwen3-30B-A3B-Instruct-2507.description": "Qwen3-30B-A3B-Instruct-2507 è la versione aggiornata non pensante di Qwen3-30B-A3B. È un modello MoE con 30,5 miliardi di parametri totali e 3,3 miliardi attivi. Migliora significativamente il seguito delle istruzioni, il ragionamento logico, la comprensione del testo, la matematica, la scienza, la programmazione e l'uso degli strumenti, amplia la conoscenza multilingue di nicchia e si allinea meglio alle preferenze degli utenti nei compiti soggettivi aperti. Supporta un contesto di 256K. Questo modello è esclusivamente non pensante e non genera tag `<think></think>`.",
  "Qwen/Qwen3-30B-A3B-Thinking-2507.description": "Qwen3-30B-A3B-Thinking-2507 è l'ultimo modello pensante della serie Qwen3. È un modello MoE con 30,5 miliardi di parametri totali e 3,3 miliardi attivi, progettato per compiti complessi. Mostra miglioramenti significativi in logica, matematica, scienza, programmazione e benchmark accademici, e migliora il seguito delle istruzioni, l'uso degli strumenti, la generazione di testo e l'allineamento alle preferenze. Supporta nativamente un contesto di 256K ed è estendibile fino a 1 milione di token. Questa versione è progettata per la modalità pensante, con ragionamento dettagliato passo dopo passo e forti capacità agentiche.",
  "Qwen/Qwen3-30B-A3B.description": "Qwen3 è un modello Tongyi Qwen di nuova generazione con importanti progressi nel ragionamento, nelle capacità generali, nelle funzionalità agentiche e nelle prestazioni multilingue, e supporta la commutazione tra modalità di pensiero.",
  "Qwen/Qwen3-32B.description": "Qwen3 è un modello Tongyi Qwen di nuova generazione con importanti progressi nel ragionamento, nelle capacità generali, nelle funzionalità agentiche e nelle prestazioni multilingue, e supporta la commutazione tra modalità di pensiero.",
  "Qwen/Qwen3-8B.description": "Qwen3 è un modello Tongyi Qwen di nuova generazione con importanti progressi nel ragionamento, nelle capacità generali, nelle funzionalità agentiche e nelle prestazioni multilingue, e supporta la commutazione tra modalità di pensiero.",
  "Qwen/Qwen3-Coder-30B-A3B-Instruct.description": "Qwen3-Coder-30B-A3B-Instruct è un modello Qwen3 per la programmazione sviluppato dal team Qwen. È ottimizzato per alte prestazioni ed efficienza, potenziando le capacità di codifica. Mostra vantaggi significativi nella programmazione agentica, nelle operazioni automatizzate del browser e nell'uso degli strumenti tra i modelli open source. Supporta nativamente un contesto di 256K ed è estendibile fino a 1 milione di token per una comprensione a livello di codice base. Alimenta la programmazione agentica su piattaforme come Qwen Code e CLINE con un formato dedicato per le chiamate di funzione.",
  "Qwen/Qwen3-Coder-480B-A35B-Instruct.description": "Qwen3-Coder-480B-A35B-Instruct è il modello di programmazione più avanzato di Alibaba. È un modello MoE con 480 miliardi di parametri totali e 35 miliardi attivi, che bilancia efficienza e prestazioni. Supporta nativamente un contesto di 256K ed è estendibile fino a 1 milione di token tramite YaRN, permettendo la gestione di grandi basi di codice. Progettato per flussi di lavoro di programmazione agentica, può interagire con strumenti e ambienti per risolvere compiti di programmazione complessi. Raggiunge risultati di punta tra i modelli open source nei benchmark di programmazione e agenti, comparabili a modelli leader come Claude Sonnet 4.",
  "Qwen/Qwen3-Next-80B-A3B-Instruct.description": "Qwen3-Next-80B-A3B-Instruct è un modello base di nuova generazione che utilizza l'architettura Qwen3-Next per un'efficienza estrema in addestramento e inferenza. Combina attenzione ibrida (Gated DeltaNet + Gated Attention), MoE altamente sparso e ottimizzazioni per la stabilità dell'addestramento. Con 80 miliardi di parametri totali ma solo ~3 miliardi attivi in inferenza, riduce il calcolo e offre oltre 10 volte il throughput rispetto a Qwen3-32B su contesti >32K. Questa versione ottimizzata per le istruzioni è pensata per compiti generali (senza modalità pensante). Ha prestazioni comparabili a Qwen3-235B in alcuni benchmark e mostra forti vantaggi nei compiti con contesto ultra-lungo.",
  "Qwen/Qwen3-Next-80B-A3B-Thinking.description": "Qwen3-Next-80B-A3B-Thinking è un modello base di nuova generazione per il ragionamento complesso. Utilizza l'architettura Qwen3-Next con attenzione ibrida (Gated DeltaNet + Gated Attention) e MoE altamente sparso per un'efficienza estrema in addestramento e inferenza. Con 80 miliardi di parametri totali ma solo ~3 miliardi attivi in inferenza, riduce il calcolo e offre oltre 10 volte il throughput rispetto a Qwen3-32B su contesti >32K. Questa versione pensante è progettata per compiti multi-step come dimostrazioni, sintesi di codice, analisi logica e pianificazione, generando catene di pensiero strutturate. Supera Qwen3-32B-Thinking e batte Gemini-2.5-Flash-Thinking in diversi benchmark.",
  "Qwen/Qwen3-Omni-30B-A3B-Captioner.description": "Qwen3-Omni-30B-A3B-Captioner è un modello VLM della serie Qwen3 progettato per generare didascalie di immagini di alta qualità, dettagliate e accurate. Utilizza un'architettura MoE da 30 miliardi di parametri per comprendere a fondo le immagini e produrre descrizioni fluide, eccellendo nella cattura dei dettagli, nella comprensione della scena, nel riconoscimento degli oggetti e nel ragionamento relazionale.",
  "Qwen/Qwen3-Omni-30B-A3B-Instruct.description": "Qwen3-Omni-30B-A3B-Instruct è un modello MoE della serie Qwen3 con 30 miliardi di parametri totali e 3 miliardi attivi, che offre prestazioni elevate a un costo di inferenza ridotto. Addestrato su dati multilingue di alta qualità provenienti da più fonti, supporta input multimodali completi (testo, immagini, audio, video) e comprensione e generazione cross-modale.",
  "Qwen/Qwen3-Omni-30B-A3B-Thinking.description": "Qwen3-Omni-30B-A3B-Thinking è il componente \"pensante\" principale di Qwen3-Omni. Elabora input multimodali (testo, audio, immagini, video) e svolge ragionamenti complessi a catena, unificando gli input in una rappresentazione condivisa per una comprensione cross-modale profonda. È un modello MoE con 30 miliardi di parametri totali e 3 miliardi attivi, che bilancia ragionamento avanzato ed efficienza computazionale.",
  "Qwen/Qwen3-VL-235B-A22B-Instruct.description": "Qwen3-VL-235B-A22B-Instruct è un grande modello Qwen3-VL ottimizzato per le istruzioni, basato su architettura MoE, che offre eccellente comprensione e generazione multimodale. Supporta nativamente un contesto di 256K ed è adatto a servizi multimodali in produzione ad alta concorrenza.",
  "Qwen/Qwen3-VL-235B-A22B-Thinking.description": "Qwen3-VL-235B-A22B-Thinking è la versione pensante di punta di Qwen3-VL, ottimizzata per il ragionamento multimodale complesso, il ragionamento su contesti lunghi e l'interazione con agenti in scenari aziendali.",
  "Qwen/Qwen3-VL-30B-A3B-Instruct.description": "Qwen3-VL-30B-A3B-Instruct è il modello Qwen3-VL ottimizzato per le istruzioni, con forte comprensione e generazione linguistico-visiva. Supporta nativamente un contesto di 256K per chat multimodali e generazione condizionata da immagini.",
  "Qwen/Qwen3-VL-30B-A3B-Thinking.description": "Qwen3-VL-30B-A3B-Thinking è la versione potenziata per il ragionamento di Qwen3-VL, ottimizzata per il ragionamento multimodale, la conversione da immagine a codice e la comprensione visiva complessa. Supporta un contesto di 256K con una maggiore capacità di catena di pensiero.",
  "Qwen/Qwen3-VL-32B-Instruct.description": "Qwen3-VL-32B-Instruct è un modello linguistico-visivo del team Qwen con risultati SOTA su diversi benchmark VL. Supporta immagini ad alta risoluzione (megapixel) e offre forte comprensione visiva, OCR multilingue, ancoraggio visivo dettagliato e dialogo visivo. Gestisce compiti multimodali complessi e supporta chiamate di strumenti e completamento con prefisso.",
  "Qwen/Qwen3-VL-32B-Thinking.description": "Qwen3-VL-32B-Thinking è ottimizzato per il ragionamento visivo complesso. Include una modalità pensante integrata che genera passaggi intermedi di ragionamento prima delle risposte, migliorando logica multi-step, pianificazione e ragionamento complesso. Supporta immagini megapixel, forte comprensione visiva, OCR multilingue, ancoraggio dettagliato, dialogo visivo, chiamate di strumenti e completamento con prefisso.",
  "Qwen/Qwen3-VL-8B-Instruct.description": "Qwen3-VL-8B-Instruct è un modello linguistico-visivo Qwen3 basato su Qwen3-8B-Instruct e addestrato su grandi quantità di dati immagine-testo. Eccelle nella comprensione visiva generale, nel dialogo centrato sulla visione e nel riconoscimento multilingue del testo nelle immagini, adatto a QA visivo, didascalie, seguito di istruzioni multimodali e uso di strumenti.",
  "Qwen/Qwen3-VL-8B-Thinking.description": "Qwen3-VL-8B-Thinking è la versione visiva pensante di Qwen3, ottimizzata per il ragionamento complesso multi-step. Genera una catena di pensiero prima delle risposte per migliorarne l'accuratezza, ideale per QA visivo profondo e analisi dettagliata delle immagini.",
  "Qwen2-72B-Instruct.description": "Qwen2 è l'ultima versione della serie Qwen, con supporto per una finestra di contesto di 128k. Rispetto ai migliori modelli open attuali, Qwen2-72B supera significativamente i principali modelli in comprensione del linguaggio naturale, conoscenza, programmazione, matematica e capacità multilingue.",
  "Qwen2-7B-Instruct.description": "Qwen2 è l'ultima versione della serie Qwen, che supera i migliori modelli open della stessa dimensione e persino modelli più grandi. Qwen2 7B mostra vantaggi significativi in diversi benchmark, in particolare nella programmazione e nella comprensione del cinese.",
  "Qwen2-VL-72B.description": "Qwen2-VL-72B è un potente modello visione-linguaggio che supporta l'elaborazione multimodale immagine-testo, riconoscendo accuratamente i contenuti visivi e generando descrizioni o risposte pertinenti.",
  "Qwen2.5-14B-Instruct.description": "Qwen2.5-14B-Instruct è un LLM da 14 miliardi di parametri con prestazioni elevate, ottimizzato per scenari in cinese e multilingue, con supporto per domande e risposte intelligenti e generazione di contenuti.",
  "Qwen2.5-32B-Instruct.description": "Qwen2.5-32B-Instruct è un LLM da 32 miliardi di parametri con prestazioni bilanciate, ottimizzato per scenari in cinese e multilingue, con supporto per domande e risposte intelligenti e generazione di contenuti.",
  "Qwen2.5-72B-Instruct.description": "LLM per cinese e inglese, ottimizzato per linguaggio, programmazione, matematica e ragionamento.",
  "Qwen2.5-7B-Instruct.description": "Qwen2.5-7B-Instruct è un LLM da 7 miliardi di parametri che supporta chiamate a funzioni e integrazione fluida con sistemi esterni, migliorando notevolmente flessibilità ed estensibilità. È ottimizzato per scenari in cinese e multilingue, con supporto per domande e risposte intelligenti e generazione di contenuti.",
  "Qwen2.5-Coder-14B-Instruct.description": "Qwen2.5-Coder-14B-Instruct è un modello di istruzioni per la programmazione su larga scala, con eccellenti capacità di comprensione e generazione di codice. Gestisce in modo efficiente una vasta gamma di compiti di programmazione, ideale per codifica intelligente, generazione automatica di script e domande e risposte sulla programmazione.",
  "Qwen2.5-Coder-32B-Instruct.description": "LLM avanzato per generazione di codice, ragionamento e correzione di bug nei principali linguaggi di programmazione.",
  "Qwen3-235B-A22B-Instruct-2507-FP8.description": "Qwen3 235B A22B Instruct 2507 è ottimizzato per ragionamento avanzato e seguire istruzioni, utilizzando MoE per mantenere l'efficienza del ragionamento su larga scala.",
  "Qwen3-235B.description": "Qwen3-235B-A22B è un modello MoE che introduce una modalità di ragionamento ibrida, consentendo agli utenti di passare senza interruzioni tra pensiero e non-pensiero. Supporta comprensione e ragionamento in 119 lingue e dialetti e ha forti capacità di utilizzo di strumenti, competendo con modelli di punta come DeepSeek R1, OpenAI o1, o3-mini, Grok 3 e Google Gemini 2.5 Pro nei benchmark su abilità generali, codice e matematica, capacità multilingue e ragionamento basato sulla conoscenza.",
  "Qwen3-32B.description": "Qwen3-32B è un modello denso che introduce una modalità di ragionamento ibrida, consentendo agli utenti di passare tra pensiero e non-pensiero. Grazie a miglioramenti architetturali, più dati e un addestramento migliore, offre prestazioni comparabili a Qwen2.5-72B.",
  "SenseChat-128K.description": "Base V4 con contesto da 128K, eccellente nella comprensione e generazione di testi lunghi.",
  "SenseChat-32K.description": "Base V4 con contesto da 32K, flessibile per molti scenari.",
  "SenseChat-5-1202.description": "Ultima versione basata su V5.5, con miglioramenti significativi nelle basi di cinese/inglese, chat, conoscenze STEM, umanistiche, scrittura, matematica/logica e controllo della lunghezza.",
  "SenseChat-5-Cantonese.description": "Progettato per le abitudini di dialogo di Hong Kong, slang e conoscenze locali; supera GPT-4 nella comprensione del cantonese e rivaleggia con GPT-4 Turbo in conoscenza, ragionamento, matematica e programmazione.",
  "SenseChat-5-beta.description": "Alcune prestazioni superano SenseChat-5-1202.",
  "SenseChat-5.description": "Ultima versione V5.5 con contesto da 128K; grandi miglioramenti nel ragionamento matematico, chat in inglese, esecuzione di istruzioni e comprensione di testi lunghi, comparabile a GPT-4o.",
  "SenseChat-Character-Pro.description": "Modello avanzato per chat con personaggi, con contesto da 32K, capacità migliorate e supporto per cinese/inglese.",
  "SenseChat-Character.description": "Modello standard per chat con personaggi, con contesto da 8K e alta velocità di risposta.",
  "SenseChat-Turbo-1202.description": "Ultimo modello leggero che raggiunge oltre il 90% delle capacità del modello completo con costi di inferenza significativamente inferiori.",
  "SenseChat-Turbo.description": "Adatto per domande e risposte rapide e scenari di fine-tuning del modello.",
  "SenseChat-Vision.description": "Ultima versione V5.5 con input multi-immagine e ampi miglioramenti nelle capacità di riconoscimento di attributi, relazioni spaziali, rilevamento di azioni/eventi, comprensione di scene, riconoscimento delle emozioni, ragionamento basato sul senso comune e comprensione/generazione di testo.",
  "SenseChat.description": "Base V4 con contesto da 4K e forti capacità generali.",
  "SenseNova-V6-5-Pro.description": "Con aggiornamenti completi ai dati multimodali, linguistici e di ragionamento, oltre all'ottimizzazione della strategia di addestramento, il nuovo modello migliora significativamente il ragionamento multimodale e il seguito delle istruzioni generalizzate, supporta una finestra di contesto fino a 128k e si distingue nei compiti di riconoscimento OCR e IP culturali/turistici.",
  "SenseNova-V6-5-Turbo.description": "Con aggiornamenti completi ai dati multimodali, linguistici e di ragionamento, oltre all'ottimizzazione della strategia di addestramento, il nuovo modello migliora significativamente il ragionamento multimodale e il seguito delle istruzioni generalizzate, supporta una finestra di contesto fino a 128k e si distingue nei compiti di riconoscimento OCR e IP culturali/turistici.",
  "SenseNova-V6-Pro.description": "Unifica nativamente immagine, testo e video, superando i limiti tradizionali dei modelli multimodali; si posiziona ai vertici su OpenCompass e SuperCLUE.",
  "SenseNova-V6-Reasoner.description": "Combina ragionamento profondo visivo e linguistico, supportando pensiero lento e catene complete di ragionamento.",
  "SenseNova-V6-Turbo.description": "Unifica nativamente immagine, testo e video, superando i limiti tradizionali dei modelli multimodali. Guida le capacità linguistiche e multimodali di base e si classifica tra i migliori in molte valutazioni.",
  "Skylark2-lite-8k.description": "Modello Skylark di seconda generazione. Skylark2-lite offre risposte rapide per scenari in tempo reale e sensibili ai costi, con esigenze di accuratezza inferiori, e una finestra di contesto da 8K.",
  "Skylark2-pro-32k.description": "Modello Skylark di seconda generazione. Skylark2-pro offre maggiore accuratezza per generazione di testi complessi come copywriting professionale, scrittura di romanzi e traduzioni di alta qualità, con una finestra di contesto da 32K.",
  "Skylark2-pro-4k.description": "Modello Skylark di seconda generazione. Skylark2-pro offre maggiore accuratezza per generazione di testi complessi come copywriting professionale, scrittura di romanzi e traduzioni di alta qualità, con una finestra di contesto da 4K.",
  "Skylark2-pro-character-4k.description": "Modello Skylark di seconda generazione. Skylark2-pro-character eccelle nel gioco di ruolo e nella chat, adattando i prompt a stili di personaggi distinti e dialoghi naturali per chatbot, assistenti virtuali e assistenza clienti, con risposte rapide.",
  "Skylark2-pro-turbo-8k.description": "Modello Skylark di seconda generazione. Skylark2-pro-turbo-8k offre inferenza più veloce a costi inferiori con una finestra di contesto da 8K.",
  "THUDM/GLM-4-32B-0414.description": "GLM-4-32B-0414 è un modello GLM open-source di nuova generazione con 32 miliardi di parametri, comparabile in prestazioni a OpenAI GPT e alla serie DeepSeek V3/R1.",
  "THUDM/GLM-4-9B-0414.description": "GLM-4-9B-0414 è un modello GLM da 9 miliardi di parametri che eredita le tecniche di GLM-4-32B offrendo un'implementazione più leggera. Eccelle nella generazione di codice, progettazione web, generazione SVG e scrittura basata su ricerca.",
  "THUDM/GLM-4.1V-9B-Thinking.description": "GLM-4.1V-9B-Thinking è un VLM open-source sviluppato da Zhipu AI e Tsinghua KEG Lab, progettato per la cognizione multimodale complessa. Basato su GLM-4-9B-0414, aggiunge ragionamento a catena e RL per migliorare significativamente il ragionamento cross-modale e la stabilità.",
  "THUDM/GLM-Z1-32B-0414.description": "GLM-Z1-32B-0414 è un modello di ragionamento profondo costruito a partire da GLM-4-32B-0414 con dati cold-start e RL esteso, ulteriormente addestrato su matematica, codice e logica. Migliora significativamente la capacità matematica e la risoluzione di compiti complessi rispetto al modello base.",
  "THUDM/GLM-Z1-9B-0414.description": "GLM-Z1-9B-0414 è un modello GLM compatto da 9 miliardi di parametri che mantiene i punti di forza open-source offrendo capacità impressionanti. Eccelle nel ragionamento matematico e nei compiti generali, guidando la sua classe di dimensione tra i modelli open.",
  "THUDM/GLM-Z1-Rumination-32B-0414.description": "GLM-Z1-Rumination-32B-0414 è un modello di ragionamento profondo con capacità di riflessione (valutato rispetto a OpenAI Deep Research). A differenza dei modelli di pensiero profondo tipici, impiega più tempo per risolvere problemi aperti e complessi.",
  "THUDM/glm-4-9b-chat.description": "GLM-4-9B-Chat è il modello GLM-4 open-source di Zhipu AI. Eccelle in semantica, matematica, ragionamento, codice e conoscenza. Oltre alla chat multi-turno, supporta navigazione web, esecuzione di codice, chiamate a strumenti personalizzati e ragionamento su testi lunghi. Supporta 26 lingue (inclusi cinese, inglese, giapponese, coreano, tedesco). Ottiene buoni risultati su AlignBench-v2, MT-Bench, MMLU e C-Eval, e supporta fino a 128K di contesto per uso accademico e aziendale.",
  "Tongyi-Zhiwen/QwenLong-L1-32B.description": "QwenLong-L1-32B è il primo modello di ragionamento a lungo contesto (LRM) addestrato con RL, ottimizzato per il ragionamento su testi lunghi. Il suo RL con espansione progressiva del contesto consente un trasferimento stabile da contesti brevi a lunghi. Supera OpenAI-o3-mini e Qwen3-235B-A22B in sette benchmark di QA su documenti a lungo contesto, rivaleggiando con Claude-3.7-Sonnet-Thinking. È particolarmente forte in matematica, logica e ragionamento multi-hop.",
  "Yi-34B-Chat.description": "Yi-1.5-34B mantiene le forti capacità linguistiche generali della serie, migliorando significativamente logica matematica e programmazione grazie a un addestramento incrementale su 500 miliardi di token di alta qualità.",
  "abab5.5-chat.description": "Progettato per scenari di produttività, gestisce compiti complessi e genera testo in modo efficiente per uso professionale.",
  "abab5.5s-chat.description": "Progettato per chat con personaggi in cinese, offrendo dialoghi di alta qualità per varie applicazioni.",
  "abab6.5g-chat.description": "Progettato per chat con personaggi multilingue, supporta generazione di dialoghi di alta qualità in inglese e altre lingue.",
  "abab6.5s-chat.description": "Adatto a un'ampia gamma di compiti NLP, inclusa la generazione di testo e sistemi di dialogo.",
  "abab6.5t-chat.description": "Ottimizzato per chat con personaggi in cinese, fornendo dialoghi fluidi che rispettano le abitudini espressive cinesi.",
  "accounts/fireworks/models/deepseek-r1.description": "DeepSeek-R1 è un modello linguistico all'avanguardia ottimizzato con apprendimento per rinforzo e dati cold-start, che offre prestazioni eccellenti in ragionamento, matematica e programmazione.",
  "accounts/fireworks/models/deepseek-v3.description": "Un potente modello linguistico Mixture-of-Experts (MoE) di DeepSeek con 671 miliardi di parametri totali e 37 miliardi di parametri attivi per token.",
  "accounts/fireworks/models/llama-v3-70b-instruct.description": "Meta ha sviluppato e rilasciato la serie di modelli linguistici Meta Llama 3, che include modelli pre-addestrati e ottimizzati per l'uso conversazionale da 8B e 70B. I modelli Llama 3 ottimizzati per le istruzioni sono progettati per l'interazione conversazionale e superano molti modelli open chat esistenti nei benchmark di settore.",
  "accounts/fireworks/models/llama-v3-8b-instruct-hf.description": "I modelli Llama 3 ottimizzati per le istruzioni sono progettati per l'interazione conversazionale e superano molti modelli open chat esistenti nei benchmark di settore. Llama 3 8B Instruct (versione HF) è la versione FP16 originale di Llama 3 8B Instruct, con risultati attesi in linea con l'implementazione ufficiale di Hugging Face.",
  "accounts/fireworks/models/llama-v3-8b-instruct.description": "Meta ha sviluppato e rilasciato la serie di modelli linguistici Meta Llama 3, una collezione di modelli pre-addestrati e ottimizzati per la generazione di testo da 8B e 70B. I modelli Llama 3 ottimizzati per le istruzioni sono progettati per l'uso conversazionale e superano molti modelli open chat esistenti nei benchmark di settore.",
  "accounts/fireworks/models/llama-v3p1-405b-instruct.description": "Meta Llama 3.1 è una famiglia di modelli linguistici multilingue con modelli di generazione pre-addestrati e ottimizzati per le istruzioni nei formati 8B, 70B e 405B. I modelli ottimizzati per le istruzioni sono progettati per il dialogo multilingue e superano molti modelli open e closed chat nei benchmark di settore. Il modello 405B è il più avanzato della famiglia Llama 3.1, utilizzando inferenza FP8 che replica fedelmente l'implementazione di riferimento.",
  "accounts/fireworks/models/llama-v3p1-70b-instruct.description": "Meta Llama 3.1 è una famiglia di modelli linguistici multilingue con modelli di generazione pre-addestrati e ottimizzati per le istruzioni nei formati 8B, 70B e 405B. I modelli ottimizzati per le istruzioni sono progettati per il dialogo multilingue e superano molti modelli open e closed chat nei benchmark di settore.",
  "accounts/fireworks/models/llama-v3p1-8b-instruct.description": "Meta Llama 3.1 è una famiglia di modelli linguistici multilingue con modelli di generazione pre-addestrati e ottimizzati per le istruzioni nei formati 8B, 70B e 405B. I modelli ottimizzati per le istruzioni sono progettati per il dialogo multilingue e superano molti modelli open e closed chat nei benchmark di settore.",
  "accounts/fireworks/models/llama-v3p2-11b-vision-instruct.description": "Un modello di ragionamento visivo ottimizzato per le istruzioni di Meta con 11 miliardi di parametri, progettato per il riconoscimento visivo, il ragionamento su immagini, la generazione di didascalie e domande e risposte basate su immagini. Comprende dati visivi come grafici e tabelle e collega visione e linguaggio generando descrizioni testuali dei dettagli visivi.",
  "accounts/fireworks/models/llama-v3p2-3b-instruct.description": "Llama 3.2 3B Instruct è un modello multilingue leggero di Meta, progettato per un'esecuzione efficiente con vantaggi significativi in termini di latenza e costi rispetto ai modelli più grandi. Gli usi tipici includono la riscrittura di query/promt e l'assistenza alla scrittura.",
  "accounts/fireworks/models/llama-v3p2-90b-vision-instruct.description": "Un modello di ragionamento visivo ottimizzato per le istruzioni di Meta con 90 miliardi di parametri, progettato per il riconoscimento visivo, il ragionamento su immagini, la generazione di didascalie e domande e risposte basate su immagini. Comprende dati visivi come grafici e tabelle e collega visione e linguaggio generando descrizioni testuali dei dettagli visivi. Nota: questo modello è attualmente fornito in via sperimentale come modello serverless. Per l'uso in produzione, Fireworks potrebbe ritirare il deployment con breve preavviso.",
  "accounts/fireworks/models/llama-v3p3-70b-instruct.description": "Llama 3.3 70B Instruct è l'aggiornamento di dicembre del modello Llama 3.1 70B. Migliora l'uso degli strumenti, il supporto multilingue, la matematica e la programmazione rispetto alla versione di luglio 2024. Raggiunge prestazioni leader nel settore in ragionamento, matematica e comprensione delle istruzioni, offrendo prestazioni comparabili al modello 3.1 405B con vantaggi significativi in termini di velocità e costi.",
  "accounts/fireworks/models/mistral-small-24b-instruct-2501.description": "Un modello da 24 miliardi di parametri con capacità all'avanguardia comparabili a modelli più grandi.",
  "accounts/fireworks/models/mixtral-8x22b-instruct.description": "Mixtral MoE 8x22B Instruct v0.1 è la versione ottimizzata per le istruzioni di Mixtral MoE 8x22B v0.1, con API di completamento chat abilitata.",
  "accounts/fireworks/models/mixtral-8x7b-instruct.description": "Mixtral MoE 8x7B Instruct è la versione ottimizzata per le istruzioni di Mixtral MoE 8x7B, con API di completamento chat abilitata.",
  "accounts/fireworks/models/mythomax-l2-13b.description": "Una variante migliorata di MythoMix, probabilmente la sua forma più raffinata, che unisce MythoLogic-L2 e Huginn con una tecnica di fusione tensoriale altamente sperimentale. La sua natura unica lo rende eccellente per la narrazione e il gioco di ruolo.",
  "accounts/fireworks/models/phi-3-vision-128k-instruct.description": "Phi-3-Vision-128K-Instruct è un modello multimodale leggero e all'avanguardia costruito con dati sintetici e dataset pubblici selezionati, focalizzato su dati testuali e visivi di alta qualità e ad alta intensità di ragionamento. Fa parte della famiglia Phi-3, con una versione multimodale che supporta una lunghezza di contesto di 128K token. Il modello è stato migliorato con fine-tuning supervisionato e ottimizzazione diretta delle preferenze, per garantire un'accurata comprensione delle istruzioni e solide misure di sicurezza.",
  "accounts/fireworks/models/qwen-qwq-32b-preview.description": "Il modello Qwen QwQ si concentra sull'avanzamento del ragionamento dell'IA, dimostrando che i modelli open possono competere con quelli closed di frontiera. QwQ-32B-Preview è una versione sperimentale che eguaglia o1 e supera GPT-4o e Claude 3.5 Sonnet nel ragionamento e nell'analisi su GPQA, AIME, MATH-500 e LiveCodeBench. Nota: questo modello è attualmente fornito in via sperimentale come modello serverless. Per l'uso in produzione, Fireworks potrebbe ritirare il deployment con breve preavviso.",
  "accounts/fireworks/models/qwen2-vl-72b-instruct.description": "Il modello Qwen-VL da 72B è l'ultima iterazione di Alibaba, frutto di quasi un anno di innovazione.",
  "accounts/fireworks/models/qwen2p5-72b-instruct.description": "Qwen2.5 è una serie di modelli linguistici solo decoder sviluppata dal team Qwen e da Alibaba Cloud, disponibile nei formati 0.5B, 1.5B, 3B, 7B, 14B, 32B e 72B, con varianti base e ottimizzate per le istruzioni.",
  "accounts/fireworks/models/qwen2p5-coder-32b-instruct.description": "Qwen2.5-Coder è l'ultimo modello linguistico Qwen progettato per la programmazione (precedentemente CodeQwen). Nota: questo modello è attualmente fornito in via sperimentale come modello serverless. Per l'uso in produzione, Fireworks potrebbe ritirare il deployment con breve preavviso.",
  "accounts/yi-01-ai/models/yi-large.description": "Yi-Large è un modello linguistico di alto livello che si posiziona appena sotto GPT-4, Gemini 1.5 Pro e Claude 3 Opus nella classifica LMSYS. Eccelle nella capacità multilingue, in particolare in spagnolo, cinese, giapponese, tedesco e francese. Yi-Large è anche adatto agli sviluppatori, utilizzando lo stesso schema API di OpenAI per una facile integrazione.",
  "ai21-jamba-1.5-large.description": "Un modello multilingue da 398 miliardi di parametri (94B attivi) con una finestra di contesto di 256K, supporto per chiamate di funzione, output strutturato e generazione ancorata.",
  "ai21-jamba-1.5-mini.description": "Un modello multilingue da 52 miliardi di parametri (12B attivi) con una finestra di contesto di 256K, supporto per chiamate di funzione, output strutturato e generazione ancorata.",
  "ai21-labs/AI21-Jamba-1.5-Large.description": "Un modello multilingue da 398 miliardi di parametri (94B attivi) con una finestra di contesto di 256K, supporto per chiamate di funzione, output strutturato e generazione ancorata.",
  "ai21-labs/AI21-Jamba-1.5-Mini.description": "Un modello multilingue da 52 miliardi di parametri (12B attivi) con una finestra di contesto di 256K, supporto per chiamate di funzione, output strutturato e generazione ancorata.",
  "alibaba/qwen-3-14b.description": "Qwen3 è l'ultima generazione della serie Qwen, che offre una gamma completa di modelli densi e MoE. Basato su un addestramento esteso, introduce innovazioni nel ragionamento, nella comprensione delle istruzioni, nelle capacità agentiche e nel supporto multilingue.",
  "alibaba/qwen-3-235b.description": "Qwen3 è l'ultima generazione della serie Qwen, che offre una gamma completa di modelli densi e MoE. Basato su un addestramento esteso, introduce innovazioni nel ragionamento, nella comprensione delle istruzioni, nelle capacità agentiche e nel supporto multilingue.",
  "alibaba/qwen-3-30b.description": "Qwen3 è l'ultima generazione della serie Qwen, che offre una gamma completa di modelli densi e MoE. Basato su un addestramento esteso, introduce innovazioni nel ragionamento, nella comprensione delle istruzioni, nelle capacità agentiche e nel supporto multilingue.",
  "alibaba/qwen-3-32b.description": "Qwen3 è l'ultima generazione della serie Qwen, che offre una gamma completa di modelli densi e MoE. Basato su un addestramento esteso, introduce innovazioni nel ragionamento, nella comprensione delle istruzioni, nelle capacità agentiche e nel supporto multilingue.",
  "alibaba/qwen3-coder.description": "Qwen3-Coder-480B-A35B-Instruct è il modello Qwen più avanzato per la programmazione, con ottime prestazioni in attività agentiche di codifica, uso del browser e altri compiti fondamentali, raggiungendo risultati comparabili a Claude Sonnet.",
  "amazon/nova-lite.description": "Un modello multimodale a bassissimo costo con elaborazione estremamente rapida di input immagine, video e testo.",
  "amazon/nova-micro.description": "Un modello solo testuale che offre una latenza ultra-bassa a un costo molto contenuto.",
  "amazon/nova-pro.description": "Un modello multimodale altamente performante con il miglior equilibrio tra accuratezza, velocità e costo per un'ampia gamma di compiti.",
  "amazon/titan-embed-text-v2.description": "Amazon Titan Text Embeddings V2 è un modello di embedding multilingue leggero ed efficiente che supporta dimensioni di 1024, 512 e 256.",
  "anthropic.claude-3-5-sonnet-20240620-v1:0.description": "Claude 3.5 Sonnet alza lo standard del settore, superando i concorrenti e Claude 3 Opus in valutazioni ampie, mantenendo velocità e costi di fascia media.",
  "anthropic.claude-3-5-sonnet-20241022-v2:0.description": "Claude 3.5 Sonnet alza lo standard del settore, superando i concorrenti e Claude 3 Opus in valutazioni ampie, mantenendo velocità e costi di fascia media.",
  "anthropic.claude-3-haiku-20240307-v1:0.description": "Claude 3 Haiku è il modello più veloce e compatto di Anthropic, progettato per risposte quasi istantanee a domande semplici. Offre esperienze AI fluide e simili a quelle umane e supporta input immagine con una finestra di contesto di 200K.",
  "anthropic.claude-3-opus-20240229-v1:0.description": "Claude 3 Opus è il modello AI più potente di Anthropic, con prestazioni all'avanguardia in compiti altamente complessi. Gestisce prompt aperti e scenari inediti con eccezionale fluidità e comprensione simile a quella umana, e supporta input immagine con una finestra di contesto di 200K.",
  "anthropic.claude-3-sonnet-20240229-v1:0.description": "Claude 3 Sonnet bilancia intelligenza e velocità per carichi di lavoro aziendali, offrendo un ottimo valore a costi contenuti. È progettato come un modello affidabile per implementazioni AI su larga scala e supporta input immagine con una finestra di contesto di 200K.",
  "anthropic.claude-instant-v1.description": "Un modello veloce, economico ma capace per chat quotidiane, analisi testuale, riassunti e domande su documenti.",
  "anthropic.claude-v2.description": "Un modello altamente capace per compiti che vanno dal dialogo complesso alla generazione creativa fino al rispetto dettagliato delle istruzioni.",
  "anthropic.claude-v2:1.description": "Una versione aggiornata di Claude 2 con il doppio della finestra di contesto e miglioramenti in affidabilità, riduzione delle allucinazioni e accuratezza basata su prove per documenti lunghi e RAG.",
  "anthropic/claude-3-haiku.description": "Claude 3 Haiku è il modello più veloce di Anthropic, progettato per carichi di lavoro aziendali con prompt lunghi. Può analizzare rapidamente documenti estesi come report trimestrali, contratti o casi legali a metà del costo dei concorrenti.",
  "anthropic/claude-3-opus.description": "Claude 3 Opus è il modello più intelligente di Anthropic, con prestazioni leader di mercato in compiti altamente complessi, gestendo prompt aperti e scenari inediti con eccezionale fluidità e comprensione simile a quella umana.",
  "anthropic/claude-3.5-haiku.description": "Claude 3.5 Haiku offre velocità migliorata, accuratezza nel codice e uso degli strumenti, adatto a scenari con requisiti elevati di velocità e interazione con strumenti.",
  "anthropic/claude-3.5-sonnet.description": "Claude 3.5 Sonnet è il modello veloce ed efficiente della famiglia Sonnet, con migliori prestazioni in codifica e ragionamento; alcune versioni sono gradualmente sostituite da Sonnet 3.7 e successivi.",
  "anthropic/claude-3.7-sonnet.description": "Claude 3.7 Sonnet è un modello Sonnet aggiornato con ragionamento e codifica potenziati, adatto a compiti complessi di livello aziendale.",
  "anthropic/claude-haiku-4.5.description": "Claude Haiku 4.5 è il modello veloce ad alte prestazioni di Anthropic, con latenza molto bassa e alta accuratezza.",
  "anthropic/claude-opus-4.1.description": "Opus 4.1 è il modello di fascia alta di Anthropic, ottimizzato per programmazione, ragionamento complesso e compiti di lunga durata.",
  "anthropic/claude-opus-4.5.description": "Claude Opus 4.5 è il modello di punta di Anthropic, che combina intelligenza di alto livello con prestazioni scalabili per compiti complessi e ragionamento di alta qualità.",
  "anthropic/claude-opus-4.description": "Opus 4 è il modello di punta di Anthropic, progettato per compiti complessi e applicazioni aziendali.",
  "anthropic/claude-sonnet-4.5.description": "Claude Sonnet 4.5 è l'ultimo modello di ragionamento ibrido di Anthropic, ottimizzato per ragionamento complesso e codifica.",
  "anthropic/claude-sonnet-4.description": "Claude Sonnet 4 è il modello di ragionamento ibrido di Anthropic con capacità miste di pensiero e non-pensiero.",
  "ascend-tribe/pangu-pro-moe.description": "Pangu-Pro-MoE 72B-A16B è un LLM sparso con 72 miliardi di parametri totali e 16 miliardi attivi, basato su un'architettura MoE raggruppata (MoGE). Raggruppa gli esperti durante la selezione e vincola i token ad attivare un numero uguale di esperti per gruppo, bilanciando il carico e migliorando l'efficienza di distribuzione su Ascend.",
  "aya.description": "Aya 23 è il modello multilingue di Cohere che supporta 23 lingue per casi d'uso diversificati.",
  "aya:35b.description": "Aya 23 è il modello multilingue di Cohere che supporta 23 lingue per casi d'uso diversificati.",
  "azure-DeepSeek-R1-0528.description": "Distribuito da Microsoft; DeepSeek R1 è stato aggiornato a DeepSeek-R1-0528. L'aggiornamento aumenta la potenza di calcolo e le ottimizzazioni post-addestramento, migliorando significativamente la profondità di ragionamento e l'inferenza. Ottiene ottimi risultati in matematica, programmazione e logica generale, avvicinandosi a modelli leader come O3 e Gemini 2.5 Pro.",
  "baichuan-m2-32b.description": "Baichuan M2 32B è un modello MoE di Baichuan Intelligence con forte capacità di ragionamento.",
  "baichuan/baichuan2-13b-chat.description": "Baichuan-13B è un LLM open-source e commercialmente utilizzabile con 13 miliardi di parametri, che ottiene risultati di riferimento eccellenti per la sua dimensione su benchmark autorevoli in cinese e inglese.",
  "baidu/ERNIE-4.5-300B-A47B.description": "ERNIE-4.5-300B-A47B è un LLM MoE di Baidu con 300 miliardi di parametri totali e 47 miliardi attivi per token, che bilancia prestazioni elevate ed efficienza computazionale. Come modello centrale di ERNIE 4.5, eccelle in comprensione, generazione, ragionamento e programmazione. Utilizza un metodo di pre-addestramento multimodale eterogeneo MoE con addestramento congiunto testo-visione per potenziare le capacità generali, in particolare nel seguire istruzioni e nella conoscenza del mondo.",
  "baidu/ernie-5.0-thinking-preview.description": "ERNIE 5.0 Thinking Preview è il modello ERNIE multimodale nativo di nuova generazione di Baidu, forte nella comprensione multimodale, nel seguire istruzioni, nella creazione, nelle domande e risposte fattuali e nell'uso di strumenti.",
  "black-forest-labs/flux-1.1-pro.description": "FLUX 1.1 Pro è una versione più veloce e migliorata di FLUX Pro con eccellente qualità delle immagini e aderenza ai prompt.",
  "black-forest-labs/flux-dev.description": "FLUX Dev è la versione di sviluppo di FLUX per uso non commerciale.",
  "black-forest-labs/flux-pro.description": "FLUX Pro è il modello FLUX professionale per output di immagini di alta qualità.",
  "black-forest-labs/flux-schnell.description": "FLUX Schnell è un modello di generazione immagini veloce ottimizzato per la rapidità.",
  "c4ai-aya-expanse-32b.description": "Aya Expanse è un modello multilingue ad alte prestazioni da 32B che utilizza l'istruction tuning, l'arbitraggio dei dati, l'addestramento basato sulle preferenze e la fusione di modelli per competere con i modelli monolingue. Supporta 23 lingue.",
  "c4ai-aya-expanse-8b.description": "Aya Expanse è un modello multilingue ad alte prestazioni da 8B che utilizza l'istruction tuning, l'arbitraggio dei dati, l'addestramento basato sulle preferenze e la fusione di modelli per competere con i modelli monolingue. Supporta 23 lingue.",
  "c4ai-aya-vision-32b.description": "Aya Vision è un modello multimodale all'avanguardia che offre prestazioni eccellenti nei principali benchmark di linguaggio, testo e visione. Supporta 23 lingue. Questa versione da 32B è focalizzata su prestazioni multilingue di livello superiore.",
  "c4ai-aya-vision-8b.description": "Aya Vision è un modello multimodale all'avanguardia che offre prestazioni eccellenti nei principali benchmark di linguaggio, testo e visione. Questa versione da 8B è ottimizzata per bassa latenza e prestazioni elevate.",
  "charglm-3.description": "CharGLM-3 è progettato per il gioco di ruolo e la compagnia emotiva, supportando una memoria multi-turno ultra-lunga e dialoghi personalizzati.",
  "charglm-4.description": "CharGLM-4 è progettato per il gioco di ruolo e la compagnia emotiva, supportando una memoria multi-turno ultra-lunga e dialoghi personalizzati.",
  "chatgpt-4o-latest.description": "ChatGPT-4o è un modello dinamico aggiornato in tempo reale, che combina comprensione e generazione avanzate per casi d'uso su larga scala come assistenza clienti, istruzione e supporto tecnico.",
  "claude-2.0.description": "Claude 2 introduce miglioramenti chiave per le imprese, tra cui un contesto leader da 200.000 token, riduzione delle allucinazioni, prompt di sistema e una nuova funzione di test: chiamata agli strumenti.",
  "claude-2.1.description": "Claude 2 introduce miglioramenti chiave per le imprese, tra cui un contesto leader da 200.000 token, riduzione delle allucinazioni, prompt di sistema e una nuova funzione di test: chiamata agli strumenti.",
  "claude-3-5-haiku-20241022.description": "Claude 3.5 Haiku è il modello di nuova generazione più veloce di Anthropic. Rispetto a Claude 3 Haiku, migliora in tutte le competenze e supera il precedente modello di punta Claude 3 Opus in molti benchmark di intelligenza.",
  "claude-3-5-haiku-latest.description": "Claude 3.5 Haiku fornisce risposte rapide per attività leggere.",
  "claude-3-7-sonnet-20250219.description": "Claude 3.7 Sonnet è il modello più intelligente di Anthropic e il primo modello di ragionamento ibrido sul mercato. È in grado di fornire risposte quasi istantanee o ragionamenti estesi passo dopo passo visibili all’utente. Sonnet eccelle in particolare nella programmazione, data science, visione artificiale e compiti per agenti.",
  "claude-3-7-sonnet-latest.description": "Claude 3.7 Sonnet è il modello più recente e avanzato di Anthropic per compiti altamente complessi, eccellendo in prestazioni, intelligenza, fluidità e comprensione.",
  "claude-3-haiku-20240307.description": "Claude 3 Haiku è il modello più veloce e compatto di Anthropic, progettato per risposte quasi istantanee con prestazioni rapide e accurate.",
  "claude-3-opus-20240229.description": "Claude 3 Opus è il modello più potente di Anthropic per compiti altamente complessi, eccellendo in prestazioni, intelligenza, fluidità e comprensione.",
  "claude-3-sonnet-20240229.description": "Claude 3 Sonnet bilancia intelligenza e velocità per carichi di lavoro aziendali, offrendo alta utilità a costi inferiori e distribuzione affidabile su larga scala.",
  "claude-haiku-4-5-20251001.description": "Claude Haiku 4.5 è il modello Haiku più veloce e intelligente di Anthropic, con una velocità fulminea e capacità di ragionamento esteso.",
  "claude-opus-4-1-20250805-thinking.description": "Claude Opus 4.1 Thinking è una variante avanzata in grado di mostrare il proprio processo di ragionamento.",
  "claude-opus-4-1-20250805.description": "Claude Opus 4.1 è il modello più recente e avanzato di Anthropic per compiti altamente complessi, eccellendo in prestazioni, intelligenza, fluidità e comprensione.",
  "claude-opus-4-20250514.description": "Claude Opus 4 è il modello più potente di Anthropic per compiti altamente complessi, eccellendo in prestazioni, intelligenza, fluidità e comprensione.",
  "claude-opus-4-5-20251101.description": "Claude Opus 4.5 è il modello di punta di Anthropic, che combina intelligenza eccezionale e prestazioni scalabili, ideale per compiti complessi che richiedono risposte e ragionamenti di altissima qualità.",
  "claude-opus-4-6.description": "Claude Opus 4.6 è il modello più intelligente di Anthropic per la creazione di agenti e la programmazione.",
  "claude-sonnet-4-20250514-thinking.description": "Claude Sonnet 4 Thinking può produrre risposte quasi istantanee o riflessioni estese passo dopo passo con processo visibile.",
  "claude-sonnet-4-20250514.description": "Claude Sonnet 4 è in grado di fornire risposte quasi istantanee o ragionamenti estesi passo dopo passo con processo visibile.",
  "claude-sonnet-4-5-20250929.description": "Claude Sonnet 4.5 è il modello più intelligente mai realizzato da Anthropic.",
  "codegeex-4.description": "CodeGeeX-4 è un potente assistente di codifica AI che supporta Q&A multilingue e completamento del codice per aumentare la produttività degli sviluppatori.",
  "codegeex4-all-9b.description": "CodeGeeX4-ALL-9B è un modello multilingue di generazione di codice che supporta completamento e generazione di codice, interprete di codice, ricerca web, chiamata di funzioni e Q&A a livello di repository, coprendo un'ampia gamma di scenari di sviluppo software. È un modello di codice di alto livello con meno di 10B parametri.",
  "codegemma.description": "CodeGemma è un modello leggero per compiti di programmazione vari, che consente iterazioni rapide e facile integrazione.",
  "codegemma:2b.description": "CodeGemma è un modello leggero per compiti di programmazione vari, che consente iterazioni rapide e facile integrazione.",
  "codellama.description": "Code Llama è un LLM focalizzato sulla generazione e discussione di codice, con ampio supporto linguistico per i flussi di lavoro degli sviluppatori.",
  "codellama/CodeLlama-34b-Instruct-hf.description": "Code Llama è un LLM focalizzato sulla generazione e discussione di codice, con ampio supporto linguistico per i flussi di lavoro degli sviluppatori.",
  "codellama:13b.description": "Code Llama è un LLM focalizzato sulla generazione e discussione di codice, con ampio supporto linguistico per i flussi di lavoro degli sviluppatori.",
  "codellama:34b.description": "Code Llama è un LLM focalizzato sulla generazione e discussione di codice, con ampio supporto linguistico per i flussi di lavoro degli sviluppatori.",
  "codellama:70b.description": "Code Llama è un LLM focalizzato sulla generazione e discussione di codice, con ampio supporto linguistico per i flussi di lavoro degli sviluppatori.",
  "codeqwen.description": "CodeQwen1.5 è un modello linguistico di grandi dimensioni addestrato su un ampio set di dati di codice, progettato per compiti di programmazione complessi.",
  "codestral-latest.description": "Codestral è il nostro modello di codifica più avanzato; la versione v2 (gennaio 2025) è pensata per compiti a bassa latenza e alta frequenza come FIM, correzione del codice e generazione di test.",
  "codestral.description": "Codestral è il primo modello di codice di Mistral AI, che offre un forte supporto alla generazione di codice.",
  "codex-mini-latest.description": "codex-mini-latest è un modello o4-mini ottimizzato per Codex CLI. Per l'uso diretto via API, si consiglia di iniziare con gpt-4.1.",
  "cogito-2.1:671b.description": "Cogito v2.1 671B è un LLM open-source statunitense gratuito per uso commerciale, con prestazioni paragonabili ai modelli di punta, maggiore efficienza nel ragionamento sui token, contesto lungo da 128k e capacità complessive elevate.",
  "cogview-4.description": "CogView-4 è il primo modello open-source di testo-immagine di Zhipu in grado di generare caratteri cinesi. Migliora la comprensione semantica, la qualità delle immagini e la resa del testo in cinese/inglese, supporta prompt bilingue di lunghezza arbitraria e può generare immagini a qualsiasi risoluzione entro intervalli specificati.",
  "cohere-command-r-plus.description": "Command R+ è un modello avanzato ottimizzato per RAG, progettato per carichi di lavoro aziendali.",
  "cohere-command-r.description": "Command R è un modello generativo scalabile progettato per RAG e l'uso di strumenti, abilitando AI di livello produttivo.",
  "cohere/Cohere-command-r-plus.description": "Command R+ è un modello avanzato ottimizzato per RAG, progettato per carichi di lavoro aziendali.",
  "cohere/Cohere-command-r.description": "Command R è un modello generativo scalabile progettato per RAG e l'uso di strumenti, abilitando AI di livello produttivo.",
  "cohere/command-a.description": "Command A è il modello più potente di Cohere, eccellente nell'uso di strumenti, agenti, RAG e scenari multilingue. Ha una finestra di contesto da 256K, funziona con solo due GPU e offre una produttività superiore del 150% rispetto a Command R+ 08-2024.",
  "cohere/command-r-plus.description": "Command R+ è l'ultimo LLM di Cohere ottimizzato per chat e contesto lungo, con prestazioni eccezionali per passare dai prototipi alla produzione.",
  "cohere/command-r.description": "Command R è ottimizzato per chat e compiti a contesto lungo, posizionato come modello \"scalabile\" che bilancia alte prestazioni e precisione per passare dai prototipi alla produzione.",
  "cohere/embed-v4.0.description": "Un modello che classifica o converte testo, immagini o contenuti misti in embedding.",
  "comfyui/flux-dev.description": "FLUX.1 Dev è un modello testo-immagine di alta qualità (10–50 passaggi), ideale per output creativi e artistici di livello premium.",
  "comfyui/flux-kontext-dev.description": "FLUX.1 Kontext-dev è un modello di editing immagini che supporta modifiche guidate da testo, inclusi ritocchi locali e trasferimento di stile.",
  "comfyui/flux-krea-dev.description": "FLUX.1 Krea-dev è un modello testo-immagine con filtri di sicurezza integrati, sviluppato in collaborazione con Krea.",
  "comfyui/flux-schnell.description": "FLUX.1 Schnell è un modello testo-immagine ultra-veloce che genera immagini di alta qualità in 1-4 passaggi, ideale per uso in tempo reale e prototipazione rapida.",
  "comfyui/stable-diffusion-15.description": "Stable Diffusion 1.5 è un classico modello testo-immagine 512x512, ideale per prototipazione rapida ed esperimenti creativi.",
  "comfyui/stable-diffusion-35-inclclip.description": "Stable Diffusion 3.5 con encoder CLIP/T5 integrati non richiede file encoder esterni, adatto a modelli come sd3.5_medium_incl_clips con uso ridotto di risorse.",
  "comfyui/stable-diffusion-35.description": "Stable Diffusion 3.5 è un modello testo-immagine di nuova generazione con varianti Large e Medium. Richiede file encoder CLIP esterni e offre eccellente qualità d'immagine e aderenza ai prompt.",
  "comfyui/stable-diffusion-custom-refiner.description": "Modello personalizzato SDXL immagine-a-immagine. Usa custom_sd_lobe.safetensors come nome file del modello; se hai un VAE, usa custom_sd_vae_lobe.safetensors. Inserisci i file modello nelle cartelle richieste da Comfy.",
  "comfyui/stable-diffusion-custom.description": "Modello personalizzato SD testo-a-immagine. Usa custom_sd_lobe.safetensors come nome file del modello; se hai un VAE, usa custom_sd_vae_lobe.safetensors. Inserisci i file modello nelle cartelle richieste da Comfy.",
  "comfyui/stable-diffusion-refiner.description": "Modello SDXL immagine-a-immagine che esegue trasformazioni di alta qualità da immagini in input, supportando trasferimento di stile, restauro e variazioni creative.",
  "comfyui/stable-diffusion-xl.description": "SDXL è un modello testo-immagine che supporta generazione ad alta risoluzione 1024x1024 con migliore qualità e dettaglio visivo.",
  "command-a-03-2025.description": "Command A è il nostro modello più avanzato, eccellente nell'uso di strumenti, agenti, RAG e scenari multilingue. Ha una finestra di contesto di 256K, funziona con solo due GPU e offre una produttività superiore del 150% rispetto a Command R+ 08-2024.",
  "command-light-nightly.description": "Per ridurre il tempo tra le versioni principali, offriamo build notturne di Command. Per la serie command-light si chiama command-light-nightly. È la versione più recente ed esperimentale (potenzialmente instabile), aggiornata regolarmente senza preavviso, quindi non è consigliata per ambienti di produzione.",
  "command-light.description": "Una variante Command più piccola e veloce, quasi altrettanto capace ma più rapida.",
  "command-nightly.description": "Per ridurre il tempo tra le versioni principali, offriamo build notturne di Command. Per la serie Command si chiama command-nightly. È la versione più recente ed esperimentale (potenzialmente instabile), aggiornata regolarmente senza preavviso, quindi non è consigliata per ambienti di produzione.",
  "command-r-03-2024.description": "Command R è un modello di chat che segue istruzioni, con qualità superiore, maggiore affidabilità e una finestra di contesto più lunga rispetto ai modelli precedenti. Supporta flussi di lavoro complessi come generazione di codice, RAG, uso di strumenti e agenti.",
  "command-r-08-2024.description": "command-r-08-2024 è una versione aggiornata del modello Command R rilasciata ad agosto 2024.",
  "command-r-plus-04-2024.description": "command-r-plus è un alias di command-r-plus-04-2024, quindi usare command-r-plus nell'API punta a quel modello.",
  "command-r-plus-08-2024.description": "Command R+ è un modello di chat che segue istruzioni, con qualità superiore, maggiore affidabilità e una finestra di contesto più lunga rispetto ai modelli precedenti. È ideale per flussi di lavoro RAG complessi e uso multi-step di strumenti.",
  "command-r-plus.description": "Command R+ è un LLM ad alte prestazioni progettato per scenari aziendali reali e applicazioni complesse.",
  "command-r.description": "Command R è un LLM ottimizzato per chat e compiti a lungo contesto, ideale per interazioni dinamiche e gestione della conoscenza.",
  "command-r7b-12-2024.description": "command-r7b-12-2024 è un aggiornamento piccolo ed efficiente rilasciato a dicembre 2024. Eccelle in RAG, uso di strumenti e compiti per agenti che richiedono ragionamento complesso multi-step.",
  "command.description": "Un modello di chat che segue istruzioni, offrendo maggiore qualità e affidabilità nei compiti linguistici, con una finestra di contesto più lunga rispetto ai nostri modelli generativi base.",
  "computer-use-preview.description": "computer-use-preview è un modello specializzato per lo strumento \"uso del computer\", addestrato per comprendere ed eseguire compiti legati al computer.",
  "dall-e-2.description": "Modello DALL·E di seconda generazione con generazione di immagini più realistica e accurata e risoluzione 4× rispetto alla prima generazione.",
  "dall-e-3.description": "L'ultimo modello DALL·E, rilasciato a novembre 2023, supporta generazione di immagini più realistica e accurata con maggiore dettaglio.",
  "databricks/dbrx-instruct.description": "DBRX Instruct offre una gestione delle istruzioni altamente affidabile in diversi settori.",
  "deepseek-ai/DeepSeek-OCR.description": "DeepSeek-OCR è un modello visione-linguaggio sviluppato da DeepSeek AI, focalizzato sull'OCR e sulla \"compressione ottica contestuale\". Esplora la compressione del contesto dalle immagini, elabora documenti in modo efficiente e li converte in testo strutturato (es. Markdown). Riconosce accuratamente il testo nelle immagini, ideale per la digitalizzazione di documenti, l'estrazione di testo e l'elaborazione strutturata.",
  "deepseek-ai/DeepSeek-R1-0528-Qwen3-8B.description": "DeepSeek-R1-0528-Qwen3-8B distilla il chain-of-thought da DeepSeek-R1-0528 nel modello Qwen3 8B Base. Raggiunge lo stato dell'arte tra i modelli open-source, superando Qwen3 8B del 10% su AIME 2024 e uguagliando le prestazioni di Qwen3-235B-thinking. Eccelle nel ragionamento matematico, nella programmazione e nei benchmark di logica generale. Condivide l'architettura di Qwen3-8B ma utilizza il tokenizer di DeepSeek-R1-0528.",
  "deepseek-ai/DeepSeek-R1-0528.description": "DeepSeek R1 sfrutta maggiore potenza computazionale e ottimizzazioni algoritmiche post-addestramento per approfondire il ragionamento. Ottiene ottimi risultati nei benchmark di matematica, programmazione e logica generale, avvicinandosi a modelli leader come o3 e Gemini 2.5 Pro.",
  "deepseek-ai/DeepSeek-R1-Distill-Llama-70B.description": "I modelli distillati DeepSeek-R1 utilizzano apprendimento per rinforzo (RL) e dati cold-start per migliorare il ragionamento e stabilire nuovi benchmark multi-task per modelli open-source.",
  "deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B.description": "I modelli distillati DeepSeek-R1 utilizzano apprendimento per rinforzo (RL) e dati cold-start per migliorare il ragionamento e stabilire nuovi benchmark multi-task per modelli open-source.",
  "deepseek-ai/DeepSeek-R1-Distill-Qwen-14B.description": "I modelli distillati DeepSeek-R1 utilizzano apprendimento per rinforzo (RL) e dati cold-start per migliorare il ragionamento e stabilire nuovi benchmark multi-task per modelli open-source.",
  "deepseek-ai/DeepSeek-R1-Distill-Qwen-32B.description": "DeepSeek-R1-Distill-Qwen-32B è distillato da Qwen2.5-32B e ottimizzato su 800.000 campioni curati da DeepSeek-R1. Eccelle in matematica, programmazione e ragionamento, ottenendo risultati eccellenti su AIME 2024, MATH-500 (94,3% di accuratezza) e GPQA Diamond.",
  "deepseek-ai/DeepSeek-R1-Distill-Qwen-7B.description": "DeepSeek-R1-Distill-Qwen-7B è distillato da Qwen2.5-Math-7B e ottimizzato su 800.000 campioni curati da DeepSeek-R1. Ottiene ottime prestazioni: 92,8% su MATH-500, 55,5% su AIME 2024 e un punteggio CodeForces di 1189 per un modello da 7B.",
  "deepseek-ai/DeepSeek-R1.description": "DeepSeek-R1 migliora il ragionamento grazie a dati cold-start e apprendimento per rinforzo, stabilendo nuovi benchmark multi-task per modelli open-source e superando OpenAI-o1-mini.",
  "deepseek-ai/DeepSeek-V2.5.description": "DeepSeek-V2.5 aggiorna DeepSeek-V2-Chat e DeepSeek-Coder-V2-Instruct, combinando capacità generali e di programmazione. Migliora la scrittura e il rispetto delle istruzioni per un migliore allineamento alle preferenze, con progressi significativi su AlpacaEval 2.0, ArenaHard, AlignBench e MT-Bench.",
  "deepseek-ai/DeepSeek-V3.1-Terminus.description": "DeepSeek-V3.1-Terminus è una versione aggiornata del modello V3.1, concepito come agente ibrido LLM. Risolve problemi segnalati dagli utenti e migliora stabilità, coerenza linguistica e riduce caratteri anomali o misti cinese/inglese. Integra modalità di pensiero e non-pensiero con template di chat per passaggi flessibili. Migliora anche le prestazioni di Code Agent e Search Agent per un uso più affidabile degli strumenti e compiti multi-step.",
  "deepseek-ai/DeepSeek-V3.1.description": "DeepSeek V3.1 utilizza un'architettura di ragionamento ibrida e supporta sia modalità di pensiero che non-pensiero.",
  "deepseek-ai/DeepSeek-V3.2-Exp.description": "DeepSeek-V3.2-Exp è una versione sperimentale della serie V3.2 che fa da ponte verso la prossima architettura. Aggiunge DeepSeek Sparse Attention (DSA) sopra V3.1-Terminus per migliorare l'efficienza nell'addestramento e inferenza su contesti lunghi, con ottimizzazioni per l'uso di strumenti, comprensione di documenti lunghi e ragionamento multi-step. Ideale per esplorare una maggiore efficienza di ragionamento con budget di contesto estesi.",
  "deepseek-ai/DeepSeek-V3.description": "DeepSeek-V3 è un modello MoE con 671 miliardi di parametri che utilizza MLA e DeepSeekMoE con bilanciamento del carico senza perdite per un addestramento e inferenza efficienti. Preaddestrato su 14,8 trilioni di token di alta qualità con SFT e RL, supera altri modelli open-source e si avvicina ai modelli chiusi leader.",
  "deepseek-ai/deepseek-llm-67b-chat.description": "DeepSeek LLM Chat (67B) è un modello innovativo che offre una profonda comprensione linguistica e interazione.",
  "deepseek-ai/deepseek-v3.1-terminus.description": "DeepSeek V3.1 è un modello di nuova generazione per il ragionamento, con capacità avanzate di ragionamento complesso e chain-of-thought per compiti di analisi approfondita.",
  "deepseek-ai/deepseek-v3.1.description": "DeepSeek V3.1 è un modello di nuova generazione per il ragionamento, con capacità avanzate di ragionamento complesso e chain-of-thought per compiti di analisi approfondita.",
  "deepseek-ai/deepseek-vl2.description": "DeepSeek-VL2 è un modello visione-linguaggio MoE basato su DeepSeekMoE-27B con attivazione sparsa, che raggiunge prestazioni elevate con solo 4,5B di parametri attivi. Eccelle in QA visivo, OCR, comprensione di documenti/tabelle/grafici e grounding visivo.",
  "deepseek-chat.description": "Un nuovo modello open-source che combina capacità generali e di programmazione. Mantiene il dialogo naturale del modello conversazionale e la potenza del modello di codifica, con un migliore allineamento alle preferenze. DeepSeek-V2.5 migliora anche la scrittura e l’esecuzione di istruzioni.",
  "deepseek-coder-33B-instruct.description": "DeepSeek Coder 33B è un modello linguistico per il codice addestrato su 2 trilioni di token (87% codice, 13% testo in cinese/inglese). Introduce una finestra di contesto da 16K e compiti di completamento intermedio, offrendo completamento di codice a livello di progetto e riempimento di snippet.",
  "deepseek-coder-v2.description": "DeepSeek Coder V2 è un modello MoE open-source per il codice che ottiene ottimi risultati nei compiti di programmazione, comparabile a GPT-4 Turbo.",
  "deepseek-coder-v2:236b.description": "DeepSeek Coder V2 è un modello MoE open-source per il codice che ottiene ottimi risultati nei compiti di programmazione, comparabile a GPT-4 Turbo.",
  "deepseek-ocr.description": "DeepSeek-OCR è un modello visione-linguaggio sviluppato da DeepSeek AI, focalizzato sull'OCR e sulla \"compressione ottica contestuale\". Esplora la compressione delle informazioni contestuali dalle immagini, elabora documenti in modo efficiente e li converte in formati di testo strutturato come Markdown. Riconosce accuratamente il testo nelle immagini, rendendolo ideale per la digitalizzazione di documenti, l'estrazione di testo e l'elaborazione strutturata.",
  "deepseek-r1-0528.description": "Modello completo da 685B rilasciato il 28/05/2025. DeepSeek-R1 utilizza RL su larga scala nel post-addestramento, migliorando notevolmente il ragionamento con dati etichettati minimi, ottenendo ottimi risultati in matematica, programmazione e ragionamento in linguaggio naturale.",
  "deepseek-r1-250528.description": "DeepSeek R1 250528 è il modello completo di ragionamento DeepSeek-R1 per compiti complessi di matematica e logica.",
  "deepseek-r1-70b-fast-online.description": "DeepSeek R1 70B edizione veloce con ricerca web in tempo reale, che fornisce risposte più rapide mantenendo alte prestazioni.",
  "deepseek-r1-70b-online.description": "DeepSeek R1 70B edizione standard con ricerca web in tempo reale, adatta per chat aggiornate e compiti testuali.",
  "deepseek-r1-distill-llama-70b.description": "DeepSeek R1 Distill Llama 70B combina il ragionamento R1 con l'ecosistema Llama.",
  "deepseek-r1-distill-llama-8b.description": "DeepSeek-R1-Distill-Llama-8B è distillato da Llama-3.1-8B utilizzando gli output di DeepSeek R1.",
  "deepseek-r1-distill-llama.description": "deepseek-r1-distill-llama è distillato da DeepSeek-R1 su Llama.",
  "deepseek-r1-distill-qianfan-70b.description": "DeepSeek R1 Distill Qianfan 70B è una distillazione R1 basata su Qianfan-70B con elevato valore.",
  "deepseek-r1-distill-qianfan-8b.description": "DeepSeek R1 Distill Qianfan 8B è una distillazione R1 basata su Qianfan-8B per applicazioni di piccole e medie dimensioni.",
  "deepseek-r1-distill-qianfan-llama-70b.description": "DeepSeek R1 Distill Qianfan Llama 70B è una distillazione R1 basata su Llama-70B.",
  "deepseek-r1-distill-qwen-1.5b.description": "DeepSeek R1 Distill Qwen 1.5B è un modello distillato ultra-leggero per ambienti con risorse molto limitate.",
  "deepseek-r1-distill-qwen-14b.description": "DeepSeek R1 Distill Qwen 14B è un modello distillato di medie dimensioni per implementazioni in scenari multipli.",
  "deepseek-r1-distill-qwen-32b.description": "DeepSeek R1 Distill Qwen 32B è una distillazione R1 basata su Qwen-32B, che bilancia prestazioni e costi.",
  "deepseek-r1-distill-qwen-7b.description": "DeepSeek R1 Distill Qwen 7B è un modello distillato leggero per ambienti edge e aziendali privati.",
  "deepseek-r1-distill-qwen.description": "deepseek-r1-distill-qwen è distillato da DeepSeek-R1 su Qwen.",
  "deepseek-r1-fast-online.description": "DeepSeek R1 versione completa veloce con ricerca web in tempo reale, che combina capacità su scala 671B e risposte rapide.",
  "deepseek-r1-online.description": "DeepSeek R1 versione completa con 671 miliardi di parametri e ricerca web in tempo reale, che offre una comprensione e generazione più avanzate.",
  "deepseek-r1.description": "DeepSeek-R1 utilizza dati cold-start prima dell'RL e ottiene prestazioni comparabili a OpenAI-o1 in matematica, programmazione e ragionamento.",
  "deepseek-reasoner.description": "La modalità di pensiero DeepSeek V3.2 produce una catena di ragionamento prima della risposta finale per migliorare l’accuratezza.",
  "deepseek-v2.description": "DeepSeek V2 è un modello MoE efficiente per un'elaborazione conveniente.",
  "deepseek-v2:236b.description": "DeepSeek V2 236B è il modello DeepSeek focalizzato sul codice con forte capacità di generazione.",
  "deepseek-v3-0324.description": "DeepSeek-V3-0324 è un modello MoE con 671 miliardi di parametri, con punti di forza nella programmazione, capacità tecnica, comprensione del contesto e gestione di testi lunghi.",
  "deepseek-v3.1-terminus.description": "DeepSeek-V3.1-Terminus è un LLM ottimizzato per terminali, sviluppato da DeepSeek e progettato specificamente per dispositivi a riga di comando.",
  "deepseek-v3.1-think-250821.description": "DeepSeek V3.1 Think 250821 è il modello di pensiero profondo corrispondente alla versione Terminus, costruito per un ragionamento ad alte prestazioni.",
  "deepseek-v3.1.description": "DeepSeek-V3.1 è un nuovo modello di ragionamento ibrido di DeepSeek, che supporta modalità di pensiero e non-pensiero, offrendo un'efficienza di pensiero superiore rispetto a DeepSeek-R1-0528. Le ottimizzazioni post-addestramento migliorano notevolmente l'uso degli strumenti da parte degli agenti e le prestazioni nei compiti. Supporta una finestra di contesto di 128k e fino a 64k token in output.",
  "deepseek-v3.1:671b.description": "DeepSeek V3.1 è un modello di ragionamento di nuova generazione con capacità avanzate di ragionamento complesso e catene di pensiero, ideale per compiti che richiedono analisi approfondite.",
  "deepseek-v3.2-exp.description": "deepseek-v3.2-exp introduce l'attenzione sparsa per migliorare l'efficienza di addestramento e inferenza su testi lunghi, a un costo inferiore rispetto a deepseek-v3.1.",
  "deepseek-v3.2-think.description": "DeepSeek V3.2 Think è un modello completo di pensiero profondo con capacità potenziate di ragionamento a catena lunga.",
  "deepseek-v3.2.description": "DeepSeek-V3.2 è il primo modello ibrido di ragionamento di DeepSeek che integra il pensiero nell'uso degli strumenti. Utilizza un'architettura efficiente per ridurre il calcolo, l'apprendimento per rinforzo su larga scala per potenziare le capacità e dati sintetici su larga scala per rafforzare la generalizzazione. La combinazione di questi tre elementi consente prestazioni paragonabili a GPT-5-High, con una lunghezza di output significativamente ridotta, diminuendo notevolmente il carico computazionale e i tempi di attesa per l'utente.",
  "deepseek-v3.description": "DeepSeek-V3 è un potente modello MoE con 671 miliardi di parametri totali e 37 miliardi attivi per token.",
  "deepseek-vl2-small.description": "DeepSeek VL2 Small è una versione multimodale leggera, pensata per ambienti con risorse limitate e alta concorrenza.",
  "deepseek-vl2.description": "DeepSeek VL2 è un modello multimodale per la comprensione immagine-testo e domande visive dettagliate.",
  "deepseek/deepseek-chat-v3-0324.description": "DeepSeek V3 è un modello MoE da 685 miliardi di parametri e rappresenta l'ultima iterazione della serie di chat di punta di DeepSeek.\n\nSi basa su [DeepSeek V3](/deepseek/deepseek-chat-v3) e offre prestazioni elevate in vari compiti.",
  "deepseek/deepseek-chat-v3-0324:free.description": "DeepSeek V3 è un modello MoE da 685 miliardi di parametri e rappresenta l'ultima iterazione della serie di chat di punta di DeepSeek.\n\nSi basa su [DeepSeek V3](/deepseek/deepseek-chat-v3) e offre prestazioni elevate in vari compiti.",
  "deepseek/deepseek-chat-v3.1.description": "DeepSeek-V3.1 è il modello di ragionamento ibrido a lungo contesto di DeepSeek, che supporta modalità miste di pensiero/non-pensiero e integrazione con strumenti.",
  "deepseek/deepseek-chat.description": "DeepSeek-V3 è il modello di ragionamento ibrido ad alte prestazioni di DeepSeek, progettato per compiti complessi e integrazione con strumenti.",
  "deepseek/deepseek-math-v2.description": "DeepSeek Math V2 è un modello che ha compiuto importanti progressi nelle capacità di ragionamento matematico. La sua innovazione principale risiede nel meccanismo di addestramento \"auto-verifica\" e ha raggiunto livelli da medaglia d'oro in diverse competizioni matematiche di alto livello.",
  "deepseek/deepseek-r1-0528.description": "DeepSeek R1 0528 è una variante aggiornata focalizzata sulla disponibilità aperta e su un ragionamento più profondo.",
  "deepseek/deepseek-r1-0528:free.description": "DeepSeek-R1 migliora notevolmente il ragionamento utilizzando un numero minimo di dati etichettati e genera una catena di pensiero prima della risposta finale per aumentare l'accuratezza.",
  "deepseek/deepseek-r1-distill-llama-70b.description": "DeepSeek R1 Distill Llama 70B è un LLM distillato basato su Llama 3.3 70B, ottimizzato utilizzando gli output di DeepSeek R1 per raggiungere prestazioni competitive con i modelli di frontiera di grandi dimensioni.",
  "deepseek/deepseek-r1-distill-llama-8b.description": "DeepSeek R1 Distill Llama 8B è un LLM distillato basato su Llama-3.1-8B-Instruct, addestrato utilizzando gli output di DeepSeek R1.",
  "deepseek/deepseek-r1-distill-qwen-14b.description": "DeepSeek R1 Distill Qwen 14B è un LLM distillato basato su Qwen 2.5 14B, addestrato utilizzando gli output di DeepSeek R1. Supera OpenAI o1-mini in diversi benchmark, raggiungendo risultati all'avanguardia tra i modelli densi. Risultati salienti:\nAIME 2024 pass@1: 69.7\nMATH-500 pass@1: 93.9\nCodeForces Rating: 1481\nIl fine-tuning sugli output di DeepSeek R1 garantisce prestazioni competitive con i modelli di frontiera più grandi.",
  "deepseek/deepseek-r1-distill-qwen-32b.description": "DeepSeek R1 Distill Qwen 32B è un LLM distillato basato su Qwen 2.5 32B, addestrato utilizzando gli output di DeepSeek R1. Supera OpenAI o1-mini in diversi benchmark, raggiungendo risultati all'avanguardia tra i modelli densi. Risultati salienti:\nAIME 2024 pass@1: 72.6\nMATH-500 pass@1: 94.3\nCodeForces Rating: 1691\nIl fine-tuning sugli output di DeepSeek R1 garantisce prestazioni competitive con i modelli di frontiera più grandi.",
  "deepseek/deepseek-r1.description": "DeepSeek R1 è stato aggiornato a DeepSeek-R1-0528. Con maggiore potenza computazionale e ottimizzazioni algoritmiche post-addestramento, migliora significativamente la profondità e la capacità di ragionamento. Offre prestazioni elevate in benchmark di matematica, programmazione e logica generale, avvicinandosi a leader come o3 e Gemini 2.5 Pro.",
  "deepseek/deepseek-r1/community.description": "DeepSeek R1 è l'ultimo modello open-source rilasciato dal team DeepSeek, con prestazioni di ragionamento molto elevate, in particolare in matematica, programmazione e compiti logici, comparabili a OpenAI o1.",
  "deepseek/deepseek-r1:free.description": "DeepSeek-R1 migliora notevolmente il ragionamento utilizzando un numero minimo di dati etichettati e genera una catena di pensiero prima della risposta finale per aumentare l'accuratezza.",
  "deepseek/deepseek-reasoner.description": "DeepSeek-V3 Thinking (reasoner) è il modello sperimentale di ragionamento di DeepSeek, adatto a compiti di alta complessità.",
  "deepseek/deepseek-v3.1-base.description": "DeepSeek V3.1 Base è una versione migliorata del modello DeepSeek V3.",
  "deepseek/deepseek-v3.description": "Un LLM veloce e generico con capacità di ragionamento potenziate.",
  "deepseek/deepseek-v3/community.description": "DeepSeek-V3 rappresenta un importante progresso nella velocità di ragionamento rispetto ai modelli precedenti. Si posiziona al primo posto tra i modelli open-source e rivaleggia con i modelli chiusi più avanzati. DeepSeek-V3 adotta l'attenzione latente multi-testa (MLA) e l'architettura DeepSeekMoE, entrambe validate in DeepSeek-V2. Introduce inoltre una strategia ausiliaria lossless per il bilanciamento del carico e un obiettivo di addestramento con previsione multi-token per prestazioni superiori.",
  "deepseek_r1.description": "DeepSeek-R1 è un modello di ragionamento guidato dall'apprendimento per rinforzo che affronta problemi di ripetizione e leggibilità. Prima dell'RL, utilizza dati di avvio a freddo per migliorare ulteriormente le prestazioni di ragionamento. È comparabile a OpenAI-o1 in matematica, programmazione e compiti logici, con un addestramento attentamente progettato che migliora i risultati complessivi.",
  "deepseek_r1_distill_llama_70b.description": "DeepSeek-R1-Distill-Llama-70B è distillato da Llama-3.3-70B-Instruct. Fa parte della serie DeepSeek-R1, è ottimizzato su campioni generati da DeepSeek-R1 e offre prestazioni elevate in matematica, programmazione e ragionamento.",
  "deepseek_r1_distill_qwen_14b.description": "DeepSeek-R1-Distill-Qwen-14B è distillato da Qwen2.5-14B e ottimizzato su 800.000 campioni curati generati da DeepSeek-R1, offrendo un ragionamento solido.",
  "deepseek_r1_distill_qwen_32b.description": "DeepSeek-R1-Distill-Qwen-32B è distillato da Qwen2.5-32B e ottimizzato su 800.000 campioni curati generati da DeepSeek-R1, eccellendo in matematica, programmazione e ragionamento.",
  "devstral-2:123b.description": "Devstral 2 123B eccelle nell'utilizzo di strumenti per esplorare basi di codice, modificare più file e supportare agenti di ingegneria del software.",
  "doubao-1.5-lite-32k.description": "Doubao-1.5-lite è un nuovo modello leggero con risposta ultra-rapida, che offre qualità e latenza di livello superiore.",
  "doubao-1.5-pro-256k.description": "Doubao-1.5-pro-256k è un aggiornamento completo di Doubao-1.5-Pro, con un miglioramento delle prestazioni complessive del 10%. Supporta una finestra contestuale di 256k e fino a 12k token in output, offrendo prestazioni superiori, una finestra più ampia e un ottimo rapporto qualità-prezzo per casi d'uso più ampi.",
  "doubao-1.5-pro-32k.description": "Doubao-1.5-pro è un modello di punta di nuova generazione con miglioramenti su tutta la linea, eccellente in conoscenza, programmazione e ragionamento.",
  "doubao-1.5-thinking-pro-m.description": "Doubao-1.5 è un nuovo modello di ragionamento profondo (la versione m include ragionamento profondo multimodale nativo) che eccelle in matematica, programmazione, ragionamento scientifico e compiti generali come la scrittura creativa. Raggiunge o si avvicina ai migliori risultati nei benchmark come AIME 2024, Codeforces e GPQA. Supporta una finestra contestuale di 128k e 16k token in output.",
  "doubao-1.5-thinking-pro.description": "Doubao-1.5 è un nuovo modello di ragionamento profondo che eccelle in matematica, programmazione, ragionamento scientifico e compiti generali come la scrittura creativa. Raggiunge o si avvicina ai migliori risultati nei benchmark come AIME 2024, Codeforces e GPQA. Supporta una finestra contestuale di 128k e 16k token in output.",
  "doubao-1.5-thinking-vision-pro.description": "Un nuovo modello visivo di ragionamento profondo con una comprensione e un ragionamento multimodale più avanzati, che raggiunge risultati SOTA in 37 su 59 benchmark pubblici.",
  "doubao-1.5-ui-tars.description": "Doubao-1.5-UI-TARS è un modello agente nativo focalizzato sulle interfacce grafiche, che interagisce in modo fluido con le interfacce attraverso percezione, ragionamento e azione simili a quelle umane.",
  "doubao-1.5-vision-lite.description": "Doubao-1.5-vision-lite è un modello multimodale aggiornato che supporta immagini a qualsiasi risoluzione e con rapporti d'aspetto estremi, migliorando il ragionamento visivo, il riconoscimento di documenti, la comprensione dei dettagli e il rispetto delle istruzioni. Supporta una finestra contestuale di 128k e fino a 16k token in output.",
  "doubao-1.5-vision-pro-32k.description": "Doubao-1.5-vision-pro è un modello multimodale aggiornato che supporta immagini a qualsiasi risoluzione e con rapporti d'aspetto estremi, migliorando il ragionamento visivo, il riconoscimento di documenti, la comprensione dei dettagli e il rispetto delle istruzioni.",
  "doubao-1.5-vision-pro.description": "Doubao-1.5-vision-pro è un modello multimodale aggiornato che supporta immagini a qualsiasi risoluzione e con rapporti d'aspetto estremi, migliorando il ragionamento visivo, il riconoscimento di documenti, la comprensione dei dettagli e il rispetto delle istruzioni.",
  "doubao-lite-128k.description": "Risposta ultra-rapida con un miglior rapporto qualità-prezzo, offrendo scelte più flessibili in diversi scenari. Supporta ragionamento e fine-tuning con una finestra contestuale di 128k.",
  "doubao-lite-32k.description": "Risposta ultra-rapida con un miglior rapporto qualità-prezzo, offrendo scelte più flessibili in diversi scenari. Supporta ragionamento e fine-tuning con una finestra contestuale di 32k.",
  "doubao-lite-4k.description": "Risposta ultra-rapida con un miglior rapporto qualità-prezzo, offrendo scelte più flessibili in diversi scenari. Supporta ragionamento e fine-tuning con una finestra contestuale di 4k.",
  "doubao-pro-256k.description": "Il modello di punta con le migliori prestazioni per compiti complessi, con risultati eccellenti in QA con riferimento, riassunti, creazione, classificazione del testo e simulazione di ruoli. Supporta ragionamento e fine-tuning con una finestra contestuale di 256k.",
  "doubao-pro-32k.description": "Il modello di punta con le migliori prestazioni per compiti complessi, con risultati eccellenti in QA con riferimento, riassunti, creazione, classificazione del testo e simulazione di ruoli. Supporta ragionamento e fine-tuning con una finestra contestuale di 32k.",
  "doubao-seed-1.6-flash.description": "Doubao-Seed-1.6-flash è un modello multimodale di ragionamento profondo ultra-rapido con TPOT fino a 10ms. Supporta testo e visione, supera il precedente modello lite nella comprensione del testo e si equipara ai modelli pro concorrenti nella visione. Supporta una finestra contestuale di 256k e fino a 16k token in output.",
  "doubao-seed-1.6-lite.description": "Doubao-Seed-1.6-lite è un nuovo modello multimodale di ragionamento profondo con sforzo di ragionamento regolabile (Minimo, Basso, Medio, Alto), che offre un miglior rapporto qualità-prezzo ed è una scelta solida per compiti comuni, con una finestra contestuale fino a 256k.",
  "doubao-seed-1.6-thinking.description": "Doubao-Seed-1.6 potenzia significativamente il ragionamento, migliorando ulteriormente le capacità fondamentali in programmazione, matematica e logica rispetto a Doubao-1.5-thinking-pro, aggiungendo anche la comprensione visiva. Supporta una finestra contestuale di 256k e fino a 16k token in output.",
  "doubao-seed-1.6-vision.description": "Doubao-Seed-1.6-vision è un modello visivo di ragionamento profondo che offre una comprensione e un ragionamento multimodale più forti per l'istruzione, la revisione di immagini, l'ispezione/sicurezza e la ricerca AI con domande e risposte. Supporta una finestra contestuale di 256k e fino a 64k token in output.",
  "doubao-seed-1.6.description": "Doubao-Seed-1.6 è un nuovo modello multimodale di ragionamento profondo con modalità auto, thinking e non-thinking. In modalità non-thinking, supera significativamente Doubao-1.5-pro/250115. Supporta una finestra contestuale di 256k e fino a 16k token in output.",
  "doubao-seed-1.8.description": "Doubao-Seed-1.8 offre una comprensione multimodale più avanzata e capacità da agente, supporta input di testo/immagine/video e memorizzazione del contesto, garantendo prestazioni eccellenti in compiti complessi.",
  "doubao-seed-code.description": "Doubao-Seed-Code è ottimizzato in profondità per la programmazione agentica, supporta input multimodali (testo/immagine/video) e una finestra contestuale di 256k, è compatibile con l'API Anthropic ed è adatto a flussi di lavoro di programmazione, comprensione visiva e agenti.",
  "doubao-seededit-3-0-i2i-250628.description": "Il modello di immagini Doubao di ByteDance Seed supporta input di testo e immagini con generazione di immagini di alta qualità e altamente controllabile. Supporta l'editing di immagini guidato da testo, con dimensioni di output tra 512 e 1536 sul lato lungo.",
  "doubao-seedream-3-0-t2i-250415.description": "Seedream 3.0 è un modello di generazione di immagini di ByteDance Seed, che supporta input di testo e immagini con generazione di immagini di alta qualità e altamente controllabile. Genera immagini da prompt testuali.",
  "doubao-seedream-4-0-250828.description": "Seedream 4.0 è un modello di generazione di immagini di ByteDance Seed, che supporta input di testo e immagini con generazione di immagini di alta qualità e altamente controllabile. Genera immagini da prompt testuali.",
  "doubao-vision-lite-32k.description": "Doubao-vision è un modello multimodale di Doubao con forte comprensione e ragionamento visivo, oltre a un'accurata esecuzione delle istruzioni. Eccelle in compiti di estrazione immagine-testo e ragionamento basato su immagini, abilitando scenari di QA visivo più complessi e ampi.",
  "doubao-vision-pro-32k.description": "Doubao-vision è un modello multimodale di Doubao con forte comprensione e ragionamento visivo, oltre a un'accurata esecuzione delle istruzioni. Eccelle in compiti di estrazione immagine-testo e ragionamento basato su immagini, abilitando scenari di QA visivo più complessi e ampi.",
  "emohaa.description": "Emohaa è un modello per la salute mentale con capacità di consulenza professionale per aiutare gli utenti a comprendere le problematiche emotive.",
  "ernie-4.5-0.3b.description": "ERNIE 4.5 0.3B è un modello open-source leggero per implementazioni locali e personalizzate.",
  "ernie-4.5-21b-a3b.description": "ERNIE 4.5 21B A3B è un modello open-source con un numero elevato di parametri e una maggiore capacità di comprensione e generazione.",
  "ernie-4.5-300b-a47b.description": "ERNIE 4.5 300B A47B è il modello MoE ultra-large di Baidu ERNIE con eccellenti capacità di ragionamento.",
  "ernie-4.5-8k-preview.description": "ERNIE 4.5 8K Preview è un modello di anteprima con finestra contestuale da 8K per la valutazione di ERNIE 4.5.",
  "ernie-4.5-turbo-128k-preview.description": "Anteprima di ERNIE 4.5 Turbo 128K con capacità di livello release, adatto per integrazione e test canary.",
  "ernie-4.5-turbo-128k.description": "ERNIE 4.5 Turbo 128K è un modello generale ad alte prestazioni con supporto alla ricerca e chiamata di strumenti per QA, programmazione e scenari agentici.",
  "ernie-4.5-turbo-32k.description": "ERNIE 4.5 Turbo 32K è una versione con contesto medio per QA, recupero da base di conoscenza e dialoghi multi-turno.",
  "ernie-4.5-turbo-latest.description": "Ultima versione di ERNIE 4.5 Turbo con prestazioni ottimizzate, ideale come modello principale in produzione.",
  "ernie-4.5-turbo-vl-32k-preview.description": "ERNIE 4.5 Turbo VL 32K Preview è un modello multimodale di anteprima da 32K per valutare la capacità visiva su contesti lunghi.",
  "ernie-4.5-turbo-vl-32k.description": "ERNIE 4.5 Turbo VL 32K è una versione multimodale medio-lunga per la comprensione combinata di documenti lunghi e immagini.",
  "ernie-4.5-turbo-vl-latest.description": "ERNIE 4.5 Turbo VL Latest è la versione multimodale più recente con migliorata comprensione e ragionamento immagine-testo.",
  "ernie-4.5-turbo-vl-preview.description": "ERNIE 4.5 Turbo VL Preview è un modello multimodale di anteprima per comprensione e generazione immagine-testo, adatto a QA visivo e comprensione dei contenuti.",
  "ernie-4.5-turbo-vl.description": "ERNIE 4.5 Turbo VL è un modello multimodale maturo per la comprensione e il riconoscimento immagine-testo in produzione.",
  "ernie-4.5-vl-28b-a3b.description": "ERNIE 4.5 VL 28B A3B è un modello multimodale open-source per la comprensione e il ragionamento immagine-testo.",
  "ernie-5.0-thinking-latest.description": "Wenxin 5.0 Thinking è un modello di punta nativo full-modal con modellazione unificata di testo, immagini, audio e video. Offre ampi miglioramenti nelle capacità per domande complesse, creazione e scenari con agenti.",
  "ernie-5.0-thinking-preview.description": "Wenxin 5.0 Thinking Preview è un modello di punta nativo full-modal con modellazione unificata di testo, immagini, audio e video. Offre ampi miglioramenti nelle capacità per domande complesse, creazione e scenari con agenti.",
  "ernie-char-8k.description": "ERNIE Character 8K è un modello di dialogo con personalità per la creazione di personaggi IP e conversazioni di compagnia a lungo termine.",
  "ernie-char-fiction-8k-preview.description": "ERNIE Character Fiction 8K Preview è un’anteprima del modello per la creazione di personaggi e trame, utile per valutazioni e test di funzionalità.",
  "ernie-char-fiction-8k.description": "ERNIE Character Fiction 8K è un modello con personalità per romanzi e creazione di trame, adatto alla generazione di storie di lunga durata.",
  "ernie-irag-edit.description": "ERNIE iRAG Edit è un modello per l’editing di immagini che supporta cancellazione, ritocco e generazione di varianti.",
  "ernie-lite-pro-128k.description": "ERNIE Lite Pro 128K è un modello leggero ad alte prestazioni per scenari sensibili a latenza e costi.",
  "ernie-novel-8k.description": "ERNIE Novel 8K è progettato per romanzi lunghi e trame IP con narrazioni multi-personaggio.",
  "ernie-speed-pro-128k.description": "ERNIE Speed Pro 128K è un modello ad alto valore e alta concorrenza per servizi online su larga scala e applicazioni aziendali.",
  "ernie-x1-turbo-32k.description": "ERNIE X1 Turbo 32K è un modello di pensiero veloce con contesto da 32K per ragionamento complesso e chat multi-turno.",
  "ernie-x1.1-preview.description": "ERNIE X1.1 Preview è un’anteprima del modello di pensiero per valutazioni e test.",
  "fal-ai/bytedance/seedream/v4.description": "Seedream 4.0 è un modello di generazione di immagini di ByteDance Seed, che supporta input testuali e visivi con generazione di immagini di alta qualità e altamente controllabile. Genera immagini a partire da prompt testuali.",
  "fal-ai/flux-kontext/dev.description": "FLUX.1 è un modello focalizzato sull’editing di immagini, che supporta input di testo e immagini.",
  "fal-ai/flux-pro/kontext.description": "FLUX.1 Kontext [pro] accetta testo e immagini di riferimento come input, consentendo modifiche locali mirate e trasformazioni complesse della scena globale.",
  "fal-ai/flux/krea.description": "Flux Krea [dev] è un modello di generazione di immagini con una preferenza estetica per immagini più realistiche e naturali.",
  "fal-ai/flux/schnell.description": "FLUX.1 [schnell] è un modello di generazione di immagini con 12 miliardi di parametri progettato per output rapidi e di alta qualità.",
  "fal-ai/hunyuan-image/v3.description": "Un potente modello nativo multimodale per la generazione di immagini.",
  "fal-ai/imagen4/preview.description": "Modello di generazione di immagini di alta qualità sviluppato da Google.",
  "fal-ai/nano-banana.description": "Nano Banana è il modello multimodale nativo più recente, veloce ed efficiente di Google, che consente la generazione e l’editing di immagini tramite conversazione.",
  "fal-ai/qwen-image-edit.description": "Modello professionale di editing immagini del team Qwen che supporta modifiche semantiche e visive, modifica precisa di testo in cinese e inglese, e consente trasformazioni di alta qualità come il trasferimento di stile e la rotazione di oggetti.",
  "fal-ai/qwen-image.description": "Potente modello di generazione di immagini del team Qwen con eccellente resa del testo cinese e stili visivi diversificati.",
  "flux-1-schnell.description": "Modello testo-immagine da 12 miliardi di parametri di Black Forest Labs che utilizza la distillazione latente avversariale per generare immagini di alta qualità in 1-4 passaggi. Con licenza Apache-2.0 per uso personale, di ricerca e commerciale.",
  "flux-dev.description": "FLUX.1 [dev] è un modello distillato a pesi aperti per uso non commerciale. Mantiene una qualità d’immagine quasi professionale e capacità di seguire istruzioni, con maggiore efficienza rispetto ai modelli standard di pari dimensioni.",
  "flux-kontext-max.description": "Generazione ed editing di immagini contestuali all’avanguardia, combinando testo e immagini per risultati precisi e coerenti.",
  "flux-kontext-pro.description": "Generazione ed editing di immagini contestuali all’avanguardia, combinando testo e immagini per risultati precisi e coerenti.",
  "flux-merged.description": "FLUX.1-merged combina le funzionalità approfondite esplorate in \"DEV\" con i vantaggi di velocità di \"Schnell\", estendendo i limiti delle prestazioni e ampliando le applicazioni.",
  "flux-pro-1.1-ultra.description": "Generazione di immagini ad altissima risoluzione con output da 4MP, producendo immagini nitide in 10 secondi.",
  "flux-pro-1.1.description": "Modello aggiornato di generazione di immagini di livello professionale con eccellente qualità visiva e aderenza precisa ai prompt.",
  "flux-pro.description": "Modello commerciale di generazione di immagini di fascia alta con qualità visiva impareggiabile e output diversificati.",
  "flux-schnell.description": "FLUX.1 [schnell] è il modello open-source più avanzato a pochi passaggi, superiore a concorrenti simili e persino a modelli non distillati come Midjourney v6.0 e DALL-E 3 (HD). Ottimizzato per preservare la diversità del pretraining, migliora notevolmente la qualità visiva, il rispetto delle istruzioni, la variazione di dimensioni/aspetto, la gestione dei font e la diversità degli output.",
  "flux.1-schnell.description": "FLUX.1-schnell è un modello ad alte prestazioni per la generazione di immagini rapide in più stili.",
  "gemini-1.0-pro-001.description": "Gemini 1.0 Pro 001 (Tuning) offre prestazioni stabili e regolabili per compiti complessi.",
  "gemini-1.0-pro-002.description": "Gemini 1.0 Pro 002 (Tuning) fornisce un forte supporto multimodale per compiti complessi.",
  "gemini-1.0-pro-latest.description": "Gemini 1.0 Pro è il modello AI ad alte prestazioni di Google progettato per l’esecuzione su larga scala di compiti generali.",
  "gemini-1.5-flash-001.description": "Gemini 1.5 Flash 001 è un modello multimodale efficiente per l’implementazione su larga scala.",
  "gemini-1.5-flash-002.description": "Gemini 1.5 Flash 002 è un modello multimodale efficiente progettato per una distribuzione estesa.",
  "gemini-1.5-flash-8b-exp-0924.description": "Gemini 1.5 Flash 8B 0924 è il più recente modello sperimentale con miglioramenti significativi nei casi d’uso testuali e multimodali.",
  "gemini-1.5-flash-8b-latest.description": "Gemini 1.5 Flash 8B è un modello multimodale efficiente progettato per una distribuzione estesa.",
  "gemini-1.5-flash-8b.description": "Gemini 1.5 Flash 8B è un modello multimodale efficiente per l’implementazione su larga scala.",
  "gemini-1.5-flash-exp-0827.description": "Gemini 1.5 Flash 0827 offre un’elaborazione multimodale ottimizzata per compiti complessi.",
  "gemini-1.5-flash-latest.description": "Gemini 1.5 Flash è l’ultimo modello AI multimodale di Google con elaborazione rapida, supporto per input testuali, visivi e video, ideale per l’esecuzione efficiente di compiti su larga scala.",
  "gemini-1.5-pro-001.description": "Gemini 1.5 Pro 001 è una soluzione AI multimodale scalabile per compiti complessi.",
  "gemini-1.5-pro-002.description": "Gemini 1.5 Pro 002 è l’ultima versione pronta per la produzione con output di qualità superiore, in particolare per matematica, contesti lunghi e compiti visivi.",
  "gemini-1.5-pro-exp-0801.description": "Gemini 1.5 Pro 0801 offre un’elaborazione multimodale avanzata con maggiore flessibilità per lo sviluppo di applicazioni.",
  "gemini-1.5-pro-exp-0827.description": "Gemini 1.5 Pro 0827 applica le ultime ottimizzazioni per un’elaborazione multimodale più efficiente.",
  "gemini-1.5-pro-latest.description": "Gemini 1.5 Pro supporta fino a 2 milioni di token, un modello multimodale di medie dimensioni ideale per compiti complessi.",
  "gemini-2.0-flash-001.description": "Gemini 2.0 Flash offre funzionalità di nuova generazione tra cui velocità eccezionale, uso nativo di strumenti, generazione multimodale e una finestra di contesto da 1 milione di token.",
  "gemini-2.0-flash-exp-image-generation.description": "Modello sperimentale Gemini 2.0 Flash con supporto alla generazione di immagini.",
  "gemini-2.0-flash-lite-001.description": "Una variante di Gemini 2.0 Flash ottimizzata per efficienza dei costi e bassa latenza.",
  "gemini-2.0-flash-lite.description": "Una variante di Gemini 2.0 Flash ottimizzata per efficienza dei costi e bassa latenza.",
  "gemini-2.0-flash.description": "Gemini 2.0 Flash offre funzionalità di nuova generazione tra cui velocità eccezionale, uso nativo di strumenti, generazione multimodale e una finestra di contesto da 1 milione di token.",
  "gemini-2.5-flash-image.description": "Nano Banana è il più recente, veloce ed efficiente modello multimodale nativo di Google, che consente la generazione e modifica di immagini in conversazione.",
  "gemini-2.5-flash-image:image.description": "Nano Banana è il più recente, veloce ed efficiente modello multimodale nativo di Google, che consente la generazione e modifica di immagini in conversazione.",
  "gemini-2.5-flash-lite-preview-06-17.description": "Gemini 2.5 Flash-Lite Preview è il modello più piccolo e conveniente di Google, progettato per l’uso su larga scala.",
  "gemini-2.5-flash-lite-preview-09-2025.description": "Versione di anteprima (25 settembre 2025) di Gemini 2.5 Flash-Lite",
  "gemini-2.5-flash-lite.description": "Gemini 2.5 Flash-Lite è il modello più piccolo e conveniente di Google, progettato per l’uso su larga scala.",
  "gemini-2.5-flash-preview-04-17.description": "Gemini 2.5 Flash Preview è il modello più conveniente di Google con funzionalità complete.",
  "gemini-2.5-flash-preview-09-2025.description": "Versione di anteprima (25 settembre 2025) di Gemini 2.5 Flash",
  "gemini-2.5-flash.description": "Gemini 2.5 Flash è il modello più conveniente di Google con funzionalità complete.",
  "gemini-2.5-pro-preview-03-25.description": "Gemini 2.5 Pro Preview è il modello di ragionamento più avanzato di Google, in grado di ragionare su codice, matematica e problemi STEM, e analizzare grandi dataset, basi di codice e documenti con contesto esteso.",
  "gemini-2.5-pro-preview-05-06.description": "Gemini 2.5 Pro Preview è il modello di ragionamento più avanzato di Google, in grado di ragionare su codice, matematica e problemi STEM, e analizzare grandi dataset, basi di codice e documenti con contesto esteso.",
  "gemini-2.5-pro-preview-06-05.description": "Gemini 2.5 Pro Preview è il modello di ragionamento più avanzato di Google, in grado di ragionare su codice, matematica e problemi STEM, e analizzare grandi dataset, basi di codice e documenti con contesto esteso.",
  "gemini-2.5-pro.description": "Gemini 2.5 Pro è il modello di ragionamento più avanzato di Google, in grado di ragionare su codice, matematica e problemi STEM, e analizzare grandi dataset, basi di codice e documenti con contesto esteso.",
  "gemini-3-flash-preview.description": "Gemini 3 Flash è il modello più intelligente progettato per la velocità, che combina intelligenza all'avanguardia con un eccellente ancoraggio alla ricerca.",
  "gemini-3-pro-image-preview.description": "Gemini 3 Pro Image (Nano Banana Pro) è il modello di generazione di immagini di Google, che supporta anche la conversazione multimodale.",
  "gemini-3-pro-image-preview:image.description": "Gemini 3 Pro Image (Nano Banana Pro) è il modello di generazione di immagini di Google e supporta anche chat multimodale.",
  "gemini-3-pro-preview.description": "Gemini 3 Pro è il modello più potente di Google per agenti e codifica creativa, offrendo visuali più ricche e interazioni più profonde grazie a un ragionamento all'avanguardia.",
  "gemini-flash-latest.description": "Ultima versione di Gemini Flash",
  "gemini-flash-lite-latest.description": "Ultima versione di Gemini Flash-Lite",
  "gemini-pro-latest.description": "Ultima versione di Gemini Pro",
  "gemma-7b-it.description": "Gemma 7B è conveniente per compiti di piccola e media scala.",
  "gemma2-9b-it.description": "Gemma 2 9B è ottimizzato per compiti specifici e integrazione con strumenti.",
  "gemma2.description": "Gemma 2 è il modello efficiente di Google, adatto a casi d'uso che vanno da app leggere a elaborazioni dati complesse.",
  "gemma2:27b.description": "Gemma 2 è il modello efficiente di Google, adatto a casi d'uso che vanno da app leggere a elaborazioni dati complesse.",
  "gemma2:2b.description": "Gemma 2 è il modello efficiente di Google, adatto a casi d'uso che vanno da app leggere a elaborazioni dati complesse.",
  "generalv3.5.description": "Spark Max è la versione più completa, con supporto alla ricerca web e numerosi plugin integrati. Le sue capacità ottimizzate, i ruoli di sistema e le chiamate di funzione offrono prestazioni eccellenti in scenari applicativi complessi.",
  "generalv3.description": "Spark Pro è un LLM ad alte prestazioni ottimizzato per ambiti professionali, con focus su matematica, programmazione, sanità ed educazione. Supporta la ricerca web e plugin integrati come meteo e data. Offre prestazioni elevate e grande efficienza in Q&A complessi, comprensione linguistica e creazione avanzata di testi, rendendolo ideale per usi professionali.",
  "glm-4-0520.description": "GLM-4-0520 è l'ultima versione del modello, progettata per compiti altamente complessi e diversificati con prestazioni eccellenti.",
  "glm-4-7.description": "GLM-4.7 è il modello di punta più recente di Zhipu AI. Migliora le capacità di programmazione, la pianificazione di compiti a lungo termine e la collaborazione con strumenti per scenari di Agentic Coding, raggiungendo prestazioni leader tra i modelli open-source in numerosi benchmark pubblici. Le capacità generali sono migliorate, con risposte più concise e naturali e una scrittura più immersiva. Nei compiti agentici complessi, il rispetto delle istruzioni durante le chiamate agli strumenti è più forte, e l'estetica del frontend di Artifacts e Agentic Coding, così come l'efficienza nel completamento di compiti a lungo termine, sono ulteriormente migliorate. • Capacità di programmazione potenziate: miglioramenti significativi nella codifica multilingue e nelle prestazioni degli agenti terminali; GLM-4.7 può ora implementare meccanismi \"pensare prima, agire poi\" in framework di programmazione come Claude Code, Kilo Code, TRAE, Cline e Roo Code, con prestazioni più stabili nei compiti complessi. • Miglioramento dell'estetica del frontend: GLM-4.7 mostra progressi significativi nella qualità della generazione frontend, in grado di creare siti web, presentazioni e poster con maggiore impatto visivo. • Capacità di chiamata strumenti potenziate: GLM-4.7 migliora le capacità di chiamata strumenti, ottenendo 67 nel test BrowseComp e 84,7 nel benchmark interattivo τ²-Bench, superando Claude Sonnet 4.5 come SOTA open-source. • Miglioramento del ragionamento: capacità matematiche e di ragionamento notevolmente migliorate, con un punteggio del 42,8% nel benchmark HLE (\"Humanity's Last Exam\"), un miglioramento del 41% rispetto a GLM-4.6, superando GPT-5.1. • Potenziamento generale: le conversazioni con GLM-4.7 sono più concise, intelligenti e umane; la scrittura e il role-playing sono più letterari e immersivi.",
  "glm-4-9b-chat.description": "GLM-4-9B-Chat offre prestazioni elevate in semantica, matematica, ragionamento, codice e conoscenza. Supporta anche navigazione web, esecuzione di codice, chiamate a strumenti personalizzati e ragionamento su testi lunghi, con supporto per 26 lingue tra cui giapponese, coreano e tedesco.",
  "glm-4-air-250414.description": "GLM-4-Air è un'opzione ad alto valore con prestazioni vicine a GLM-4, velocità elevata e costi ridotti.",
  "glm-4-air.description": "GLM-4-Air è un'opzione ad alto valore con prestazioni vicine a GLM-4, velocità elevata e costi ridotti.",
  "glm-4-airx.description": "GLM-4-AirX è una variante più efficiente di GLM-4-Air con ragionamento fino a 2,6 volte più veloce.",
  "glm-4-alltools.description": "GLM-4-AllTools è un modello agente versatile ottimizzato per la pianificazione di istruzioni complesse e l'uso di strumenti come navigazione web, spiegazione di codice e generazione di testo, adatto all'esecuzione multi-task.",
  "glm-4-flash-250414.description": "GLM-4-Flash è ideale per compiti semplici: il più veloce e gratuito.",
  "glm-4-flash.description": "GLM-4-Flash è ideale per compiti semplici: il più veloce e gratuito.",
  "glm-4-flashx.description": "GLM-4-FlashX è una versione Flash potenziata con ragionamento ultra-rapido.",
  "glm-4-long.description": "GLM-4-Long supporta input ultra-lunghi per compiti di tipo memoria e l'elaborazione di documenti su larga scala.",
  "glm-4-plus.description": "GLM-4-Plus è un modello di punta ad alta intelligenza con forte gestione di testi lunghi e compiti complessi, e prestazioni complessive migliorate.",
  "glm-4.1v-thinking-flash.description": "GLM-4.1V-Thinking è il più potente VLM da ~10B noto, coprendo compiti SOTA come comprensione video, QA su immagini, risoluzione di problemi, OCR, lettura di documenti e grafici, agenti GUI, codifica frontend e grounding. Supera persino Qwen2.5-VL-72B, 8 volte più grande, in molti compiti. Con RL avanzato, utilizza il ragionamento a catena per migliorare accuratezza e ricchezza, superando i modelli tradizionali non pensanti sia nei risultati che nella spiegabilità.",
  "glm-4.1v-thinking-flashx.description": "GLM-4.1V-Thinking è il più potente VLM da ~10B noto, coprendo compiti SOTA come comprensione video, QA su immagini, risoluzione di problemi, OCR, lettura di documenti e grafici, agenti GUI, codifica frontend e grounding. Supera persino Qwen2.5-VL-72B, 8 volte più grande, in molti compiti. Con RL avanzato, utilizza il ragionamento a catena per migliorare accuratezza e ricchezza, superando i modelli tradizionali non pensanti sia nei risultati che nella spiegabilità.",
  "glm-4.5-air.description": "Edizione leggera di GLM-4.5 che bilancia prestazioni e costi, con modalità di pensiero ibride flessibili.",
  "glm-4.5-airx.description": "Edizione veloce di GLM-4.5-Air con risposte più rapide per usi ad alta scala e velocità.",
  "glm-4.5-x.description": "Edizione veloce di GLM-4.5, con prestazioni elevate e velocità di generazione fino a 100 token/sec.",
  "glm-4.5.description": "Modello di punta di Zhipu con modalità di pensiero commutabile, che offre SOTA open-source complessivo e fino a 128K di contesto.",
  "glm-4.5v.description": "Il modello di ragionamento visivo di nuova generazione MoE di Zhipu ha 106B parametri totali con 12B attivi, raggiungendo SOTA tra i modelli multimodali open-source di dimensioni simili in compiti su immagini, video, documenti e GUI.",
  "glm-4.6.description": "GLM-4.6 (355B), il nuovo modello di punta di Zhipu, supera completamente i suoi predecessori in codifica avanzata, elaborazione di testi lunghi, ragionamento e capacità agentiche. Si distingue in particolare per le sue abilità di programmazione, comparabili a quelle di Claude Sonnet 4, affermandosi come il miglior modello di codifica in Cina.",
  "glm-4.7-flash.description": "GLM-4.7-Flash, come modello SOTA da 30B, offre una nuova opzione che bilancia prestazioni ed efficienza. Migliora le capacità di programmazione, la pianificazione di compiti a lungo termine e la collaborazione con strumenti per scenari di Agentic Coding, raggiungendo prestazioni leader tra i modelli open-source della stessa dimensione in numerosi benchmark attuali. Nell'esecuzione di compiti agentici complessi, mostra maggiore aderenza alle istruzioni durante le chiamate agli strumenti e migliora ulteriormente l'estetica del frontend e l'efficienza nel completamento di compiti a lungo termine per Artifacts e Agentic Coding.",
  "glm-4.7-flashx.description": "GLM-4.7-Flash, come modello SOTA da 30B, offre una nuova opzione che bilancia prestazioni ed efficienza. Migliora le capacità di programmazione, la pianificazione di compiti a lungo termine e la collaborazione con strumenti per scenari di Agentic Coding, raggiungendo prestazioni leader tra i modelli open-source della stessa dimensione in numerosi benchmark attuali. Nell'esecuzione di compiti agentici complessi, mostra maggiore aderenza alle istruzioni durante le chiamate agli strumenti e migliora ulteriormente l'estetica del frontend e l'efficienza nel completamento di compiti a lungo termine per Artifacts e Agentic Coding.",
  "glm-4.7.description": "GLM-4.7 è il nuovo modello di punta di Zhipu, ottimizzato per scenari di codifica agentica con capacità migliorate nella programmazione, pianificazione di compiti a lungo termine e collaborazione con strumenti. Raggiunge prestazioni leader tra i modelli open-source su numerosi benchmark pubblici. Le capacità generali sono state potenziate con risposte più concise e naturali e una scrittura più coinvolgente. Per compiti agentici complessi, il modello segue meglio le istruzioni durante l'uso degli strumenti, e l'estetica del frontend e l'efficienza nel completamento di compiti a lungo termine in Artifacts e Agentic Coding sono ulteriormente migliorate.",
  "glm-4.description": "GLM-4 è il precedente modello di punta rilasciato a gennaio 2024, ora sostituito dal più potente GLM-4-0520.",
  "glm-4v-flash.description": "GLM-4V-Flash è focalizzato sulla comprensione efficiente di immagini singole per scenari di analisi rapida come l'elaborazione di immagini in tempo reale o in batch.",
  "glm-4v-plus-0111.description": "GLM-4V-Plus comprende video e immagini multiple, ideale per compiti multimodali.",
  "glm-4v-plus.description": "GLM-4V-Plus comprende video e immagini multiple, ideale per compiti multimodali.",
  "glm-4v.description": "GLM-4V offre una solida comprensione e capacità di ragionamento visivo su compiti basati su immagini.",
  "glm-z1-air.description": "Modello di ragionamento con elevate capacità inferenziali per compiti che richiedono deduzioni complesse.",
  "glm-z1-airx.description": "Ragionamento ultra-rapido con alta qualità inferenziale.",
  "glm-z1-flash.description": "La serie GLM-Z1 eccelle nel ragionamento complesso, con prestazioni elevate in logica, matematica e programmazione.",
  "glm-z1-flashx.description": "Veloce ed economico: versione Flash con ragionamento ultra-rapido e maggiore concorrenza.",
  "glm-zero-preview.description": "GLM-Zero-Preview offre un ragionamento complesso avanzato, eccellendo in logica, matematica e programmazione.",
  "global.anthropic.claude-opus-4-5-20251101-v1:0.description": "Claude Opus 4.5 è il modello di punta di Anthropic, che combina intelligenza eccezionale e prestazioni scalabili per compiti complessi che richiedono risposte e ragionamenti della massima qualità.",
  "google/gemini-2.0-flash-001.description": "Gemini 2.0 Flash offre capacità di nuova generazione, tra cui velocità eccezionale, uso nativo di strumenti, generazione multimodale e una finestra di contesto da 1 milione di token.",
  "google/gemini-2.0-flash-lite-001.description": "Gemini 2.0 Flash Lite è una variante leggera di Gemini con il ragionamento disattivato per impostazione predefinita per migliorare latenza e costi, ma può essere attivato tramite parametri.",
  "google/gemini-2.0-flash-lite.description": "Gemini 2.0 Flash Lite offre funzionalità di nuova generazione tra cui velocità eccezionale, uso integrato di strumenti, generazione multimodale e una finestra di contesto da 1 milione di token.",
  "google/gemini-2.0-flash.description": "Gemini 2.0 Flash è il modello di ragionamento ad alte prestazioni di Google per compiti multimodali estesi.",
  "google/gemini-2.5-flash-image-free.description": "Gemini 2.5 Flash Image livello gratuito con generazione multimodale a quota limitata.",
  "google/gemini-2.5-flash-image-preview.description": "Modello sperimentale Gemini 2.5 Flash con supporto alla generazione di immagini.",
  "google/gemini-2.5-flash-image.description": "Gemini 2.5 Flash Image (Nano Banana) è il modello di generazione di immagini di Google con supporto alla conversazione multimodale.",
  "google/gemini-2.5-flash-lite.description": "Gemini 2.5 Flash Lite è la variante leggera di Gemini 2.5, ottimizzata per latenza e costi, adatta a scenari ad alto volume.",
  "google/gemini-2.5-flash-preview.description": "Gemini 2.5 Flash è il modello di punta più avanzato di Google, progettato per compiti complessi di ragionamento, programmazione, matematica e scienza. Include un sistema di 'pensiero' integrato per fornire risposte più accurate con elaborazione contestuale più fine.\n\nNota: questo modello ha due varianti — con e senza pensiero. Il prezzo dell'output varia significativamente a seconda che il pensiero sia attivato. Se scegli la variante standard (senza il suffisso ':thinking'), il modello eviterà esplicitamente di generare token di pensiero.\n\nPer utilizzare il pensiero e ricevere token di pensiero, devi selezionare la variante ':thinking', che comporta un costo maggiore per l'output.\n\nGemini 2.5 Flash può anche essere configurato tramite il parametro 'max reasoning tokens' come documentato (https://openrouter.ai/docs/use-cases/reasoning-tokens#max-tokens-for-reasoning).",
  "google/gemini-2.5-flash-preview:thinking.description": "Gemini 2.5 Flash è il modello di punta più avanzato di Google, progettato per compiti complessi di ragionamento, programmazione, matematica e scienza. Include un sistema di 'pensiero' integrato per fornire risposte più accurate con elaborazione contestuale più fine.\n\nNota: questo modello ha due varianti — con e senza pensiero. Il prezzo dell'output varia significativamente a seconda che il pensiero sia attivato. Se scegli la variante standard (senza il suffisso ':thinking'), il modello eviterà esplicitamente di generare token di pensiero.\n\nPer utilizzare il pensiero e ricevere token di pensiero, devi selezionare la variante ':thinking', che comporta un costo maggiore per l'output.\n\nGemini 2.5 Flash può anche essere configurato tramite il parametro 'max reasoning tokens' come documentato (https://openrouter.ai/docs/use-cases/reasoning-tokens#max-tokens-for-reasoning).",
  "google/gemini-2.5-flash.description": "Gemini 2.5 Flash (Lite/Pro/Flash) è la famiglia di modelli di Google che spazia da bassa latenza a ragionamento ad alte prestazioni.",
  "google/gemini-2.5-pro-free.description": "Gemini 2.5 Pro livello gratuito offre generazione multimodale con contesto esteso a quota limitata, adatto per prove e flussi di lavoro leggeri.",
  "google/gemini-2.5-pro-preview.description": "Gemini 2.5 Pro Preview è il modello di pensiero più avanzato di Google per il ragionamento su problemi complessi in codice, matematica e STEM, e per l'analisi di grandi dataset, basi di codice e documenti con contesto esteso.",
  "google/gemini-2.5-pro.description": "Gemini 2.5 Pro è il modello di ragionamento di punta di Google con supporto a contesto esteso per compiti complessi.",
  "google/gemini-3-pro-image-preview-free.description": "Gemini 3 Pro Image livello gratuito con generazione multimodale a quota limitata.",
  "google/gemini-3-pro-image-preview.description": "Gemini 3 Pro Image (Nano Banana Pro) è il modello di generazione di immagini di Google con supporto alla conversazione multimodale.",
  "google/gemini-3-pro-preview-free.description": "Gemini 3 Pro Preview Free offre la stessa comprensione e ragionamento multimodale della versione standard, ma con limiti di quota e frequenza, ideale per prove e uso a bassa frequenza.",
  "google/gemini-3-pro-preview.description": "Gemini 3 Pro è il modello di ragionamento multimodale di nuova generazione della famiglia Gemini, in grado di comprendere testo, audio, immagini e video, e di gestire compiti complessi e grandi basi di codice.",
  "google/gemini-embedding-001.description": "Un modello di embedding all'avanguardia con prestazioni elevate in inglese, multilingua e compiti di programmazione.",
  "google/gemini-flash-1.5.description": "Gemini 1.5 Flash offre un'elaborazione multimodale ottimizzata per una vasta gamma di compiti complessi.",
  "google/gemini-pro-1.5.description": "Gemini 1.5 Pro combina le ottimizzazioni più recenti per un'elaborazione più efficiente dei dati multimodali.",
  "google/gemma-2-27b-it.description": "Gemma 2 27B è un LLM generico con prestazioni elevate in molti scenari.",
  "google/gemma-2-27b.description": "Gemma 2 è la famiglia di modelli efficienti di Google per casi d'uso che vanno da app leggere a elaborazioni dati complesse.",
  "google/gemma-2-2b-it.description": "Un modello linguistico avanzato di piccole dimensioni progettato per applicazioni edge.",
  "google/gemma-2-9b-it.description": "Gemma 2 9B, sviluppato da Google, offre esecuzione efficiente delle istruzioni e solide capacità generali.",
  "google/gemma-2-9b-it:free.description": "Gemma 2 è la famiglia di modelli di testo open-source leggeri di Google.",
  "google/gemma-2-9b.description": "Gemma 2 è la famiglia di modelli efficienti di Google per casi d'uso che vanno da app leggere a elaborazioni dati complesse.",
  "google/gemma-2b-it.description": "Gemma Instruct (2B) fornisce gestione di istruzioni di base per applicazioni leggere.",
  "google/gemma-3-12b-it.description": "Gemma 3 12B è un modello linguistico open-source di Google che stabilisce un nuovo standard in termini di efficienza e prestazioni.",
  "google/gemma-3-27b-it.description": "Gemma 3 27B è un modello linguistico open-source di Google che stabilisce un nuovo standard in termini di efficienza e prestazioni.",
  "google/text-embedding-005.description": "Un modello di embedding testuale focalizzato sull'inglese, ottimizzato per compiti in lingua inglese e codice.",
  "google/text-multilingual-embedding-002.description": "Un modello di embedding testuale multilingue ottimizzato per compiti cross-lingua in molte lingue.",
  "gpt-3.5-turbo-0125.description": "GPT 3.5 Turbo per generazione e comprensione del testo; attualmente punta a gpt-3.5-turbo-0125.",
  "gpt-3.5-turbo-1106.description": "GPT 3.5 Turbo per generazione e comprensione del testo; attualmente punta a gpt-3.5-turbo-0125.",
  "gpt-3.5-turbo-instruct.description": "GPT 3.5 Turbo per compiti di generazione e comprensione del testo, ottimizzato per seguire istruzioni.",
  "gpt-3.5-turbo.description": "GPT 3.5 Turbo per generazione e comprensione del testo; attualmente punta a gpt-3.5-turbo-0125.",
  "gpt-35-turbo-16k.description": "GPT-3.5 Turbo 16k è un modello di generazione testuale ad alta capacità per compiti complessi.",
  "gpt-35-turbo.description": "GPT-3.5 Turbo è il modello efficiente di OpenAI per chat e generazione di testo, con supporto per chiamate di funzione parallele.",
  "gpt-4-0125-preview.description": "Il più recente GPT-4 Turbo aggiunge la visione. Le richieste visive supportano la modalità JSON e le chiamate di funzione. È un modello multimodale conveniente che bilancia accuratezza ed efficienza per applicazioni in tempo reale.",
  "gpt-4-0613.description": "GPT-4 offre una finestra contestuale più ampia per gestire input lunghi, adatto a sintesi informative ampie e analisi dati.",
  "gpt-4-1106-preview.description": "Il più recente GPT-4 Turbo aggiunge la visione. Le richieste visive supportano la modalità JSON e le chiamate di funzione. È un modello multimodale conveniente che bilancia accuratezza ed efficienza per applicazioni in tempo reale.",
  "gpt-4-32k-0613.description": "GPT-4 offre una finestra contestuale più ampia per gestire input lunghi in scenari che richiedono integrazione informativa ampia e analisi dati.",
  "gpt-4-32k.description": "GPT-4 offre una finestra contestuale più ampia per gestire input lunghi in scenari che richiedono integrazione informativa ampia e analisi dati.",
  "gpt-4-turbo-2024-04-09.description": "Il più recente GPT-4 Turbo aggiunge la visione. Le richieste visive supportano la modalità JSON e le chiamate di funzione. È un modello multimodale conveniente che bilancia accuratezza ed efficienza per applicazioni in tempo reale.",
  "gpt-4-turbo-preview.description": "Il più recente GPT-4 Turbo aggiunge la visione. Le richieste visive supportano la modalità JSON e le chiamate di funzione. È un modello multimodale conveniente che bilancia accuratezza ed efficienza per applicazioni in tempo reale.",
  "gpt-4-turbo.description": "Il più recente GPT-4 Turbo aggiunge la visione. Le richieste visive supportano la modalità JSON e le chiamate di funzione. È un modello multimodale conveniente che bilancia accuratezza ed efficienza per applicazioni in tempo reale.",
  "gpt-4-vision-preview.description": "Anteprima di GPT-4 Vision, progettato per compiti di analisi e elaborazione immagini.",
  "gpt-4.1-mini.description": "GPT-4.1 mini bilancia intelligenza, velocità e costo, rendendolo adatto a molti casi d'uso.",
  "gpt-4.1-nano.description": "GPT-4.1 nano è il modello GPT-4.1 più veloce ed economico.",
  "gpt-4.1.description": "GPT-4.1 è il nostro modello di punta per compiti complessi e risoluzione di problemi cross-domain.",
  "gpt-4.5-preview.description": "GPT-4.5-preview è il più recente modello generico con profonda conoscenza del mondo e migliore comprensione dell'intento, eccellente in compiti creativi e pianificazione di agenti. Il suo cutoff di conoscenza è ottobre 2023.",
  "gpt-4.description": "GPT-4 offre una finestra contestuale più ampia per gestire input lunghi, adatto a sintesi informative ampie e analisi dati.",
  "gpt-4o-2024-05-13.description": "ChatGPT-4o è un modello dinamico aggiornato in tempo reale, che combina forte comprensione e generazione per casi d'uso su larga scala come assistenza clienti, istruzione e supporto tecnico.",
  "gpt-4o-2024-08-06.description": "ChatGPT-4o è un modello dinamico aggiornato in tempo reale. Combina una solida comprensione e generazione del linguaggio per casi d’uso su larga scala come l’assistenza clienti, l’istruzione e il supporto tecnico.",
  "gpt-4o-2024-11-20.description": "ChatGPT-4o è un modello dinamico aggiornato in tempo reale, che unisce una forte capacità di comprensione e generazione per casi d’uso su larga scala come l’assistenza clienti, l’istruzione e il supporto tecnico.",
  "gpt-4o-audio-preview.description": "Modello GPT-4o Audio Preview con input e output audio.",
  "gpt-4o-mini-audio-preview.description": "Modello audio GPT-4o mini con input e output audio.",
  "gpt-4o-mini-realtime-preview.description": "Variante in tempo reale di GPT-4o-mini con input/output audio e testuale in tempo reale.",
  "gpt-4o-mini-search-preview.description": "GPT-4o mini Search Preview è addestrato per comprendere ed eseguire query di ricerca web tramite l’API Chat Completions. La ricerca web è fatturata per ogni chiamata allo strumento, oltre ai costi dei token.",
  "gpt-4o-mini-transcribe.description": "GPT-4o Mini Transcribe è un modello di trascrizione vocale che converte l’audio in testo con GPT-4o, migliorando il tasso di errore, l’identificazione della lingua e la precisione rispetto al modello Whisper originale.",
  "gpt-4o-mini-tts.description": "GPT-4o mini TTS è un modello di sintesi vocale basato su GPT-4o mini, che converte il testo in parlato naturale con un massimo di 2000 token in input.",
  "gpt-4o-mini.description": "GPT-4o mini è l’ultimo modello di OpenAI dopo GPT-4 Omni, supporta input di testo+immagine con output testuale. È il loro modello compatto più avanzato, molto più economico rispetto ai modelli di frontiera recenti e oltre il 60% più conveniente di GPT-3.5 Turbo, mantenendo un’intelligenza di alto livello (82% MMLU).",
  "gpt-4o-realtime-preview-2024-10-01.description": "Variante GPT-4o in tempo reale con input/output audio e testuale in tempo reale.",
  "gpt-4o-realtime-preview-2025-06-03.description": "Variante GPT-4o in tempo reale con input/output audio e testuale in tempo reale.",
  "gpt-4o-realtime-preview.description": "Variante GPT-4o in tempo reale con input/output audio e testuale in tempo reale.",
  "gpt-4o-search-preview.description": "GPT-4o Search Preview è addestrato per comprendere ed eseguire query di ricerca web tramite l’API Chat Completions. La ricerca web è fatturata per ogni chiamata allo strumento, oltre ai costi dei token.",
  "gpt-4o-transcribe.description": "GPT-4o Transcribe è un modello di trascrizione vocale che converte l’audio in testo con GPT-4o, migliorando il tasso di errore, l’identificazione della lingua e la precisione rispetto al modello Whisper originale.",
  "gpt-4o.description": "ChatGPT-4o è un modello dinamico aggiornato in tempo reale, che unisce una forte capacità di comprensione e generazione per casi d’uso su larga scala come l’assistenza clienti, l’istruzione e il supporto tecnico.",
  "gpt-5-chat-latest.description": "Il modello GPT-5 utilizzato in ChatGPT, che combina una forte comprensione e generazione per applicazioni conversazionali.",
  "gpt-5-chat.description": "GPT-5 Chat è un modello in anteprima ottimizzato per scenari conversazionali. Supporta input di testo e immagini, produce solo output testuale ed è adatto a chatbot e applicazioni di intelligenza artificiale conversazionale.",
  "gpt-5-codex.description": "GPT-5 Codex è una variante di GPT-5 ottimizzata per compiti di programmazione agentica in ambienti simili a Codex.",
  "gpt-5-mini.description": "Una variante GPT-5 più veloce ed economica per compiti ben definiti, che fornisce risposte rapide mantenendo la qualità.",
  "gpt-5-nano.description": "La variante GPT-5 più veloce ed economica, ideale per applicazioni sensibili alla latenza e ai costi.",
  "gpt-5-pro.description": "GPT-5 pro utilizza più risorse computazionali per pensare in profondità e fornire risposte migliori in modo costante.",
  "gpt-5.1-chat-latest.description": "GPT-5.1 Chat: la variante ChatGPT di GPT-5.1, progettata per scenari di chat.",
  "gpt-5.1-codex-mini.description": "GPT-5.1 Codex mini: una variante Codex più piccola ed economica ottimizzata per compiti di programmazione agentica.",
  "gpt-5.1-codex.description": "GPT-5.1 Codex: una variante di GPT-5.1 ottimizzata per compiti di programmazione agentica, per flussi di lavoro complessi di codice/agent nella Responses API.",
  "gpt-5.1.description": "GPT-5.1 — un modello di punta ottimizzato per compiti di programmazione e agent con sforzo di ragionamento configurabile e contesto esteso.",
  "gpt-5.2-chat-latest.description": "GPT-5.2 Chat è la variante ChatGPT (chat-latest) con i più recenti miglioramenti nella conversazione.",
  "gpt-5.2-pro.description": "GPT-5.2 Pro: una variante GPT-5.2 più intelligente e precisa (solo API Responses), adatta a problemi complessi e ragionamenti multi-turno estesi.",
  "gpt-5.2.description": "GPT-5.2 è un modello di punta per flussi di lavoro di programmazione e agent con ragionamento potenziato e prestazioni su contesti lunghi.",
  "gpt-5.description": "Il miglior modello per compiti di programmazione e agent cross-domain. GPT-5 rappresenta un salto in accuratezza, velocità, ragionamento, consapevolezza del contesto, pensiero strutturato e risoluzione dei problemi.",
  "gpt-audio.description": "GPT Audio è un modello di chat generale con input/output audio, supportato nell’API Chat Completions.",
  "gpt-image-1-mini.description": "Una variante a basso costo di GPT Image 1 con input nativo di testo e immagine e output immagine.",
  "gpt-image-1.5.description": "Un modello migliorato GPT Image 1 con generazione 4× più veloce, editing più preciso e rendering del testo migliorato.",
  "gpt-image-1.description": "Modello nativo multimodale di generazione immagini di ChatGPT.",
  "gpt-oss-120b.description": "L’accesso richiede una richiesta. GPT-OSS-120B è un modello linguistico open-source di grandi dimensioni di OpenAI con una forte capacità di generazione testuale.",
  "gpt-oss-20b.description": "L’accesso richiede una richiesta. GPT-OSS-20B è un modello linguistico open-source di medie dimensioni di OpenAI con generazione testuale efficiente.",
  "gpt-oss:120b.description": "GPT-OSS 120B è il grande LLM open-source di OpenAI che utilizza la quantizzazione MXFP4 ed è posizionato come modello di punta. Richiede ambienti multi-GPU o workstation di fascia alta e offre prestazioni eccellenti in ragionamento complesso, generazione di codice ed elaborazione multilingue, con chiamata di funzioni avanzata e integrazione di strumenti.",
  "gpt-oss:20b.description": "GPT-OSS 20B è un LLM open-source di OpenAI che utilizza la quantizzazione MXFP4, adatto a GPU consumer di fascia alta o Mac con Apple Silicon. Offre buone prestazioni in generazione di dialoghi, programmazione e compiti di ragionamento, supportando chiamata di funzioni e uso di strumenti.",
  "gpt-realtime.description": "Un modello generale in tempo reale che supporta input/output testuale e audio in tempo reale, oltre all’input di immagini.",
  "grok-2-image-1212.description": "Il nostro più recente modello di generazione di immagini crea immagini vivide e realistiche da prompt, eccellendo in ambiti come marketing, social media e intrattenimento.",
  "grok-2-vision-1212.description": "Miglioramenti in accuratezza, rispetto delle istruzioni e capacità multilingue.",
  "grok-3-mini.description": "Un modello leggero che riflette prima di rispondere. È veloce e intelligente per compiti logici che non richiedono conoscenze specialistiche, con accesso a tracce di ragionamento grezze.",
  "grok-3.description": "Un modello di punta che eccelle in casi d'uso aziendali come estrazione dati, programmazione e sintesi, con profonda conoscenza nei settori finanziario, sanitario, legale e scientifico.",
  "grok-4-0709.description": "Grok 4 di xAI con una forte capacità di ragionamento.",
  "grok-4-1-fast-non-reasoning.description": "Un modello multimodale all'avanguardia ottimizzato per l'uso con strumenti agentici ad alte prestazioni.",
  "grok-4-1-fast-reasoning.description": "Un modello multimodale all'avanguardia ottimizzato per l'uso con strumenti agentici ad alte prestazioni.",
  "grok-4-fast-non-reasoning.description": "Siamo entusiasti di presentare Grok 4 Fast, il nostro ultimo progresso nei modelli di ragionamento a basso costo.",
  "grok-4-fast-reasoning.description": "Siamo entusiasti di presentare Grok 4 Fast, il nostro ultimo progresso nei modelli di ragionamento a basso costo.",
  "grok-4.description": "Il nostro modello di punta più recente e potente, eccellente in NLP, matematica e ragionamento—un tuttofare ideale.",
  "grok-code-fast-1.description": "Siamo entusiasti di lanciare grok-code-fast-1, un modello di ragionamento veloce ed economico che eccelle nella programmazione agentica.",
  "groq/compound-mini.description": "Compound-mini è un sistema AI composito alimentato da modelli pubblici disponibili su GroqCloud, che utilizza strumenti in modo intelligente e selettivo per rispondere alle domande degli utenti.",
  "groq/compound.description": "Compound è un sistema AI composito alimentato da più modelli pubblici disponibili su GroqCloud, che utilizza strumenti in modo intelligente e selettivo per rispondere alle domande degli utenti.",
  "gryphe/mythomax-l2-13b.description": "MythoMax L2 13B è un modello linguistico creativo e intelligente ottenuto dalla fusione di più modelli di alto livello.",
  "hunyuan-a13b.description": "Il primo modello di ragionamento ibrido di Hunyuan, aggiornato da hunyuan-standard-256K (80B totali, 13B attivi). Di default utilizza un pensiero lento e supporta il passaggio veloce/lento tramite parametri o prefisso /no_think. Le capacità complessive sono migliorate rispetto alla generazione precedente, in particolare in matematica, scienza, comprensione di testi lunghi e compiti agentici.",
  "hunyuan-code.description": "Ultimo modello di generazione di codice addestrato con 200B di codice di alta qualità e sei mesi di SFT; contesto esteso a 8K. È ai vertici nei benchmark automatizzati per cinque linguaggi e nelle valutazioni umane su dieci criteri.",
  "hunyuan-functioncall.description": "Ultimo modello MoE FunctionCall addestrato con dati di chiamata funzione di alta qualità, con una finestra di contesto di 32K e risultati di benchmark leader in più dimensioni.",
  "hunyuan-large-longcontext.description": "Eccelle nei compiti su documenti lunghi come sintesi e QA, gestendo anche la generazione generale. Forte nell'analisi e generazione di testi lunghi e complessi.",
  "hunyuan-large-vision.description": "Un modello linguistico-visivo addestrato da Hunyuan Large per la comprensione immagine-testo. Supporta input multi-immagine + testo a qualsiasi risoluzione e migliora la comprensione visiva multilingue.",
  "hunyuan-large.description": "Hunyuan-large ha ~389B parametri totali e ~52B attivati, il più grande e potente modello MoE open-source in architettura Transformer.",
  "hunyuan-lite-vision.description": "Ultimo modello multimodale da 7B con finestra di contesto da 32K, supporta chat multimodale cinese/inglese, riconoscimento oggetti, comprensione di tabelle e matematica multimodale, superando i pari da 7B in molti benchmark.",
  "hunyuan-lite.description": "Aggiornato a un'architettura MoE con finestra di contesto da 256K, guida molti modelli open-source nei benchmark NLP, codice, matematica e industriali.",
  "hunyuan-pro.description": "Modello MOE-32K a trilioni di parametri con contesto lungo, leader nei benchmark, forte in istruzioni complesse e ragionamento, matematica avanzata, chiamate funzione, e ottimizzato per traduzione multilingue, finanza, diritto e medicina.",
  "hunyuan-role.description": "Ultimo modello per roleplay, ufficialmente ottimizzato su dataset di roleplay, con prestazioni di base più forti per scenari di interpretazione di ruoli.",
  "hunyuan-standard-256K.description": "Utilizza un routing migliorato per mitigare il bilanciamento del carico e il collasso degli esperti. Raggiunge il 99,9% nel test 'ago nel pagliaio' su contesto lungo. MOE-256K espande ulteriormente la lunghezza e qualità del contesto.",
  "hunyuan-standard-vision.description": "Ultimo modello multimodale con risposte multilingue e capacità bilanciate in cinese/inglese.",
  "hunyuan-standard.description": "Utilizza un routing migliorato per mitigare il bilanciamento del carico e il collasso degli esperti. Raggiunge il 99,9% nel test 'ago nel pagliaio' su contesto lungo. MOE-32K offre grande valore nella gestione di input lunghi.",
  "hunyuan-t1-20250321.description": "Costruisce capacità bilanciate tra discipline artistiche e STEM con forte cattura di informazioni da testi lunghi. Supporta risposte ragionate per problemi di matematica, logica, scienza e codice a vari livelli di difficoltà.",
  "hunyuan-t1-20250403.description": "Migliora la generazione di codice a livello di progetto e la qualità della scrittura, rafforza la comprensione di argomenti multi-turno e il rispetto delle istruzioni ToB, migliora la comprensione a livello di parola e riduce i problemi di output misto tra cinese semplificato/tradizionale e cinese/inglese.",
  "hunyuan-t1-20250529.description": "Migliora la scrittura creativa e la composizione, rafforza la programmazione frontend, la matematica e il ragionamento logico, e migliora il rispetto delle istruzioni.",
  "hunyuan-t1-20250711.description": "Migliora notevolmente la matematica complessa, la logica e la programmazione, aumenta la stabilità dell'output e potenzia la capacità su testi lunghi.",
  "hunyuan-t1-latest.description": "Migliora significativamente il modello a pensiero lento su matematica complessa, ragionamento articolato, programmazione difficile, rispetto delle istruzioni e qualità della scrittura creativa.",
  "hunyuan-t1-vision-20250619.description": "Ultimo modello multimodale t1-vision con ragionamento profondo e catena di pensiero nativa, notevolmente migliorato rispetto alla versione predefinita precedente.",
  "hunyuan-t1-vision-20250916.description": "Ultimo modello t1-vision con importanti miglioramenti in VQA, grounding visivo, OCR, grafici, risoluzione di problemi fotografati e creazione basata su immagini, oltre a una maggiore competenza in inglese e lingue a bassa risorsa.",
  "hunyuan-turbo-20241223.description": "Questa versione potenzia la scalabilità delle istruzioni per una migliore generalizzazione, migliora significativamente il ragionamento in matematica/codice/logica, rafforza la comprensione a livello di parola e migliora la qualità della scrittura.",
  "hunyuan-turbo-latest.description": "Miglioramenti generali nell'esperienza su comprensione NLP, scrittura, chat, QA, traduzione e domini; risposte più umane, chiarimenti migliori su intenti ambigui, parsing delle parole migliorato, maggiore qualità creativa e interattività, e conversazioni multi-turno più forti.",
  "hunyuan-turbo-vision.description": "Modello di punta linguistico-visivo di nuova generazione con nuova architettura MoE, con ampi miglioramenti in riconoscimento, creazione di contenuti, QA su conoscenze e ragionamento analitico.",
  "hunyuan-turbo.description": "Anteprima del prossimo LLM di Hunyuan con nuova architettura MoE, che offre ragionamento più veloce e risultati migliori rispetto a hunyuan-pro.",
  "hunyuan-turbos-20250313.description": "Unifica lo stile di risoluzione dei problemi matematici e rafforza le domande e risposte matematiche multi-turno. Lo stile di scrittura è stato raffinato per ridurre il tono artificiale e migliorare la qualità.",
  "hunyuan-turbos-20250416.description": "Base di pre-addestramento aggiornata per migliorare la comprensione e l’esecuzione delle istruzioni; l’allineamento migliora matematica, codice, logica e scienza; migliora la qualità della scrittura, la comprensione, l’accuratezza della traduzione e le domande e risposte basate sulla conoscenza; potenzia le capacità degli agenti, in particolare nella comprensione multi-turno.",
  "hunyuan-turbos-20250604.description": "Base di pre-addestramento aggiornata con miglioramenti nella scrittura e comprensione del testo, significativi progressi nel codice e nelle materie STEM, e migliore esecuzione di istruzioni complesse.",
  "hunyuan-turbos-20250926.description": "Qualità dei dati di pre-addestramento e strategia di post-addestramento migliorate, con potenziamenti per agenti, lingue inglese e a bassa risorsa, esecuzione di istruzioni, codice e capacità STEM.",
  "hunyuan-turbos-latest.description": "Il più recente modello di punta Hunyuan TurboS con ragionamento potenziato e un’esperienza complessiva migliorata.",
  "hunyuan-turbos-longtext-128k-20250325.description": "Eccelle nei compiti su documenti lunghi come riassunti e domande e risposte, gestendo anche generazione generale. Forte nell’analisi e generazione di testi lunghi per contenuti complessi e dettagliati.",
  "hunyuan-turbos-role-plus.description": "Ultimo modello per roleplay, ufficialmente ottimizzato su dataset specifici, con prestazioni di base più solide per scenari di interpretazione di ruoli.",
  "hunyuan-turbos-vision-20250619.description": "Ultimo modello di punta visione-linguaggio TurboS con grandi miglioramenti nei compiti immagine-testo come riconoscimento entità, domande e risposte basate sulla conoscenza, copywriting e risoluzione di problemi da foto.",
  "hunyuan-turbos-vision.description": "Modello di punta visione-linguaggio di nuova generazione basato sull’ultimo TurboS, focalizzato su compiti di comprensione immagine-testo come riconoscimento entità, domande e risposte basate sulla conoscenza, copywriting e risoluzione di problemi da foto.",
  "hunyuan-vision-1.5-instruct.description": "Modello di generazione testo da immagine basato su TurboS, con miglioramenti evidenti rispetto alla versione precedente in riconoscimento di base e ragionamento visivo.",
  "hunyuan-vision.description": "Ultimo modello multimodale che supporta input immagine + testo per generare testo.",
  "image-01-live.description": "Modello di generazione immagini con dettagli raffinati, supporta testo-immagine e stili controllabili predefiniti.",
  "image-01.description": "Nuovo modello di generazione immagini con dettagli raffinati, supporta testo-immagine e immagine-immagine.",
  "imagen-4.0-fast-generate-001.description": "Versione Fast della serie di modelli di generazione immagini da testo di quarta generazione Imagen",
  "imagen-4.0-generate-001.description": "Serie di modelli di generazione immagini da testo di quarta generazione Imagen",
  "imagen-4.0-generate-preview-06-06.description": "Famiglia di modelli di generazione immagini da testo di quarta generazione Imagen.",
  "imagen-4.0-ultra-generate-001.description": "Versione Ultra della serie di modelli di generazione immagini da testo di quarta generazione Imagen",
  "imagen-4.0-ultra-generate-preview-06-06.description": "Variante Ultra della quarta generazione di modelli di generazione immagini da testo Imagen.",
  "inception/mercury-coder-small.description": "Mercury Coder Small è ideale per la generazione di codice, il debug e il refactoring con una latenza minima.",
  "inclusionAI/Ling-flash-2.0.description": "Ling-flash-2.0 è il terzo modello dell'architettura Ling 2.0 del team Bailing di Ant Group. È un modello MoE con 100 miliardi di parametri totali, ma solo 6,1 miliardi attivi per token (4,8 miliardi esclusi gli embedding). Nonostante la configurazione leggera, eguaglia o supera modelli densi da 40 miliardi e MoE ancora più grandi in diversi benchmark, esplorando l'efficienza attraverso architettura e strategia di addestramento.",
  "inclusionAI/Ling-mini-2.0.description": "Ling-mini-2.0 è un piccolo LLM MoE ad alte prestazioni con 16 miliardi di parametri totali e solo 1,4 miliardi attivi per token (789 milioni esclusi gli embedding), offrendo una generazione molto rapida. Grazie a un design MoE efficiente e a un ampio dataset di addestramento di alta qualità, raggiunge prestazioni di livello superiore comparabili a modelli densi sotto i 10 miliardi e a MoE più grandi.",
  "inclusionAI/Ring-flash-2.0.description": "Ring-flash-2.0 è un modello di ragionamento ad alte prestazioni ottimizzato a partire da Ling-flash-2.0-base. Utilizza un'architettura MoE con 100 miliardi di parametri totali e solo 6,1 miliardi attivi per inferenza. Il suo algoritmo icepop stabilizza l'addestramento RL per i modelli MoE, consentendo progressi continui nel ragionamento complesso. Ottiene risultati eccezionali in benchmark difficili (gare di matematica, generazione di codice, ragionamento logico), superando i migliori modelli densi sotto i 40 miliardi e rivaleggiando con MoE aperti più grandi e modelli chiusi di ragionamento. Eccelle anche nella scrittura creativa e la sua architettura efficiente consente inferenze rapide a costi di distribuzione ridotti per scenari ad alta concorrenza.",
  "inclusionai/ling-1t.description": "Ling-1T è il modello MoE da 1 trilione di parametri di inclusionAI, ottimizzato per compiti di ragionamento intensivo e contesti di grandi dimensioni.",
  "inclusionai/ling-flash-2.0.description": "Ling-flash-2.0 è il modello MoE di inclusionAI ottimizzato per efficienza e prestazioni di ragionamento, adatto a compiti di media e grande scala.",
  "inclusionai/ling-mini-2.0.description": "Ling-mini-2.0 è il modello MoE leggero di inclusionAI, che riduce significativamente i costi mantenendo la capacità di ragionamento.",
  "inclusionai/ming-flash-omini-preview.description": "Ming-flash-omni Preview è il modello multimodale di inclusionAI, che supporta input vocali, immagini e video, con rendering delle immagini migliorato e riconoscimento vocale avanzato.",
  "inclusionai/ring-1t.description": "Ring-1T è il modello MoE da un trilione di parametri di inclusionAI per il ragionamento, adatto a compiti di ricerca e ragionamento su larga scala.",
  "inclusionai/ring-flash-2.0.description": "Ring-flash-2.0 è una variante del modello Ring di inclusionAI per scenari ad alto throughput, con enfasi su velocità ed efficienza dei costi.",
  "inclusionai/ring-mini-2.0.description": "Ring-mini-2.0 è il modello MoE leggero ad alto throughput di inclusionAI, progettato per la concorrenza elevata.",
  "internlm/internlm2_5-7b-chat.description": "InternLM2.5-7B-Chat è un modello di chat open-source basato sull'architettura InternLM2. Il modello da 7 miliardi è focalizzato sulla generazione di dialoghi con supporto per cinese e inglese, utilizzando tecniche di addestramento moderne per conversazioni fluide e intelligenti. È adatto a molti scenari di chat come assistenza clienti e assistenti personali.",
  "internlm2.5-latest.description": "Modelli legacy ancora mantenuti con prestazioni eccellenti e stabili dopo numerose iterazioni. Disponibili nelle versioni da 7B e 20B, supportano contesti da 1M e una maggiore capacità di seguire istruzioni e utilizzare strumenti. Impostato di default sulla serie InternLM2.5 più recente (attualmente internlm2.5-20b-chat).",
  "internlm3-latest.description": "La nostra serie di modelli più recente con prestazioni di ragionamento eccellenti, leader tra i modelli open-source della sua categoria. Impostato di default sulla serie InternLM3 più recente (attualmente internlm3-8b-instruct).",
  "internvl2.5-38b-mpo.description": "InternVL2.5 38B MPO è un modello multimodale preaddestrato per il ragionamento complesso immagine-testo.",
  "internvl2.5-latest.description": "InternVL2.5 è ancora mantenuto con prestazioni forti e stabili. Impostato di default sulla serie InternVL2.5 più recente (attualmente internvl2.5-78b).",
  "internvl3-14b.description": "InternVL3 14B è un modello multimodale di medie dimensioni che bilancia prestazioni e costi.",
  "internvl3-1b.description": "InternVL3 1B è un modello multimodale leggero per distribuzioni con risorse limitate.",
  "internvl3-38b.description": "InternVL3 38B è un grande modello multimodale open-source per una comprensione immagine-testo ad alta precisione.",
  "internvl3-latest.description": "Il nostro modello multimodale più recente con una comprensione immagine-testo più avanzata e capacità di analisi di immagini in sequenza lunga, comparabile ai migliori modelli chiusi. Impostato di default sulla serie InternVL più recente (attualmente internvl3-78b).",
  "irag-1.0.description": "ERNIE iRAG è un modello di generazione aumentata dal recupero di immagini per la ricerca visiva, il recupero immagine-testo e la generazione di contenuti.",
  "jamba-large.description": "Il nostro modello più potente e avanzato, progettato per compiti aziendali complessi con prestazioni eccezionali.",
  "jamba-mini.description": "Il modello più efficiente della sua categoria, che bilancia velocità e qualità con un ingombro ridotto.",
  "jina-deepsearch-v1.description": "DeepSearch combina ricerca web, lettura e ragionamento per indagini approfondite. Pensalo come un agente che prende il tuo compito di ricerca, esegue ricerche ampie con più iterazioni e solo dopo produce una risposta. Il processo prevede ricerca continua, ragionamento e risoluzione di problemi da più angolazioni, fondamentalmente diverso dai LLM standard che rispondono dai dati di preaddestramento o dai sistemi RAG tradizionali che si basano su una ricerca superficiale one-shot.",
  "kimi-k2-0711-preview.description": "kimi-k2 è un modello base MoE con forti capacità di programmazione e agenti (1T di parametri totali, 32B attivi), che supera altri modelli open-source mainstream nei benchmark di ragionamento, programmazione, matematica e agenti.",
  "kimi-k2-0905-preview.description": "kimi-k2-0905-preview offre una finestra di contesto da 256k, una programmazione agentica più forte, una qualità del codice front-end migliorata e una comprensione del contesto più profonda.",
  "kimi-k2-instruct.description": "Kimi K2 Instruct è il modello ufficiale di ragionamento di Kimi con contesto esteso per codice, domande e risposte e altro.",
  "kimi-k2-thinking-turbo.description": "Variante K2 long-thinking ad alta velocità con contesto da 256k, ragionamento profondo avanzato e output da 60–100 token/sec.",
  "kimi-k2-thinking.description": "kimi-k2-thinking è un modello di ragionamento di Moonshot AI con capacità generali di agenti e ragionamento. Eccelle nel ragionamento profondo e può risolvere problemi complessi tramite l'uso di strumenti multi-step.",
  "kimi-k2-turbo-preview.description": "kimi-k2 è un modello base MoE con forti capacità di programmazione e agenti (1T di parametri totali, 32B attivi), che supera altri modelli open-source mainstream nei benchmark di ragionamento, programmazione, matematica e agenti.",
  "kimi-k2.5.description": "Kimi K2.5 è il modello Kimi più avanzato, che offre prestazioni SOTA open-source in compiti da agente, programmazione e comprensione visiva. Supporta input multimodali e modalità con o senza pensiero.",
  "kimi-k2.description": "Kimi-K2 è un modello base MoE di Moonshot AI con forti capacità di programmazione e agenti, per un totale di 1T di parametri con 32B attivi. Nei benchmark per ragionamento generale, programmazione, matematica e compiti agentici, supera altri modelli open-source mainstream.",
  "kimi-k2:1t.description": "Kimi K2 è un grande LLM MoE di Moonshot AI con 1T di parametri totali e 32B attivi per passaggio. È ottimizzato per capacità agentiche tra cui uso avanzato di strumenti, ragionamento e sintesi di codice.",
  "kimi-latest.description": "Kimi Latest utilizza il modello Kimi più recente e può includere funzionalità sperimentali. Supporta la comprensione delle immagini e seleziona automaticamente i modelli di fatturazione 8k/32k/128k in base alla lunghezza del contesto.",
  "kuaishou/kat-coder-pro-v1.description": "KAT-Coder-Pro-V1 (gratuito per un periodo limitato) è focalizzato sulla comprensione del codice e sull'automazione per agenti di programmazione efficienti.",
  "learnlm-1.5-pro-experimental.description": "LearnLM è un modello sperimentale e specifico per compiti, addestrato secondo i principi della scienza dell'apprendimento per seguire istruzioni di sistema in scenari di insegnamento/apprendimento, agendo come un tutor esperto.",
  "learnlm-2.0-flash-experimental.description": "LearnLM è un modello sperimentale e specifico per compiti, addestrato secondo i principi della scienza dell'apprendimento per seguire istruzioni di sistema in scenari di insegnamento/apprendimento, agendo come un tutor esperto.",
  "lite.description": "Spark Lite è un LLM leggero con latenza ultra-bassa ed elaborazione efficiente. È completamente gratuito e supporta la ricerca web in tempo reale. Le sue risposte rapide si comportano bene su dispositivi a bassa potenza e per il fine-tuning dei modelli, offrendo un'esperienza intelligente e conveniente, soprattutto per domande e risposte, generazione di contenuti e scenari di ricerca.",
  "llama-3.1-70b-versatile.description": "Llama 3.1 70B offre un ragionamento AI avanzato per applicazioni complesse, supportando carichi computazionali elevati con alta efficienza e precisione.",
  "llama-3.1-8b-instant.description": "Llama 3.1 8B è un modello ad alta efficienza con generazione di testo rapida, ideale per applicazioni su larga scala e a basso costo.",
  "llama-3.1-instruct.description": "Il modello Llama 3.1 ottimizzato per istruzioni è progettato per chat e supera molti modelli open source nei benchmark di settore.",
  "llama-3.2-11b-vision-instruct.description": "Potente ragionamento visivo su immagini ad alta risoluzione, ideale per applicazioni di comprensione visiva.",
  "llama-3.2-11b-vision-preview.description": "Llama 3.2 è progettato per compiti che combinano visione e testo, eccellendo in didascalie di immagini e domande e risposte visive, unendo generazione linguistica e ragionamento visivo.",
  "llama-3.2-90b-vision-instruct.description": "Ragionamento visivo avanzato per applicazioni di agenti con comprensione visiva.",
  "llama-3.2-90b-vision-preview.description": "Llama 3.2 è progettato per compiti che combinano visione e testo, eccellendo in didascalie di immagini e domande e risposte visive, unendo generazione linguistica e ragionamento visivo.",
  "llama-3.2-vision-instruct.description": "Il modello Llama 3.2-Vision ottimizzato per istruzioni è progettato per riconoscimento visivo, ragionamento su immagini, generazione di didascalie e domande e risposte generali su immagini.",
  "llama-3.3-70b-versatile.description": "Meta Llama 3.3 è un LLM multilingue con 70 miliardi di parametri (input/output testuale), disponibile in versioni pre-addestrate e ottimizzate per istruzioni. Il modello testuale ottimizzato per istruzioni è pensato per dialoghi multilingue e supera molti modelli open e closed nei benchmark di settore.",
  "llama-3.3-70b.description": "Llama 3.3 70B: un modello Llama di dimensioni medio-grandi che bilancia ragionamento e throughput.",
  "llama-3.3-instruct.description": "Il modello Llama 3.3 ottimizzato per istruzioni è progettato per chat e supera molti modelli open source nei benchmark di settore.",
  "llama3-70b-8192.description": "Meta Llama 3 70B offre una gestione eccezionale della complessità per progetti impegnativi.",
  "llama3-8b-8192.description": "Meta Llama 3 8B garantisce prestazioni di ragionamento solide in scenari diversificati.",
  "llama3-groq-70b-8192-tool-use-preview.description": "Llama 3 Groq 70B Tool Use offre un uso efficiente degli strumenti per la gestione di compiti complessi.",
  "llama3-groq-8b-8192-tool-use-preview.description": "Llama 3 Groq 8B Tool Use è ottimizzato per un uso efficiente degli strumenti con calcolo parallelo veloce.",
  "llama3.1-8b.description": "Llama 3.1 8B: una variante Llama compatta e a bassa latenza per inferenza online leggera e chat.",
  "llama3.1.description": "Llama 3.1 è il modello di punta di Meta, scalabile fino a 405 miliardi di parametri per dialoghi complessi, traduzioni multilingue e analisi dei dati.",
  "llama3.1:405b.description": "Llama 3.1 è il modello di punta di Meta, scalabile fino a 405 miliardi di parametri per dialoghi complessi, traduzioni multilingue e analisi dei dati.",
  "llama3.1:70b.description": "Llama 3.1 è il modello di punta di Meta, scalabile fino a 405 miliardi di parametri per dialoghi complessi, traduzioni multilingue e analisi dei dati.",
  "llava-v1.5-7b-4096-preview.description": "LLaVA 1.5 7B integra l'elaborazione visiva per generare output complessi da input visivi.",
  "llava.description": "LLaVA è un modello multimodale che combina un encoder visivo e Vicuna per una solida comprensione visione-linguaggio.",
  "llava:13b.description": "LLaVA è un modello multimodale che combina un encoder visivo e Vicuna per una solida comprensione visione-linguaggio.",
  "llava:34b.description": "LLaVA è un modello multimodale che combina un encoder visivo e Vicuna per una solida comprensione visione-linguaggio.",
  "magistral-medium-latest.description": "Magistral Medium 1.2 è un modello di ragionamento avanzato di Mistral AI (settembre 2025) con supporto visivo.",
  "magistral-small-2509.description": "Magistral Small 1.2 è un modello open source compatto di Mistral AI (settembre 2025) con supporto visivo.",
  "mathstral.description": "MathΣtral è progettato per la ricerca scientifica e il ragionamento matematico, con forti capacità di calcolo e spiegazione.",
  "max-32k.description": "Spark Max 32K offre elaborazione di contesti estesi con una comprensione logica e contestuale avanzata, supportando input fino a 32.000 token per lettura di documenti lunghi e domande su conoscenze private.",
  "megrez-3b-instruct.description": "Megrez 3B Instruct è un modello compatto ed efficiente sviluppato da Wuwen Xinqiong.",
  "meituan/longcat-flash-chat.description": "Un modello base open source non riflessivo di Meituan, ottimizzato per dialoghi e compiti agentici, eccellente nell'uso di strumenti e interazioni complesse multi-turno.",
  "meta-llama-3-70b-instruct.description": "Un potente modello da 70 miliardi di parametri che eccelle nel ragionamento, nella programmazione e nei compiti linguistici generali.",
  "meta-llama-3-8b-instruct.description": "Un modello versatile da 8 miliardi di parametri ottimizzato per chat e generazione di testo.",
  "meta-llama-3.1-405b-instruct.description": "Modello testuale Llama 3.1 ottimizzato per istruzioni, progettato per chat multilingue, con prestazioni elevate nei benchmark di settore tra i modelli open e closed.",
  "meta-llama-3.1-70b-instruct.description": "Modello testuale Llama 3.1 ottimizzato per istruzioni, progettato per chat multilingue, con prestazioni elevate nei benchmark di settore tra i modelli open e closed.",
  "meta-llama-3.1-8b-instruct.description": "Modello testuale Llama 3.1 ottimizzato per istruzioni, progettato per chat multilingue, con prestazioni elevate nei benchmark di settore tra i modelli open e closed.",
  "meta-llama/Llama-2-13b-chat-hf.description": "LLaMA-2 Chat (13B) offre una solida gestione linguistica e un'esperienza di chat affidabile.",
  "meta-llama/Llama-2-70b-hf.description": "LLaMA-2 offre una solida gestione linguistica e un'interazione fluida.",
  "meta-llama/Llama-3-70b-chat-hf.description": "Llama 3 70B Instruct Reference è un potente modello di chat per dialoghi complessi.",
  "meta-llama/Llama-3-8b-chat-hf.description": "Llama 3 8B Instruct Reference offre supporto multilingue e conoscenza su ampi domini.",
  "meta-llama/Llama-3.2-11B-Vision-Instruct-Turbo.description": "LLaMA 3.2 è progettato per compiti che combinano visione e testo. Eccelle in didascalie di immagini e domande e risposte visive, unendo generazione linguistica e ragionamento visivo.",
  "meta-llama/Llama-3.2-3B-Instruct-Turbo.description": "LLaMA 3.2 è progettato per compiti che combinano visione e testo. Eccelle in didascalie di immagini e domande e risposte visive, unendo generazione linguistica e ragionamento visivo.",
  "meta-llama/Llama-3.2-90B-Vision-Instruct-Turbo.description": "LLaMA 3.2 è progettato per compiti che combinano visione e testo. Eccelle in didascalie di immagini e domande e risposte visive, unendo generazione linguistica e ragionamento visivo.",
  "meta-llama/Llama-3.3-70B-Instruct-Turbo.description": "Meta Llama 3.3 è un LLM multilingue da 70B (input/output testuale), pre-addestrato e ottimizzato per istruzioni. La versione testuale ottimizzata per istruzioni è pensata per chat multilingue e supera molti modelli open e closed nei benchmark di settore.",
  "meta-llama/Llama-Vision-Free.description": "LLaMA 3.2 è progettato per compiti che combinano visione e testo. Eccelle in didascalie di immagini e domande e risposte visive, unendo generazione linguistica e ragionamento visivo.",
  "meta-llama/Meta-Llama-3-70B-Instruct-Lite.description": "Llama 3 70B Instruct Lite è progettato per alte prestazioni con bassa latenza.",
  "meta-llama/Meta-Llama-3-70B-Instruct-Turbo.description": "Llama 3 70B Instruct Turbo offre comprensione e generazione avanzate per i carichi di lavoro più esigenti.",
  "meta-llama/Meta-Llama-3-8B-Instruct-Lite.description": "Llama 3 8B Instruct Lite bilancia prestazioni e risorse per ambienti con vincoli.",
  "meta-llama/Meta-Llama-3-8B-Instruct-Turbo.description": "Llama 3 8B Instruct Turbo è un LLM ad alte prestazioni per un'ampia gamma di casi d'uso.",
  "meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo.description": "Il modello Llama 3.1 Turbo da 405B offre una capacità di contesto enorme per l'elaborazione di big data ed eccelle in applicazioni AI su scala ultra.",
  "meta-llama/Meta-Llama-3.1-405B-Instruct.description": "Llama 3.1 è la famiglia di modelli di punta di Meta, scalabile fino a 405 miliardi di parametri per dialoghi complessi, traduzioni multilingue e analisi dei dati.",
  "meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo.description": "Llama 3.1 70B è finemente ottimizzato per applicazioni ad alto carico; la quantizzazione FP8 garantisce calcolo efficiente e precisione in scenari complessi.",
  "meta-llama/Meta-Llama-3.1-70B.description": "Llama 3.1 è la famiglia di modelli di punta di Meta, scalabile fino a 405 miliardi di parametri per dialoghi complessi, traduzioni multilingue e analisi dei dati.",
  "meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo.description": "Llama 3.1 8B utilizza quantizzazione FP8, supporta fino a 131.072 token di contesto e si posiziona tra i migliori modelli open per compiti complessi su numerosi benchmark.",
  "meta-llama/llama-3-70b-instruct.description": "Llama 3 70B Instruct è ottimizzato per dialoghi di alta qualità e mostra ottime prestazioni nelle valutazioni umane.",
  "meta-llama/llama-3-8b-instruct.description": "Llama 3 8B Instruct è ottimizzato per dialoghi di alta qualità, superando molti modelli closed.",
  "meta-llama/llama-3.1-70b-instruct.description": "La serie Llama 3.1 più recente di Meta, variante da 70B ottimizzata per istruzioni e dialoghi di alta qualità. Nei benchmark di settore, mostra prestazioni elevate rispetto ai principali modelli closed. (Disponibile solo per entità verificate aziendalmente.)",
  "meta-llama/llama-3.1-8b-instruct.description": "La serie Llama 3.1 più recente di Meta, variante da 8B ottimizzata per istruzioni, particolarmente veloce ed efficiente. Nei benchmark di settore, offre prestazioni elevate, superando molti modelli closed. (Disponibile solo per entità verificate aziendalmente.)",
  "meta-llama/llama-3.1-8b-instruct:free.description": "LLaMA 3.1 offre supporto multilingue ed è uno dei principali modelli generativi.",
  "meta-llama/llama-3.2-11b-vision-instruct.description": "LLaMA 3.2 è progettato per compiti che combinano visione e testo. Eccelle in didascalie di immagini e domande e risposte visive, unendo generazione linguistica e ragionamento visivo.",
  "meta-llama/llama-3.2-3b-instruct.description": "meta-llama/llama-3.2-3b-instruct",
  "meta-llama/llama-3.2-90b-vision-instruct.description": "LLaMA 3.2 è progettato per compiti che combinano visione e testo. Eccelle in didascalie di immagini e domande e risposte visive, unendo generazione linguistica e ragionamento visivo.",
  "meta-llama/llama-3.3-70b-instruct.description": "Llama 3.3 è il modello Llama open source multilingue più avanzato, con prestazioni vicine a quelle dei modelli da 405B a costi molto contenuti. Basato su Transformer, è migliorato con SFT e RLHF per utilità e sicurezza. La versione ottimizzata per istruzioni è pensata per chat multilingue e supera molti modelli open e closed nei benchmark di settore. Data di cutoff: dicembre 2023.",
  "meta-llama/llama-3.3-70b-instruct:free.description": "Llama 3.3 è il modello Llama open source multilingue più avanzato, con prestazioni vicine a quelle dei modelli da 405B a costi molto contenuti. Basato su Transformer, è migliorato con SFT e RLHF per utilità e sicurezza. La versione ottimizzata per istruzioni è pensata per chat multilingue e supera molti modelli open e closed nei benchmark di settore. Data di cutoff: dicembre 2023.",
  "meta.llama3-1-405b-instruct-v1:0.description": "Meta Llama 3.1 405B Instruct è il modello Llama 3.1 Instruct più grande e potente, altamente avanzato per il ragionamento dialogico e la generazione di dati sintetici, e una solida base per pretraining o fine-tuning specifici per dominio. I LLM multilingue Llama 3.1 sono una serie di modelli di generazione preaddestrati e ottimizzati per le istruzioni in versioni da 8B, 70B e 405B (input/output testuale). I modelli ottimizzati per le istruzioni sono progettati per dialoghi multilingue e superano molti modelli open chat disponibili nei benchmark industriali. Llama 3.1 è pensato per l'uso commerciale e di ricerca in più lingue. I modelli ottimizzati per le istruzioni sono adatti a chat in stile assistente, mentre i modelli preaddestrati si adattano a compiti più generali di generazione linguistica. Gli output di Llama 3.1 possono anche essere utilizzati per migliorare altri modelli, inclusa la generazione e il perfezionamento di dati sintetici. Llama 3.1 è un modello Transformer autoregressivo con architettura ottimizzata. Le versioni ottimizzate utilizzano fine-tuning supervisionato (SFT) e apprendimento per rinforzo con feedback umano (RLHF) per allinearsi alle preferenze umane in termini di utilità e sicurezza.",
  "meta.llama3-1-70b-instruct-v1:0.description": "Meta Llama 3.1 70B Instruct aggiornato con una finestra di contesto estesa a 128K, supporto multilingue e ragionamento migliorato. I modelli Llama 3.1 multilingue sono pre-addestrati e ottimizzati per la generazione in 8B, 70B e 405B. I modelli ottimizzati per istruzioni sono ideali per chat in stile assistente, mentre i modelli pre-addestrati si adattano a compiti generali di generazione linguistica. I risultati possono anche migliorare altri modelli, inclusa la generazione e il perfezionamento di dati sintetici. Llama 3.1 è un modello Transformer autoregressivo con architettura ottimizzata. Le versioni ottimizzate usano SFT e RLHF per allinearsi alle preferenze umane in termini di utilità e sicurezza.",
  "meta.llama3-1-8b-instruct-v1:0.description": "Meta Llama 3.1 8B Instruct aggiornato con finestra di contesto da 128K, supporto multilingue e ragionamento migliorato. La famiglia Llama 3.1 include modelli ottimizzati per istruzioni da 8B, 70B e 405B, ideali per chat multilingue e prestazioni elevate nei benchmark. Progettato per uso commerciale e di ricerca in più lingue. I risultati possono migliorare altri modelli (es. dati sintetici). È un modello Transformer autoregressivo, con SFT e RLHF per allineamento a utilità e sicurezza.",
  "meta.llama3-70b-instruct-v1:0.description": "Meta Llama 3 è un LLM open-source per sviluppatori, ricercatori e aziende, progettato per costruire, sperimentare e scalare responsabilmente idee di IA generativa. Parte della base per l'innovazione della comunità globale, è adatto per creazione di contenuti, IA conversazionale, comprensione linguistica, R&S e applicazioni aziendali.",
  "meta.llama3-8b-instruct-v1:0.description": "Meta Llama 3 è un LLM open-source pensato per sviluppatori, ricercatori e aziende, progettato per supportare la creazione, la sperimentazione e la scalabilità responsabile di idee basate su IA generativa. Parte integrante dell’ecosistema globale per l’innovazione comunitaria, è ideale per ambienti con risorse limitate, dispositivi edge e tempi di addestramento ridotti.",
  "meta/Llama-3.2-11B-Vision-Instruct.description": "Solido ragionamento visivo su immagini ad alta risoluzione, ideale per applicazioni di comprensione visiva.",
  "meta/Llama-3.2-90B-Vision-Instruct.description": "Ragionamento visivo avanzato per applicazioni agenti di comprensione visiva.",
  "meta/Llama-3.3-70B-Instruct.description": "Llama 3.3 è il modello Llama open-source multilingue più avanzato, con prestazioni paragonabili a modelli da 405B a costi molto contenuti. Basato su architettura Transformer, è migliorato con SFT e RLHF per garantire utilità e sicurezza. La versione ottimizzata per istruzioni eccelle nelle chat multilingue e supera molti modelli, sia open che closed, nei benchmark di settore. Data di cutoff: dicembre 2023.",
  "meta/Meta-Llama-3-70B-Instruct.description": "Un potente modello da 70 miliardi di parametri eccellente nel ragionamento, nella programmazione e nei compiti linguistici generali.",
  "meta/Meta-Llama-3-8B-Instruct.description": "Un modello versatile da 8 miliardi di parametri ottimizzato per chat e generazione di testo.",
  "meta/Meta-Llama-3.1-405B-Instruct.description": "Modello Llama 3.1 ottimizzato per istruzioni, progettato per chat multilingue, con prestazioni elevate nei benchmark industriali tra modelli open e closed.",
  "meta/Meta-Llama-3.1-70B-Instruct.description": "Modello Llama 3.1 ottimizzato per istruzioni, progettato per chat multilingue, con prestazioni elevate nei benchmark industriali tra modelli open e closed.",
  "meta/Meta-Llama-3.1-8B-Instruct.description": "Modello Llama 3.1 ottimizzato per istruzioni, progettato per chat multilingue, con prestazioni elevate nei benchmark industriali tra modelli open e closed.",
  "meta/llama-3-70b.description": "Modello open-source da 70 miliardi di parametri, ottimizzato da Meta per seguire istruzioni, distribuito da Groq su hardware LPU per inferenza rapida ed efficiente.",
  "meta/llama-3-8b.description": "Modello open-source da 8 miliardi di parametri, ottimizzato da Meta per seguire istruzioni, distribuito da Groq su hardware LPU per inferenza rapida ed efficiente.",
  "meta/llama-3.1-405b-instruct.description": "Modello LLM avanzato che supporta generazione di dati sintetici, distillazione della conoscenza e ragionamento per chatbot, programmazione e compiti specifici di dominio.",
  "meta/llama-3.1-70b-instruct.description": "Progettato per dialoghi complessi con eccellente comprensione del contesto, ragionamento e generazione di testo.",
  "meta/llama-3.1-70b.description": "Versione aggiornata di Meta Llama 3 70B Instruct con contesto esteso a 128K, supporto multilingue e ragionamento migliorato.",
  "meta/llama-3.1-8b-instruct.description": "Modello all’avanguardia con solida comprensione linguistica, capacità di ragionamento e generazione di testo.",
  "meta/llama-3.1-8b.description": "Llama 3.1 8B supporta una finestra di contesto di 128K, ideale per chat in tempo reale e analisi dei dati, offrendo un notevole risparmio rispetto ai modelli più grandi. Distribuito da Groq su hardware LPU per inferenza rapida ed efficiente.",
  "meta/llama-3.2-11b-vision-instruct.description": "Modello linguistico-visivo di frontiera eccellente nel ragionamento di alta qualità a partire da immagini.",
  "meta/llama-3.2-11b.description": "Modello ottimizzato per istruzioni e ragionamento su immagini (input testo+immagine, output testo), ideale per riconoscimento visivo, ragionamento su immagini, didascalie e domande generali su immagini.",
  "meta/llama-3.2-1b-instruct.description": "Modello linguistico compatto e all’avanguardia con forte comprensione, ragionamento e generazione di testo.",
  "meta/llama-3.2-1b.description": "Modello solo testo per utilizzi su dispositivo come recupero locale multilingue, sintesi e riscrittura.",
  "meta/llama-3.2-3b-instruct.description": "Modello linguistico compatto e all’avanguardia con forte comprensione, ragionamento e generazione di testo.",
  "meta/llama-3.2-3b.description": "Modello solo testo ottimizzato per utilizzi su dispositivo come recupero locale multilingue, sintesi e riscrittura.",
  "meta/llama-3.2-90b-vision-instruct.description": "Modello linguistico-visivo di frontiera eccellente nel ragionamento di alta qualità a partire da immagini.",
  "meta/llama-3.2-90b.description": "Modello ottimizzato per istruzioni e ragionamento su immagini (input testo+immagine, output testo), ideale per riconoscimento visivo, ragionamento su immagini, didascalie e domande generali su immagini.",
  "meta/llama-3.3-70b-instruct.description": "LLM avanzato con solide capacità di ragionamento, matematica, buon senso e chiamata di funzioni.",
  "meta/llama-3.3-70b.description": "Un perfetto equilibrio tra prestazioni ed efficienza. Progettato per IA conversazionale ad alte prestazioni in creazione di contenuti, applicazioni aziendali e ricerca, con forte comprensione linguistica per sintesi, classificazione, analisi del sentiment e generazione di codice.",
  "meta/llama-4-maverick.description": "La famiglia Llama 4 è una serie di modelli AI nativamente multimodali che supportano esperienze testuali e multimodali, utilizzando MoE per una comprensione avanzata di testo e immagini. Llama 4 Maverick è un modello da 17B con 128 esperti, distribuito da DeepInfra.",
  "meta/llama-4-scout.description": "La famiglia Llama 4 è una serie di modelli AI nativamente multimodali che supportano esperienze testuali e multimodali, utilizzando MoE per una comprensione avanzata di testo e immagini. Llama 4 Scout è un modello da 17B con 16 esperti, distribuito da DeepInfra.",
  "microsoft/Phi-3-medium-128k-instruct.description": "Lo stesso modello Phi-3-medium con una finestra di contesto più ampia per prompt RAG o few-shot.",
  "microsoft/Phi-3-medium-4k-instruct.description": "Un modello da 14B parametri con qualità superiore rispetto a Phi-3-mini, focalizzato su dati di alta qualità e intensivi in ragionamento.",
  "microsoft/Phi-3-mini-128k-instruct.description": "Lo stesso modello Phi-3-mini con una finestra di contesto più ampia per prompt RAG o few-shot.",
  "microsoft/Phi-3-mini-4k-instruct.description": "Il membro più piccolo della famiglia Phi-3, ottimizzato per qualità e bassa latenza.",
  "microsoft/Phi-3-small-128k-instruct.description": "Lo stesso modello Phi-3-small con una finestra contestuale più ampia per RAG o prompt few-shot.",
  "microsoft/Phi-3-small-8k-instruct.description": "Un modello da 7 miliardi di parametri con qualità superiore rispetto a Phi-3-mini, focalizzato su dati di alta qualità e ad alta intensità di ragionamento.",
  "microsoft/Phi-3.5-mini-instruct.description": "Una versione aggiornata del modello Phi-3-mini.",
  "microsoft/Phi-3.5-vision-instruct.description": "Una versione aggiornata del modello Phi-3-vision.",
  "microsoft/WizardLM-2-8x22B.description": "WizardLM 2 è un modello linguistico di Microsoft AI eccellente nei dialoghi complessi, nei compiti multilingue, nel ragionamento e negli assistenti.",
  "microsoft/wizardlm-2-8x22b.description": "WizardLM-2 8x22B è il modello Wizard più avanzato di Microsoft AI, con prestazioni altamente competitive.",
  "mimo-v2-flash.description": "MiMo-V2-Flash: un modello efficiente per ragionamento, programmazione e basi per agenti.",
  "minicpm-v.description": "MiniCPM-V è il modello multimodale di nuova generazione di OpenBMB, con eccellenti capacità OCR e comprensione multimodale per un'ampia gamma di casi d'uso.",
  "minimax-m2.1.description": "MiniMax-M2.1 è l'ultima versione della serie MiniMax, ottimizzata per la programmazione multilingue e compiti complessi del mondo reale. Come modello nativo IA, MiniMax-M2.1 offre miglioramenti significativi in prestazioni, supporto per framework agentici e adattamento a scenari multipli, con l'obiettivo di aiutare aziende e individui a trovare più rapidamente uno stile di vita e lavoro nativo IA.",
  "minimax-m2.description": "MiniMax M2 è un modello linguistico di grandi dimensioni efficiente, costruito specificamente per la programmazione e i flussi di lavoro degli agenti.",
  "minimax/minimax-m2.1.description": "MiniMax-M2.1 è un modello linguistico di grandi dimensioni all'avanguardia e leggero, ottimizzato per la programmazione, i flussi di lavoro proxy e lo sviluppo di applicazioni moderne, offrendo output più puliti e concisi e tempi di risposta percettiva più rapidi.",
  "minimax/minimax-m2.description": "MiniMax-M2 è un modello ad alto valore che eccelle nella codifica e nei compiti per agenti in molti scenari ingegneristici.",
  "minimaxai/minimax-m2.description": "MiniMax-M2 è un modello MoE compatto, veloce ed economico (230B totali, 10B attivi) progettato per prestazioni di alto livello nella codifica e nei compiti per agenti, mantenendo una forte intelligenza generale. Eccelle in modifiche multi-file, cicli di esecuzione-correzione del codice, validazione dei test e catene di strumenti complesse.",
  "ministral-3b-latest.description": "Ministral 3B è il modello edge di punta di Mistral.",
  "ministral-8b-latest.description": "Ministral 8B è un modello edge altamente conveniente di Mistral.",
  "mistral-ai/Mistral-Large-2411.description": "Il modello di punta di Mistral per compiti complessi che richiedono ragionamento su larga scala o specializzazione (generazione di testo sintetico, generazione di codice, RAG o agenti).",
  "mistral-ai/Mistral-Nemo.description": "Mistral Nemo è un LLM all'avanguardia con ragionamento di alto livello, conoscenza del mondo e capacità di codifica per la sua dimensione.",
  "mistral-ai/mistral-small-2503.description": "Mistral Small è adatto a qualsiasi compito linguistico che richieda alta efficienza e bassa latenza.",
  "mistral-large-instruct.description": "Mistral-Large-Instruct-2407 è un LLM denso avanzato con 123 miliardi di parametri e ragionamento, conoscenza e codifica all'avanguardia.",
  "mistral-large-latest.description": "Mistral Large è il modello di punta, forte nei compiti multilingue, nel ragionamento complesso e nella generazione di codice—ideale per applicazioni di fascia alta.",
  "mistral-large.description": "Mixtral Large è il modello di punta di Mistral, che combina generazione di codice, matematica e ragionamento con una finestra contestuale di 128K.",
  "mistral-medium-latest.description": "Mistral Medium 3 offre prestazioni all'avanguardia a un costo 8× inferiore e semplifica l'implementazione aziendale.",
  "mistral-nemo-instruct.description": "Mistral-Nemo-Instruct-2407 è la versione ottimizzata per istruzioni di Mistral-Nemo-Base-2407.",
  "mistral-nemo.description": "Mistral Nemo è un modello da 12B ad alta efficienza di Mistral AI e NVIDIA.",
  "mistral-small-latest.description": "Mistral Small è un'opzione conveniente, veloce e affidabile per traduzione, sintesi e analisi del sentiment.",
  "mistral-small.description": "Mistral Small è adatto a qualsiasi compito linguistico che richieda alta efficienza e bassa latenza.",
  "mistral.description": "Mistral è il modello da 7B di Mistral AI, adatto a compiti linguistici vari.",
  "mistral/codestral-embed.description": "Un modello di embedding per codici, utile per indicizzare basi di codice e repository a supporto di assistenti alla programmazione.",
  "mistral/codestral.description": "Mistral Codestral 25.01 è un modello di codifica all'avanguardia ottimizzato per bassa latenza e uso ad alta frequenza. Supporta oltre 80 linguaggi e si distingue in FIM, correzione del codice e generazione di test.",
  "mistral/devstral-small.description": "Devstral è un LLM agentico per compiti di ingegneria del software, rendendolo una scelta solida per agenti software.",
  "mistral/magistral-medium.description": "Pensiero complesso supportato da una comprensione profonda con ragionamento trasparente che puoi seguire e verificare. Mantiene un ragionamento ad alta fedeltà tra le lingue, anche a metà compito.",
  "mistral/magistral-small.description": "Pensiero complesso supportato da una comprensione profonda con ragionamento trasparente che puoi seguire e verificare. Mantiene un ragionamento ad alta fedeltà tra le lingue, anche a metà compito.",
  "mistral/ministral-3b.description": "Un modello compatto ed efficiente per compiti on-device come assistenti e analisi locali, con prestazioni a bassa latenza.",
  "mistral/ministral-8b.description": "Un modello più potente con inferenza veloce ed efficiente in memoria, ideale per flussi di lavoro complessi e applicazioni edge esigenti.",
  "mistral/mistral-embed.description": "Un modello generale di embedding testuale per ricerca semantica, similarità, clustering e flussi di lavoro RAG.",
  "mistral/mistral-large.description": "Mistral Large è ideale per compiti complessi che richiedono forte ragionamento o specializzazione—generazione di testo sintetico, generazione di codice, RAG o agenti.",
  "mistral/mistral-small.description": "Mistral Small è ideale per compiti semplici e batchabili come classificazione, supporto clienti o generazione di testo, offrendo ottime prestazioni a un prezzo accessibile.",
  "mistral/mixtral-8x22b-instruct.description": "Modello Instruct 8x22B. 8x22B è un modello MoE open source servito da Mistral.",
  "mistral/pixtral-12b.description": "Un modello da 12B con comprensione delle immagini e testo.",
  "mistral/pixtral-large.description": "Pixtral Large è il secondo modello della nostra famiglia multimodale con comprensione delle immagini di livello avanzato. Gestisce documenti, grafici e immagini naturali mantenendo la comprensione testuale leader di Mistral Large 2.",
  "mistralai/Mistral-7B-Instruct-v0.1.description": "Mistral (7B) Instruct è noto per le forti prestazioni in molti compiti linguistici.",
  "mistralai/Mistral-7B-Instruct-v0.2.description": "Mistral (7B) Instruct v0.2 migliora la gestione delle istruzioni e l'accuratezza dei risultati.",
  "mistralai/Mistral-7B-Instruct-v0.3.description": "Mistral (7B) Instruct v0.3 offre calcolo efficiente e forte comprensione linguistica per molti casi d'uso.",
  "mistralai/Mistral-7B-v0.1.description": "Mistral 7B è compatto ma ad alte prestazioni, forte nell'elaborazione batch e in compiti semplici come classificazione e generazione di testo, con solido ragionamento.",
  "mistralai/Mixtral-8x22B-Instruct-v0.1.description": "Mixtral-8x22B Instruct (141B) è un LLM molto grande per carichi di lavoro pesanti.",
  "mistralai/Mixtral-8x7B-Instruct-v0.1.description": "Mixtral-8x7B Instruct (46.7B) offre alta capacità per l'elaborazione di dati su larga scala.",
  "mistralai/Mixtral-8x7B-v0.1.description": "Mixtral 8x7B è un modello MoE sparso che aumenta la velocità di inferenza, adatto a compiti multilingue e generazione di codice.",
  "mistralai/mistral-nemo.description": "Mistral Nemo è un modello da 7.3B con supporto multilingue e forti prestazioni nella codifica.",
  "mixtral-8x7b-32768.description": "Mixtral 8x7B fornisce calcolo parallelo tollerante ai guasti per compiti complessi.",
  "mixtral.description": "Mixtral è il modello MoE di Mistral AI con pesi open-source, che supporta la generazione di codice e la comprensione linguistica.",
  "mixtral:8x22b.description": "Mixtral è il modello MoE di Mistral AI con pesi open-source, che supporta la generazione di codice e la comprensione linguistica.",
  "moonshot-v1-128k-vision-preview.description": "I modelli visivi Kimi (inclusi moonshot-v1-8k-vision-preview/moonshot-v1-32k-vision-preview/moonshot-v1-128k-vision-preview) comprendono contenuti visivi come testo, colori e forme degli oggetti.",
  "moonshot-v1-128k.description": "Moonshot V1 128K offre un contesto ultra-lungo per la generazione di testi molto estesi, gestendo fino a 128.000 token per scenari di ricerca, accademici e documenti di grandi dimensioni.",
  "moonshot-v1-32k-vision-preview.description": "I modelli visivi Kimi (inclusi moonshot-v1-8k-vision-preview/moonshot-v1-32k-vision-preview/moonshot-v1-128k-vision-preview) comprendono contenuti visivi come testo, colori e forme degli oggetti.",
  "moonshot-v1-32k.description": "Moonshot V1 32K supporta 32.768 token per contesti di media lunghezza, ideale per documenti lunghi e dialoghi complessi in creazione di contenuti, report e sistemi di chat.",
  "moonshot-v1-8k-vision-preview.description": "I modelli visivi Kimi (inclusi moonshot-v1-8k-vision-preview/moonshot-v1-32k-vision-preview/moonshot-v1-128k-vision-preview) comprendono contenuti visivi come testo, colori e forme degli oggetti.",
  "moonshot-v1-8k.description": "Moonshot V1 8K è ottimizzato per la generazione di testi brevi con prestazioni efficienti, gestendo 8.192 token per chat brevi, appunti e contenuti rapidi.",
  "moonshot-v1-auto.description": "Moonshot V1 Auto seleziona automaticamente il modello più adatto in base all'utilizzo corrente dei token di contesto.",
  "moonshotai/Kimi-Dev-72B.description": "Kimi-Dev-72B è un LLM open-source per il codice, ottimizzato con RL su larga scala per generare patch robuste e pronte per la produzione. Ottiene un punteggio del 60,4% su SWE-bench Verified, stabilendo un nuovo record tra i modelli open-source per attività di ingegneria del software automatizzata come la correzione di bug e la revisione del codice.",
  "moonshotai/Kimi-K2-Instruct-0905.description": "Kimi K2-Instruct-0905 è la versione più recente e potente della serie Kimi K2. È un modello MoE di fascia alta con 1T di parametri totali e 32B attivi. Tra le caratteristiche principali: maggiore intelligenza agentica nella programmazione, miglioramenti significativi nei benchmark e nei compiti reali per agenti, oltre a un'estetica e usabilità del codice frontend più curate.",
  "moonshotai/Kimi-K2-Thinking.description": "Kimi K2 Thinking è il più recente e potente modello open-source per il ragionamento. Estende notevolmente la profondità del ragionamento multi-step e mantiene un uso stabile degli strumenti per 200–300 chiamate consecutive, stabilendo nuovi record su Humanity's Last Exam (HLE), BrowseComp e altri benchmark. Eccelle in programmazione, matematica, logica e scenari agentici. Basato su un'architettura MoE con ~1T di parametri totali, supporta una finestra di contesto di 256K e chiamate a strumenti.",
  "moonshotai/kimi-k2-0711.description": "Kimi K2 0711 è la variante instruct della serie Kimi, adatta per codice di alta qualità e uso di strumenti.",
  "moonshotai/kimi-k2-0905.description": "Kimi K2 0905 è un aggiornamento che migliora le prestazioni di contesto e ragionamento con ottimizzazioni per la programmazione.",
  "moonshotai/kimi-k2-instruct-0905.description": "Il modello kimi-k2-0905-preview supporta una finestra di contesto di 256k, con programmazione agentica più avanzata, codice frontend più rifinito e pratico, e una migliore comprensione del contesto.",
  "moonshotai/kimi-k2-thinking-turbo.description": "Kimi K2 Thinking Turbo è una versione ad alta velocità di Kimi K2 Thinking, che riduce significativamente la latenza mantenendo un ragionamento profondo.",
  "moonshotai/kimi-k2-thinking.description": "Kimi K2 Thinking è il modello di ragionamento di Moonshot ottimizzato per compiti di ragionamento profondo, con capacità agentiche generali.",
  "moonshotai/kimi-k2.description": "Kimi K2 è un grande modello MoE di Moonshot AI con 1T di parametri totali e 32B attivi per passaggio, ottimizzato per capacità agentiche tra cui uso avanzato di strumenti, ragionamento e sintesi di codice.",
  "morph/morph-v3-fast.description": "Morph offre un modello specializzato per applicare modifiche al codice suggerite da modelli avanzati (es. Claude o GPT-4o) ai tuoi file esistenti a una velocità di oltre 4500 token/sec. È l'ultimo passaggio in un flusso di lavoro di programmazione AI e supporta 16k token in input/output.",
  "morph/morph-v3-large.description": "Morph offre un modello specializzato per applicare modifiche al codice suggerite da modelli avanzati (es. Claude o GPT-4o) ai tuoi file esistenti a una velocità di oltre 2500 token/sec. È l'ultimo passaggio in un flusso di lavoro di programmazione AI e supporta 16k token in input/output.",
  "nousresearch/hermes-2-pro-llama-3-8b.description": "Hermes 2 Pro Llama 3 8B è una versione aggiornata di Nous Hermes 2 con i più recenti dataset sviluppati internamente.",
  "nvidia/Llama-3.1-Nemotron-70B-Instruct-HF.description": "Llama 3.1 Nemotron 70B è un LLM personalizzato da NVIDIA per migliorare l'utilità. Ottiene ottimi risultati su Arena Hard, AlpacaEval 2 LC e GPT-4-Turbo MT-Bench, classificandosi al primo posto in tutti e tre i benchmark di auto-allineamento al 1° ottobre 2024. È addestrato da Llama-3.1-70B-Instruct usando RLHF (REINFORCE), Llama-3.1-Nemotron-70B-Reward e prompt HelpSteer2-Preference.",
  "nvidia/llama-3.1-nemotron-51b-instruct.description": "Un modello linguistico distintivo che offre precisione ed efficienza eccezionali.",
  "nvidia/llama-3.1-nemotron-70b-instruct.description": "Llama-3.1-Nemotron-70B-Instruct è un modello personalizzato da NVIDIA progettato per migliorare l'utilità delle risposte LLM.",
  "o1-mini.description": "Più piccolo e veloce di o1-preview, con un costo inferiore dell'80%, eccelle nella generazione di codice e nei compiti a contesto breve.",
  "o1-preview.description": "Focalizzato su ragionamento avanzato e risoluzione di problemi complessi, inclusi matematica e scienze. Ideale per applicazioni che richiedono comprensione profonda del contesto e flussi di lavoro autonomi.",
  "o1-pro.description": "La serie o1 è addestrata con apprendimento per rinforzo per pensare prima di rispondere e gestire ragionamenti complessi. o1-pro utilizza più risorse computazionali per un pensiero più profondo e risposte di qualità costantemente superiore.",
  "o1.description": "o1 è il nuovo modello di ragionamento di OpenAI con input testo+immagine e output testuale, adatto a compiti complessi che richiedono conoscenze ampie. Ha una finestra di contesto di 200K e un cutoff di conoscenza a ottobre 2023.",
  "o3-2025-04-16.description": "o3 è il nuovo modello di ragionamento di OpenAI con input testo+immagine e output testuale per compiti complessi che richiedono conoscenze ampie.",
  "o3-deep-research.description": "o3-deep-research è il nostro modello più avanzato per ricerca approfondita su compiti multi-step complessi. Può cercare sul web e accedere ai tuoi dati tramite connettori MCP.",
  "o3-mini.description": "o3-mini è il nostro ultimo modello di ragionamento compatto, che offre maggiore intelligenza mantenendo gli stessi obiettivi di costo e latenza di o1-mini.",
  "o3-pro-2025-06-10.description": "o3 Pro è il nuovo modello di ragionamento di OpenAI con input testo+immagine e output testuale per compiti complessi che richiedono conoscenze ampie.",
  "o3-pro.description": "o3-pro utilizza più risorse computazionali per pensare più a fondo e fornire risposte costantemente migliori; disponibile solo tramite l'API Responses.",
  "o3.description": "o3 è un modello versatile e potente che stabilisce un nuovo standard per matematica, scienze, programmazione e ragionamento visivo. Eccelle nella scrittura tecnica e nel seguire istruzioni, e può analizzare testo, codice e immagini per problemi multi-step.",
  "o4-mini-2025-04-16.description": "o4-mini è un modello di ragionamento OpenAI con input testo+immagine e output testuale, adatto a compiti complessi che richiedono conoscenze ampie, con una finestra di contesto di 200K.",
  "o4-mini-deep-research.description": "o4-mini-deep-research è un modello di ricerca approfondita più veloce ed economico per ricerche complesse a più passaggi. Può cercare sul web e accedere ai tuoi dati tramite connettori MCP.",
  "o4-mini.description": "o4-mini è l'ultimo modello compatto della serie o, ottimizzato per un ragionamento rapido ed efficace, con alta efficienza nei compiti di programmazione e visione.",
  "open-codestral-mamba.description": "Codestral Mamba è un modello linguistico Mamba 2 focalizzato sulla generazione di codice, adatto a compiti avanzati di programmazione e ragionamento.",
  "open-mistral-7b.description": "Mistral 7B è compatto ma ad alte prestazioni, ideale per l'elaborazione in batch e compiti semplici come classificazione e generazione di testo, con solide capacità di ragionamento.",
  "open-mistral-nemo.description": "Mistral Nemo è un modello da 12B sviluppato in collaborazione con Nvidia, che offre elevate prestazioni in ragionamento e programmazione, con integrazione semplificata.",
  "open-mixtral-8x22b.description": "Mixtral 8x22B è un modello MoE di grandi dimensioni per compiti complessi, con forte capacità di ragionamento e throughput elevato.",
  "open-mixtral-8x7b.description": "Mixtral 8x7B è un modello MoE sparso che accelera l'inferenza, adatto a compiti multilingue e di generazione di codice.",
  "openai/gpt-3.5-turbo-instruct.description": "Capacità simili ai modelli dell'era GPT-3, compatibile con endpoint legacy di completamento piuttosto che chat.",
  "openai/gpt-3.5-turbo.description": "Il modello GPT-3.5 più capace ed economico di OpenAI, ottimizzato per la chat ma ancora valido per completamenti classici.",
  "openai/gpt-4-turbo.description": "gpt-4-turbo di OpenAI possiede una vasta conoscenza generale e competenze specialistiche, segue istruzioni complesse in linguaggio naturale e risolve problemi difficili con precisione. Il cutoff di conoscenza è aprile 2023 con una finestra di contesto di 128k.",
  "openai/gpt-4.1-mini.description": "GPT-4.1 Mini offre una latenza ridotta e un miglior rapporto qualità-prezzo per carichi di lavoro a contesto medio.",
  "openai/gpt-4.1-nano.description": "GPT-4.1 Nano è un'opzione a bassissimo costo e latenza per chat brevi ad alta frequenza o classificazione.",
  "openai/gpt-4.1.description": "La serie GPT-4.1 offre finestre di contesto più ampie e capacità ingegneristiche e di ragionamento più avanzate.",
  "openai/gpt-4o-mini.description": "GPT-4o-mini è una variante compatta e veloce di GPT-4o per utilizzi multimodali a bassa latenza.",
  "openai/gpt-4o.description": "La famiglia GPT-4o è il modello Omni di OpenAI con input testuale + immagine e output testuale.",
  "openai/gpt-5-chat.description": "GPT-5 Chat è una variante di GPT-5 ottimizzata per conversazioni con latenza ridotta per una migliore interattività.",
  "openai/gpt-5-codex.description": "GPT-5-Codex è una variante di GPT-5 ulteriormente ottimizzata per la programmazione e flussi di lavoro su larga scala.",
  "openai/gpt-5-mini.description": "GPT-5 Mini è una variante compatta di GPT-5 per scenari a bassa latenza e basso costo.",
  "openai/gpt-5-nano.description": "GPT-5 Nano è la variante ultra-compatta per scenari con vincoli stringenti di costo e latenza.",
  "openai/gpt-5-pro.description": "GPT-5 Pro è il modello di punta di OpenAI, con capacità avanzate di ragionamento, generazione di codice e funzionalità di livello enterprise, con routing in fase di test e politiche di sicurezza più rigorose.",
  "openai/gpt-5.1-chat.description": "GPT-5.1 Chat è il membro leggero della famiglia GPT-5.1, ottimizzato per conversazioni a bassa latenza mantenendo forti capacità di ragionamento ed esecuzione di istruzioni.",
  "openai/gpt-5.1-codex-mini.description": "GPT-5.1-Codex-Mini è una versione più piccola e veloce di GPT-5.1-Codex, ideale per scenari di programmazione sensibili a latenza e costi.",
  "openai/gpt-5.1-codex.description": "GPT-5.1-Codex è una variante di GPT-5.1 ottimizzata per l'ingegneria del software e i flussi di lavoro di programmazione, adatta a grandi refactoring, debug complessi e compiti autonomi prolungati.",
  "openai/gpt-5.1.description": "GPT-5.1 è il nuovo modello di punta della serie GPT-5, con miglioramenti significativi rispetto a GPT-5 nel ragionamento generale, nel seguire istruzioni e nella naturalezza conversazionale, adatto a compiti ampi.",
  "openai/gpt-5.2-chat.description": "GPT-5.2 Chat è la variante ChatGPT per sperimentare i più recenti miglioramenti nella conversazione.",
  "openai/gpt-5.2-pro.description": "GPT-5.2 Pro: una variante GPT-5.2 più intelligente e precisa (solo tramite Responses API), adatta a problemi complessi e ragionamenti multi-turno estesi.",
  "openai/gpt-5.2.description": "GPT-5.2 è un modello di punta per la programmazione e i flussi di lavoro agentici, con ragionamento potenziato e prestazioni su contesti lunghi.",
  "openai/gpt-5.description": "GPT-5 è il modello ad alte prestazioni di OpenAI per un'ampia gamma di compiti di produzione e ricerca.",
  "openai/gpt-oss-120b.description": "Un LLM generalista altamente capace con ragionamento forte e controllabile.",
  "openai/gpt-oss-20b.description": "Un modello linguistico compatto a pesi aperti ottimizzato per bassa latenza e ambienti con risorse limitate, inclusi deployment locali e edge.",
  "openai/o1-mini.description": "o1-mini è un modello di ragionamento veloce ed economico progettato per programmazione, matematica e scienze. Ha un contesto di 128K e un cutoff di conoscenza a ottobre 2023.",
  "openai/o1-preview.description": "o1 è il nuovo modello di ragionamento di OpenAI per compiti complessi che richiedono ampia conoscenza. Ha un contesto di 128K e un cutoff di conoscenza a ottobre 2023.",
  "openai/o1.description": "OpenAI o1 è un modello di ragionamento di punta progettato per problemi complessi che richiedono pensiero profondo, offrendo ragionamento avanzato e maggiore accuratezza nei compiti a più passaggi.",
  "openai/o3-mini-high.description": "o3-mini (ragionamento avanzato) offre maggiore intelligenza mantenendo gli stessi obiettivi di costo e latenza di o1-mini.",
  "openai/o3-mini.description": "o3-mini è l'ultimo modello compatto di ragionamento di OpenAI, che offre maggiore intelligenza agli stessi livelli di costo e latenza di o1-mini.",
  "openai/o3.description": "OpenAI o3 è il modello di ragionamento più potente, stabilendo nuovi standard nello stato dell'arte per programmazione, matematica, scienze e percezione visiva. Eccelle in query complesse e articolate, in particolare nell'analisi di immagini, grafici e diagrammi.",
  "openai/o4-mini-high.description": "o4-mini livello di ragionamento avanzato, ottimizzato per ragionamento veloce ed efficiente con elevate prestazioni in programmazione e visione.",
  "openai/o4-mini.description": "OpenAI o4-mini è un modello compatto ed efficiente di ragionamento per scenari a bassa latenza.",
  "openai/text-embedding-3-large.description": "Il modello di embedding più avanzato di OpenAI per compiti in inglese e in altre lingue.",
  "openai/text-embedding-3-small.description": "Variante migliorata e ad alte prestazioni del modello ada di embedding di OpenAI.",
  "openai/text-embedding-ada-002.description": "Modello legacy di embedding testuale di OpenAI.",
  "openrouter/auto.description": "In base alla lunghezza del contesto, all'argomento e alla complessità, la tua richiesta viene instradata a Llama 3 70B Instruct, Claude 3.5 Sonnet (auto-moderato) o GPT-4o.",
  "perplexity/sonar-pro.description": "Il prodotto di punta di Perplexity con ancoraggio alla ricerca, supporta query avanzate e follow-up.",
  "perplexity/sonar-reasoning-pro.description": "Un modello avanzato focalizzato sul ragionamento che produce catene di pensiero (CoT) con ricerca migliorata, incluse più query per richiesta.",
  "perplexity/sonar-reasoning.description": "Un modello focalizzato sul ragionamento che produce catene di pensiero (CoT) con spiegazioni dettagliate basate sulla ricerca.",
  "perplexity/sonar.description": "Il prodotto leggero di Perplexity con ancoraggio alla ricerca, più veloce ed economico rispetto a Sonar Pro.",
  "phi3.description": "Phi-3 è il modello open-source leggero di Microsoft per un'integrazione efficiente e ragionamento su larga scala.",
  "phi3:14b.description": "Phi-3 è il modello open-source leggero di Microsoft per un'integrazione efficiente e ragionamento su larga scala.",
  "pixtral-12b-2409.description": "Pixtral è forte nella comprensione di grafici/immagini, QA su documenti, ragionamento multimodale e seguire istruzioni. Elabora immagini alla risoluzione/aspect ratio nativi e gestisce qualsiasi numero di immagini entro una finestra di contesto di 128K.",
  "pixtral-large-latest.description": "Pixtral Large è un modello multimodale open-source da 124B parametri basato su Mistral Large 2, il secondo della nostra famiglia multimodale con comprensione visiva di livello avanzato.",
  "pro-128k.description": "Spark Pro 128K offre una capacità di contesto molto ampia, gestendo fino a 128K token, ideale per documenti lunghi che richiedono analisi testuale completa e coerenza a lungo raggio, con logica fluida e supporto a citazioni diversificate in discussioni complesse.",
  "pro-deepseek-r1.description": "Modello di servizio dedicato per aziende con concorrenza inclusa.",
  "pro-deepseek-v3.description": "Modello di servizio dedicato per aziende con concorrenza inclusa.",
  "qianfan-70b.description": "Qianfan 70B è un grande modello cinese per generazione di alta qualità e ragionamento complesso.",
  "qianfan-8b.description": "Qianfan 8B è un modello generale di medie dimensioni che bilancia costi e qualità per generazione di testo e domande-risposte.",
  "qianfan-agent-intent-32k.description": "Qianfan Agent Intent 32K è progettato per il riconoscimento dell’intento e l’orchestrazione di agenti con supporto a contesti lunghi.",
  "qianfan-agent-lite-8k.description": "Qianfan Agent Lite 8K è un modello leggero per dialoghi multi-turno a basso costo e flussi di lavoro.",
  "qianfan-check-vl.description": "Qianfan Check VL è un modello multimodale per la revisione di contenuti e il riconoscimento immagine-testo.",
  "qianfan-composition.description": "Qianfan Composition è un modello multimodale per comprensione e generazione mista immagine-testo.",
  "qianfan-engcard-vl.description": "Qianfan EngCard VL è un modello di riconoscimento multimodale focalizzato su scenari in lingua inglese.",
  "qianfan-lightning-128b-a19b.description": "Qianfan Lightning 128B A19B è un modello generale cinese ad alte prestazioni per domande complesse e ragionamento su larga scala.",
  "qianfan-llama-vl-8b.description": "Qianfan Llama VL 8B è un modello multimodale basato su Llama per la comprensione generale immagine-testo.",
  "qianfan-multipicocr.description": "Qianfan MultiPicOCR è un modello OCR multi-immagine per rilevamento e riconoscimento del testo su più immagini.",
  "qianfan-qi-vl.description": "Qianfan QI VL è un modello multimodale di domande-risposte per recupero accurato e QA in scenari immagine-testo complessi.",
  "qianfan-singlepicocr.description": "Qianfan SinglePicOCR è un modello OCR per singola immagine con riconoscimento caratteri ad alta precisione.",
  "qianfan-vl-70b.description": "Qianfan VL 70B è un grande modello VLM per la comprensione complessa immagine-testo.",
  "qianfan-vl-8b.description": "Qianfan VL 8B è un VLM leggero per domande-risposte e analisi immagine-testo quotidiane.",
  "qvq-72b-preview.description": "QVQ-72B-Preview è un modello sperimentale del team Qwen focalizzato sul miglioramento del ragionamento visivo.",
  "qvq-max.description": "Il modello di ragionamento visivo Qwen QVQ supporta input visivi e output con catena di pensiero, con prestazioni superiori in matematica, programmazione, analisi visiva, creatività e compiti generali.",
  "qvq-plus.description": "Modello di ragionamento visivo con input visivo e output con catena di pensiero. La serie qvq-plus segue qvq-max e offre ragionamento più veloce con un miglior equilibrio qualità-costo.",
  "qwen-3-32b.description": "Qwen 3 32B: eccellente in compiti multilingue e di programmazione, adatto per produzione su scala media.",
  "qwen-coder-plus.description": "Modello di programmazione Qwen.",
  "qwen-coder-turbo-latest.description": "Modello di programmazione Qwen.",
  "qwen-coder-turbo.description": "Modello di programmazione Qwen.",
  "qwen-flash.description": "Modello Qwen più veloce ed economico, ideale per compiti semplici.",
  "qwen-image-edit.description": "Qwen Image Edit è un modello immagine-a-immagine che modifica immagini in base a input visivi e prompt testuali, consentendo regolazioni precise e trasformazioni creative.",
  "qwen-image.description": "Qwen-Image è un modello generale di generazione di immagini che supporta più stili artistici e una forte resa di testi complessi, in particolare in cinese e inglese. Supporta layout su più righe, testo a livello di paragrafo e dettagli fini per layout immagine-testo complessi.",
  "qwen-long.description": "Modello Qwen ultra-large con contesto esteso e chat su scenari multi-documento e lunghi.",
  "qwen-math-plus-latest.description": "Qwen Math è un modello linguistico specializzato nella risoluzione di problemi matematici.",
  "qwen-math-plus.description": "Qwen Math è un modello linguistico specializzato nella risoluzione di problemi matematici.",
  "qwen-math-turbo-latest.description": "Qwen Math è un modello linguistico specializzato nella risoluzione di problemi matematici.",
  "qwen-math-turbo.description": "Qwen Math è un modello linguistico specializzato nella risoluzione di problemi matematici.",
  "qwen-max.description": "Modello Qwen ultra-large da centinaia di miliardi di parametri che supporta cinese, inglese e altre lingue; è il modello API alla base dei prodotti Qwen2.5 attuali.",
  "qwen-omni-turbo.description": "I modelli Qwen-Omni supportano input multimodali (video, audio, immagini, testo) e output audio e testuali.",
  "qwen-plus.description": "Modello Qwen ultra-large potenziato che supporta cinese, inglese e altre lingue.",
  "qwen-turbo.description": "Qwen Turbo non sarà più aggiornato; sostituirlo con Qwen Flash. Modello Qwen ultra-large che supporta cinese, inglese e altre lingue.",
  "qwen-vl-chat-v1.description": "Qwen VL supporta interazioni flessibili tra cui input multi-immagine, domande-risposte multi-turno e compiti creativi.",
  "qwen-vl-max-latest.description": "Modello Qwen visione-linguaggio ultra-large. Rispetto alla versione potenziata, migliora ulteriormente il ragionamento visivo e il rispetto delle istruzioni per una percezione e cognizione più forti.",
  "qwen-vl-max.description": "Modello Qwen visione-linguaggio ultra-large. Rispetto alla versione potenziata, migliora ulteriormente il ragionamento visivo e il rispetto delle istruzioni per una percezione visiva più forte.",
  "qwen-vl-ocr.description": "Qwen OCR è un modello di estrazione testo per documenti, tabelle, immagini di esami e scrittura a mano. Supporta cinese, inglese, francese, giapponese, coreano, tedesco, russo, italiano, vietnamita e arabo.",
  "qwen-vl-plus-latest.description": "Modello Qwen visione-linguaggio potenziato su larga scala con grandi miglioramenti nel riconoscimento dei dettagli e del testo, supporta risoluzioni superiori a un megapixel e rapporti d’aspetto arbitrari.",
  "qwen-vl-plus.description": "Modello Qwen visione-linguaggio potenziato su larga scala con grandi miglioramenti nel riconoscimento dei dettagli e del testo, supporta risoluzioni superiori a un megapixel e rapporti d’aspetto arbitrari.",
  "qwen-vl-v1.description": "Modello preaddestrato inizializzato da Qwen-7B con modulo visivo aggiunto e input immagine a risoluzione 448.",
  "qwen/qwen-2-7b-instruct.description": "Qwen2 è la nuova serie di LLM Qwen. Qwen2 7B è un modello basato su transformer che eccelle in comprensione linguistica, capacità multilingue, programmazione, matematica e ragionamento.",
  "qwen/qwen-2-7b-instruct:free.description": "Qwen2 è una nuova famiglia di modelli linguistici di grandi dimensioni con maggiore capacità di comprensione e generazione.",
  "qwen/qwen-2-vl-72b-instruct.description": "Qwen2-VL è l’ultima iterazione di Qwen-VL, con prestazioni all’avanguardia nei benchmark visivi come MathVista, DocVQA, RealWorldQA e MTVQA. Comprende oltre 20 minuti di video per domande-risposte, dialoghi e creazione di contenuti di alta qualità. Gestisce anche ragionamento complesso e decisioni, integrandosi con dispositivi mobili e robot per agire in base al contesto visivo e alle istruzioni testuali. Oltre a cinese e inglese, legge testi in immagini in molte lingue, tra cui la maggior parte delle lingue europee, giapponese, coreano, arabo e vietnamita.",
  "qwen/qwen-2.5-72b-instruct.description": "Qwen2.5-72B-Instruct è uno degli ultimi rilasci LLM di Alibaba Cloud. Il modello da 72B offre miglioramenti significativi in programmazione e matematica, supporta oltre 29 lingue (inclusi cinese e inglese) e migliora notevolmente l’esecuzione di istruzioni, la comprensione di dati strutturati e l’output strutturato (in particolare JSON).",
  "qwen/qwen2.5-coder-32b-instruct.description": "Un avanzato LLM per la generazione, il ragionamento e la correzione del codice nei principali linguaggi di programmazione.",
  "qwen/qwen2.5-coder-7b-instruct.description": "Un solido modello di codice di medie dimensioni con contesto da 32K, eccellente nella programmazione multilingue.",
  "qwen/qwen3-14b.description": "Qwen3-14B è la variante da 14B per il ragionamento generale e scenari di chat.",
  "qwen/qwen3-14b:free.description": "Qwen3-14B è un LLM causale denso con 14,8 miliardi di parametri, progettato per ragionamento complesso e chat efficiente. Passa da una modalità di pensiero per matematica, programmazione e logica a una modalità non-pensante per la chat generale. Ottimizzato per seguire istruzioni, usare strumenti agentici e scrittura creativa in oltre 100 lingue e dialetti. Supporta nativamente un contesto di 32K e scala fino a 131K con YaRN.",
  "qwen/qwen3-235b-a22b-2507.description": "Qwen3-235B-A22B-Instruct-2507 è la variante Instruct della serie Qwen3, che bilancia l'uso multilingue delle istruzioni con scenari a lungo contesto.",
  "qwen/qwen3-235b-a22b-thinking-2507.description": "Qwen3-235B-A22B-Thinking-2507 è la variante Thinking di Qwen3, potenziata per compiti complessi di matematica e ragionamento.",
  "qwen/qwen3-235b-a22b.description": "Qwen3-235B-A22B è un modello MoE da 235 miliardi di parametri con 22 miliardi attivi per passaggio. Passa da una modalità di pensiero per ragionamento complesso, matematica e codice a una modalità non-pensante per chat efficiente. Offre ragionamento avanzato, supporto multilingue (oltre 100 lingue/dialetti), capacità avanzate di seguire istruzioni e uso di strumenti agentici. Supporta nativamente 32K di contesto e scala fino a 131K con YaRN.",
  "qwen/qwen3-235b-a22b:free.description": "Qwen3-235B-A22B è un modello MoE da 235 miliardi di parametri con 22 miliardi attivi per passaggio. Passa da una modalità di pensiero per ragionamento complesso, matematica e codice a una modalità non-pensante per chat efficiente. Offre ragionamento avanzato, supporto multilingue (oltre 100 lingue/dialetti), capacità avanzate di seguire istruzioni e uso di strumenti agentici. Supporta nativamente 32K di contesto e scala fino a 131K con YaRN.",
  "qwen/qwen3-30b-a3b.description": "Qwen3 è l'ultima generazione di LLM Qwen con architetture dense e MoE, eccellente nel ragionamento, supporto multilingue e compiti avanzati per agenti. La sua capacità unica di passare da una modalità di pensiero per ragionamento complesso a una modalità non-pensante per chat efficiente garantisce prestazioni versatili e di alta qualità.\n\nQwen3 supera significativamente i modelli precedenti come QwQ e Qwen2.5, offrendo eccellenza in matematica, programmazione, ragionamento di buon senso, scrittura creativa e chat interattiva. La variante Qwen3-30B-A3B ha 30,5 miliardi di parametri (3,3B attivi), 48 layer, 128 esperti (8 attivi per compito) e supporta fino a 131K di contesto con YaRN, stabilendo un nuovo standard per i modelli open source.",
  "qwen/qwen3-30b-a3b:free.description": "Qwen3 è l'ultima generazione di LLM Qwen con architetture dense e MoE, eccellente nel ragionamento, supporto multilingue e compiti avanzati per agenti. La sua capacità unica di passare da una modalità di pensiero per ragionamento complesso a una modalità non-pensante per chat efficiente garantisce prestazioni versatili e di alta qualità.\n\nQwen3 supera significativamente i modelli precedenti come QwQ e Qwen2.5, offrendo eccellenza in matematica, programmazione, ragionamento di buon senso, scrittura creativa e chat interattiva. La variante Qwen3-30B-A3B ha 30,5 miliardi di parametri (3,3B attivi), 48 layer, 128 esperti (8 attivi per compito) e supporta fino a 131K di contesto con YaRN, stabilendo un nuovo standard per i modelli open source.",
  "qwen/qwen3-32b.description": "Qwen3-32B è un LLM causale denso con 32,8 miliardi di parametri, ottimizzato per ragionamento complesso e chat efficiente. Passa da una modalità di pensiero per matematica, programmazione e logica a una modalità non-pensante per chat generale più veloce. Eccelle nel seguire istruzioni, uso di strumenti agentici e scrittura creativa in oltre 100 lingue e dialetti. Supporta nativamente 32K di contesto e scala fino a 131K con YaRN.",
  "qwen/qwen3-32b:free.description": "Qwen3-32B è un LLM causale denso con 32,8 miliardi di parametri, ottimizzato per ragionamento complesso e chat efficiente. Passa da una modalità di pensiero per matematica, programmazione e logica a una modalità non-pensante per chat generale più veloce. Eccelle nel seguire istruzioni, uso di strumenti agentici e scrittura creativa in oltre 100 lingue e dialetti. Supporta nativamente 32K di contesto e scala fino a 131K con YaRN.",
  "qwen/qwen3-8b:free.description": "Qwen3-8B è un LLM causale denso con 8,2 miliardi di parametri, progettato per compiti con forte componente di ragionamento e chat efficiente. Passa da una modalità di pensiero per matematica, programmazione e logica a una modalità non-pensante per chat generale. Ottimizzato per seguire istruzioni, integrazione con agenti e scrittura creativa in oltre 100 lingue e dialetti. Supporta nativamente 32K di contesto e scala fino a 131K con YaRN.",
  "qwen/qwen3-coder-plus.description": "Qwen3-Coder-Plus è un modello agente per la programmazione della serie Qwen, ottimizzato per l'uso di strumenti complessi e sessioni prolungate.",
  "qwen/qwen3-coder.description": "Qwen3-Coder è la famiglia di modelli Qwen3 per la generazione di codice, eccellente nella comprensione e generazione di codice su documenti lunghi.",
  "qwen/qwen3-max-preview.description": "Qwen3 Max (anteprima) è la variante Max per ragionamento avanzato e integrazione con strumenti.",
  "qwen/qwen3-max.description": "Qwen3 Max è il modello di ragionamento di fascia alta della serie Qwen3, progettato per ragionamento multilingue e integrazione con strumenti.",
  "qwen3-coder:480b.description": "Modello ad alte prestazioni di Alibaba per attività di agenti e programmazione, con supporto a contesti lunghi.",
  "qwen3-max-preview.description": "Il modello Qwen con le migliori prestazioni per compiti complessi e multi-step. La versione preview supporta il ragionamento.",
  "qwen3-max.description": "I modelli Qwen3 Max offrono miglioramenti significativi rispetto alla serie 2.5 in capacità generali, comprensione di cinese/inglese, esecuzione di istruzioni complesse, compiti soggettivi aperti, abilità multilingue e uso di strumenti, con meno allucinazioni. L'ultima versione qwen3-max migliora la programmazione agentica e l'uso degli strumenti rispetto a qwen3-max-preview. Questa release raggiunge lo stato dell’arte e risponde a esigenze agentiche più complesse.",
  "qwen3-next-80b-a3b-instruct.description": "Modello open-source di nuova generazione Qwen3 senza capacità di ragionamento. Rispetto alla versione precedente (Qwen3-235B-A22B-Instruct-2507), offre una migliore comprensione del cinese, un ragionamento logico più forte e una generazione di testo migliorata.",
  "qwen3-next-80b-a3b-thinking.description": "Qwen3 Next 80B A3B Thinking è la versione di punta per il ragionamento, progettata per compiti complessi.",
  "qwen3-omni-flash.description": "Qwen-Omni accetta input combinati da testo, immagini, audio e video, e genera output in forma testuale o vocale. Offre stili vocali naturali multipli, supporta lingue e dialetti diversi, ed è adatto a casi d’uso come scrittura, riconoscimento visivo e assistenti vocali.",
  "qwen3-vl-235b-a22b-instruct.description": "Qwen3 VL 235B A22B Instruct è un modello multimodale di punta per comprensione e creazione avanzate.",
  "qwen3-vl-235b-a22b-thinking.description": "Qwen3 VL 235B A22B Thinking è la versione di punta per il ragionamento multimodale complesso e la pianificazione.",
  "qwen3-vl-30b-a3b-instruct.description": "Qwen3 VL 30B A3B Instruct è un grande modello multimodale che bilancia accuratezza e capacità di ragionamento.",
  "qwen3-vl-30b-a3b-thinking.description": "Qwen3 VL 30B A3B Thinking è una versione avanzata per il ragionamento profondo in compiti multimodali complessi.",
  "qwen3-vl-32b-instruct.description": "Qwen3 VL 32B Instruct è un modello multimodale ottimizzato per istruzioni, ideale per QA immagine-testo di alta qualità e creazione.",
  "qwen3-vl-32b-thinking.description": "Qwen3 VL 32B Thinking è una versione multimodale per il ragionamento profondo, adatta ad analisi complesse e catene logiche lunghe.",
  "qwen3-vl-8b-instruct.description": "Qwen3 VL 8B Instruct è un modello multimodale leggero per QA visivo quotidiano e integrazione in app.",
  "qwen3-vl-8b-thinking.description": "Qwen3 VL 8B Thinking è un modello multimodale con catena di pensiero per ragionamento visivo dettagliato.",
  "qwen3-vl-flash.description": "Qwen3 VL Flash: versione leggera e ad alta velocità per richieste sensibili alla latenza o ad alto volume.",
  "qwen3-vl-plus.description": "Qwen VL è un modello di generazione testuale con comprensione visiva. Può eseguire OCR, riassumere e ragionare, ad esempio estraendo attributi da foto di prodotti o risolvendo problemi da immagini.",
  "qwen3.description": "Qwen3 è il modello linguistico di nuova generazione di Alibaba, con prestazioni elevate in una vasta gamma di casi d’uso.",
  "qwq-32b-preview.description": "QwQ è un modello sperimentale di ricerca della famiglia Qwen, focalizzato sul miglioramento del ragionamento.",
  "qwq-32b.description": "QwQ è un modello di ragionamento della famiglia Qwen. Rispetto ai modelli standard ottimizzati per istruzioni, offre capacità di pensiero e ragionamento che migliorano significativamente le prestazioni nei compiti complessi. QwQ-32B è un modello di medie dimensioni che compete con i migliori modelli di ragionamento come DeepSeek-R1 e o1-mini.",
  "qwq-plus.description": "Il modello di ragionamento QwQ, addestrato su Qwen2.5, utilizza l’apprendimento per rinforzo per migliorare notevolmente il ragionamento. Ottiene punteggi di punta in matematica/codice (AIME 24/25, LiveCodeBench) e benchmark generali (IFEval, LiveBench), raggiungendo il livello di DeepSeek-R1.",
  "qwq.description": "QwQ è un modello di ragionamento della famiglia Qwen. Rispetto ai modelli standard ottimizzati per istruzioni, offre capacità di pensiero e ragionamento che migliorano significativamente le prestazioni nei compiti difficili. QwQ-32B è un modello di medie dimensioni che compete con i migliori modelli di ragionamento come DeepSeek-R1 e o1-mini.",
  "qwq_32b.description": "Modello di ragionamento di medie dimensioni della famiglia Qwen. Rispetto ai modelli standard ottimizzati per istruzioni, le capacità di pensiero e ragionamento di QwQ migliorano significativamente le prestazioni nei compiti difficili.",
  "r1-1776.description": "R1-1776 è una variante post-addestrata di DeepSeek R1 progettata per fornire informazioni fattuali non censurate e imparziali.",
  "solar-mini-ja.description": "Solar Mini (Ja) estende Solar Mini con un focus sul giapponese, mantenendo prestazioni efficienti e solide in inglese e coreano.",
  "solar-mini.description": "Solar Mini è un LLM compatto che supera GPT-3.5, con forte capacità multilingue in inglese e coreano, offrendo una soluzione efficiente e leggera.",
  "solar-pro.description": "Solar Pro è un LLM ad alta intelligenza di Upstage, focalizzato sull’esecuzione di istruzioni su una singola GPU, con punteggi IFEval superiori a 80. Attualmente supporta l’inglese; il rilascio completo è previsto per novembre 2024 con supporto linguistico ampliato e contesto più lungo.",
  "sonar-deep-research.description": "Deep Research esegue ricerche approfondite a livello esperto e le sintetizza in report accessibili e utili.",
  "sonar-pro.description": "Prodotto di ricerca avanzata con ancoraggio alla ricerca per query complesse e follow-up.",
  "sonar-reasoning-pro.description": "Prodotto di ricerca avanzata con ancoraggio alla ricerca per query complesse e follow-up.",
  "sonar-reasoning.description": "Prodotto di ricerca avanzata con ancoraggio alla ricerca per query complesse e follow-up.",
  "sonar.description": "Prodotto leggero con ancoraggio alla ricerca, più veloce ed economico rispetto a Sonar Pro.",
  "spark-x.description": "Aggiornamenti X1.5: (1) aggiunge modalità di pensiero dinamico controllata dal campo `thinking`; (2) lunghezza del contesto aumentata a 64K input e 64K output; (3) supporta FunctionCall.",
  "stable-diffusion-3-medium.description": "L'ultimo modello text-to-image di Stability AI. Questa versione migliora significativamente la qualità delle immagini, la comprensione del testo e la diversità stilistica, interpretando con maggiore precisione prompt complessi in linguaggio naturale e generando immagini più accurate e varie.",
  "stable-diffusion-3.5-large-turbo.description": "stable-diffusion-3.5-large-turbo applica la distillazione per diffusione avversaria (ADD) a stable-diffusion-3.5-large per una maggiore velocità.",
  "stable-diffusion-3.5-large.description": "stable-diffusion-3.5-large è un modello text-to-image MMDiT da 800M parametri con qualità eccellente e allineamento ai prompt, supporta immagini da 1 megapixel ed è efficiente su hardware consumer.",
  "stable-diffusion-v1.5.description": "stable-diffusion-v1.5 è inizializzato dal checkpoint v1.2 e ottimizzato per 595k step su \"laion-aesthetics v2 5+\" a risoluzione 512x512, riducendo il conditioning testuale del 10% per migliorare il campionamento classifier-free.",
  "stable-diffusion-xl-base-1.0.description": "Modello open-source text-to-image di Stability AI con generazione creativa di immagini leader nel settore. Ha una forte comprensione delle istruzioni e supporta definizioni inverse dei prompt per generazioni precise.",
  "stable-diffusion-xl.description": "stable-diffusion-xl introduce miglioramenti significativi rispetto alla v1.5 e raggiunge i migliori risultati open-source text-to-image. Include un backbone UNet 3 volte più grande, un modulo di raffinamento per immagini migliori e tecniche di addestramento più efficienti.",
  "step-1-128k.description": "Equilibrio tra prestazioni e costi per scenari generali.",
  "step-1-256k.description": "Gestione di contesti extra-lunghi, ideale per l’analisi di documenti estesi.",
  "step-1-32k.description": "Supporta conversazioni di media lunghezza per un’ampia gamma di scenari.",
  "step-1-8k.description": "Modello piccolo adatto a compiti leggeri.",
  "step-1-flash.description": "Modello ad alta velocità adatto a chat in tempo reale.",
  "step-1.5v-mini.description": "Forti capacità di comprensione video.",
  "step-1o-turbo-vision.description": "Eccellente comprensione delle immagini, supera 1o in matematica e programmazione. Più piccolo di 1o con output più veloce.",
  "step-1o-vision-32k.description": "Forte comprensione visiva con prestazioni superiori rispetto alla serie Step-1V.",
  "step-1v-32k.description": "Supporta input visivi per interazioni multimodali più ricche.",
  "step-1v-8k.description": "Modello visivo compatto per compiti base immagine-testo.",
  "step-1x-edit.description": "Questo modello si concentra sull’editing di immagini, modificando e migliorando immagini in base a input testuali e visivi forniti dall’utente. Supporta più formati di input e genera modifiche coerenti con l’intento dell’utente.",
  "step-1x-medium.description": "Questo modello offre una forte generazione di immagini da prompt testuali. Con supporto nativo al cinese, comprende meglio le descrizioni in cinese, ne cattura la semantica e le trasforma in caratteristiche visive per una generazione più accurata. Produce immagini ad alta risoluzione e qualità, con supporto a un certo grado di trasferimento di stile.",
  "step-2-16k-exp.description": "Build sperimentale Step-2 con le ultime funzionalità e aggiornamenti continui. Non consigliato per ambienti di produzione.",
  "step-2-16k.description": "Supporta interazioni a contesto esteso per dialoghi complessi.",
  "step-2-mini.description": "Basato sulla nuova architettura MFA attention proprietaria, offre risultati simili a Step-1 a costi molto inferiori, con throughput più elevato e latenza ridotta. Gestisce compiti generali con forti capacità di programmazione.",
  "step-2x-large.description": "Modello di nuova generazione StepFun focalizzato sulla generazione di immagini, produce immagini di alta qualità da prompt testuali. Offre texture più realistiche e una resa testuale cinese/inglese più forte.",
  "step-3.description": "Questo modello ha una forte percezione visiva e capacità di ragionamento complesso, gestendo con precisione la comprensione della conoscenza cross-domain, l’analisi matematica-visiva e una vasta gamma di compiti visivi quotidiani.",
  "step-r1-v-mini.description": "Modello di ragionamento con forte comprensione delle immagini, in grado di elaborare immagini e testo e generare testo dopo un ragionamento profondo. Eccelle nel ragionamento visivo e offre prestazioni di alto livello in matematica, programmazione e ragionamento testuale, con una finestra di contesto da 100K.",
  "v0-1.5-lg.description": "v0-1.5-lg è adatto a compiti avanzati di pensiero e ragionamento.",
  "v0-1.5-md.description": "v0-1.5-md è adatto a compiti quotidiani e alla generazione di interfacce utente.",
  "vercel/v0-1.0-md.description": "Accedi ai modelli dietro v0 per generare, correggere e ottimizzare applicazioni web moderne con ragionamento specifico per framework e conoscenze aggiornate.",
  "vercel/v0-1.5-md.description": "Accedi ai modelli dietro v0 per generare, correggere e ottimizzare applicazioni web moderne con ragionamento specifico per framework e conoscenze aggiornate.",
  "volcengine/doubao-seed-code.description": "Doubao-Seed-Code è il modello LLM di Volcano Engine di ByteDance ottimizzato per la programmazione agentica, con prestazioni elevate nei benchmark di programmazione e agenti e supporto per contesti fino a 256K.",
  "wan2.2-t2i-flash.description": "Wanxiang 2.2 Speed è il modello più recente con miglioramenti in creatività, stabilità e realismo, offrendo generazione rapida e alto valore.",
  "wan2.2-t2i-plus.description": "Wanxiang 2.2 Pro è il modello più recente con miglioramenti in creatività, stabilità e realismo, producendo dettagli più ricchi.",
  "wanx-v1.description": "Modello base da testo a immagine. Corrisponde a Tongyi Wanxiang 1.0 General.",
  "wanx2.0-t2i-turbo.description": "Eccelle nei ritratti con texture, con velocità moderata e costi ridotti. Corrisponde a Tongyi Wanxiang 2.0 Speed.",
  "wanx2.1-t2i-plus.description": "Versione completamente aggiornata con immagini più dettagliate e velocità leggermente inferiore. Corrisponde a Tongyi Wanxiang 2.1 Pro.",
  "wanx2.1-t2i-turbo.description": "Versione completamente aggiornata con generazione rapida, qualità complessiva elevata e alto valore. Corrisponde a Tongyi Wanxiang 2.1 Speed.",
  "whisper-1.description": "Modello generale di riconoscimento vocale che supporta ASR multilingue, traduzione vocale e identificazione della lingua.",
  "wizardlm2.description": "WizardLM 2 è un modello linguistico di Microsoft AI che eccelle in dialoghi complessi, compiti multilingue, ragionamento e assistenza.",
  "wizardlm2:8x22b.description": "WizardLM 2 è un modello linguistico di Microsoft AI che eccelle in dialoghi complessi, compiti multilingue, ragionamento e assistenza.",
  "x-ai/grok-4-fast-non-reasoning.description": "Grok 4 Fast (Non-Reasoning) è il modello multimodale ad alta capacità e basso costo di xAI (supporta una finestra di contesto da 2M), ideale per scenari sensibili alla latenza e ai costi che non richiedono ragionamento interno. È affiancato dalla versione con ragionamento, attivabile tramite il parametro API reasoning. Prompt e completamenti possono essere utilizzati da xAI o OpenRouter per migliorare i modelli futuri.",
  "x-ai/grok-4-fast.description": "Grok 4 Fast è il modello ad alta capacità e basso costo di xAI (supporta una finestra di contesto da 2M), ideale per casi d'uso con alta concorrenza e contesti lunghi.",
  "x-ai/grok-4.1-fast-non-reasoning.description": "Grok 4 Fast (Non-Reasoning) è il modello multimodale ad alta capacità e basso costo di xAI (supporta una finestra di contesto da 2M), ideale per scenari sensibili alla latenza e ai costi che non richiedono ragionamento interno. È affiancato dalla versione con ragionamento, attivabile tramite il parametro API reasoning. Prompt e completamenti possono essere utilizzati da xAI o OpenRouter per migliorare i modelli futuri.",
  "x-ai/grok-4.1-fast.description": "Grok 4 Fast è il modello ad alta capacità e basso costo di xAI (supporta una finestra di contesto da 2M), ideale per casi d'uso con alta concorrenza e contesti lunghi.",
  "x-ai/grok-4.description": "Grok 4 è il modello di punta di xAI con forti capacità di ragionamento e multimodalità.",
  "x-ai/grok-code-fast-1.description": "Grok Code Fast 1 è il modello veloce di xAI per la programmazione, con output leggibile e adatto all'ingegneria.",
  "xai/grok-2-vision.description": "Grok 2 Vision eccelle nei compiti visivi, offrendo prestazioni all'avanguardia nel ragionamento matematico visivo (MathVista) e nella QA su documenti (DocVQA). Gestisce documenti, grafici, tabelle, screenshot e foto.",
  "xai/grok-2.description": "Grok 2 è un modello all'avanguardia con prestazioni eccellenti in ragionamento, chat, programmazione e classificato sopra Claude 3.5 Sonnet e GPT-4 Turbo su LMSYS.",
  "xai/grok-3-fast.description": "Il modello di punta di xAI eccelle in casi d'uso aziendali come estrazione dati, programmazione e sintesi, con profonda conoscenza nei settori finanza, sanità, diritto e scienza. La variante veloce utilizza un'infrastruttura più rapida per risposte molto più veloci a un costo per token più elevato.",
  "xai/grok-3-mini-fast.description": "Modello leggero di xAI che riflette prima di rispondere, ideale per compiti semplici o basati sulla logica senza conoscenze specialistiche. Sono disponibili tracce di ragionamento grezze. La variante veloce utilizza un'infrastruttura più rapida per risposte molto più veloci a un costo per token più elevato.",
  "xai/grok-3-mini.description": "Modello leggero di xAI che riflette prima di rispondere, ideale per compiti semplici o basati sulla logica senza conoscenze specialistiche. Sono disponibili tracce di ragionamento grezze.",
  "xai/grok-3.description": "Il modello di punta di xAI eccelle in casi d'uso aziendali come estrazione dati, programmazione e sintesi, con profonda conoscenza nei settori finanza, sanità, diritto e scienza.",
  "xai/grok-4.description": "Il nuovo modello di punta di xAI con prestazioni impareggiabili in linguaggio naturale, matematica e ragionamento: un tuttofare ideale.",
  "yi-large-fc.description": "Basato su yi-large con funzionalità avanzate di tool-calling, adatto a scenari con agenti e flussi di lavoro.",
  "yi-large-preview.description": "Versione preliminare; si consiglia l'uso di yi-large (più recente).",
  "yi-large-rag.description": "Servizio avanzato basato su yi-large, che combina recupero e generazione per risposte precise con ricerca web in tempo reale.",
  "yi-large-turbo.description": "Valore e prestazioni eccezionali, ottimizzato per un forte equilibrio tra qualità, velocità e costo.",
  "yi-large.description": "Un nuovo modello da 100 miliardi di parametri con forti capacità di Q&A e generazione di testo.",
  "yi-lightning-lite.description": "Versione leggera; si consiglia yi-lightning.",
  "yi-lightning.description": "Modello ad alte prestazioni di ultima generazione con inferenza rapida e output di alta qualità.",
  "yi-medium-200k.description": "Modello con contesto lungo da 200K per una comprensione e generazione approfondita di testi lunghi.",
  "yi-medium.description": "Modello di medie dimensioni ottimizzato per seguire istruzioni, con capacità e valore bilanciati.",
  "yi-spark.description": "Modello compatto e veloce con capacità potenziate in matematica e programmazione.",
  "yi-vision-v2.description": "Modello visivo per compiti complessi con forte comprensione e analisi multi-immagine.",
  "yi-vision.description": "Modello visivo per compiti complessi con forte comprensione e analisi delle immagini.",
  "z-ai/glm-4.5-air.description": "GLM 4.5 Air è una variante leggera di GLM 4.5 per scenari sensibili ai costi, mantenendo forti capacità di ragionamento.",
  "z-ai/glm-4.5.description": "GLM 4.5 è il modello di punta di Z.AI con ragionamento ibrido ottimizzato per compiti ingegneristici e contesti lunghi.",
  "z-ai/glm-4.6.description": "GLM 4.6 è il modello di punta di Z.AI con contesto esteso e capacità di programmazione.",
  "zai-org/GLM-4.5-Air.description": "GLM-4.5-Air è un modello base per applicazioni agentiche con architettura Mixture-of-Experts. Ottimizzato per l'uso di strumenti, navigazione web, ingegneria software e programmazione frontend, si integra con agenti di codice come Claude Code e Roo Code. Utilizza ragionamento ibrido per gestire sia scenari complessi che quotidiani.",
  "zai-org/GLM-4.5.description": "GLM-4.5 è un modello base progettato per applicazioni agentiche con architettura Mixture-of-Experts. Ottimizzato per l'uso di strumenti, navigazione web, ingegneria software e programmazione frontend, si integra con agenti di codice come Claude Code e Roo Code. Utilizza ragionamento ibrido per gestire sia scenari complessi che quotidiani.",
  "zai-org/GLM-4.5V.description": "GLM-4.5V è il più recente VLM di Zhipu AI, basato sul modello testuale di punta GLM-4.5-Air (106B totali, 12B attivi) con architettura MoE per prestazioni elevate a costi ridotti. Segue il percorso GLM-4.1V-Thinking e aggiunge 3D-RoPE per migliorare il ragionamento spaziale 3D. Ottimizzato tramite pretraining, SFT e RL, gestisce immagini, video e documenti lunghi, classificandosi tra i migliori modelli open source su 41 benchmark multimodali pubblici. Una modalità Thinking consente di bilanciare velocità e profondità.",
  "zai-org/GLM-4.6.description": "Rispetto a GLM-4.5, GLM-4.6 estende il contesto da 128K a 200K per compiti agentici più complessi. Ottiene punteggi più alti nei benchmark di codice e mostra prestazioni superiori in applicazioni reali come Claude Code, Cline, Roo Code e Kilo Code, inclusa una migliore generazione di pagine frontend. Il ragionamento è migliorato e l'uso di strumenti è supportato durante il ragionamento, rafforzando le capacità complessive. Si integra meglio nei framework agentici, migliora gli agenti di ricerca/strumenti e offre uno stile di scrittura più naturale e preferito dagli utenti.",
  "zai/glm-4.5-air.description": "GLM-4.5 e GLM-4.5-Air sono i nostri modelli di punta più recenti per applicazioni agentiche, entrambi con architettura MoE. GLM-4.5 ha 355B totali e 32B attivi per passaggio; GLM-4.5-Air è più snello con 106B totali e 12B attivi.",
  "zai/glm-4.5.description": "La serie GLM-4.5 è progettata per agenti. Il modello di punta GLM-4.5 combina ragionamento, programmazione e capacità agentiche con 355B parametri totali (32B attivi) e offre modalità operative doppie come sistema di ragionamento ibrido.",
  "zai/glm-4.5v.description": "GLM-4.5V si basa su GLM-4.5-Air, ereditando le tecniche collaudate di GLM-4.1V-Thinking e scalando con una potente architettura MoE da 106B parametri.",
  "zenmux/auto.description": "Il sistema di instradamento automatico ZenMux seleziona il modello con il miglior rapporto qualità/prezzo tra quelli supportati in base alla tua richiesta."
}
