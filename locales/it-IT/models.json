{
  "01-ai/yi-1.5-34b-chat.description": "Il più recente modello open-source di 01.AI, ottimizzato con 34 miliardi di parametri. Supporta molteplici scenari di dialogo, è addestrato su dati di alta qualità e allineato alle preferenze umane.",
  "01-ai/yi-1.5-9b-chat.description": "Il più recente modello open-source di 01.AI, ottimizzato con 9 miliardi di parametri. Supporta molteplici scenari di dialogo, è addestrato su dati di alta qualità e allineato alle preferenze umane.",
  "360/deepseek-r1.description": "DeepSeek-R1 distribuito su 360 utilizza l'apprendimento per rinforzo su larga scala nella fase di post-addestramento per migliorare notevolmente il ragionamento con un numero minimo di etichette. Raggiunge le prestazioni del modello OpenAI o1 nei compiti di matematica, programmazione e ragionamento in linguaggio naturale.",
  "360gpt-pro-trans.description": "Modello specializzato nella traduzione, ottimizzato in profondità per offrire una qualità di traduzione di livello superiore.",
  "360gpt-pro.description": "360GPT Pro è un modello chiave di 360 AI per l'elaborazione efficiente del testo in scenari NLP diversificati, con supporto per la comprensione di testi lunghi e dialoghi multi-turno.",
  "360gpt-turbo-responsibility-8k.description": "360GPT Turbo Responsibility 8K pone l'accento sulla sicurezza semantica e la responsabilità nei contesti sensibili, garantendo esperienze utente accurate e affidabili.",
  "360gpt-turbo.description": "360GPT Turbo offre elevate capacità di calcolo e conversazione, con eccellente comprensione semantica ed efficienza generativa, ideale per aziende e sviluppatori.",
  "360gpt2-o1.description": "360gpt2-o1 costruisce catene di pensiero tramite ricerca ad albero con meccanismo di riflessione e addestramento con RL, abilitando auto-riflessione e auto-correzione.",
  "360gpt2-pro.description": "360GPT2 Pro è un modello NLP avanzato di 360 con eccellenti capacità di generazione e comprensione del testo, particolarmente adatto a compiti creativi, trasformazioni complesse e simulazioni di ruolo.",
  "360zhinao2-o1.description": "360zhinao2-o1 costruisce catene di pensiero tramite ricerca ad albero con meccanismo di riflessione e addestramento con RL, abilitando auto-riflessione e auto-correzione.",
  "4.0Ultra.description": "Spark Ultra è il modello più potente della serie Spark, migliora la comprensione e il riassunto del testo e potenzia la ricerca web. È una soluzione completa per aumentare la produttività sul lavoro e fornire risposte accurate, posizionandosi come prodotto intelligente leader.",
  "AnimeSharp.description": "AnimeSharp (noto anche come \"4x-AnimeSharp\") è un modello open-source di super-risoluzione basato su ESRGAN di Kim2091, focalizzato sull'ingrandimento e la nitidezza delle immagini in stile anime. È stato rinominato da \"4x-TextSharpV1\" nel febbraio 2022, originariamente pensato anche per immagini testuali ma fortemente ottimizzato per contenuti anime.",
  "Baichuan2-Turbo.description": "Utilizza l'augmentazione tramite ricerca per collegare il modello alla conoscenza di dominio e del web. Supporta caricamenti PDF/Word e input tramite URL per un recupero tempestivo e completo, con output professionali e accurati.",
  "Baichuan3-Turbo-128k.description": "Con una finestra di contesto ultra-lunga da 128K, è ottimizzato per scenari aziendali ad alta frequenza, con miglioramenti significativi. Rispetto a Baichuan2, la creazione di contenuti migliora del 20%, le risposte a domande di conoscenza del 17% e le simulazioni di ruolo del 40%. Le prestazioni complessive superano GPT-3.5.",
  "Baichuan3-Turbo.description": "Ottimizzato per scenari aziendali ad alta frequenza, con miglioramenti significativi. Rispetto a Baichuan2, la creazione di contenuti migliora del 20%, le risposte a domande di conoscenza del 17% e le simulazioni di ruolo del 40%. Le prestazioni complessive superano GPT-3.5.",
  "Baichuan4-Air.description": "Modello di punta in Cina, supera i principali modelli esteri nei compiti in lingua cinese come conoscenza, testi lunghi e generazione creativa. Presenta anche capacità multimodali all'avanguardia con risultati eccellenti nei benchmark autorevoli.",
  "Baichuan4-Turbo.description": "Modello di punta in Cina, supera i principali modelli esteri nei compiti in lingua cinese come conoscenza, testi lunghi e generazione creativa. Presenta anche capacità multimodali all'avanguardia con risultati eccellenti nei benchmark autorevoli.",
  "Baichuan4.description": "Prestazioni nazionali al top, superiori ai principali modelli esteri nei compiti in lingua cinese come conoscenza enciclopedica, testi lunghi e generazione creativa. Offre anche capacità multimodali all'avanguardia e risultati eccellenti nei benchmark.",
  "ByteDance-Seed/Seed-OSS-36B-Instruct.description": "Seed-OSS è una famiglia di LLM open-source di ByteDance Seed, progettata per una gestione efficace di contesti lunghi, ragionamento, agenti e capacità generali. Seed-OSS-36B-Instruct è un modello da 36B ottimizzato per istruzioni, con contesto ultra-lungo nativo per elaborare documenti o basi di codice estesi. Ottimizzato per ragionamento, generazione di codice e compiti agentici (uso di strumenti), mantiene forti capacità generali. Una caratteristica chiave è il \"Thinking Budget\", che consente una lunghezza di ragionamento flessibile per migliorare l'efficienza.",
  "DeepSeek-R1-Distill-Llama-70B.description": "DeepSeek R1, il modello più grande e intelligente della suite DeepSeek, è stato distillato nell'architettura Llama 70B. I benchmark e le valutazioni umane dimostrano che è più intelligente del Llama 70B base, in particolare nei compiti di matematica e precisione dei fatti.",
  "DeepSeek-R1-Distill-Qwen-1.5B.description": "Un modello distillato DeepSeek-R1 basato su Qwen2.5-Math-1.5B. L'apprendimento per rinforzo e i dati di avvio a freddo ottimizzano le prestazioni di ragionamento, stabilendo nuovi benchmark multi-task per i modelli open-source.",
  "DeepSeek-R1-Distill-Qwen-14B.description": "I modelli DeepSeek-R1-Distill sono ottimizzati a partire da modelli open-source utilizzando dati campione generati da DeepSeek-R1.",
  "DeepSeek-R1-Distill-Qwen-32B.description": "I modelli DeepSeek-R1-Distill sono ottimizzati a partire da modelli open-source utilizzando dati campione generati da DeepSeek-R1.",
  "DeepSeek-R1-Distill-Qwen-7B.description": "Un modello distillato DeepSeek-R1 basato su Qwen2.5-Math-7B. L'apprendimento per rinforzo e i dati di avvio a freddo ottimizzano le prestazioni di ragionamento, stabilendo nuovi benchmark multi-task per i modelli open-source.",
  "DeepSeek-R1.description": "DeepSeek-R1 applica l'apprendimento per rinforzo su larga scala nella fase di post-addestramento, migliorando notevolmente il ragionamento con pochissimi dati etichettati. Raggiunge le prestazioni del modello OpenAI o1 nei compiti di matematica, programmazione e ragionamento in linguaggio naturale.",
  "DeepSeek-V3-1.description": "DeepSeek V3.1 è un modello di ragionamento di nuova generazione con miglioramenti nel ragionamento complesso e nella catena di pensiero, adatto ad attività di analisi approfondita.",
  "DeepSeek-V3-Fast.description": "Fornitore: sophnet. DeepSeek V3 Fast è la versione ad alta velocità di DeepSeek V3 0324, a precisione completa (non quantizzata), con prestazioni superiori in programmazione e matematica e risposte più rapide.",
  "DeepSeek-V3.1-Fast.description": "DeepSeek V3.1 Fast è la variante veloce ad alta velocità di DeepSeek V3.1. Modalità di pensiero ibrida: tramite template di chat, un solo modello supporta modalità con e senza pensiero. Uso più intelligente degli strumenti: il post-addestramento migliora le prestazioni nei compiti agentici e nell'uso degli strumenti.",
  "DeepSeek-V3.1-Think.description": "Modalità di pensiero DeepSeek-V3.1: un nuovo modello di ragionamento ibrido con modalità di pensiero e non-pensiero, più efficiente di DeepSeek-R1-0528. Le ottimizzazioni post-addestramento migliorano significativamente l'uso degli strumenti agentici e le prestazioni nei compiti agentici.",
  "DeepSeek-V3.description": "DeepSeek-V3 è un modello MoE sviluppato da DeepSeek. Supera altri modelli open-source come Qwen2.5-72B e Llama-3.1-405B in molti benchmark ed è competitivo con i principali modelli chiusi come GPT-4o e Claude 3.5 Sonnet.",
  "Doubao-lite-128k.description": "Doubao-lite offre risposte ultra-rapide e un ottimo rapporto qualità/prezzo, con opzioni flessibili per diversi scenari. Supporta un contesto di 128K per inferenza e fine-tuning.",
  "Doubao-lite-32k.description": "Doubao-lite offre risposte ultra-rapide e un ottimo rapporto qualità/prezzo, con opzioni flessibili per diversi scenari. Supporta un contesto di 32K per inferenza e fine-tuning.",
  "Doubao-lite-4k.description": "Doubao-lite offre risposte ultra-rapide e un ottimo rapporto qualità/prezzo, con opzioni flessibili per diversi scenari. Supporta un contesto di 4K per inferenza e fine-tuning.",
  "Doubao-pro-128k.description": "Modello di punta con le migliori prestazioni per compiti complessi, eccellente in QA con fonti, riassunti, creazione, classificazione e simulazioni di ruolo. Supporta un contesto di 128K per inferenza e fine-tuning.",
  "Doubao-pro-32k.description": "Modello di punta con le migliori prestazioni per compiti complessi, eccellente in QA con fonti, riassunti, creazione, classificazione e simulazioni di ruolo. Supporta un contesto di 32K per inferenza e fine-tuning.",
  "Doubao-pro-4k.description": "Modello di punta con le migliori prestazioni per compiti complessi, eccellente in QA con fonti, riassunti, creazione, classificazione e simulazioni di ruolo. Supporta un contesto di 4K per inferenza e fine-tuning.",
  "DreamO.description": "DreamO è un modello open-source per la personalizzazione delle immagini sviluppato congiuntamente da ByteDance e l'Università di Pechino, che utilizza un'architettura unificata per supportare la generazione di immagini multi-task. Impiega una modellazione compositiva efficiente per generare immagini altamente coerenti e personalizzate in base a identità, soggetto, stile, sfondo e altre condizioni specificate dall'utente.",
  "ERNIE-3.5-128K.description": "Modello LLM di punta di Baidu, addestrato su vasti corpora in cinese e inglese, con eccellenti capacità generali per chat, creazione e utilizzo di plugin; supporta l'integrazione automatica del plugin Baidu Search per risposte aggiornate.",
  "ERNIE-3.5-8K-Preview.description": "Modello LLM di punta di Baidu, addestrato su vasti corpora in cinese e inglese, con eccellenti capacità generali per chat, creazione e utilizzo di plugin; supporta l'integrazione automatica del plugin Baidu Search per risposte aggiornate.",
  "ERNIE-3.5-8K.description": "Modello LLM di punta di Baidu, addestrato su vasti corpora in cinese e inglese, con eccellenti capacità generali per chat, creazione e utilizzo di plugin; supporta l'integrazione automatica del plugin Baidu Search per risposte aggiornate.",
  "ERNIE-4.0-8K-Latest.description": "Modello LLM ultra-avanzato di Baidu con aggiornamenti completi rispetto a ERNIE 3.5, adatto a compiti complessi in diversi ambiti; supporta l'integrazione del plugin Baidu Search per risposte aggiornate.",
  "ERNIE-4.0-8K-Preview.description": "Modello LLM ultra-avanzato di Baidu con aggiornamenti completi rispetto a ERNIE 3.5, adatto a compiti complessi in diversi ambiti; supporta l'integrazione del plugin Baidu Search per risposte aggiornate.",
  "ERNIE-4.0-Turbo-8K-Latest.description": "Modello LLM ultra-avanzato di Baidu con prestazioni generali elevate per compiti complessi, con integrazione del plugin Baidu Search per risposte aggiornate. Supera le prestazioni di ERNIE 4.0.",
  "ERNIE-4.0-Turbo-8K-Preview.description": "Modello LLM ultra-avanzato di Baidu con prestazioni generali elevate per compiti complessi, con integrazione del plugin Baidu Search per risposte aggiornate. Supera le prestazioni di ERNIE 4.0.",
  "ERNIE-Character-8K.description": "Modello LLM di Baidu per domini verticali come NPC nei giochi, assistenza clienti e roleplay, con maggiore coerenza del personaggio, migliore comprensione delle istruzioni e capacità di ragionamento potenziate.",
  "ERNIE-Lite-Pro-128K.description": "Modello LLM leggero di Baidu che bilancia qualità e prestazioni di inferenza, superiore a ERNIE Lite e adatto ad acceleratori a bassa potenza.",
  "ERNIE-Speed-128K.description": "Ultimo modello LLM ad alte prestazioni di Baidu (2024) con forti capacità generali, ideale come base per il fine-tuning in scenari specifici, con eccellenti prestazioni di ragionamento.",
  "ERNIE-Speed-Pro-128K.description": "Ultimo modello LLM ad alte prestazioni di Baidu (2024) con forti capacità generali, superiore a ERNIE Speed, ideale come base per il fine-tuning con eccellenti prestazioni di ragionamento.",
  "FLUX-1.1-pro.description": "FLUX.1.1 Pro",
  "FLUX.1-Kontext-dev.description": "FLUX.1-Kontext-dev è un modello multimodale per generazione ed editing di immagini sviluppato da Black Forest Labs, basato su un'architettura Rectified Flow Transformer con 12 miliardi di parametri. Si concentra sulla generazione, ricostruzione, miglioramento o modifica di immagini in base a condizioni contestuali. Combina la generazione controllabile dei modelli di diffusione con la modellazione contestuale dei Transformer, supportando output di alta qualità per compiti come inpainting, outpainting e ricostruzione di scene visive.",
  "FLUX.1-Kontext-pro.description": "FLUX.1 Kontext [pro]",
  "FLUX.1-dev.description": "FLUX.1-dev è un modello linguistico multimodale open-source (MLLM) di Black Forest Labs, ottimizzato per compiti immagine-testo e in grado di comprendere e generare contenuti visivi e testuali. Basato su LLM avanzati (come Mistral-7B), utilizza un encoder visivo progettato con cura e un tuning a più stadi per abilitare il coordinamento multimodale e il ragionamento su compiti complessi.",
  "Gryphe/MythoMax-L2-13b.description": "MythoMax-L2 (13B) è un modello innovativo per domini diversificati e compiti complessi.",
  "HelloMeme.description": "HelloMeme è uno strumento AI che genera meme, GIF o brevi video a partire da immagini o movimenti forniti. Non richiede abilità di disegno o programmazione: basta un'immagine di riferimento per creare contenuti divertenti, accattivanti e stilisticamente coerenti.",
  "HiDream-I1-Full.description": "HiDream-E1-Full è un modello open-source per l'editing multimodale di immagini sviluppato da HiDream.ai, basato su un'architettura Diffusion Transformer avanzata e una solida comprensione linguistica (con LLaMA 3.1-8B-Instruct integrato). Supporta generazione di immagini guidata da linguaggio naturale, trasferimento di stile, modifiche locali e ritinteggiatura, con eccellente comprensione ed esecuzione immagine-testo.",
  "HunyuanDiT-v1.2-Diffusers-Distilled.description": "hunyuandit-v1.2-distilled è un modello leggero text-to-image ottimizzato tramite distillazione per generare immagini di alta qualità in modo rapido, particolarmente adatto ad ambienti con risorse limitate e generazione in tempo reale.",
  "InstantCharacter.description": "InstantCharacter è un modello di generazione di personaggi personalizzati senza tuning, rilasciato da Tencent AI nel 2025, progettato per una generazione fedele e coerente di personaggi in diversi scenari. Può modellare un personaggio da una singola immagine di riferimento e trasferirlo con flessibilità tra stili, azioni e sfondi.",
  "InternVL2-8B.description": "InternVL2-8B è un potente modello visione-linguaggio che supporta l'elaborazione multimodale immagine-testo, riconoscendo accuratamente i contenuti visivi e generando descrizioni o risposte pertinenti.",
  "InternVL2.5-26B.description": "InternVL2.5-26B è un potente modello visione-linguaggio che supporta l'elaborazione multimodale immagine-testo, riconoscendo accuratamente i contenuti visivi e generando descrizioni o risposte pertinenti.",
  "Kolors.description": "Kolors è un modello text-to-image sviluppato dal team Kuaishou Kolors. Addestrato con miliardi di parametri, offre vantaggi notevoli in qualità visiva, comprensione semantica del cinese e resa del testo.",
  "Kwai-Kolors/Kolors.description": "Kolors è un modello text-to-image a diffusione latente su larga scala sviluppato dal team Kuaishou Kolors. Addestrato su miliardi di coppie testo-immagine, eccelle in qualità visiva, accuratezza semantica complessa e resa del testo in cinese/inglese, con forte comprensione e generazione di contenuti in cinese.",
  "Kwaipilot/KAT-Dev.description": "KAT-Dev (32B) è un modello open-source da 32 miliardi di parametri per compiti di ingegneria del software. Raggiunge un tasso di risoluzione del 62,4% su SWE-Bench Verified, classificandosi al 5° posto tra i modelli open. È ottimizzato tramite mid-training, SFT e RL per completamento del codice, correzione di bug e revisione del codice.",
  "Llama-3.2-11B-Vision-Instruct.description": "Solido ragionamento visivo su immagini ad alta risoluzione, adatto ad applicazioni di comprensione visiva.",
  "Llama-3.2-90B-Vision-Instruct\t.description": "Ragionamento visivo avanzato per applicazioni di agenti con comprensione visiva.",
  "Meta-Llama-3-3-70B-Instruct.description": "Llama 3.3 70B è un modello Transformer versatile per compiti di chat e generazione.",
  "Meta-Llama-3.1-405B-Instruct.description": "Modello testuale Llama 3.1 ottimizzato per chat multilingue, con prestazioni elevate nei benchmark industriali tra modelli open e closed.",
  "Meta-Llama-3.1-70B-Instruct.description": "Modello testuale Llama 3.1 ottimizzato per chat multilingue, con prestazioni elevate nei benchmark industriali tra modelli open e closed.",
  "Meta-Llama-3.1-8B-Instruct.description": "Modello testuale Llama 3.1 ottimizzato per chat multilingue, con prestazioni elevate nei benchmark industriali tra modelli open e closed.",
  "Meta-Llama-3.2-1B-Instruct.description": "Modello linguistico compatto all'avanguardia con forte comprensione del linguaggio, eccellente ragionamento e generazione testuale.",
  "Meta-Llama-3.2-3B-Instruct.description": "Modello linguistico compatto all'avanguardia con forte comprensione del linguaggio, eccellente ragionamento e generazione testuale.",
  "Meta-Llama-3.3-70B-Instruct.description": "Llama 3.3 è il modello Llama open-source multilingue più avanzato, con prestazioni vicine a quelle del 405B a costi molto contenuti. Basato su Transformer, è migliorato con SFT e RLHF per utilità e sicurezza. La versione instruction-tuned è ottimizzata per chat multilingue e supera molti modelli open e closed nei benchmark industriali. Data di cutoff: dicembre 2023.",
  "Meta-Llama-4-Maverick-17B-128E-Instruct-FP8.description": "Llama 4 Maverick è un grande modello MoE con attivazione efficiente degli esperti per prestazioni di ragionamento elevate.",
  "MiniMax-M1.description": "Nuovo modello di ragionamento proprietario con 80K chain-of-thought e 1M di input, con prestazioni comparabili ai migliori modelli globali.",
  "MiniMax-M2-Stable.description": "Progettato per flussi di lavoro di codifica e agenti efficienti, con maggiore concorrenza per l'uso commerciale.",
  "MiniMax-M2.1-Lightning.description": "Potenti capacità di programmazione multilingue e un'esperienza di sviluppo completamente rinnovata. Più veloce ed efficiente.",
  "MiniMax-M2.1.description": "Potenti capacità di programmazione multilingue e un'esperienza di sviluppo completamente rinnovata",
  "MiniMax-M2.description": "Progettato specificamente per una programmazione efficiente e flussi di lavoro con agenti",
  "MiniMax-Text-01.description": "MiniMax-01 introduce l'attenzione lineare su larga scala oltre i Transformer classici, con 456B parametri e 45,9B attivati per passaggio. Raggiunge prestazioni di alto livello e supporta fino a 4M token di contesto (32× GPT-4o, 20× Claude-3.5-Sonnet).",
  "MiniMaxAI/MiniMax-M1-80k.description": "MiniMax-M1 è un modello di ragionamento ibrido su larga scala con pesi open, 456B parametri totali e ~45,9B attivi per token. Supporta nativamente 1M di contesto e utilizza Flash Attention per ridurre i FLOPs del 75% nella generazione di 100K token rispetto a DeepSeek R1. Con architettura MoE, CISPO e addestramento RL ibrido, raggiunge prestazioni leader su ragionamento con input lunghi e compiti reali di ingegneria del software.",
  "MiniMaxAI/MiniMax-M2.description": "MiniMax-M2 ridefinisce l'efficienza degli agenti. È un modello MoE compatto, veloce ed economico con 230B parametri totali e 10B attivi, progettato per compiti di codifica e agenti di alto livello mantenendo una forte intelligenza generale. Con soli 10B parametri attivi, rivaleggia con modelli molto più grandi, rendendolo ideale per applicazioni ad alta efficienza.",
  "Moonshot-Kimi-K2-Instruct.description": "1T parametri totali con 32B attivi. Tra i modelli non pensanti, è tra i migliori per conoscenze avanzate, matematica e programmazione, ed è più forte nei compiti generali da agente. Ottimizzato per carichi di lavoro da agente, può eseguire azioni, non solo rispondere a domande. Ideale per conversazioni improvvisate, chat generali e esperienze da agente, come modello reattivo senza riflessione prolungata.",
  "NousResearch/Nous-Hermes-2-Mixtral-8x7B-DPO.description": "Nous Hermes 2 - Mixtral 8x7B-DPO (46,7B) è un modello ad alta precisione per istruzioni complesse e calcoli avanzati.",
  "OmniConsistency.description": "OmniConsistency migliora la coerenza stilistica e la generalizzazione nei compiti immagine-a-immagine introducendo Diffusion Transformers (DiTs) su larga scala e dati stilizzati accoppiati, evitando il degrado dello stile.",
  "Phi-3-medium-128k-instruct.description": "Lo stesso modello Phi-3-medium con una finestra contestuale più ampia per prompt RAG o few-shot.",
  "Phi-3-medium-4k-instruct.description": "Un modello da 14B parametri con qualità superiore rispetto a Phi-3-mini, focalizzato su dati di alta qualità e ad alta intensità di ragionamento.",
  "Phi-3-mini-128k-instruct.description": "Lo stesso modello Phi-3-mini con una finestra contestuale più ampia per prompt RAG o few-shot.",
  "Phi-3-mini-4k-instruct.description": "Il membro più piccolo della famiglia Phi-3, ottimizzato per qualità e bassa latenza.",
  "Phi-3-small-128k-instruct.description": "Lo stesso modello Phi-3-small con una finestra contestuale più ampia per prompt RAG o few-shot.",
  "Phi-3-small-8k-instruct.description": "Un modello da 7B parametri con qualità superiore rispetto a Phi-3-mini, focalizzato su dati di alta qualità e ad alta intensità di ragionamento.",
  "Phi-3.5-mini-instruct.description": "Una versione aggiornata del modello Phi-3-mini.",
  "Phi-3.5-vision-instrust.description": "Una versione aggiornata del modello Phi-3-vision.",
  "Pro/Qwen/Qwen2-7B-Instruct.description": "Qwen2-7B-Instruct è un LLM da 7B parametri ottimizzato per istruzioni nella serie Qwen2. Utilizza un'architettura Transformer con SwiGLU, bias QKV per l'attenzione e grouped-query attention, ed è in grado di gestire input di grandi dimensioni. Eccelle in comprensione linguistica, generazione, compiti multilingue, programmazione, matematica e ragionamento, superando la maggior parte dei modelli open-source e competendo con quelli proprietari. Supera Qwen1.5-7B-Chat in diversi benchmark.",
  "Pro/Qwen/Qwen2.5-7B-Instruct.description": "Qwen2.5-7B-Instruct fa parte della nuova serie LLM di Alibaba Cloud. Il modello da 7B offre miglioramenti significativi in programmazione e matematica, supporta oltre 29 lingue e migliora il rispetto delle istruzioni, la comprensione dei dati strutturati e la generazione di output strutturati (in particolare JSON).",
  "Pro/Qwen/Qwen2.5-Coder-7B-Instruct.description": "Qwen2.5-Coder-7B-Instruct è l'ultimo LLM di Alibaba Cloud focalizzato sul codice. Basato su Qwen2.5 e addestrato su 5,5T token, migliora notevolmente la generazione, il ragionamento e la correzione del codice, mantenendo al contempo le capacità matematiche e generali, fornendo una solida base per agenti di programmazione.",
  "Pro/Qwen/Qwen2.5-VL-7B-Instruct.description": "Qwen2.5-VL è un nuovo modello visione-linguaggio della serie Qwen con forte comprensione visiva. Analizza testo, grafici e layout nelle immagini, comprende video lunghi ed eventi, supporta il ragionamento e l'uso di strumenti, l'ancoraggio multi-formato degli oggetti e output strutturati. Migliora la risoluzione dinamica e l'addestramento a frame-rate per la comprensione video e aumenta l'efficienza dell'encoder visivo.",
  "Pro/THUDM/GLM-4.1V-9B-Thinking.description": "GLM-4.1V-9B-Thinking è un modello VLM open-source sviluppato da Zhipu AI e dal laboratorio KEG della Tsinghua, progettato per la cognizione multimodale complessa. Basato su GLM-4-9B-0414, aggiunge ragionamento a catena e apprendimento per rinforzo (RL) per migliorare significativamente il ragionamento cross-modale e la stabilità.",
  "Pro/THUDM/glm-4-9b-chat.description": "GLM-4-9B-Chat è il modello open-source GLM-4 di Zhipu AI. Eccelle in semantica, matematica, ragionamento, codice e conoscenza. Oltre alla chat multi-turno, supporta la navigazione web, l'esecuzione di codice, chiamate a strumenti personalizzati e ragionamento su testi lunghi. Supporta 26 lingue (tra cui cinese, inglese, giapponese, coreano, tedesco). Ottiene buoni risultati su AlignBench-v2, MT-Bench, MMLU e C-Eval, e supporta fino a 128K di contesto per usi accademici e aziendali.",
  "Pro/deepseek-ai/DeepSeek-R1-Distill-Qwen-7B.description": "DeepSeek-R1-Distill-Qwen-7B è distillato da Qwen2.5-Math-7B e ottimizzato su 800K campioni curati DeepSeek-R1. Ottiene ottimi risultati: 92,8% su MATH-500, 55,5% su AIME 2024 e un punteggio CodeForces di 1189 per un modello da 7B.",
  "Pro/deepseek-ai/DeepSeek-R1.description": "DeepSeek-R1 è un modello di ragionamento guidato da RL che riduce la ripetizione e migliora la leggibilità. Utilizza dati cold-start prima del RL per potenziare ulteriormente il ragionamento, eguaglia OpenAI-o1 in compiti di matematica, codice e ragionamento, migliorando i risultati complessivi grazie a un addestramento accurato.",
  "Pro/deepseek-ai/DeepSeek-V3.1-Terminus.description": "DeepSeek-V3.1-Terminus è una versione aggiornata del modello V3.1, posizionato come LLM ibrido per agenti. Risolve problemi segnalati dagli utenti e migliora la stabilità, la coerenza linguistica e riduce caratteri anomali e misti cinese/inglese. Integra modalità di pensiero e non-pensiero con template di chat per passaggi flessibili. Migliora anche le prestazioni di Code Agent e Search Agent per un uso più affidabile degli strumenti e compiti multi-step.",
  "Pro/deepseek-ai/DeepSeek-V3.2-Exp.description": "DeepSeek-V3.2-Exp è una versione sperimentale della serie V3.2 che fa da ponte verso la prossima architettura. Aggiunge DeepSeek Sparse Attention (DSA) sopra V3.1-Terminus per migliorare l'efficienza nell'addestramento e inferenza su contesti lunghi, con ottimizzazioni per l'uso di strumenti, comprensione di documenti lunghi e ragionamento multi-step. Ideale per esplorare una maggiore efficienza di ragionamento con budget di contesto elevati.",
  "Pro/deepseek-ai/DeepSeek-V3.description": "DeepSeek-V3 è un modello MoE da 671B parametri che utilizza MLA e DeepSeekMoE con bilanciamento del carico senza perdite per un'inferenza e addestramento efficienti. Preaddestrato su 14,8T token di alta qualità e ulteriormente ottimizzato con SFT e RL, supera altri modelli open-source e si avvicina ai modelli chiusi leader.",
  "Pro/moonshotai/Kimi-K2-Instruct-0905.description": "Kimi K2-Instruct-0905 è la versione più recente e potente di Kimi K2. È un modello MoE di fascia alta con 1T di parametri totali e 32B attivi. Le caratteristiche principali includono un'intelligenza di codifica agentica più forte con miglioramenti significativi nei benchmark e nei compiti reali da agente, oltre a una migliore estetica e usabilità del codice frontend.",
  "Pro/moonshotai/Kimi-K2-Thinking.description": "Kimi K2 Thinking Turbo è la variante Turbo ottimizzata per velocità di ragionamento e throughput, mantenendo il ragionamento multi-step e l'uso di strumenti di K2 Thinking. È un modello MoE con ~1T parametri totali, contesto nativo da 256K e chiamata stabile di strumenti su larga scala per scenari di produzione con requisiti più severi di latenza e concorrenza.",
  "Pro/zai-org/glm-4.7.description": "GLM-4.7 è il modello di punta di nuova generazione di Zhipu, con 355 miliardi di parametri totali e 32 miliardi di parametri attivi, completamente aggiornato nelle capacità di dialogo generale, ragionamento e agenti. GLM-4.7 migliora il Pensiero Intercalato e introduce il Pensiero Conservato e il Pensiero a Livello di Turno.",
  "QwQ-32B-Preview.description": "Qwen QwQ è un modello di ricerca sperimentale focalizzato sul miglioramento del ragionamento.",
  "Qwen/QVQ-72B-Preview.description": "QVQ-72B-Preview è un modello di ricerca del team Qwen focalizzato sul ragionamento visivo, con punti di forza nella comprensione di scene complesse e nella risoluzione di problemi visivi di matematica.",
  "Qwen/QwQ-32B-Preview.description": "Qwen QwQ è un modello di ricerca sperimentale focalizzato sul miglioramento del ragionamento dell'IA.",
  "Qwen/QwQ-32B.description": "QwQ è un modello di ragionamento della famiglia Qwen. Rispetto ai modelli standard ottimizzati per seguire istruzioni, integra capacità di pensiero e ragionamento che migliorano significativamente le prestazioni nei compiti complessi. QwQ-32B è un modello di medie dimensioni competitivo con i migliori modelli di ragionamento come DeepSeek-R1 e o1-mini. Utilizza RoPE, SwiGLU, RMSNorm e bias QKV nell'attenzione, con 64 layer e 40 teste di attenzione Q (8 KV in GQA).",
  "Qwen/Qwen-Image-Edit-2509.description": "Qwen-Image-Edit-2509 è l'ultima versione di editing dell'immagine sviluppata dal team Qwen. Basato sul modello Qwen-Image da 20B, estende le potenti capacità di rendering del testo all'editing delle immagini per modifiche testuali precise. Utilizza un'architettura a doppio controllo, inviando gli input a Qwen2.5-VL per il controllo semantico e a un encoder VAE per il controllo dell'aspetto, consentendo modifiche sia semantiche che visive. Supporta modifiche locali (aggiunta/rimozione/modifica) e modifiche semantiche di alto livello come la creazione di IP e il trasferimento di stile, preservando il significato originale. Ottiene risultati SOTA in numerosi benchmark.",
  "Qwen/Qwen-Image.description": "Qwen-Image è un modello di base per la generazione di immagini con 20 miliardi di parametri, sviluppato dal team Qwen. Offre miglioramenti significativi nel rendering di testo complesso e nell'editing preciso delle immagini, in particolare per testi in cinese e inglese ad alta fedeltà. Supporta layout multilinea e paragrafi mantenendo la coerenza tipografica. Oltre al rendering testuale, supporta una vasta gamma di stili, dal fotorealistico all'anime, e funzionalità avanzate come trasferimento di stile, aggiunta/rimozione di oggetti, miglioramento dei dettagli, modifica del testo e controllo della posa, con l'obiettivo di essere una base completa per la creazione visiva.",
  "Qwen/Qwen2-72B-Instruct.description": "Qwen 2 Instruct (72B) offre un'esecuzione precisa delle istruzioni per carichi di lavoro aziendali.",
  "Qwen/Qwen2-7B-Instruct.description": "Qwen2-7B-Instruct è un modello da 7B ottimizzato per seguire istruzioni nella serie Qwen2, basato su Transformer, SwiGLU, bias QKV e attenzione a query raggruppate. Gestisce input di grandi dimensioni e si comporta molto bene in benchmark di comprensione, generazione, multilingua, programmazione, matematica e ragionamento, superando la maggior parte dei modelli open source e Qwen1.5-7B-Chat in diverse valutazioni.",
  "Qwen/Qwen2-VL-72B-Instruct.description": "Qwen2-VL è l'ultima versione del modello Qwen-VL, che raggiunge risultati SOTA in benchmark visivi come MathVista, DocVQA, RealWorldQA e MTVQA. È in grado di comprendere video di oltre 20 minuti per domande su video, dialoghi e creazione di contenuti. Supporta anche ragionamento complesso e decisioni, integrandosi con dispositivi/robot per azioni guidate dalla visione. Oltre all'inglese e al cinese, può leggere testi in molte lingue, tra cui la maggior parte delle lingue europee, giapponese, coreano, arabo e vietnamita.",
  "Qwen/Qwen2.5-14B-Instruct.description": "Qwen2.5-14B-Instruct fa parte della nuova serie LLM di Alibaba Cloud. Il modello da 14B offre miglioramenti significativi nella programmazione e nella matematica, supporta oltre 29 lingue e migliora l'esecuzione delle istruzioni, la comprensione dei dati strutturati e la generazione di output strutturati (in particolare JSON).",
  "Qwen/Qwen2.5-32B-Instruct.description": "Qwen2.5-32B-Instruct fa parte della nuova serie LLM di Alibaba Cloud. Il modello da 32B offre miglioramenti significativi nella programmazione e nella matematica, supporta oltre 29 lingue e migliora l'esecuzione delle istruzioni, la comprensione dei dati strutturati e la generazione di output strutturati (in particolare JSON).",
  "Qwen/Qwen2.5-72B-Instruct-128K.description": "Qwen2.5-72B-Instruct fa parte della nuova serie LLM di Alibaba Cloud. Il modello da 72B migliora la programmazione e la matematica, supporta fino a 128K di input e oltre 8K di output, offre supporto per oltre 29 lingue e migliora l'esecuzione delle istruzioni e la generazione di output strutturati (in particolare JSON).",
  "Qwen/Qwen2.5-72B-Instruct-Turbo.description": "Qwen2.5 è una nuova famiglia di LLM ottimizzata per compiti basati su istruzioni.",
  "Qwen/Qwen2.5-72B-Instruct.description": "Qwen2.5-72B-Instruct fa parte della nuova serie LLM di Alibaba Cloud. Il modello da 72B offre miglioramenti significativi nella programmazione e nella matematica, supporta oltre 29 lingue e migliora l'esecuzione delle istruzioni, la comprensione dei dati strutturati e la generazione di output strutturati (in particolare JSON).",
  "Qwen/Qwen2.5-7B-Instruct-Turbo.description": "Qwen2.5 è una nuova famiglia di LLM ottimizzata per compiti basati su istruzioni.",
  "Qwen/Qwen2.5-7B-Instruct.description": "Qwen2.5-7B-Instruct fa parte della nuova serie LLM di Alibaba Cloud. Il modello da 7B offre miglioramenti significativi nella programmazione e nella matematica, supporta oltre 29 lingue e migliora l'esecuzione delle istruzioni, la comprensione dei dati strutturati e la generazione di output strutturati (in particolare JSON).",
  "Qwen/Qwen2.5-Coder-32B-Instruct.description": "Qwen2.5 Coder 32B Instruct è l'ultimo LLM di Alibaba Cloud focalizzato sul codice. Basato su Qwen2.5 e addestrato su 5,5T token, migliora significativamente la generazione di codice, il ragionamento e la correzione, mantenendo le capacità matematiche e generali, fornendo una solida base per agenti di programmazione.",
  "Qwen/Qwen2.5-Coder-7B-Instruct.description": "Qwen2.5-Coder-7B-Instruct è l'ultimo LLM di Alibaba Cloud focalizzato sul codice. Basato su Qwen2.5 e addestrato su 5,5T token, migliora significativamente la generazione di codice, il ragionamento e la correzione, mantenendo le capacità matematiche e generali, fornendo una base solida per agenti di programmazione.",
  "Qwen/Qwen2.5-VL-32B-Instruct.description": "Qwen2.5-VL-32B-Instruct è un modello multimodale del team Qwen. Riconosce oggetti comuni e analizza testo, grafici, icone, elementi visivi e layout. Come agente visivo, può ragionare e controllare dinamicamente strumenti, inclusi computer e telefoni. Localizza con precisione oggetti e genera output strutturati per fatture e tabelle. Rispetto a Qwen2-VL, RL migliora ulteriormente la matematica e la risoluzione di problemi, con risposte più preferite dagli utenti.",
  "Qwen/Qwen2.5-VL-72B-Instruct.description": "Qwen2.5-VL è il modello visione-linguaggio della serie Qwen2.5 con importanti aggiornamenti: comprensione visiva più forte per oggetti, testo, grafici e layout; ragionamento come agente visivo con uso dinamico di strumenti; comprensione di video oltre 1 ora e cattura di eventi chiave; localizzazione precisa di oggetti tramite riquadri o punti; e output strutturati per dati scansionati come fatture e tabelle.",
  "Qwen/Qwen3-14B.description": "Qwen3 è un modello Tongyi Qwen di nuova generazione con importanti miglioramenti nel ragionamento, nelle capacità generali, nelle funzionalità agentiche e nelle prestazioni multilingue, e supporta la commutazione tra modalità di pensiero.",
  "Qwen/Qwen3-235B-A22B-Instruct-2507.description": "Qwen3-235B-A22B-Instruct-2507 è un modello di punta della serie Qwen3 MoE con 235 miliardi di parametri totali e 22 miliardi attivi. È una versione aggiornata non pensante, focalizzata sul miglioramento del seguito delle istruzioni, del ragionamento logico, della comprensione del testo, della matematica, della scienza, della programmazione e dell'uso degli strumenti. Amplia inoltre la conoscenza multilingue di nicchia e si allinea meglio alle preferenze degli utenti nei compiti soggettivi e aperti.",
  "Qwen/Qwen3-235B-A22B-Thinking-2507.description": "Qwen3-235B-A22B-Thinking-2507 è un modello Qwen3 progettato per il ragionamento complesso e avanzato. Utilizza un'architettura MoE con 235 miliardi di parametri totali e circa 22 miliardi attivi per token, ottimizzando l'efficienza. In quanto modello dedicato al pensiero, mostra miglioramenti significativi in logica, matematica, scienza, programmazione e benchmark accademici, raggiungendo prestazioni di alto livello nel pensiero aperto. Migliora anche il seguito delle istruzioni, l'uso degli strumenti e la generazione di testo, supportando nativamente un contesto di 256K per ragionamenti profondi e documenti lunghi.",
  "Qwen/Qwen3-235B-A22B.description": "Qwen3 è un modello Tongyi Qwen di nuova generazione con importanti progressi nel ragionamento, nelle capacità generali, nelle funzionalità agentiche e nelle prestazioni multilingue, e supporta la commutazione tra modalità di pensiero.",
  "Qwen/Qwen3-30B-A3B-Instruct-2507.description": "Qwen3-30B-A3B-Instruct-2507 è la versione aggiornata non pensante di Qwen3-30B-A3B. È un modello MoE con 30,5 miliardi di parametri totali e 3,3 miliardi attivi. Migliora significativamente il seguito delle istruzioni, il ragionamento logico, la comprensione del testo, la matematica, la scienza, la programmazione e l'uso degli strumenti, amplia la conoscenza multilingue di nicchia e si allinea meglio alle preferenze degli utenti nei compiti soggettivi aperti. Supporta un contesto di 256K. Questo modello è esclusivamente non pensante e non genera tag `<think></think>`.",
  "Qwen/Qwen3-30B-A3B-Thinking-2507.description": "Qwen3-30B-A3B-Thinking-2507 è l'ultimo modello pensante della serie Qwen3. È un modello MoE con 30,5 miliardi di parametri totali e 3,3 miliardi attivi, progettato per compiti complessi. Mostra miglioramenti significativi in logica, matematica, scienza, programmazione e benchmark accademici, e migliora il seguito delle istruzioni, l'uso degli strumenti, la generazione di testo e l'allineamento alle preferenze. Supporta nativamente un contesto di 256K ed è estendibile fino a 1 milione di token. Questa versione è progettata per la modalità pensante, con ragionamento dettagliato passo dopo passo e forti capacità agentiche.",
  "Qwen/Qwen3-30B-A3B.description": "Qwen3 è un modello Tongyi Qwen di nuova generazione con importanti progressi nel ragionamento, nelle capacità generali, nelle funzionalità agentiche e nelle prestazioni multilingue, e supporta la commutazione tra modalità di pensiero.",
  "Qwen/Qwen3-32B.description": "Qwen3 è un modello Tongyi Qwen di nuova generazione con importanti progressi nel ragionamento, nelle capacità generali, nelle funzionalità agentiche e nelle prestazioni multilingue, e supporta la commutazione tra modalità di pensiero.",
  "Qwen/Qwen3-8B.description": "Qwen3 è un modello Tongyi Qwen di nuova generazione con importanti progressi nel ragionamento, nelle capacità generali, nelle funzionalità agentiche e nelle prestazioni multilingue, e supporta la commutazione tra modalità di pensiero.",
  "Qwen/Qwen3-Coder-30B-A3B-Instruct.description": "Qwen3-Coder-30B-A3B-Instruct è un modello Qwen3 per la programmazione sviluppato dal team Qwen. È ottimizzato per alte prestazioni ed efficienza, potenziando le capacità di codifica. Mostra vantaggi significativi nella programmazione agentica, nelle operazioni automatizzate del browser e nell'uso degli strumenti tra i modelli open source. Supporta nativamente un contesto di 256K ed è estendibile fino a 1 milione di token per una comprensione a livello di codice base. Alimenta la programmazione agentica su piattaforme come Qwen Code e CLINE con un formato dedicato per le chiamate di funzione.",
  "Qwen/Qwen3-Coder-480B-A35B-Instruct.description": "Qwen3-Coder-480B-A35B-Instruct è il modello di programmazione più avanzato di Alibaba. È un modello MoE con 480 miliardi di parametri totali e 35 miliardi attivi, che bilancia efficienza e prestazioni. Supporta nativamente un contesto di 256K ed è estendibile fino a 1 milione di token tramite YaRN, permettendo la gestione di grandi basi di codice. Progettato per flussi di lavoro di programmazione agentica, può interagire con strumenti e ambienti per risolvere compiti di programmazione complessi. Raggiunge risultati di punta tra i modelli open source nei benchmark di programmazione e agenti, comparabili a modelli leader come Claude Sonnet 4.",
  "Qwen/Qwen3-Next-80B-A3B-Instruct.description": "Qwen3-Next-80B-A3B-Instruct è un modello base di nuova generazione che utilizza l'architettura Qwen3-Next per un'efficienza estrema in addestramento e inferenza. Combina attenzione ibrida (Gated DeltaNet + Gated Attention), MoE altamente sparso e ottimizzazioni per la stabilità dell'addestramento. Con 80 miliardi di parametri totali ma solo ~3 miliardi attivi in inferenza, riduce il calcolo e offre oltre 10 volte il throughput rispetto a Qwen3-32B su contesti >32K. Questa versione ottimizzata per le istruzioni è pensata per compiti generali (senza modalità pensante). Ha prestazioni comparabili a Qwen3-235B in alcuni benchmark e mostra forti vantaggi nei compiti con contesto ultra-lungo.",
  "Qwen/Qwen3-Next-80B-A3B-Thinking.description": "Qwen3-Next-80B-A3B-Thinking è un modello base di nuova generazione per il ragionamento complesso. Utilizza l'architettura Qwen3-Next con attenzione ibrida (Gated DeltaNet + Gated Attention) e MoE altamente sparso per un'efficienza estrema in addestramento e inferenza. Con 80 miliardi di parametri totali ma solo ~3 miliardi attivi in inferenza, riduce il calcolo e offre oltre 10 volte il throughput rispetto a Qwen3-32B su contesti >32K. Questa versione pensante è progettata per compiti multi-step come dimostrazioni, sintesi di codice, analisi logica e pianificazione, generando catene di pensiero strutturate. Supera Qwen3-32B-Thinking e batte Gemini-2.5-Flash-Thinking in diversi benchmark.",
  "Qwen/Qwen3-Omni-30B-A3B-Captioner.description": "Qwen3-Omni-30B-A3B-Captioner è un modello VLM della serie Qwen3 progettato per generare didascalie di immagini di alta qualità, dettagliate e accurate. Utilizza un'architettura MoE da 30 miliardi di parametri per comprendere a fondo le immagini e produrre descrizioni fluide, eccellendo nella cattura dei dettagli, nella comprensione della scena, nel riconoscimento degli oggetti e nel ragionamento relazionale.",
  "Qwen/Qwen3-Omni-30B-A3B-Instruct.description": "Qwen3-Omni-30B-A3B-Instruct è un modello MoE della serie Qwen3 con 30 miliardi di parametri totali e 3 miliardi attivi, che offre prestazioni elevate a un costo di inferenza ridotto. Addestrato su dati multilingue di alta qualità provenienti da più fonti, supporta input multimodali completi (testo, immagini, audio, video) e comprensione e generazione cross-modale.",
  "Qwen/Qwen3-Omni-30B-A3B-Thinking.description": "Qwen3-Omni-30B-A3B-Thinking è il componente \"pensante\" principale di Qwen3-Omni. Elabora input multimodali (testo, audio, immagini, video) e svolge ragionamenti complessi a catena, unificando gli input in una rappresentazione condivisa per una comprensione cross-modale profonda. È un modello MoE con 30 miliardi di parametri totali e 3 miliardi attivi, che bilancia ragionamento avanzato ed efficienza computazionale.",
  "Qwen/Qwen3-VL-235B-A22B-Instruct.description": "Qwen3-VL-235B-A22B-Instruct è un grande modello Qwen3-VL ottimizzato per le istruzioni, basato su architettura MoE, che offre eccellente comprensione e generazione multimodale. Supporta nativamente un contesto di 256K ed è adatto a servizi multimodali in produzione ad alta concorrenza.",
  "Qwen/Qwen3-VL-235B-A22B-Thinking.description": "Qwen3-VL-235B-A22B-Thinking è la versione pensante di punta di Qwen3-VL, ottimizzata per il ragionamento multimodale complesso, il ragionamento su contesti lunghi e l'interazione con agenti in scenari aziendali.",
  "Qwen/Qwen3-VL-30B-A3B-Instruct.description": "Qwen3-VL-30B-A3B-Instruct è il modello Qwen3-VL ottimizzato per le istruzioni, con forte comprensione e generazione linguistico-visiva. Supporta nativamente un contesto di 256K per chat multimodali e generazione condizionata da immagini.",
  "Qwen/Qwen3-VL-30B-A3B-Thinking.description": "Qwen3-VL-30B-A3B-Thinking è la versione potenziata per il ragionamento di Qwen3-VL, ottimizzata per il ragionamento multimodale, la conversione da immagine a codice e la comprensione visiva complessa. Supporta un contesto di 256K con una maggiore capacità di catena di pensiero.",
  "Qwen/Qwen3-VL-32B-Instruct.description": "Qwen3-VL-32B-Instruct è un modello linguistico-visivo del team Qwen con risultati SOTA su diversi benchmark VL. Supporta immagini ad alta risoluzione (megapixel) e offre forte comprensione visiva, OCR multilingue, ancoraggio visivo dettagliato e dialogo visivo. Gestisce compiti multimodali complessi e supporta chiamate di strumenti e completamento con prefisso.",
  "Qwen/Qwen3-VL-32B-Thinking.description": "Qwen3-VL-32B-Thinking è ottimizzato per il ragionamento visivo complesso. Include una modalità pensante integrata che genera passaggi intermedi di ragionamento prima delle risposte, migliorando logica multi-step, pianificazione e ragionamento complesso. Supporta immagini megapixel, forte comprensione visiva, OCR multilingue, ancoraggio dettagliato, dialogo visivo, chiamate di strumenti e completamento con prefisso.",
  "Qwen/Qwen3-VL-8B-Instruct.description": "Qwen3-VL-8B-Instruct è un modello linguistico-visivo Qwen3 basato su Qwen3-8B-Instruct e addestrato su grandi quantità di dati immagine-testo. Eccelle nella comprensione visiva generale, nel dialogo centrato sulla visione e nel riconoscimento multilingue del testo nelle immagini, adatto a QA visivo, didascalie, seguito di istruzioni multimodali e uso di strumenti.",
  "Qwen/Qwen3-VL-8B-Thinking.description": "Qwen3-VL-8B-Thinking è la versione visiva pensante di Qwen3, ottimizzata per il ragionamento complesso multi-step. Genera una catena di pensiero prima delle risposte per migliorarne l'accuratezza, ideale per QA visivo profondo e analisi dettagliata delle immagini.",
  "Qwen2-72B-Instruct.description": "Qwen2 è l'ultima versione della serie Qwen, con supporto per una finestra di contesto di 128k. Rispetto ai migliori modelli open attuali, Qwen2-72B supera significativamente i principali modelli in comprensione del linguaggio naturale, conoscenza, programmazione, matematica e capacità multilingue.",
  "Qwen2-7B-Instruct.description": "Qwen2 è l'ultima versione della serie Qwen, che supera i migliori modelli open della stessa dimensione e persino modelli più grandi. Qwen2 7B mostra vantaggi significativi in diversi benchmark, in particolare nella programmazione e nella comprensione del cinese.",
  "Qwen2-VL-72B.description": "Qwen2-VL-72B è un potente modello visione-linguaggio che supporta l'elaborazione multimodale immagine-testo, riconoscendo accuratamente i contenuti visivi e generando descrizioni o risposte pertinenti.",
  "Qwen2.5-14B-Instruct.description": "Qwen2.5-14B-Instruct è un LLM da 14 miliardi di parametri con prestazioni elevate, ottimizzato per scenari in cinese e multilingue, con supporto per domande e risposte intelligenti e generazione di contenuti.",
  "Qwen2.5-32B-Instruct.description": "Qwen2.5-32B-Instruct è un LLM da 32 miliardi di parametri con prestazioni bilanciate, ottimizzato per scenari in cinese e multilingue, con supporto per domande e risposte intelligenti e generazione di contenuti.",
  "Qwen2.5-72B-Instruct.description": "LLM per cinese e inglese, ottimizzato per linguaggio, programmazione, matematica e ragionamento.",
  "Qwen2.5-7B-Instruct.description": "Qwen2.5-7B-Instruct è un LLM da 7 miliardi di parametri che supporta chiamate a funzioni e integrazione fluida con sistemi esterni, migliorando notevolmente flessibilità ed estensibilità. È ottimizzato per scenari in cinese e multilingue, con supporto per domande e risposte intelligenti e generazione di contenuti.",
  "Qwen2.5-Coder-14B-Instruct.description": "Qwen2.5-Coder-14B-Instruct è un modello di istruzioni per la programmazione su larga scala, con eccellenti capacità di comprensione e generazione di codice. Gestisce in modo efficiente una vasta gamma di compiti di programmazione, ideale per codifica intelligente, generazione automatica di script e domande e risposte sulla programmazione.",
  "Qwen2.5-Coder-32B-Instruct.description": "LLM avanzato per generazione di codice, ragionamento e correzione di bug nei principali linguaggi di programmazione.",
  "Qwen3-235B-A22B-Instruct-2507-FP8.description": "Qwen3 235B A22B Instruct 2507 è ottimizzato per ragionamento avanzato e seguire istruzioni, utilizzando MoE per mantenere l'efficienza del ragionamento su larga scala.",
  "Qwen3-235B.description": "Qwen3-235B-A22B è un modello MoE che introduce una modalità di ragionamento ibrida, consentendo agli utenti di passare senza interruzioni tra pensiero e non-pensiero. Supporta comprensione e ragionamento in 119 lingue e dialetti e ha forti capacità di utilizzo di strumenti, competendo con modelli di punta come DeepSeek R1, OpenAI o1, o3-mini, Grok 3 e Google Gemini 2.5 Pro nei benchmark su abilità generali, codice e matematica, capacità multilingue e ragionamento basato sulla conoscenza.",
  "Qwen3-32B.description": "Qwen3-32B è un modello denso che introduce una modalità di ragionamento ibrida, consentendo agli utenti di passare tra pensiero e non-pensiero. Grazie a miglioramenti architetturali, più dati e un addestramento migliore, offre prestazioni comparabili a Qwen2.5-72B.",
  "SenseChat-128K.description": "Base V4 con contesto da 128K, eccellente nella comprensione e generazione di testi lunghi.",
  "SenseChat-32K.description": "Base V4 con contesto da 32K, flessibile per molti scenari.",
  "SenseChat-5-1202.description": "Ultima versione basata su V5.5, con miglioramenti significativi nelle basi di cinese/inglese, chat, conoscenze STEM, umanistiche, scrittura, matematica/logica e controllo della lunghezza.",
  "SenseChat-5-Cantonese.description": "Progettato per le abitudini di dialogo di Hong Kong, slang e conoscenze locali; supera GPT-4 nella comprensione del cantonese e rivaleggia con GPT-4 Turbo in conoscenza, ragionamento, matematica e programmazione.",
  "SenseChat-5-beta.description": "Alcune prestazioni superano SenseChat-5-1202.",
  "SenseChat-5.description": "Ultima versione V5.5 con contesto da 128K; grandi miglioramenti nel ragionamento matematico, chat in inglese, esecuzione di istruzioni e comprensione di testi lunghi, comparabile a GPT-4o.",
  "SenseChat-Character-Pro.description": "Modello avanzato per chat con personaggi, con contesto da 32K, capacità migliorate e supporto per cinese/inglese.",
  "SenseChat-Character.description": "Modello standard per chat con personaggi, con contesto da 8K e alta velocità di risposta.",
  "SenseChat-Turbo-1202.description": "Ultimo modello leggero che raggiunge oltre il 90% delle capacità del modello completo con costi di inferenza significativamente inferiori.",
  "SenseChat-Turbo.description": "Adatto per domande e risposte rapide e scenari di fine-tuning del modello.",
  "SenseChat-Vision.description": "Ultima versione V5.5 con input multi-immagine e ampi miglioramenti nelle capacità di riconoscimento di attributi, relazioni spaziali, rilevamento di azioni/eventi, comprensione di scene, riconoscimento delle emozioni, ragionamento basato sul senso comune e comprensione/generazione di testo.",
  "SenseChat.description": "Base V4 con contesto da 4K e forti capacità generali.",
  "SenseNova-V6-5-Pro.description": "Con aggiornamenti completi ai dati multimodali, linguistici e di ragionamento, oltre all'ottimizzazione della strategia di addestramento, il nuovo modello migliora significativamente il ragionamento multimodale e il seguito delle istruzioni generalizzate, supporta una finestra di contesto fino a 128k e si distingue nei compiti di riconoscimento OCR e IP culturali/turistici.",
  "SenseNova-V6-5-Turbo.description": "Con aggiornamenti completi ai dati multimodali, linguistici e di ragionamento, oltre all'ottimizzazione della strategia di addestramento, il nuovo modello migliora significativamente il ragionamento multimodale e il seguito delle istruzioni generalizzate, supporta una finestra di contesto fino a 128k e si distingue nei compiti di riconoscimento OCR e IP culturali/turistici.",
  "SenseNova-V6-Pro.description": "Unifica nativamente immagine, testo e video, superando i limiti tradizionali dei modelli multimodali; si posiziona ai vertici su OpenCompass e SuperCLUE.",
  "SenseNova-V6-Reasoner.description": "Combina ragionamento profondo visivo e linguistico, supportando pensiero lento e catene complete di ragionamento.",
  "SenseNova-V6-Turbo.description": "Unifica nativamente immagine, testo e video, superando i limiti tradizionali dei modelli multimodali. Guida le capacità linguistiche e multimodali di base e si classifica tra i migliori in molte valutazioni.",
  "Skylark2-lite-8k.description": "Modello Skylark di seconda generazione. Skylark2-lite offre risposte rapide per scenari in tempo reale e sensibili ai costi, con esigenze di accuratezza inferiori, e una finestra di contesto da 8K.",
  "Skylark2-pro-32k.description": "Modello Skylark di seconda generazione. Skylark2-pro offre maggiore accuratezza per generazione di testi complessi come copywriting professionale, scrittura di romanzi e traduzioni di alta qualità, con una finestra di contesto da 32K.",
  "Skylark2-pro-4k.description": "Modello Skylark di seconda generazione. Skylark2-pro offre maggiore accuratezza per generazione di testi complessi come copywriting professionale, scrittura di romanzi e traduzioni di alta qualità, con una finestra di contesto da 4K.",
  "Skylark2-pro-character-4k.description": "Modello Skylark di seconda generazione. Skylark2-pro-character eccelle nel gioco di ruolo e nella chat, adattando i prompt a stili di personaggi distinti e dialoghi naturali per chatbot, assistenti virtuali e assistenza clienti, con risposte rapide.",
  "Skylark2-pro-turbo-8k.description": "Modello Skylark di seconda generazione. Skylark2-pro-turbo-8k offre inferenza più veloce a costi inferiori con una finestra di contesto da 8K.",
  "THUDM/GLM-4-32B-0414.description": "GLM-4-32B-0414 è un modello GLM open-source di nuova generazione con 32 miliardi di parametri, comparabile in prestazioni a OpenAI GPT e alla serie DeepSeek V3/R1.",
  "THUDM/GLM-4-9B-0414.description": "GLM-4-9B-0414 è un modello GLM da 9 miliardi di parametri che eredita le tecniche di GLM-4-32B offrendo un'implementazione più leggera. Eccelle nella generazione di codice, progettazione web, generazione SVG e scrittura basata su ricerca.",
  "THUDM/GLM-4.1V-9B-Thinking.description": "GLM-4.1V-9B-Thinking è un VLM open-source sviluppato da Zhipu AI e Tsinghua KEG Lab, progettato per la cognizione multimodale complessa. Basato su GLM-4-9B-0414, aggiunge ragionamento a catena e RL per migliorare significativamente il ragionamento cross-modale e la stabilità.",
  "THUDM/GLM-Z1-32B-0414.description": "GLM-Z1-32B-0414 è un modello di ragionamento profondo costruito a partire da GLM-4-32B-0414 con dati cold-start e RL esteso, ulteriormente addestrato su matematica, codice e logica. Migliora significativamente la capacità matematica e la risoluzione di compiti complessi rispetto al modello base.",
  "THUDM/GLM-Z1-9B-0414.description": "GLM-Z1-9B-0414 è un modello GLM compatto da 9 miliardi di parametri che mantiene i punti di forza open-source offrendo capacità impressionanti. Eccelle nel ragionamento matematico e nei compiti generali, guidando la sua classe di dimensione tra i modelli open.",
  "THUDM/GLM-Z1-Rumination-32B-0414.description": "GLM-Z1-Rumination-32B-0414 è un modello di ragionamento profondo con capacità di riflessione (valutato rispetto a OpenAI Deep Research). A differenza dei modelli di pensiero profondo tipici, impiega più tempo per risolvere problemi aperti e complessi.",
  "THUDM/glm-4-9b-chat.description": "GLM-4-9B-Chat è il modello GLM-4 open-source di Zhipu AI. Eccelle in semantica, matematica, ragionamento, codice e conoscenza. Oltre alla chat multi-turno, supporta navigazione web, esecuzione di codice, chiamate a strumenti personalizzati e ragionamento su testi lunghi. Supporta 26 lingue (inclusi cinese, inglese, giapponese, coreano, tedesco). Ottiene buoni risultati su AlignBench-v2, MT-Bench, MMLU e C-Eval, e supporta fino a 128K di contesto per uso accademico e aziendale.",
  "Tongyi-Zhiwen/QwenLong-L1-32B.description": "QwenLong-L1-32B è il primo modello di ragionamento a lungo contesto (LRM) addestrato con RL, ottimizzato per il ragionamento su testi lunghi. Il suo RL con espansione progressiva del contesto consente un trasferimento stabile da contesti brevi a lunghi. Supera OpenAI-o3-mini e Qwen3-235B-A22B in sette benchmark di QA su documenti a lungo contesto, rivaleggiando con Claude-3.7-Sonnet-Thinking. È particolarmente forte in matematica, logica e ragionamento multi-hop.",
  "Yi-34B-Chat.description": "Yi-1.5-34B mantiene le forti capacità linguistiche generali della serie, migliorando significativamente logica matematica e programmazione grazie a un addestramento incrementale su 500 miliardi di token di alta qualità.",
  "abab5.5-chat.description": "Progettato per scenari di produttività, gestisce compiti complessi e genera testo in modo efficiente per uso professionale.",
  "abab5.5s-chat.description": "Progettato per chat con personaggi in cinese, offrendo dialoghi di alta qualità per varie applicazioni.",
  "abab6.5g-chat.description": "Progettato per chat con personaggi multilingue, supporta generazione di dialoghi di alta qualità in inglese e altre lingue.",
  "abab6.5s-chat.description": "Adatto a un'ampia gamma di compiti NLP, inclusa la generazione di testo e sistemi di dialogo.",
  "abab6.5t-chat.description": "Ottimizzato per chat con personaggi in cinese, fornendo dialoghi fluidi che rispettano le abitudini espressive cinesi.",
  "accounts/fireworks/models/deepseek-r1.description": "DeepSeek-R1 è un modello linguistico all'avanguardia ottimizzato con apprendimento per rinforzo e dati cold-start, che offre prestazioni eccellenti in ragionamento, matematica e programmazione.",
  "accounts/fireworks/models/deepseek-v3.description": "Un potente modello linguistico Mixture-of-Experts (MoE) di DeepSeek con 671 miliardi di parametri totali e 37 miliardi di parametri attivi per token.",
  "accounts/fireworks/models/llama-v3-70b-instruct.description": "Meta ha sviluppato e rilasciato la serie di modelli linguistici Meta Llama 3, che include modelli pre-addestrati e ottimizzati per l'uso conversazionale da 8B e 70B. I modelli Llama 3 ottimizzati per le istruzioni sono progettati per l'interazione conversazionale e superano molti modelli open chat esistenti nei benchmark di settore.",
  "accounts/fireworks/models/llama-v3-8b-instruct-hf.description": "I modelli Llama 3 ottimizzati per le istruzioni sono progettati per l'interazione conversazionale e superano molti modelli open chat esistenti nei benchmark di settore. Llama 3 8B Instruct (versione HF) è la versione FP16 originale di Llama 3 8B Instruct, con risultati attesi in linea con l'implementazione ufficiale di Hugging Face.",
  "accounts/fireworks/models/llama-v3-8b-instruct.description": "Meta ha sviluppato e rilasciato la serie di modelli linguistici Meta Llama 3, una collezione di modelli pre-addestrati e ottimizzati per la generazione di testo da 8B e 70B. I modelli Llama 3 ottimizzati per le istruzioni sono progettati per l'uso conversazionale e superano molti modelli open chat esistenti nei benchmark di settore.",
  "accounts/fireworks/models/llama-v3p1-405b-instruct.description": "Meta Llama 3.1 è una famiglia di modelli linguistici multilingue con modelli di generazione pre-addestrati e ottimizzati per le istruzioni nei formati 8B, 70B e 405B. I modelli ottimizzati per le istruzioni sono progettati per il dialogo multilingue e superano molti modelli open e closed chat nei benchmark di settore. Il modello 405B è il più avanzato della famiglia Llama 3.1, utilizzando inferenza FP8 che replica fedelmente l'implementazione di riferimento.",
  "accounts/fireworks/models/llama-v3p1-70b-instruct.description": "Meta Llama 3.1 è una famiglia di modelli linguistici multilingue con modelli di generazione pre-addestrati e ottimizzati per le istruzioni nei formati 8B, 70B e 405B. I modelli ottimizzati per le istruzioni sono progettati per il dialogo multilingue e superano molti modelli open e closed chat nei benchmark di settore.",
  "accounts/fireworks/models/llama-v3p1-8b-instruct.description": "Meta Llama 3.1 è una famiglia di modelli linguistici multilingue con modelli di generazione pre-addestrati e ottimizzati per le istruzioni nei formati 8B, 70B e 405B. I modelli ottimizzati per le istruzioni sono progettati per il dialogo multilingue e superano molti modelli open e closed chat nei benchmark di settore.",
  "accounts/fireworks/models/llama-v3p2-11b-vision-instruct.description": "Un modello di ragionamento visivo ottimizzato per le istruzioni di Meta con 11 miliardi di parametri, progettato per il riconoscimento visivo, il ragionamento su immagini, la generazione di didascalie e domande e risposte basate su immagini. Comprende dati visivi come grafici e tabelle e collega visione e linguaggio generando descrizioni testuali dei dettagli visivi.",
  "accounts/fireworks/models/llama-v3p2-3b-instruct.description": "Llama 3.2 3B Instruct è un modello multilingue leggero di Meta, progettato per un'esecuzione efficiente con vantaggi significativi in termini di latenza e costi rispetto ai modelli più grandi. Gli usi tipici includono la riscrittura di query/promt e l'assistenza alla scrittura.",
  "accounts/fireworks/models/llama-v3p2-90b-vision-instruct.description": "Un modello di ragionamento visivo ottimizzato per le istruzioni di Meta con 90 miliardi di parametri, progettato per il riconoscimento visivo, il ragionamento su immagini, la generazione di didascalie e domande e risposte basate su immagini. Comprende dati visivi come grafici e tabelle e collega visione e linguaggio generando descrizioni testuali dei dettagli visivi. Nota: questo modello è attualmente fornito in via sperimentale come modello serverless. Per l'uso in produzione, Fireworks potrebbe ritirare il deployment con breve preavviso.",
  "accounts/fireworks/models/llama-v3p3-70b-instruct.description": "Llama 3.3 70B Instruct è l'aggiornamento di dicembre del modello Llama 3.1 70B. Migliora l'uso degli strumenti, il supporto multilingue, la matematica e la programmazione rispetto alla versione di luglio 2024. Raggiunge prestazioni leader nel settore in ragionamento, matematica e comprensione delle istruzioni, offrendo prestazioni comparabili al modello 3.1 405B con vantaggi significativi in termini di velocità e costi.",
  "accounts/fireworks/models/mistral-small-24b-instruct-2501.description": "Un modello da 24 miliardi di parametri con capacità all'avanguardia comparabili a modelli più grandi.",
  "accounts/fireworks/models/mixtral-8x22b-instruct.description": "Mixtral MoE 8x22B Instruct v0.1 è la versione ottimizzata per le istruzioni di Mixtral MoE 8x22B v0.1, con API di completamento chat abilitata.",
  "accounts/fireworks/models/mixtral-8x7b-instruct.description": "Mixtral MoE 8x7B Instruct è la versione ottimizzata per le istruzioni di Mixtral MoE 8x7B, con API di completamento chat abilitata.",
  "accounts/fireworks/models/mythomax-l2-13b.description": "Una variante migliorata di MythoMix, probabilmente la sua forma più raffinata, che unisce MythoLogic-L2 e Huginn con una tecnica di fusione tensoriale altamente sperimentale. La sua natura unica lo rende eccellente per la narrazione e il gioco di ruolo.",
  "accounts/fireworks/models/phi-3-vision-128k-instruct.description": "Phi-3-Vision-128K-Instruct è un modello multimodale leggero e all'avanguardia costruito con dati sintetici e dataset pubblici selezionati, focalizzato su dati testuali e visivi di alta qualità e ad alta intensità di ragionamento. Fa parte della famiglia Phi-3, con una versione multimodale che supporta una lunghezza di contesto di 128K token. Il modello è stato migliorato con fine-tuning supervisionato e ottimizzazione diretta delle preferenze, per garantire un'accurata comprensione delle istruzioni e solide misure di sicurezza.",
  "accounts/fireworks/models/qwen-qwq-32b-preview.description": "Il modello Qwen QwQ si concentra sull'avanzamento del ragionamento dell'IA, dimostrando che i modelli open possono competere con quelli closed di frontiera. QwQ-32B-Preview è una versione sperimentale che eguaglia o1 e supera GPT-4o e Claude 3.5 Sonnet nel ragionamento e nell'analisi su GPQA, AIME, MATH-500 e LiveCodeBench. Nota: questo modello è attualmente fornito in via sperimentale come modello serverless. Per l'uso in produzione, Fireworks potrebbe ritirare il deployment con breve preavviso.",
  "accounts/fireworks/models/qwen2-vl-72b-instruct.description": "Il modello Qwen-VL da 72B è l'ultima iterazione di Alibaba, frutto di quasi un anno di innovazione.",
  "accounts/fireworks/models/qwen2p5-72b-instruct.description": "Qwen2.5 è una serie di modelli linguistici solo decoder sviluppata dal team Qwen e da Alibaba Cloud, disponibile nei formati 0.5B, 1.5B, 3B, 7B, 14B, 32B e 72B, con varianti base e ottimizzate per le istruzioni.",
  "accounts/fireworks/models/qwen2p5-coder-32b-instruct.description": "Qwen2.5-Coder è l'ultimo modello linguistico Qwen progettato per la programmazione (precedentemente CodeQwen). Nota: questo modello è attualmente fornito in via sperimentale come modello serverless. Per l'uso in produzione, Fireworks potrebbe ritirare il deployment con breve preavviso.",
  "accounts/yi-01-ai/models/yi-large.description": "Yi-Large è un modello linguistico di alto livello che si posiziona appena sotto GPT-4, Gemini 1.5 Pro e Claude 3 Opus nella classifica LMSYS. Eccelle nella capacità multilingue, in particolare in spagnolo, cinese, giapponese, tedesco e francese. Yi-Large è anche adatto agli sviluppatori, utilizzando lo stesso schema API di OpenAI per una facile integrazione.",
  "ai21-jamba-1.5-large.description": "Un modello multilingue da 398 miliardi di parametri (94B attivi) con una finestra di contesto di 256K, supporto per chiamate di funzione, output strutturato e generazione ancorata.",
  "ai21-jamba-1.5-mini.description": "Un modello multilingue da 52 miliardi di parametri (12B attivi) con una finestra di contesto di 256K, supporto per chiamate di funzione, output strutturato e generazione ancorata.",
  "ai21-labs/AI21-Jamba-1.5-Large.description": "Un modello multilingue da 398 miliardi di parametri (94B attivi) con una finestra di contesto di 256K, supporto per chiamate di funzione, output strutturato e generazione ancorata.",
  "ai21-labs/AI21-Jamba-1.5-Mini.description": "Un modello multilingue da 52 miliardi di parametri (12B attivi) con una finestra di contesto di 256K, supporto per chiamate di funzione, output strutturato e generazione ancorata.",
  "alibaba/qwen-3-14b.description": "Qwen3 è l'ultima generazione della serie Qwen, che offre una gamma completa di modelli densi e MoE. Basato su un addestramento esteso, introduce innovazioni nel ragionamento, nella comprensione delle istruzioni, nelle capacità agentiche e nel supporto multilingue.",
  "alibaba/qwen-3-235b.description": "Qwen3 è l'ultima generazione della serie Qwen, che offre una gamma completa di modelli densi e MoE. Basato su un addestramento esteso, introduce innovazioni nel ragionamento, nella comprensione delle istruzioni, nelle capacità agentiche e nel supporto multilingue.",
  "alibaba/qwen-3-30b.description": "Qwen3 è l'ultima generazione della serie Qwen, che offre una gamma completa di modelli densi e MoE. Basato su un addestramento esteso, introduce innovazioni nel ragionamento, nella comprensione delle istruzioni, nelle capacità agentiche e nel supporto multilingue.",
  "alibaba/qwen-3-32b.description": "Qwen3 è l'ultima generazione della serie Qwen, che offre una gamma completa di modelli densi e MoE. Basato su un addestramento esteso, introduce innovazioni nel ragionamento, nella comprensione delle istruzioni, nelle capacità agentiche e nel supporto multilingue.",
  "alibaba/qwen3-coder.description": "Qwen3-Coder-480B-A35B-Instruct è il modello Qwen più avanzato per la programmazione, con ottime prestazioni in attività agentiche di codifica, uso del browser e altri compiti fondamentali, raggiungendo risultati comparabili a Claude Sonnet.",
  "amazon/nova-lite.description": "Un modello multimodale a bassissimo costo con elaborazione estremamente rapida di input immagine, video e testo.",
  "amazon/nova-micro.description": "Un modello solo testuale che offre una latenza ultra-bassa a un costo molto contenuto.",
  "amazon/nova-pro.description": "Un modello multimodale altamente performante con il miglior equilibrio tra accuratezza, velocità e costo per un'ampia gamma di compiti.",
  "amazon/titan-embed-text-v2.description": "Amazon Titan Text Embeddings V2 è un modello di embedding multilingue leggero ed efficiente che supporta dimensioni di 1024, 512 e 256.",
  "anthropic.claude-3-5-sonnet-20240620-v1:0.description": "Claude 3.5 Sonnet alza lo standard del settore, superando i concorrenti e Claude 3 Opus in valutazioni ampie, mantenendo velocità e costi di fascia media.",
  "anthropic.claude-3-5-sonnet-20241022-v2:0.description": "Claude 3.5 Sonnet alza lo standard del settore, superando i concorrenti e Claude 3 Opus in valutazioni ampie, mantenendo velocità e costi di fascia media.",
  "anthropic.claude-3-haiku-20240307-v1:0.description": "Claude 3 Haiku è il modello più veloce e compatto di Anthropic, progettato per risposte quasi istantanee a domande semplici. Offre esperienze AI fluide e simili a quelle umane e supporta input immagine con una finestra di contesto di 200K.",
  "anthropic.claude-3-opus-20240229-v1:0.description": "Claude 3 Opus è il modello AI più potente di Anthropic, con prestazioni all'avanguardia in compiti altamente complessi. Gestisce prompt aperti e scenari inediti con eccezionale fluidità e comprensione simile a quella umana, e supporta input immagine con una finestra di contesto di 200K.",
  "anthropic.claude-3-sonnet-20240229-v1:0.description": "Claude 3 Sonnet bilancia intelligenza e velocità per carichi di lavoro aziendali, offrendo un ottimo valore a costi contenuti. È progettato come un modello affidabile per implementazioni AI su larga scala e supporta input immagine con una finestra di contesto di 200K.",
  "anthropic.claude-instant-v1.description": "Un modello veloce, economico ma capace per chat quotidiane, analisi testuale, riassunti e domande su documenti.",
  "anthropic.claude-v2.description": "Un modello altamente capace per compiti che vanno dal dialogo complesso alla generazione creativa fino al rispetto dettagliato delle istruzioni.",
  "anthropic.claude-v2:1.description": "Una versione aggiornata di Claude 2 con il doppio della finestra di contesto e miglioramenti in affidabilità, riduzione delle allucinazioni e accuratezza basata su prove per documenti lunghi e RAG.",
  "anthropic/claude-3-haiku.description": "Claude 3 Haiku è il modello più veloce di Anthropic, progettato per carichi di lavoro aziendali con prompt lunghi. Può analizzare rapidamente documenti estesi come report trimestrali, contratti o casi legali a metà del costo dei concorrenti.",
  "anthropic/claude-3-opus.description": "Claude 3 Opus è il modello più intelligente di Anthropic, con prestazioni leader di mercato in compiti altamente complessi, gestendo prompt aperti e scenari inediti con eccezionale fluidità e comprensione simile a quella umana.",
  "anthropic/claude-3.5-haiku.description": "Claude 3.5 Haiku offre velocità migliorata, accuratezza nel codice e uso degli strumenti, adatto a scenari con requisiti elevati di velocità e interazione con strumenti.",
  "anthropic/claude-3.5-sonnet.description": "Claude 3.5 Sonnet è il modello veloce ed efficiente della famiglia Sonnet, con migliori prestazioni in codifica e ragionamento; alcune versioni sono gradualmente sostituite da Sonnet 3.7 e successivi.",
  "anthropic/claude-3.7-sonnet.description": "Claude 3.7 Sonnet è un modello Sonnet aggiornato con ragionamento e codifica potenziati, adatto a compiti complessi di livello aziendale.",
  "anthropic/claude-haiku-4.5.description": "Claude Haiku 4.5 è il modello veloce ad alte prestazioni di Anthropic, con latenza molto bassa e alta accuratezza.",
  "anthropic/claude-opus-4.1.description": "Opus 4.1 è il modello di fascia alta di Anthropic, ottimizzato per programmazione, ragionamento complesso e compiti di lunga durata.",
  "anthropic/claude-opus-4.5.description": "Claude Opus 4.5 è il modello di punta di Anthropic, che combina intelligenza di alto livello con prestazioni scalabili per compiti complessi e ragionamento di alta qualità.",
  "anthropic/claude-opus-4.description": "Opus 4 è il modello di punta di Anthropic, progettato per compiti complessi e applicazioni aziendali.",
  "anthropic/claude-sonnet-4.5.description": "Claude Sonnet 4.5 è l'ultimo modello di ragionamento ibrido di Anthropic, ottimizzato per ragionamento complesso e codifica.",
  "anthropic/claude-sonnet-4.description": "Claude Sonnet 4 è il modello di ragionamento ibrido di Anthropic con capacità miste di pensiero e non-pensiero.",
  "ascend-tribe/pangu-pro-moe.description": "Pangu-Pro-MoE 72B-A16B è un LLM sparso con 72 miliardi di parametri totali e 16 miliardi attivi, basato su un'architettura MoE raggruppata (MoGE). Raggruppa gli esperti durante la selezione e vincola i token ad attivare un numero uguale di esperti per gruppo, bilanciando il carico e migliorando l'efficienza di distribuzione su Ascend.",
  "aya.description": "Aya 23 è il modello multilingue di Cohere che supporta 23 lingue per casi d'uso diversificati.",
  "aya:35b.description": "Aya 23 è il modello multilingue di Cohere che supporta 23 lingue per casi d'uso diversificati.",
  "azure-DeepSeek-R1-0528.description": "Distribuito da Microsoft; DeepSeek R1 è stato aggiornato a DeepSeek-R1-0528. L'aggiornamento aumenta la potenza di calcolo e le ottimizzazioni post-addestramento, migliorando significativamente la profondità di ragionamento e l'inferenza. Ottiene ottimi risultati in matematica, programmazione e logica generale, avvicinandosi a modelli leader come O3 e Gemini 2.5 Pro.",
  "baichuan-m2-32b.description": "Baichuan M2 32B è un modello MoE di Baichuan Intelligence con forte capacità di ragionamento.",
  "baichuan/baichuan2-13b-chat.description": "Baichuan-13B è un LLM open-source e commercialmente utilizzabile con 13 miliardi di parametri, che ottiene risultati di riferimento eccellenti per la sua dimensione su benchmark autorevoli in cinese e inglese.",
  "baidu/ERNIE-4.5-300B-A47B.description": "ERNIE-4.5-300B-A47B è un LLM MoE di Baidu con 300 miliardi di parametri totali e 47 miliardi attivi per token, che bilancia prestazioni elevate ed efficienza computazionale. Come modello centrale di ERNIE 4.5, eccelle in comprensione, generazione, ragionamento e programmazione. Utilizza un metodo di pre-addestramento multimodale eterogeneo MoE con addestramento congiunto testo-visione per potenziare le capacità generali, in particolare nel seguire istruzioni e nella conoscenza del mondo.",
  "baidu/ernie-5.0-thinking-preview.description": "ERNIE 5.0 Thinking Preview è il modello ERNIE multimodale nativo di nuova generazione di Baidu, forte nella comprensione multimodale, nel seguire istruzioni, nella creazione, nelle domande e risposte fattuali e nell'uso di strumenti.",
  "black-forest-labs/flux-1.1-pro.description": "FLUX 1.1 Pro è una versione più veloce e migliorata di FLUX Pro con eccellente qualità delle immagini e aderenza ai prompt.",
  "black-forest-labs/flux-dev.description": "FLUX Dev è la versione di sviluppo di FLUX per uso non commerciale.",
  "black-forest-labs/flux-pro.description": "FLUX Pro è il modello FLUX professionale per output di immagini di alta qualità.",
  "black-forest-labs/flux-schnell.description": "FLUX Schnell è un modello di generazione immagini veloce ottimizzato per la rapidità.",
  "c4ai-aya-expanse-32b.description": "Aya Expanse è un modello multilingue ad alte prestazioni da 32B che utilizza l'istruction tuning, l'arbitraggio dei dati, l'addestramento basato sulle preferenze e la fusione di modelli per competere con i modelli monolingue. Supporta 23 lingue.",
  "c4ai-aya-expanse-8b.description": "Aya Expanse è un modello multilingue ad alte prestazioni da 8B che utilizza l'istruction tuning, l'arbitraggio dei dati, l'addestramento basato sulle preferenze e la fusione di modelli per competere con i modelli monolingue. Supporta 23 lingue.",
  "c4ai-aya-vision-32b.description": "Aya Vision è un modello multimodale all'avanguardia che offre prestazioni eccellenti nei principali benchmark di linguaggio, testo e visione. Supporta 23 lingue. Questa versione da 32B è focalizzata su prestazioni multilingue di livello superiore.",
  "c4ai-aya-vision-8b.description": "Aya Vision è un modello multimodale all'avanguardia che offre prestazioni eccellenti nei principali benchmark di linguaggio, testo e visione. Questa versione da 8B è ottimizzata per bassa latenza e prestazioni elevate.",
  "charglm-3.description": "CharGLM-3 è progettato per il gioco di ruolo e la compagnia emotiva, supportando una memoria multi-turno ultra-lunga e dialoghi personalizzati.",
  "charglm-4.description": "CharGLM-4 è progettato per il gioco di ruolo e la compagnia emotiva, supportando una memoria multi-turno ultra-lunga e dialoghi personalizzati.",
  "chatgpt-4o-latest.description": "ChatGPT-4o è un modello dinamico aggiornato in tempo reale, che combina comprensione e generazione avanzate per casi d'uso su larga scala come assistenza clienti, istruzione e supporto tecnico.",
  "claude-2.0.description": "Claude 2 introduce miglioramenti chiave per le imprese, tra cui un contesto leader da 200.000 token, riduzione delle allucinazioni, prompt di sistema e una nuova funzione di test: chiamata agli strumenti.",
  "claude-2.1.description": "Claude 2 introduce miglioramenti chiave per le imprese, tra cui un contesto leader da 200.000 token, riduzione delle allucinazioni, prompt di sistema e una nuova funzione di test: chiamata agli strumenti.",
  "claude-3-5-haiku-20241022.description": "Claude 3.5 Haiku è il modello di nuova generazione più veloce di Anthropic. Rispetto a Claude 3 Haiku, migliora in tutte le competenze e supera il precedente modello di punta Claude 3 Opus in molti benchmark di intelligenza.",
  "claude-3-5-haiku-latest.description": "Claude 3.5 Haiku fornisce risposte rapide per attività leggere.",
  "claude-3-7-sonnet-20250219.description": "Claude 3.7 Sonnet è il modello più intelligente di Anthropic e il primo modello di ragionamento ibrido sul mercato. È in grado di fornire risposte quasi istantanee o ragionamenti estesi passo dopo passo visibili all’utente. Sonnet eccelle in particolare nella programmazione, data science, visione artificiale e compiti per agenti.",
  "claude-3-7-sonnet-latest.description": "Claude 3.7 Sonnet è il modello più recente e avanzato di Anthropic per compiti altamente complessi, eccellendo in prestazioni, intelligenza, fluidità e comprensione.",
  "claude-3-haiku-20240307.description": "Claude 3 Haiku è il modello più veloce e compatto di Anthropic, progettato per risposte quasi istantanee con prestazioni rapide e accurate.",
  "claude-3-opus-20240229.description": "Claude 3 Opus è il modello più potente di Anthropic per compiti altamente complessi, eccellendo in prestazioni, intelligenza, fluidità e comprensione.",
  "claude-3-sonnet-20240229.description": "Claude 3 Sonnet bilancia intelligenza e velocità per carichi di lavoro aziendali, offrendo alta utilità a costi inferiori e distribuzione affidabile su larga scala.",
  "claude-haiku-4-5-20251001.description": "Claude Haiku 4.5 è il modello Haiku più veloce e intelligente di Anthropic, con una velocità fulminea e capacità di ragionamento estese.",
  "claude-opus-4-1-20250805-thinking.description": "Claude Opus 4.1 Thinking è una variante avanzata in grado di mostrare il proprio processo di ragionamento.",
  "claude-opus-4-1-20250805.description": "Claude Opus 4.1 è il modello più recente e potente di Anthropic per compiti altamente complessi, eccellendo in prestazioni, intelligenza, fluidità e comprensione.",
  "claude-opus-4-20250514.description": "Claude Opus 4 è il modello più potente di Anthropic per compiti altamente complessi, eccellendo in prestazioni, intelligenza, fluidità e comprensione.",
  "claude-opus-4-5-20251101.description": "Claude Opus 4.5 è il modello di punta di Anthropic, che combina intelligenza eccezionale e prestazioni scalabili, ideale per compiti complessi che richiedono risposte e ragionamenti di altissima qualità.",
  "claude-sonnet-4-20250514-thinking.description": "Claude Sonnet 4 Thinking può produrre risposte quasi istantanee o riflessioni estese passo dopo passo con processo visibile.",
  "claude-sonnet-4-20250514.description": "Claude Sonnet 4 è in grado di fornire risposte quasi istantanee o ragionamenti estesi passo dopo passo con un processo visibile.",
  "claude-sonnet-4-5-20250929.description": "Claude Sonnet 4.5 è il modello più intelligente di Anthropic fino ad oggi.",
  "codegeex-4.description": "CodeGeeX-4 è un potente assistente di codifica AI che supporta Q&A multilingue e completamento del codice per aumentare la produttività degli sviluppatori.",
  "codegeex4-all-9b.description": "CodeGeeX4-ALL-9B è un modello multilingue di generazione di codice che supporta completamento e generazione di codice, interprete di codice, ricerca web, chiamata di funzioni e Q&A a livello di repository, coprendo un'ampia gamma di scenari di sviluppo software. È un modello di codice di alto livello con meno di 10B parametri.",
  "codegemma.description": "CodeGemma è un modello leggero per compiti di programmazione vari, che consente iterazioni rapide e facile integrazione.",
  "codegemma:2b.description": "CodeGemma è un modello leggero per compiti di programmazione vari, che consente iterazioni rapide e facile integrazione.",
  "codellama.description": "Code Llama è un LLM focalizzato sulla generazione e discussione di codice, con ampio supporto linguistico per i flussi di lavoro degli sviluppatori.",
  "codellama/CodeLlama-34b-Instruct-hf.description": "Code Llama è un LLM focalizzato sulla generazione e discussione di codice, con ampio supporto linguistico per i flussi di lavoro degli sviluppatori.",
  "codellama:13b.description": "Code Llama è un LLM focalizzato sulla generazione e discussione di codice, con ampio supporto linguistico per i flussi di lavoro degli sviluppatori.",
  "codellama:34b.description": "Code Llama è un LLM focalizzato sulla generazione e discussione di codice, con ampio supporto linguistico per i flussi di lavoro degli sviluppatori.",
  "codellama:70b.description": "Code Llama è un LLM focalizzato sulla generazione e discussione di codice, con ampio supporto linguistico per i flussi di lavoro degli sviluppatori.",
  "codeqwen.description": "CodeQwen1.5 è un modello linguistico di grandi dimensioni addestrato su un ampio set di dati di codice, progettato per compiti di programmazione complessi.",
  "codestral-latest.description": "Codestral è il nostro modello di codifica più avanzato; la versione v2 (gennaio 2025) è pensata per compiti a bassa latenza e alta frequenza come FIM, correzione del codice e generazione di test.",
  "codestral.description": "Codestral è il primo modello di codice di Mistral AI, che offre un forte supporto alla generazione di codice.",
  "codex-mini-latest.description": "codex-mini-latest è un modello o4-mini ottimizzato per Codex CLI. Per l'uso diretto via API, si consiglia di iniziare con gpt-4.1.",
  "cogito-2.1:671b.description": "Cogito v2.1 671B è un LLM open-source statunitense gratuito per uso commerciale, con prestazioni paragonabili ai modelli di punta, maggiore efficienza nel ragionamento sui token, contesto lungo da 128k e capacità complessive elevate.",
  "cogview-4.description": "CogView-4 è il primo modello open-source di testo-immagine di Zhipu in grado di generare caratteri cinesi. Migliora la comprensione semantica, la qualità delle immagini e la resa del testo in cinese/inglese, supporta prompt bilingue di lunghezza arbitraria e può generare immagini a qualsiasi risoluzione entro intervalli specificati.",
  "cohere-command-r-plus.description": "Command R+ è un modello avanzato ottimizzato per RAG, progettato per carichi di lavoro aziendali.",
  "cohere-command-r.description": "Command R è un modello generativo scalabile progettato per RAG e l'uso di strumenti, abilitando AI di livello produttivo.",
  "cohere/Cohere-command-r-plus.description": "Command R+ è un modello avanzato ottimizzato per RAG, progettato per carichi di lavoro aziendali.",
  "cohere/Cohere-command-r.description": "Command R è un modello generativo scalabile progettato per RAG e l'uso di strumenti, abilitando AI di livello produttivo.",
  "cohere/command-a.description": "Command A è il modello più potente di Cohere, eccellente nell'uso di strumenti, agenti, RAG e scenari multilingue. Ha una finestra di contesto da 256K, funziona con solo due GPU e offre una produttività superiore del 150% rispetto a Command R+ 08-2024.",
  "cohere/command-r-plus.description": "Command R+ è l'ultimo LLM di Cohere ottimizzato per chat e contesto lungo, con prestazioni eccezionali per passare dai prototipi alla produzione.",
  "cohere/command-r.description": "Command R è ottimizzato per chat e compiti a contesto lungo, posizionato come modello \"scalabile\" che bilancia alte prestazioni e precisione per passare dai prototipi alla produzione.",
  "cohere/embed-v4.0.description": "Un modello che classifica o converte testo, immagini o contenuti misti in embedding.",
  "comfyui/flux-dev.description": "FLUX.1 Dev è un modello testo-immagine di alta qualità (10–50 passaggi), ideale per output creativi e artistici di livello premium.",
  "comfyui/flux-kontext-dev.description": "FLUX.1 Kontext-dev è un modello di editing immagini che supporta modifiche guidate da testo, inclusi ritocchi locali e trasferimento di stile.",
  "comfyui/flux-krea-dev.description": "FLUX.1 Krea-dev è un modello testo-immagine con filtri di sicurezza integrati, sviluppato in collaborazione con Krea.",
  "comfyui/flux-schnell.description": "FLUX.1 Schnell è un modello testo-immagine ultra-veloce che genera immagini di alta qualità in 1-4 passaggi, ideale per uso in tempo reale e prototipazione rapida.",
  "comfyui/stable-diffusion-15.description": "Stable Diffusion 1.5 è un classico modello testo-immagine 512x512, ideale per prototipazione rapida ed esperimenti creativi.",
  "comfyui/stable-diffusion-35-inclclip.description": "Stable Diffusion 3.5 con encoder CLIP/T5 integrati non richiede file encoder esterni, adatto a modelli come sd3.5_medium_incl_clips con uso ridotto di risorse.",
  "comfyui/stable-diffusion-35.description": "Stable Diffusion 3.5 è un modello testo-immagine di nuova generazione con varianti Large e Medium. Richiede file encoder CLIP esterni e offre eccellente qualità d'immagine e aderenza ai prompt.",
  "comfyui/stable-diffusion-custom-refiner.description": "Modello personalizzato SDXL immagine-a-immagine. Usa custom_sd_lobe.safetensors come nome file del modello; se hai un VAE, usa custom_sd_vae_lobe.safetensors. Inserisci i file modello nelle cartelle richieste da Comfy.",
  "comfyui/stable-diffusion-custom.description": "Modello personalizzato SD testo-a-immagine. Usa custom_sd_lobe.safetensors come nome file del modello; se hai un VAE, usa custom_sd_vae_lobe.safetensors. Inserisci i file modello nelle cartelle richieste da Comfy.",
  "comfyui/stable-diffusion-refiner.description": "Modello SDXL immagine-a-immagine che esegue trasformazioni di alta qualità da immagini in input, supportando trasferimento di stile, restauro e variazioni creative.",
  "comfyui/stable-diffusion-xl.description": "SDXL è un modello testo-immagine che supporta generazione ad alta risoluzione 1024x1024 con migliore qualità e dettaglio visivo.",
  "command-a-03-2025.description": "Command A è il nostro modello più avanzato, eccellente nell'uso di strumenti, agenti, RAG e scenari multilingue. Ha una finestra di contesto di 256K, funziona con solo due GPU e offre una produttività superiore del 150% rispetto a Command R+ 08-2024.",
  "command-light-nightly.description": "Per ridurre il tempo tra le versioni principali, offriamo build notturne di Command. Per la serie command-light si chiama command-light-nightly. È la versione più recente ed esperimentale (potenzialmente instabile), aggiornata regolarmente senza preavviso, quindi non è consigliata per ambienti di produzione.",
  "command-light.description": "Una variante Command più piccola e veloce, quasi altrettanto capace ma più rapida.",
  "command-nightly.description": "Per ridurre il tempo tra le versioni principali, offriamo build notturne di Command. Per la serie Command si chiama command-nightly. È la versione più recente ed esperimentale (potenzialmente instabile), aggiornata regolarmente senza preavviso, quindi non è consigliata per ambienti di produzione.",
  "command-r-03-2024.description": "Command R è un modello di chat che segue istruzioni, con qualità superiore, maggiore affidabilità e una finestra di contesto più lunga rispetto ai modelli precedenti. Supporta flussi di lavoro complessi come generazione di codice, RAG, uso di strumenti e agenti.",
  "command-r-08-2024.description": "command-r-08-2024 è una versione aggiornata del modello Command R rilasciata ad agosto 2024.",
  "command-r-plus-04-2024.description": "command-r-plus è un alias di command-r-plus-04-2024, quindi usare command-r-plus nell'API punta a quel modello.",
  "command-r-plus-08-2024.description": "Command R+ è un modello di chat che segue istruzioni, con qualità superiore, maggiore affidabilità e una finestra di contesto più lunga rispetto ai modelli precedenti. È ideale per flussi di lavoro RAG complessi e uso multi-step di strumenti.",
  "command-r-plus.description": "Command R+ è un LLM ad alte prestazioni progettato per scenari aziendali reali e applicazioni complesse.",
  "command-r.description": "Command R è un LLM ottimizzato per chat e compiti a lungo contesto, ideale per interazioni dinamiche e gestione della conoscenza.",
  "command-r7b-12-2024.description": "command-r7b-12-2024 è un aggiornamento piccolo ed efficiente rilasciato a dicembre 2024. Eccelle in RAG, uso di strumenti e compiti per agenti che richiedono ragionamento complesso multi-step.",
  "command.description": "Un modello di chat che segue istruzioni, offrendo maggiore qualità e affidabilità nei compiti linguistici, con una finestra di contesto più lunga rispetto ai nostri modelli generativi base.",
  "computer-use-preview.description": "computer-use-preview è un modello specializzato per lo strumento \"uso del computer\", addestrato per comprendere ed eseguire compiti legati al computer.",
  "dall-e-2.description": "Modello DALL·E di seconda generazione con generazione di immagini più realistica e accurata e risoluzione 4× rispetto alla prima generazione.",
  "dall-e-3.description": "L'ultimo modello DALL·E, rilasciato a novembre 2023, supporta generazione di immagini più realistica e accurata con maggiore dettaglio.",
  "databricks/dbrx-instruct.description": "DBRX Instruct offre una gestione delle istruzioni altamente affidabile in diversi settori.",
  "deepseek-ai/DeepSeek-OCR.description": "DeepSeek-OCR è un modello visione-linguaggio sviluppato da DeepSeek AI, focalizzato sull'OCR e sulla \"compressione ottica contestuale\". Esplora la compressione del contesto dalle immagini, elabora documenti in modo efficiente e li converte in testo strutturato (es. Markdown). Riconosce accuratamente il testo nelle immagini, ideale per la digitalizzazione di documenti, l'estrazione di testo e l'elaborazione strutturata.",
  "deepseek-ai/DeepSeek-R1-0528-Qwen3-8B.description": "DeepSeek-R1-0528-Qwen3-8B distilla il chain-of-thought da DeepSeek-R1-0528 nel modello Qwen3 8B Base. Raggiunge lo stato dell'arte tra i modelli open-source, superando Qwen3 8B del 10% su AIME 2024 e uguagliando le prestazioni di Qwen3-235B-thinking. Eccelle nel ragionamento matematico, nella programmazione e nei benchmark di logica generale. Condivide l'architettura di Qwen3-8B ma utilizza il tokenizer di DeepSeek-R1-0528.",
  "deepseek-ai/DeepSeek-R1-0528.description": "DeepSeek R1 sfrutta maggiore potenza computazionale e ottimizzazioni algoritmiche post-addestramento per approfondire il ragionamento. Ottiene ottimi risultati nei benchmark di matematica, programmazione e logica generale, avvicinandosi a modelli leader come o3 e Gemini 2.5 Pro.",
  "deepseek-ai/DeepSeek-R1-Distill-Llama-70B.description": "I modelli distillati DeepSeek-R1 utilizzano apprendimento per rinforzo (RL) e dati cold-start per migliorare il ragionamento e stabilire nuovi benchmark multi-task per modelli open-source.",
  "deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B.description": "I modelli distillati DeepSeek-R1 utilizzano apprendimento per rinforzo (RL) e dati cold-start per migliorare il ragionamento e stabilire nuovi benchmark multi-task per modelli open-source.",
  "deepseek-ai/DeepSeek-R1-Distill-Qwen-14B.description": "I modelli distillati DeepSeek-R1 utilizzano apprendimento per rinforzo (RL) e dati cold-start per migliorare il ragionamento e stabilire nuovi benchmark multi-task per modelli open-source.",
  "deepseek-ai/DeepSeek-R1-Distill-Qwen-32B.description": "DeepSeek-R1-Distill-Qwen-32B è distillato da Qwen2.5-32B e ottimizzato su 800.000 campioni curati da DeepSeek-R1. Eccelle in matematica, programmazione e ragionamento, ottenendo risultati eccellenti su AIME 2024, MATH-500 (94,3% di accuratezza) e GPQA Diamond.",
  "deepseek-ai/DeepSeek-R1-Distill-Qwen-7B.description": "DeepSeek-R1-Distill-Qwen-7B è distillato da Qwen2.5-Math-7B e ottimizzato su 800.000 campioni curati da DeepSeek-R1. Ottiene ottime prestazioni: 92,8% su MATH-500, 55,5% su AIME 2024 e un punteggio CodeForces di 1189 per un modello da 7B.",
  "deepseek-ai/DeepSeek-R1.description": "DeepSeek-R1 migliora il ragionamento grazie a dati cold-start e apprendimento per rinforzo, stabilendo nuovi benchmark multi-task per modelli open-source e superando OpenAI-o1-mini.",
  "deepseek-ai/DeepSeek-V2.5.description": "DeepSeek-V2.5 aggiorna DeepSeek-V2-Chat e DeepSeek-Coder-V2-Instruct, combinando capacità generali e di programmazione. Migliora la scrittura e il rispetto delle istruzioni per un migliore allineamento alle preferenze, con progressi significativi su AlpacaEval 2.0, ArenaHard, AlignBench e MT-Bench.",
  "deepseek-ai/DeepSeek-V3.1-Terminus.description": "DeepSeek-V3.1-Terminus è una versione aggiornata del modello V3.1, concepito come agente ibrido LLM. Risolve problemi segnalati dagli utenti e migliora stabilità, coerenza linguistica e riduce caratteri anomali o misti cinese/inglese. Integra modalità di pensiero e non-pensiero con template di chat per passaggi flessibili. Migliora anche le prestazioni di Code Agent e Search Agent per un uso più affidabile degli strumenti e compiti multi-step.",
  "deepseek-ai/DeepSeek-V3.1.description": "DeepSeek V3.1 utilizza un'architettura di ragionamento ibrida e supporta sia modalità di pensiero che non-pensiero.",
  "deepseek-ai/DeepSeek-V3.2-Exp.description": "DeepSeek-V3.2-Exp è una versione sperimentale della serie V3.2 che fa da ponte verso la prossima architettura. Aggiunge DeepSeek Sparse Attention (DSA) sopra V3.1-Terminus per migliorare l'efficienza nell'addestramento e inferenza su contesti lunghi, con ottimizzazioni per l'uso di strumenti, comprensione di documenti lunghi e ragionamento multi-step. Ideale per esplorare una maggiore efficienza di ragionamento con budget di contesto estesi.",
  "deepseek-ai/DeepSeek-V3.description": "DeepSeek-V3 è un modello MoE con 671 miliardi di parametri che utilizza MLA e DeepSeekMoE con bilanciamento del carico senza perdite per un addestramento e inferenza efficienti. Preaddestrato su 14,8 trilioni di token di alta qualità con SFT e RL, supera altri modelli open-source e si avvicina ai modelli chiusi leader.",
  "deepseek-ai/deepseek-llm-67b-chat.description": "DeepSeek LLM Chat (67B) è un modello innovativo che offre una profonda comprensione linguistica e interazione.",
  "deepseek-ai/deepseek-r1.description": "Un modello LLM all'avanguardia, efficiente e potente nel ragionamento, matematica e programmazione.",
  "deepseek-ai/deepseek-v3.1-terminus.description": "DeepSeek V3.1 è un modello di nuova generazione per il ragionamento, con capacità avanzate di ragionamento complesso e chain-of-thought per compiti di analisi approfondita.",
  "deepseek-ai/deepseek-v3.1.description": "DeepSeek V3.1 è un modello di nuova generazione per il ragionamento, con capacità avanzate di ragionamento complesso e chain-of-thought per compiti di analisi approfondita.",
  "deepseek-ai/deepseek-vl2.description": "DeepSeek-VL2 è un modello visione-linguaggio MoE basato su DeepSeekMoE-27B con attivazione sparsa, che raggiunge prestazioni elevate con solo 4,5B di parametri attivi. Eccelle in QA visivo, OCR, comprensione di documenti/tabelle/grafici e grounding visivo.",
  "deepseek-chat.description": "Un nuovo modello open-source che combina capacità generali e di programmazione. Mantiene la capacità di dialogo del modello conversazionale e la potenza di codifica del modello per sviluppatori, con un migliore allineamento alle preferenze. DeepSeek-V2.5 migliora anche la scrittura e la comprensione delle istruzioni.",
  "deepseek-coder-33B-instruct.description": "DeepSeek Coder 33B è un modello linguistico per il codice addestrato su 2 trilioni di token (87% codice, 13% testo in cinese/inglese). Introduce una finestra di contesto da 16K e compiti di completamento intermedio, offrendo completamento di codice a livello di progetto e riempimento di snippet.",
  "deepseek-coder-v2.description": "DeepSeek Coder V2 è un modello MoE open-source per il codice che ottiene ottimi risultati nei compiti di programmazione, comparabile a GPT-4 Turbo.",
  "deepseek-coder-v2:236b.description": "DeepSeek Coder V2 è un modello MoE open-source per il codice che ottiene ottimi risultati nei compiti di programmazione, comparabile a GPT-4 Turbo.",
  "deepseek-ocr.description": "DeepSeek-OCR è un modello visione-linguaggio sviluppato da DeepSeek AI, focalizzato sull'OCR e sulla \"compressione ottica contestuale\". Esplora la compressione delle informazioni contestuali dalle immagini, elabora documenti in modo efficiente e li converte in formati di testo strutturato come Markdown. Riconosce accuratamente il testo nelle immagini, rendendolo ideale per la digitalizzazione di documenti, l'estrazione di testo e l'elaborazione strutturata.",
  "deepseek-r1-0528.description": "Modello completo da 685B rilasciato il 28/05/2025. DeepSeek-R1 utilizza RL su larga scala nel post-addestramento, migliorando notevolmente il ragionamento con dati etichettati minimi, ottenendo ottimi risultati in matematica, programmazione e ragionamento in linguaggio naturale.",
  "deepseek-r1-250528.description": "DeepSeek R1 250528 è il modello completo di ragionamento DeepSeek-R1 per compiti complessi di matematica e logica.",
  "deepseek-r1-70b-fast-online.description": "DeepSeek R1 70B edizione veloce con ricerca web in tempo reale, che fornisce risposte più rapide mantenendo alte prestazioni.",
  "deepseek-r1-70b-online.description": "DeepSeek R1 70B edizione standard con ricerca web in tempo reale, adatta per chat aggiornate e compiti testuali.",
  "deepseek-r1-distill-llama-70b.description": "DeepSeek R1 Distill Llama 70B combina il ragionamento R1 con l'ecosistema Llama.",
  "deepseek-r1-distill-llama-8b.description": "DeepSeek-R1-Distill-Llama-8B è distillato da Llama-3.1-8B utilizzando gli output di DeepSeek R1.",
  "deepseek-r1-distill-llama.description": "deepseek-r1-distill-llama è distillato da DeepSeek-R1 su Llama.",
  "deepseek-r1-distill-qianfan-70b.description": "DeepSeek R1 Distill Qianfan 70B è una distillazione R1 basata su Qianfan-70B con elevato valore.",
  "deepseek-r1-distill-qianfan-8b.description": "DeepSeek R1 Distill Qianfan 8B è una distillazione R1 basata su Qianfan-8B per applicazioni di piccole e medie dimensioni.",
  "deepseek-r1-distill-qianfan-llama-70b.description": "DeepSeek R1 Distill Qianfan Llama 70B è una distillazione R1 basata su Llama-70B.",
  "deepseek-r1-distill-qwen-1.5b.description": "DeepSeek R1 Distill Qwen 1.5B è un modello distillato ultra-leggero per ambienti con risorse molto limitate.",
  "deepseek-r1-distill-qwen-14b.description": "DeepSeek R1 Distill Qwen 14B è un modello distillato di medie dimensioni per implementazioni in scenari multipli.",
  "deepseek-r1-distill-qwen-32b.description": "DeepSeek R1 Distill Qwen 32B è una distillazione R1 basata su Qwen-32B, che bilancia prestazioni e costi.",
  "deepseek-r1-distill-qwen-7b.description": "DeepSeek R1 Distill Qwen 7B è un modello distillato leggero per ambienti edge e aziendali privati.",
  "deepseek-r1-distill-qwen.description": "deepseek-r1-distill-qwen è distillato da DeepSeek-R1 su Qwen.",
  "deepseek-r1-fast-online.description": "DeepSeek R1 versione completa veloce con ricerca web in tempo reale, che combina capacità su scala 671B e risposte rapide.",
  "deepseek-r1-online.description": "DeepSeek R1 versione completa con 671 miliardi di parametri e ricerca web in tempo reale, che offre una comprensione e generazione più avanzate.",
  "deepseek-r1.description": "DeepSeek-R1 utilizza dati cold-start prima dell'RL e ottiene prestazioni comparabili a OpenAI-o1 in matematica, programmazione e ragionamento.",
  "deepseek-reasoner.description": "La modalità di pensiero DeepSeek V3.2 produce una catena di ragionamenti prima della risposta finale per migliorare l'accuratezza.",
  "deepseek-v2.description": "DeepSeek V2 è un modello MoE efficiente per un'elaborazione conveniente.",
  "deepseek-v2:236b.description": "DeepSeek V2 236B è il modello DeepSeek focalizzato sul codice con forte capacità di generazione.",
  "deepseek-v3-0324.description": "DeepSeek-V3-0324 è un modello MoE con 671 miliardi di parametri, con punti di forza nella programmazione, capacità tecnica, comprensione del contesto e gestione di testi lunghi.",
  "deepseek-v3.1-terminus.description": "DeepSeek-V3.1-Terminus è un LLM ottimizzato per terminali, sviluppato da DeepSeek e progettato specificamente per dispositivi a riga di comando.",
  "deepseek-v3.1-think-250821.description": "DeepSeek V3.1 Think 250821 è il modello di pensiero profondo corrispondente alla versione Terminus, costruito per un ragionamento ad alte prestazioni.",
  "deepseek-v3.1.description": "DeepSeek-V3.1 è un nuovo modello di ragionamento ibrido di DeepSeek, che supporta modalità di pensiero e non-pensiero, offrendo un'efficienza di pensiero superiore rispetto a DeepSeek-R1-0528. Le ottimizzazioni post-addestramento migliorano notevolmente l'uso degli strumenti da parte degli agenti e le prestazioni nei compiti. Supporta una finestra di contesto di 128k e fino a 64k token in output.",
  "deepseek-v3.1:671b.description": "DeepSeek V3.1 è un modello di ragionamento di nuova generazione con capacità avanzate di ragionamento complesso e catene di pensiero, ideale per compiti che richiedono analisi approfondite.",
  "deepseek-v3.2-exp.description": "deepseek-v3.2-exp introduce l'attenzione sparsa per migliorare l'efficienza di addestramento e inferenza su testi lunghi, a un costo inferiore rispetto a deepseek-v3.1.",
  "deepseek-v3.2-think.description": "DeepSeek V3.2 Think è un modello completo di pensiero profondo con capacità potenziate di ragionamento a catena lunga.",
  "deepseek-v3.2.description": "DeepSeek-V3.2 è il primo modello ibrido di ragionamento di DeepSeek che integra il pensiero nell'uso degli strumenti. Utilizza un'architettura efficiente per ridurre il calcolo, l'apprendimento per rinforzo su larga scala per potenziare le capacità e dati sintetici su larga scala per rafforzare la generalizzazione. La combinazione di questi tre elementi consente prestazioni paragonabili a GPT-5-High, con una lunghezza di output significativamente ridotta, diminuendo notevolmente il carico computazionale e i tempi di attesa per l'utente.",
  "deepseek-v3.description": "DeepSeek-V3 è un potente modello MoE con 671 miliardi di parametri totali e 37 miliardi attivi per token.",
  "deepseek-vl2-small.description": "DeepSeek VL2 Small è una versione multimodale leggera, pensata per ambienti con risorse limitate e alta concorrenza.",
  "deepseek-vl2.description": "DeepSeek VL2 è un modello multimodale per la comprensione immagine-testo e domande visive dettagliate.",
  "deepseek/deepseek-chat-v3-0324.description": "DeepSeek V3 è un modello MoE da 685 miliardi di parametri e rappresenta l'ultima iterazione della serie di chat di punta di DeepSeek.\n\nSi basa su [DeepSeek V3](/deepseek/deepseek-chat-v3) e offre prestazioni elevate in vari compiti.",
  "deepseek/deepseek-chat-v3-0324:free.description": "DeepSeek V3 è un modello MoE da 685 miliardi di parametri e rappresenta l'ultima iterazione della serie di chat di punta di DeepSeek.\n\nSi basa su [DeepSeek V3](/deepseek/deepseek-chat-v3) e offre prestazioni elevate in vari compiti.",
  "deepseek/deepseek-chat-v3.1.description": "DeepSeek-V3.1 è il modello di ragionamento ibrido a lungo contesto di DeepSeek, che supporta modalità miste di pensiero/non-pensiero e integrazione con strumenti.",
  "deepseek/deepseek-chat.description": "DeepSeek-V3 è il modello di ragionamento ibrido ad alte prestazioni di DeepSeek, progettato per compiti complessi e integrazione con strumenti.",
  "deepseek/deepseek-math-v2.description": "DeepSeek Math V2 è un modello che ha compiuto importanti progressi nelle capacità di ragionamento matematico. La sua innovazione principale risiede nel meccanismo di addestramento \"auto-verifica\" e ha raggiunto livelli da medaglia d'oro in diverse competizioni matematiche di alto livello.",
  "deepseek/deepseek-r1-0528.description": "DeepSeek R1 0528 è una variante aggiornata focalizzata sulla disponibilità aperta e su un ragionamento più profondo.",
  "deepseek/deepseek-r1-0528:free.description": "DeepSeek-R1 migliora notevolmente il ragionamento utilizzando un numero minimo di dati etichettati e genera una catena di pensiero prima della risposta finale per aumentare l'accuratezza.",
  "deepseek/deepseek-r1-distill-llama-70b.description": "DeepSeek R1 Distill Llama 70B è un LLM distillato basato su Llama 3.3 70B, ottimizzato utilizzando gli output di DeepSeek R1 per raggiungere prestazioni competitive con i modelli di frontiera di grandi dimensioni.",
  "deepseek/deepseek-r1-distill-llama-8b.description": "DeepSeek R1 Distill Llama 8B è un LLM distillato basato su Llama-3.1-8B-Instruct, addestrato utilizzando gli output di DeepSeek R1.",
  "deepseek/deepseek-r1-distill-qwen-14b.description": "DeepSeek R1 Distill Qwen 14B è un LLM distillato basato su Qwen 2.5 14B, addestrato utilizzando gli output di DeepSeek R1. Supera OpenAI o1-mini in diversi benchmark, raggiungendo risultati all'avanguardia tra i modelli densi. Risultati salienti:\nAIME 2024 pass@1: 69.7\nMATH-500 pass@1: 93.9\nCodeForces Rating: 1481\nIl fine-tuning sugli output di DeepSeek R1 garantisce prestazioni competitive con i modelli di frontiera più grandi.",
  "deepseek/deepseek-r1-distill-qwen-32b.description": "DeepSeek R1 Distill Qwen 32B è un LLM distillato basato su Qwen 2.5 32B, addestrato utilizzando gli output di DeepSeek R1. Supera OpenAI o1-mini in diversi benchmark, raggiungendo risultati all'avanguardia tra i modelli densi. Risultati salienti:\nAIME 2024 pass@1: 72.6\nMATH-500 pass@1: 94.3\nCodeForces Rating: 1691\nIl fine-tuning sugli output di DeepSeek R1 garantisce prestazioni competitive con i modelli di frontiera più grandi.",
  "deepseek/deepseek-r1.description": "DeepSeek R1 è stato aggiornato a DeepSeek-R1-0528. Con maggiore potenza computazionale e ottimizzazioni algoritmiche post-addestramento, migliora significativamente la profondità e la capacità di ragionamento. Offre prestazioni elevate in benchmark di matematica, programmazione e logica generale, avvicinandosi a leader come o3 e Gemini 2.5 Pro.",
  "deepseek/deepseek-r1/community.description": "DeepSeek R1 è l'ultimo modello open-source rilasciato dal team DeepSeek, con prestazioni di ragionamento molto elevate, in particolare in matematica, programmazione e compiti logici, comparabili a OpenAI o1.",
  "deepseek/deepseek-r1:free.description": "DeepSeek-R1 migliora notevolmente il ragionamento utilizzando un numero minimo di dati etichettati e genera una catena di pensiero prima della risposta finale per aumentare l'accuratezza.",
  "deepseek/deepseek-reasoner.description": "DeepSeek-V3 Thinking (reasoner) è il modello sperimentale di ragionamento di DeepSeek, adatto a compiti di alta complessità.",
  "deepseek/deepseek-v3.1-base.description": "DeepSeek V3.1 Base è una versione migliorata del modello DeepSeek V3.",
  "deepseek/deepseek-v3.description": "Un LLM veloce e generico con capacità di ragionamento potenziate.",
  "deepseek/deepseek-v3/community.description": "DeepSeek-V3 rappresenta un importante progresso nella velocità di ragionamento rispetto ai modelli precedenti. Si posiziona al primo posto tra i modelli open-source e rivaleggia con i modelli chiusi più avanzati. DeepSeek-V3 adotta l'attenzione latente multi-testa (MLA) e l'architettura DeepSeekMoE, entrambe validate in DeepSeek-V2. Introduce inoltre una strategia ausiliaria lossless per il bilanciamento del carico e un obiettivo di addestramento con previsione multi-token per prestazioni superiori.",
  "deepseek_r1.description": "DeepSeek-R1 è un modello di ragionamento guidato dall'apprendimento per rinforzo che affronta problemi di ripetizione e leggibilità. Prima dell'RL, utilizza dati di avvio a freddo per migliorare ulteriormente le prestazioni di ragionamento. È comparabile a OpenAI-o1 in matematica, programmazione e compiti logici, con un addestramento attentamente progettato che migliora i risultati complessivi.",
  "deepseek_r1_distill_llama_70b.description": "DeepSeek-R1-Distill-Llama-70B è distillato da Llama-3.3-70B-Instruct. Fa parte della serie DeepSeek-R1, è ottimizzato su campioni generati da DeepSeek-R1 e offre prestazioni elevate in matematica, programmazione e ragionamento.",
  "deepseek_r1_distill_qwen_14b.description": "DeepSeek-R1-Distill-Qwen-14B è distillato da Qwen2.5-14B e ottimizzato su 800.000 campioni curati generati da DeepSeek-R1, offrendo un ragionamento solido.",
  "deepseek_r1_distill_qwen_32b.description": "DeepSeek-R1-Distill-Qwen-32B è distillato da Qwen2.5-32B e ottimizzato su 800.000 campioni curati generati da DeepSeek-R1, eccellendo in matematica, programmazione e ragionamento.",
  "devstral-2:123b.description": "Devstral 2 123B eccelle nell'utilizzo di strumenti per esplorare basi di codice, modificare più file e supportare agenti di ingegneria del software.",
  "doubao-1.5-lite-32k.description": "Doubao-1.5-lite è un nuovo modello leggero con risposta ultra-rapida, che offre qualità e latenza di livello superiore.",
  "doubao-1.5-pro-256k.description": "Doubao-1.5-pro-256k è un aggiornamento completo di Doubao-1.5-Pro, con un miglioramento delle prestazioni complessive del 10%. Supporta una finestra contestuale di 256k e fino a 12k token in output, offrendo prestazioni superiori, una finestra più ampia e un ottimo rapporto qualità-prezzo per casi d'uso più ampi.",
  "doubao-1.5-pro-32k.description": "Doubao-1.5-pro è un modello di punta di nuova generazione con miglioramenti su tutta la linea, eccellente in conoscenza, programmazione e ragionamento.",
  "doubao-1.5-thinking-pro-m.description": "Doubao-1.5 è un nuovo modello di ragionamento profondo (la versione m include ragionamento profondo multimodale nativo) che eccelle in matematica, programmazione, ragionamento scientifico e compiti generali come la scrittura creativa. Raggiunge o si avvicina ai migliori risultati nei benchmark come AIME 2024, Codeforces e GPQA. Supporta una finestra contestuale di 128k e 16k token in output.",
  "doubao-1.5-thinking-pro.description": "Doubao-1.5 è un nuovo modello di ragionamento profondo che eccelle in matematica, programmazione, ragionamento scientifico e compiti generali come la scrittura creativa. Raggiunge o si avvicina ai migliori risultati nei benchmark come AIME 2024, Codeforces e GPQA. Supporta una finestra contestuale di 128k e 16k token in output.",
  "doubao-1.5-thinking-vision-pro.description": "Un nuovo modello visivo di ragionamento profondo con una comprensione e un ragionamento multimodale più avanzati, che raggiunge risultati SOTA in 37 su 59 benchmark pubblici.",
  "doubao-1.5-ui-tars.description": "Doubao-1.5-UI-TARS è un modello agente nativo focalizzato sulle interfacce grafiche, che interagisce in modo fluido con le interfacce attraverso percezione, ragionamento e azione simili a quelle umane.",
  "doubao-1.5-vision-lite.description": "Doubao-1.5-vision-lite è un modello multimodale aggiornato che supporta immagini a qualsiasi risoluzione e con rapporti d'aspetto estremi, migliorando il ragionamento visivo, il riconoscimento di documenti, la comprensione dei dettagli e il rispetto delle istruzioni. Supporta una finestra contestuale di 128k e fino a 16k token in output.",
  "doubao-1.5-vision-pro-32k.description": "Doubao-1.5-vision-pro è un modello multimodale aggiornato che supporta immagini a qualsiasi risoluzione e con rapporti d'aspetto estremi, migliorando il ragionamento visivo, il riconoscimento di documenti, la comprensione dei dettagli e il rispetto delle istruzioni.",
  "doubao-1.5-vision-pro.description": "Doubao-1.5-vision-pro è un modello multimodale aggiornato che supporta immagini a qualsiasi risoluzione e con rapporti d'aspetto estremi, migliorando il ragionamento visivo, il riconoscimento di documenti, la comprensione dei dettagli e il rispetto delle istruzioni.",
  "doubao-lite-128k.description": "Risposta ultra-rapida con un miglior rapporto qualità-prezzo, offrendo scelte più flessibili in diversi scenari. Supporta ragionamento e fine-tuning con una finestra contestuale di 128k.",
  "doubao-lite-32k.description": "Risposta ultra-rapida con un miglior rapporto qualità-prezzo, offrendo scelte più flessibili in diversi scenari. Supporta ragionamento e fine-tuning con una finestra contestuale di 32k.",
  "doubao-lite-4k.description": "Risposta ultra-rapida con un miglior rapporto qualità-prezzo, offrendo scelte più flessibili in diversi scenari. Supporta ragionamento e fine-tuning con una finestra contestuale di 4k.",
  "doubao-pro-256k.description": "Il modello di punta con le migliori prestazioni per compiti complessi, con risultati eccellenti in QA con riferimento, riassunti, creazione, classificazione del testo e simulazione di ruoli. Supporta ragionamento e fine-tuning con una finestra contestuale di 256k.",
  "doubao-pro-32k.description": "Il modello di punta con le migliori prestazioni per compiti complessi, con risultati eccellenti in QA con riferimento, riassunti, creazione, classificazione del testo e simulazione di ruoli. Supporta ragionamento e fine-tuning con una finestra contestuale di 32k.",
  "doubao-seed-1.6-flash.description": "Doubao-Seed-1.6-flash è un modello multimodale di ragionamento profondo ultra-rapido con TPOT fino a 10ms. Supporta testo e visione, supera il precedente modello lite nella comprensione del testo e si equipara ai modelli pro concorrenti nella visione. Supporta una finestra contestuale di 256k e fino a 16k token in output.",
  "doubao-seed-1.6-lite.description": "Doubao-Seed-1.6-lite è un nuovo modello multimodale di ragionamento profondo con sforzo di ragionamento regolabile (Minimo, Basso, Medio, Alto), che offre un miglior rapporto qualità-prezzo ed è una scelta solida per compiti comuni, con una finestra contestuale fino a 256k.",
  "doubao-seed-1.6-thinking.description": "Doubao-Seed-1.6 potenzia significativamente il ragionamento, migliorando ulteriormente le capacità fondamentali in programmazione, matematica e logica rispetto a Doubao-1.5-thinking-pro, aggiungendo anche la comprensione visiva. Supporta una finestra contestuale di 256k e fino a 16k token in output.",
  "doubao-seed-1.6-vision.description": "Doubao-Seed-1.6-vision è un modello visivo di ragionamento profondo che offre una comprensione e un ragionamento multimodale più forti per l'istruzione, la revisione di immagini, l'ispezione/sicurezza e la ricerca AI con domande e risposte. Supporta una finestra contestuale di 256k e fino a 64k token in output.",
  "doubao-seed-1.6.description": "Doubao-Seed-1.6 è un nuovo modello multimodale di ragionamento profondo con modalità auto, thinking e non-thinking. In modalità non-thinking, supera significativamente Doubao-1.5-pro/250115. Supporta una finestra contestuale di 256k e fino a 16k token in output.",
  "doubao-seed-1.8.description": "Doubao-Seed-1.8 offre una comprensione multimodale più avanzata e capacità da agente, supporta input di testo/immagine/video e memorizzazione del contesto, garantendo prestazioni eccellenti in compiti complessi.",
  "doubao-seed-code.description": "Doubao-Seed-Code è ottimizzato in profondità per la programmazione agentica, supporta input multimodali (testo/immagine/video) e una finestra contestuale di 256k, è compatibile con l'API Anthropic ed è adatto a flussi di lavoro di programmazione, comprensione visiva e agenti.",
  "doubao-seededit-3-0-i2i-250628.description": "Il modello di immagini Doubao di ByteDance Seed supporta input di testo e immagini con generazione di immagini di alta qualità e altamente controllabile. Supporta l'editing di immagini guidato da testo, con dimensioni di output tra 512 e 1536 sul lato lungo.",
  "doubao-seedream-3-0-t2i-250415.description": "Seedream 3.0 è un modello di generazione di immagini di ByteDance Seed, che supporta input di testo e immagini con generazione di immagini di alta qualità e altamente controllabile. Genera immagini da prompt testuali.",
  "doubao-seedream-4-0-250828.description": "Seedream 4.0 è un modello di generazione di immagini di ByteDance Seed, che supporta input di testo e immagini con generazione di immagini di alta qualità e altamente controllabile. Genera immagini da prompt testuali.",
  "doubao-vision-lite-32k.description": "Doubao-vision è un modello multimodale di Doubao con forte comprensione e ragionamento visivo, oltre a un'accurata esecuzione delle istruzioni. Eccelle in compiti di estrazione immagine-testo e ragionamento basato su immagini, abilitando scenari di QA visivo più complessi e ampi.",
  "doubao-vision-pro-32k.description": "Doubao-vision è un modello multimodale di Doubao con forte comprensione e ragionamento visivo, oltre a un'accurata esecuzione delle istruzioni. Eccelle in compiti di estrazione immagine-testo e ragionamento basato su immagini, abilitando scenari di QA visivo più complessi e ampi.",
  "emohaa.description": "Emohaa è un modello per la salute mentale con capacità di consulenza professionale per aiutare gli utenti a comprendere le problematiche emotive.",
  "ernie-4.5-0.3b.description": "ERNIE 4.5 0.3B è un modello open-source leggero per implementazioni locali e personalizzate.",
  "ernie-4.5-21b-a3b.description": "ERNIE 4.5 21B A3B è un modello open-source con un numero elevato di parametri e una maggiore capacità di comprensione e generazione.",
  "ernie-4.5-300b-a47b.description": "ERNIE 4.5 300B A47B è il modello MoE ultra-large di Baidu ERNIE con eccellenti capacità di ragionamento.",
  "ernie-4.5-8k-preview.description": "ERNIE 4.5 8K Preview è un modello di anteprima con finestra contestuale da 8K per la valutazione di ERNIE 4.5.",
  "ernie-4.5-turbo-128k-preview.description": "Anteprima di ERNIE 4.5 Turbo 128K con capacità di livello release, adatto per integrazione e test canary.",
  "ernie-4.5-turbo-128k.description": "ERNIE 4.5 Turbo 128K è un modello generale ad alte prestazioni con supporto alla ricerca e chiamata di strumenti per QA, programmazione e scenari agentici.",
  "ernie-4.5-turbo-32k.description": "ERNIE 4.5 Turbo 32K è una versione con contesto medio per QA, recupero da base di conoscenza e dialoghi multi-turno.",
  "ernie-4.5-turbo-latest.description": "Ultima versione di ERNIE 4.5 Turbo con prestazioni ottimizzate, ideale come modello principale in produzione.",
  "ernie-4.5-turbo-vl-32k-preview.description": "ERNIE 4.5 Turbo VL 32K Preview è un modello multimodale di anteprima da 32K per valutare la capacità visiva su contesti lunghi.",
  "ernie-4.5-turbo-vl-32k.description": "ERNIE 4.5 Turbo VL 32K è una versione multimodale medio-lunga per la comprensione combinata di documenti lunghi e immagini.",
  "ernie-4.5-turbo-vl-latest.description": "ERNIE 4.5 Turbo VL Latest è la versione multimodale più recente con migliorata comprensione e ragionamento immagine-testo.",
  "ernie-4.5-turbo-vl-preview.description": "ERNIE 4.5 Turbo VL Preview è un modello multimodale di anteprima per comprensione e generazione immagine-testo, adatto a QA visivo e comprensione dei contenuti.",
  "ernie-4.5-turbo-vl.description": "ERNIE 4.5 Turbo VL è un modello multimodale maturo per la comprensione e il riconoscimento immagine-testo in produzione.",
  "ernie-4.5-vl-28b-a3b.description": "ERNIE 4.5 VL 28B A3B è un modello multimodale open-source per la comprensione e il ragionamento immagine-testo.",
  "ernie-5.0-thinking-latest.description": "Wenxin 5.0 Thinking è un modello di punta nativo full-modal con modellazione unificata di testo, immagini, audio e video. Offre ampi miglioramenti nelle capacità per domande complesse, creazione e scenari con agenti.",
  "ernie-5.0-thinking-preview.description": "Wenxin 5.0 Thinking Preview è un modello di punta nativo full-modal con modellazione unificata di testo, immagini, audio e video. Offre ampi miglioramenti nelle capacità per domande complesse, creazione e scenari con agenti.",
  "ernie-char-8k.description": "ERNIE Character 8K è un modello di dialogo con personalità per la creazione di personaggi IP e conversazioni di compagnia a lungo termine.",
  "ernie-char-fiction-8k-preview.description": "ERNIE Character Fiction 8K Preview è un’anteprima del modello per la creazione di personaggi e trame, utile per valutazioni e test di funzionalità.",
  "ernie-char-fiction-8k.description": "ERNIE Character Fiction 8K è un modello con personalità per romanzi e creazione di trame, adatto alla generazione di storie di lunga durata.",
  "ernie-irag-edit.description": "ERNIE iRAG Edit è un modello per l’editing di immagini che supporta cancellazione, ritocco e generazione di varianti.",
  "ernie-lite-8k.description": "ERNIE Lite 8K è un modello generale leggero per domande e risposte quotidiane e generazione di contenuti sensibili ai costi.",
  "ernie-lite-pro-128k.description": "ERNIE Lite Pro 128K è un modello leggero ad alte prestazioni per scenari sensibili a latenza e costi.",
  "ernie-novel-8k.description": "ERNIE Novel 8K è progettato per romanzi lunghi e trame IP con narrazioni multi-personaggio.",
  "ernie-speed-128k.description": "ERNIE Speed 128K è un modello senza costi di I/O per la comprensione di testi lunghi e prove su larga scala.",
  "ernie-speed-8k.description": "ERNIE Speed 8K è un modello gratuito e veloce per chat quotidiane e compiti testuali leggeri.",
  "ernie-speed-pro-128k.description": "ERNIE Speed Pro 128K è un modello ad alto valore e alta concorrenza per servizi online su larga scala e applicazioni aziendali.",
  "ernie-tiny-8k.description": "ERNIE Tiny 8K è un modello ultra-leggero per domande semplici, classificazione e inferenza a basso costo.",
  "ernie-x1-turbo-32k.description": "ERNIE X1 Turbo 32K è un modello di pensiero veloce con contesto da 32K per ragionamento complesso e chat multi-turno.",
  "ernie-x1.1-preview.description": "ERNIE X1.1 Preview è un’anteprima del modello di pensiero per valutazioni e test.",
  "fal-ai/bytedance/seedream/v4.description": "Seedream 4.0 è un modello di generazione di immagini di ByteDance Seed, che supporta input testuali e visivi con generazione di immagini di alta qualità e altamente controllabile. Genera immagini a partire da prompt testuali.",
  "fal-ai/flux-kontext/dev.description": "FLUX.1 è un modello focalizzato sull’editing di immagini, che supporta input di testo e immagini.",
  "fal-ai/flux-pro/kontext.description": "FLUX.1 Kontext [pro] accetta testo e immagini di riferimento come input, consentendo modifiche locali mirate e trasformazioni complesse della scena globale.",
  "fal-ai/flux/krea.description": "Flux Krea [dev] è un modello di generazione di immagini con una preferenza estetica per immagini più realistiche e naturali.",
  "fal-ai/flux/schnell.description": "FLUX.1 [schnell] è un modello di generazione di immagini con 12 miliardi di parametri progettato per output rapidi e di alta qualità.",
  "fal-ai/hunyuan-image/v3.description": "Un potente modello nativo multimodale per la generazione di immagini.",
  "fal-ai/imagen4/preview.description": "Modello di generazione di immagini di alta qualità sviluppato da Google.",
  "fal-ai/nano-banana.description": "Nano Banana è il modello multimodale nativo più recente, veloce ed efficiente di Google, che consente la generazione e l’editing di immagini tramite conversazione.",
  "fal-ai/qwen-image-edit.description": "Un modello professionale di editing di immagini del team Qwen che supporta modifiche semantiche e visive, modifica con precisione testi in cinese e inglese, e consente modifiche di alta qualità come trasferimento di stile e rotazione di oggetti.",
  "fal-ai/qwen-image.description": "Un potente modello di generazione di immagini del team Qwen con una resa impressionante del testo cinese e stili visivi diversificati.",
  "flux-1-schnell.description": "Modello testo-immagine da 12 miliardi di parametri di Black Forest Labs che utilizza la distillazione latente avversariale per generare immagini di alta qualità in 1-4 passaggi. Con licenza Apache-2.0 per uso personale, di ricerca e commerciale.",
  "flux-dev.description": "FLUX.1 [dev] è un modello distillato a pesi aperti per uso non commerciale. Mantiene una qualità d’immagine quasi professionale e capacità di seguire istruzioni, con maggiore efficienza rispetto ai modelli standard di pari dimensioni.",
  "flux-kontext-max.description": "Generazione ed editing di immagini contestuali all’avanguardia, combinando testo e immagini per risultati precisi e coerenti.",
  "flux-kontext-pro.description": "Generazione ed editing di immagini contestuali all’avanguardia, combinando testo e immagini per risultati precisi e coerenti.",
  "flux-merged.description": "FLUX.1-merged combina le funzionalità approfondite esplorate in \"DEV\" con i vantaggi di velocità di \"Schnell\", estendendo i limiti delle prestazioni e ampliando le applicazioni.",
  "flux-pro-1.1-ultra.description": "Generazione di immagini ad altissima risoluzione con output da 4MP, producendo immagini nitide in 10 secondi.",
  "flux-pro-1.1.description": "Modello aggiornato di generazione di immagini di livello professionale con eccellente qualità visiva e aderenza precisa ai prompt.",
  "flux-pro.description": "Modello commerciale di generazione di immagini di fascia alta con qualità visiva impareggiabile e output diversificati.",
  "flux-schnell.description": "FLUX.1 [schnell] è il modello open-source più avanzato a pochi passaggi, superiore a concorrenti simili e persino a modelli non distillati come Midjourney v6.0 e DALL-E 3 (HD). Ottimizzato per preservare la diversità del pretraining, migliora notevolmente la qualità visiva, il rispetto delle istruzioni, la variazione di dimensioni/aspetto, la gestione dei font e la diversità degli output.",
  "flux.1-schnell.description": "FLUX.1-schnell è un modello ad alte prestazioni per la generazione di immagini rapide in più stili.",
  "gemini-1.0-pro-001.description": "Gemini 1.0 Pro 001 (Tuning) offre prestazioni stabili e regolabili per compiti complessi.",
  "gemini-1.0-pro-002.description": "Gemini 1.0 Pro 002 (Tuning) fornisce un forte supporto multimodale per compiti complessi.",
  "gemini-1.0-pro-latest.description": "Gemini 1.0 Pro è il modello AI ad alte prestazioni di Google progettato per l’esecuzione su larga scala di compiti generali.",
  "gemini-1.5-flash-001.description": "Gemini 1.5 Flash 001 è un modello multimodale efficiente per l’implementazione su larga scala.",
  "gemini-1.5-flash-002.description": "Gemini 1.5 Flash 002 è un modello multimodale efficiente progettato per una distribuzione estesa.",
  "gemini-1.5-flash-8b-exp-0924.description": "Gemini 1.5 Flash 8B 0924 è il più recente modello sperimentale con miglioramenti significativi nei casi d’uso testuali e multimodali.",
  "gemini-1.5-flash-8b-latest.description": "Gemini 1.5 Flash 8B è un modello multimodale efficiente progettato per una distribuzione estesa.",
  "gemini-1.5-flash-8b.description": "Gemini 1.5 Flash 8B è un modello multimodale efficiente per l’implementazione su larga scala.",
  "gemini-1.5-flash-exp-0827.description": "Gemini 1.5 Flash 0827 offre un’elaborazione multimodale ottimizzata per compiti complessi.",
  "gemini-1.5-flash-latest.description": "Gemini 1.5 Flash è l’ultimo modello AI multimodale di Google con elaborazione rapida, supporto per input testuali, visivi e video, ideale per l’esecuzione efficiente di compiti su larga scala.",
  "gemini-1.5-pro-001.description": "Gemini 1.5 Pro 001 è una soluzione AI multimodale scalabile per compiti complessi.",
  "gemini-1.5-pro-002.description": "Gemini 1.5 Pro 002 è l’ultima versione pronta per la produzione con output di qualità superiore, in particolare per matematica, contesti lunghi e compiti visivi.",
  "gemini-1.5-pro-exp-0801.description": "Gemini 1.5 Pro 0801 offre un’elaborazione multimodale avanzata con maggiore flessibilità per lo sviluppo di applicazioni.",
  "gemini-1.5-pro-exp-0827.description": "Gemini 1.5 Pro 0827 applica le ultime ottimizzazioni per un’elaborazione multimodale più efficiente.",
  "gemini-1.5-pro-latest.description": "Gemini 1.5 Pro supporta fino a 2 milioni di token, un modello multimodale di medie dimensioni ideale per compiti complessi.",
  "gemini-2.0-flash-001.description": "Gemini 2.0 Flash offre funzionalità di nuova generazione tra cui velocità eccezionale, uso nativo di strumenti, generazione multimodale e una finestra di contesto da 1 milione di token.",
  "gemini-2.0-flash-exp-image-generation.description": "Modello sperimentale Gemini 2.0 Flash con supporto alla generazione di immagini.",
  "gemini-2.0-flash-exp.description": "Una variante di Gemini 2.0 Flash ottimizzata per efficienza dei costi e bassa latenza.",
  "gemini-2.0-flash-lite-001.description": "Una variante di Gemini 2.0 Flash ottimizzata per efficienza dei costi e bassa latenza.",
  "gemini-2.0-flash-lite.description": "Una variante di Gemini 2.0 Flash ottimizzata per efficienza dei costi e bassa latenza.",
  "gemini-2.0-flash.description": "Gemini 2.0 Flash offre funzionalità di nuova generazione tra cui velocità eccezionale, uso nativo di strumenti, generazione multimodale e una finestra di contesto da 1 milione di token.",
  "gemini-2.5-flash-image-preview.description": "Nano Banana è il più recente, veloce ed efficiente modello multimodale nativo di Google, che consente la generazione e modifica di immagini in conversazione.",
  "gemini-2.5-flash-image-preview:image.description": "Nano Banana è il più recente, veloce ed efficiente modello multimodale nativo di Google, che consente la generazione e modifica di immagini in conversazione.",
  "gemini-2.5-flash-image.description": "Nano Banana è il più recente, veloce ed efficiente modello multimodale nativo di Google, che consente la generazione e modifica di immagini in conversazione.",
  "gemini-2.5-flash-image:image.description": "Nano Banana è il più recente, veloce ed efficiente modello multimodale nativo di Google, che consente la generazione e modifica di immagini in conversazione.",
  "gemini-2.5-flash-lite-preview-06-17.description": "Gemini 2.5 Flash-Lite Preview è il modello più piccolo e conveniente di Google, progettato per l’uso su larga scala.",
  "gemini-2.5-flash-lite-preview-09-2025.description": "Versione di anteprima (25 settembre 2025) di Gemini 2.5 Flash-Lite",
  "gemini-2.5-flash-lite.description": "Gemini 2.5 Flash-Lite è il modello più piccolo e conveniente di Google, progettato per l’uso su larga scala.",
  "gemini-2.5-flash-preview-04-17.description": "Gemini 2.5 Flash Preview è il modello più conveniente di Google con funzionalità complete.",
  "gemini-2.5-flash-preview-09-2025.description": "Versione di anteprima (25 settembre 2025) di Gemini 2.5 Flash",
  "gemini-2.5-flash.description": "Gemini 2.5 Flash è il modello più conveniente di Google con funzionalità complete.",
  "gemini-2.5-pro-preview-03-25.description": "Gemini 2.5 Pro Preview è il modello di ragionamento più avanzato di Google, in grado di ragionare su codice, matematica e problemi STEM, e analizzare grandi dataset, basi di codice e documenti con contesto esteso.",
  "gemini-2.5-pro-preview-05-06.description": "Gemini 2.5 Pro Preview è il modello di ragionamento più avanzato di Google, in grado di ragionare su codice, matematica e problemi STEM, e analizzare grandi dataset, basi di codice e documenti con contesto esteso.",
  "gemini-2.5-pro-preview-06-05.description": "Gemini 2.5 Pro Preview è il modello di ragionamento più avanzato di Google, in grado di ragionare su codice, matematica e problemi STEM, e analizzare grandi dataset, basi di codice e documenti con contesto esteso.",
  "gemini-2.5-pro.description": "Gemini 2.5 Pro è il modello di ragionamento più avanzato di Google, in grado di ragionare su codice, matematica e problemi STEM, e analizzare grandi dataset, basi di codice e documenti con contesto esteso.",
  "gemini-3-flash-preview.description": "Gemini 3 Flash è il modello più intelligente progettato per la velocità, che combina intelligenza all'avanguardia con un eccellente ancoraggio alla ricerca.",
  "gemini-3-pro-image-preview.description": "Gemini 3 Pro Image (Nano Banana Pro) è il modello di generazione di immagini di Google, che supporta anche la conversazione multimodale.",
  "gemini-3-pro-image-preview:image.description": "Gemini 3 Pro Image (Nano Banana Pro) è il modello di generazione di immagini di Google e supporta anche la chat multimodale.",
  "gemini-3-pro-preview.description": "Gemini 3 Pro è il modello più potente di Google per agenti e codifica creativa, offrendo visuali più ricche e interazioni più profonde grazie a un ragionamento all'avanguardia.",
  "gemini-flash-latest.description": "Ultima versione di Gemini Flash",
  "gemini-flash-lite-latest.description": "Ultima versione di Gemini Flash-Lite",
  "gemini-pro-latest.description": "Ultima versione di Gemini Pro",
  "gemma-7b-it.description": "Gemma 7B è conveniente per compiti di piccola e media scala.",
  "gemma2-9b-it.description": "Gemma 2 9B è ottimizzato per compiti specifici e integrazione con strumenti.",
  "gemma2.description": "Gemma 2 è il modello efficiente di Google, adatto a casi d'uso che vanno da app leggere a elaborazioni dati complesse.",
  "gemma2:27b.description": "Gemma 2 è il modello efficiente di Google, adatto a casi d'uso che vanno da app leggere a elaborazioni dati complesse.",
  "gemma2:2b.description": "Gemma 2 è il modello efficiente di Google, adatto a casi d'uso che vanno da app leggere a elaborazioni dati complesse.",
  "generalv3.5.description": "Spark Max è la versione più completa, con supporto alla ricerca web e numerosi plugin integrati. Le sue capacità ottimizzate, i ruoli di sistema e le chiamate di funzione offrono prestazioni eccellenti in scenari applicativi complessi.",
  "generalv3.description": "Spark Pro è un LLM ad alte prestazioni ottimizzato per ambiti professionali, con focus su matematica, programmazione, sanità ed educazione. Supporta la ricerca web e plugin integrati come meteo e data. Offre prestazioni elevate e grande efficienza in Q&A complessi, comprensione linguistica e creazione avanzata di testi, rendendolo ideale per usi professionali.",
  "glm-4-0520.description": "GLM-4-0520 è l'ultima versione del modello, progettata per compiti altamente complessi e diversificati con prestazioni eccellenti.",
  "glm-4-32b-0414.description": "GLM-4 32B 0414 è un modello GLM generale che supporta generazione e comprensione di testo multi-task.",
  "glm-4-9b-chat.description": "GLM-4-9B-Chat offre prestazioni elevate in semantica, matematica, ragionamento, codice e conoscenza. Supporta anche navigazione web, esecuzione di codice, chiamate a strumenti personalizzati e ragionamento su testi lunghi, con supporto per 26 lingue tra cui giapponese, coreano e tedesco.",
  "glm-4-air-250414.description": "GLM-4-Air è un'opzione ad alto valore con prestazioni vicine a GLM-4, velocità elevata e costi ridotti.",
  "glm-4-air.description": "GLM-4-Air è un'opzione ad alto valore con prestazioni vicine a GLM-4, velocità elevata e costi ridotti.",
  "glm-4-airx.description": "GLM-4-AirX è una variante più efficiente di GLM-4-Air con ragionamento fino a 2,6 volte più veloce.",
  "glm-4-alltools.description": "GLM-4-AllTools è un modello agente versatile ottimizzato per la pianificazione di istruzioni complesse e l'uso di strumenti come navigazione web, spiegazione di codice e generazione di testo, adatto all'esecuzione multi-task.",
  "glm-4-flash-250414.description": "GLM-4-Flash è ideale per compiti semplici: il più veloce e gratuito.",
  "glm-4-flash.description": "GLM-4-Flash è ideale per compiti semplici: il più veloce e gratuito.",
  "glm-4-flashx.description": "GLM-4-FlashX è una versione Flash potenziata con ragionamento ultra-rapido.",
  "glm-4-long.description": "GLM-4-Long supporta input ultra-lunghi per compiti di tipo memoria e l'elaborazione di documenti su larga scala.",
  "glm-4-plus.description": "GLM-4-Plus è un modello di punta ad alta intelligenza con forte gestione di testi lunghi e compiti complessi, e prestazioni complessive migliorate.",
  "glm-4.1v-thinking-flash.description": "GLM-4.1V-Thinking è il più potente VLM da ~10B noto, coprendo compiti SOTA come comprensione video, QA su immagini, risoluzione di problemi, OCR, lettura di documenti e grafici, agenti GUI, codifica frontend e grounding. Supera persino Qwen2.5-VL-72B, 8 volte più grande, in molti compiti. Con RL avanzato, utilizza il ragionamento a catena per migliorare accuratezza e ricchezza, superando i modelli tradizionali non pensanti sia nei risultati che nella spiegabilità.",
  "glm-4.1v-thinking-flashx.description": "GLM-4.1V-Thinking è il più potente VLM da ~10B noto, coprendo compiti SOTA come comprensione video, QA su immagini, risoluzione di problemi, OCR, lettura di documenti e grafici, agenti GUI, codifica frontend e grounding. Supera persino Qwen2.5-VL-72B, 8 volte più grande, in molti compiti. Con RL avanzato, utilizza il ragionamento a catena per migliorare accuratezza e ricchezza, superando i modelli tradizionali non pensanti sia nei risultati che nella spiegabilità.",
  "glm-4.5-air.description": "Edizione leggera di GLM-4.5 che bilancia prestazioni e costi, con modalità di pensiero ibride flessibili.",
  "glm-4.5-airx.description": "Edizione veloce di GLM-4.5-Air con risposte più rapide per usi ad alta scala e velocità.",
  "glm-4.5-flash.description": "Livello gratuito di GLM-4.5 con prestazioni elevate in ragionamento, programmazione e compiti da agente.",
  "glm-4.5-x.description": "Edizione veloce di GLM-4.5, con prestazioni elevate e velocità di generazione fino a 100 token/sec.",
  "glm-4.5.description": "Modello di punta di Zhipu con modalità di pensiero commutabile, che offre SOTA open-source complessivo e fino a 128K di contesto.",
  "glm-4.5v.description": "Il modello di ragionamento visivo di nuova generazione MoE di Zhipu ha 106B parametri totali con 12B attivi, raggiungendo SOTA tra i modelli multimodali open-source di dimensioni simili in compiti su immagini, video, documenti e GUI.",
  "meta.llama3-8b-instruct-v1:0.description": "Meta Llama 3 è un LLM open-source pensato per sviluppatori, ricercatori e aziende, progettato per supportare la creazione, la sperimentazione e la scalabilità responsabile di idee basate su IA generativa. Parte integrante dell’ecosistema globale per l’innovazione comunitaria, è ideale per ambienti con risorse limitate, dispositivi edge e tempi di addestramento ridotti.",
  "meta/Llama-3.2-11B-Vision-Instruct.description": "Solido ragionamento visivo su immagini ad alta risoluzione, ideale per applicazioni di comprensione visiva.",
  "meta/Llama-3.2-90B-Vision-Instruct.description": "Ragionamento visivo avanzato per applicazioni agenti di comprensione visiva.",
  "meta/Llama-3.3-70B-Instruct.description": "Llama 3.3 è il modello Llama open-source multilingue più avanzato, con prestazioni paragonabili a modelli da 405B a costi molto contenuti. Basato su architettura Transformer, è migliorato con SFT e RLHF per garantire utilità e sicurezza. La versione ottimizzata per istruzioni eccelle nelle chat multilingue e supera molti modelli, sia open che closed, nei benchmark di settore. Data di cutoff: dicembre 2023.",
  "meta/Meta-Llama-3-70B-Instruct.description": "Un potente modello da 70 miliardi di parametri eccellente nel ragionamento, nella programmazione e nei compiti linguistici generali.",
  "meta/Meta-Llama-3-8B-Instruct.description": "Un modello versatile da 8 miliardi di parametri ottimizzato per chat e generazione di testo.",
  "meta/Meta-Llama-3.1-405B-Instruct.description": "Modello Llama 3.1 ottimizzato per istruzioni, progettato per chat multilingue, con prestazioni elevate nei benchmark industriali tra modelli open e closed.",
  "meta/Meta-Llama-3.1-70B-Instruct.description": "Modello Llama 3.1 ottimizzato per istruzioni, progettato per chat multilingue, con prestazioni elevate nei benchmark industriali tra modelli open e closed.",
  "meta/Meta-Llama-3.1-8B-Instruct.description": "Modello Llama 3.1 ottimizzato per istruzioni, progettato per chat multilingue, con prestazioni elevate nei benchmark industriali tra modelli open e closed.",
  "meta/llama-3-70b.description": "Modello open-source da 70 miliardi di parametri, ottimizzato da Meta per seguire istruzioni, distribuito da Groq su hardware LPU per inferenza rapida ed efficiente.",
  "meta/llama-3-8b.description": "Modello open-source da 8 miliardi di parametri, ottimizzato da Meta per seguire istruzioni, distribuito da Groq su hardware LPU per inferenza rapida ed efficiente.",
  "meta/llama-3.1-405b-instruct.description": "Modello LLM avanzato che supporta generazione di dati sintetici, distillazione della conoscenza e ragionamento per chatbot, programmazione e compiti specifici di dominio.",
  "meta/llama-3.1-70b-instruct.description": "Progettato per dialoghi complessi con eccellente comprensione del contesto, ragionamento e generazione di testo.",
  "meta/llama-3.1-70b.description": "Versione aggiornata di Meta Llama 3 70B Instruct con contesto esteso a 128K, supporto multilingue e ragionamento migliorato.",
  "meta/llama-3.1-8b-instruct.description": "Modello all’avanguardia con solida comprensione linguistica, capacità di ragionamento e generazione di testo.",
  "meta/llama-3.1-8b.description": "Llama 3.1 8B supporta una finestra di contesto di 128K, ideale per chat in tempo reale e analisi dei dati, offrendo un notevole risparmio rispetto ai modelli più grandi. Distribuito da Groq su hardware LPU per inferenza rapida ed efficiente.",
  "meta/llama-3.2-11b-vision-instruct.description": "Modello linguistico-visivo di frontiera eccellente nel ragionamento di alta qualità a partire da immagini.",
  "meta/llama-3.2-11b.description": "Modello ottimizzato per istruzioni e ragionamento su immagini (input testo+immagine, output testo), ideale per riconoscimento visivo, ragionamento su immagini, didascalie e domande generali su immagini.",
  "meta/llama-3.2-1b-instruct.description": "Modello linguistico compatto e all’avanguardia con forte comprensione, ragionamento e generazione di testo.",
  "meta/llama-3.2-1b.description": "Modello solo testo per utilizzi su dispositivo come recupero locale multilingue, sintesi e riscrittura.",
  "meta/llama-3.2-3b-instruct.description": "Modello linguistico compatto e all’avanguardia con forte comprensione, ragionamento e generazione di testo.",
  "meta/llama-3.2-3b.description": "Modello solo testo ottimizzato per utilizzi su dispositivo come recupero locale multilingue, sintesi e riscrittura.",
  "meta/llama-3.2-90b-vision-instruct.description": "Modello linguistico-visivo di frontiera eccellente nel ragionamento di alta qualità a partire da immagini.",
  "meta/llama-3.2-90b.description": "Modello ottimizzato per istruzioni e ragionamento su immagini (input testo+immagine, output testo), ideale per riconoscimento visivo, ragionamento su immagini, didascalie e domande generali su immagini.",
  "meta/llama-3.3-70b-instruct.description": "LLM avanzato con solide capacità di ragionamento, matematica, buon senso e chiamata di funzioni.",
  "meta/llama-3.3-70b.description": "Un perfetto equilibrio tra prestazioni ed efficienza. Progettato per IA conversazionale ad alte prestazioni in creazione di contenuti, applicazioni aziendali e ricerca, con forte comprensione linguistica per sintesi, classificazione, analisi del sentiment e generazione di codice.",
  "meta/llama-4-maverick.description": "La famiglia Llama 4 è una serie di modelli AI nativamente multimodali che supportano esperienze testuali e multimodali, utilizzando MoE per una comprensione avanzata di testo e immagini. Llama 4 Maverick è un modello da 17B con 128 esperti, distribuito da DeepInfra.",
  "meta/llama-4-scout.description": "La famiglia Llama 4 è una serie di modelli AI nativamente multimodali che supportano esperienze testuali e multimodali, utilizzando MoE per una comprensione avanzata di testo e immagini. Llama 4 Scout è un modello da 17B con 16 esperti, distribuito da DeepInfra.",
  "microsoft/Phi-3-mini-4k-instruct.description": "Il membro più piccolo della famiglia Phi-3, ottimizzato per qualità e bassa latenza.",
  "microsoft/Phi-3-small-128k-instruct.description": "Lo stesso modello Phi-3-small con una finestra contestuale più ampia per RAG o prompt few-shot.",
  "microsoft/Phi-3-small-8k-instruct.description": "Un modello da 7 miliardi di parametri con qualità superiore rispetto a Phi-3-mini, focalizzato su dati di alta qualità e ad alta intensità di ragionamento.",
  "microsoft/Phi-3.5-mini-instruct.description": "Una versione aggiornata del modello Phi-3-mini.",
  "microsoft/Phi-3.5-vision-instruct.description": "Una versione aggiornata del modello Phi-3-vision.",
  "microsoft/WizardLM-2-8x22B.description": "WizardLM 2 è un modello linguistico di Microsoft AI eccellente nei dialoghi complessi, nei compiti multilingue, nel ragionamento e negli assistenti.",
  "microsoft/wizardlm-2-8x22b.description": "WizardLM-2 8x22B è il modello Wizard più avanzato di Microsoft AI, con prestazioni altamente competitive.",
  "minicpm-v.description": "MiniCPM-V è il modello multimodale di nuova generazione di OpenBMB, con eccellenti capacità OCR e comprensione multimodale per un'ampia gamma di casi d'uso.",
  "minimax/minimax-m2.description": "MiniMax-M2 è un modello ad alto valore che eccelle nella codifica e nei compiti per agenti in molti scenari ingegneristici.",
  "minimaxai/minimax-m2.description": "MiniMax-M2 è un modello MoE compatto, veloce ed economico (230B totali, 10B attivi) progettato per prestazioni di alto livello nella codifica e nei compiti per agenti, mantenendo una forte intelligenza generale. Eccelle in modifiche multi-file, cicli di esecuzione-correzione del codice, validazione dei test e catene di strumenti complesse.",
  "ministral-3b-latest.description": "Ministral 3B è il modello edge di punta di Mistral.",
  "ministral-8b-latest.description": "Ministral 8B è un modello edge altamente conveniente di Mistral.",
  "mistral-ai/Mistral-Large-2411.description": "Il modello di punta di Mistral per compiti complessi che richiedono ragionamento su larga scala o specializzazione (generazione di testo sintetico, generazione di codice, RAG o agenti).",
  "mistral-ai/Mistral-Nemo.description": "Mistral Nemo è un LLM all'avanguardia con ragionamento di alto livello, conoscenza del mondo e capacità di codifica per la sua dimensione.",
  "mistral-ai/mistral-small-2503.description": "Mistral Small è adatto a qualsiasi compito linguistico che richieda alta efficienza e bassa latenza.",
  "mistral-large-instruct.description": "Mistral-Large-Instruct-2407 è un LLM denso avanzato con 123 miliardi di parametri e ragionamento, conoscenza e codifica all'avanguardia.",
  "mistral-large-latest.description": "Mistral Large è il modello di punta, forte nei compiti multilingue, nel ragionamento complesso e nella generazione di codice—ideale per applicazioni di fascia alta.",
  "mistral-large.description": "Mixtral Large è il modello di punta di Mistral, che combina generazione di codice, matematica e ragionamento con una finestra contestuale di 128K.",
  "mistral-medium-latest.description": "Mistral Medium 3 offre prestazioni all'avanguardia a un costo 8× inferiore e semplifica l'implementazione aziendale.",
  "mistral-nemo-instruct.description": "Mistral-Nemo-Instruct-2407 è la versione ottimizzata per istruzioni di Mistral-Nemo-Base-2407.",
  "mistral-nemo.description": "Mistral Nemo è un modello da 12B ad alta efficienza di Mistral AI e NVIDIA.",
  "mistral-small-latest.description": "Mistral Small è un'opzione conveniente, veloce e affidabile per traduzione, sintesi e analisi del sentiment.",
  "mistral-small.description": "Mistral Small è adatto a qualsiasi compito linguistico che richieda alta efficienza e bassa latenza.",
  "mistral.description": "Mistral è il modello da 7B di Mistral AI, adatto a compiti linguistici vari.",
  "mistral/codestral-embed.description": "Un modello di embedding per codici, utile per indicizzare basi di codice e repository a supporto di assistenti alla programmazione.",
  "mistral/codestral.description": "Mistral Codestral 25.01 è un modello di codifica all'avanguardia ottimizzato per bassa latenza e uso ad alta frequenza. Supporta oltre 80 linguaggi e si distingue in FIM, correzione del codice e generazione di test.",
  "mistral/devstral-small.description": "Devstral è un LLM agentico per compiti di ingegneria del software, rendendolo una scelta solida per agenti software.",
  "mistral/magistral-medium.description": "Pensiero complesso supportato da una comprensione profonda con ragionamento trasparente che puoi seguire e verificare. Mantiene un ragionamento ad alta fedeltà tra le lingue, anche a metà compito.",
  "mistral/magistral-small.description": "Pensiero complesso supportato da una comprensione profonda con ragionamento trasparente che puoi seguire e verificare. Mantiene un ragionamento ad alta fedeltà tra le lingue, anche a metà compito.",
  "mistral/ministral-3b.description": "Un modello compatto ed efficiente per compiti on-device come assistenti e analisi locali, con prestazioni a bassa latenza.",
  "mistral/ministral-8b.description": "Un modello più potente con inferenza veloce ed efficiente in memoria, ideale per flussi di lavoro complessi e applicazioni edge esigenti.",
  "mistral/mistral-embed.description": "Un modello generale di embedding testuale per ricerca semantica, similarità, clustering e flussi di lavoro RAG.",
  "mistral/mistral-large.description": "Mistral Large è ideale per compiti complessi che richiedono forte ragionamento o specializzazione—generazione di testo sintetico, generazione di codice, RAG o agenti.",
  "mistral/mistral-small.description": "Mistral Small è ideale per compiti semplici e batchabili come classificazione, supporto clienti o generazione di testo, offrendo ottime prestazioni a un prezzo accessibile.",
  "mistral/mixtral-8x22b-instruct.description": "Modello Instruct 8x22B. 8x22B è un modello MoE open source servito da Mistral.",
  "mistral/pixtral-12b.description": "Un modello da 12B con comprensione delle immagini e testo.",
  "mistral/pixtral-large.description": "Pixtral Large è il secondo modello della nostra famiglia multimodale con comprensione delle immagini di livello avanzato. Gestisce documenti, grafici e immagini naturali mantenendo la comprensione testuale leader di Mistral Large 2.",
  "mistralai/Mistral-7B-Instruct-v0.1.description": "Mistral (7B) Instruct è noto per le forti prestazioni in molti compiti linguistici.",
  "mistralai/Mistral-7B-Instruct-v0.2.description": "Mistral (7B) Instruct v0.2 migliora la gestione delle istruzioni e l'accuratezza dei risultati.",
  "mistralai/Mistral-7B-Instruct-v0.3.description": "Mistral (7B) Instruct v0.3 offre calcolo efficiente e forte comprensione linguistica per molti casi d'uso.",
  "mistralai/Mistral-7B-v0.1.description": "Mistral 7B è compatto ma ad alte prestazioni, forte nell'elaborazione batch e in compiti semplici come classificazione e generazione di testo, con solido ragionamento.",
  "mistralai/Mixtral-8x22B-Instruct-v0.1.description": "Mixtral-8x22B Instruct (141B) è un LLM molto grande per carichi di lavoro pesanti.",
  "mistralai/Mixtral-8x7B-Instruct-v0.1.description": "Mixtral-8x7B Instruct (46.7B) offre alta capacità per l'elaborazione di dati su larga scala.",
  "mistralai/Mixtral-8x7B-v0.1.description": "Mixtral 8x7B è un modello MoE sparso che aumenta la velocità di inferenza, adatto a compiti multilingue e generazione di codice.",
  "mistralai/mistral-nemo.description": "Mistral Nemo è un modello da 7.3B con supporto multilingue e forti prestazioni nella codifica.",
  "o4-mini-deep-research.description": "o4-mini-deep-research è un modello di ricerca approfondita più veloce ed economico per ricerche complesse a più passaggi. Può cercare sul web e accedere ai tuoi dati tramite connettori MCP.",
  "o4-mini.description": "o4-mini è l'ultimo modello compatto della serie o, ottimizzato per un ragionamento rapido ed efficace, con alta efficienza nei compiti di programmazione e visione.",
  "open-codestral-mamba.description": "Codestral Mamba è un modello linguistico Mamba 2 focalizzato sulla generazione di codice, adatto a compiti avanzati di programmazione e ragionamento.",
  "open-mistral-7b.description": "Mistral 7B è compatto ma ad alte prestazioni, ideale per l'elaborazione in batch e compiti semplici come classificazione e generazione di testo, con solide capacità di ragionamento.",
  "open-mistral-nemo.description": "Mistral Nemo è un modello da 12B sviluppato in collaborazione con Nvidia, che offre elevate prestazioni in ragionamento e programmazione, con integrazione semplificata.",
  "open-mixtral-8x22b.description": "Mixtral 8x22B è un modello MoE di grandi dimensioni per compiti complessi, con forte capacità di ragionamento e throughput elevato.",
  "open-mixtral-8x7b.description": "Mixtral 8x7B è un modello MoE sparso che accelera l'inferenza, adatto a compiti multilingue e di generazione di codice.",
  "openai/gpt-3.5-turbo-instruct.description": "Capacità simili ai modelli dell'era GPT-3, compatibile con endpoint legacy di completamento piuttosto che chat.",
  "openai/gpt-3.5-turbo.description": "Il modello GPT-3.5 più capace ed economico di OpenAI, ottimizzato per la chat ma ancora valido per completamenti classici.",
  "openai/gpt-4-turbo.description": "gpt-4-turbo di OpenAI possiede una vasta conoscenza generale e competenze specialistiche, segue istruzioni complesse in linguaggio naturale e risolve problemi difficili con precisione. Il cutoff di conoscenza è aprile 2023 con una finestra di contesto di 128k.",
  "openai/gpt-4.1-mini.description": "GPT-4.1 Mini offre una latenza ridotta e un miglior rapporto qualità-prezzo per carichi di lavoro a contesto medio.",
  "openai/gpt-4.1-nano.description": "GPT-4.1 Nano è un'opzione a bassissimo costo e latenza per chat brevi ad alta frequenza o classificazione.",
  "openai/gpt-4.1.description": "La serie GPT-4.1 offre finestre di contesto più ampie e capacità ingegneristiche e di ragionamento più avanzate.",
  "openai/gpt-4o-mini.description": "GPT-4o-mini è una variante compatta e veloce di GPT-4o per utilizzi multimodali a bassa latenza.",
  "openai/gpt-4o.description": "La famiglia GPT-4o è il modello Omni di OpenAI con input testuale + immagine e output testuale.",
  "openai/gpt-5-chat.description": "GPT-5 Chat è una variante di GPT-5 ottimizzata per conversazioni con latenza ridotta per una migliore interattività.",
  "openai/gpt-5-codex.description": "GPT-5-Codex è una variante di GPT-5 ulteriormente ottimizzata per la programmazione e flussi di lavoro su larga scala.",
  "openai/gpt-5-mini.description": "GPT-5 Mini è una variante compatta di GPT-5 per scenari a bassa latenza e basso costo.",
  "openai/gpt-5-nano.description": "GPT-5 Nano è la variante ultra-compatta per scenari con vincoli stringenti di costo e latenza.",
  "openai/gpt-5-pro.description": "GPT-5 Pro è il modello di punta di OpenAI, con capacità avanzate di ragionamento, generazione di codice e funzionalità di livello enterprise, con routing in fase di test e politiche di sicurezza più rigorose.",
  "openai/gpt-5.1-chat.description": "GPT-5.1 Chat è il membro leggero della famiglia GPT-5.1, ottimizzato per conversazioni a bassa latenza mantenendo forti capacità di ragionamento ed esecuzione di istruzioni.",
  "openai/gpt-5.1-codex-mini.description": "GPT-5.1-Codex-Mini è una versione più piccola e veloce di GPT-5.1-Codex, ideale per scenari di programmazione sensibili a latenza e costi.",
  "openai/gpt-5.1-codex.description": "GPT-5.1-Codex è una variante di GPT-5.1 ottimizzata per l'ingegneria del software e i flussi di lavoro di programmazione, adatta a grandi refactoring, debug complessi e compiti autonomi prolungati.",
  "openai/gpt-5.1.description": "GPT-5.1 è il nuovo modello di punta della serie GPT-5, con miglioramenti significativi rispetto a GPT-5 nel ragionamento generale, nel seguire istruzioni e nella naturalezza conversazionale, adatto a compiti ampi.",
  "openai/gpt-5.description": "GPT-5 è il modello ad alte prestazioni di OpenAI per un'ampia gamma di compiti di produzione e ricerca.",
  "openai/gpt-oss-120b.description": "Un LLM generalista altamente capace con ragionamento forte e controllabile.",
  "openai/gpt-oss-20b.description": "Un modello linguistico compatto a pesi aperti ottimizzato per bassa latenza e ambienti con risorse limitate, inclusi deployment locali e edge.",
  "openai/o1-mini.description": "o1-mini è un modello di ragionamento veloce ed economico progettato per programmazione, matematica e scienze. Ha un contesto di 128K e un cutoff di conoscenza a ottobre 2023.",
  "openai/o1-preview.description": "o1 è il nuovo modello di ragionamento di OpenAI per compiti complessi che richiedono ampia conoscenza. Ha un contesto di 128K e un cutoff di conoscenza a ottobre 2023.",
  "openai/o1.description": "OpenAI o1 è un modello di ragionamento di punta progettato per problemi complessi che richiedono pensiero profondo, offrendo ragionamento avanzato e maggiore accuratezza nei compiti a più passaggi.",
  "openai/o3-mini-high.description": "o3-mini (ragionamento avanzato) offre maggiore intelligenza mantenendo gli stessi obiettivi di costo e latenza di o1-mini.",
  "openai/o3-mini.description": "o3-mini è l'ultimo modello compatto di ragionamento di OpenAI, che offre maggiore intelligenza agli stessi livelli di costo e latenza di o1-mini.",
  "openai/o3.description": "OpenAI o3 è il modello di ragionamento più potente, stabilendo nuovi standard nello stato dell'arte per programmazione, matematica, scienze e percezione visiva. Eccelle in query complesse e articolate, in particolare nell'analisi di immagini, grafici e diagrammi.",
  "openai/o4-mini-high.description": "o4-mini livello di ragionamento avanzato, ottimizzato per ragionamento veloce ed efficiente con elevate prestazioni in programmazione e visione.",
  "openai/o4-mini.description": "OpenAI o4-mini è un modello compatto ed efficiente di ragionamento per scenari a bassa latenza.",
  "openai/text-embedding-3-large.description": "Il modello di embedding più avanzato di OpenAI per compiti in inglese e in altre lingue.",
  "openai/text-embedding-3-small.description": "Variante migliorata e ad alte prestazioni del modello ada di embedding di OpenAI.",
  "openai/text-embedding-ada-002.description": "Modello legacy di embedding testuale di OpenAI.",
  "openrouter/auto.description": "In base alla lunghezza del contesto, all'argomento e alla complessità, la tua richiesta viene instradata a Llama 3 70B Instruct, Claude 3.5 Sonnet (auto-moderato) o GPT-4o.",
  "qwen/qwen2.5-coder-32b-instruct.description": "Un avanzato LLM per la generazione, il ragionamento e la correzione del codice nei principali linguaggi di programmazione.",
  "qwen/qwen2.5-coder-7b-instruct.description": "Un solido modello di codice di medie dimensioni con contesto da 32K, eccellente nella programmazione multilingue.",
  "qwen/qwen3-14b.description": "Qwen3-14B è la variante da 14B per il ragionamento generale e scenari di chat.",
  "qwen/qwen3-14b:free.description": "Qwen3-14B è un LLM causale denso con 14,8 miliardi di parametri, progettato per ragionamento complesso e chat efficiente. Passa da una modalità di pensiero per matematica, programmazione e logica a una modalità non-pensante per la chat generale. Ottimizzato per seguire istruzioni, usare strumenti agentici e scrittura creativa in oltre 100 lingue e dialetti. Supporta nativamente un contesto di 32K e scala fino a 131K con YaRN.",
  "qwen/qwen3-235b-a22b-2507.description": "Qwen3-235B-A22B-Instruct-2507 è la variante Instruct della serie Qwen3, che bilancia l'uso multilingue delle istruzioni con scenari a lungo contesto.",
  "qwen/qwen3-235b-a22b-thinking-2507.description": "Qwen3-235B-A22B-Thinking-2507 è la variante Thinking di Qwen3, potenziata per compiti complessi di matematica e ragionamento.",
  "qwen/qwen3-235b-a22b.description": "Qwen3-235B-A22B è un modello MoE da 235 miliardi di parametri con 22 miliardi attivi per passaggio. Passa da una modalità di pensiero per ragionamento complesso, matematica e codice a una modalità non-pensante per chat efficiente. Offre ragionamento avanzato, supporto multilingue (oltre 100 lingue/dialetti), capacità avanzate di seguire istruzioni e uso di strumenti agentici. Supporta nativamente 32K di contesto e scala fino a 131K con YaRN.",
  "qwen/qwen3-235b-a22b:free.description": "Qwen3-235B-A22B è un modello MoE da 235 miliardi di parametri con 22 miliardi attivi per passaggio. Passa da una modalità di pensiero per ragionamento complesso, matematica e codice a una modalità non-pensante per chat efficiente. Offre ragionamento avanzato, supporto multilingue (oltre 100 lingue/dialetti), capacità avanzate di seguire istruzioni e uso di strumenti agentici. Supporta nativamente 32K di contesto e scala fino a 131K con YaRN.",
  "qwen/qwen3-30b-a3b.description": "Qwen3 è l'ultima generazione di LLM Qwen con architetture dense e MoE, eccellente nel ragionamento, supporto multilingue e compiti avanzati per agenti. La sua capacità unica di passare da una modalità di pensiero per ragionamento complesso a una modalità non-pensante per chat efficiente garantisce prestazioni versatili e di alta qualità.\n\nQwen3 supera significativamente i modelli precedenti come QwQ e Qwen2.5, offrendo eccellenza in matematica, programmazione, ragionamento di buon senso, scrittura creativa e chat interattiva. La variante Qwen3-30B-A3B ha 30,5 miliardi di parametri (3,3B attivi), 48 layer, 128 esperti (8 attivi per compito) e supporta fino a 131K di contesto con YaRN, stabilendo un nuovo standard per i modelli open source.",
  "qwen/qwen3-30b-a3b:free.description": "Qwen3 è l'ultima generazione di LLM Qwen con architetture dense e MoE, eccellente nel ragionamento, supporto multilingue e compiti avanzati per agenti. La sua capacità unica di passare da una modalità di pensiero per ragionamento complesso a una modalità non-pensante per chat efficiente garantisce prestazioni versatili e di alta qualità.\n\nQwen3 supera significativamente i modelli precedenti come QwQ e Qwen2.5, offrendo eccellenza in matematica, programmazione, ragionamento di buon senso, scrittura creativa e chat interattiva. La variante Qwen3-30B-A3B ha 30,5 miliardi di parametri (3,3B attivi), 48 layer, 128 esperti (8 attivi per compito) e supporta fino a 131K di contesto con YaRN, stabilendo un nuovo standard per i modelli open source.",
  "qwen/qwen3-32b.description": "Qwen3-32B è un LLM causale denso con 32,8 miliardi di parametri, ottimizzato per ragionamento complesso e chat efficiente. Passa da una modalità di pensiero per matematica, programmazione e logica a una modalità non-pensante per chat generale più veloce. Eccelle nel seguire istruzioni, uso di strumenti agentici e scrittura creativa in oltre 100 lingue e dialetti. Supporta nativamente 32K di contesto e scala fino a 131K con YaRN.",
  "qwen/qwen3-32b:free.description": "Qwen3-32B è un LLM causale denso con 32,8 miliardi di parametri, ottimizzato per ragionamento complesso e chat efficiente. Passa da una modalità di pensiero per matematica, programmazione e logica a una modalità non-pensante per chat generale più veloce. Eccelle nel seguire istruzioni, uso di strumenti agentici e scrittura creativa in oltre 100 lingue e dialetti. Supporta nativamente 32K di contesto e scala fino a 131K con YaRN.",
  "qwen/qwen3-8b:free.description": "Qwen3-8B è un LLM causale denso con 8,2 miliardi di parametri, progettato per compiti con forte componente di ragionamento e chat efficiente. Passa da una modalità di pensiero per matematica, programmazione e logica a una modalità non-pensante per chat generale. Ottimizzato per seguire istruzioni, integrazione con agenti e scrittura creativa in oltre 100 lingue e dialetti. Supporta nativamente 32K di contesto e scala fino a 131K con YaRN.",
  "qwen/qwen3-coder-plus.description": "Qwen3-Coder-Plus è un modello agente per la programmazione della serie Qwen, ottimizzato per l'uso di strumenti complessi e sessioni prolungate.",
  "qwen/qwen3-coder.description": "Qwen3-Coder è la famiglia di modelli Qwen3 per la generazione di codice, eccellente nella comprensione e generazione di codice su documenti lunghi.",
  "qwen/qwen3-max-preview.description": "Qwen3 Max (anteprima) è la variante Max per ragionamento avanzato e integrazione con strumenti.",
  "qwen/qwen3-max.description": "Qwen3 Max è il modello di ragionamento di fascia alta della serie Qwen3, progettato per ragionamento multilingue e integrazione con strumenti.",
  "qwen3-coder:480b.description": "Modello ad alte prestazioni di Alibaba per attività di agenti e programmazione, con supporto a contesti lunghi.",
  "qwen3-max-preview.description": "Il modello Qwen con le migliori prestazioni per compiti complessi e multi-step. La versione preview supporta il ragionamento.",
  "qwen3-max.description": "I modelli Qwen3 Max offrono miglioramenti significativi rispetto alla serie 2.5 in capacità generali, comprensione di cinese/inglese, esecuzione di istruzioni complesse, compiti soggettivi aperti, abilità multilingue e uso di strumenti, con meno allucinazioni. L'ultima versione qwen3-max migliora la programmazione agentica e l'uso degli strumenti rispetto a qwen3-max-preview. Questa release raggiunge lo stato dell’arte e risponde a esigenze agentiche più complesse.",
  "qwen3-next-80b-a3b-instruct.description": "Modello open-source di nuova generazione Qwen3 senza capacità di ragionamento. Rispetto alla versione precedente (Qwen3-235B-A22B-Instruct-2507), offre una migliore comprensione del cinese, un ragionamento logico più forte e una generazione di testo migliorata.",
  "qwen3-next-80b-a3b-thinking.description": "Qwen3 Next 80B A3B Thinking è la versione di punta per il ragionamento, progettata per compiti complessi.",
  "qwen3-omni-flash.description": "Qwen-Omni accetta input combinati da testo, immagini, audio e video, e genera output in forma testuale o vocale. Offre stili vocali naturali multipli, supporta lingue e dialetti diversi, ed è adatto a casi d’uso come scrittura, riconoscimento visivo e assistenti vocali.",
  "qwen3-vl-235b-a22b-instruct.description": "Qwen3 VL 235B A22B Instruct è un modello multimodale di punta per comprensione e creazione avanzate.",
  "qwen3-vl-235b-a22b-thinking.description": "Qwen3 VL 235B A22B Thinking è la versione di punta per il ragionamento multimodale complesso e la pianificazione.",
  "qwen3-vl-30b-a3b-instruct.description": "Qwen3 VL 30B A3B Instruct è un grande modello multimodale che bilancia accuratezza e capacità di ragionamento.",
  "qwen3-vl-30b-a3b-thinking.description": "Qwen3 VL 30B A3B Thinking è una versione avanzata per il ragionamento profondo in compiti multimodali complessi.",
  "qwen3-vl-32b-instruct.description": "Qwen3 VL 32B Instruct è un modello multimodale ottimizzato per istruzioni, ideale per QA immagine-testo di alta qualità e creazione.",
  "qwen3-vl-32b-thinking.description": "Qwen3 VL 32B Thinking è una versione multimodale per il ragionamento profondo, adatta ad analisi complesse e catene logiche lunghe.",
  "qwen3-vl-8b-instruct.description": "Qwen3 VL 8B Instruct è un modello multimodale leggero per QA visivo quotidiano e integrazione in app.",
  "qwen3-vl-8b-thinking.description": "Qwen3 VL 8B Thinking è un modello multimodale con catena di pensiero per ragionamento visivo dettagliato.",
  "qwen3-vl-flash.description": "Qwen3 VL Flash: versione leggera e ad alta velocità per richieste sensibili alla latenza o ad alto volume.",
  "qwen3-vl-plus.description": "Qwen VL è un modello di generazione testuale con comprensione visiva. Può eseguire OCR, riassumere e ragionare, ad esempio estraendo attributi da foto di prodotti o risolvendo problemi da immagini.",
  "qwen3.description": "Qwen3 è il modello linguistico di nuova generazione di Alibaba, con prestazioni elevate in una vasta gamma di casi d’uso.",
  "qwq-32b-preview.description": "QwQ è un modello sperimentale di ricerca della famiglia Qwen, focalizzato sul miglioramento del ragionamento.",
  "qwq-32b.description": "QwQ è un modello di ragionamento della famiglia Qwen. Rispetto ai modelli standard ottimizzati per istruzioni, offre capacità di pensiero e ragionamento che migliorano significativamente le prestazioni nei compiti complessi. QwQ-32B è un modello di medie dimensioni che compete con i migliori modelli di ragionamento come DeepSeek-R1 e o1-mini.",
  "qwq-plus.description": "Il modello di ragionamento QwQ, addestrato su Qwen2.5, utilizza l’apprendimento per rinforzo per migliorare notevolmente il ragionamento. Ottiene punteggi di punta in matematica/codice (AIME 24/25, LiveCodeBench) e benchmark generali (IFEval, LiveBench), raggiungendo il livello di DeepSeek-R1.",
  "qwq.description": "QwQ è un modello di ragionamento della famiglia Qwen. Rispetto ai modelli standard ottimizzati per istruzioni, offre capacità di pensiero e ragionamento che migliorano significativamente le prestazioni nei compiti difficili. QwQ-32B è un modello di medie dimensioni che compete con i migliori modelli di ragionamento come DeepSeek-R1 e o1-mini.",
  "qwq_32b.description": "Modello di ragionamento di medie dimensioni della famiglia Qwen. Rispetto ai modelli standard ottimizzati per istruzioni, le capacità di pensiero e ragionamento di QwQ migliorano significativamente le prestazioni nei compiti difficili.",
  "r1-1776.description": "R1-1776 è una variante post-addestrata di DeepSeek R1 progettata per fornire informazioni fattuali non censurate e imparziali.",
  "solar-mini-ja.description": "Solar Mini (Ja) estende Solar Mini con un focus sul giapponese, mantenendo prestazioni efficienti e solide in inglese e coreano.",
  "solar-mini.description": "Solar Mini è un LLM compatto che supera GPT-3.5, con forte capacità multilingue in inglese e coreano, offrendo una soluzione efficiente e leggera.",
  "solar-pro.description": "Solar Pro è un LLM ad alta intelligenza di Upstage, focalizzato sull’esecuzione di istruzioni su una singola GPU, con punteggi IFEval superiori a 80. Attualmente supporta l’inglese; il rilascio completo è previsto per novembre 2024 con supporto linguistico ampliato e contesto più lungo.",
  "sonar-deep-research.description": "Deep Research esegue ricerche approfondite a livello esperto e le sintetizza in report accessibili e utili.",
  "sonar-pro.description": "Prodotto di ricerca avanzata con ancoraggio alla ricerca per query complesse e follow-up.",
  "sonar-reasoning-pro.description": "Prodotto di ricerca avanzata con ancoraggio alla ricerca per query complesse e follow-up.",
  "sonar-reasoning.description": "Prodotto di ricerca avanzata con ancoraggio alla ricerca per query complesse e follow-up.",
  "sonar.description": "Prodotto leggero con ancoraggio alla ricerca, più veloce ed economico rispetto a Sonar Pro.",
  "spark-x.description": "Aggiornamenti X1.5: (1) aggiunge modalità di pensiero dinamico controllata dal campo `thinking`; (2) lunghezza del contesto aumentata a 64K input e 64K output; (3) supporta FunctionCall.",
  "stable-diffusion-3-medium.description": "L'ultimo modello text-to-image di Stability AI. Questa versione migliora significativamente la qualità delle immagini, la comprensione del testo e la diversità stilistica, interpretando con maggiore precisione prompt complessi in linguaggio naturale e generando immagini più accurate e varie.",
  "stable-diffusion-3.5-large-turbo.description": "stable-diffusion-3.5-large-turbo applica la distillazione per diffusione avversaria (ADD) a stable-diffusion-3.5-large per una maggiore velocità.",
  "stable-diffusion-3.5-large.description": "stable-diffusion-3.5-large è un modello text-to-image MMDiT da 800M parametri con qualità eccellente e allineamento ai prompt, supporta immagini da 1 megapixel ed è efficiente su hardware consumer.",
  "stable-diffusion-v1.5.description": "stable-diffusion-v1.5 è inizializzato dal checkpoint v1.2 e ottimizzato per 595k step su \"laion-aesthetics v2 5+\" a risoluzione 512x512, riducendo il conditioning testuale del 10% per migliorare il campionamento classifier-free.",
  "stable-diffusion-xl-base-1.0.description": "Modello open-source text-to-image di Stability AI con generazione creativa di immagini leader nel settore. Ha una forte comprensione delle istruzioni e supporta definizioni inverse dei prompt per generazioni precise.",
  "stable-diffusion-xl.description": "stable-diffusion-xl introduce miglioramenti significativi rispetto alla v1.5 e raggiunge i migliori risultati open-source text-to-image. Include un backbone UNet 3 volte più grande, un modulo di raffinamento per immagini migliori e tecniche di addestramento più efficienti.",
  "step-1-128k.description": "Equilibrio tra prestazioni e costi per scenari generali.",
  "step-1-256k.description": "Gestione di contesti extra-lunghi, ideale per l’analisi di documenti estesi.",
  "step-1-32k.description": "Supporta conversazioni di media lunghezza per un’ampia gamma di scenari.",
  "step-1-8k.description": "Modello piccolo adatto a compiti leggeri.",
  "step-1-flash.description": "Modello ad alta velocità adatto a chat in tempo reale.",
  "step-1.5v-mini.description": "Forti capacità di comprensione video.",
  "step-1o-turbo-vision.description": "Eccellente comprensione delle immagini, supera 1o in matematica e programmazione. Più piccolo di 1o con output più veloce.",
  "step-1o-vision-32k.description": "Forte comprensione visiva con prestazioni superiori rispetto alla serie Step-1V.",
  "step-1v-32k.description": "Supporta input visivi per interazioni multimodali più ricche.",
  "step-1v-8k.description": "Modello visivo compatto per compiti base immagine-testo.",
  "step-1x-edit.description": "Questo modello si concentra sull’editing di immagini, modificando e migliorando immagini in base a input testuali e visivi forniti dall’utente. Supporta più formati di input e genera modifiche coerenti con l’intento dell’utente.",
  "step-1x-medium.description": "Questo modello offre una forte generazione di immagini da prompt testuali. Con supporto nativo al cinese, comprende meglio le descrizioni in cinese, ne cattura la semantica e le trasforma in caratteristiche visive per una generazione più accurata. Produce immagini ad alta risoluzione e qualità, con supporto a un certo grado di trasferimento di stile.",
  "step-2-16k-exp.description": "Build sperimentale Step-2 con le ultime funzionalità e aggiornamenti continui. Non consigliato per ambienti di produzione.",
  "step-2-16k.description": "Supporta interazioni a contesto esteso per dialoghi complessi.",
  "step-2-mini.description": "Basato sulla nuova architettura MFA attention proprietaria, offre risultati simili a Step-1 a costi molto inferiori, con throughput più elevato e latenza ridotta. Gestisce compiti generali con forti capacità di programmazione.",
  "step-2x-large.description": "Modello di nuova generazione StepFun focalizzato sulla generazione di immagini, produce immagini di alta qualità da prompt testuali. Offre texture più realistiche e una resa testuale cinese/inglese più forte.",
  "step-3.description": "Questo modello ha una forte percezione visiva e capacità di ragionamento complesso, gestendo con precisione la comprensione della conoscenza cross-domain, l’analisi matematica-visiva e una vasta gamma di compiti visivi quotidiani.",
  "step-r1-v-mini.description": "Modello di ragionamento con forte comprensione delle immagini, in grado di elaborare immagini e testo e generare testo dopo un ragionamento profondo. Eccelle nel ragionamento visivo e offre prestazioni di alto livello in matematica, programmazione e ragionamento testuale, con una finestra di contesto da 100K.",
  "v0-1.5-lg.description": "v0-1.5-lg è adatto a compiti avanzati di pensiero e ragionamento.",
  "v0-1.5-md.description": "v0-1.5-md è adatto a compiti quotidiani e alla generazione di interfacce utente.",
  "vercel/v0-1.0-md.description": "Accedi ai modelli dietro v0 per generare, correggere e ottimizzare applicazioni web moderne con ragionamento specifico per framework e conoscenze aggiornate.",
  "vercel/v0-1.5-md.description": "Accedi ai modelli dietro v0 per generare, correggere e ottimizzare applicazioni web moderne con ragionamento specifico per framework e conoscenze aggiornate.",
  "volcengine/doubao-seed-code.description": "Doubao-Seed-Code è il modello LLM di Volcano Engine di ByteDance ottimizzato per la programmazione agentica, con prestazioni elevate nei benchmark di programmazione e agenti e supporto per contesti fino a 256K.",
  "wan2.2-t2i-flash.description": "Wanxiang 2.2 Speed è il modello più recente con miglioramenti in creatività, stabilità e realismo, offrendo generazione rapida e alto valore.",
  "wan2.2-t2i-plus.description": "Wanxiang 2.2 Pro è il modello più recente con miglioramenti in creatività, stabilità e realismo, producendo dettagli più ricchi.",
  "wanx-v1.description": "Modello base da testo a immagine. Corrisponde a Tongyi Wanxiang 1.0 General.",
  "wanx2.0-t2i-turbo.description": "Eccelle nei ritratti con texture, con velocità moderata e costi ridotti. Corrisponde a Tongyi Wanxiang 2.0 Speed.",
  "wanx2.1-t2i-plus.description": "Versione completamente aggiornata con immagini più dettagliate e velocità leggermente inferiore. Corrisponde a Tongyi Wanxiang 2.1 Pro.",
  "wanx2.1-t2i-turbo.description": "Versione completamente aggiornata con generazione rapida, qualità complessiva elevata e alto valore. Corrisponde a Tongyi Wanxiang 2.1 Speed.",
  "whisper-1.description": "Modello generale di riconoscimento vocale che supporta ASR multilingue, traduzione vocale e identificazione della lingua.",
  "wizardlm2.description": "WizardLM 2 è un modello linguistico di Microsoft AI che eccelle in dialoghi complessi, compiti multilingue, ragionamento e assistenza.",
  "wizardlm2:8x22b.description": "WizardLM 2 è un modello linguistico di Microsoft AI che eccelle in dialoghi complessi, compiti multilingue, ragionamento e assistenza.",
  "x-ai/grok-4-fast-non-reasoning.description": "Grok 4 Fast (Non-Reasoning) è il modello multimodale ad alta capacità e basso costo di xAI (supporta una finestra di contesto da 2M), ideale per scenari sensibili alla latenza e ai costi che non richiedono ragionamento interno. È affiancato dalla versione con ragionamento, attivabile tramite il parametro API reasoning. Prompt e completamenti possono essere utilizzati da xAI o OpenRouter per migliorare i modelli futuri.",
  "x-ai/grok-4-fast.description": "Grok 4 Fast è il modello ad alta capacità e basso costo di xAI (supporta una finestra di contesto da 2M), ideale per casi d'uso con alta concorrenza e contesti lunghi.",
  "x-ai/grok-4.1-fast-non-reasoning.description": "Grok 4 Fast (Non-Reasoning) è il modello multimodale ad alta capacità e basso costo di xAI (supporta una finestra di contesto da 2M), ideale per scenari sensibili alla latenza e ai costi che non richiedono ragionamento interno. È affiancato dalla versione con ragionamento, attivabile tramite il parametro API reasoning. Prompt e completamenti possono essere utilizzati da xAI o OpenRouter per migliorare i modelli futuri.",
  "x-ai/grok-4.1-fast.description": "Grok 4 Fast è il modello ad alta capacità e basso costo di xAI (supporta una finestra di contesto da 2M), ideale per casi d'uso con alta concorrenza e contesti lunghi.",
  "x-ai/grok-4.description": "Grok 4 è il modello di punta di xAI con forti capacità di ragionamento e multimodalità.",
  "x-ai/grok-code-fast-1.description": "Grok Code Fast 1 è il modello veloce di xAI per la programmazione, con output leggibile e adatto all'ingegneria.",
  "xai/grok-2-vision.description": "Grok 2 Vision eccelle nei compiti visivi, offrendo prestazioni all'avanguardia nel ragionamento matematico visivo (MathVista) e nella QA su documenti (DocVQA). Gestisce documenti, grafici, tabelle, screenshot e foto.",
  "xai/grok-2.description": "Grok 2 è un modello all'avanguardia con prestazioni eccellenti in ragionamento, chat, programmazione e classificato sopra Claude 3.5 Sonnet e GPT-4 Turbo su LMSYS.",
  "xai/grok-3-fast.description": "Il modello di punta di xAI eccelle in casi d'uso aziendali come estrazione dati, programmazione e sintesi, con profonda conoscenza nei settori finanza, sanità, diritto e scienza. La variante veloce utilizza un'infrastruttura più rapida per risposte molto più veloci a un costo per token più elevato.",
  "xai/grok-3-mini-fast.description": "Modello leggero di xAI che riflette prima di rispondere, ideale per compiti semplici o basati sulla logica senza conoscenze specialistiche. Sono disponibili tracce di ragionamento grezze. La variante veloce utilizza un'infrastruttura più rapida per risposte molto più veloci a un costo per token più elevato.",
  "xai/grok-3-mini.description": "Modello leggero di xAI che riflette prima di rispondere, ideale per compiti semplici o basati sulla logica senza conoscenze specialistiche. Sono disponibili tracce di ragionamento grezze.",
  "xai/grok-3.description": "Il modello di punta di xAI eccelle in casi d'uso aziendali come estrazione dati, programmazione e sintesi, con profonda conoscenza nei settori finanza, sanità, diritto e scienza.",
  "xai/grok-4.description": "Il nuovo modello di punta di xAI con prestazioni impareggiabili in linguaggio naturale, matematica e ragionamento: un tuttofare ideale.",
  "yi-large-fc.description": "Basato su yi-large con funzionalità avanzate di tool-calling, adatto a scenari con agenti e flussi di lavoro.",
  "yi-large-preview.description": "Versione preliminare; si consiglia l'uso di yi-large (più recente).",
  "yi-large-rag.description": "Servizio avanzato basato su yi-large, che combina recupero e generazione per risposte precise con ricerca web in tempo reale.",
  "yi-large-turbo.description": "Valore e prestazioni eccezionali, ottimizzato per un forte equilibrio tra qualità, velocità e costo.",
  "yi-large.description": "Un nuovo modello da 100 miliardi di parametri con forti capacità di Q&A e generazione di testo.",
  "yi-lightning-lite.description": "Versione leggera; si consiglia yi-lightning.",
  "yi-lightning.description": "Modello ad alte prestazioni di ultima generazione con inferenza rapida e output di alta qualità.",
  "yi-medium-200k.description": "Modello con contesto lungo da 200K per una comprensione e generazione approfondita di testi lunghi.",
  "yi-medium.description": "Modello di medie dimensioni ottimizzato per seguire istruzioni, con capacità e valore bilanciati.",
  "yi-spark.description": "Modello compatto e veloce con capacità potenziate in matematica e programmazione.",
  "yi-vision-v2.description": "Modello visivo per compiti complessi con forte comprensione e analisi multi-immagine.",
  "yi-vision.description": "Modello visivo per compiti complessi con forte comprensione e analisi delle immagini.",
  "z-ai/glm-4.5-air.description": "GLM 4.5 Air è una variante leggera di GLM 4.5 per scenari sensibili ai costi, mantenendo forti capacità di ragionamento.",
  "z-ai/glm-4.5.description": "GLM 4.5 è il modello di punta di Z.AI con ragionamento ibrido ottimizzato per compiti ingegneristici e contesti lunghi.",
  "z-ai/glm-4.6.description": "GLM 4.6 è il modello di punta di Z.AI con contesto esteso e capacità di programmazione.",
  "zai-glm-4.6.description": "Eccelle in compiti di programmazione e ragionamento, supporta lo streaming e le chiamate a strumenti, ed è adatto alla programmazione agentica e al ragionamento complesso.",
  "zai-org/GLM-4.5-Air.description": "GLM-4.5-Air è un modello base per applicazioni agentiche con architettura Mixture-of-Experts. Ottimizzato per l'uso di strumenti, navigazione web, ingegneria software e programmazione frontend, si integra con agenti di codice come Claude Code e Roo Code. Utilizza ragionamento ibrido per gestire sia scenari complessi che quotidiani.",
  "zai-org/GLM-4.5.description": "GLM-4.5 è un modello base progettato per applicazioni agentiche con architettura Mixture-of-Experts. Ottimizzato per l'uso di strumenti, navigazione web, ingegneria software e programmazione frontend, si integra con agenti di codice come Claude Code e Roo Code. Utilizza ragionamento ibrido per gestire sia scenari complessi che quotidiani.",
  "zai-org/GLM-4.5V.description": "GLM-4.5V è il più recente VLM di Zhipu AI, basato sul modello testuale di punta GLM-4.5-Air (106B totali, 12B attivi) con architettura MoE per prestazioni elevate a costi ridotti. Segue il percorso GLM-4.1V-Thinking e aggiunge 3D-RoPE per migliorare il ragionamento spaziale 3D. Ottimizzato tramite pretraining, SFT e RL, gestisce immagini, video e documenti lunghi, classificandosi tra i migliori modelli open source su 41 benchmark multimodali pubblici. Una modalità Thinking consente di bilanciare velocità e profondità.",
  "zai-org/GLM-4.6.description": "Rispetto a GLM-4.5, GLM-4.6 estende il contesto da 128K a 200K per compiti agentici più complessi. Ottiene punteggi più alti nei benchmark di codice e mostra prestazioni superiori in applicazioni reali come Claude Code, Cline, Roo Code e Kilo Code, inclusa una migliore generazione di pagine frontend. Il ragionamento è migliorato e l'uso di strumenti è supportato durante il ragionamento, rafforzando le capacità complessive. Si integra meglio nei framework agentici, migliora gli agenti di ricerca/strumenti e offre uno stile di scrittura più naturale e preferito dagli utenti.",
  "zai/glm-4.5-air.description": "GLM-4.5 e GLM-4.5-Air sono i nostri modelli di punta più recenti per applicazioni agentiche, entrambi con architettura MoE. GLM-4.5 ha 355B totali e 32B attivi per passaggio; GLM-4.5-Air è più snello con 106B totali e 12B attivi.",
  "zai/glm-4.5.description": "La serie GLM-4.5 è progettata per agenti. Il modello di punta GLM-4.5 combina ragionamento, programmazione e capacità agentiche con 355B parametri totali (32B attivi) e offre modalità operative doppie come sistema di ragionamento ibrido.",
  "zai/glm-4.5v.description": "GLM-4.5V si basa su GLM-4.5-Air, ereditando le tecniche collaudate di GLM-4.1V-Thinking e scalando con una potente architettura MoE da 106B parametri.",
  "zenmux/auto.description": "Il sistema di instradamento automatico ZenMux seleziona il modello con il miglior rapporto qualità/prezzo tra quelli supportati in base alla tua richiesta."
}
