{
  "01-ai/yi-1.5-34b-chat.description": "Il più recente modello open-source ottimizzato di 01.AI con 34 miliardi di parametri, supporta molteplici scenari di dialogo, addestrato su dati di alta qualità e allineato alle preferenze umane.",
  "01-ai/yi-1.5-9b-chat.description": "Il più recente modello open-source ottimizzato di 01.AI con 9 miliardi di parametri, supporta molteplici scenari di dialogo, addestrato su dati di alta qualità e allineato alle preferenze umane.",
  "360/deepseek-r1.description": "DeepSeek-R1, distribuito da 360, utilizza l'apprendimento per rinforzo su larga scala nella fase di post-addestramento per migliorare notevolmente il ragionamento con un numero minimo di etichette. Eguaglia OpenAI o1 nei compiti di matematica, programmazione e ragionamento in linguaggio naturale.",
  "360gpt-pro-trans.description": "Modello specializzato nella traduzione, ottimizzato in profondità per offrire una qualità di traduzione di livello superiore.",
  "360gpt-pro.description": "360GPT Pro è un modello chiave di 360 AI con elaborazione testuale efficiente per diversi scenari NLP, supporta la comprensione di testi lunghi e dialoghi multi-turno.",
  "360gpt-turbo-responsibility-8k.description": "360GPT Turbo Responsibility 8K pone l'accento sulla sicurezza semantica e la responsabilità nei contesti sensibili, garantendo esperienze utente accurate e affidabili.",
  "360gpt-turbo.description": "360GPT Turbo offre elevate capacità di calcolo e conversazione con eccellente comprensione semantica ed efficienza generativa, ideale per aziende e sviluppatori.",
  "360gpt2-o1.description": "360gpt2-o1 costruisce catene di pensiero tramite ricerca ad albero con meccanismo di riflessione e addestramento RL, abilitando auto-riflessione e auto-correzione.",
  "360gpt2-pro.description": "360GPT2 Pro è un modello NLP avanzato di 360 con eccellenti capacità di generazione e comprensione del testo, particolarmente adatto a compiti creativi, trasformazioni complesse e simulazioni di ruolo.",
  "360zhinao2-o1.description": "360zhinao2-o1 costruisce catene di pensiero tramite ricerca ad albero con meccanismo di riflessione e addestramento RL, abilitando auto-riflessione e auto-correzione.",
  "4.0Ultra.description": "Spark Ultra è il modello più potente della serie Spark, migliora la comprensione e il riassunto del testo e potenzia la ricerca web. È una soluzione completa per aumentare la produttività lavorativa e fornire risposte accurate, posizionandosi come prodotto intelligente leader.",
  "AnimeSharp.description": "AnimeSharp (noto anche come \"4x-AnimeSharp\") è un modello open-source di super-risoluzione basato su ESRGAN di Kim2091, focalizzato sull'ingrandimento e la nitidezza delle immagini in stile anime. Rinominato da \"4x-TextSharpV1\" nel febbraio 2022, originariamente pensato anche per immagini testuali ma fortemente ottimizzato per contenuti anime.",
  "Baichuan2-Turbo.description": "Utilizza l'augmentazione tramite ricerca per collegare il modello alla conoscenza di dominio e del web. Supporta il caricamento di file PDF/Word e l'inserimento di URL per un recupero tempestivo e completo e output professionali e accurati.",
  "Baichuan3-Turbo-128k.description": "Con una finestra di contesto ultra-lunga da 128K, è ottimizzato per scenari aziendali ad alta frequenza con grandi vantaggi e valore. Rispetto a Baichuan2, la creazione di contenuti migliora del 20%, le domande e risposte di conoscenza del 17% e le simulazioni di ruolo del 40%. Le prestazioni complessive superano GPT-3.5.",
  "Baichuan3-Turbo.description": "Ottimizzato per scenari aziendali ad alta frequenza con grandi vantaggi e valore. Rispetto a Baichuan2, la creazione di contenuti migliora del 20%, le domande e risposte di conoscenza del 17% e le simulazioni di ruolo del 40%. Le prestazioni complessive superano GPT-3.5.",
  "Baichuan4-Air.description": "Modello di punta in Cina, supera i principali modelli esteri nei compiti in lingua cinese come conoscenza, testi lunghi e generazione creativa. Presenta anche capacità multimodali all'avanguardia con risultati eccellenti nei benchmark autorevoli.",
  "Baichuan4-Turbo.description": "Modello di punta in Cina, supera i principali modelli esteri nei compiti in lingua cinese come conoscenza, testi lunghi e generazione creativa. Presenta anche capacità multimodali all'avanguardia con risultati eccellenti nei benchmark autorevoli.",
  "Baichuan4.description": "Prestazioni domestiche di alto livello, superiori ai principali modelli esteri nei compiti in lingua cinese come conoscenza enciclopedica, testi lunghi e generazione creativa. Offre anche capacità multimodali all'avanguardia e ottimi risultati nei benchmark.",
  "ByteDance-Seed/Seed-OSS-36B-Instruct.description": "Seed-OSS è una famiglia di LLM open-source di ByteDance Seed, progettata per una gestione efficace di contesti lunghi, ragionamento, agenti e capacità generali. Seed-OSS-36B-Instruct è un modello da 36 miliardi di parametri ottimizzato per istruzioni, con supporto nativo per contesti ultra-lunghi, adatto all'elaborazione di documenti o basi di codice estesi. Ottimizzato per ragionamento, generazione di codice e compiti agentici (uso di strumenti), mantiene forti capacità generali. Una caratteristica chiave è il \"Thinking Budget\", che consente una lunghezza di ragionamento flessibile per migliorare l'efficienza.",
  "DeepSeek-R1-Distill-Llama-70B.description": "DeepSeek R1, il modello più grande e intelligente della suite DeepSeek, è stato distillato nell'architettura Llama 70B. I benchmark e le valutazioni umane dimostrano che è più intelligente del Llama 70B base, in particolare nei compiti di matematica e precisione dei fatti.",
  "DeepSeek-R1-Distill-Qwen-1.5B.description": "Modello distillato DeepSeek-R1 basato su Qwen2.5-Math-1.5B. L'apprendimento per rinforzo e i dati cold-start ottimizzano le prestazioni di ragionamento, stabilendo nuovi benchmark multi-task per i modelli open-source.",
  "DeepSeek-R1-Distill-Qwen-14B.description": "I modelli DeepSeek-R1-Distill sono ottimizzati a partire da modelli open-source utilizzando dati campione generati da DeepSeek-R1.",
  "DeepSeek-R1-Distill-Qwen-32B.description": "I modelli DeepSeek-R1-Distill sono ottimizzati a partire da modelli open-source utilizzando dati campione generati da DeepSeek-R1.",
  "DeepSeek-R1-Distill-Qwen-7B.description": "Modello distillato DeepSeek-R1 basato su Qwen2.5-Math-7B. L'apprendimento per rinforzo e i dati cold-start ottimizzano le prestazioni di ragionamento, stabilendo nuovi benchmark multi-task per i modelli open-source.",
  "DeepSeek-R1.description": "DeepSeek-R1 applica l'apprendimento per rinforzo su larga scala nella fase di post-addestramento, migliorando notevolmente il ragionamento con pochissimi dati etichettati. Eguaglia il modello di produzione OpenAI o1 nei compiti di matematica, programmazione e ragionamento in linguaggio naturale.",
  "DeepSeek-V3-1.description": "DeepSeek V3.1 è un modello di ragionamento di nuova generazione con miglioramenti nel ragionamento complesso e nella catena di pensiero, adatto a compiti di analisi approfondita.",
  "DeepSeek-V3-Fast.description": "Fornitore: sophnet. DeepSeek V3 Fast è la versione ad alta velocità di DeepSeek V3 0324, a precisione completa (non quantizzata), con prestazioni superiori in programmazione e matematica e risposte più rapide.",
  "DeepSeek-V3.1-Fast.description": "DeepSeek V3.1 Fast è la variante veloce ad alta velocità di DeepSeek V3.1. Modalità di pensiero ibrida: tramite template di chat, un solo modello supporta sia il pensiero che la risposta diretta. Uso più intelligente degli strumenti: il post-addestramento migliora le prestazioni nei compiti agentici e nell'uso degli strumenti.",
  "DeepSeek-V3.1-Think.description": "Modalità di pensiero DeepSeek-V3.1: un nuovo modello di ragionamento ibrido con modalità di pensiero e non-pensiero, più efficiente di DeepSeek-R1-0528. Le ottimizzazioni post-addestramento migliorano significativamente l'uso degli strumenti agentici e le prestazioni nei compiti agentici.",
  "DeepSeek-V3.description": "DeepSeek-V3 è un modello MoE sviluppato da DeepSeek. Supera altri modelli open-source come Qwen2.5-72B e Llama-3.1-405B in molti benchmark ed è competitivo con i principali modelli chiusi come GPT-4o e Claude 3.5 Sonnet.",
  "Doubao-lite-128k.description": "Doubao-lite offre risposte ultra-rapide e un miglior rapporto qualità/prezzo, con opzioni flessibili per diversi scenari. Supporta un contesto di 128K per inferenza e fine-tuning.",
  "Doubao-lite-32k.description": "Doubao-lite offre risposte ultra-rapide e un miglior rapporto qualità/prezzo, con opzioni flessibili per diversi scenari. Supporta un contesto di 32K per inferenza e fine-tuning.",
  "Doubao-lite-4k.description": "Doubao-lite offre risposte ultra-rapide e un miglior rapporto qualità/prezzo, con opzioni flessibili per diversi scenari. Supporta un contesto di 4K per inferenza e fine-tuning.",
  "Doubao-pro-128k.description": "Modello di punta con le migliori prestazioni per compiti complessi, eccelle in domande e risposte con fonti, riassunti, creazione, classificazione e simulazioni di ruolo. Supporta un contesto di 128K per inferenza e fine-tuning.",
  "Doubao-pro-32k.description": "Modello di punta con le migliori prestazioni per compiti complessi, eccelle in domande e risposte con fonti, riassunti, creazione, classificazione e simulazioni di ruolo. Supporta un contesto di 32K per inferenza e fine-tuning.",
  "Doubao-pro-4k.description": "Modello di punta con le migliori prestazioni per compiti complessi, eccelle in domande e risposte con fonti, riassunti, creazione, classificazione e simulazioni di ruolo. Supporta un contesto di 4K per inferenza e fine-tuning.",
  "DreamO.description": "DreamO è un modello open-source per la personalizzazione delle immagini sviluppato congiuntamente da ByteDance e l'Università di Pechino, utilizza un'architettura unificata per supportare la generazione di immagini multi-task. Impiega una modellazione compositiva efficiente per generare immagini altamente coerenti e personalizzate in base a identità, soggetto, stile, sfondo e altre condizioni specificate dall'utente.",
  "amazon/titan-embed-text-v2.description": "Amazon Titan Text Embeddings V2 è un modello di embedding multilingue leggero ed efficiente, disponibile in dimensioni da 1024, 512 e 256.",
  "gemini-flash-latest.description": "Ultima versione di Gemini Flash",
  "gemini-flash-lite-latest.description": "Ultima versione di Gemini Flash-Lite",
  "gemini-pro-latest.description": "Ultima versione di Gemini Pro",
  "meta/Llama-3.2-90B-Vision-Instruct.description": "Ragionamento avanzato su immagini per applicazioni di agenti con comprensione visiva.",
  "meta/Llama-3.3-70B-Instruct.description": "Llama 3.3 è il modello Llama open-source multilingue più avanzato, con prestazioni simili a un modello da 405B a costi molto contenuti. Basato su Transformer, è stato migliorato con SFT e RLHF per garantire utilità e sicurezza. La versione ottimizzata per istruzioni è progettata per chat multilingue e supera molti modelli open e closed nei benchmark di settore. Data di cutoff: dicembre 2023.",
  "meta/Meta-Llama-3-70B-Instruct.description": "Un potente modello da 70 miliardi di parametri eccellente nel ragionamento, nella programmazione e nei compiti linguistici generali.",
  "meta/Meta-Llama-3-8B-Instruct.description": "Un modello versatile da 8 miliardi di parametri ottimizzato per chat e generazione di testo.",
  "meta/Meta-Llama-3.1-405B-Instruct.description": "Modello testuale Llama 3.1 ottimizzato per chat multilingue, con prestazioni elevate nei benchmark di settore tra i modelli open e closed.",
  "meta/Meta-Llama-3.1-70B-Instruct.description": "Modello testuale Llama 3.1 ottimizzato per chat multilingue, con prestazioni elevate nei benchmark di settore tra i modelli open e closed.",
  "meta/Meta-Llama-3.1-8B-Instruct.description": "Modello testuale Llama 3.1 ottimizzato per chat multilingue, con prestazioni elevate nei benchmark di settore tra i modelli open e closed.",
  "meta/llama-3-70b.description": "Modello open-source da 70 miliardi di parametri ottimizzato da Meta per seguire istruzioni, distribuito da Groq su hardware LPU per inferenza rapida ed efficiente.",
  "meta/llama-3-8b.description": "Modello open-source da 8 miliardi di parametri ottimizzato da Meta per seguire istruzioni, distribuito da Groq su hardware LPU per inferenza rapida ed efficiente.",
  "meta/llama-3.1-405b-instruct.description": "Modello linguistico avanzato che supporta generazione di dati sintetici, distillazione della conoscenza e ragionamento per chatbot, programmazione e compiti specifici di dominio.",
  "meta/llama-3.1-70b-instruct.description": "Progettato per dialoghi complessi con eccellente comprensione del contesto, ragionamento e generazione di testo.",
  "meta/llama-3.1-70b.description": "Versione aggiornata di Meta Llama 3 70B Instruct con contesto da 128K, supporto multilingue e ragionamento migliorato.",
  "meta/llama-3.1-8b-instruct.description": "Modello all'avanguardia con forte comprensione linguistica, capacità di ragionamento e generazione di testo.",
  "meta/llama-3.1-8b.description": "Llama 3.1 8B supporta una finestra di contesto da 128K, ideale per chat in tempo reale e analisi dei dati, offrendo un notevole risparmio rispetto ai modelli più grandi. Distribuito da Groq su hardware LPU per inferenza rapida ed efficiente.",
  "meta/llama-3.2-11b-vision-instruct.description": "Modello linguistico-visivo di frontiera eccellente nel ragionamento di alta qualità a partire da immagini.",
  "meta/llama-3.2-11b.description": "Modello di ragionamento su immagini ottimizzato per il riconoscimento visivo, il ragionamento su immagini, la didascalia e le domande generali su immagini (input testo+immagine, output testuale).",
  "meta/llama-3.2-1b-instruct.description": "Modello linguistico compatto e all'avanguardia con forte comprensione, ragionamento e generazione di testo.",
  "meta/llama-3.2-1b.description": "Modello solo testuale per casi d'uso su dispositivo come recupero locale multilingue, sintesi e riscrittura.",
  "meta/llama-3.2-3b-instruct.description": "Modello linguistico compatto e all'avanguardia con forte comprensione, ragionamento e generazione di testo.",
  "meta/llama-3.2-3b.description": "Modello solo testuale ottimizzato per casi d'uso su dispositivo come recupero locale multilingue, sintesi e riscrittura.",
  "meta/llama-3.2-90b-vision-instruct.description": "Modello linguistico-visivo di frontiera eccellente nel ragionamento di alta qualità a partire da immagini.",
  "meta/llama-3.2-90b.description": "Modello di ragionamento su immagini ottimizzato per il riconoscimento visivo, il ragionamento su immagini, la didascalia e le domande generali su immagini (input testo+immagine, output testuale).",
  "meta/llama-3.3-70b-instruct.description": "Modello linguistico avanzato con forti capacità di ragionamento, matematica, buon senso e chiamata di funzioni.",
  "meta/llama-3.3-70b.description": "Un perfetto equilibrio tra prestazioni ed efficienza. Progettato per IA conversazionale ad alte prestazioni in creazione di contenuti, applicazioni aziendali e ricerca, con forte comprensione linguistica per sintesi, classificazione, analisi del sentiment e generazione di codice.",
  "meta/llama-4-maverick.description": "La famiglia Llama 4 è una serie di modelli AI nativamente multimodali che supportano esperienze testuali e multimodali, utilizzando MoE per una comprensione avanzata di testo e immagini. Llama 4 Maverick è un modello da 17B con 128 esperti, distribuito da DeepInfra.",
  "meta/llama-4-scout.description": "La famiglia Llama 4 è una serie di modelli AI nativamente multimodali che supportano esperienze testuali e multimodali, utilizzando MoE per una comprensione avanzata di testo e immagini. Llama 4 Scout è un modello da 17B con 16 esperti, distribuito da DeepInfra."
}
