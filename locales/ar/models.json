{
  "01-ai/yi-1.5-34b-chat.description": "أحدث نموذج مفتوح المصدر من 01.AI، مدرب بدقة ويحتوي على 34 مليار معلمة، يدعم سيناريوهات حوار متعددة، ومدرب على بيانات عالية الجودة ومتوافق مع تفضيلات البشر.",
  "01-ai/yi-1.5-9b-chat.description": "أحدث نموذج مفتوح المصدر من 01.AI، مدرب بدقة ويحتوي على 9 مليارات معلمة، يدعم سيناريوهات حوار متعددة، ومدرب على بيانات عالية الجودة ومتوافق مع تفضيلات البشر.",
  "360/deepseek-r1.description": "نموذج DeepSeek-R1 من 360 يستخدم التعلم المعزز واسع النطاق في مرحلة ما بعد التدريب لتعزيز قدرات الاستدلال بشكل كبير باستخدام الحد الأدنى من البيانات الموسومة. يضاهي نموذج OpenAI o1 في مهام الرياضيات والبرمجة والاستدلال اللغوي.",
  "360gpt-pro-trans.description": "نموذج متخصص في الترجمة، مدرب بدقة لتحقيق جودة ترجمة رائدة.",
  "360gpt-pro.description": "360GPT Pro هو نموذج رئيسي من 360 للذكاء الاصطناعي يتميز بكفاءة عالية في معالجة النصوص لمجموعة متنوعة من سيناريوهات معالجة اللغة الطبيعية، ويدعم فهم النصوص الطويلة والحوار متعدد الأدوار.",
  "360gpt-turbo-responsibility-8k.description": "360GPT Turbo Responsibility 8K يركز على الأمان الدلالي والمسؤولية في التطبيقات الحساسة للمحتوى، لضمان تجربة مستخدم دقيقة وموثوقة.",
  "360gpt-turbo.description": "360GPT Turbo يقدم أداءً قويًا في الحوسبة والدردشة مع فهم دلالي ممتاز وكفاءة عالية في التوليد، مما يجعله مثاليًا للمؤسسات والمطورين.",
  "360gpt2-o1.description": "360gpt2-o1 يبني سلسلة التفكير من خلال البحث الشجري وآلية الانعكاس والتدريب بالتعلم المعزز، مما يمكنه من التفكير الذاتي وتصحيح الأخطاء.",
  "360gpt2-pro.description": "360GPT2 Pro هو نموذج متقدم لمعالجة اللغة الطبيعية من 360 يتميز بتوليد وفهم نصوص ممتاز، خاصة في المهام الإبداعية، ويعالج التحولات المعقدة ولعب الأدوار.",
  "360zhinao2-o1.description": "360zhinao2-o1 يبني سلسلة التفكير من خلال البحث الشجري وآلية الانعكاس والتدريب بالتعلم المعزز، مما يمكنه من التفكير الذاتي وتصحيح الأخطاء.",
  "4.0Ultra.description": "Spark Ultra هو أقوى نموذج في سلسلة Spark، يعزز فهم النصوص وتلخيصها، ويطور البحث عبر الإنترنت. يُعد حلاً شاملاً لزيادة الإنتاجية في بيئة العمل وتقديم إجابات دقيقة، مما يجعله منتجًا ذكيًا رائدًا.",
  "AnimeSharp.description": "AnimeSharp (المعروف أيضًا باسم \"4x-AnimeSharp\") هو نموذج مفتوح المصدر لتحسين دقة الصور يعتمد على ESRGAN من Kim2091، يركز على تكبير وتحسين صور الأنمي. تم تغيير اسمه من \"4x-TextSharpV1\" في فبراير 2022، وكان مخصصًا أيضًا لصور النصوص ولكنه أصبح محسنًا بشكل كبير لمحتوى الأنمي.",
  "Baichuan2-Turbo.description": "يستخدم تعزيز البحث لربط النموذج بالمعرفة المتخصصة ومعرفة الويب. يدعم تحميل ملفات PDF/Word وإدخال الروابط لاسترجاع شامل وفي الوقت المناسب، مع مخرجات دقيقة واحترافية.",
  "Baichuan3-Turbo-128k.description": "بفضل نافذة السياق الطويلة جدًا بحجم 128K، تم تحسينه لسيناريوهات المؤسسات عالية التكرار مع مكاسب كبيرة وقيمة قوية. مقارنة بـ Baichuan2، تحسنت قدرات إنشاء المحتوى بنسبة 20%، والإجابة على الأسئلة المعرفية بنسبة 17%، ولعب الأدوار بنسبة 40%. الأداء العام أفضل من GPT-3.5.",
  "Baichuan3-Turbo.description": "تم تحسينه لسيناريوهات المؤسسات عالية التكرار مع مكاسب كبيرة وقيمة قوية. مقارنة بـ Baichuan2، تحسنت قدرات إنشاء المحتوى بنسبة 20%، والإجابة على الأسئلة المعرفية بنسبة 17%، ولعب الأدوار بنسبة 40%. الأداء العام أفضل من GPT-3.5.",
  "Baichuan4-Air.description": "نموذج رائد في الصين، يتفوق على النماذج العالمية في المهام الصينية مثل المعرفة، النصوص الطويلة، والتوليد الإبداعي. كما يتميز بقدرات متعددة الوسائط رائدة في الصناعة ونتائج قوية في المعايير الموثوقة.",
  "Baichuan4-Turbo.description": "نموذج رائد في الصين، يتفوق على النماذج العالمية في المهام الصينية مثل المعرفة، النصوص الطويلة، والتوليد الإبداعي. كما يتميز بقدرات متعددة الوسائط رائدة في الصناعة ونتائج قوية في المعايير الموثوقة.",
  "Baichuan4.description": "أداء محلي رائد، يتفوق على النماذج العالمية في المهام الصينية مثل المعرفة الموسوعية، النصوص الطويلة، والتوليد الإبداعي. كما يقدم قدرات متعددة الوسائط رائدة ونتائج قوية في المعايير.",
  "ByteDance-Seed/Seed-OSS-36B-Instruct.description": "Seed-OSS هي عائلة من النماذج مفتوحة المصدر من ByteDance Seed، مصممة للتعامل مع السياقات الطويلة، والاستدلال، والمهام العامة. Seed-OSS-36B-Instruct هو نموذج موجه بالتعليم يحتوي على 36 مليار معلمة مع دعم أصلي للسياقات الطويلة جدًا لمعالجة المستندات الكبيرة أو قواعد الشيفرة. يتميز بقدرات قوية في الاستدلال وتوليد الشيفرة واستخدام الأدوات. من أبرز ميزاته \"ميزانية التفكير\" التي تسمح بطول استدلال مرن لتحسين الكفاءة.",
  "DeepSeek-R1-Distill-Llama-70B.description": "تم تقطير DeepSeek R1، النموذج الأكبر والأذكى في مجموعة DeepSeek، إلى بنية Llama 70B. تُظهر المعايير والتقييمات البشرية أنه أذكى من Llama 70B الأساسي، خاصة في مهام الرياضيات ودقة الحقائق.",
  "DeepSeek-R1-Distill-Qwen-1.5B.description": "نموذج مقطر من DeepSeek-R1 يعتمد على Qwen2.5-Math-1.5B. يعمل التعلم المعزز وبيانات البداية الباردة على تحسين أداء الاستدلال، مما يضع معايير جديدة للمهام المتعددة في النماذج المفتوحة.",
  "DeepSeek-R1-Distill-Qwen-14B.description": "نماذج DeepSeek-R1-Distill مدربة بدقة من نماذج مفتوحة المصدر باستخدام بيانات عينة تم إنشاؤها بواسطة DeepSeek-R1.",
  "DeepSeek-R1-Distill-Qwen-32B.description": "نماذج DeepSeek-R1-Distill مدربة بدقة من نماذج مفتوحة المصدر باستخدام بيانات عينة تم إنشاؤها بواسطة DeepSeek-R1.",
  "DeepSeek-R1-Distill-Qwen-7B.description": "نموذج مقطر من DeepSeek-R1 يعتمد على Qwen2.5-Math-7B. يعمل التعلم المعزز وبيانات البداية الباردة على تحسين أداء الاستدلال، مما يضع معايير جديدة للمهام المتعددة في النماذج المفتوحة.",
  "DeepSeek-R1.description": "يطبق DeepSeek-R1 التعلم المعزز واسع النطاق في مرحلة ما بعد التدريب، مما يعزز قدرات الاستدلال بشكل كبير باستخدام القليل من البيانات الموسومة. يضاهي نموذج OpenAI o1 في مهام الرياضيات، البرمجة، والاستدلال اللغوي.",
  "DeepSeek-V3-1.description": "DeepSeek V3.1 هو نموذج استدلال من الجيل التالي يتميز بتحسينات في الاستدلال المعقد وسلسلة التفكير، مناسب لمهام التحليل العميق.",
  "DeepSeek-V3-Fast.description": "المزود: sophnet. DeepSeek V3 Fast هو الإصدار عالي السرعة من DeepSeek V3 0324، بدقة كاملة (غير مضغوطة) مع أداء أقوى في البرمجة والرياضيات واستجابات أسرع.",
  "DeepSeek-V3.1-Fast.description": "DeepSeek V3.1 Fast هو الإصدار السريع عالي السرعة من DeepSeek V3.1. وضع تفكير هجين: من خلال قوالب الدردشة، يدعم نموذج واحد كلاً من أوضاع التفكير وغير التفكير. استخدام أدوات أذكى: التحسينات بعد التدريب تعزز أداء المهام التي تتطلب أدوات ووكلاء.",
  "DeepSeek-V3.1-Think.description": "وضع التفكير في DeepSeek-V3.1: نموذج استدلال هجين جديد يدعم أوضاع التفكير وغير التفكير، أكثر كفاءة من DeepSeek-R1-0528. التحسينات بعد التدريب تعزز بشكل كبير استخدام الأدوات وأداء المهام التي تتطلب وكلاء.",
  "DeepSeek-V3.description": "DeepSeek-V3 هو نموذج MoE تم تطويره بواسطة DeepSeek. يتفوق على نماذج مفتوحة أخرى مثل Qwen2.5-72B وLlama-3.1-405B في العديد من المعايير، ويتنافس مع النماذج المغلقة الرائدة مثل GPT-4o وClaude 3.5 Sonnet.",
  "Doubao-lite-128k.description": "يوفر Doubao-lite استجابات فائقة السرعة وقيمة أفضل، مع خيارات مرنة عبر السيناريوهات. يدعم سياق 128K للاستدلال والتدريب الدقيق.",
  "Doubao-lite-32k.description": "يوفر Doubao-lite استجابات فائقة السرعة وقيمة أفضل، مع خيارات مرنة عبر السيناريوهات. يدعم سياق 32K للاستدلال والتدريب الدقيق.",
  "Doubao-lite-4k.description": "يوفر Doubao-lite استجابات فائقة السرعة وقيمة أفضل، مع خيارات مرنة عبر السيناريوهات. يدعم سياق 4K للاستدلال والتدريب الدقيق.",
  "Doubao-pro-128k.description": "أفضل نموذج رئيسي للأداء في المهام المعقدة، يتميز بقوة في الإجابة المرجعية، التلخيص، الإبداع، التصنيف، ولعب الأدوار. يدعم سياق 128K للاستدلال والتدريب الدقيق.",
  "Doubao-pro-32k.description": "أفضل نموذج رئيسي للأداء في المهام المعقدة، يتميز بقوة في الإجابة المرجعية، التلخيص، الإبداع، التصنيف، ولعب الأدوار. يدعم سياق 32K للاستدلال والتدريب الدقيق.",
  "Doubao-pro-4k.description": "أفضل نموذج رئيسي للأداء في المهام المعقدة، يتميز بقوة في الإجابة المرجعية، التلخيص، الإبداع، التصنيف، ولعب الأدوار. يدعم سياق 4K للاستدلال والتدريب الدقيق.",
  "DreamO.description": "DreamO هو نموذج مفتوح المصدر لتخصيص الصور تم تطويره بشكل مشترك من قبل ByteDance وجامعة بكين، يستخدم بنية موحدة لدعم توليد الصور متعددة المهام. يستخدم نمذجة تركيبية فعالة لإنشاء صور مخصصة ومتسقة بدرجة عالية بناءً على الهوية، الموضوع، النمط، الخلفية، وغيرها من الشروط التي يحددها المستخدم.",
  "ERNIE-3.5-128K.description": "نموذج اللغة الكبير الرائد من بايدو، مدرّب على مجموعات ضخمة من النصوص الصينية والإنجليزية، يتمتع بقدرات عامة قوية في المحادثة، الإبداع، واستخدام الإضافات؛ يدعم التكامل التلقائي مع إضافة بحث بايدو للحصول على إجابات حديثة.",
  "ERNIE-3.5-8K-Preview.description": "نموذج اللغة الكبير الرائد من بايدو، مدرّب على مجموعات ضخمة من النصوص الصينية والإنجليزية، يتمتع بقدرات عامة قوية في المحادثة، الإبداع، واستخدام الإضافات؛ يدعم التكامل التلقائي مع إضافة بحث بايدو للحصول على إجابات حديثة.",
  "ERNIE-3.5-8K.description": "نموذج اللغة الكبير الرائد من بايدو، مدرّب على مجموعات ضخمة من النصوص الصينية والإنجليزية، يتمتع بقدرات عامة قوية في المحادثة، الإبداع، واستخدام الإضافات؛ يدعم التكامل التلقائي مع إضافة بحث بايدو للحصول على إجابات حديثة.",
  "ERNIE-4.0-8K-Latest.description": "نموذج اللغة الكبير فائق الحجم من بايدو مع تحسينات شاملة مقارنة بـ ERNIE 3.5، مناسب للمهام المعقدة في مختلف المجالات؛ يدعم التكامل مع إضافة بحث بايدو للحصول على إجابات حديثة.",
  "ERNIE-4.0-8K-Preview.description": "نموذج اللغة الكبير فائق الحجم من بايدو مع تحسينات شاملة مقارنة بـ ERNIE 3.5، مناسب للمهام المعقدة في مختلف المجالات؛ يدعم التكامل مع إضافة بحث بايدو للحصول على إجابات حديثة.",
  "ERNIE-4.0-Turbo-8K-Latest.description": "نموذج اللغة الكبير فائق الحجم من بايدو بأداء عام قوي للمهام المعقدة، مع تكامل إضافة بحث بايدو للحصول على إجابات حديثة. يتفوق على ERNIE 4.0.",
  "ERNIE-4.0-Turbo-8K-Preview.description": "نموذج اللغة الكبير فائق الحجم من بايدو بأداء عام قوي للمهام المعقدة، مع تكامل إضافة بحث بايدو للحصول على إجابات حديثة. يتفوق على ERNIE 4.0.",
  "ERNIE-Character-8K.description": "نموذج لغة متخصص من بايدو للمجالات العمودية مثل شخصيات الألعاب، خدمة العملاء، وتمثيل الأدوار، يتميز باتساق أوضح في الشخصية، واتباع أقوى للتعليمات، وقدرات استدلال أفضل.",
  "ERNIE-Lite-Pro-128K.description": "نموذج لغة خفيف الوزن من بايدو يوازن بين الجودة وأداء الاستدلال، أفضل من ERNIE Lite ومناسب لمسرّعات الحوسبة منخفضة الموارد.",
  "ERNIE-Speed-128K.description": "أحدث نموذج عالي الأداء من بايدو (2024) بقدرات عامة قوية، مناسب كأساس للتخصيص لمواقف محددة، ويتميز بأداء استدلال ممتاز.",
  "ERNIE-Speed-Pro-128K.description": "أحدث نموذج عالي الأداء من بايدو (2024) بقدرات عامة قوية، أفضل من ERNIE Speed، مناسب كأساس للتخصيص مع أداء استدلال ممتاز.",
  "FLUX-1.1-pro.description": "FLUX.1.1 Pro",
  "FLUX.1-Kontext-dev.description": "FLUX.1-Kontext-dev هو نموذج توليد وتحرير صور متعدد الوسائط من Black Forest Labs، مبني على بنية Rectified Flow Transformer ويحتوي على 12 مليار معامل. يركز على توليد الصور، إعادة بنائها، تحسينها أو تحريرها ضمن شروط سياقية محددة. يجمع بين قدرات التوليد القابلة للتحكم لنماذج الانتشار ونمذجة السياق باستخدام Transformer، ويدعم مخرجات عالية الجودة لمهام مثل inpainting، outpainting، وإعادة بناء المشاهد البصرية.",
  "FLUX.1-Kontext-pro.description": "FLUX.1 Kontext [pro]",
  "FLUX.1-dev.description": "FLUX.1-dev هو نموذج لغة متعدد الوسائط مفتوح المصدر من Black Forest Labs، محسن لمهام النص والصورة، ويجمع بين فهم وتوليد النصوص/الصور. مبني على نماذج LLM متقدمة (مثل Mistral-7B)، ويستخدم مشفر رؤية مصمم بعناية وضبط تعليمات متعدد المراحل لتمكين التنسيق متعدد الوسائط والاستدلال المعقد.",
  "Gryphe/MythoMax-L2-13b.description": "MythoMax-L2 (13B) هو نموذج مبتكر لمجالات متنوعة ومهام معقدة.",
  "HelloMeme.description": "HelloMeme هي أداة ذكاء اصطناعي لإنشاء الميمات، الصور المتحركة (GIFs)، أو مقاطع الفيديو القصيرة من الصور أو الحركات التي تقدمها. لا تتطلب مهارات رسم أو برمجة—فقط صورة مرجعية—لإنتاج محتوى ممتع وجذاب ومتناسق من حيث الأسلوب.",
  "HiDream-I1-Full.description": "HiDream-E1-Full هو نموذج تحرير صور متعدد الوسائط مفتوح المصدر من HiDream.ai، مبني على بنية Diffusion Transformer متقدمة وفهم لغوي قوي (مدمج مع LLaMA 3.1-8B-Instruct). يدعم توليد الصور باستخدام اللغة الطبيعية، نقل الأسلوب، التعديلات المحلية، وإعادة التلوين، مع فهم وتنفيذ ممتازين للنصوص والصور.",
  "HunyuanDiT-v1.2-Diffusers-Distilled.description": "hunyuandit-v1.2-distilled هو نموذج تحويل نص إلى صورة خفيف الوزن، محسن عبر التقطير لتوليد صور عالية الجودة بسرعة، ومناسب بشكل خاص للبيئات منخفضة الموارد والتوليد في الوقت الحقيقي.",
  "InstantCharacter.description": "InstantCharacter هو نموذج توليد شخصيات مخصص بدون ضبط من Tencent AI لعام 2025، يهدف إلى توليد شخصيات عالية الدقة ومتسقة عبر السيناريوهات. يمكنه نمذجة شخصية من صورة مرجعية واحدة ونقلها بمرونة عبر الأساليب، الحركات، والخلفيات.",
  "InternVL2-8B.description": "InternVL2-8B هو نموذج رؤية-لغة قوي يدعم معالجة الصور والنصوص متعددة الوسائط، يتعرف بدقة على محتوى الصور ويولد أوصافًا أو إجابات ذات صلة.",
  "InternVL2.5-26B.description": "InternVL2.5-26B هو نموذج رؤية-لغة قوي يدعم معالجة الصور والنصوص متعددة الوسائط، يتعرف بدقة على محتوى الصور ويولد أوصافًا أو إجابات ذات صلة.",
  "Kolors.description": "Kolors هو نموذج تحويل نص إلى صورة طوره فريق Kolors في Kuaishou. مدرب على مليارات المعاملات، يتميز بجودة بصرية عالية، فهم دلالي قوي للغة الصينية، وقدرات متميزة في عرض النصوص.",
  "Kwai-Kolors/Kolors.description": "Kolors هو نموذج تحويل نص إلى صورة واسع النطاق من فريق Kolors في Kuaishou. مدرب على مليارات أزواج النصوص والصور، يتفوق في الجودة البصرية، الدقة الدلالية المعقدة، وعرض النصوص الصينية/الإنجليزية، مع فهم وتوليد قويين للمحتوى الصيني.",
  "Kwaipilot/KAT-Dev.description": "KAT-Dev (32B) هو نموذج مفتوح المصدر لمهام هندسة البرمجيات. يحقق معدل حل 62.4% على SWE-Bench Verified، ويحتل المرتبة الخامسة بين النماذج المفتوحة. تم تحسينه عبر التدريب الوسيط، SFT، وRL لإكمال الشيفرة، إصلاح الأخطاء، ومراجعة الشيفرة.",
  "Llama-3.2-11B-Vision-Instruct.description": "استدلال بصري قوي على الصور عالية الدقة، مناسب لتطبيقات الفهم البصري.",
  "Llama-3.2-90B-Vision-Instruct\t.description": "استدلال بصري متقدم لتطبيقات الفهم البصري المعتمدة على الوكلاء.",
  "Meta-Llama-3-3-70B-Instruct.description": "Llama 3.3 70B هو نموذج Transformer متعدد الاستخدامات لمهام المحادثة والتوليد.",
  "Meta-Llama-3.1-405B-Instruct.description": "نموذج Llama 3.1 مضبوط على التعليمات، محسن للمحادثة متعددة اللغات، ويؤدي بقوة في معايير الصناعة الشائعة بين النماذج المفتوحة والمغلقة.",
  "Meta-Llama-3.1-70B-Instruct.description": "نموذج Llama 3.1 مضبوط على التعليمات، محسن للمحادثة متعددة اللغات، ويؤدي بقوة في معايير الصناعة الشائعة بين النماذج المفتوحة والمغلقة.",
  "Meta-Llama-3.1-8B-Instruct.description": "نموذج Llama 3.1 مضبوط على التعليمات، محسن للمحادثة متعددة اللغات، ويؤدي بقوة في معايير الصناعة الشائعة بين النماذج المفتوحة والمغلقة.",
  "Meta-Llama-3.2-1B-Instruct.description": "نموذج لغة صغير متطور يتمتع بفهم لغوي قوي، استدلال ممتاز، وتوليد نصوص عالي الجودة.",
  "Meta-Llama-3.2-3B-Instruct.description": "نموذج لغة صغير متطور يتمتع بفهم لغوي قوي، استدلال ممتاز، وتوليد نصوص عالي الجودة.",
  "Meta-Llama-3.3-70B-Instruct.description": "Llama 3.3 هو النموذج مفتوح المصدر متعدد اللغات الأكثر تقدمًا من Llama، يقدم أداءً قريبًا من نموذج 405B بتكلفة منخفضة جدًا. يعتمد على بنية Transformer ومحسن باستخدام SFT وRLHF لتحقيق الفائدة والسلامة. النسخة المضبوطة على التعليمات محسنّة للمحادثة متعددة اللغات وتتفوّق على العديد من النماذج المفتوحة والمغلقة في معايير الصناعة. تاريخ التحديث المعرفي: ديسمبر 2023.",
  "Meta-Llama-4-Maverick-17B-128E-Instruct-FP8.description": "Llama 4 Maverick هو نموذج MoE كبير مع تفعيل خبراء فعال لأداء استدلال قوي.",
  "MiniMax-M1.description": "نموذج استدلال داخلي جديد بسلسلة تفكير تصل إلى 80K ومدخلات حتى 1M، يقدم أداءً مماثلاً لأفضل النماذج العالمية.",
  "MiniMax-M2-Stable.description": "مصمم لتدفقات العمل البرمجية والوكلاء بكفاءة عالية، مع قدرة تزامن أعلى للاستخدام التجاري.",
  "MiniMax-M2.1-Lightning.description": "قدرات برمجية متعددة اللغات قوية، ترتقي بتجربة البرمجة إلى مستوى جديد. أسرع وأكثر كفاءة.",
  "MiniMax-M2.1.description": "قدرات برمجية متعددة اللغات قوية، ترتقي بتجربة البرمجة إلى مستوى جديد.",
  "MiniMax-M2.description": "مصمم خصيصًا للبرمجة الفعالة وتدفقات عمل الوكلاء.",
  "MiniMax-Text-01.description": "MiniMax-01 يقدم انتباهًا خطيًا واسع النطاق يتجاوز Transformers التقليدية، مع 456 مليار معامل و45.9 مليار مفعّلة في كل تمرير. يحقق أداءً من الدرجة الأولى ويدعم حتى 4 ملايين رمز سياقي (32× GPT-4o، 20× Claude-3.5-Sonnet).",
  "MiniMaxAI/MiniMax-M1-80k.description": "MiniMax-M1 هو نموذج استدلال واسع النطاق بوزن مفتوح يستخدم انتباهًا هجينًا، يحتوي على 456 مليار معامل إجماليًا و~45.9 مليار مفعّلة لكل رمز. يدعم سياقًا يصل إلى 1M ويستخدم Flash Attention لتقليل FLOPs بنسبة 75% عند توليد 100K رمز مقارنة بـ DeepSeek R1. بهيكل MoE وتدريب RL هجين، يحقق أداءً رائدًا في الاستدلال طويل المدخلات ومهام هندسة البرمجيات الواقعية.",
  "MiniMaxAI/MiniMax-M2.description": "MiniMax-M2 يعيد تعريف كفاءة الوكلاء. هو نموذج MoE مدمج وسريع وفعال من حيث التكلفة يحتوي على 230 مليار معامل إجماليًا و10 مليار مفعّلة، مصمم لمهام البرمجة والوكلاء من الدرجة الأولى مع الحفاظ على ذكاء عام قوي. مع 10 مليار معامل مفعّلة فقط، ينافس نماذج أكبر بكثير، مما يجعله مثاليًا للتطبيقات عالية الكفاءة.",
  "Moonshot-Kimi-K2-Instruct.description": "يحتوي على 1 تريليون معامل إجماليًا و32 مليار مفعّلة. من بين النماذج غير المفكرة، يتصدر في المعرفة المتقدمة، الرياضيات، والبرمجة، وأقوى في مهام الوكلاء العامة. محسن لأعباء عمل الوكلاء، يمكنه اتخاذ إجراءات وليس فقط الإجابة على الأسئلة. الأفضل للمحادثات العامة الارتجالية وتجارب الوكلاء كنموذج يعمل بردود فعل دون تفكير طويل.",
  "NousResearch/Nous-Hermes-2-Mixtral-8x7B-DPO.description": "Nous Hermes 2 - Mixtral 8x7B-DPO (46.7B) هو نموذج تعليمات عالي الدقة للحسابات المعقدة.",
  "OmniConsistency.description": "تحسّن OmniConsistency التناسق الأسلوبي والتعميم في مهام تحويل الصور إلى صور من خلال إدخال محولات الانتشار واسعة النطاق (DiTs) وبيانات مزدوجة النمط، مما يمنع تدهور الأسلوب.",
  "Phi-3-medium-128k-instruct.description": "نفس نموذج Phi-3-medium ولكن مع نافذة سياق أكبر لدعم استرجاع المعرفة (RAG) أو التعليمات القليلة.",
  "Phi-3-medium-4k-instruct.description": "نموذج يحتوي على 14 مليار معلمة بجودة أعلى من Phi-3-mini، يركز على البيانات عالية الجودة التي تتطلب استدلالًا مكثفًا.",
  "Phi-3-mini-128k-instruct.description": "نفس نموذج Phi-3-mini ولكن مع نافذة سياق أكبر لدعم استرجاع المعرفة (RAG) أو التعليمات القليلة.",
  "Phi-3-mini-4k-instruct.description": "أصغر عضو في عائلة Phi-3، مُحسّن للجودة وانخفاض زمن الاستجابة.",
  "Phi-3-small-128k-instruct.description": "نفس نموذج Phi-3-small ولكن مع نافذة سياق أكبر لدعم استرجاع المعرفة (RAG) أو التعليمات القليلة.",
  "Phi-3-small-8k-instruct.description": "نموذج يحتوي على 7 مليارات معلمة بجودة أعلى من Phi-3-mini، يركز على البيانات عالية الجودة التي تتطلب استدلالًا مكثفًا.",
  "Phi-3.5-mini-instruct.description": "إصدار محدث من نموذج Phi-3-mini.",
  "Phi-3.5-vision-instrust.description": "إصدار محدث من نموذج Phi-3-vision.",
  "Pro/Qwen/Qwen2-7B-Instruct.description": "Qwen2-7B-Instruct هو نموذج لغوي كبير (LLM) موجه للتعليمات ضمن سلسلة Qwen2. يستخدم بنية Transformer مع SwiGLU، وانحياز QKV في الانتباه، وانتباه الاستعلامات المجمعة، ويعالج مدخلات كبيرة. يتميز بأداء قوي في فهم اللغة، التوليد، المهام متعددة اللغات، البرمجة، الرياضيات، والاستدلال، متفوقًا على معظم النماذج المفتوحة ومنافسًا للنماذج التجارية. يتفوق على Qwen1.5-7B-Chat في العديد من المعايير.",
  "Pro/Qwen/Qwen2.5-7B-Instruct.description": "Qwen2.5-7B-Instruct هو جزء من أحدث سلسلة نماذج لغوية كبيرة من Alibaba Cloud. يقدم هذا النموذج ذو 7 مليارات معلمة تحسينات ملحوظة في البرمجة والرياضيات، ويدعم أكثر من 29 لغة، ويعزز اتباع التعليمات، وفهم البيانات المنظمة، وإنتاج المخرجات المنظمة (خصوصًا JSON).",
  "Pro/Qwen/Qwen2.5-Coder-7B-Instruct.description": "Qwen2.5-Coder-7B-Instruct هو أحدث نموذج لغوي كبير من Alibaba Cloud يركز على البرمجة. مبني على Qwen2.5 ومدرب على 5.5 تريليون رمز، يعزز بشكل كبير توليد الشيفرة، الاستدلال، والإصلاح، مع الحفاظ على القوة في الرياضيات والقدرات العامة، مما يوفر أساسًا قويًا لوكلاء البرمجة.",
  "Pro/Qwen/Qwen2.5-VL-7B-Instruct.description": "Qwen2.5-VL هو نموذج رؤية-لغة جديد من Qwen يتمتع بفهم بصري قوي. يحلل النصوص، الرسوم البيانية، والتخطيطات في الصور، ويفهم مقاطع الفيديو الطويلة والأحداث، ويدعم الاستدلال واستخدام الأدوات، وتحديد الكائنات عبر تنسيقات متعددة، وإنتاج مخرجات منظمة. يعزز فهم الفيديو من خلال تحسينات في الدقة الديناميكية ومعدل الإطارات، ويزيد من كفاءة مشفر الرؤية.",
  "Pro/THUDM/GLM-4.1V-9B-Thinking.description": "GLM-4.1V-9B-Thinking هو نموذج رؤية-لغة مفتوح المصدر من Zhipu AI ومختبر KEG في جامعة تسينغهوا، مصمم للإدراك متعدد الوسائط المعقد. مبني على GLM-4-9B-0414، ويضيف استدلال سلسلة الأفكار والتعلم المعزز (RL) لتحسين الاستدلال عبر الوسائط والاستقرار بشكل كبير.",
  "Pro/THUDM/glm-4-9b-chat.description": "GLM-4-9B-Chat هو النموذج المفتوح المصدر من سلسلة GLM-4 من Zhipu AI. يتميز بأداء قوي في الدلالات، الرياضيات، الاستدلال، البرمجة، والمعرفة. بالإضافة إلى المحادثة متعددة الأدوار، يدعم تصفح الويب، تنفيذ الشيفرة، استدعاء الأدوات المخصصة، والاستدلال على النصوص الطويلة. يدعم 26 لغة (بما في ذلك الصينية، الإنجليزية، اليابانية، الكورية، والألمانية). يحقق نتائج جيدة في AlignBench-v2، MT-Bench، MMLU، وC-Eval، ويدعم سياقًا يصل إلى 128 ألف رمز للاستخدام الأكاديمي والتجاري.",
  "Pro/deepseek-ai/DeepSeek-R1-Distill-Qwen-7B.description": "تم تقطير DeepSeek-R1-Distill-Qwen-7B من Qwen2.5-Math-7B وتم تحسينه باستخدام 800 ألف عينة مختارة من DeepSeek-R1. يتميز بأداء قوي، حيث يحقق 92.8٪ في MATH-500، و55.5٪ في AIME 2024، وتصنيف 1189 في CodeForces لنموذج بحجم 7 مليارات معلمة.",
  "Pro/deepseek-ai/DeepSeek-R1.description": "DeepSeek-R1 هو نموذج استدلال مدفوع بالتعلم المعزز يقلل التكرار ويحسن قابلية القراءة. يستخدم بيانات بداية باردة قبل التعلم المعزز لتعزيز الاستدلال، ويضاهي OpenAI-o1 في مهام الرياضيات، البرمجة، والاستدلال، ويحقق نتائج أفضل من خلال تدريب دقيق.",
  "Pro/deepseek-ai/DeepSeek-V3.1-Terminus.description": "DeepSeek-V3.1-Terminus هو إصدار محدث من نموذج V3.1، مصمم كنموذج وكيل هجين. يعالج المشكلات التي أبلغ عنها المستخدمون، ويحسن الاستقرار، وتناسق اللغة، ويقلل من الخلط بين الصينية/الإنجليزية والرموز غير الطبيعية. يدمج أوضاع التفكير وغير التفكير مع قوالب محادثة للتبديل المرن. كما يعزز أداء وكلاء الشيفرة والبحث لاستخدام أدوات أكثر موثوقية ومهام متعددة الخطوات.",
  "Pro/deepseek-ai/DeepSeek-V3.2-Exp.description": "DeepSeek-V3.2-Exp هو إصدار تجريبي من V3.2 يربط بالمعمارية التالية. يضيف انتباهًا متفرقًا (DSA) إلى V3.1-Terminus لتحسين كفاءة التدريب والاستدلال في السياقات الطويلة، مع تحسينات لاستخدام الأدوات، وفهم المستندات الطويلة، والاستدلال متعدد الخطوات. مثالي لاستكشاف كفاءة استدلال أعلى ضمن ميزانيات سياق كبيرة.",
  "Pro/deepseek-ai/DeepSeek-V3.description": "DeepSeek-V3 هو نموذج MoE يحتوي على 671 مليار معلمة، يستخدم MLA وDeepSeekMoE مع توازن تحميل خالٍ من الفقدان لتحقيق كفاءة في الاستدلال والتدريب. تم تدريبه مسبقًا على 14.8 تريليون رمز عالي الجودة وتم تحسينه باستخدام SFT وRL، متفوقًا على النماذج المفتوحة الأخرى ويقترب من النماذج المغلقة الرائدة.",
  "Pro/moonshotai/Kimi-K2-Instruct-0905.description": "Kimi K2-Instruct-0905 هو أحدث وأقوى إصدار من Kimi K2. إنه نموذج MoE من الدرجة الأولى يحتوي على إجمالي 1 تريليون و32 مليار معلمة نشطة. من أبرز ميزاته الذكاء البرمجي القوي مع تحسينات كبيرة في المعايير ومهام الوكلاء الواقعية، بالإضافة إلى تحسينات في جمالية واجهة الشيفرة وسهولة الاستخدام.",
  "Pro/moonshotai/Kimi-K2-Thinking.description": "Kimi K2 Thinking Turbo هو إصدار Turbo محسّن لسرعة الاستدلال والإنتاجية مع الحفاظ على قدرات التفكير متعدد الخطوات واستخدام الأدوات في K2 Thinking. إنه نموذج MoE يحتوي على حوالي 1 تريليون معلمة إجمالية، ويدعم سياقًا أصليًا بطول 256 ألف رمز، واستدعاء أدوات واسع النطاق ومستقر لسيناريوهات الإنتاج التي تتطلب زمن استجابة وتزامنًا صارمين.",
  "Pro/zai-org/glm-4.7.description": "GLM-4.7 هو النموذج الرائد من الجيل الجديد لشركة Zhipu، بإجمالي 355 مليار معلمة و32 مليار معلمة نشطة. يقدم تحسينات شاملة في الحوار العام، الاستدلال، وقدرات الوكلاء الذكية. يعزز GLM-4.7 مفهوم التفكير المتداخل (Interleaved Thinking)، ويقدم مفهومي التفكير المحفوظ (Preserved Thinking) والتفكير على مستوى الدور (Turn-level Thinking).",
  "QwQ-32B-Preview.description": "Qwen QwQ هو نموذج بحث تجريبي يركز على تحسين الاستدلال.",
  "Qwen/QVQ-72B-Preview.description": "QVQ-72B-Preview هو نموذج بحث من Qwen يركز على الاستدلال البصري، يتميز بفهم المشاهد المعقدة وحل مسائل الرياضيات البصرية.",
  "Qwen/QwQ-32B-Preview.description": "Qwen QwQ هو نموذج بحث تجريبي يركز على تحسين استدلال الذكاء الاصطناعي.",
  "Qwen/QwQ-32B.description": "QwQ هو نموذج استدلال ضمن عائلة Qwen. مقارنة بالنماذج التقليدية الموجهة للتعليمات، يضيف QwQ قدرات تفكير واستدلال تعزز الأداء بشكل كبير في المهام الصعبة. QwQ-32B هو نموذج استدلال متوسط الحجم ينافس نماذج استدلال رائدة مثل DeepSeek-R1 وo1-mini. يستخدم RoPE، SwiGLU، RMSNorm، وانحياز QKV في الانتباه، مع 64 طبقة و40 رأس انتباه (8 KV في GQA).",
  "Qwen/Qwen-Image-Edit-2509.description": "Qwen-Image-Edit-2509 هو أحدث إصدار لتحرير الصور من فريق Qwen. مبني على نموذج Qwen-Image بحجم 20 مليار معلمة، ويمتد من قدرات عرض النصوص القوية إلى تحرير الصور بدقة. يستخدم بنية تحكم مزدوجة، حيث تُرسل المدخلات إلى Qwen2.5-VL للتحكم الدلالي وإلى مشفر VAE للتحكم في المظهر، مما يتيح تحريرًا على مستوى الدلالة والمظهر. يدعم التعديلات المحلية (إضافة/إزالة/تعديل) والتعديلات الدلالية المتقدمة مثل إنشاء الملكية الفكرية ونقل الأسلوب مع الحفاظ على المعنى. يحقق نتائج رائدة في العديد من المعايير.",
  "Qwen/Qwen-Image.description": "Qwen-Image هو نموذج أساسي لتوليد الصور يحتوي على 20 مليار معلمة من فريق Qwen. يحقق تقدمًا كبيرًا في عرض النصوص المعقدة وتحرير الصور بدقة، خاصة للنصوص الصينية/الإنجليزية عالية الدقة. يدعم تخطيطات متعددة الأسطر والفقرة مع الحفاظ على تناسق الطباعة. بالإضافة إلى عرض النصوص، يدعم مجموعة واسعة من الأساليب من الواقعية إلى الأنمي، والتحرير المتقدم مثل نقل الأسلوب، إضافة/إزالة الكائنات، تحسين التفاصيل، تحرير النصوص، والتحكم في الوضعية، ويهدف إلى أن يكون نموذجًا أساسيًا شاملاً للإبداع البصري.",
  "Qwen/Qwen2-72B-Instruct.description": "يقدم Qwen 2 Instruct (72B) استجابة دقيقة للتعليمات، مما يجعله مناسبًا لأعباء العمل المؤسسية.",
  "Qwen/Qwen2-7B-Instruct.description": "Qwen2-7B-Instruct هو نموذج بحجم 7B مضبوط على التعليمات ضمن سلسلة Qwen2، يستخدم تقنيات Transformer وSwiGLU وQKV bias والانتباه المجمع. يتميز بقدرته على معالجة مدخلات كبيرة وأداء قوي في مجالات الفهم، التوليد، التعدد اللغوي، البرمجة، الرياضيات، والاستدلال، متفوقًا على معظم النماذج المفتوحة وسابقه Qwen1.5-7B-Chat في عدة تقييمات.",
  "Qwen/Qwen2-VL-72B-Instruct.description": "Qwen2-VL هو أحدث نموذج من سلسلة Qwen-VL، يحقق نتائج رائدة في اختبارات الرؤية مثل MathVista وDocVQA وRealWorldQA وMTVQA. يمكنه فهم مقاطع فيديو تتجاوز 20 دقيقة لأغراض الأسئلة والأجوبة، الحوار، وإنشاء المحتوى. كما يدعم الاستدلال المعقد واتخاذ القرار، ويتكامل مع الأجهزة/الروبوتات لتنفيذ إجراءات تعتمد على الرؤية. بالإضافة إلى الإنجليزية والصينية، يمكنه قراءة نصوص بلغات متعددة تشمل معظم اللغات الأوروبية، اليابانية، الكورية، العربية، والفيتنامية.",
  "Qwen/Qwen2.5-14B-Instruct.description": "Qwen2.5-14B-Instruct هو جزء من أحدث سلسلة نماذج LLM من Alibaba Cloud. يوفر هذا النموذج بحجم 14B تحسينات ملحوظة في البرمجة والرياضيات، ويدعم أكثر من 29 لغة، ويعزز اتباع التعليمات وفهم البيانات المنظمة وإنتاج مخرجات منظمة (خصوصًا بصيغة JSON).",
  "Qwen/Qwen2.5-32B-Instruct.description": "Qwen2.5-32B-Instruct هو جزء من أحدث سلسلة نماذج LLM من Alibaba Cloud. يوفر هذا النموذج بحجم 32B تحسينات ملحوظة في البرمجة والرياضيات، ويدعم أكثر من 29 لغة، ويعزز اتباع التعليمات وفهم البيانات المنظمة وإنتاج مخرجات منظمة (خصوصًا بصيغة JSON).",
  "Qwen/Qwen2.5-72B-Instruct-128K.description": "Qwen2.5-72B-Instruct هو جزء من أحدث سلسلة نماذج LLM من Alibaba Cloud. يوفر هذا النموذج بحجم 72B تحسينات في البرمجة والرياضيات، ويدعم مدخلات تصل إلى 128K ومخرجات تتجاوز 8K، ويشمل دعمًا لأكثر من 29 لغة، مع تحسينات في اتباع التعليمات وإنتاج مخرجات منظمة (خصوصًا بصيغة JSON).",
  "Qwen/Qwen2.5-72B-Instruct-Turbo.description": "Qwen2.5 هو عائلة جديدة من نماذج LLM مصممة خصيصًا لمهام تعتمد على التعليمات.",
  "Qwen/Qwen2.5-72B-Instruct.description": "Qwen2.5-72B-Instruct هو جزء من أحدث سلسلة نماذج LLM من Alibaba Cloud. يوفر هذا النموذج بحجم 72B تحسينات ملحوظة في البرمجة والرياضيات، ويدعم أكثر من 29 لغة، ويعزز اتباع التعليمات وفهم البيانات المنظمة وإنتاج مخرجات منظمة (خصوصًا بصيغة JSON).",
  "Qwen/Qwen2.5-7B-Instruct-Turbo.description": "Qwen2.5 هو عائلة جديدة من نماذج LLM مصممة خصيصًا لمهام تعتمد على التعليمات.",
  "Qwen/Qwen2.5-7B-Instruct.description": "Qwen2.5-7B-Instruct هو جزء من أحدث سلسلة نماذج LLM من Alibaba Cloud. يوفر هذا النموذج بحجم 7B تحسينات ملحوظة في البرمجة والرياضيات، ويدعم أكثر من 29 لغة، ويعزز اتباع التعليمات وفهم البيانات المنظمة وإنتاج مخرجات منظمة (خصوصًا بصيغة JSON).",
  "Qwen/Qwen2.5-Coder-32B-Instruct.description": "Qwen2.5 Coder 32B Instruct هو أحدث نموذج LLM من Alibaba Cloud يركز على البرمجة. مبني على Qwen2.5 ومدرب على 5.5 تريليون رمز، يعزز بشكل كبير توليد الشيفرة، الاستدلال، وتصحيح الأخطاء، مع الحفاظ على قدرات قوية في الرياضيات والمهام العامة، مما يجعله أساسًا قويًا لوكلاء البرمجة.",
  "Qwen/Qwen2.5-Coder-7B-Instruct.description": "Qwen2.5-Coder-7B-Instruct هو أحدث نموذج LLM من Alibaba Cloud يركز على البرمجة. مبني على Qwen2.5 ومدرب على 5.5 تريليون رمز، يعزز بشكل كبير توليد الشيفرة، الاستدلال، وتصحيح الأخطاء، مع الحفاظ على قدرات قوية في الرياضيات والمهام العامة، مما يجعله أساسًا متينًا لوكلاء البرمجة.",
  "Qwen/Qwen2.5-VL-32B-Instruct.description": "Qwen2.5-VL-32B-Instruct هو نموذج متعدد الوسائط من فريق Qwen. يتعرف على الكائنات الشائعة ويحلل النصوص، الرسوم البيانية، الأيقونات، الرسومات، والتصاميم. كوكل بصري، يمكنه الاستدلال والتحكم الديناميكي في الأدوات، بما في ذلك استخدام الحاسوب والهاتف. يحدد الكائنات بدقة وينتج مخرجات منظمة للفواتير والجداول. مقارنة بـ Qwen2-VL، يوفر تحسينات إضافية في الرياضيات وحل المشكلات، مع استجابات مفضلة أكثر من قبل البشر.",
  "Qwen/Qwen2.5-VL-72B-Instruct.description": "Qwen2.5-VL هو نموذج رؤية-لغة في سلسلة Qwen2.5 مع ترقيات رئيسية: فهم بصري أقوى للكائنات، النصوص، الرسوم البيانية، والتصاميم؛ الاستدلال كوكل بصري باستخدام أدوات ديناميكية؛ فهم مقاطع فيديو تتجاوز الساعة والتقاط الأحداث الرئيسية؛ تحديد دقيق للكائنات باستخدام مربعات أو نقاط؛ ومخرجات منظمة للبيانات الممسوحة مثل الفواتير والجداول.",
  "Qwen/Qwen3-14B.description": "Qwen3 هو الجيل التالي من نموذج Tongyi Qwen، يحقق تقدمًا كبيرًا في الاستدلال، القدرات العامة، قدرات الوكلاء، والأداء متعدد اللغات، ويدعم التبديل بين أوضاع التفكير.",
  "Qwen/Qwen3-235B-A22B-Instruct-2507.description": "Qwen3-235B-A22B-Instruct-2507 هو النموذج الرائد من نوع MoE في سلسلة Qwen3، يحتوي على 235 مليار معلمة إجمالية و22 مليار نشطة. هو إصدار غير مفكر محدث يركز على تحسين اتباع التعليمات، الاستدلال المنطقي، فهم النصوص، الرياضيات، العلوم، البرمجة، واستخدام الأدوات. كما يوسع المعرفة متعددة اللغات ويعزز التوافق مع تفضيلات المستخدم في المهام المفتوحة الذاتية.",
  "Qwen/Qwen3-235B-A22B-Thinking-2507.description": "Qwen3-235B-A22B-Thinking-2507 هو نموذج Qwen3 مخصص للاستدلال المعقد. يستخدم بنية MoE مع 235 مليار معلمة إجمالية وحوالي 22 مليار نشطة لكل رمز لتعزيز الكفاءة. كنموذج تفكير مخصص، يظهر تقدمًا كبيرًا في المنطق، الرياضيات، العلوم، البرمجة، والمعايير الأكاديمية، محققًا أداءً رائدًا في التفكير المفتوح. كما يحسن اتباع التعليمات، استخدام الأدوات، وتوليد النصوص، ويدعم سياقًا يصل إلى 256K للاستدلال العميق والوثائق الطويلة.",
  "Qwen/Qwen3-235B-A22B.description": "Qwen3 هو الجيل التالي من نموذج Tongyi Qwen، يحقق تقدمًا كبيرًا في الاستدلال، القدرات العامة، قدرات الوكلاء، والأداء متعدد اللغات، ويدعم التبديل بين أوضاع التفكير.",
  "Qwen/Qwen3-30B-A3B-Instruct-2507.description": "Qwen3-30B-A3B-Instruct-2507 هو الإصدار غير المفكر المحدث من Qwen3-30B-A3B. هو نموذج MoE يحتوي على 30.5 مليار معلمة إجمالية و3.3 مليار نشطة. يعزز بشكل كبير اتباع التعليمات، الاستدلال المنطقي، فهم النصوص، الرياضيات، العلوم، البرمجة، واستخدام الأدوات، ويوسع المعرفة متعددة اللغات، ويتماشى بشكل أفضل مع تفضيلات المستخدم في المهام المفتوحة الذاتية. يدعم سياقًا يصل إلى 256K. هذا النموذج غير مفكر فقط ولن ينتج علامات `<think></think>`.",
  "Qwen/Qwen3-30B-A3B-Thinking-2507.description": "Qwen3-30B-A3B-Thinking-2507 هو أحدث نموذج تفكير في سلسلة Qwen3. هو نموذج MoE يحتوي على 30.5 مليار معلمة إجمالية و3.3 مليار نشطة، يركز على المهام المعقدة. يظهر تقدمًا كبيرًا في المنطق، الرياضيات، العلوم، البرمجة، والمعايير الأكاديمية، ويحسن اتباع التعليمات، استخدام الأدوات، توليد النصوص، والتوافق مع التفضيلات. يدعم سياقًا يصل إلى 256K ويمكن توسيعه إلى مليون رمز. هذا الإصدار مصمم لوضع التفكير مع استدلال تفصيلي خطوة بخطوة وقدرات وكيل قوية.",
  "Qwen/Qwen3-30B-A3B.description": "Qwen3 هو الجيل التالي من نموذج Tongyi Qwen، يحقق تقدمًا كبيرًا في الاستدلال، القدرات العامة، قدرات الوكلاء، والأداء متعدد اللغات، ويدعم التبديل بين أوضاع التفكير.",
  "Qwen/Qwen3-32B.description": "Qwen3 هو الجيل التالي من نموذج Tongyi Qwen، يحقق تقدمًا كبيرًا في الاستدلال، القدرات العامة، قدرات الوكلاء، والأداء متعدد اللغات، ويدعم التبديل بين أوضاع التفكير.",
  "Qwen/Qwen3-8B.description": "Qwen3 هو الجيل التالي من نموذج Tongyi Qwen، يحقق تقدمًا كبيرًا في الاستدلال، القدرات العامة، قدرات الوكلاء، والأداء متعدد اللغات، ويدعم التبديل بين أوضاع التفكير.",
  "Qwen/Qwen3-Coder-30B-A3B-Instruct.description": "Qwen3-Coder-30B-A3B-Instruct هو نموذج برمجة من سلسلة Qwen3. مصمم لتحقيق أداء وكفاءة عالية مع تعزيز قدرات البرمجة. يظهر تفوقًا في البرمجة الوكيلة، تشغيل المتصفح التلقائي، واستخدام الأدوات بين النماذج المفتوحة. يدعم سياقًا يصل إلى 256K ويمكن توسيعه إلى مليون رمز لفهم على مستوى قواعد الشيفرة. يدعم البرمجة الوكيلة على منصات مثل Qwen Code وCLINE باستخدام تنسيق مخصص لاستدعاء الوظائف.",
  "Qwen/Qwen3-Coder-480B-A35B-Instruct.description": "Qwen3-Coder-480B-A35B-Instruct هو أقوى نموذج برمجة من Alibaba حتى الآن. يعتمد على بنية MoE ويحتوي على 480 مليار معلمة إجمالية و35 مليار معلمة نشطة، مما يوازن بين الكفاءة والأداء. يدعم سياقًا يصل إلى 256 ألف رمز بشكل أصلي، ويمكن توسيعه إلى مليون رمز باستخدام YaRN، مما يتيح التعامل مع قواعد بيانات برمجية ضخمة. صُمم لسير عمل برمجي قائم على الوكلاء، ويمكنه التفاعل مع الأدوات والبيئات لحل مهام برمجية معقدة. يحقق نتائج رائدة بين النماذج المفتوحة في اختبارات البرمجة والوكلاء، ويقارن بأداء نماذج مثل Claude Sonnet 4.",
  "Qwen/Qwen3-Next-80B-A3B-Instruct.description": "Qwen3-Next-80B-A3B-Instruct هو نموذج أساسي من الجيل التالي يستخدم بنية Qwen3-Next لتحقيق كفاءة عالية في التدريب والتنفيذ. يجمع بين انتباه هجين (Gated DeltaNet + Gated Attention)، وبنية MoE شديدة التفرع، وتحسينات في استقرار التدريب. يحتوي على 80 مليار معلمة إجمالية، ولكن حوالي 3 مليارات فقط نشطة أثناء التنفيذ، مما يقلل من استهلاك الموارد ويوفر أداءً أسرع بأكثر من 10 مرات مقارنة بـ Qwen3-32B في سياقات تتجاوز 32 ألف رمز. هذا الإصدار الموجه للتعليمات يستهدف المهام العامة (بدون وضع التفكير). يقدم أداءً مماثلاً لـ Qwen3-235B في بعض الاختبارات، ويظهر تفوقًا واضحًا في المهام ذات السياقات الطويلة جدًا.",
  "Qwen/Qwen3-Next-80B-A3B-Thinking.description": "Qwen3-Next-80B-A3B-Thinking هو نموذج أساسي من الجيل التالي مصمم للتفكير المعقد. يستخدم بنية Qwen3-Next مع انتباه هجين (Gated DeltaNet + Gated Attention) وبنية MoE شديدة التفرع لتحقيق كفاءة عالية في التدريب والتنفيذ. يحتوي على 80 مليار معلمة إجمالية، ولكن حوالي 3 مليارات فقط نشطة أثناء التنفيذ، مما يقلل من استهلاك الموارد ويوفر أداءً أسرع بأكثر من 10 مرات مقارنة بـ Qwen3-32B في سياقات تتجاوز 32 ألف رمز. هذا الإصدار المخصص للتفكير يستهدف المهام متعددة الخطوات مثل الإثباتات، توليد الشيفرة، التحليل المنطقي، والتخطيط، ويُنتج تسلسلات تفكير منظمة. يتفوق على Qwen3-32B-Thinking ويتجاوز Gemini-2.5-Flash-Thinking في عدة اختبارات.",
  "Qwen/Qwen3-Omni-30B-A3B-Captioner.description": "Qwen3-Omni-30B-A3B-Captioner هو نموذج رؤية-لغة من سلسلة Qwen3 مصمم لتوليد أوصاف صور عالية الجودة، دقيقة ومفصلة. يستخدم بنية MoE تحتوي على 30 مليار معلمة لفهم الصور بعمق وتوليد أوصاف سلسة، ويتفوق في التقاط التفاصيل، وفهم المشاهد، والتعرف على الكائنات، والاستدلال العلاقي.",
  "Qwen/Qwen3-Omni-30B-A3B-Instruct.description": "Qwen3-Omni-30B-A3B-Instruct هو نموذج MoE من سلسلة Qwen3 يحتوي على 30 مليار معلمة إجمالية و3 مليارات نشطة، ويقدم أداءً قويًا بتكلفة تنفيذ منخفضة. تم تدريبه على بيانات متعددة اللغات وعالية الجودة من مصادر متنوعة، ويدعم إدخالًا متعدد الوسائط (نص، صور، صوت، فيديو) وفهمًا وتوليدًا عبر الوسائط.",
  "Qwen/Qwen3-Omni-30B-A3B-Thinking.description": "Qwen3-Omni-30B-A3B-Thinking هو المكون الأساسي \"المفكر\" في Qwen3-Omni. يعالج مدخلات متعددة الوسائط (نص، صوت، صور، فيديو) ويؤدي استدلالًا معقدًا بتسلسل تفكير، موحدًا المدخلات في تمثيل مشترك لفهم عميق عبر الوسائط. إنه نموذج MoE يحتوي على 30 مليار معلمة إجمالية و3 مليارات نشطة، ويوازن بين قوة الاستدلال وكفاءة الحوسبة.",
  "Qwen/Qwen3-VL-235B-A22B-Instruct.description": "Qwen3-VL-235B-A22B-Instruct هو نموذج Qwen3-VL كبير موجه للتعليمات، مبني على بنية MoE، ويقدم فهمًا وتوليدًا متعدد الوسائط ممتازًا. يدعم سياقًا يصل إلى 256 ألف رمز بشكل أصلي، ومناسب لخدمات الإنتاج متعددة الوسائط ذات التوافر العالي.",
  "Qwen/Qwen3-VL-235B-A22B-Thinking.description": "Qwen3-VL-235B-A22B-Thinking هو الإصدار الرائد للتفكير من Qwen3-VL، مُحسَّن للاستدلال متعدد الوسائط المعقد، والاستدلال في السياقات الطويلة، وتفاعل الوكلاء في سيناريوهات المؤسسات.",
  "Qwen/Qwen3-VL-30B-A3B-Instruct.description": "Qwen3-VL-30B-A3B-Instruct هو نموذج Qwen3-VL موجه للتعليمات يتمتع بفهم وتوليد قوي بين الرؤية واللغة. يدعم سياقًا يصل إلى 256 ألف رمز بشكل أصلي للدردشة متعددة الوسائط وتوليد النصوص بناءً على الصور.",
  "Qwen/Qwen3-VL-30B-A3B-Thinking.description": "Qwen3-VL-30B-A3B-Thinking هو الإصدار المعزز بالاستدلال من Qwen3-VL، مُحسَّن للاستدلال متعدد الوسائط، وتحويل الصور إلى شيفرة، وفهم بصري معقد. يدعم سياقًا يصل إلى 256 ألف رمز مع قدرة أقوى على تسلسل التفكير.",
  "Qwen/Qwen3-VL-32B-Instruct.description": "Qwen3-VL-32B-Instruct هو نموذج رؤية-لغة من فريق Qwen يحقق نتائج رائدة في اختبارات VL متعددة. يدعم صورًا بدقة ميغابيكسل ويوفر فهمًا بصريًا قويًا، والتعرف البصري متعدد اللغات، وتحديد دقيق للعناصر البصرية، وحوارًا بصريًا. يتعامل مع مهام متعددة الوسائط معقدة ويدعم استدعاء الأدوات وإكمال المقدمات.",
  "Qwen/Qwen3-VL-32B-Thinking.description": "Qwen3-VL-32B-Thinking مُحسَّن للاستدلال البصري المعقد. يتضمن وضع تفكير مدمج يُنتج خطوات استدلال وسيطة قبل الإجابات، مما يعزز المنطق متعدد الخطوات، والتخطيط، والاستدلال المعقد. يدعم صورًا بدقة ميغابيكسل، وفهمًا بصريًا قويًا، والتعرف البصري متعدد اللغات، وتحديدًا دقيقًا، وحوارًا بصريًا، واستدعاء الأدوات، وإكمال المقدمات.",
  "Qwen/Qwen3-VL-8B-Instruct.description": "Qwen3-VL-8B-Instruct هو نموذج رؤية-لغة من Qwen3 مبني على Qwen3-8B-Instruct ومدرب على بيانات ضخمة من الصور والنصوص. يتفوق في الفهم البصري العام، والحوار المرتكز على الرؤية، والتعرف على النصوص متعددة اللغات في الصور، ومناسب لأسئلة وأجوبة بصرية، وتوليد أوصاف، واتباع التعليمات متعددة الوسائط، واستخدام الأدوات.",
  "Qwen/Qwen3-VL-8B-Thinking.description": "Qwen3-VL-8B-Thinking هو إصدار التفكير البصري من Qwen3، مُحسَّن للاستدلال متعدد الخطوات المعقد. يُنتج سلسلة تفكير قبل الإجابات لتحسين الدقة، ومثالي لأسئلة وأجوبة بصرية عميقة وتحليل صور مفصل.",
  "Qwen2-72B-Instruct.description": "Qwen2 هو أحدث إصدار من سلسلة Qwen، يدعم نافذة سياق تصل إلى 128 ألف رمز. مقارنة بأفضل النماذج المفتوحة الحالية، يتفوق Qwen2-72B بشكل كبير في فهم اللغة الطبيعية، والمعرفة، والبرمجة، والرياضيات، والقدرات متعددة اللغات.",
  "Qwen2-7B-Instruct.description": "Qwen2 هو أحدث إصدار من سلسلة Qwen، ويتفوق على أفضل النماذج المفتوحة من نفس الحجم وحتى الأكبر منها. يُظهر Qwen2 7B تفوقًا ملحوظًا في عدة اختبارات، خاصة في البرمجة وفهم اللغة الصينية.",
  "Qwen2-VL-72B.description": "Qwen2-VL-72B هو نموذج رؤية-لغة قوي يدعم معالجة متعددة الوسائط للنصوص والصور، ويتعرف بدقة على محتوى الصور ويولد أوصافًا أو إجابات ذات صلة.",
  "Qwen2.5-14B-Instruct.description": "Qwen2.5-14B-Instruct هو نموذج لغوي كبير يحتوي على 14 مليار معلمة، يتمتع بأداء قوي، ومُحسَّن للسيناريوهات الصينية ومتعددة اللغات، ويدعم الأسئلة والأجوبة الذكية وتوليد المحتوى.",
  "Qwen2.5-32B-Instruct.description": "Qwen2.5-32B-Instruct هو نموذج لغوي كبير يحتوي على 32 مليار معلمة، يتمتع بأداء متوازن، ومُحسَّن للسيناريوهات الصينية ومتعددة اللغات، ويدعم الأسئلة والأجوبة الذكية وتوليد المحتوى.",
  "Qwen2.5-72B-Instruct.description": "نموذج لغوي كبير للغتين الصينية والإنجليزية، مُحسَّن للغة، والبرمجة، والرياضيات، والاستدلال.",
  "Qwen2.5-7B-Instruct.description": "Qwen2.5-7B-Instruct هو نموذج لغوي يحتوي على 7 مليارات معلمة، يدعم استدعاء الوظائف والتكامل السلس مع الأنظمة الخارجية، مما يعزز المرونة وقابلية التوسع. مُحسَّن للسيناريوهات الصينية ومتعددة اللغات، ويدعم الأسئلة والأجوبة الذكية وتوليد المحتوى.",
  "Qwen2.5-Coder-14B-Instruct.description": "Qwen2.5-Coder-14B-Instruct هو نموذج تعليمات برمجة مدرب مسبقًا على نطاق واسع يتمتع بفهم وتوليد قوي للشيفرة. يتعامل بكفاءة مع مجموعة واسعة من مهام البرمجة، ومثالي للبرمجة الذكية، وتوليد السكربتات التلقائي، والأسئلة والأجوبة البرمجية.",
  "Qwen2.5-Coder-32B-Instruct.description": "نموذج لغوي متقدم لتوليد الشيفرة، والاستدلال، وإصلاح الأخطاء عبر لغات البرمجة الرئيسية.",
  "Qwen3-235B-A22B-Instruct-2507-FP8.description": "Qwen3 235B A22B Instruct 2507 مُحسَّن للاستدلال المتقدم واتباع التعليمات، ويستخدم بنية MoE للحفاظ على كفاءة الاستدلال على نطاق واسع.",
  "Qwen3-235B.description": "Qwen3-235B-A22B هو نموذج MoE يُقدِّم وضع استدلال هجين، يتيح للمستخدمين التبديل بسلاسة بين التفكير وعدم التفكير. يدعم الفهم والاستدلال عبر 119 لغة ولهجة، ويتمتع بقدرات قوية على استدعاء الأدوات، ويتنافس مع نماذج رائدة مثل DeepSeek R1 وOpenAI o1 وo3-mini وGrok 3 وGoogle Gemini 2.5 Pro في اختبارات القدرات العامة، والبرمجة والرياضيات، والقدرات متعددة اللغات، واستدلال المعرفة.",
  "Qwen3-32B.description": "Qwen3-32B هو نموذج كثيف يُقدِّم وضع استدلال هجين، يتيح للمستخدمين التبديل بين التفكير وعدم التفكير. بفضل تحسينات في البنية، وبيانات أكثر، وتدريب أفضل، يقدم أداءً مماثلًا لـ Qwen2.5-72B.",
  "SenseChat-128K.description": "الإصدار الرابع الأساسي مع سياق 128 ألف رمز، قوي في فهم وتوليد النصوص الطويلة.",
  "SenseChat-32K.description": "الإصدار الرابع الأساسي مع سياق 32 ألف رمز، مرن لمجموعة متنوعة من السيناريوهات.",
  "SenseChat-5-1202.description": "أحدث إصدار مبني على V5.5، مع تحسينات كبيرة في الأساسيات الصينية/الإنجليزية، والدردشة، ومعرفة العلوم والتكنولوجيا، والمعرفة الإنسانية، والكتابة، والرياضيات/المنطق، والتحكم في الطول.",
  "SenseChat-5-Cantonese.description": "مصمم ليتماشى مع عادات الحوار في هونغ كونغ، واللغة العامية، والمعرفة المحلية؛ يتفوق على GPT-4 في فهم الكانتونية ويضاهي GPT-4 Turbo في المعرفة، والاستدلال، والرياضيات، والبرمجة.",
  "SenseChat-5-beta.description": "يتفوق في بعض الجوانب على SenseChat-5-1202.",
  "SenseChat-5.description": "أحدث إصدار V5.5 مع سياق 128 ألف رمز؛ تحسينات كبيرة في الاستدلال الرياضي، والدردشة باللغة الإنجليزية، واتباع التعليمات، وفهم النصوص الطويلة، ويقارن بـ GPT-4o.",
  "SenseChat-Character-Pro.description": "نموذج دردشة متقدم للشخصيات مع سياق 32 ألف رمز، وقدرات محسنة، ودعم للغتين الصينية والإنجليزية.",
  "SenseChat-Character.description": "نموذج دردشة قياسي للشخصيات مع سياق 8 آلاف رمز وسرعة استجابة عالية.",
  "SenseChat-Turbo-1202.description": "أحدث نموذج خفيف الوزن يصل إلى أكثر من 90% من قدرات النموذج الكامل بتكلفة تنفيذ أقل بكثير.",
  "SenseChat-Turbo.description": "مناسب لأسئلة وأجوبة سريعة وسيناريوهات تحسين النماذج.",
  "SenseChat-Vision.description": "أحدث إصدار V5.5 مع إدخال متعدد الصور وتحسينات شاملة في التعرف على السمات، والعلاقات المكانية، واكتشاف الأحداث/الحركات، وفهم المشاهد، والتعرف على المشاعر، والاستدلال المنطقي، وفهم/توليد النصوص.",
  "SenseChat.description": "الإصدار الرابع الأساسي مع سياق 4 آلاف رمز وقدرات عامة قوية.",
  "SenseNova-V6-5-Pro.description": "مع تحديثات شاملة في البيانات متعددة الوسائط واللغوية والاستدلالية، إلى جانب تحسين استراتيجية التدريب، يُظهر النموذج الجديد تحسنًا كبيرًا في الاستدلال متعدد الوسائط واتباع التعليمات العامة، ويدعم نافذة سياق تصل إلى 128 ألف رمز، ويتفوق في مهام التعرف على النصوص (OCR) والتعرف على الملكية الفكرية في السياحة الثقافية.",
  "SenseNova-V6-5-Turbo.description": "مع تحديثات شاملة في البيانات متعددة الوسائط واللغوية والاستدلالية، إلى جانب تحسين استراتيجية التدريب، يُظهر النموذج الجديد تحسنًا كبيرًا في الاستدلال متعدد الوسائط واتباع التعليمات العامة، ويدعم نافذة سياق تصل إلى 128 ألف رمز، ويتفوق في مهام التعرف على النصوص (OCR) والتعرف على الملكية الفكرية في السياحة الثقافية.",
  "SenseNova-V6-Pro.description": "يوحد بشكل أصيل بين الصورة والنص والفيديو، متجاوزًا الحواجز التقليدية بين الوسائط المتعددة؛ ويحتل المراتب الأولى في OpenCompass وSuperCLUE.",
  "SenseNova-V6-Reasoner.description": "يجمع بين الرؤية واللغة في استدلال عميق، ويدعم التفكير البطيء وسلسلة التفكير الكاملة.",
  "SenseNova-V6-Turbo.description": "يوحد بشكل أصيل بين الصورة والنص والفيديو، متجاوزًا الحواجز التقليدية بين الوسائط المتعددة. يتفوق في القدرات الأساسية للوسائط المتعددة واللغة، ويحتل مرتبة متقدمة في العديد من التقييمات.",
  "Skylark2-lite-8k.description": "الجيل الثاني من نموذج Skylark. يتميز Skylark2-lite بسرعة استجابة عالية في السيناريوهات الحساسة للتكلفة والتي لا تتطلب دقة عالية، مع نافذة سياق تصل إلى 8 آلاف رمز.",
  "Skylark2-pro-32k.description": "الجيل الثاني من نموذج Skylark. يوفر Skylark2-pro دقة أعلى في توليد النصوص المعقدة مثل كتابة المحتوى الاحترافي، وتأليف الروايات، والترجمة عالية الجودة، مع نافذة سياق تصل إلى 32 ألف رمز.",
  "Skylark2-pro-4k.description": "الجيل الثاني من نموذج Skylark. يوفر Skylark2-pro دقة أعلى في توليد النصوص المعقدة مثل كتابة المحتوى الاحترافي، وتأليف الروايات، والترجمة عالية الجودة، مع نافذة سياق تصل إلى 4 آلاف رمز.",
  "Skylark2-pro-character-4k.description": "الجيل الثاني من نموذج Skylark. يتميز Skylark2-pro-character في تقمص الأدوار والدردشة، حيث يطابق التعليمات بأساليب شخصية مميزة وحوار طبيعي، مما يجعله مثاليًا للروبوتات الافتراضية والمساعدين الافتراضيين وخدمة العملاء، مع استجابات سريعة.",
  "Skylark2-pro-turbo-8k.description": "الجيل الثاني من نموذج Skylark. يوفر Skylark2-pro-turbo-8k استدلالًا أسرع بتكلفة أقل مع نافذة سياق تصل إلى 8 آلاف رمز.",
  "THUDM/GLM-4-32B-0414.description": "GLM-4-32B-0414 هو نموذج GLM من الجيل التالي يحتوي على 32 مليار معامل، ويقارن في الأداء مع نماذج OpenAI GPT وسلسلة DeepSeek V3/R1.",
  "THUDM/GLM-4-9B-0414.description": "GLM-4-9B-0414 هو نموذج GLM يحتوي على 9 مليارات معامل، ويعتمد على تقنيات GLM-4-32B مع إمكانية نشر أخف. يتميز في توليد الشيفرات، وتصميم الويب، وتوليد SVG، والكتابة المعتمدة على البحث.",
  "THUDM/GLM-4.1V-9B-Thinking.description": "GLM-4.1V-9B-Thinking هو نموذج رؤية-لغة مفتوح المصدر من Zhipu AI ومختبر KEG بجامعة تسينغهوا، مصمم للإدراك المعقد متعدد الوسائط. يعتمد على GLM-4-9B-0414 ويضيف سلسلة التفكير والتعلم المعزز لتحسين الاستدلال عبر الوسائط والاستقرار بشكل كبير.",
  "THUDM/GLM-Z1-32B-0414.description": "GLM-Z1-32B-0414 هو نموذج استدلال عميق مبني على GLM-4-32B-0414 باستخدام بيانات بدء باردة وتوسيع التعلم المعزز، وتم تدريبه بشكل إضافي على الرياضيات والبرمجة والمنطق. يُظهر تحسنًا كبيرًا في القدرة على حل المسائل الرياضية والمهام المعقدة مقارنة بالنموذج الأساسي.",
  "THUDM/GLM-Z1-9B-0414.description": "GLM-Z1-9B-0414 هو نموذج GLM صغير يحتوي على 9 مليارات معامل، يحتفظ بقوة المصدر المفتوح ويقدم أداءً مميزًا. يتميز في الاستدلال الرياضي والمهام العامة، ويتفوق على النماذج المفتوحة من نفس الفئة الحجمية.",
  "THUDM/GLM-Z1-Rumination-32B-0414.description": "GLM-Z1-Rumination-32B-0414 هو نموذج استدلال عميق يتمتع بقدرات تأملية (تمت مقارنته بـ OpenAI Deep Research). على عكس النماذج التقليدية، يقضي وقتًا أطول في التفكير لحل المشكلات المفتوحة والمعقدة.",
  "THUDM/glm-4-9b-chat.description": "GLM-4-9B-Chat هو النموذج مفتوح المصدر من Zhipu AI ضمن سلسلة GLM-4. يتميز بقوة في الفهم الدلالي، والرياضيات، والاستدلال، والبرمجة، والمعرفة. بالإضافة إلى الدردشة متعددة الأدوار، يدعم تصفح الويب، وتنفيذ الشيفرات، واستدعاء الأدوات المخصصة، والاستدلال على النصوص الطويلة. يدعم 26 لغة (بما في ذلك الصينية، والإنجليزية، واليابانية، والكورية، والألمانية). يحقق أداءً جيدًا في AlignBench-v2 وMT-Bench وMMLU وC-Eval، ويدعم نافذة سياق تصل إلى 128 ألف رمز للاستخدام الأكاديمي والتجاري.",
  "Tongyi-Zhiwen/QwenLong-L1-32B.description": "QwenLong-L1-32B هو أول نموذج استدلال طويل السياق (LRM) تم تدريبه باستخدام التعلم المعزز، ومُحسَّن للاستدلال على النصوص الطويلة. تتيح استراتيجية التوسيع التدريجي للسياق انتقالًا مستقرًا من السياقات القصيرة إلى الطويلة. يتفوق على OpenAI-o3-mini وQwen3-235B-A22B في سبعة اختبارات استدلال على مستندات طويلة، ويضاهي Claude-3.7-Sonnet-Thinking. يتميز بقوة خاصة في الرياضيات والمنطق والاستدلال متعدد الخطوات.",
  "Yi-34B-Chat.description": "Yi-1.5-34B يحتفظ بقدرات اللغة العامة القوية للسلسلة، ويستخدم تدريبًا تدريجيًا على 500 مليار رمز عالي الجودة لتحسين كبير في المنطق الرياضي والبرمجة.",
  "abab5.5-chat.description": "مصمم لسيناريوهات الإنتاجية، مع قدرة على التعامل مع المهام المعقدة وتوليد نصوص فعالة للاستخدام المهني.",
  "abab5.5s-chat.description": "مصمم للدردشة بشخصيات صينية، ويقدم حوارات صينية عالية الجودة لمجموعة متنوعة من التطبيقات.",
  "abab6.5g-chat.description": "مصمم للدردشة متعددة اللغات بشخصيات، ويدعم توليد حوارات عالية الجودة بالإنجليزية ولغات أخرى.",
  "abab6.5s-chat.description": "مناسب لمجموعة واسعة من مهام معالجة اللغة الطبيعية، بما في ذلك توليد النصوص وأنظمة الحوار.",
  "abab6.5t-chat.description": "محسن للدردشة بشخصيات صينية، ويوفر حوارات سلسة تتماشى مع أساليب التعبير الصينية.",
  "accounts/fireworks/models/deepseek-r1.description": "DeepSeek-R1 هو نموذج لغة كبير متقدم تم تحسينه باستخدام التعلم المعزز وبيانات بدء باردة، ويقدم أداءً ممتازًا في الاستدلال والرياضيات والبرمجة.",
  "accounts/fireworks/models/deepseek-v3.description": "نموذج لغة قوي من نوع Mixture-of-Experts (MoE) من DeepSeek يحتوي على 671 مليار معامل إجمالي و37 مليار معامل نشط لكل رمز.",
  "accounts/fireworks/models/llama-v3-70b-instruct.description": "طورت Meta وأصدرت سلسلة نماذج Meta Llama 3 LLM، والتي تتضمن نماذج توليد نصوص مدربة مسبقًا ومضبوطة على التعليم بحجم 8B و70B. تم تحسين نماذج Llama 3 المضبوطة على التعليم للاستخدام في المحادثات، وتتفوّق على العديد من نماذج الدردشة المفتوحة الحالية في معايير الصناعة الشائعة.",
  "accounts/fireworks/models/llama-v3-8b-instruct-hf.description": "تم تحسين نماذج Llama 3 من Meta المضبوطة على التعليم للاستخدام في المحادثات، وتتفوّق على العديد من نماذج الدردشة المفتوحة الحالية في معايير الصناعة الشائعة. Llama 3 8B Instruct (إصدار HF) هو النسخة الأصلية FP16 من Llama 3 8B Instruct، ومن المتوقع أن تتطابق نتائجه مع تنفيذ Hugging Face الرسمي.",
  "accounts/fireworks/models/llama-v3-8b-instruct.description": "طورت Meta وأصدرت سلسلة نماذج Meta Llama 3 LLM، وهي مجموعة من نماذج توليد النصوص المدربة مسبقًا والمضبوطة على التعليم بحجم 8B و70B. تم تحسين نماذج Llama 3 المضبوطة على التعليم للاستخدام في المحادثات، وتتفوّق على العديد من نماذج الدردشة المفتوحة الحالية في معايير الصناعة الشائعة.",
  "accounts/fireworks/models/llama-v3p1-405b-instruct.description": "Meta Llama 3.1 هي عائلة من نماذج اللغة الكبيرة متعددة اللغات، تشمل نماذج توليد مدربة مسبقًا ومضبوطة على التعليم بأحجام 8B و70B و405B. تم تحسين النماذج النصية المضبوطة على التعليم للحوار متعدد اللغات، وتتفوّق على العديد من نماذج الدردشة المفتوحة والمغلقة في معايير الصناعة الشائعة. يُعد نموذج 405B الأقوى في عائلة Llama 3.1، ويستخدم استدلال FP8 يتطابق بشكل وثيق مع التنفيذ المرجعي.",
  "accounts/fireworks/models/llama-v3p1-70b-instruct.description": "Meta Llama 3.1 هي عائلة من نماذج اللغة الكبيرة متعددة اللغات، تشمل نماذج توليد مدربة مسبقًا ومضبوطة على التعليم بأحجام 8B و70B و405B. تم تحسين النماذج النصية المضبوطة على التعليم للحوار متعدد اللغات، وتتفوّق على العديد من نماذج الدردشة المفتوحة والمغلقة في معايير الصناعة الشائعة.",
  "accounts/fireworks/models/llama-v3p1-8b-instruct.description": "Meta Llama 3.1 هي عائلة من نماذج اللغة الكبيرة متعددة اللغات، تشمل نماذج توليد مدربة مسبقًا ومضبوطة على التعليم بأحجام 8B و70B و405B. تم تحسين النماذج النصية المضبوطة على التعليم للحوار متعدد اللغات، وتتفوّق على العديد من نماذج الدردشة المفتوحة والمغلقة في معايير الصناعة الشائعة.",
  "accounts/fireworks/models/llama-v3p2-11b-vision-instruct.description": "نموذج استدلال بصري مضبوط على التعليم من Meta يحتوي على 11 مليار معامل، مُحسّن للتعرف البصري، واستدلال الصور، والتعليق التوضيحي، والأسئلة والأجوبة المتعلقة بالصور. يفهم البيانات البصرية مثل الرسوم البيانية والمخططات، ويصل بين الرؤية واللغة من خلال توليد أوصاف نصية لتفاصيل الصور.",
  "accounts/fireworks/models/llama-v3p2-3b-instruct.description": "Llama 3.2 3B Instruct هو نموذج متعدد اللغات خفيف الوزن من Meta، مصمم لتشغيل فعال بزمن استجابة منخفض وتكلفة أقل مقارنة بالنماذج الأكبر. تشمل حالات الاستخدام الشائعة إعادة صياغة الاستعلامات/المطالبات والمساعدة في الكتابة.",
  "accounts/fireworks/models/llama-v3p2-90b-vision-instruct.description": "نموذج استدلال بصري مضبوط على التعليم من Meta يحتوي على 90 مليار معامل، مُحسّن للتعرف البصري، واستدلال الصور، والتعليق التوضيحي، والأسئلة والأجوبة المتعلقة بالصور. يفهم البيانات البصرية مثل الرسوم البيانية والمخططات، ويصل بين الرؤية واللغة من خلال توليد أوصاف نصية لتفاصيل الصور. ملاحظة: يتم توفير هذا النموذج حاليًا بشكل تجريبي كنموذج بدون خادم. للاستخدام الإنتاجي، يرجى ملاحظة أن Fireworks قد توقف نشر النموذج دون إشعار مسبق.",
  "accounts/fireworks/models/llama-v3p3-70b-instruct.description": "Llama 3.3 70B Instruct هو التحديث الصادر في ديسمبر لنموذج Llama 3.1 70B. يُحسّن استخدام الأدوات، ودعم النصوص متعددة اللغات، والرياضيات، والبرمجة مقارنة بإصدار يوليو 2024. يحقق أداءً رائدًا في الصناعة في مجالات الاستدلال، والرياضيات، واتباع التعليمات، ويقدم أداءً مماثلًا لـ 3.1 405B مع مزايا كبيرة في السرعة والتكلفة.",
  "accounts/fireworks/models/mistral-small-24b-instruct-2501.description": "نموذج يحتوي على 24 مليار معامل يتمتع بقدرات متقدمة تضاهي النماذج الأكبر حجمًا.",
  "accounts/fireworks/models/mixtral-8x22b-instruct.description": "Mixtral MoE 8x22B Instruct v0.1 هو الإصدار المضبوط على التعليم من Mixtral MoE 8x22B v0.1، مع تمكين واجهة برمجة تطبيقات إكمال الدردشة.",
  "accounts/fireworks/models/mixtral-8x7b-instruct.description": "Mixtral MoE 8x7B Instruct هو الإصدار المضبوط على التعليم من Mixtral MoE 8x7B، مع تمكين واجهة برمجة تطبيقات إكمال الدردشة.",
  "accounts/fireworks/models/mythomax-l2-13b.description": "نسخة محسّنة من MythoMix، ربما تكون شكله الأكثر تطورًا، تدمج بين MythoLogic-L2 وHuginn باستخدام تقنية دمج تجريبية للغاية من نوع tensor. تميزها يجعلها ممتازة لسرد القصص ولعب الأدوار.",
  "accounts/fireworks/models/phi-3-vision-128k-instruct.description": "Phi-3-Vision-128K-Instruct هو نموذج متعدد الوسائط خفيف الوزن ومتقدم، تم بناؤه باستخدام بيانات تركيبية ومجموعات بيانات عامة منسقة من الويب، ويركز على بيانات النصوص والرؤية عالية الجودة والمكثفة في الاستدلال. ينتمي إلى عائلة Phi-3، ويتميز بإصدار متعدد الوسائط يدعم طول سياق يصل إلى 128 ألف رمز. يخضع النموذج لتحسينات دقيقة تشمل الضبط الخاضع للإشراف وتحسين التفضيلات المباشرة لضمان اتباع التعليمات بدقة وتدابير أمان قوية.",
  "accounts/fireworks/models/qwen-qwq-32b-preview.description": "يركز نموذج Qwen QwQ على تعزيز قدرات الاستدلال في الذكاء الاصطناعي، ويُظهر أن النماذج المفتوحة يمكن أن تنافس النماذج المغلقة الرائدة في مجال الاستدلال. QwQ-32B-Preview هو إصدار تجريبي يضاهي o1 ويتفوق على GPT-4o وClaude 3.5 Sonnet في الاستدلال والتحليل عبر معايير GPQA وAIME وMATH-500 وLiveCodeBench. ملاحظة: يتم توفير هذا النموذج حاليًا بشكل تجريبي كنموذج بدون خادم. للاستخدام الإنتاجي، يرجى ملاحظة أن Fireworks قد توقف نشر النموذج دون إشعار مسبق.",
  "accounts/fireworks/models/qwen2-vl-72b-instruct.description": "نموذج Qwen-VL بحجم 72B هو أحدث إصدار من Alibaba، ويعكس ما يقرب من عام من الابتكار.",
  "accounts/fireworks/models/qwen2p5-72b-instruct.description": "Qwen2.5 هي سلسلة نماذج LLM تعتمد فقط على وحدة فك التشفير، تم تطويرها بواسطة فريق Qwen وAlibaba Cloud، وتتوفر بأحجام 0.5B و1.5B و3B و7B و14B و32B و72B، مع إصدارات أساسية ومضبوطة على التعليم.",
  "accounts/fireworks/models/qwen2p5-coder-32b-instruct.description": "Qwen2.5-Coder هو أحدث نموذج LLM من Qwen مصمم للبرمجة (سابقًا CodeQwen). ملاحظة: يتم توفير هذا النموذج حاليًا بشكل تجريبي كنموذج بدون خادم. للاستخدام الإنتاجي، يرجى ملاحظة أن Fireworks قد توقف نشر النموذج دون إشعار مسبق.",
  "accounts/yi-01-ai/models/yi-large.description": "Yi-Large هو نموذج LLM من الدرجة الأولى يحتل مرتبة أقل بقليل من GPT-4 وGemini 1.5 Pro وClaude 3 Opus في لوحة تصنيف LMSYS. يتميز بقدرات متعددة اللغات، خاصة في الإسبانية والصينية واليابانية والألمانية والفرنسية. كما أنه صديق للمطورين، حيث يستخدم نفس مخطط واجهة برمجة التطبيقات مثل OpenAI لتسهيل التكامل.",
  "ai21-jamba-1.5-large.description": "نموذج متعدد اللغات يحتوي على 398 مليار معلمة (94 مليار نشطة)، يدعم نافذة سياق تصل إلى 256 ألف، واستدعاء الدوال، وإخراج منظم، وتوليد مستند إلى مصادر.",
  "ai21-jamba-1.5-mini.description": "نموذج متعدد اللغات يحتوي على 52 مليار معلمة (12 مليار نشطة)، يدعم نافذة سياق تصل إلى 256 ألف، واستدعاء الدوال، وإخراج منظم، وتوليد مستند إلى مصادر.",
  "ai21-labs/AI21-Jamba-1.5-Large.description": "نموذج متعدد اللغات يحتوي على 398 مليار معلمة (94 مليار نشطة)، يدعم نافذة سياق تصل إلى 256 ألف، واستدعاء الدوال، وإخراج منظم، وتوليد مستند إلى مصادر.",
  "ai21-labs/AI21-Jamba-1.5-Mini.description": "نموذج متعدد اللغات يحتوي على 52 مليار معلمة (12 مليار نشطة)، يدعم نافذة سياق تصل إلى 256 ألف، واستدعاء الدوال، وإخراج منظم، وتوليد مستند إلى مصادر.",
  "alibaba/qwen-3-14b.description": "Qwen3 هو الجيل الأحدث من سلسلة Qwen، ويقدم مجموعة شاملة من النماذج الكثيفة ونماذج MoE. تم تدريبه على نطاق واسع، ويحقق تطورات في الاستدلال، واتباع التعليمات، وقدرات الوكلاء، ودعم متعدد اللغات.",
  "alibaba/qwen-3-235b.description": "Qwen3 هو الجيل الأحدث من سلسلة Qwen، ويقدم مجموعة شاملة من النماذج الكثيفة ونماذج MoE. تم تدريبه على نطاق واسع، ويحقق تطورات في الاستدلال، واتباع التعليمات، وقدرات الوكلاء، ودعم متعدد اللغات.",
  "alibaba/qwen-3-30b.description": "Qwen3 هو الجيل الأحدث من سلسلة Qwen، ويقدم مجموعة شاملة من النماذج الكثيفة ونماذج MoE. تم تدريبه على نطاق واسع، ويحقق تطورات في الاستدلال، واتباع التعليمات، وقدرات الوكلاء، ودعم متعدد اللغات.",
  "alibaba/qwen-3-32b.description": "Qwen3 هو الجيل الأحدث من سلسلة Qwen، ويقدم مجموعة شاملة من النماذج الكثيفة ونماذج MoE. تم تدريبه على نطاق واسع، ويحقق تطورات في الاستدلال، واتباع التعليمات، وقدرات الوكلاء، ودعم متعدد اللغات.",
  "alibaba/qwen3-coder.description": "Qwen3-Coder-480B-A35B-Instruct هو أقوى نموذج ترميز من Qwen، يتميز بأداء قوي في الترميز التفاعلي، واستخدام المتصفح، والمهام البرمجية الأساسية، ويضاهي نتائج Claude Sonnet.",
  "amazon/nova-lite.description": "نموذج متعدد الوسائط منخفض التكلفة للغاية، يتميز بسرعة فائقة في معالجة الصور والفيديو والنصوص.",
  "amazon/nova-micro.description": "نموذج نصي فقط يوفر زمن استجابة منخفض جداً بتكلفة منخفضة.",
  "amazon/nova-pro.description": "نموذج متعدد الوسائط عالي الكفاءة يوازن بين الدقة والسرعة والتكلفة لمجموعة واسعة من المهام.",
  "amazon/titan-embed-text-v2.description": "Amazon Titan Text Embeddings V2 هو نموذج تضمين متعدد اللغات خفيف وفعال يدعم أبعاد 1024 و512 و256.",
  "anthropic.claude-3-5-sonnet-20240620-v1:0.description": "Claude 3.5 Sonnet يرفع معايير الصناعة، متفوقًا على المنافسين وClaude 3 Opus في تقييمات شاملة، مع الحفاظ على سرعة وتكلفة متوسطة.",
  "anthropic.claude-3-5-sonnet-20241022-v2:0.description": "Claude 3.5 Sonnet يرفع معايير الصناعة، متفوقًا على المنافسين وClaude 3 Opus في تقييمات شاملة، مع الحفاظ على سرعة وتكلفة متوسطة.",
  "anthropic.claude-3-haiku-20240307-v1:0.description": "Claude 3 Haiku هو أسرع وأصغر نموذج من Anthropic، يقدم استجابات شبه فورية للاستفسارات البسيطة. يوفر تجربة ذكاء اصطناعي سلسة شبيهة بالبشر ويدعم إدخال الصور مع نافذة سياق 200 ألف.",
  "anthropic.claude-3-opus-20240229-v1:0.description": "Claude 3 Opus هو أقوى نموذج ذكاء اصطناعي من Anthropic بأداء رائد في المهام المعقدة. يتعامل مع المطالبات المفتوحة والسيناريوهات الجديدة بطلاقة وفهم شبيه بالبشر، ويدعم إدخال الصور مع نافذة سياق 200 ألف.",
  "anthropic.claude-3-sonnet-20240229-v1:0.description": "Claude 3 Sonnet يوازن بين الذكاء والسرعة لمهام المؤسسات، ويوفر قيمة قوية بتكلفة أقل. صُمم ليكون نموذجًا موثوقًا للنشر واسع النطاق ويدعم إدخال الصور مع نافذة سياق 200 ألف.",
  "anthropic.claude-instant-v1.description": "نموذج سريع واقتصادي وفعال للدردشة اليومية، وتحليل النصوص، والتلخيص، والأسئلة والأجوبة على الوثائق.",
  "anthropic.claude-v2.description": "نموذج عالي الكفاءة في المهام من الحوار المعقد والتوليد الإبداعي إلى اتباع التعليمات التفصيلية.",
  "anthropic.claude-v2:1.description": "Claude 2 محدث مع ضعف نافذة السياق وتحسين الموثوقية، وتقليل معدل الهلوسة، ودقة أعلى مبنية على الأدلة للوثائق الطويلة وRAG.",
  "anthropic/claude-3-haiku.description": "Claude 3 Haiku هو أسرع نموذج من Anthropic، مصمم لمهام المؤسسات ذات المطالبات الطويلة. يمكنه تحليل مستندات كبيرة بسرعة مثل التقارير الفصلية والعقود والقضايا القانونية بنصف تكلفة النماذج المماثلة.",
  "anthropic/claude-3-opus.description": "Claude 3 Opus هو أذكى نموذج من Anthropic بأداء رائد في المهام المعقدة، يتعامل مع المطالبات المفتوحة والسيناريوهات الجديدة بطلاقة وفهم شبيه بالبشر.",
  "anthropic/claude-3.5-haiku.description": "Claude 3.5 Haiku يتميز بسرعة محسنة ودقة في الترميز واستخدام الأدوات، مناسب للسيناريوهات التي تتطلب سرعة وتفاعل مع الأدوات.",
  "anthropic/claude-3.5-sonnet.description": "Claude 3.5 Sonnet هو النموذج السريع والفعال في عائلة Sonnet، يقدم أداءً أفضل في الترميز والاستدلال، مع استبدال تدريجي ببعض الإصدارات الأحدث مثل Sonnet 3.7.",
  "anthropic/claude-3.7-sonnet.description": "Claude 3.7 Sonnet هو نموذج Sonnet مطور يتمتع باستدلال وترميز أقوى، مناسب للمهام المعقدة على مستوى المؤسسات.",
  "anthropic/claude-haiku-4.5.description": "Claude Haiku 4.5 هو نموذج سريع عالي الأداء من Anthropic، يوفر زمن استجابة منخفض جداً مع الحفاظ على دقة عالية.",
  "anthropic/claude-opus-4.1.description": "Opus 4.1 هو نموذج متقدم من Anthropic مُحسَّن للبرمجة، والاستدلال المعقد، والمهام طويلة الأمد.",
  "anthropic/claude-opus-4.5.description": "Claude Opus 4.5 هو النموذج الرائد من Anthropic، يجمع بين ذكاء من الدرجة الأولى وأداء قابل للتوسع للمهام المعقدة عالية الجودة.",
  "anthropic/claude-opus-4.description": "Opus 4 هو النموذج الرائد من Anthropic المصمم للمهام المعقدة وتطبيقات المؤسسات.",
  "anthropic/claude-sonnet-4.5.description": "Claude Sonnet 4.5 هو أحدث نموذج استدلال هجين من Anthropic مُحسَّن للاستدلال المعقد والترميز.",
  "anthropic/claude-sonnet-4.description": "Claude Sonnet 4 هو نموذج استدلال هجين من Anthropic يجمع بين التفكير وغير التفكير.",
  "ascend-tribe/pangu-pro-moe.description": "Pangu-Pro-MoE 72B-A16B هو نموذج LLM متفرق يحتوي على 72 مليار معلمة إجمالية و16 مليار نشطة، يعتمد على بنية MoGE. يقوم بتجميع الخبراء أثناء الاختيار ويقيد الرموز لتنشيط عدد متساوٍ من الخبراء لكل مجموعة، مما يوازن الحمل ويحسن كفاءة النشر على Ascend.",
  "aya.description": "Aya 23 هو نموذج متعدد اللغات من Cohere يدعم 23 لغة لمجموعة متنوعة من الاستخدامات.",
  "aya:35b.description": "Aya 23 هو نموذج متعدد اللغات من Cohere يدعم 23 لغة لمجموعة متنوعة من الاستخدامات.",
  "azure-DeepSeek-R1-0528.description": "تم نشره بواسطة Microsoft؛ تم ترقية DeepSeek R1 إلى DeepSeek-R1-0528. يتضمن التحديث تحسينات في الحوسبة وخوارزميات ما بعد التدريب، مما يعزز عمق الاستدلال والاستنتاج بشكل كبير. يتميز بأداء قوي في الرياضيات، والترميز، والمعايير المنطقية العامة، ويقترب من نماذج رائدة مثل O3 وGemini 2.5 Pro.",
  "baichuan-m2-32b.description": "Baichuan M2 32B هو نموذج MoE من Baichuan Intelligence يتمتع بقدرات استدلال قوية.",
  "baichuan/baichuan2-13b-chat.description": "Baichuan-13B هو نموذج LLM مفتوح المصدر وقابل للاستخدام التجاري يحتوي على 13 مليار معلمة من Baichuan، يحقق نتائج رائدة في فئته على معايير اللغة الصينية والإنجليزية الموثوقة.",
  "baidu/ERNIE-4.5-300B-A47B.description": "ERNIE-4.5-300B-A47B هو نموذج MoE من Baidu يحتوي على 300 مليار معلمة إجمالية و47 مليار نشطة لكل رمز، يوازن بين الأداء القوي وكفاءة الحوسبة. كنموذج أساسي في سلسلة ERNIE 4.5، يتميز بالفهم والتوليد والاستدلال والبرمجة. يستخدم طريقة تدريب مسبق متعددة الوسائط غير متجانسة مع تدريب مشترك على النصوص والرؤية لتعزيز القدرات، خاصة في اتباع التعليمات والمعرفة العامة.",
  "baidu/ernie-5.0-thinking-preview.description": "ERNIE 5.0 Thinking Preview هو نموذج ERNIE متعدد الوسائط من الجيل التالي من Baidu، يتميز بفهم متعدد الوسائط قوي، واتباع التعليمات، والإبداع، والأسئلة والأجوبة الواقعية، واستدعاء الأدوات.",
  "black-forest-labs/flux-1.1-pro.description": "FLUX 1.1 Pro هو إصدار أسرع ومحسّن من FLUX Pro يتميز بجودة صور ممتازة والتزام دقيق بالتعليمات.",
  "black-forest-labs/flux-dev.description": "FLUX Dev هو الإصدار المخصص للتطوير من FLUX للاستخدام غير التجاري.",
  "black-forest-labs/flux-pro.description": "FLUX Pro هو النموذج الاحترافي من FLUX لإنتاج صور عالية الجودة.",
  "black-forest-labs/flux-schnell.description": "FLUX Schnell هو نموذج توليد صور سريع مُحسّن للأداء العالي.",
  "c4ai-aya-expanse-32b.description": "Aya Expanse هو نموذج متعدد اللغات عالي الأداء بحجم 32B يستخدم ضبط التعليمات، وتحليل البيانات، وتدريب التفضيلات، ودمج النماذج لمنافسة النماذج أحادية اللغة. يدعم 23 لغة.",
  "c4ai-aya-expanse-8b.description": "Aya Expanse هو نموذج متعدد اللغات عالي الأداء بحجم 8B يستخدم ضبط التعليمات، وتحليل البيانات، وتدريب التفضيلات، ودمج النماذج لمنافسة النماذج أحادية اللغة. يدعم 23 لغة.",
  "c4ai-aya-vision-32b.description": "Aya Vision هو نموذج متعدد الوسائط متقدم يقدم أداءً قويًا في اختبارات اللغة والنصوص والرؤية. يدعم 23 لغة. يركز إصدار 32B على الأداء المتعدد اللغات من الدرجة الأولى.",
  "c4ai-aya-vision-8b.description": "Aya Vision هو نموذج متعدد الوسائط متقدم يقدم أداءً قويًا في اختبارات اللغة والنصوص والرؤية. يركز إصدار 8B على تقليل التأخير مع الحفاظ على أداء قوي.",
  "charglm-3.description": "CharGLM-3 مصمم للمحادثات التمثيلية والدعم العاطفي، ويدعم ذاكرة طويلة متعددة الأدوار وحوارات مخصصة.",
  "charglm-4.description": "CharGLM-4 مصمم للمحادثات التمثيلية والدعم العاطفي، ويدعم ذاكرة طويلة متعددة الأدوار وحوارات مخصصة.",
  "chatgpt-4o-latest.description": "ChatGPT-4o هو نموذج ديناميكي يتم تحديثه في الوقت الفعلي، يجمع بين الفهم العميق والقدرة على التوليد لتلبية احتياجات الاستخدام الواسعة مثل دعم العملاء والتعليم والدعم الفني.",
  "claude-2.0.description": "Claude 2 يقدم تحسينات رئيسية للمؤسسات، بما في ذلك سياق 200 ألف رمز، تقليل الهلوسة، دعم التعليمات النظامية، وميزة جديدة: استدعاء الأدوات.",
  "claude-2.1.description": "Claude 2 يقدم تحسينات رئيسية للمؤسسات، بما في ذلك سياق 200 ألف رمز، تقليل الهلوسة، دعم التعليمات النظامية، وميزة جديدة: استدعاء الأدوات.",
  "claude-3-5-haiku-20241022.description": "Claude 3.5 Haiku هو أسرع نموذج من الجيل التالي لشركة Anthropic. مقارنةً بـ Claude 3 Haiku، فإنه يقدم تحسينات في المهارات ويتفوق على النموذج الأكبر السابق Claude 3 Opus في العديد من اختبارات الذكاء.",
  "claude-3-5-haiku-latest.description": "Claude 3.5 Haiku يقدم استجابات سريعة للمهام الخفيفة.",
  "claude-3-7-sonnet-20250219.description": "Claude 3.7 Sonnet هو أذكى نموذج من Anthropic وأول نموذج استدلال هجين في السوق. يمكنه تقديم ردود شبه فورية أو استدلال تدريجي مرئي للمستخدم. يتميز Sonnet بقوة خاصة في البرمجة، علم البيانات، الرؤية، ومهام الوكلاء.",
  "claude-3-7-sonnet-latest.description": "Claude 3.7 Sonnet هو أحدث وأقوى نموذج من Anthropic للمهام المعقدة، يتميز بالأداء العالي، الذكاء، الطلاقة، والفهم العميق.",
  "claude-3-haiku-20240307.description": "Claude 3 Haiku هو أسرع وأصغر نموذج من Anthropic، مصمم لتقديم استجابات شبه فورية بأداء سريع ودقيق.",
  "claude-3-opus-20240229.description": "Claude 3 Opus هو أقوى نموذج من Anthropic للمهام المعقدة، يتميز بالأداء العالي، الذكاء، الطلاقة، والفهم.",
  "claude-3-sonnet-20240229.description": "Claude 3 Sonnet يوازن بين الذكاء والسرعة لتلبية احتياجات المؤسسات، ويوفر فائدة عالية بتكلفة أقل ونشر موثوق على نطاق واسع.",
  "claude-haiku-4-5-20251001.description": "Claude Haiku 4.5 هو أسرع وأذكى نموذج Haiku من Anthropic، يتميز بسرعة فائقة وقدرة استدلال ممتدة.",
  "claude-opus-4-1-20250805-thinking.description": "Claude Opus 4.1 Thinking هو إصدار متقدم يمكنه عرض عملية تفكيره.",
  "claude-opus-4-1-20250805.description": "Claude Opus 4.1 هو أحدث وأقوى نموذج من Anthropic للمهام المعقدة، يتميز بالأداء العالي، الذكاء، الطلاقة، والفهم.",
  "claude-opus-4-20250514.description": "Claude Opus 4 هو أقوى نموذج من Anthropic للمهام المعقدة للغاية، يتميز بالأداء العالي، الذكاء، الطلاقة، والفهم العميق.",
  "claude-opus-4-5-20251101.description": "Claude Opus 4.5 هو النموذج الرائد من Anthropic، يجمع بين الذكاء الاستثنائي والأداء القابل للتوسع، مثالي للمهام المعقدة التي تتطلب استجابات عالية الجودة وتفكير متقدم.",
  "claude-sonnet-4-20250514-thinking.description": "Claude Sonnet 4 Thinking يمكنه تقديم استجابات شبه فورية أو تفكير متسلسل مرئي.",
  "claude-sonnet-4-20250514.description": "Claude Sonnet 4 يمكنه تقديم ردود شبه فورية أو تفكير تدريجي مرئي بخطوات واضحة.",
  "claude-sonnet-4-5-20250929.description": "Claude Sonnet 4.5 هو أذكى نموذج من Anthropic حتى الآن.",
  "codegeex-4.description": "CodeGeeX-4 هو مساعد برمجة ذكي يدعم الأسئلة والأجوبة متعددة اللغات وإكمال الشيفرة لزيادة إنتاجية المطورين.",
  "codegeex4-all-9b.description": "CodeGeeX4-ALL-9B هو نموذج توليد شيفرة متعدد اللغات يدعم الإكمال والتوليد، تفسير الشيفرة، البحث عبر الإنترنت، استدعاء الوظائف، وأسئلة وأجوبة على مستوى المستودع، ويغطي مجموعة واسعة من سيناريوهات تطوير البرمجيات. يُعد من أفضل نماذج الشيفرة تحت 10B.",
  "codegemma.description": "CodeGemma هو نموذج خفيف الوزن لمهام البرمجة المتنوعة، يتيح التكرار السريع والتكامل السلس.",
  "codegemma:2b.description": "CodeGemma هو نموذج خفيف الوزن لمهام البرمجة المتنوعة، يتيح التكرار السريع والتكامل السلس.",
  "codellama.description": "Code Llama هو نموذج لغوي كبير يركز على توليد الشيفرة ومناقشتها، ويدعم لغات متعددة لتسهيل سير عمل المطورين.",
  "codellama/CodeLlama-34b-Instruct-hf.description": "Code Llama هو نموذج لغوي كبير يركز على توليد الشيفرة ومناقشتها، ويدعم لغات متعددة لتسهيل سير عمل المطورين.",
  "codellama:13b.description": "Code Llama هو نموذج لغوي كبير يركز على توليد الشيفرة ومناقشتها، ويدعم لغات متعددة لتسهيل سير عمل المطورين.",
  "codellama:34b.description": "Code Llama هو نموذج لغوي كبير يركز على توليد الشيفرة ومناقشتها، ويدعم لغات متعددة لتسهيل سير عمل المطورين.",
  "codellama:70b.description": "Code Llama هو نموذج لغوي كبير يركز على توليد الشيفرة ومناقشتها، ويدعم لغات متعددة لتسهيل سير عمل المطورين.",
  "codeqwen.description": "CodeQwen1.5 هو نموذج لغوي كبير مدرب على بيانات شيفرة واسعة النطاق، مصمم للمهام البرمجية المعقدة.",
  "codestral-latest.description": "Codestral هو أحدث نموذج برمجة لدينا؛ الإصدار v2 (يناير 2025) يستهدف المهام منخفضة التأخير وعالية التكرار مثل FIM، تصحيح الشيفرة، وتوليد الاختبارات.",
  "codestral.description": "Codestral هو أول نموذج شيفرة من Mistral AI، يقدم دعمًا قويًا لتوليد الشيفرة.",
  "codex-mini-latest.description": "codex-mini-latest هو نموذج o4-mini محسّن لواجهة سطر أوامر Codex. للاستخدام المباشر عبر API، نوصي بالبدء بـ gpt-4.1.",
  "cogito-2.1:671b.description": "Cogito v2.1 671B هو نموذج مفتوح المصدر من الولايات المتحدة للاستخدام التجاري، يتمتع بأداء ينافس النماذج الرائدة، وكفاءة أعلى في الاستدلال على الرموز، وسياق طويل يصل إلى 128 ألف رمز، وقدرات قوية بشكل عام.",
  "cogview-4.description": "CogView-4 هو أول نموذج مفتوح المصدر لتحويل النص إلى صورة من Zhipu يدعم توليد الحروف الصينية. يعزز الفهم الدلالي، جودة الصور، وعرض النصوص الصينية/الإنجليزية، ويدعم مطالبات ثنائية اللغة بأي طول، ويمكنه توليد صور بأي دقة ضمن النطاقات المحددة.",
  "cohere-command-r-plus.description": "Command R+ هو نموذج متقدم محسّن لاسترجاع المعرفة (RAG) مصمم لأعباء العمل المؤسسية.",
  "cohere-command-r.description": "Command R هو نموذج توليدي قابل للتوسع مصمم لاستخدام أدوات واسترجاع المعرفة، مما يتيح ذكاءً اصطناعيًا بجودة الإنتاج.",
  "cohere/Cohere-command-r-plus.description": "Command R+ هو نموذج متقدم محسّن لاسترجاع المعرفة (RAG) مصمم لأعباء العمل المؤسسية.",
  "cohere/Cohere-command-r.description": "Command R هو نموذج توليدي قابل للتوسع مصمم لاستخدام أدوات واسترجاع المعرفة، مما يتيح ذكاءً اصطناعيًا بجودة الإنتاج.",
  "cohere/command-a.description": "Command A هو أقوى نموذج من Cohere حتى الآن، يتفوق في استخدام الأدوات، الوكلاء، استرجاع المعرفة، وحالات الاستخدام متعددة اللغات. يتمتع بسياق بطول 256 ألف رمز، ويعمل على وحدتي GPU فقط، ويوفر إنتاجية أعلى بنسبة 150٪ مقارنة بـ Command R+ 08-2024.",
  "cohere/command-r-plus.description": "Command R+ هو أحدث نموذج LLM من Cohere محسّن للدردشة والسياق الطويل، يهدف إلى أداء استثنائي لتمكين الشركات من الانتقال من النماذج الأولية إلى الإنتاج.",
  "cohere/command-r.description": "Command R محسّن لمهام الدردشة والسياق الطويل، ويُعد نموذجًا \"قابلًا للتوسع\" يوازن بين الأداء العالي والدقة، مما يمكّن الشركات من تجاوز النماذج الأولية إلى الإنتاج.",
  "cohere/embed-v4.0.description": "نموذج يصنف أو يحول النصوص، الصور، أو المحتوى المختلط إلى تمثيلات مضمنة (embeddings).",
  "comfyui/flux-dev.description": "FLUX.1 Dev هو نموذج تحويل النص إلى صورة عالي الجودة (10–50 خطوة)، مثالي للإنتاج الإبداعي والفني المتميز.",
  "comfyui/flux-kontext-dev.description": "FLUX.1 Kontext-dev هو نموذج لتحرير الصور يدعم التعديلات الموجهة بالنص، بما في ذلك التعديلات المحلية ونقل الأسلوب.",
  "comfyui/flux-krea-dev.description": "FLUX.1 Krea-dev هو نموذج تحويل نص إلى صورة معزز بالأمان تم تطويره بالتعاون مع Krea، ويحتوي على مرشحات أمان مدمجة.",
  "comfyui/flux-schnell.description": "FLUX.1 Schnell هو نموذج تحويل نص إلى صورة فائق السرعة يولد صورًا عالية الجودة في 1-4 خطوات، مثالي للاستخدام في الوقت الحقيقي والنماذج الأولية السريعة.",
  "comfyui/stable-diffusion-15.description": "Stable Diffusion 1.5 هو نموذج تحويل نص إلى صورة كلاسيكي بدقة 512x512، مثالي للنماذج الأولية السريعة والتجارب الإبداعية.",
  "comfyui/stable-diffusion-35-inclclip.description": "Stable Diffusion 3.5 مع مشفرات CLIP/T5 مدمجة لا يحتاج إلى ملفات مشفر خارجية، مناسب لنماذج مثل sd3.5_medium_incl_clips مع استخدام موارد أقل.",
  "comfyui/stable-diffusion-35.description": "Stable Diffusion 3.5 هو نموذج تحويل نص إلى صورة من الجيل التالي مع نسخ كبيرة ومتوسطة. يتطلب ملفات مشفر CLIP خارجية ويوفر جودة صور ممتازة والتزامًا قويًا بالمطالبات.",
  "comfyui/stable-diffusion-custom-refiner.description": "نموذج تحويل صورة إلى صورة مخصص لـ SDXL. استخدم custom_sd_lobe.safetensors كاسم ملف النموذج؛ إذا كان لديك VAE، استخدم custom_sd_vae_lobe.safetensors. ضع ملفات النموذج في المجلدات المطلوبة لـ Comfy.",
  "comfyui/stable-diffusion-custom.description": "نموذج تحويل نص إلى صورة مخصص لـ SD. استخدم custom_sd_lobe.safetensors كاسم ملف النموذج؛ إذا كان لديك VAE، استخدم custom_sd_vae_lobe.safetensors. ضع ملفات النموذج في المجلدات المطلوبة لـ Comfy.",
  "comfyui/stable-diffusion-refiner.description": "نموذج تحويل صورة إلى صورة لـ SDXL ينفذ تحويلات عالية الجودة من الصور المدخلة، ويدعم نقل الأسلوب، الاستعادة، والتنوع الإبداعي.",
  "comfyui/stable-diffusion-xl.description": "SDXL هو نموذج تحويل نص إلى صورة يدعم التوليد عالي الدقة 1024x1024 مع جودة صور وتفاصيل محسّنة.",
  "command-a-03-2025.description": "Command A هو أقوى نموذج لدينا حتى الآن، يتفوق في استخدام الأدوات، الوكلاء، استرجاع المعرفة، والسيناريوهات متعددة اللغات. يتمتع بسياق بطول 256 ألف رمز، ويعمل على وحدتي GPU فقط، ويوفر إنتاجية أعلى بنسبة 150٪ مقارنة بـ Command R+ 08-2024.",
  "command-light-nightly.description": "لتقليل الفجوة بين الإصدارات الرئيسية، نقدم إصدارات Command الليلية. لسلسلة command-light، يُطلق عليها command-light-nightly. إنها النسخة الأحدث والأكثر تجريبية (وقد تكون غير مستقرة)، ويتم تحديثها بانتظام دون إشعار، لذا لا يُنصح باستخدامها في الإنتاج.",
  "command-light.description": "نسخة أصغر وأسرع من Command تتمتع بقدرات شبه مماثلة ولكن بسرعة أعلى.",
  "command-nightly.description": "لتقليل الفجوة بين الإصدارات الرئيسية، نقدم إصدارات Command الليلية. لسلسلة Command، يُطلق عليها command-nightly. إنها النسخة الأحدث والأكثر تجريبية (وقد تكون غير مستقرة)، ويتم تحديثها بانتظام دون إشعار، لذا لا يُنصح باستخدامها في الإنتاج.",
  "command-r-03-2024.description": "Command R هو نموذج دردشة يتبع التعليمات بجودة أعلى، موثوقية أكبر، وسياق أطول من النماذج السابقة. يدعم سير العمل المعقد مثل توليد الشيفرة، استرجاع المعرفة، استخدام الأدوات، والوكلاء.",
  "command-r-08-2024.description": "command-r-08-2024 هو إصدار محدث من نموذج Command R تم إطلاقه في أغسطس 2024.",
  "command-r-plus-04-2024.description": "command-r-plus هو اسم مستعار لـ command-r-plus-04-2024، لذا فإن استخدام command-r-plus في API يشير إلى هذا النموذج.",
  "command-r-plus-08-2024.description": "Command R+ هو نموذج دردشة يتبع التعليمات بجودة أعلى، موثوقية أكبر، وسياق أطول من النماذج السابقة. مثالي لسير العمل المعقد في استرجاع المعرفة واستخدام الأدوات متعددة الخطوات.",
  "command-r-plus.description": "Command R+ هو نموذج LLM عالي الأداء مصمم لسيناريوهات مؤسسية حقيقية وتطبيقات معقدة.",
  "command-r.description": "Command R هو نموذج LLM محسّن لمهام الدردشة والسياق الطويل، مثالي للتفاعل الديناميكي وإدارة المعرفة.",
  "command-r7b-12-2024.description": "command-r7b-12-2024 هو تحديث صغير وفعال تم إصداره في ديسمبر 2024. يتفوق في استرجاع المعرفة، استخدام الأدوات، ومهام الوكلاء التي تتطلب استدلالًا معقدًا متعدد الخطوات.",
  "command.description": "نموذج دردشة يتبع التعليمات يوفر جودة وموثوقية أعلى في مهام اللغة، مع سياق أطول من نماذجنا التوليدية الأساسية.",
  "computer-use-preview.description": "computer-use-preview هو نموذج متخصص لأداة \"استخدام الحاسوب\"، مدرب لفهم وتنفيذ المهام المتعلقة بالحاسوب.",
  "dall-e-2.description": "الجيل الثاني من نموذج DALL·E لتوليد صور أكثر واقعية ودقة، بدقة أعلى أربع مرات من الجيل الأول.",
  "dall-e-3.description": "أحدث إصدار من نموذج DALL·E، تم إطلاقه في نوفمبر 2023، يدعم توليد صور أكثر واقعية ودقة مع تفاصيل أقوى.",
  "databricks/dbrx-instruct.description": "يوفر DBRX Instruct معالجة موثوقة للتعليمات عبر مختلف الصناعات.",
  "deepseek-ai/DeepSeek-OCR.description": "DeepSeek-OCR هو نموذج رؤية-لغة من DeepSeek AI يركز على التعرف البصري على الحروف (OCR) و\"الضغط البصري السياقي\". يستكشف ضغط السياق من الصور، ويعالج المستندات بكفاءة، ويحولها إلى نص منظم (مثل Markdown). يتعرف بدقة على النصوص في الصور، مما يجعله مناسبًا لتحويل المستندات إلى صيغة رقمية، واستخراج النصوص، والمعالجة المنظمة.",
  "deepseek-ai/DeepSeek-R1-0528-Qwen3-8B.description": "يستخلص DeepSeek-R1-0528-Qwen3-8B سلسلة التفكير من DeepSeek-R1-0528 ويطبقها على Qwen3 8B Base. يحقق أداءً رائدًا بين النماذج المفتوحة، متفوقًا على Qwen3 8B بنسبة 10٪ في AIME 2024 ويضاهي أداء Qwen3-235B-thinking. يتميز في اختبارات التفكير الرياضي، والبرمجة، والمنطق العام. يستخدم نفس بنية Qwen3-8B ولكن مع محول الرموز الخاص بـ DeepSeek-R1-0528.",
  "deepseek-ai/DeepSeek-R1-0528.description": "يستفيد DeepSeek R1 من قدرات حوسبة إضافية وتحسينات خوارزمية بعد التدريب لتعزيز قدرات التفكير. يحقق أداءً قويًا في اختبارات الرياضيات، والبرمجة، والمنطق العام، ويقترب من نماذج رائدة مثل o3 وGemini 2.5 Pro.",
  "deepseek-ai/DeepSeek-R1-Distill-Llama-70B.description": "تستخدم نماذج DeepSeek-R1 المستخلصة التعلم المعزز وبيانات البداية الباردة لتحسين التفكير وتحديد معايير جديدة للنماذج المفتوحة متعددة المهام.",
  "deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B.description": "تستخدم نماذج DeepSeek-R1 المستخلصة التعلم المعزز وبيانات البداية الباردة لتحسين التفكير وتحديد معايير جديدة للنماذج المفتوحة متعددة المهام.",
  "deepseek-ai/DeepSeek-R1-Distill-Qwen-14B.description": "تستخدم نماذج DeepSeek-R1 المستخلصة التعلم المعزز وبيانات البداية الباردة لتحسين التفكير وتحديد معايير جديدة للنماذج المفتوحة متعددة المهام.",
  "deepseek-ai/DeepSeek-R1-Distill-Qwen-32B.description": "تم استخلاص DeepSeek-R1-Distill-Qwen-32B من Qwen2.5-32B وتم تحسينه باستخدام 800 ألف عينة مختارة من DeepSeek-R1. يتميز في الرياضيات، والبرمجة، والتفكير، ويحقق نتائج قوية في AIME 2024، وMATH-500 (بدقة 94.3٪)، وGPQA Diamond.",
  "deepseek-ai/DeepSeek-R1-Distill-Qwen-7B.description": "تم استخلاص DeepSeek-R1-Distill-Qwen-7B من Qwen2.5-Math-7B وتم تحسينه باستخدام 800 ألف عينة مختارة من DeepSeek-R1. يحقق أداءً قويًا بنسبة 92.8٪ في MATH-500، و55.5٪ في AIME 2024، وتصنيف 1189 في CodeForces لنموذج بحجم 7B.",
  "deepseek-ai/DeepSeek-R1.description": "يعزز DeepSeek-R1 قدرات التفكير باستخدام التعلم المعزز وبيانات البداية الباردة، ويحدد معايير جديدة للنماذج المفتوحة متعددة المهام متفوقًا على OpenAI-o1-mini.",
  "deepseek-ai/DeepSeek-V2.5.description": "يعمل DeepSeek-V2.5 على ترقية DeepSeek-V2-Chat وDeepSeek-Coder-V2-Instruct، ويمزج بين القدرات العامة والبرمجية. يحسن الكتابة واتباع التعليمات لمواءمة التفضيلات بشكل أفضل، ويظهر تحسنًا ملحوظًا في AlpacaEval 2.0 وArenaHard وAlignBench وMT-Bench.",
  "deepseek-ai/DeepSeek-V3.1-Terminus.description": "DeepSeek-V3.1-Terminus هو إصدار محدث من V3.1 كنموذج وكيل هجين. يعالج المشكلات التي أبلغ عنها المستخدمون ويحسن الاستقرار واتساق اللغة ويقلل من الخلط بين الصينية/الإنجليزية والرموز غير الطبيعية. يدمج أوضاع التفكير وغير التفكير مع قوالب المحادثة للتبديل المرن. كما يعزز أداء وكلاء الكود والبحث لاستخدام الأدوات بشكل أكثر موثوقية وتنفيذ المهام متعددة الخطوات.",
  "deepseek-ai/DeepSeek-V3.1.description": "يستخدم DeepSeek V3.1 بنية تفكير هجينة ويدعم أوضاع التفكير وغير التفكير.",
  "deepseek-ai/DeepSeek-V3.2-Exp.description": "DeepSeek-V3.2-Exp هو إصدار تجريبي من V3.2 يربط بالهيكلية القادمة. يضيف انتباهًا متفرقًا (DSA) إلى V3.1-Terminus لتحسين كفاءة التدريب والاستدلال في السياقات الطويلة، مع تحسينات لاستخدام الأدوات، وفهم المستندات الطويلة، والتفكير متعدد الخطوات. مثالي لاستكشاف كفاءة تفكير أعلى بميزانيات سياق كبيرة.",
  "deepseek-ai/DeepSeek-V3.description": "DeepSeek-V3 هو نموذج MoE يحتوي على 671 مليار معلمة، يستخدم MLA وDeepSeekMoE مع توازن تحميل خالٍ من الفقدان لتدريب واستدلال فعال. تم تدريبه مسبقًا على 14.8 تريليون رمز عالي الجودة مع SFT وRL، ويتفوق على النماذج المفتوحة الأخرى ويقترب من النماذج المغلقة الرائدة.",
  "deepseek-ai/deepseek-llm-67b-chat.description": "DeepSeek LLM Chat (67B) هو نموذج مبتكر يوفر فهمًا عميقًا للغة وتفاعلًا ذكيًا.",
  "deepseek-ai/deepseek-r1.description": "نموذج لغة كبير فعال وحديث يتميز بقوة في التفكير، والرياضيات، والبرمجة.",
  "deepseek-ai/deepseek-v3.1-terminus.description": "DeepSeek V3.1 هو نموذج تفكير من الجيل التالي يتمتع بقدرات أقوى في التفكير المعقد وسلسلة التفكير لمهام التحليل العميق.",
  "deepseek-ai/deepseek-v3.1.description": "DeepSeek V3.1 هو نموذج تفكير من الجيل التالي يتمتع بقدرات أقوى في التفكير المعقد وسلسلة التفكير لمهام التحليل العميق.",
  "deepseek-ai/deepseek-vl2.description": "DeepSeek-VL2 هو نموذج رؤية-لغة MoE يعتمد على DeepSeekMoE-27B مع تنشيط متفرق، ويحقق أداءً قويًا باستخدام 4.5 مليار معلمة نشطة فقط. يتميز في الأسئلة البصرية، وOCR، وفهم المستندات/الجداول/المخططات، والتأريض البصري.",
  "deepseek-chat.description": "نموذج مفتوح المصدر جديد يجمع بين القدرات العامة والبرمجية. يحافظ على حوار النموذج العام وقوة البرمجة في نموذج المبرمج، مع تحسين توافق التفضيلات. كما يعزز DeepSeek-V2.5 قدرات الكتابة واتباع التعليمات.",
  "deepseek-coder-33B-instruct.description": "DeepSeek Coder 33B هو نموذج لغة برمجية تم تدريبه على 2 تريليون رمز (87٪ كود، 13٪ نص صيني/إنجليزي). يقدم نافذة سياق 16K ومهام الإكمال في المنتصف، ويوفر إكمال كود على مستوى المشاريع وملء مقاطع الكود.",
  "deepseek-coder-v2.description": "DeepSeek Coder V2 هو نموذج كود MoE مفتوح المصدر يتميز بأداء قوي في مهام البرمجة، ويضاهي GPT-4 Turbo.",
  "deepseek-coder-v2:236b.description": "DeepSeek Coder V2 هو نموذج كود MoE مفتوح المصدر يتميز بأداء قوي في مهام البرمجة، ويضاهي GPT-4 Turbo.",
  "deepseek-ocr.description": "DeepSeek-OCR هو نموذج رؤية-لغة من DeepSeek AI يركز على OCR و\"الضغط البصري السياقي\". يستكشف ضغط المعلومات السياقية من الصور، ويعالج المستندات بكفاءة، ويحولها إلى تنسيقات نصية منظمة مثل Markdown. يتعرف بدقة على النصوص في الصور، مما يجعله مثاليًا لتحويل المستندات إلى صيغة رقمية، واستخراج النصوص، والمعالجة المنظمة.",
  "deepseek-r1-0528.description": "نموذج كامل بسعة 685 مليار تم إصداره في 28 مايو 2025. يستخدم DeepSeek-R1 التعلم المعزز واسع النطاق بعد التدريب، مما يعزز التفكير بشكل كبير باستخدام بيانات معنونة قليلة، ويؤدي أداءً قويًا في الرياضيات، والبرمجة، والتفكير باللغة الطبيعية.",
  "deepseek-r1-250528.description": "DeepSeek R1 250528 هو النموذج الكامل للتفكير من DeepSeek-R1 للمهام الرياضية والمنطقية الصعبة.",
  "deepseek-r1-70b-fast-online.description": "إصدار سريع من DeepSeek R1 70B مع بحث ويب في الوقت الحقيقي، يوفر استجابات أسرع مع الحفاظ على الأداء.",
  "deepseek-r1-70b-online.description": "الإصدار القياسي من DeepSeek R1 70B مع بحث ويب في الوقت الحقيقي، مناسب للدردشة والمهام النصية المحدثة.",
  "deepseek-r1-distill-llama-70b.description": "يجمع DeepSeek R1 Distill Llama 70B بين تفكير R1 ونظام Llama البيئي.",
  "deepseek-r1-distill-llama-8b.description": "تم استخلاص DeepSeek-R1-Distill-Llama-8B من Llama-3.1-8B باستخدام مخرجات DeepSeek R1.",
  "deepseek-r1-distill-llama.description": "تم استخلاص deepseek-r1-distill-llama من DeepSeek-R1 على Llama.",
  "deepseek-r1-distill-qianfan-70b.description": "DeepSeek R1 Distill Qianfan 70B هو نموذج مستخلص من R1 يعتمد على Qianfan-70B بقيمة عالية.",
  "deepseek-r1-distill-qianfan-8b.description": "DeepSeek R1 Distill Qianfan 8B هو نموذج مستخلص من R1 يعتمد على Qianfan-8B للتطبيقات الصغيرة والمتوسطة.",
  "deepseek-r1-distill-qianfan-llama-70b.description": "DeepSeek R1 Distill Qianfan Llama 70B هو نموذج مستخلص من R1 يعتمد على Llama-70B.",
  "deepseek-r1-distill-qwen-1.5b.description": "DeepSeek R1 Distill Qwen 1.5B هو نموذج مستخلص فائق الخفة للبيئات ذات الموارد المنخفضة جدًا.",
  "deepseek-r1-distill-qwen-14b.description": "DeepSeek R1 Distill Qwen 14B هو نموذج مستخلص متوسط الحجم للنشر في سيناريوهات متعددة.",
  "deepseek-r1-distill-qwen-32b.description": "DeepSeek R1 Distill Qwen 32B هو نموذج مستخلص من R1 يعتمد على Qwen-32B، يوازن بين الأداء والتكلفة.",
  "deepseek-r1-distill-qwen-7b.description": "DeepSeek R1 Distill Qwen 7B هو نموذج مستخلص خفيف الوزن للبيئات الطرفية والمؤسسات الخاصة.",
  "deepseek-r1-distill-qwen.description": "تم استخلاص deepseek-r1-distill-qwen من DeepSeek-R1 على Qwen.",
  "deepseek-r1-fast-online.description": "الإصدار الكامل السريع من DeepSeek R1 مع بحث ويب في الوقت الحقيقي، يجمع بين قدرات بحجم 671B واستجابة أسرع.",
  "deepseek-r1-online.description": "الإصدار الكامل من DeepSeek R1 مع 671 مليار معلمة وبحث ويب في الوقت الحقيقي، يوفر فهمًا وتوليدًا أقوى.",
  "deepseek-r1.description": "يستخدم DeepSeek-R1 بيانات البداية الباردة قبل التعلم المعزز ويؤدي أداءً مماثلًا لـ OpenAI-o1 في الرياضيات، والبرمجة، والتفكير.",
  "deepseek-reasoner.description": "وضع التفكير في DeepSeek V3.2 ينتج سلسلة من الأفكار قبل الإجابة النهائية لتحسين الدقة.",
  "deepseek-v2.description": "DeepSeek V2 هو نموذج MoE فعال لمعالجة منخفضة التكلفة.",
  "deepseek-v2:236b.description": "DeepSeek V2 236B هو نموذج DeepSeek الموجه للبرمجة مع قدرات قوية في توليد الكود.",
  "deepseek-v3-0324.description": "DeepSeek-V3-0324 هو نموذج MoE يحتوي على 671 مليار معلمة يتميز بقوة في البرمجة، والقدرات التقنية، وفهم السياق، والتعامل مع النصوص الطويلة.",
  "deepseek-v3.1-terminus.description": "DeepSeek-V3.1-Terminus هو نموذج لغوي كبير محسّن للأجهزة الطرفية، مصمم خصيصًا لأجهزة الطرفية.",
  "deepseek-v3.1-think-250821.description": "DeepSeek V3.1 Think 250821 هو النموذج العميق للتفكير المقابل لإصدار Terminus، مصمم للاستدلال عالي الأداء.",
  "deepseek-v3.1.description": "DeepSeek-V3.1 هو نموذج استدلال هجين جديد من DeepSeek، يدعم أوضاع التفكير وغير التفكير، ويوفر كفاءة تفكير أعلى من DeepSeek-R1-0528. التحسينات بعد التدريب تعزز بشكل كبير استخدام أدوات الوكلاء وأداء المهام. يدعم نافذة سياق 128k وما يصل إلى 64k من الرموز الناتجة.",
  "deepseek-v3.1:671b.description": "DeepSeek V3.1 هو نموذج استدلال من الجيل التالي مع تحسينات في الاستدلال المعقد وسلسلة الأفكار، مناسب للمهام التي تتطلب تحليلاً عميقًا.",
  "deepseek-v3.2-exp.description": "deepseek-v3.2-exp يقدم انتباهاً متفرقاً لتحسين كفاءة التدريب والاستدلال على النصوص الطويلة، بسعر أقل من deepseek-v3.1.",
  "deepseek-v3.2-think.description": "DeepSeek V3.2 Think هو نموذج تفكير عميق كامل يتميز باستدلال طويل السلسلة أقوى.",
  "deepseek-v3.2.description": "DeepSeek-V3.2 هو أول نموذج استدلال هجين من DeepSeek يدمج التفكير مع استخدام الأدوات. يستخدم بنية فعالة لتقليل استهلاك الحوسبة، ويعزز القدرات من خلال التعلم المعزز واسع النطاق وبيانات مهام تركيبية ضخمة. يجمع بين هذه العناصر لتحقيق أداء يقارب GPT-5-High، مع تقليل كبير في طول الإخراج، مما يقلل من التكاليف والوقت المنتظر للمستخدم.",
  "deepseek-v3.description": "DeepSeek-V3 هو نموذج MoE قوي بإجمالي 671 مليار معلمة و37 مليار معلمة نشطة لكل رمز.",
  "deepseek-vl2-small.description": "DeepSeek VL2 Small هو إصدار متعدد الوسائط خفيف الوزن للاستخدام في البيئات ذات الموارد المحدودة أو التزامن العالي.",
  "deepseek-vl2.description": "DeepSeek VL2 هو نموذج متعدد الوسائط لفهم النصوص والصور والإجابة البصرية الدقيقة.",
  "deepseek/deepseek-chat-v3-0324.description": "DeepSeek V3 هو نموذج MoE يحتوي على 685 مليار معلمة، وهو أحدث إصدار من سلسلة دردشة DeepSeek الرائدة.\n\nيعتمد على [DeepSeek V3](/deepseek/deepseek-chat-v3) ويؤدي أداءً قويًا عبر المهام.",
  "deepseek/deepseek-chat-v3-0324:free.description": "DeepSeek V3 هو نموذج MoE يحتوي على 685 مليار معلمة، وهو أحدث إصدار من سلسلة دردشة DeepSeek الرائدة.\n\nيعتمد على [DeepSeek V3](/deepseek/deepseek-chat-v3) ويؤدي أداءً قويًا عبر المهام.",
  "deepseek/deepseek-chat-v3.1.description": "DeepSeek-V3.1 هو نموذج استدلال هجين طويل السياق من DeepSeek، يدعم أوضاع التفكير وغير التفكير ودمج الأدوات.",
  "deepseek/deepseek-chat.description": "DeepSeek-V3 هو نموذج استدلال هجين عالي الأداء من DeepSeek للمهام المعقدة ودمج الأدوات.",
  "deepseek/deepseek-r1-0528.description": "DeepSeek R1 0528 هو إصدار محدث يركز على الإتاحة المفتوحة والاستدلال الأعمق.",
  "deepseek/deepseek-r1-0528:free.description": "يحسن DeepSeek-R1 الاستدلال بشكل كبير باستخدام بيانات معنونة قليلة، ويخرج سلسلة من الأفكار قبل الإجابة النهائية لتحسين الدقة.",
  "deepseek/deepseek-r1-distill-llama-70b.description": "DeepSeek R1 Distill Llama 70B هو نموذج LLM مكرر يعتمد على Llama 3.3 70B، تم تحسينه باستخدام مخرجات DeepSeek R1 لتحقيق أداء تنافسي مع النماذج الرائدة.",
  "deepseek/deepseek-r1-distill-llama-8b.description": "DeepSeek R1 Distill Llama 8B هو نموذج LLM مكرر يعتمد على Llama-3.1-8B-Instruct، تم تدريبه باستخدام مخرجات DeepSeek R1.",
  "deepseek/deepseek-r1-distill-qwen-14b.description": "DeepSeek R1 Distill Qwen 14B هو نموذج LLM مكرر يعتمد على Qwen 2.5 14B، تم تدريبه باستخدام مخرجات DeepSeek R1. يتفوق على OpenAI o1-mini في العديد من المعايير، ويحقق نتائج رائدة بين النماذج الكثيفة.",
  "deepseek/deepseek-r1-distill-qwen-32b.description": "DeepSeek R1 Distill Qwen 32B هو نموذج LLM مكرر يعتمد على Qwen 2.5 32B، تم تدريبه باستخدام مخرجات DeepSeek R1. يتفوق على OpenAI o1-mini في العديد من المعايير، ويحقق نتائج رائدة بين النماذج الكثيفة.",
  "deepseek/deepseek-r1.description": "تم تحديث DeepSeek R1 إلى DeepSeek-R1-0528. مع موارد حوسبة أكبر وتحسينات خوارزمية بعد التدريب، يعزز بشكل كبير عمق وقدرة الاستدلال. يؤدي أداءً قويًا في اختبارات الرياضيات، البرمجة، والمنطق العام، ويقترب من نماذج رائدة مثل o3 وGemini 2.5 Pro.",
  "deepseek/deepseek-r1/community.description": "DeepSeek R1 هو أحدث نموذج مفتوح المصدر من فريق DeepSeek، يتميز بأداء استدلال قوي، خاصة في الرياضيات، البرمجة، ومهام التفكير، ويقارن بـ OpenAI o1.",
  "deepseek/deepseek-r1:free.description": "يحسن DeepSeek-R1 الاستدلال بشكل كبير باستخدام بيانات معنونة قليلة، ويخرج سلسلة من الأفكار قبل الإجابة النهائية لتحسين الدقة.",
  "deepseek/deepseek-reasoner.description": "DeepSeek-V3 Thinking (reasoner) هو نموذج استدلال تجريبي من DeepSeek، مناسب للمهام المعقدة.",
  "deepseek/deepseek-v3.1-base.description": "DeepSeek V3.1 Base هو إصدار محسّن من نموذج DeepSeek V3.",
  "deepseek/deepseek-v3.description": "نموذج لغوي عام سريع مع استدلال محسّن.",
  "deepseek/deepseek-v3/community.description": "يُقدّم DeepSeek-V3 تقدمًا كبيرًا في سرعة الاستدلال مقارنة بالإصدارات السابقة. يحتل المرتبة الأولى بين النماذج مفتوحة المصدر ويضاهي أكثر النماذج المغلقة تقدمًا. يعتمد DeepSeek-V3 على آلية الانتباه الكامن متعدد الرؤوس (MLA) وبنية DeepSeekMoE، وكلاهما تم التحقق منه بالكامل في DeepSeek-V2. كما يُدخل استراتيجية مساعدة غير فقدية لتحقيق توازن في التحميل، وهدف تدريب على التنبؤ بعدة رموز لتعزيز الأداء.",
  "deepseek_r1.description": "DeepSeek-R1 هو نموذج استدلال مدفوع بالتعلم المعزز يعالج مشكلات التكرار وقابلية القراءة. قبل تطبيق التعلم المعزز، يستخدم بيانات بداية باردة لتحسين أداء الاستدلال. يضاهي نموذج OpenAI-o1 في مهام الرياضيات والبرمجة والاستدلال، مع تدريب مصمم بعناية لتحسين النتائج العامة.",
  "deepseek_r1_distill_llama_70b.description": "تم تقطير DeepSeek-R1-Distill-Llama-70B من Llama-3.3-70B-Instruct. كجزء من سلسلة DeepSeek-R1، تم ضبطه بدقة باستخدام عينات تم إنشاؤها بواسطة DeepSeek-R1، ويؤدي بقوة في مجالات الرياضيات والبرمجة والاستدلال.",
  "deepseek_r1_distill_qwen_14b.description": "تم تقطير DeepSeek-R1-Distill-Qwen-14B من Qwen2.5-14B وتم ضبطه بدقة باستخدام 800 ألف عينة منسقة تم إنشاؤها بواسطة DeepSeek-R1، مما يوفر أداءً قويًا في الاستدلال.",
  "deepseek_r1_distill_qwen_32b.description": "تم تقطير DeepSeek-R1-Distill-Qwen-32B من Qwen2.5-32B وتم ضبطه بدقة باستخدام 800 ألف عينة منسقة تم إنشاؤها بواسطة DeepSeek-R1، ويتفوق في مجالات الرياضيات والبرمجة والاستدلال.",
  "devstral-2:123b.description": "يتفوق Devstral 2 123B في استخدام الأدوات لاستكشاف قواعد الشيفرة، وتحرير ملفات متعددة، ودعم وكلاء هندسة البرمجيات.",
  "doubao-1.5-lite-32k.description": "Doubao-1.5-lite هو نموذج خفيف الوزن جديد يتميز بسرعة استجابة فائقة، ويقدم جودة عالية وأداء منخفض الكمون من الدرجة الأولى.",
  "doubao-1.5-pro-256k.description": "Doubao-1.5-pro-256k هو ترقية شاملة لـ Doubao-1.5-Pro، حيث يحسن الأداء العام بنسبة 10٪. يدعم نافذة سياق بحجم 256k وما يصل إلى 12k من الرموز الناتجة، مما يوفر أداءً أعلى، وسياقًا أوسع، وقيمة قوية لحالات الاستخدام المتنوعة.",
  "doubao-1.5-pro-32k.description": "Doubao-1.5-pro هو نموذج رائد من الجيل الجديد يتميز بترقيات شاملة، ويتفوق في المعرفة والبرمجة والاستدلال.",
  "doubao-1.5-thinking-pro-m.description": "Doubao-1.5 هو نموذج جديد للاستدلال العميق (الإصدار m يدعم الاستدلال العميق متعدد الوسائط بشكل أصلي) ويتفوق في الرياضيات والبرمجة والاستدلال العلمي والمهام العامة مثل الكتابة الإبداعية. يحقق نتائج من الدرجة الأولى أو يقترب منها في معايير مثل AIME 2024 وCodeforces وGPQA. يدعم نافذة سياق بحجم 128k وما يصل إلى 16k من الرموز الناتجة.",
  "doubao-1.5-thinking-pro.description": "Doubao-1.5 هو نموذج جديد للاستدلال العميق يتفوق في الرياضيات والبرمجة والاستدلال العلمي والمهام العامة مثل الكتابة الإبداعية. يحقق نتائج من الدرجة الأولى أو يقترب منها في معايير مثل AIME 2024 وCodeforces وGPQA. يدعم نافذة سياق بحجم 128k وما يصل إلى 16k من الرموز الناتجة.",
  "doubao-1.5-thinking-vision-pro.description": "نموذج جديد للاستدلال البصري العميق يتمتع بفهم واستدلال متعدد الوسائط أقوى، ويحقق نتائج رائدة في 37 من أصل 59 معيارًا عامًا.",
  "doubao-1.5-ui-tars.description": "Doubao-1.5-UI-TARS هو نموذج وكيل يركز على واجهات المستخدم الرسومية (GUI) ويتفاعل بسلاسة مع الواجهات من خلال الإدراك البشري، والاستدلال، والعمل.",
  "doubao-1.5-vision-lite.description": "Doubao-1.5-vision-lite هو نموذج متعدد الوسائط مطور يدعم الصور بأي دقة ونسب أبعاد متطرفة، مما يعزز الاستدلال البصري، والتعرف على المستندات، وفهم التفاصيل، واتباع التعليمات. يدعم نافذة سياق بحجم 128k وما يصل إلى 16k من الرموز الناتجة.",
  "doubao-1.5-vision-pro-32k.description": "Doubao-1.5-vision-pro هو نموذج متعدد الوسائط مطور يدعم الصور بأي دقة ونسب أبعاد متطرفة، مما يعزز الاستدلال البصري، والتعرف على المستندات، وفهم التفاصيل، واتباع التعليمات.",
  "doubao-1.5-vision-pro.description": "Doubao-1.5-vision-pro هو نموذج متعدد الوسائط مطور يدعم الصور بأي دقة ونسب أبعاد متطرفة، مما يعزز الاستدلال البصري، والتعرف على المستندات، وفهم التفاصيل، واتباع التعليمات.",
  "doubao-lite-128k.description": "استجابة فائقة السرعة مع قيمة أفضل، توفر خيارات أكثر مرونة عبر السيناريوهات. يدعم الاستدلال والتخصيص الدقيق مع نافذة سياق بحجم 128k.",
  "doubao-lite-32k.description": "استجابة فائقة السرعة مع قيمة أفضل، توفر خيارات أكثر مرونة عبر السيناريوهات. يدعم الاستدلال والتخصيص الدقيق مع نافذة سياق بحجم 32k.",
  "doubao-lite-4k.description": "استجابة فائقة السرعة مع قيمة أفضل، توفر خيارات أكثر مرونة عبر السيناريوهات. يدعم الاستدلال والتخصيص الدقيق مع نافذة سياق بحجم 4k.",
  "doubao-pro-256k.description": "أفضل نموذج رائد للأداء في المهام المعقدة، مع نتائج قوية في الأسئلة المرجعية، والتلخيص، والإبداع، وتصنيف النصوص، والمحاكاة. يدعم الاستدلال والتخصيص الدقيق مع نافذة سياق بحجم 256k.",
  "doubao-pro-32k.description": "أفضل نموذج رائد للأداء في المهام المعقدة، مع نتائج قوية في الأسئلة المرجعية، والتلخيص، والإبداع، وتصنيف النصوص، والمحاكاة. يدعم الاستدلال والتخصيص الدقيق مع نافذة سياق بحجم 32k.",
  "doubao-seed-1.6-flash.description": "Doubao-Seed-1.6-flash هو نموذج استدلال عميق متعدد الوسائط فائق السرعة بزمن معالجة منخفض يصل إلى 10 مللي ثانية. يدعم النصوص والرؤية، ويتفوق على النموذج الخفيف السابق في فهم النصوص، ويضاهي النماذج الاحترافية المنافسة في الرؤية. يدعم نافذة سياق بحجم 256k وما يصل إلى 16k من الرموز الناتجة.",
  "doubao-seed-1.6-lite.description": "Doubao-Seed-1.6-lite هو نموذج استدلال عميق متعدد الوسائط جديد مع جهد استدلال قابل للتعديل (أدنى، منخفض، متوسط، عالٍ)، يوفر قيمة أفضل وخيارًا قويًا للمهام الشائعة، مع نافذة سياق تصل إلى 256k.",
  "doubao-seed-1.6-thinking.description": "يعزز Doubao-Seed-1.6-thinking قدرات الاستدلال بشكل كبير، ويحسن القدرات الأساسية في البرمجة والرياضيات والمنطق مقارنة بـ Doubao-1.5-thinking-pro، مع إضافة فهم بصري. يدعم نافذة سياق بحجم 256k وما يصل إلى 16k من الرموز الناتجة.",
  "doubao-seed-1.6-vision.description": "Doubao-Seed-1.6-vision هو نموذج استدلال بصري عميق يوفر فهمًا واستدلالًا متعدد الوسائط أقوى للتعليم، ومراجعة الصور، والتفتيش/الأمن، والبحث الذكي. يدعم نافذة سياق بحجم 256k وما يصل إلى 64k من الرموز الناتجة.",
  "doubao-seed-1.6.description": "Doubao-Seed-1.6 هو نموذج استدلال عميق متعدد الوسائط جديد يدعم أوضاع التفكير التلقائي، والتفكير، وعدم التفكير. في وضع عدم التفكير، يتفوق بشكل كبير على Doubao-1.5-pro/250115. يدعم نافذة سياق بحجم 256k وما يصل إلى 16k من الرموز الناتجة.",
  "doubao-seed-1.8.description": "Doubao-Seed-1.8 يتمتع بقدرات أقوى في الفهم متعدد الوسائط والقدرات الوكيلة، ويدعم إدخال النصوص/الصور/الفيديو مع تخزين السياق، ويوفر أداءً متميزًا في المهام المعقدة.",
  "doubao-seed-code.description": "Doubao-Seed-Code مُحسَّن بعمق للبرمجة الوكيلة، ويدعم إدخالات متعددة الوسائط (نص/صورة/فيديو) ونافذة سياق بحجم 256k، ومتوافق مع واجهة Anthropic API، ومناسب للبرمجة، وفهم الرؤية، وسير عمل الوكلاء.",
  "doubao-seededit-3-0-i2i-250628.description": "نموذج الصور Doubao من ByteDance Seed يدعم إدخال النصوص والصور مع توليد صور عالية الجودة وقابلة للتحكم بدرجة كبيرة. يدعم تحرير الصور الموجه بالنص، مع أحجام إخراج تتراوح بين 512 و1536 على الجانب الطويل.",
  "doubao-seedream-3-0-t2i-250415.description": "Seedream 3.0 هو نموذج توليد صور من ByteDance Seed، يدعم إدخال النصوص والصور مع توليد صور عالية الجودة وقابلة للتحكم بدرجة كبيرة. يُولّد الصور من التعليمات النصية.",
  "doubao-seedream-4-0-250828.description": "Seedream 4.0 هو نموذج توليد صور من ByteDance Seed، يدعم إدخال النصوص والصور مع توليد صور عالية الجودة وقابلة للتحكم بدرجة كبيرة. يُولّد الصور من التعليمات النصية.",
  "doubao-vision-lite-32k.description": "Doubao-vision هو نموذج متعدد الوسائط من Doubao يتمتع بفهم قوي للصور واستدلال دقيق واتباع دقيق للتعليمات. يؤدي بشكل جيد في مهام استخراج النصوص من الصور والاستدلال القائم على الصور، مما يتيح سيناريوهات أسئلة وأجوبة بصرية أكثر تعقيدًا واتساعًا.",
  "doubao-vision-pro-32k.description": "Doubao-vision هو نموذج متعدد الوسائط من Doubao يتمتع بفهم قوي للصور واستدلال دقيق واتباع دقيق للتعليمات. يؤدي بشكل جيد في مهام استخراج النصوص من الصور والاستدلال القائم على الصور، مما يتيح سيناريوهات أسئلة وأجوبة بصرية أكثر تعقيدًا واتساعًا.",
  "emohaa.description": "Emohaa هو نموذج للصحة النفسية يتمتع بقدرات استشارية احترافية لمساعدة المستخدمين على فهم المشكلات العاطفية.",
  "ernie-4.5-0.3b.description": "ERNIE 4.5 0.3B هو نموذج مفتوح المصدر وخفيف الوزن، مصمم للنشر المحلي والمخصص.",
  "ernie-4.5-21b-a3b.description": "ERNIE 4.5 21B A3B هو نموذج مفتوح المصدر ذو عدد كبير من المعلمات، يتميز بفهم وتوليد أقوى.",
  "ernie-4.5-300b-a47b.description": "ERNIE 4.5 300B A47B هو نموذج MoE فائق الحجم من Baidu ERNIE يتمتع بقدرات استدلال ممتازة.",
  "ernie-4.5-8k-preview.description": "ERNIE 4.5 8K Preview هو نموذج معاينة بسياق 8K لتقييم أداء ERNIE 4.5.",
  "ernie-4.5-turbo-128k-preview.description": "معاينة ERNIE 4.5 Turbo 128K بقدرات على مستوى الإصدار، مناسبة للتكامل والاختبار التجريبي.",
  "ernie-4.5-turbo-128k.description": "ERNIE 4.5 Turbo 128K هو نموذج عام عالي الأداء يدعم تعزيز البحث واستدعاء الأدوات لسيناريوهات الأسئلة والأجوبة، والبرمجة، والوكلاء.",
  "ernie-4.5-turbo-32k.description": "ERNIE 4.5 Turbo 32K هو إصدار متوسط الطول من السياق مخصص للأسئلة والأجوبة، واسترجاع قواعد المعرفة، والحوار متعدد الأدوار.",
  "ernie-4.5-turbo-latest.description": "أحدث إصدار من ERNIE 4.5 Turbo بأداء محسن شامل، مثالي كنموذج إنتاج رئيسي.",
  "ernie-4.5-turbo-vl-32k-preview.description": "معاينة ERNIE 4.5 Turbo VL 32K هو نموذج متعدد الوسائط بسياق طويل لتقييم قدرات الرؤية.",
  "ernie-4.5-turbo-vl-32k.description": "ERNIE 4.5 Turbo VL 32K هو إصدار متعدد الوسائط متوسط الطول لفهم المستندات الطويلة والصور معًا.",
  "ernie-4.5-turbo-vl-latest.description": "أحدث إصدار من ERNIE 4.5 Turbo VL متعدد الوسائط مع تحسينات في فهم الصور والنصوص والاستدلال.",
  "ernie-4.5-turbo-vl-preview.description": "معاينة ERNIE 4.5 Turbo VL هو نموذج متعدد الوسائط لفهم وتوليد الصور والنصوص، مناسب لأسئلة وأجوبة بصرية وفهم المحتوى.",
  "ernie-4.5-turbo-vl.description": "ERNIE 4.5 Turbo VL هو نموذج متعدد الوسائط ناضج لفهم الصور والنصوص في بيئات الإنتاج.",
  "ernie-4.5-vl-28b-a3b.description": "ERNIE 4.5 VL 28B A3B هو نموذج مفتوح المصدر متعدد الوسائط لفهم الصور والنصوص والاستدلال.",
  "ernie-5.0-thinking-latest.description": "Wenxin 5.0 Thinking هو نموذج رائد متعدد الوسائط أصلي يدعم النصوص، الصور، الصوت، والفيديو بشكل موحد. يوفر ترقيات شاملة للقدرات في الأسئلة المعقدة، الإبداع، وسيناريوهات الوكلاء.",
  "ernie-5.0-thinking-preview.description": "معاينة Wenxin 5.0 Thinking هو نموذج رائد متعدد الوسائط أصلي يدعم النصوص، الصور، الصوت، والفيديو بشكل موحد. يوفر ترقيات شاملة للقدرات في الأسئلة المعقدة، الإبداع، وسيناريوهات الوكلاء.",
  "ernie-char-8k.description": "ERNIE Character 8K هو نموذج حواري بشخصية مخصصة لبناء شخصيات IP والدردشة طويلة الأمد.",
  "ernie-char-fiction-8k-preview.description": "معاينة ERNIE Character Fiction 8K هو نموذج لإنشاء الشخصيات والحبكات القصصية، مخصص لتقييم الميزات والاختبار.",
  "ernie-char-fiction-8k.description": "ERNIE Character Fiction 8K هو نموذج شخصيات للروايات وإنشاء الحبكات، مناسب لتوليد القصص الطويلة.",
  "ernie-irag-edit.description": "ERNIE iRAG Edit هو نموذج لتحرير الصور يدعم المسح، وإعادة الرسم، وتوليد النسخ المتنوعة.",
  "ernie-lite-8k.description": "ERNIE Lite 8K هو نموذج عام خفيف الوزن للأسئلة اليومية الحساسة للتكلفة وتوليد المحتوى.",
  "ernie-lite-pro-128k.description": "ERNIE Lite Pro 128K هو نموذج خفيف الوزن وعالي الأداء للسيناريوهات الحساسة للتكلفة والزمن.",
  "ernie-novel-8k.description": "ERNIE Novel 8K مصمم خصيصًا للروايات الطويلة وحبكات IP مع سرد متعدد الشخصيات.",
  "ernie-speed-128k.description": "ERNIE Speed 128K هو نموذج بدون رسوم إدخال/إخراج لفهم النصوص الطويلة والتجارب واسعة النطاق.",
  "ernie-speed-8k.description": "ERNIE Speed 8K هو نموذج مجاني وسريع للدردشة اليومية والمهام النصية الخفيفة.",
  "ernie-speed-pro-128k.description": "ERNIE Speed Pro 128K هو نموذج عالي التوازي وعالي القيمة للخدمات عبر الإنترنت واسعة النطاق وتطبيقات المؤسسات.",
  "ernie-tiny-8k.description": "ERNIE Tiny 8K هو نموذج فائق الخفة للأسئلة البسيطة، والتصنيف، والاستدلال منخفض التكلفة.",
  "ernie-x1-turbo-32k.description": "ERNIE X1 Turbo 32K هو نموذج تفكير سريع بسياق 32K للاستدلال المعقد والدردشة متعددة الأدوار.",
  "ernie-x1.1-preview.description": "معاينة ERNIE X1.1 هو نموذج تفكير مخصص للتقييم والاختبار.",
  "meta.llama3-8b-instruct-v1:0.description": "ميتا لاما 3 هو نموذج لغوي مفتوح المصدر مخصص للمطورين والباحثين والشركات، صُمم لمساعدتهم في بناء أفكار الذكاء الاصطناعي التوليدي، وتجربتها، وتوسيع نطاقها بشكل مسؤول. يُعد جزءًا من البنية التحتية للابتكار المجتمعي العالمي، وهو مناسب للبيئات ذات الموارد المحدودة، والأجهزة الطرفية، وأوقات التدريب الأسرع.",
  "meta/Llama-3.2-11B-Vision-Instruct.description": "قدرات قوية في الاستدلال الصوري على الصور عالية الدقة، مناسب لتطبيقات الفهم البصري.",
  "meta/Llama-3.2-90B-Vision-Instruct.description": "استدلال صوري متقدم لتطبيقات الوكلاء المعتمدين على الفهم البصري.",
  "meta/Llama-3.3-70B-Instruct.description": "لاما 3.3 هو النموذج مفتوح المصدر الأكثر تقدمًا متعدد اللغات، ويقدم أداءً يقارب نماذج 405B بتكلفة منخفضة جدًا. يعتمد على بنية Transformer وتم تحسينه باستخدام SFT وRLHF لتعزيز الفائدة والسلامة. النسخة المضبوطة على التعليمات مثالية للدردشة متعددة اللغات وتتفوّق على العديد من النماذج المفتوحة والمغلقة في معايير الصناعة. تاريخ التحديث المعرفي: ديسمبر 2023.",
  "meta/Meta-Llama-3-70B-Instruct.description": "نموذج قوي يحتوي على 70 مليار معامل، يتميز في الاستدلال، والبرمجة، ومهام اللغة العامة.",
  "meta/Meta-Llama-3-8B-Instruct.description": "نموذج متعدد الاستخدامات يحتوي على 8 مليارات معامل، مُحسّن للدردشة وتوليد النصوص.",
  "meta/Meta-Llama-3.1-405B-Instruct.description": "نموذج لاما 3.1 المضبوط على التعليمات، مُحسّن للدردشة متعددة اللغات، ويؤدي أداءً قويًا في معايير الصناعة بين النماذج المفتوحة والمغلقة.",
  "meta/Meta-Llama-3.1-70B-Instruct.description": "نموذج لاما 3.1 المضبوط على التعليمات، مُحسّن للدردشة متعددة اللغات، ويؤدي أداءً قويًا في معايير الصناعة بين النماذج المفتوحة والمغلقة.",
  "meta/Meta-Llama-3.1-8B-Instruct.description": "نموذج لاما 3.1 المضبوط على التعليمات، مُحسّن للدردشة متعددة اللغات، ويؤدي أداءً قويًا في معايير الصناعة بين النماذج المفتوحة والمغلقة.",
  "meta/llama-3-70b.description": "نموذج مفتوح المصدر يحتوي على 70 مليار معامل، تم ضبطه بواسطة ميتا لمتابعة التعليمات، ويُقدَّم عبر Groq باستخدام عتاد LPU لتوفير استدلال سريع وفعّال.",
  "meta/llama-3-8b.description": "نموذج مفتوح المصدر يحتوي على 8 مليارات معامل، تم ضبطه بواسطة ميتا لمتابعة التعليمات، ويُقدَّم عبر Groq باستخدام عتاد LPU لتوفير استدلال سريع وفعّال.",
  "meta/llama-3.1-405b-instruct.description": "نموذج لغوي متقدم يدعم توليد البيانات الاصطناعية، وتقطير المعرفة، والاستدلال لمهام الدردشة والبرمجة والمجالات المتخصصة.",
  "meta/llama-3.1-70b-instruct.description": "مصمم للحوار المعقد مع فهم ممتاز للسياق، واستدلال، وتوليد نصوص.",
  "meta/llama-3.1-70b.description": "نسخة محدثة من لاما 3 70B Instruct من ميتا، تدعم سياقًا يصل إلى 128 ألف رمز، وتدعم لغات متعددة، مع تحسينات في الاستدلال.",
  "meta/llama-3.1-8b-instruct.description": "نموذج متطور يتمتع بفهم لغوي قوي، واستدلال، وتوليد نصوص.",
  "meta/llama-3.1-8b.description": "لاما 3.1 8B يدعم نافذة سياق تصل إلى 128 ألف رمز، مثالي للدردشة في الوقت الحقيقي وتحليل البيانات، ويوفر توفيرًا كبيرًا في التكلفة مقارنة بالنماذج الأكبر. يُقدَّم عبر Groq باستخدام عتاد LPU لاستدلال سريع وفعّال.",
  "meta/llama-3.2-11b-vision-instruct.description": "نموذج متقدم يجمع بين الرؤية واللغة، يتميز باستدلال عالي الجودة من الصور.",
  "meta/llama-3.2-11b.description": "نموذج استدلال صوري مضبوط على التعليمات (مدخلات نص + صورة، مخرجات نصية) مُحسّن للتعرف البصري، والاستدلال من الصور، والتعليق، والإجابة العامة على الأسئلة المتعلقة بالصور.",
  "meta/llama-3.2-1b-instruct.description": "نموذج لغوي صغير متطور يتمتع بفهم قوي، واستدلال، وتوليد نصوص.",
  "meta/llama-3.2-1b.description": "نموذج نصي فقط للاستخدام على الأجهزة مثل الاسترجاع المحلي متعدد اللغات، والتلخيص، وإعادة الصياغة.",
  "meta/llama-3.2-3b-instruct.description": "نموذج لغوي صغير متطور يتمتع بفهم قوي، واستدلال، وتوليد نصوص.",
  "meta/llama-3.2-3b.description": "نموذج نصي فقط مضبوط للاستخدام على الأجهزة مثل الاسترجاع المحلي متعدد اللغات، والتلخيص، وإعادة الصياغة.",
  "meta/llama-3.2-90b-vision-instruct.description": "نموذج متقدم يجمع بين الرؤية واللغة، يتميز باستدلال عالي الجودة من الصور.",
  "meta/llama-3.2-90b.description": "نموذج استدلال صوري مضبوط على التعليمات (مدخلات نص + صورة، مخرجات نصية) مُحسّن للتعرف البصري، والاستدلال من الصور، والتعليق، والإجابة العامة على الأسئلة المتعلقة بالصور.",
  "meta/llama-3.3-70b-instruct.description": "نموذج لغوي متقدم يتميز في الاستدلال، والرياضيات، والمنطق العام، واستدعاء الوظائف.",
  "meta/llama-3.3-70b.description": "توازن مثالي بين الأداء والكفاءة. مصمم للذكاء الاصطناعي الحواري عالي الأداء في إنشاء المحتوى، وتطبيقات المؤسسات، والبحث، مع فهم لغوي قوي للتلخيص، والتصنيف، وتحليل المشاعر، وتوليد الشيفرة.",
  "meta/llama-4-maverick.description": "عائلة لاما 4 هي مجموعة نماذج ذكاء اصطناعي متعددة الوسائط تدعم النص والتجارب متعددة الوسائط، وتستخدم MoE لفهم متقدم للنصوص والصور. لاما 4 مافريك هو نموذج يحتوي على 17 مليار معامل و128 خبيرًا، يُقدَّم عبر DeepInfra.",
  "meta/llama-4-scout.description": "عائلة لاما 4 هي مجموعة نماذج ذكاء اصطناعي متعددة الوسائط تدعم النص والتجارب متعددة الوسائط، وتستخدم MoE لفهم متقدم للنصوص والصور. لاما 4 سكاوت هو نموذج يحتوي على 17 مليار معامل و16 خبيرًا، يُقدَّم عبر DeepInfra.",
  "moonshot-v1-128k-vision-preview.description": "نماذج Kimi للرؤية (بما في ذلك moonshot-v1-8k-vision-preview/moonshot-v1-32k-vision-preview/moonshot-v1-128k-vision-preview) قادرة على فهم محتوى الصور مثل النصوص، الألوان، وأشكال الكائنات.",
  "moonshot-v1-128k.description": "Moonshot V1 128K يوفر سياقًا طويلًا للغاية لتوليد نصوص طويلة جدًا، حيث يتعامل مع ما يصل إلى 128,000 رمز، مما يجعله مثاليًا للبحث، والأكاديميا، والوثائق الكبيرة.",
  "moonshot-v1-32k-vision-preview.description": "نماذج Kimi للرؤية (بما في ذلك moonshot-v1-8k-vision-preview/moonshot-v1-32k-vision-preview/moonshot-v1-128k-vision-preview) قادرة على فهم محتوى الصور مثل النصوص، الألوان، وأشكال الكائنات.",
  "moonshot-v1-32k.description": "Moonshot V1 32K يدعم 32,768 رمزًا لسياق متوسط الطول، وهو مثالي للوثائق الطويلة والحوارات المعقدة في إنشاء المحتوى، والتقارير، وأنظمة الدردشة.",
  "moonshot-v1-8k-vision-preview.description": "نماذج Kimi للرؤية (بما في ذلك moonshot-v1-8k-vision-preview/moonshot-v1-32k-vision-preview/moonshot-v1-128k-vision-preview) قادرة على فهم محتوى الصور مثل النصوص، الألوان، وأشكال الكائنات.",
  "moonshot-v1-8k.description": "Moonshot V1 8K مُحسّن لتوليد النصوص القصيرة بكفاءة عالية، حيث يتعامل مع 8,192 رمزًا للمحادثات القصيرة، والملاحظات، والمحتوى السريع.",
  "moonshot-v1-auto.description": "Moonshot V1 Auto يختار النموذج المناسب بناءً على استخدام الرموز في السياق الحالي.",
  "moonshotai/Kimi-Dev-72B.description": "Kimi-Dev-72B هو نموذج مفتوح المصدر للبرمجة تم تحسينه باستخدام التعلم المعزز على نطاق واسع لإنتاج تصحيحات قوية وجاهزة للإنتاج. يحقق نسبة 60.4٪ على SWE-bench Verified، مسجلاً رقمًا قياسيًا جديدًا للنماذج المفتوحة في مهام هندسة البرمجيات الآلية مثل إصلاح الأخطاء ومراجعة الشيفرة.",
  "moonshotai/Kimi-K2-Instruct-0905.description": "Kimi K2-Instruct-0905 هو أحدث وأقوى إصدار من Kimi K2. إنه نموذج MoE من الدرجة الأولى يحتوي على تريليون معلمة إجمالية و32 مليار معلمة نشطة. من أبرز ميزاته الذكاء البرمجي القوي، وتحسينات كبيرة في اختبارات الأداء والمهام الواقعية، بالإضافة إلى تحسينات في جمالية واجهات الاستخدام وسهولة البرمجة الأمامية.",
  "moonshotai/Kimi-K2-Thinking.description": "Kimi K2 Thinking هو أحدث وأقوى نموذج تفكير مفتوح المصدر. يعزز بشكل كبير عمق التفكير متعدد الخطوات ويحافظ على استخدام الأدوات بثبات عبر 200–300 استدعاء متتالي، محققًا أرقامًا قياسية جديدة في Humanity's Last Exam (HLE)، وBrowseComp، وغيرها من المعايير. يتفوق في البرمجة، والرياضيات، والمنطق، وسيناريوهات الوكلاء. مبني على بنية MoE بحوالي تريليون معلمة إجمالية، ويدعم نافذة سياق بحجم 256K واستدعاء الأدوات.",
  "moonshotai/kimi-k2-0711.description": "Kimi K2 0711 هو إصدار موجه من سلسلة Kimi، مناسب للبرمجة عالية الجودة واستخدام الأدوات.",
  "moonshotai/kimi-k2-0905.description": "Kimi K2 0905 هو تحديث يعزز أداء السياق والتفكير مع تحسينات في البرمجة.",
  "moonshotai/kimi-k2-instruct-0905.description": "نموذج kimi-k2-0905-preview يدعم نافذة سياق بحجم 256K، مع برمجة وكيلة أقوى، وشيفرة أمامية أكثر صقلًا وعملية، وفهم أفضل للسياق.",
  "moonshotai/kimi-k2-thinking-turbo.description": "Kimi K2 Thinking Turbo هو إصدار عالي السرعة من Kimi K2 Thinking، يقلل بشكل كبير من زمن الاستجابة مع الحفاظ على عمق التفكير.",
  "moonshotai/kimi-k2-thinking.description": "Kimi K2 Thinking هو نموذج التفكير من Moonshot، مُحسّن لمهام التفكير العميق، مع قدرات عامة كوكلاء.",
  "moonshotai/kimi-k2.description": "Kimi K2 هو نموذج MoE كبير من Moonshot AI يحتوي على تريليون معلمة إجمالية و32 مليار معلمة نشطة لكل تمرير أمامي، مُحسّن لقدرات الوكلاء بما في ذلك استخدام الأدوات المتقدمة، والتفكير، وتوليد الشيفرة.",
  "morph/morph-v3-fast.description": "Morph يقدم نموذجًا متخصصًا لتطبيق تغييرات الشيفرة المقترحة من نماذج متقدمة (مثل Claude أو GPT-4o) على ملفاتك الحالية بسرعة تزيد عن 4500 رمز/ثانية. يُعد الخطوة الأخيرة في سير عمل البرمجة بالذكاء الاصطناعي ويدعم 16k من رموز الإدخال/الإخراج.",
  "morph/morph-v3-large.description": "Morph يقدم نموذجًا متخصصًا لتطبيق تغييرات الشيفرة المقترحة من نماذج متقدمة (مثل Claude أو GPT-4o) على ملفاتك الحالية بسرعة تزيد عن 2500 رمز/ثانية. يُعد الخطوة الأخيرة في سير عمل البرمجة بالذكاء الاصطناعي ويدعم 16k من رموز الإدخال/الإخراج.",
  "nousresearch/hermes-2-pro-llama-3-8b.description": "Hermes 2 Pro Llama 3 8B هو إصدار محدث من Nous Hermes 2 باستخدام أحدث مجموعات البيانات المطورة داخليًا.",
  "nvidia/Llama-3.1-Nemotron-70B-Instruct-HF.description": "Llama 3.1 Nemotron 70B هو نموذج LLM مخصص من NVIDIA لتحسين الفائدة. يحقق أداءً قويًا في Arena Hard وAlpacaEval 2 LC وGPT-4-Turbo MT-Bench، ويحتل المرتبة الأولى في جميع معايير المحاذاة التلقائية الثلاثة حتى 1 أكتوبر 2024. تم تدريبه من Llama-3.1-70B-Instruct باستخدام RLHF (REINFORCE)، وLlama-3.1-Nemotron-70B-Reward، ومطالبات HelpSteer2-Preference.",
  "nvidia/llama-3.1-nemotron-51b-instruct.description": "نموذج لغوي مميز يقدم دقة وكفاءة استثنائية.",
  "nvidia/llama-3.1-nemotron-70b-instruct.description": "Llama-3.1-Nemotron-70B-Instruct هو نموذج مخصص من NVIDIA مصمم لتحسين فائدة استجابات LLM.",
  "o1-mini.description": "أصغر وأسرع من o1-preview، بتكلفة أقل بنسبة 80٪، قوي في توليد الشيفرة والمهام ذات السياق القصير.",
  "o1-preview.description": "يركز على التفكير المتقدم وحل المشكلات المعقدة، بما في ذلك الرياضيات والعلوم. مثالي للتطبيقات التي تتطلب فهمًا عميقًا للسياق وسير عمل مستقل.",
  "o1-pro.description": "تم تدريب سلسلة o1 باستخدام التعلم المعزز للتفكير قبل الإجابة والتعامل مع التفكير المعقد. يستخدم o1-pro موارد حسابية أكبر للتفكير الأعمق وتقديم إجابات عالية الجودة باستمرار.",
  "o1.description": "o1 هو نموذج التفكير الجديد من OpenAI بمدخلات نصية وصورية ومخرجات نصية، مناسب للمهام المعقدة التي تتطلب معرفة واسعة. يحتوي على نافذة سياق بحجم 200K وتاريخ معرفة حتى أكتوبر 2023.",
  "o3-2025-04-16.description": "o3 هو نموذج التفكير الجديد من OpenAI بمدخلات نصية وصورية ومخرجات نصية للمهام المعقدة التي تتطلب معرفة واسعة.",
  "o3-deep-research.description": "o3-deep-research هو نموذجنا الأكثر تقدمًا للبحث العميق في المهام متعددة الخطوات المعقدة. يمكنه البحث في الويب والوصول إلى بياناتك عبر موصلات MCP.",
  "o3-mini.description": "o3-mini هو أحدث نموذج تفكير صغير لدينا، يقدم ذكاءً أعلى بنفس التكلفة وزمن الاستجابة المستهدف مثل o1-mini.",
  "o3-pro-2025-06-10.description": "o3 Pro هو نموذج التفكير الجديد من OpenAI بمدخلات نصية وصورية ومخرجات نصية للمهام المعقدة التي تتطلب معرفة واسعة.",
  "o3-pro.description": "o3-pro يستخدم موارد حسابية أكبر للتفكير الأعمق وتقديم إجابات أفضل باستمرار؛ متاح فقط عبر واجهة Responses API.",
  "o3.description": "o3 هو نموذج شامل قوي يضع معيارًا جديدًا في الرياضيات، والعلوم، والبرمجة، والتفكير البصري. يتفوق في الكتابة التقنية واتباع التعليمات، ويمكنه تحليل النصوص، والشيفرة، والصور لحل المشكلات متعددة الخطوات.",
  "o4-mini-2025-04-16.description": "o4-mini هو نموذج تفكير من OpenAI بمدخلات نصية وصورية ومخرجات نصية، مناسب للمهام المعقدة التي تتطلب معرفة واسعة، مع نافذة سياق بحجم 200K.",
  "o4-mini-deep-research.description": "o4-mini-deep-research هو نموذج بحث عميق أسرع وأكثر توفيرًا للمهام البحثية متعددة الخطوات المعقدة. يمكنه البحث في الويب والوصول إلى بياناتك عبر موصلات MCP.",
  "o4-mini.description": "o4-mini هو أحدث نموذج صغير من سلسلة o، مُحسّن للتفكير السريع والفعال مع كفاءة عالية في مهام البرمجة والرؤية.",
  "qianfan-vl-70b.description": "Qianfan VL 70B هو نموذج لغة بصري كبير لفهم معقد للنصوص والصور.",
  "qianfan-vl-8b.description": "Qianfan VL 8B هو نموذج لغة بصري خفيف الوزن مخصص للإجابة اليومية على الأسئلة وتحليل الصور والنصوص.",
  "qvq-72b-preview.description": "QVQ-72B-Preview هو نموذج بحث تجريبي من Qwen يركز على تحسين الاستدلال البصري.",
  "qvq-max.description": "نموذج الاستدلال البصري Qwen QVQ يدعم إدخال الصور وإخراج سلسلة التفكير، ويتميز بأداء قوي في الرياضيات، البرمجة، التحليل البصري، الإبداع، والمهام العامة.",
  "qvq-plus.description": "نموذج استدلال بصري يدعم إدخال الصور وإخراج سلسلة التفكير. سلسلة qvq-plus تتبع qvq-max وتوفر استدلالًا أسرع مع توازن أفضل بين الجودة والتكلفة.",
  "qwen-3-32b.description": "Qwen 3 32B: قوي في المهام متعددة اللغات والبرمجة، مناسب للاستخدام الإنتاجي متوسط النطاق.",
  "qwen-coder-plus.description": "نموذج Qwen للبرمجة.",
  "qwen-coder-turbo-latest.description": "نموذج Qwen للبرمجة.",
  "qwen-coder-turbo.description": "نموذج Qwen للبرمجة.",
  "qwen-flash.description": "أسرع وأقل نماذج Qwen تكلفة، مثالي للمهام البسيطة.",
  "qwen-image-edit.description": "Qwen Image Edit هو نموذج تحويل صورة إلى صورة يقوم بتحرير الصور بناءً على صور الإدخال والتعليمات النصية، مما يتيح تعديلات دقيقة وتحولات إبداعية.",
  "qwen-image.description": "Qwen-Image هو نموذج عام لتوليد الصور يدعم أنماط فنية متعددة وعرض نصوص معقدة، خاصة باللغتين الصينية والإنجليزية. يدعم تخطيطات متعددة الأسطر، نصوص على مستوى الفقرة، وتفاصيل دقيقة لتخطيطات النصوص والصور المعقدة.",
  "qwen-long.description": "نموذج Qwen فائق الحجم يدعم السياقات الطويلة والدردشة عبر سيناريوهات متعددة الوثائق.",
  "qwen-math-plus-latest.description": "Qwen Math هو نموذج لغوي متخصص في حل المسائل الرياضية.",
  "qwen-math-plus.description": "Qwen Math هو نموذج لغوي متخصص في حل المسائل الرياضية.",
  "qwen-math-turbo-latest.description": "Qwen Math هو نموذج لغوي متخصص في حل المسائل الرياضية.",
  "qwen-math-turbo.description": "Qwen Math هو نموذج لغوي متخصص في حل المسائل الرياضية.",
  "qwen-max.description": "نموذج Qwen فائق الحجم بمئات المليارات من المعاملات يدعم الصينية، الإنجليزية، ولغات أخرى؛ النموذج المستخدم في واجهات برمجة تطبيقات Qwen2.5 الحالية.",
  "qwen-omni-turbo.description": "نماذج Qwen-Omni تدعم مدخلات متعددة الوسائط (فيديو، صوت، صور، نص) وتنتج مخرجات صوتية ونصية.",
  "qwen-plus.description": "نموذج Qwen فائق الحجم ومحسن يدعم الصينية، الإنجليزية، ولغات أخرى.",
  "qwen-turbo.description": "لن يتم تحديث Qwen Turbo بعد الآن؛ يُنصح باستخدام Qwen Flash بدلاً منه. نموذج Qwen فائق الحجم يدعم الصينية، الإنجليزية، ولغات أخرى.",
  "qwen-vl-chat-v1.description": "يدعم Qwen VL تفاعلات مرنة تشمل إدخال صور متعددة، أسئلة وأجوبة متعددة الجولات، ومهام إبداعية.",
  "qwen-vl-max-latest.description": "نموذج Qwen فائق الحجم للغة والرؤية. مقارنة بالإصدار المحسن، يعزز الاستدلال البصري واتباع التعليمات لتحقيق إدراك وفهم أقوى.",
  "qwen-vl-max.description": "نموذج Qwen فائق الحجم للغة والرؤية. مقارنة بالإصدار المحسن، يعزز الاستدلال البصري واتباع التعليمات لتحقيق إدراك بصري وفهم أقوى.",
  "qwen-vl-ocr.description": "Qwen OCR هو نموذج لاستخراج النصوص من المستندات، الجداول، صور الامتحانات، والكتابة اليدوية. يدعم الصينية، الإنجليزية، الفرنسية، اليابانية، الكورية، الألمانية، الروسية، الإيطالية، الفيتنامية، والعربية.",
  "qwen-vl-plus-latest.description": "نموذج Qwen المحسن للغة والرؤية على نطاق واسع مع تحسينات كبيرة في التفاصيل والتعرف على النصوص، يدعم دقة تتجاوز الميجابيكسل ونسب أبعاد عشوائية.",
  "qwen-vl-plus.description": "نموذج Qwen المحسن للغة والرؤية على نطاق واسع مع تحسينات كبيرة في التفاصيل والتعرف على النصوص، يدعم دقة تتجاوز الميجابيكسل ونسب أبعاد عشوائية.",
  "qwen-vl-v1.description": "نموذج مدرب مسبقًا مستند إلى Qwen-7B مع وحدة رؤية مضافة ودقة إدخال صور 448.",
  "qwen/qwen-2-7b-instruct.description": "Qwen2 هي سلسلة نماذج اللغة الكبيرة الجديدة من Qwen. Qwen2 7B هو نموذج قائم على المحولات يتميز بفهم لغوي قوي، وقدرات متعددة اللغات، والبرمجة، والرياضيات، والاستدلال.",
  "qwen/qwen-2-7b-instruct:free.description": "Qwen2 هي عائلة جديدة من نماذج اللغة الكبيرة تتميز بفهم وتوليد أقوى.",
  "qwen/qwen-2-vl-72b-instruct.description": "Qwen2-VL هو أحدث إصدار من Qwen-VL، يحقق أداءً رائدًا في معايير الرؤية مثل MathVista وDocVQA وRealWorldQA وMTVQA. يمكنه فهم أكثر من 20 دقيقة من الفيديو للإجابة على الأسئلة، الحوار، وإنشاء المحتوى بجودة عالية. كما يتعامل مع الاستدلال المعقد واتخاذ القرار، ويتكامل مع الأجهزة المحمولة والروبوتات للتصرف بناءً على السياق البصري والتعليمات النصية. بالإضافة إلى الإنجليزية والصينية، يقرأ النصوص في الصور بلغات متعددة، منها معظم اللغات الأوروبية، اليابانية، الكورية، العربية، والفيتنامية.",
  "qwen/qwen-2.5-72b-instruct.description": "Qwen2.5-72B-Instruct هو أحد أحدث إصدارات نماذج اللغة الكبيرة من Alibaba Cloud. يقدم هذا النموذج تحسينات ملحوظة في البرمجة والرياضيات، ويدعم أكثر من 29 لغة (بما في ذلك الصينية والإنجليزية)، ويعزز بشكل كبير اتباع التعليمات، وفهم البيانات المنظمة، والإخراج المنظم (خاصة JSON).",
  "qwen/qwen2.5-32b-instruct.description": "Qwen2.5-32B-Instruct هو أحد أحدث إصدارات نماذج اللغة الكبيرة من Alibaba Cloud. يقدم هذا النموذج تحسينات ملحوظة في البرمجة والرياضيات، ويدعم أكثر من 29 لغة (بما في ذلك الصينية والإنجليزية)، ويعزز بشكل كبير اتباع التعليمات، وفهم البيانات المنظمة، والإخراج المنظم (خاصة JSON).",
  "qwen/qwen2.5-7b-instruct.description": "نموذج لغة كبير ثنائي اللغة للصينية والإنجليزية يغطي اللغة، البرمجة، الرياضيات، والاستدلال.",
  "qwen/qwen2.5-coder-32b-instruct.description": "نموذج متقدم لتوليد الشيفرة، الاستدلال، والإصلاح عبر لغات البرمجة الشائعة.",
  "qwen/qwen2.5-coder-7b-instruct.description": "نموذج برمجة متوسط الحجم قوي مع سياق 32K، يتميز بالبرمجة متعددة اللغات.",
  "qwen/qwen3-14b.description": "Qwen3-14B هو إصدار 14B مخصص للاستدلال العام وسيناريوهات الدردشة.",
  "qwen/qwen3-14b:free.description": "Qwen3-14B هو نموذج سببي كثيف يحتوي على 14.8 مليار معلمة، مصمم للاستدلال المعقد والدردشة الفعالة. يتنقل بين وضع التفكير للرياضيات، البرمجة، والمنطق، ووضع غير التفكير للدردشة العامة. تم تحسينه لاتباع التعليمات، استخدام أدوات الوكلاء، والكتابة الإبداعية بأكثر من 100 لغة ولهجة. يدعم سياق 32K أصليًا ويتوسع إلى 131K باستخدام YaRN.",
  "qwen/qwen3-235b-a22b-2507.description": "Qwen3-235B-A22B-Instruct-2507 هو إصدار Instruct من سلسلة Qwen3، يوازن بين استخدام التعليمات متعددة اللغات وسيناريوهات السياق الطويل.",
  "qwen2:1.5b.description": "Qwen2 هو نموذج اللغة الكبير من الجيل التالي من Alibaba، يتميز بأداء قوي في مجموعة متنوعة من الاستخدامات.",
  "qwen2:72b.description": "Qwen2 هو نموذج اللغة الكبير من الجيل التالي من Alibaba، يتميز بأداء قوي في مجموعة متنوعة من الاستخدامات.",
  "qwen3-0.6b.description": "Qwen3 0.6B هو نموذج مبدئي مخصص للاستدلال البسيط والبيئات المحدودة للغاية.",
  "qwen3-1.7b.description": "Qwen3 1.7B هو نموذج فائق الخفة مصمم للنشر على الأجهزة الطرفية.",
  "qwen3-14b.description": "Qwen3 14B هو نموذج متوسط الحجم مخصص للإجابة متعددة اللغات وتوليد النصوص.",
  "qwen3-235b-a22b-instruct-2507.description": "Qwen3 235B A22B Instruct 2507 هو نموذج إرشادي رائد لمجموعة واسعة من مهام التوليد والاستدلال.",
  "qwen3-235b-a22b-thinking-2507.description": "Qwen3 235B A22B Thinking 2507 هو نموذج تفكير فائق الحجم مخصص للاستدلال المعقد.",
  "qwen3-235b-a22b.description": "Qwen3 235B A22B هو نموذج عام كبير مخصص للمهام المعقدة.",
  "qwen3-30b-a3b-instruct-2507.description": "Qwen3 30B A3B Instruct 2507 هو نموذج إرشادي متوسط إلى كبير مخصص لتوليد عالي الجودة والإجابة على الأسئلة.",
  "qwen3-30b-a3b-thinking-2507.description": "Qwen3 30B A3B Thinking 2507 هو نموذج تفكير متوسط إلى كبير يوازن بين الدقة والتكلفة.",
  "qwen3-30b-a3b.description": "Qwen3 30B A3B هو نموذج عام متوسط إلى كبير يوازن بين الجودة والتكلفة.",
  "qwen3-32b.description": "Qwen3 32B مناسب للمهام العامة التي تتطلب فهماً أعمق.",
  "qwen3-4b.description": "Qwen3 4B مناسب للتطبيقات الصغيرة إلى المتوسطة والاستدلال المحلي.",
  "qwen3-8b.description": "Qwen3 8B هو نموذج خفيف الوزن يتميز بنشر مرن للتعامل مع أعباء العمل عالية التوازي.",
  "qwen3-coder-30b-a3b-instruct.description": "نموذج Qwen مفتوح المصدر للبرمجة. الإصدار الأحدث qwen3-coder-30b-a3b-instruct مبني على Qwen3 ويقدم قدرات قوية كوكلاء برمجة، واستخدام الأدوات، والتفاعل مع البيئة للبرمجة الذاتية، مع أداء ممتاز في البرمجة وقدرات عامة قوية.",
  "qwen3-coder-480b-a35b-instruct.description": "Qwen3 Coder 480B A35B Instruct هو نموذج برمجة رائد مخصص للبرمجة متعددة اللغات وفهم الكود المعقد.",
  "qwen3-coder-flash.description": "نموذج Qwen للبرمجة. سلسلة Qwen3-Coder الأحدث مبنية على Qwen3 وتوفر قدرات قوية كوكلاء برمجة، واستخدام الأدوات، والتفاعل مع البيئة للبرمجة الذاتية، مع أداء ممتاز في البرمجة وقدرات عامة قوية.",
  "qwen3-coder-plus.description": "نموذج Qwen للبرمجة. سلسلة Qwen3-Coder الأحدث مبنية على Qwen3 وتوفر قدرات قوية كوكلاء برمجة، واستخدام الأدوات، والتفاعل مع البيئة للبرمجة الذاتية، مع أداء ممتاز في البرمجة وقدرات عامة قوية.",
  "qwen3-coder:480b.description": "نموذج عالي الأداء من Alibaba لمعالجة المهام المتعلقة بالوكلاء والبرمجة مع دعم لسياقات طويلة.",
  "qwen3-max-preview.description": "أفضل نموذج Qwen للأداء في المهام المعقدة متعددة الخطوات. المعاينة تدعم التفكير.",
  "qwen3-max.description": "نماذج Qwen3 Max تقدم تحسينات كبيرة مقارنة بسلسلة 2.5 في القدرات العامة، وفهم اللغة الصينية/الإنجليزية، واتباع التعليمات المعقدة، والمهام المفتوحة الذاتية، والقدرات متعددة اللغات، واستخدام الأدوات، مع تقليل الهلوسة. الإصدار الأحدث qwen3-max يعزز البرمجة الوكيلة واستخدام الأدوات مقارنة بـ qwen3-max-preview. هذا الإصدار يحقق أداءً رائداً في المجال ويستهدف احتياجات الوكلاء المعقدة.",
  "qwen3-next-80b-a3b-instruct.description": "نموذج Qwen3 من الجيل التالي مفتوح المصدر غير مخصص للتفكير. مقارنة بالإصدار السابق (Qwen3-235B-A22B-Instruct-2507)، يتميز بفهم أفضل للغة الصينية، واستدلال منطقي أقوى، وتحسين في توليد النصوص.",
  "qwen3-next-80b-a3b-thinking.description": "Qwen3 Next 80B A3B Thinking هو إصدار رائد من نماذج التفكير مخصص للمهام المعقدة.",
  "qwen3-omni-flash.description": "Qwen-Omni يقبل مدخلات متعددة تشمل النصوص، الصور، الصوت، والفيديو، ويُنتج نصاً أو كلاماً. يوفر أنماط صوت طبيعية متعددة، ويدعم الكلام بلغات ولهجات متعددة، ومناسب لحالات استخدام مثل الكتابة، والتعرف البصري، والمساعدات الصوتية.",
  "qwen3-vl-235b-a22b-instruct.description": "Qwen3 VL 235B A22B Instruct هو نموذج متعدد الوسائط رائد مخصص للفهم والإبداع المتقدم.",
  "qwen3-vl-235b-a22b-thinking.description": "Qwen3 VL 235B A22B Thinking هو الإصدار الرائد للتفكير في المهام متعددة الوسائط المعقدة والتخطيط.",
  "qwen3-vl-30b-a3b-instruct.description": "Qwen3 VL 30B A3B Instruct هو نموذج متعدد الوسائط كبير يوازن بين الدقة وأداء الاستدلال.",
  "qwen3-vl-30b-a3b-thinking.description": "Qwen3 VL 30B A3B Thinking هو إصدار تفكير عميق مخصص للمهام متعددة الوسائط المعقدة.",
  "qwen3-vl-32b-instruct.description": "Qwen3 VL 32B Instruct هو نموذج متعدد الوسائط مضبوط على التعليمات مخصص للإجابة على الأسئلة وإنشاء المحتوى بجودة عالية من الصور والنصوص.",
  "qwen3-vl-32b-thinking.description": "Qwen3 VL 32B Thinking هو إصدار تفكير متعدد الوسائط مخصص للاستدلال المعقد والتحليل المتسلسل الطويل.",
  "qwen3-vl-8b-instruct.description": "Qwen3 VL 8B Instruct هو نموذج متعدد الوسائط خفيف الوزن مخصص للإجابة البصرية اليومية ودمج التطبيقات.",
  "qwen3-vl-8b-thinking.description": "Qwen3 VL 8B Thinking هو نموذج تفكير متعدد الوسائط مخصص للاستدلال البصري التفصيلي.",
  "qwen3-vl-flash.description": "Qwen3 VL Flash: إصدار خفيف وسريع للاستدلال مخصص للطلبات الحساسة للزمن أو ذات الحجم الكبير.",
  "qwen3-vl-plus.description": "Qwen VL هو نموذج توليد نصوص مع فهم بصري. يمكنه تنفيذ OCR، والتلخيص، والاستدلال، مثل استخراج السمات من صور المنتجات أو حل المشكلات من الصور.",
  "qwen3.description": "Qwen3 هو نموذج اللغة الكبير من الجيل التالي من Alibaba، يتميز بأداء قوي في مجموعة متنوعة من الاستخدامات.",
  "qwq-32b-preview.description": "QwQ هو نموذج بحث تجريبي من Qwen يركز على تحسين الاستدلال.",
  "qwq-32b.description": "QwQ هو نموذج استدلال من عائلة Qwen. مقارنة بالنماذج المضبوطة على التعليمات، يقدم تفكيراً واستدلالاً يعزز الأداء بشكل كبير، خاصة في المشكلات المعقدة. QwQ-32B هو نموذج متوسط الحجم ينافس أفضل نماذج الاستدلال مثل DeepSeek-R1 و o1-mini.",
  "qwq-plus.description": "نموذج الاستدلال QwQ المدرب على Qwen2.5 يستخدم التعلم المعزز لتحسين الاستدلال بشكل كبير. يحقق نتائج رائدة في الرياضيات/البرمجة (AIME 24/25، LiveCodeBench) وبعض المعايير العامة (IFEval، LiveBench) بمستوى DeepSeek-R1 الكامل.",
  "qwq.description": "QwQ هو نموذج استدلال من عائلة Qwen. مقارنة بالنماذج المضبوطة على التعليمات، يقدم قدرات تفكير واستدلال تعزز الأداء بشكل كبير، خاصة في المشكلات الصعبة. QwQ-32B هو نموذج متوسط الحجم ينافس أفضل نماذج الاستدلال مثل DeepSeek-R1 و o1-mini.",
  "qwq_32b.description": "نموذج استدلال متوسط الحجم من عائلة Qwen. مقارنة بالنماذج المضبوطة على التعليمات، تعزز قدرات التفكير والاستدلال في QwQ الأداء بشكل كبير، خاصة في المشكلات الصعبة.",
  "r1-1776.description": "R1-1776 هو إصدار ما بعد التدريب من DeepSeek R1 مصمم لتقديم معلومات واقعية غير خاضعة للرقابة أو التحيز.",
  "solar-mini-ja.description": "Solar Mini (Ja) يوسع Solar Mini مع تركيز على اللغة اليابانية مع الحفاظ على الأداء القوي والكفاءة في الإنجليزية والكورية.",
  "solar-mini.description": "Solar Mini هو نموذج لغة مدمج يتفوق على GPT-3.5، يتميز بقدرات متعددة اللغات قوية تدعم الإنجليزية والكورية، ويقدم حلاً فعالاً بصمة صغيرة.",
  "solar-pro.description": "Solar Pro هو نموذج لغة عالي الذكاء من Upstage، يركز على اتباع التعليمات باستخدام وحدة معالجة رسومات واحدة، مع درجات IFEval تتجاوز 80. حالياً يدعم اللغة الإنجليزية؛ وكان من المقرر إصدار النسخة الكاملة في نوفمبر 2024 مع دعم لغات موسع وسياق أطول.",
  "sonar-deep-research.description": "Deep Research يجري أبحاثاً شاملة على مستوى الخبراء ويحولها إلى تقارير قابلة للفهم والتنفيذ.",
  "sonar-pro.description": "منتج بحث متقدم يعتمد على البحث الموجه لفهم الاستفسارات المعقدة والمتابعة.",
  "sonar-reasoning-pro.description": "منتج بحث متقدم يعتمد على البحث الموجه لفهم الاستفسارات المعقدة والمتابعة.",
  "sonar-reasoning.description": "منتج بحث متقدم يعتمد على البحث الموجه لفهم الاستفسارات المعقدة والمتابعة.",
  "sonar.description": "منتج بحث خفيف الوزن يعتمد على البحث الموجه، أسرع وأقل تكلفة من Sonar Pro.",
  "spark-x.description": "تحديثات X1.5: (1) إضافة وضع التفكير الديناميكي يتم التحكم به عبر الحقل `thinking`؛ (2) طول سياق أكبر مع 64K إدخال و64K إخراج؛ (3) دعم FunctionCall.",
  "thudm/glm-z1-rumination-32b.description": "GLM Z1 Rumination 32B هو نموذج تفكير عميق بسعة 32 مليار في سلسلة GLM-4-Z1، مُحسّن للمهام المعقدة المفتوحة التي تتطلب تفكيرًا طويل الأمد. مبني على glm-4-32b-0414، ويضيف مراحل تعزيز التعلم (RL) إضافية ومحاذاة متعددة المراحل، مما يقدّم قدرة \"التأمل\" التي تحاكي المعالجة المعرفية الممتدة. يشمل ذلك التفكير التكراري، والتحليل متعدد الخطوات، وسير العمل المدعوم بالأدوات مثل البحث، والاسترجاع، والتوليف المدرك للاستشهادات.\n\nيتفوّق في كتابة الأبحاث، والتحليل المقارن، والأسئلة المعقدة. يدعم استدعاء الوظائف لأساسيات البحث/التنقل (`search`، `click`، `open`، `finish`) في خطوط أنابيب الوكلاء. يتم التحكم في سلوك التأمل من خلال حلقات متعددة الجولات مع تشكيل مكافآت قائم على القواعد وآليات اتخاذ القرار المؤجل، وتمت معايرته مقابل أطر البحث العميق مثل نظام المحاذاة الداخلي لـ OpenAI. هذا الإصدار يركّز على العمق بدلاً من السرعة.",
  "tngtech/deepseek-r1t-chimera:free.description": "تم إنشاء DeepSeek-R1T-Chimera من خلال دمج DeepSeek-R1 و DeepSeek-V3 (0324)، حيث يجمع بين قدرات التفكير في R1 وكفاءة الرموز في V3. يعتمد على محول DeepSeek-MoE وتم تحسينه لتوليد النصوص العامة.\n\nيُدمج الأوزان المدربة مسبقًا لتحقيق توازن بين التفكير والكفاءة واتباع التعليمات. تم إصداره بموجب ترخيص MIT للاستخدام البحثي والتجاري.",
  "togethercomputer/StripedHyena-Nous-7B.description": "يوفّر StripedHyena Nous (7B) كفاءة حوسبة محسّنة من خلال بنيته واستراتيجيته.",
  "tts-1-hd.description": "أحدث نموذج تحويل النص إلى كلام، مُحسّن للجودة.",
  "tts-1.description": "أحدث نموذج تحويل النص إلى كلام، مُحسّن للسرعة في الوقت الحقيقي.",
  "upstage/SOLAR-10.7B-Instruct-v1.0.description": "تم ضبط Upstage SOLAR Instruct v1 (11B) بدقة لتنفيذ المهام التوجيهية مع أداء لغوي قوي.",
  "us.anthropic.claude-3-5-sonnet-20241022-v2:0.description": "Claude 3.5 Sonnet يرفع المعيار الصناعي، متفوقًا على المنافسين وClaude 3 Opus في تقييمات شاملة مع الحفاظ على سرعة وتكلفة متوسطة.",
  "us.anthropic.claude-3-7-sonnet-20250219-v1:0.description": "Claude 3.7 Sonnet هو أسرع نموذج من الجيل التالي لشركة Anthropic. مقارنة بـ Claude 3 Haiku، يُظهر تحسينات في المهارات ويتفوق على النموذج الرائد السابق Claude 3 Opus في العديد من اختبارات الذكاء.",
  "us.anthropic.claude-haiku-4-5-20251001-v1:0.description": "Claude Haiku 4.5 هو أسرع وأكثر نماذج Haiku ذكاءً من Anthropic، يتميز بسرعة فائقة وقدرة على التفكير الممتد.",
  "us.anthropic.claude-sonnet-4-5-20250929-v1:0.description": "Claude Sonnet 4.5 هو النموذج الأكثر ذكاءً من Anthropic حتى الآن.",
  "v0-1.0-md.description": "v0-1.0-md هو نموذج قديم يتم تقديمه عبر واجهة برمجة التطبيقات v0.",
  "v0-1.5-lg.description": "v0-1.5-lg مناسب للمهام المتقدمة التي تتطلب تفكيرًا أو استدلالًا.",
  "v0-1.5-md.description": "v0-1.5-md مناسب للمهام اليومية وتوليد واجهات المستخدم.",
  "vercel/v0-1.0-md.description": "الوصول إلى النماذج التي تقف خلف v0 لتوليد، وتصحيح، وتحسين تطبيقات الويب الحديثة باستخدام استدلال خاص بالأطر ومعرفة محدثة.",
  "vercel/v0-1.5-md.description": "الوصول إلى النماذج التي تقف خلف v0 لتوليد، وتصحيح، وتحسين تطبيقات الويب الحديثة باستخدام استدلال خاص بالأطر ومعرفة محدثة.",
  "volcengine/doubao-seed-code.description": "Doubao-Seed-Code هو نموذج لغة كبير من محرك ByteDance Volcano، مُحسّن للبرمجة الذاتية، ويؤدي أداءً قويًا في اختبارات البرمجة والوكلاء مع دعم سياق يصل إلى 256 ألف.",
  "wan2.2-t2i-flash.description": "Wanxiang 2.2 Speed هو أحدث نموذج يتميز بتحسينات في الإبداع، والثبات، والواقعية، ويوفر توليدًا سريعًا وقيمة عالية.",
  "wan2.2-t2i-plus.description": "Wanxiang 2.2 Pro هو أحدث نموذج يتميز بتحسينات في الإبداع، والثبات، والواقعية، ويُنتج تفاصيل أغنى.",
  "wanx-v1.description": "نموذج تحويل النص إلى صورة الأساسي. يُقابل Tongyi Wanxiang 1.0 General.",
  "wanx2.0-t2i-turbo.description": "يتفوّق في الصور الشخصية الملمّسة بسرعة معتدلة وتكلفة منخفضة. يُقابل Tongyi Wanxiang 2.0 Speed.",
  "wanx2.1-t2i-plus.description": "إصدار مطوّر بالكامل مع تفاصيل صور أغنى وسرعة أبطأ قليلاً. يُقابل Tongyi Wanxiang 2.1 Pro.",
  "wanx2.1-t2i-turbo.description": "إصدار مطوّر بالكامل مع توليد سريع وجودة شاملة قوية وقيمة عالية. يُقابل Tongyi Wanxiang 2.1 Speed.",
  "whisper-1.description": "نموذج عام للتعرف على الكلام يدعم التعرف على الكلام متعدد اللغات، وترجمة الكلام، وتحديد اللغة.",
  "wizardlm2.description": "WizardLM 2 هو نموذج لغوي من Microsoft AI يتفوّق في الحوارات المعقدة، والمهام متعددة اللغات، والاستدلال، والمساعدات الذكية.",
  "wizardlm2:8x22b.description": "WizardLM 2 هو نموذج لغوي من Microsoft AI يتفوّق في الحوارات المعقدة، والمهام متعددة اللغات، والاستدلال، والمساعدات الذكية.",
  "x-ai/grok-4-fast-non-reasoning.description": "Grok 4 Fast (بدون استدلال) هو نموذج متعدد الوسائط عالي الإنتاجية ومنخفض التكلفة من xAI (يدعم نافذة سياق 2 مليون) مخصص للسيناريوهات الحساسة للزمن والتكلفة التي لا تتطلب استدلالًا داخليًا. يتوفر بجانب إصدار الاستدلال من Grok 4 Fast، ويمكن تفعيل الاستدلال عبر معلمة API عند الحاجة. قد تُستخدم المطالبات والإجابات من قبل xAI أو OpenRouter لتحسين النماذج المستقبلية.",
  "x-ai/grok-4-fast.description": "Grok 4 Fast هو نموذج عالي الإنتاجية ومنخفض التكلفة من xAI (يدعم نافذة سياق 2 مليون)، مثالي لحالات الاستخدام ذات التزامن العالي والسياق الطويل.",
  "x-ai/grok-4.1-fast-non-reasoning.description": "Grok 4.1 Fast (بدون استدلال) هو نموذج متعدد الوسائط عالي الإنتاجية ومنخفض التكلفة من xAI (يدعم نافذة سياق 2 مليون) مخصص للسيناريوهات الحساسة للزمن والتكلفة التي لا تتطلب استدلالًا داخليًا. يتوفر بجانب إصدار الاستدلال من Grok 4.1 Fast، ويمكن تفعيل الاستدلال عبر معلمة API عند الحاجة. قد تُستخدم المطالبات والإجابات من قبل xAI أو OpenRouter لتحسين النماذج المستقبلية.",
  "x-ai/grok-4.1-fast.description": "Grok 4.1 Fast هو نموذج عالي الإنتاجية ومنخفض التكلفة من xAI (يدعم نافذة سياق 2 مليون)، مثالي لحالات الاستخدام ذات التزامن العالي والسياق الطويل.",
  "x-ai/grok-4.description": "Grok 4 هو النموذج الرائد من xAI بقدرات استدلال قوية ودعم متعدد الوسائط.",
  "x-ai/grok-code-fast-1.description": "Grok Code Fast 1 هو نموذج سريع للبرمجة من xAI بإخراج قابل للقراءة ومناسب للهندسة.",
  "xai/grok-2-vision.description": "Grok 2 Vision يتفوّق في المهام البصرية، ويقدّم أداءً رائدًا في استدلال الرياضيات البصرية (MathVista) وأسئلة المستندات (DocVQA). يتعامل مع المستندات، والمخططات، والرسوم البيانية، ولقطات الشاشة، والصور.",
  "xai/grok-2.description": "Grok 2 هو نموذج متقدم بأداء رائد في الاستدلال، والدردشة، والبرمجة، ويتفوّق على Claude 3.5 Sonnet وGPT-4 Turbo في تصنيفات LMSYS.",
  "xai/grok-3-fast.description": "نموذج xAI الرائد يتفوّق في حالات الاستخدام المؤسسية مثل استخراج البيانات، والبرمجة، والتلخيص، مع معرفة عميقة في مجالات مثل المالية، والرعاية الصحية، والقانون، والعلوم. الإصدار السريع يعمل على بنية تحتية أسرع لتقديم استجابات أسرع بتكلفة أعلى لكل رمز.",
  "xai/grok-3-mini-fast.description": "نموذج xAI الخفيف الوزن الذي يفكر قبل الرد، مثالي للمهام البسيطة أو القائمة على المنطق دون الحاجة إلى معرفة تخصصية. تتوفر آثار التفكير الخام. الإصدار السريع يعمل على بنية تحتية أسرع لتقديم استجابات أسرع بتكلفة أعلى لكل رمز.",
  "xai/grok-3-mini.description": "نموذج xAI الخفيف الوزن الذي يفكر قبل الرد، مثالي للمهام البسيطة أو القائمة على المنطق دون الحاجة إلى معرفة تخصصية. تتوفر آثار التفكير الخام.",
  "xai/grok-3.description": "نموذج xAI الرائد يتفوّق في حالات الاستخدام المؤسسية مثل استخراج البيانات، والبرمجة، والتلخيص، مع معرفة عميقة في مجالات مثل المالية، والرعاية الصحية، والقانون، والعلوم.",
  "xai/grok-4.description": "أحدث نموذج رائد من xAI بأداء لا مثيل له في اللغة الطبيعية، والرياضيات، والاستدلال — مثالي لجميع الاستخدامات.",
  "yi-large-fc.description": "مبني على yi-large مع تحسين استدعاء الأدوات، مناسب لسيناريوهات الوكلاء وسير العمل.",
  "yi-large-preview.description": "إصدار مبكر؛ يُوصى باستخدام yi-large الأحدث.",
  "yi-large-rag.description": "خدمة متقدمة مبنية على yi-large، تجمع بين الاسترجاع والتوليد لتقديم إجابات دقيقة مع بحث ويب في الوقت الحقيقي.",
  "yi-large-turbo.description": "قيمة وأداء استثنائيان، مضبوط لتحقيق توازن قوي بين الجودة والسرعة والتكلفة.",
  "yi-large.description": "نموذج جديد بسعة 100 مليار مع أداء قوي في الأسئلة والأجوبة وتوليد النصوص.",
  "yi-lightning-lite.description": "إصدار خفيف الوزن؛ يُوصى باستخدام yi-lightning.",
  "yi-lightning.description": "أحدث نموذج عالي الأداء مع استدلال أسرع وإخراج عالي الجودة.",
  "yi-medium-200k.description": "نموذج طويل السياق بسعة 200 ألف لفهم وتوليد النصوص الطويلة بعمق.",
  "yi-medium.description": "نموذج متوسط الحجم مضبوط لتحقيق توازن بين القدرات والقيمة، ومُحسّن لاتباع التعليمات.",
  "yi-spark.description": "نموذج مدمج وسريع مع قدرات محسّنة في الرياضيات والبرمجة.",
  "yi-vision-v2.description": "نموذج رؤية للمهام المعقدة مع فهم وتحليل قوي لصور متعددة.",
  "yi-vision.description": "نموذج رؤية للمهام المعقدة مع فهم وتحليل قوي للصور.",
  "z-ai/glm-4.5-air.description": "GLM 4.5 Air هو إصدار خفيف الوزن من GLM 4.5 مخصص للسيناريوهات الحساسة للتكلفة مع الحفاظ على قدرات استدلال قوية.",
  "z-ai/glm-4.5.description": "GLM 4.5 هو النموذج الرائد من Z.AI باستدلال هجين مُحسّن للهندسة والمهام طويلة السياق.",
  "z-ai/glm-4.6.description": "GLM 4.6 هو النموذج الرائد من Z.AI مع طول سياق ممتد وقدرات برمجية متقدمة.",
  "zai-glm-4.6.description": "يؤدي أداءً جيدًا في مهام البرمجة والاستدلال، ويدعم البث واستدعاء الأدوات، ومناسب للبرمجة الذاتية والاستدلال المعقد.",
  "zai-org/GLM-4.5-Air.description": "GLM-4.5-Air هو نموذج أساسي لتطبيقات الوكلاء يستخدم بنية Mixture-of-Experts. مُحسّن لاستخدام الأدوات، وتصفح الويب، والهندسة البرمجية، وبرمجة الواجهات، ويتكامل مع وكلاء البرمجة مثل Claude Code وRoo Code. يستخدم استدلالًا هجينًا للتعامل مع السيناريوهات المعقدة واليومية.",
  "zai-org/GLM-4.5.description": "GLM-4.5 هو نموذج أساسي لتطبيقات الوكلاء يستخدم بنية Mixture-of-Experts. مُحسّن بعمق لاستخدام الأدوات، وتصفح الويب، والهندسة البرمجية، وبرمجة الواجهات، ويتكامل مع وكلاء البرمجة مثل Claude Code وRoo Code. يستخدم استدلالًا هجينًا للتعامل مع السيناريوهات المعقدة واليومية.",
  "zai-org/GLM-4.5V.description": "GLM-4.5V هو أحدث نموذج رؤية من Zhipu AI، مبني على نموذج النص الرائد GLM-4.5-Air (إجمالي 106 مليار، 12 مليار نشط) باستخدام بنية MoE لأداء قوي بتكلفة أقل. يتبع مسار GLM-4.1V-Thinking ويضيف 3D-RoPE لتحسين الاستدلال المكاني ثلاثي الأبعاد. مُحسّن من خلال التدريب المسبق، والتعلم الخاضع للإشراف، والتعلم المعزز، ويتعامل مع الصور، والفيديو، والمستندات الطويلة، ويتصدر النماذج المفتوحة في 41 معيارًا متعدد الوسائط. يتيح وضع التفكير للمستخدمين التوازن بين السرعة والعمق.",
  "zai-org/GLM-4.6.description": "مقارنة بـ GLM-4.5، يوسّع GLM-4.6 السياق من 128 ألف إلى 200 ألف لمهام الوكلاء المعقدة. يحقق نتائج أعلى في اختبارات البرمجة ويُظهر أداءً أقوى في التطبيقات الواقعية مثل Claude Code وCline وRoo Code وKilo Code، بما في ذلك توليد صفحات الواجهة الأمامية بشكل أفضل. تم تحسين الاستدلال ودعم استخدام الأدوات أثناء التفكير، مما يعزز القدرات العامة. يتكامل بشكل أفضل مع أطر الوكلاء، ويحسّن وكلاء الأدوات/البحث، ويتميز بأسلوب كتابة مفضل بشريًا وطبيعية في تقمص الأدوار.",
  "zai/glm-4.5-air.description": "GLM-4.5 وGLM-4.5-Air هما أحدث النماذج الرائدة لدينا لتطبيقات الوكلاء، وكلاهما يستخدم بنية MoE. يحتوي GLM-4.5 على 355 مليار إجمالي و32 مليار نشط لكل تمرير؛ بينما GLM-4.5-Air أنحف بإجمالي 106 مليار و12 مليار نشط.",
  "zai/glm-4.5.description": "سلسلة GLM-4.5 مصممة للوكلاء. النموذج الرائد GLM-4.5 يجمع بين الاستدلال، والبرمجة، ومهارات الوكلاء مع 355 مليار معلمة إجمالية (32 مليار نشطة) ويقدّم أوضاع تشغيل مزدوجة كنظام استدلال هجين.",
  "zai/glm-4.5v.description": "GLM-4.5V مبني على GLM-4.5-Air، ويَرِث تقنيات GLM-4.1V-Thinking المثبتة، ويتوسع ببنية MoE قوية بسعة 106 مليار.",
  "zenmux/auto.description": "يختار ZenMux auto-routing النموذج الأفضل من حيث القيمة والأداء من بين الخيارات المدعومة بناءً على طلبك."
}
