{
  "01-ai/yi-1.5-34b-chat.description": "01.AI의 최신 오픈소스 파인튜닝 모델로, 340억 개의 파라미터를 갖추고 있으며, 다양한 대화 시나리오를 지원합니다. 고품질 데이터로 학습되었으며, 인간의 선호도에 맞춰 정렬되었습니다.",
  "01-ai/yi-1.5-9b-chat.description": "01.AI의 최신 오픈소스 파인튜닝 모델로, 90억 개의 파라미터를 갖추고 있으며, 다양한 대화 시나리오를 지원합니다. 고품질 데이터로 학습되었으며, 인간의 선호도에 맞춰 정렬되었습니다.",
  "360/deepseek-r1.description": "360이 배포한 DeepSeek-R1은 후학습 단계에서 대규모 강화학습(RL)을 적용하여 최소한의 라벨로도 추론 능력을 크게 향상시킵니다. 수학, 코드, 자연어 추론 과제에서 OpenAI o1과 동등한 성능을 보입니다.",
  "360gpt-pro-trans.description": "최고 수준의 번역 품질을 위해 깊이 있게 파인튜닝된 번역 특화 모델입니다.",
  "360gpt-pro.description": "360GPT Pro는 다양한 자연어 처리(NLP) 시나리오에 적합한 효율적인 텍스트 처리 기능을 갖춘 360의 핵심 AI 모델로, 장문 이해 및 다중 턴 대화를 지원합니다.",
  "360gpt-turbo-responsibility-8k.description": "360GPT Turbo Responsibility 8K는 의미적 안전성과 책임성을 강조하여 민감한 콘텐츠 응용에 적합하며, 정확하고 견고한 사용자 경험을 보장합니다.",
  "360gpt-turbo.description": "360GPT Turbo는 뛰어난 의미 이해 및 생성 효율성을 바탕으로 강력한 연산 및 대화 기능을 제공하며, 기업 및 개발자에게 이상적인 선택입니다.",
  "360gpt2-o1.description": "360gpt2-o1은 트리 탐색 기반의 사고 사슬(chain-of-thought)을 구축하고 반성(reflection) 메커니즘과 강화학습을 통해 자기 반성과 자기 수정이 가능한 모델입니다.",
  "360gpt2-pro.description": "360GPT2 Pro는 창의적 작업에 특히 강한 고급 NLP 모델로, 복잡한 변환 및 역할극을 처리하며 뛰어난 텍스트 생성 및 이해 능력을 갖추고 있습니다.",
  "360zhinao2-o1.description": "360zhinao2-o1은 트리 탐색 기반의 사고 사슬을 구축하고 반성 메커니즘과 강화학습을 통해 자기 반성과 자기 수정이 가능한 모델입니다.",
  "4.0Ultra.description": "Spark Ultra는 Spark 시리즈 중 가장 강력한 모델로, 텍스트 이해 및 요약 능력을 향상시키고 웹 검색 기능을 업그레이드하였습니다. 업무 생산성과 정확한 응답을 높이는 종합 솔루션으로, 지능형 제품의 선두주자로 자리매김하고 있습니다.",
  "AnimeSharp.description": "AnimeSharp(구 \"4x-AnimeSharp\")는 Kim2091이 개발한 ESRGAN 기반의 오픈소스 초해상도 모델로, 애니메이션 스타일 이미지의 확대 및 선명화에 중점을 둡니다. 원래는 텍스트 이미지에도 사용되었으나, 2022년 2월부터 애니메이션 콘텐츠에 최적화되어 이름이 변경되었습니다.",
  "Baichuan2-Turbo.description": "검색 보강(Search Augmentation)을 통해 모델을 도메인 및 웹 지식과 연결하며, PDF/Word 업로드 및 URL 입력을 지원하여 시의적절하고 전문적이며 정확한 결과를 제공합니다.",
  "Baichuan3-Turbo-128k.description": "128K의 초장문 컨텍스트 윈도우를 갖춘 이 모델은 고빈도 기업 시나리오에 최적화되어 있으며, Baichuan2 대비 콘텐츠 생성 20%, 지식 질의응답 17%, 역할극 40% 향상된 성능을 보입니다. 전반적인 성능은 GPT-3.5를 능가합니다.",
  "Baichuan3-Turbo.description": "고빈도 기업 시나리오에 최적화되어 있으며, Baichuan2 대비 콘텐츠 생성 20%, 지식 질의응답 17%, 역할극 40% 향상된 성능을 보입니다. 전반적인 성능은 GPT-3.5를 능가합니다.",
  "Baichuan4-Air.description": "중국 내 최고 성능을 자랑하는 모델로, 지식, 장문 텍스트, 창의적 생성 등 중국어 과제에서 주요 해외 모델을 능가합니다. 또한 업계 최고 수준의 멀티모달 기능을 갖추고 있으며, 권위 있는 벤치마크에서 우수한 성과를 보입니다.",
  "Baichuan4-Turbo.description": "중국 내 최고 성능을 자랑하는 모델로, 지식, 장문 텍스트, 창의적 생성 등 중국어 과제에서 주요 해외 모델을 능가합니다. 또한 업계 최고 수준의 멀티모달 기능을 갖추고 있으며, 권위 있는 벤치마크에서 우수한 성과를 보입니다.",
  "Baichuan4.description": "국내 최고 성능을 자랑하며, 백과사전식 지식, 장문 텍스트, 창의적 생성 등 중국어 과제에서 주요 해외 모델을 능가합니다. 업계 최고 수준의 멀티모달 기능과 뛰어난 벤치마크 성능도 제공합니다.",
  "ByteDance-Seed/Seed-OSS-36B-Instruct.description": "Seed-OSS는 ByteDance Seed에서 개발한 오픈소스 LLM 시리즈로, 장문 컨텍스트 처리, 추론, 에이전트, 일반 능력에 강점을 지닙니다. Seed-OSS-36B-Instruct는 360억 파라미터의 명령어 튜닝 모델로, 대규모 문서나 코드베이스를 처리할 수 있는 초장문 컨텍스트를 기본 지원합니다. 추론, 코드 생성, 도구 사용 등 에이전트 작업에 최적화되어 있으며, \"사고 예산(Thinking Budget)\" 기능을 통해 유연한 추론 길이 조절이 가능합니다.",
  "DeepSeek-R1-Distill-Llama-70B.description": "DeepSeek R1은 DeepSeek 제품군 중 더 크고 똑똑한 모델로, Llama 70B 아키텍처에 증류되었습니다. 벤치마크 및 인간 평가에서 수학 및 사실 기반 정확도 과제에서 기본 Llama 70B보다 우수한 성능을 보입니다.",
  "DeepSeek-R1-Distill-Qwen-1.5B.description": "Qwen2.5-Math-1.5B 기반의 DeepSeek-R1 증류 모델입니다. 강화학습과 콜드스타트 데이터를 통해 추론 성능을 최적화하였으며, 오픈 모델 중 새로운 멀티태스크 벤치마크를 설정하였습니다.",
  "DeepSeek-R1-Distill-Qwen-14B.description": "DeepSeek-R1-Distill 모델은 DeepSeek-R1이 생성한 샘플 데이터를 활용하여 오픈소스 모델을 파인튜닝한 것입니다.",
  "DeepSeek-R1-Distill-Qwen-32B.description": "DeepSeek-R1-Distill 모델은 DeepSeek-R1이 생성한 샘플 데이터를 활용하여 오픈소스 모델을 파인튜닝한 것입니다.",
  "DeepSeek-R1-Distill-Qwen-7B.description": "Qwen2.5-Math-7B 기반의 DeepSeek-R1 증류 모델입니다. 강화학습과 콜드스타트 데이터를 통해 추론 성능을 최적화하였으며, 오픈 모델 중 새로운 멀티태스크 벤치마크를 설정하였습니다.",
  "DeepSeek-R1.description": "DeepSeek-R1은 후학습 단계에서 대규모 강화학습을 적용하여 최소한의 라벨로도 추론 능력을 크게 향상시킵니다. 수학, 코드, 자연어 추론 과제에서 OpenAI o1 프로덕션 모델과 동등한 성능을 보입니다.",
  "DeepSeek-V3-1.description": "DeepSeek V3.1은 복잡한 추론과 사고 사슬(chain-of-thought) 능력이 향상된 차세대 추론 모델로, 심층 분석 작업에 적합합니다.",
  "DeepSeek-V3-Fast.description": "제공자: sophnet. DeepSeek V3 Fast는 DeepSeek V3 0324의 고TPS 버전으로, 정밀도 손실 없는(full-precision) 모델입니다. 코드 및 수학 성능이 강력하며, 응답 속도가 빠릅니다.",
  "DeepSeek-V3.1-Fast.description": "DeepSeek V3.1 Fast는 DeepSeek V3.1의 고TPS 빠른 변형 모델입니다. 하이브리드 사고 모드를 지원하며, 채팅 템플릿을 통해 사고/비사고 모드를 전환할 수 있습니다. 도구 사용 능력도 향상되었습니다.",
  "DeepSeek-V3.1-Think.description": "DeepSeek-V3.1 사고 모드는 사고/비사고 모드를 모두 지원하는 새로운 하이브리드 추론 모델로, DeepSeek-R1-0528보다 효율적입니다. 후학습 최적화를 통해 에이전트 도구 사용 및 작업 성능이 크게 향상되었습니다.",
  "DeepSeek-V3.description": "DeepSeek-V3는 DeepSeek에서 개발한 MoE 모델로, Qwen2.5-72B 및 Llama-3.1-405B와 같은 오픈 모델을 능가하며, GPT-4o 및 Claude 3.5 Sonnet과 같은 주요 폐쇄형 모델과 경쟁할 수 있는 성능을 보입니다.",
  "Doubao-lite-128k.description": "Doubao-lite는 초고속 응답과 뛰어난 가성비를 제공하며, 다양한 시나리오에 유연하게 대응할 수 있습니다. 128K 컨텍스트를 지원하여 추론 및 파인튜닝이 가능합니다.",
  "Doubao-lite-32k.description": "Doubao-lite는 초고속 응답과 뛰어난 가성비를 제공하며, 다양한 시나리오에 유연하게 대응할 수 있습니다. 32K 컨텍스트를 지원하여 추론 및 파인튜닝이 가능합니다.",
  "Doubao-lite-4k.description": "Doubao-lite는 초고속 응답과 뛰어난 가성비를 제공하며, 다양한 시나리오에 유연하게 대응할 수 있습니다. 4K 컨텍스트를 지원하여 추론 및 파인튜닝이 가능합니다.",
  "Doubao-pro-128k.description": "복잡한 작업에 최적화된 최고 성능의 플래그십 모델로, 참조 기반 질의응답, 요약, 창작, 분류, 역할극에 강점을 보입니다. 128K 컨텍스트를 지원하여 추론 및 파인튜닝이 가능합니다.",
  "Doubao-pro-32k.description": "복잡한 작업에 최적화된 최고 성능의 플래그십 모델로, 참조 기반 질의응답, 요약, 창작, 분류, 역할극에 강점을 보입니다. 32K 컨텍스트를 지원하여 추론 및 파인튜닝이 가능합니다.",
  "Doubao-pro-4k.description": "복잡한 작업에 최적화된 최고 성능의 플래그십 모델로, 참조 기반 질의응답, 요약, 창작, 분류, 역할극에 강점을 보입니다. 4K 컨텍스트를 지원하여 추론 및 파인튜닝이 가능합니다.",
  "DreamO.description": "DreamO는 ByteDance와 베이징대학교가 공동 개발한 오픈소스 이미지 커스터마이징 모델로, 통합 아키텍처를 통해 다중 작업 이미지 생성을 지원합니다. 효율적인 구성 모델링을 통해 사용자가 지정한 인물, 주제, 스타일, 배경 등 조건에 따라 일관성 높은 맞춤형 이미지를 생성합니다.",
  "amazon/titan-embed-text-v2.description": "Amazon Titan Text Embeddings V2는 경량화되고 효율적인 다국어 임베딩 모델로, 1024, 512 및 256 차원을 지원합니다.",
  "gemini-flash-latest.description": "Gemini Flash 최신 버전",
  "gemini-flash-lite-latest.description": "Gemini Flash-Lite 최신 버전",
  "gemini-pro-latest.description": "Gemini Pro 최신 버전",
  "meta/Llama-3.2-90B-Vision-Instruct.description": "시각 이해 에이전트 애플리케이션을 위한 고급 이미지 추론 기능.",
  "meta/Llama-3.3-70B-Instruct.description": "Llama 3.3은 가장 진보된 다국어 오픈소스 Llama 모델로, 매우 낮은 비용으로 405B에 근접한 성능을 제공합니다. Transformer 기반이며, 유용성과 안전성을 위해 SFT 및 RLHF로 개선되었습니다. 명령어 튜닝 버전은 다국어 채팅에 최적화되어 있으며, 산업 벤치마크에서 많은 오픈 및 클로즈드 채팅 모델을 능가합니다. 지식 기준일: 2023년 12월.",
  "meta/Meta-Llama-3-70B-Instruct.description": "추론, 코딩, 다양한 언어 작업에 뛰어난 성능을 보이는 강력한 70B 파라미터 모델.",
  "meta/Meta-Llama-3-8B-Instruct.description": "채팅 및 텍스트 생성에 최적화된 다재다능한 8B 파라미터 모델.",
  "meta/Meta-Llama-3.1-405B-Instruct.description": "다국어 채팅에 최적화된 Llama 3.1 명령어 튜닝 텍스트 모델로, 오픈 및 클로즈드 채팅 모델 중 업계 표준 벤치마크에서 우수한 성능을 발휘합니다.",
  "meta/Meta-Llama-3.1-70B-Instruct.description": "다국어 채팅에 최적화된 Llama 3.1 명령어 튜닝 텍스트 모델로, 오픈 및 클로즈드 채팅 모델 중 업계 표준 벤치마크에서 우수한 성능을 발휘합니다.",
  "meta/Meta-Llama-3.1-8B-Instruct.description": "다국어 채팅에 최적화된 Llama 3.1 명령어 튜닝 텍스트 모델로, 오픈 및 클로즈드 채팅 모델 중 업계 표준 벤치마크에서 우수한 성능을 발휘합니다.",
  "meta/llama-3-70b.description": "Meta가 명령어 수행을 위해 미세 조정한 70B 오픈소스 모델로, Groq의 LPU 하드웨어에서 빠르고 효율적인 추론을 제공합니다.",
  "meta/llama-3-8b.description": "Meta가 명령어 수행을 위해 미세 조정한 8B 오픈소스 모델로, Groq의 LPU 하드웨어에서 빠르고 효율적인 추론을 제공합니다.",
  "meta/llama-3.1-405b-instruct.description": "챗봇, 코딩, 도메인 작업을 위한 합성 데이터 생성, 지식 증류, 추론을 지원하는 고급 LLM.",
  "meta/llama-3.1-70b-instruct.description": "우수한 문맥 이해, 추론, 텍스트 생성을 통해 복잡한 대화를 처리하도록 설계됨.",
  "meta/llama-3.1-70b.description": "128K 문맥, 다국어 지원, 향상된 추론 기능을 갖춘 최신 Meta Llama 3 70B Instruct.",
  "meta/llama-3.1-8b-instruct.description": "강력한 언어 이해, 추론, 텍스트 생성 기능을 갖춘 최첨단 모델.",
  "meta/llama-3.1-8b.description": "Llama 3.1 8B는 128K 문맥 창을 지원하며, 실시간 채팅 및 데이터 분석에 이상적이며, 대형 모델 대비 비용 효율성이 뛰어납니다. Groq의 LPU 하드웨어에서 빠르고 효율적인 추론을 제공합니다.",
  "meta/llama-3.2-11b-vision-instruct.description": "이미지로부터 고품질 추론을 수행하는 최첨단 비전-언어 모델.",
  "meta/llama-3.2-11b.description": "시각 인식, 이미지 추론, 캡션 생성, 일반 이미지 QA에 최적화된 명령어 튜닝 이미지 추론 모델 (텍스트+이미지 입력, 텍스트 출력).",
  "meta/llama-3.2-1b-instruct.description": "강력한 이해력, 추론력, 텍스트 생성 능력을 갖춘 최첨단 소형 언어 모델.",
  "meta/llama-3.2-1b.description": "다국어 로컬 검색, 요약, 재작성과 같은 온디바이스 사용 사례를 위한 텍스트 전용 모델.",
  "meta/llama-3.2-3b-instruct.description": "강력한 이해력, 추론력, 텍스트 생성 능력을 갖춘 최첨단 소형 언어 모델.",
  "meta/llama-3.2-3b.description": "다국어 로컬 검색, 요약, 재작성과 같은 온디바이스 사용 사례를 위해 미세 조정된 텍스트 전용 모델.",
  "meta/llama-3.2-90b-vision-instruct.description": "이미지로부터 고품질 추론을 수행하는 최첨단 비전-언어 모델.",
  "meta/llama-3.2-90b.description": "시각 인식, 이미지 추론, 캡션 생성, 일반 이미지 QA에 최적화된 명령어 튜닝 이미지 추론 모델 (텍스트+이미지 입력, 텍스트 출력).",
  "meta/llama-3.3-70b-instruct.description": "추론, 수학, 상식, 함수 호출에 강한 고급 LLM.",
  "meta/llama-3.3-70b.description": "성능과 효율성의 완벽한 균형. 콘텐츠 제작, 엔터프라이즈 앱, 연구를 위한 고성능 대화형 AI로 설계되었으며, 요약, 분류, 감정 분석, 코드 생성에 강력한 언어 이해력을 제공합니다.",
  "meta/llama-4-maverick.description": "Llama 4 시리즈는 텍스트 및 멀티모달 경험을 지원하는 네이티브 멀티모달 AI 모델 세트로, MoE를 활용하여 탁월한 텍스트 및 이미지 이해를 제공합니다. Llama 4 Maverick은 128명의 전문가를 갖춘 17B 모델로, DeepInfra에서 제공됩니다.",
  "meta/llama-4-scout.description": "Llama 4 시리즈는 텍스트 및 멀티모달 경험을 지원하는 네이티브 멀티모달 AI 모델 세트로, MoE를 활용하여 탁월한 텍스트 및 이미지 이해를 제공합니다. Llama 4 Scout은 16명의 전문가를 갖춘 17B 모델로, DeepInfra에서 제공됩니다.",
  "microsoft/Phi-3-medium-128k-instruct.description": "RAG 또는 few-shot 프롬프트를 위한 더 큰 문맥 창을 갖춘 동일한 Phi-3-medium 모델.",
  "microsoft/Phi-3-medium-4k-instruct.description": "Phi-3-mini보다 높은 품질을 제공하는 14B 파라미터 모델로, 고품질 및 추론 중심 데이터에 중점을 둠.",
  "microsoft/Phi-3-mini-128k-instruct.description": "RAG 또는 few-shot 프롬프트를 위한 더 큰 문맥 창을 갖춘 동일한 Phi-3-mini 모델.",
  "microsoft/Phi-3-mini-4k-instruct.description": "가장 작은 Phi-3 시리즈 모델로, 품질과 낮은 지연 시간에 최적화됨.",
  "microsoft/Phi-3-small-128k-instruct.description": "RAG 또는 few-shot 프롬프트를 위한 더 큰 문맥 창을 갖춘 동일한 Phi-3-small 모델.",
  "microsoft/Phi-3-small-8k-instruct.description": "Phi-3-mini보다 높은 품질을 제공하는 7B 파라미터 모델로, 고품질 및 추론 중심 데이터에 중점을 둠.",
  "microsoft/Phi-3.5-mini-instruct.description": "Phi-3-mini 모델의 업데이트 버전.",
  "microsoft/Phi-3.5-vision-instruct.description": "Phi-3-vision 모델의 업데이트 버전.",
  "microsoft/WizardLM-2-8x22B.description": "WizardLM 2는 Microsoft AI의 언어 모델로, 복잡한 대화, 다국어 작업, 추론, 어시스턴트에 뛰어납니다.",
  "microsoft/wizardlm-2-8x22b.description": "WizardLM-2 8x22B는 Microsoft AI의 가장 진보된 Wizard 모델로, 매우 경쟁력 있는 성능을 제공합니다.",
  "minicpm-v.description": "MiniCPM-V는 OpenBMB의 차세대 멀티모달 모델로, 광범위한 사용 사례에 대해 뛰어난 OCR 및 멀티모달 이해력을 제공합니다.",
  "minimax-m2.description": "MiniMax M2는 코딩 및 에이전트 워크플로우를 위해 설계된 효율적인 LLM입니다.",
  "minimax/minimax-m2.description": "MiniMax-M2는 다양한 엔지니어링 시나리오에서 코딩 및 에이전트 작업에 뛰어난 고가치 모델입니다.",
  "minimaxai/minimax-m2.description": "MiniMax-M2는 컴팩트하고 빠르며 비용 효율적인 MoE 모델(총 230B, 활성 10B)로, 다중 파일 편집, 코드 실행-수정 루프, 테스트 검증, 복잡한 툴체인에서 뛰어난 성능을 발휘하며 강력한 일반 지능을 유지합니다.",
  "ministral-3b-latest.description": "Ministral 3B는 Mistral의 최고급 엣지 모델입니다.",
  "ministral-8b-latest.description": "Ministral 8B는 Mistral의 매우 비용 효율적인 엣지 모델입니다.",
  "mistral-ai/Mistral-Large-2411.description": "대규모 추론 또는 특수화가 필요한 복잡한 작업을 위한 Mistral의 플래그십 모델 (합성 텍스트 생성, 코드 생성, RAG 또는 에이전트 등).",
  "mistral-ai/Mistral-Nemo.description": "Mistral Nemo는 크기에 비해 최첨단 추론, 세계 지식, 코딩 성능을 제공하는 최첨단 LLM입니다.",
  "mistral-ai/mistral-small-2503.description": "Mistral Small은 고효율 및 낮은 지연 시간이 필요한 모든 언어 기반 작업에 적합합니다.",
  "mistral-large-instruct.description": "Mistral-Large-Instruct-2407은 123B 파라미터를 갖춘 고급 밀집 LLM으로, 최첨단 추론, 지식, 코딩 기능을 제공합니다.",
  "mistral-large-latest.description": "Mistral Large는 다국어 작업, 복잡한 추론, 코드 생성에 강력한 플래그십 모델로, 고급 애플리케이션에 이상적입니다.",
  "mistral-large.description": "Mixtral Large는 Mistral의 플래그십 모델로, 코드 생성, 수학, 추론을 128K 문맥 창과 결합합니다.",
  "mistral-medium-latest.description": "Mistral Medium 3는 8배 낮은 비용으로 최첨단 성능을 제공하며, 엔터프라이즈 배포를 간소화합니다.",
  "mistral-nemo-instruct.description": "Mistral-Nemo-Instruct-2407은 Mistral-Nemo-Base-2407의 명령어 튜닝 버전입니다.",
  "mistral-nemo.description": "Mistral Nemo는 Mistral AI와 NVIDIA가 공동 개발한 고효율 12B 모델입니다.",
  "mistral-small-latest.description": "Mistral Small은 번역, 요약, 감정 분석에 적합한 비용 효율적이고 빠르며 신뢰할 수 있는 옵션입니다.",
  "mistral-small.description": "Mistral Small은 고효율 및 낮은 지연 시간이 필요한 모든 언어 기반 작업에 적합합니다.",
  "mistral.description": "Mistral은 다양한 언어 작업에 적합한 Mistral AI의 7B 모델입니다."
}
