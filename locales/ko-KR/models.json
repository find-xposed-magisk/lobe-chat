{
  "01-ai/yi-1.5-34b-chat.description": "01.AI의 최신 오픈소스 파인튜닝 모델로, 340억 개의 파라미터를 갖추고 있으며, 다양한 대화 시나리오를 지원합니다. 고품질 데이터로 학습되었으며, 인간의 선호도에 맞춰 정렬되었습니다.",
  "01-ai/yi-1.5-9b-chat.description": "01.AI의 최신 오픈소스 파인튜닝 모델로, 90억 개의 파라미터를 갖추고 있으며, 다양한 대화 시나리오를 지원합니다. 고품질 데이터로 학습되었으며, 인간의 선호도에 맞춰 정렬되었습니다.",
  "360/deepseek-r1.description": "360이 배포한 DeepSeek-R1은 후학습 단계에서 대규모 강화학습(RL)을 적용하여 최소한의 라벨로도 추론 능력을 크게 향상시킵니다. 수학, 코드, 자연어 추론 과제에서 OpenAI o1과 동등한 성능을 보입니다.",
  "360gpt-pro-trans.description": "최고 수준의 번역 품질을 위해 깊이 있게 파인튜닝된 번역 특화 모델입니다.",
  "360gpt-pro.description": "360GPT Pro는 다양한 자연어 처리(NLP) 시나리오에 적합한 효율적인 텍스트 처리 기능을 갖춘 360의 핵심 AI 모델로, 장문 이해 및 다중 턴 대화를 지원합니다.",
  "360gpt-turbo-responsibility-8k.description": "360GPT Turbo Responsibility 8K는 의미적 안전성과 책임성을 강조하여 민감한 콘텐츠 응용에 적합하며, 정확하고 견고한 사용자 경험을 보장합니다.",
  "360gpt-turbo.description": "360GPT Turbo는 뛰어난 의미 이해 및 생성 효율성을 바탕으로 강력한 연산 및 대화 기능을 제공하며, 기업 및 개발자에게 이상적인 선택입니다.",
  "360gpt2-o1.description": "360gpt2-o1은 트리 탐색 기반의 사고 사슬(chain-of-thought)을 구축하고 반성(reflection) 메커니즘과 강화학습을 통해 자기 반성과 자기 수정이 가능한 모델입니다.",
  "360gpt2-pro.description": "360GPT2 Pro는 창의적 작업에 특히 강한 고급 NLP 모델로, 복잡한 변환 및 역할극을 처리하며 뛰어난 텍스트 생성 및 이해 능력을 갖추고 있습니다.",
  "360zhinao2-o1.description": "360zhinao2-o1은 트리 탐색 기반의 사고 사슬을 구축하고 반성 메커니즘과 강화학습을 통해 자기 반성과 자기 수정이 가능한 모델입니다.",
  "4.0Ultra.description": "Spark Ultra는 Spark 시리즈 중 가장 강력한 모델로, 텍스트 이해 및 요약 능력을 향상시키고 웹 검색 기능을 업그레이드하였습니다. 업무 생산성과 정확한 응답을 높이는 종합 솔루션으로, 지능형 제품의 선두주자로 자리매김하고 있습니다.",
  "AnimeSharp.description": "AnimeSharp(구 \"4x-AnimeSharp\")는 Kim2091이 개발한 ESRGAN 기반의 오픈소스 초해상도 모델로, 애니메이션 스타일 이미지의 확대 및 선명화에 중점을 둡니다. 원래는 텍스트 이미지에도 사용되었으나, 2022년 2월부터 애니메이션 콘텐츠에 최적화되어 이름이 변경되었습니다.",
  "Baichuan2-Turbo.description": "검색 보강(Search Augmentation)을 통해 모델을 도메인 및 웹 지식과 연결하며, PDF/Word 업로드 및 URL 입력을 지원하여 시의적절하고 전문적이며 정확한 결과를 제공합니다.",
  "Baichuan3-Turbo-128k.description": "128K의 초장문 컨텍스트 윈도우를 갖춘 이 모델은 고빈도 기업 시나리오에 최적화되어 있으며, Baichuan2 대비 콘텐츠 생성 20%, 지식 질의응답 17%, 역할극 40% 향상된 성능을 보입니다. 전반적인 성능은 GPT-3.5를 능가합니다.",
  "Baichuan3-Turbo.description": "고빈도 기업 시나리오에 최적화되어 있으며, Baichuan2 대비 콘텐츠 생성 20%, 지식 질의응답 17%, 역할극 40% 향상된 성능을 보입니다. 전반적인 성능은 GPT-3.5를 능가합니다.",
  "Baichuan4-Air.description": "중국 내 최고 성능을 자랑하는 모델로, 지식, 장문 텍스트, 창의적 생성 등 중국어 과제에서 주요 해외 모델을 능가합니다. 또한 업계 최고 수준의 멀티모달 기능을 갖추고 있으며, 권위 있는 벤치마크에서 우수한 성과를 보입니다.",
  "Baichuan4-Turbo.description": "중국 내 최고 성능을 자랑하는 모델로, 지식, 장문 텍스트, 창의적 생성 등 중국어 과제에서 주요 해외 모델을 능가합니다. 또한 업계 최고 수준의 멀티모달 기능을 갖추고 있으며, 권위 있는 벤치마크에서 우수한 성과를 보입니다.",
  "Baichuan4.description": "국내 최고 성능을 자랑하며, 백과사전식 지식, 장문 텍스트, 창의적 생성 등 중국어 과제에서 주요 해외 모델을 능가합니다. 업계 최고 수준의 멀티모달 기능과 뛰어난 벤치마크 성능도 제공합니다.",
  "ByteDance-Seed/Seed-OSS-36B-Instruct.description": "Seed-OSS는 ByteDance Seed에서 개발한 오픈소스 LLM 시리즈로, 장문 컨텍스트 처리, 추론, 에이전트, 일반 능력에 강점을 지닙니다. Seed-OSS-36B-Instruct는 360억 파라미터의 명령어 튜닝 모델로, 대규모 문서나 코드베이스를 처리할 수 있는 초장문 컨텍스트를 기본 지원합니다. 추론, 코드 생성, 도구 사용 등 에이전트 작업에 최적화되어 있으며, \"사고 예산(Thinking Budget)\" 기능을 통해 유연한 추론 길이 조절이 가능합니다.",
  "DeepSeek-R1-Distill-Llama-70B.description": "DeepSeek R1은 DeepSeek 제품군 중 더 크고 똑똑한 모델로, Llama 70B 아키텍처에 증류되었습니다. 벤치마크 및 인간 평가에서 수학 및 사실 기반 정확도 과제에서 기본 Llama 70B보다 우수한 성능을 보입니다.",
  "DeepSeek-R1-Distill-Qwen-1.5B.description": "Qwen2.5-Math-1.5B 기반의 DeepSeek-R1 증류 모델입니다. 강화학습과 콜드스타트 데이터를 통해 추론 성능을 최적화하였으며, 오픈 모델 중 새로운 멀티태스크 벤치마크를 설정하였습니다.",
  "DeepSeek-R1-Distill-Qwen-14B.description": "DeepSeek-R1-Distill 모델은 DeepSeek-R1이 생성한 샘플 데이터를 활용하여 오픈소스 모델을 파인튜닝한 것입니다.",
  "DeepSeek-R1-Distill-Qwen-32B.description": "DeepSeek-R1-Distill 모델은 DeepSeek-R1이 생성한 샘플 데이터를 활용하여 오픈소스 모델을 파인튜닝한 것입니다.",
  "DeepSeek-R1-Distill-Qwen-7B.description": "Qwen2.5-Math-7B 기반의 DeepSeek-R1 증류 모델입니다. 강화학습과 콜드스타트 데이터를 통해 추론 성능을 최적화하였으며, 오픈 모델 중 새로운 멀티태스크 벤치마크를 설정하였습니다.",
  "DeepSeek-R1.description": "DeepSeek-R1은 후학습 단계에서 대규모 강화학습을 적용하여 최소한의 라벨로도 추론 능력을 크게 향상시킵니다. 수학, 코드, 자연어 추론 과제에서 OpenAI o1 프로덕션 모델과 동등한 성능을 보입니다.",
  "DeepSeek-V3-1.description": "DeepSeek V3.1은 복잡한 추론과 사고 사슬(chain-of-thought) 능력이 향상된 차세대 추론 모델로, 심층 분석 작업에 적합합니다.",
  "DeepSeek-V3-Fast.description": "제공자: sophnet. DeepSeek V3 Fast는 DeepSeek V3 0324의 고TPS 버전으로, 정밀도 손실 없는(full-precision) 모델입니다. 코드 및 수학 성능이 강력하며, 응답 속도가 빠릅니다.",
  "DeepSeek-V3.1-Fast.description": "DeepSeek V3.1 Fast는 DeepSeek V3.1의 고TPS 빠른 변형 모델입니다. 하이브리드 사고 모드를 지원하며, 채팅 템플릿을 통해 사고/비사고 모드를 전환할 수 있습니다. 도구 사용 능력도 향상되었습니다.",
  "DeepSeek-V3.1-Think.description": "DeepSeek-V3.1 사고 모드는 사고/비사고 모드를 모두 지원하는 새로운 하이브리드 추론 모델로, DeepSeek-R1-0528보다 효율적입니다. 후학습 최적화를 통해 에이전트 도구 사용 및 작업 성능이 크게 향상되었습니다.",
  "DeepSeek-V3.description": "DeepSeek-V3는 DeepSeek에서 개발한 MoE 모델로, Qwen2.5-72B 및 Llama-3.1-405B와 같은 오픈 모델을 능가하며, GPT-4o 및 Claude 3.5 Sonnet과 같은 주요 폐쇄형 모델과 경쟁할 수 있는 성능을 보입니다.",
  "Doubao-lite-128k.description": "Doubao-lite는 초고속 응답과 뛰어난 가성비를 제공하며, 다양한 시나리오에 유연하게 대응할 수 있습니다. 128K 컨텍스트를 지원하여 추론 및 파인튜닝이 가능합니다.",
  "Doubao-lite-32k.description": "Doubao-lite는 초고속 응답과 뛰어난 가성비를 제공하며, 다양한 시나리오에 유연하게 대응할 수 있습니다. 32K 컨텍스트를 지원하여 추론 및 파인튜닝이 가능합니다.",
  "Doubao-lite-4k.description": "Doubao-lite는 초고속 응답과 뛰어난 가성비를 제공하며, 다양한 시나리오에 유연하게 대응할 수 있습니다. 4K 컨텍스트를 지원하여 추론 및 파인튜닝이 가능합니다.",
  "Doubao-pro-128k.description": "복잡한 작업에 최적화된 최고 성능의 플래그십 모델로, 참조 기반 질의응답, 요약, 창작, 분류, 역할극에 강점을 보입니다. 128K 컨텍스트를 지원하여 추론 및 파인튜닝이 가능합니다.",
  "Doubao-pro-32k.description": "복잡한 작업에 최적화된 최고 성능의 플래그십 모델로, 참조 기반 질의응답, 요약, 창작, 분류, 역할극에 강점을 보입니다. 32K 컨텍스트를 지원하여 추론 및 파인튜닝이 가능합니다.",
  "Doubao-pro-4k.description": "복잡한 작업에 최적화된 최고 성능의 플래그십 모델로, 참조 기반 질의응답, 요약, 창작, 분류, 역할극에 강점을 보입니다. 4K 컨텍스트를 지원하여 추론 및 파인튜닝이 가능합니다.",
  "DreamO.description": "DreamO는 ByteDance와 베이징대학교가 공동 개발한 오픈소스 이미지 커스터마이징 모델로, 통합 아키텍처를 통해 다중 작업 이미지 생성을 지원합니다. 효율적인 구성 모델링을 통해 사용자가 지정한 인물, 주제, 스타일, 배경 등 조건에 따라 일관성 높은 맞춤형 이미지를 생성합니다.",
  "ERNIE-3.5-128K.description": "바이두의 대표적인 대규모 LLM으로, 방대한 중문/영문 말뭉치로 학습되어 대화, 창작, 플러그인 활용 등에서 뛰어난 범용 능력을 보입니다. 최신 정보를 제공하기 위해 바이두 검색 플러그인을 자동으로 연동할 수 있습니다.",
  "ERNIE-3.5-8K-Preview.description": "바이두의 대표적인 대규모 LLM으로, 방대한 중문/영문 말뭉치로 학습되어 대화, 창작, 플러그인 활용 등에서 뛰어난 범용 능력을 보입니다. 최신 정보를 제공하기 위해 바이두 검색 플러그인을 자동으로 연동할 수 있습니다.",
  "ERNIE-3.5-8K.description": "바이두의 대표적인 대규모 LLM으로, 방대한 중문/영문 말뭉치로 학습되어 대화, 창작, 플러그인 활용 등에서 뛰어난 범용 능력을 보입니다. 최신 정보를 제공하기 위해 바이두 검색 플러그인을 자동으로 연동할 수 있습니다.",
  "ERNIE-4.0-8K-Latest.description": "ERNIE 3.5보다 전반적으로 업그레이드된 바이두의 초대형 LLM으로, 다양한 분야의 복잡한 작업에 적합합니다. 최신 정보를 제공하기 위해 바이두 검색 플러그인을 연동할 수 있습니다.",
  "ERNIE-4.0-8K-Preview.description": "ERNIE 3.5보다 전반적으로 업그레이드된 바이두의 초대형 LLM으로, 다양한 분야의 복잡한 작업에 적합합니다. 최신 정보를 제공하기 위해 바이두 검색 플러그인을 연동할 수 있습니다.",
  "ERNIE-4.0-Turbo-8K-Latest.description": "복잡한 작업에 강력한 성능을 발휘하는 바이두의 초대형 LLM으로, 바이두 검색 플러그인을 연동하여 최신 정보를 제공합니다. ERNIE 4.0보다 우수한 성능을 보입니다.",
  "ERNIE-4.0-Turbo-8K-Preview.description": "복잡한 작업에 강력한 성능을 발휘하는 바이두의 초대형 LLM으로, 바이두 검색 플러그인을 연동하여 최신 정보를 제공합니다. ERNIE 4.0보다 우수한 성능을 보입니다.",
  "ERNIE-Character-8K.description": "게임 NPC, 고객 응대, 롤플레잉 등 특화된 분야를 위한 바이두의 LLM으로, 인격 일관성, 지시 이행력, 추론 능력이 향상되었습니다.",
  "ERNIE-Lite-Pro-128K.description": "ERNIE Lite보다 품질과 추론 성능이 향상된 경량형 LLM으로, 저사양 가속기 환경에서도 적합하게 작동합니다.",
  "ERNIE-Speed-128K.description": "2024년 출시된 바이두의 최신 고성능 LLM으로, 강력한 범용 능력을 갖추고 있으며 특정 시나리오에 맞춘 파인튜닝의 기반 모델로 적합합니다. 뛰어난 추론 성능을 제공합니다.",
  "ERNIE-Speed-Pro-128K.description": "2024년 출시된 바이두의 최신 고성능 LLM으로, ERNIE Speed보다 향상된 범용 능력을 갖추고 있으며, 특정 시나리오에 맞춘 파인튜닝의 기반 모델로 적합합니다. 뛰어난 추론 성능을 제공합니다.",
  "FLUX-1.1-pro.description": "FLUX.1.1 Pro",
  "FLUX.1-Kontext-dev.description": "FLUX.1-Kontext-dev는 Black Forest Labs에서 개발한 다중 모달 이미지 생성 및 편집 모델로, 120억 매개변수의 Rectified Flow Transformer 아키텍처를 기반으로 합니다. 주어진 문맥 조건 하에서 이미지 생성, 복원, 향상, 편집을 수행하며, 디퓨전 모델의 제어 가능한 생성 능력과 트랜스포머 기반 문맥 모델링을 결합하여 인페인팅, 아웃페인팅, 시각적 장면 복원 등 고품질 작업을 지원합니다.",
  "FLUX.1-Kontext-pro.description": "FLUX.1 Kontext [pro]",
  "FLUX.1-dev.description": "FLUX.1-dev는 Black Forest Labs에서 개발한 오픈소스 다중 모달 언어 모델(MLLM)로, 이미지-텍스트 작업에 최적화되어 있으며 이미지/텍스트 이해 및 생성을 결합합니다. Mistral-7B와 같은 고급 LLM을 기반으로, 정교한 비전 인코더와 다단계 지시 튜닝을 통해 다중 모달 조정 및 복잡한 작업 추론을 가능하게 합니다.",
  "Gryphe/MythoMax-L2-13b.description": "MythoMax-L2 (13B)는 다양한 분야와 복잡한 작업을 위한 혁신적인 모델입니다.",
  "HelloMeme.description": "HelloMeme은 사용자가 제공한 이미지나 동작을 기반으로 밈, GIF, 짧은 영상을 생성하는 AI 도구입니다. 그림이나 코딩 기술 없이도 참조 이미지 하나만으로 재미있고 매력적이며 스타일이 일관된 콘텐츠를 만들 수 있습니다.",
  "HiDream-I1-Full.description": "HiDream-E1-Full은 HiDream.ai에서 개발한 오픈소스 다중 모달 이미지 편집 모델로, 고급 디퓨전 트랜스포머 아키텍처와 강력한 언어 이해 능력(LLaMA 3.1-8B-Instruct 내장)을 기반으로 합니다. 자연어 기반 이미지 생성, 스타일 전환, 국소 편집, 리페인팅을 지원하며, 이미지-텍스트 이해 및 실행 능력이 뛰어납니다.",
  "HunyuanDiT-v1.2-Diffusers-Distilled.description": "hunyuandit-v1.2-distilled는 경량화된 텍스트-이미지 생성 모델로, 증류를 통해 고품질 이미지를 빠르게 생성할 수 있도록 최적화되었습니다. 저자원 환경 및 실시간 생성에 특히 적합합니다.",
  "InstantCharacter.description": "InstantCharacter는 2025년 텐센트 AI에서 출시한 튜닝이 필요 없는 개인화 캐릭터 생성 모델로, 고정밀도 및 다양한 시나리오에서 일관된 캐릭터 생성을 목표로 합니다. 단 하나의 참조 이미지로 캐릭터를 모델링하고, 스타일, 동작, 배경에 유연하게 적용할 수 있습니다.",
  "InternVL2-8B.description": "InternVL2-8B는 강력한 비전-언어 모델로, 이미지-텍스트 다중 모달 처리를 지원하며 이미지 내용을 정확히 인식하고 관련 설명이나 답변을 생성할 수 있습니다.",
  "InternVL2.5-26B.description": "InternVL2.5-26B는 강력한 비전-언어 모델로, 이미지-텍스트 다중 모달 처리를 지원하며 이미지 내용을 정확히 인식하고 관련 설명이나 답변을 생성할 수 있습니다.",
  "Kolors.description": "Kolors는 Kuaishou Kolors 팀이 개발한 텍스트-이미지 생성 모델로, 수십억 개의 파라미터로 학습되어 시각적 품질, 중국어 의미 이해, 텍스트 렌더링에서 뛰어난 성능을 보입니다.",
  "Kwai-Kolors/Kolors.description": "Kolors는 Kuaishou Kolors 팀이 개발한 대규모 잠재 디퓨전 기반 텍스트-이미지 생성 모델로, 수십억 개의 텍스트-이미지 쌍으로 학습되어 시각적 품질, 복잡한 의미 정확도, 중/영문 텍스트 렌더링에서 뛰어난 성능을 보이며, 중국어 콘텐츠 이해 및 생성 능력이 우수합니다.",
  "Kwaipilot/KAT-Dev.description": "KAT-Dev (32B)는 소프트웨어 엔지니어링 작업을 위한 오픈소스 32B 모델입니다. SWE-Bench Verified에서 62.4% 해결률을 기록하며 오픈 모델 중 5위를 차지했습니다. 코드 완성, 버그 수정, 코드 리뷰를 위해 중간 학습, SFT, RL을 통해 최적화되었습니다.",
  "Llama-3.2-11B-Vision-Instruct.description": "고해상도 이미지에 대한 강력한 이미지 추론 능력을 갖춘 모델로, 시각적 이해 응용에 적합합니다.",
  "Llama-3.2-90B-Vision-Instruct\t.description": "시각적 이해 에이전트 응용을 위한 고급 이미지 추론 모델입니다.",
  "Meta-Llama-3-3-70B-Instruct.description": "Llama 3.3 70B는 대화 및 생성 작업을 위한 다재다능한 트랜스포머 모델입니다.",
  "Meta-Llama-3.1-405B-Instruct.description": "Llama 3.1은 다국어 대화에 최적화된 지시 튜닝 텍스트 모델로, 오픈 및 클로즈드 챗 모델 중 업계 표준 벤치마크에서 뛰어난 성능을 보입니다.",
  "Meta-Llama-3.1-70B-Instruct.description": "Llama 3.1은 다국어 대화에 최적화된 지시 튜닝 텍스트 모델로, 오픈 및 클로즈드 챗 모델 중 업계 표준 벤치마크에서 뛰어난 성능을 보입니다.",
  "Meta-Llama-3.1-8B-Instruct.description": "Llama 3.1은 다국어 대화에 최적화된 지시 튜닝 텍스트 모델로, 오픈 및 클로즈드 챗 모델 중 업계 표준 벤치마크에서 뛰어난 성능을 보입니다.",
  "Meta-Llama-3.2-1B-Instruct.description": "최신 소형 언어 모델로, 뛰어난 언어 이해, 우수한 추론, 텍스트 생성 능력을 갖추고 있습니다.",
  "Meta-Llama-3.2-3B-Instruct.description": "최신 소형 언어 모델로, 뛰어난 언어 이해, 우수한 추론, 텍스트 생성 능력을 갖추고 있습니다.",
  "Meta-Llama-3.3-70B-Instruct.description": "Llama 3.3은 가장 진보된 다국어 오픈소스 Llama 모델로, 매우 낮은 비용으로 405B에 근접한 성능을 제공합니다. 트랜스포머 기반이며, SFT 및 RLHF를 통해 유용성과 안전성이 향상되었습니다. 지시 튜닝 버전은 다국어 대화에 최적화되어 있으며, 업계 벤치마크에서 많은 오픈 및 클로즈드 챗 모델을 능가합니다. 지식 기준일: 2023년 12월.",
  "Meta-Llama-4-Maverick-17B-128E-Instruct-FP8.description": "Llama 4 Maverick은 효율적인 전문가 활성화를 통해 강력한 추론 성능을 제공하는 대형 MoE 모델입니다.",
  "MiniMax-M1.description": "80K 체인 오브 싱킹과 100만 입력을 지원하는 새로운 자체 개발 추론 모델로, 세계 최고 수준의 모델과 유사한 성능을 제공합니다.",
  "MiniMax-M2-Stable.description": "상업적 사용을 위한 높은 동시성을 제공하며, 효율적인 코딩 및 에이전트 워크플로우에 최적화되어 있습니다.",
  "MiniMax-M2.1-Lightning.description": "강력한 다국어 프로그래밍 성능으로 프로그래밍 경험을 전면 업그레이드합니다. 더 빠르고, 더 효율적으로.",
  "MiniMax-M2.1.description": "강력한 다국어 프로그래밍 성능으로 프로그래밍 경험을 전면 업그레이드합니다.",
  "MiniMax-M2.description": "효율적인 코딩과 에이전트 워크플로우를 위해 설계된 모델입니다.",
  "MiniMax-Text-01.description": "MiniMax-01은 기존 트랜스포머를 넘어선 대규모 선형 어텐션을 도입한 모델로, 4560억 파라미터 중 459억이 활성화됩니다. 최대 400만 토큰의 문맥을 지원하며, GPT-4o의 32배, Claude-3.5-Sonnet의 20배에 해당합니다.",
  "MiniMaxAI/MiniMax-M1-80k.description": "MiniMax-M1은 오픈 가중치 기반의 대규모 하이브리드 어텐션 추론 모델로, 총 4560억 파라미터 중 토큰당 약 459억이 활성화됩니다. 100만 문맥을 기본 지원하며, Flash Attention을 통해 10만 토큰 생성 시 FLOPs를 DeepSeek R1 대비 75% 절감합니다. MoE 아키텍처와 CISPO, 하이브리드 어텐션 RL 학습을 통해 장문 추론 및 실제 소프트웨어 엔지니어링 작업에서 선도적인 성능을 보입니다.",
  "MiniMaxAI/MiniMax-M2.description": "MiniMax-M2는 에이전트 효율성을 재정의한 모델로, 총 2300억 파라미터 중 100억만 활성화되는 컴팩트하고 빠르며 비용 효율적인 MoE 모델입니다. 최상위 수준의 코딩 및 에이전트 작업을 위해 설계되었으며, 강력한 범용 지능을 유지합니다. 활성 파라미터가 100억에 불과함에도 훨씬 더 큰 모델과 경쟁할 수 있어 고효율 응용에 이상적입니다.",
  "Moonshot-Kimi-K2-Instruct.description": "총 1조 파라미터 중 320억이 활성화되는 모델로, 비사고형 모델 중 최상위 수준의 최신 지식, 수학, 코딩 성능을 보이며, 일반 에이전트 작업에서도 강력한 성능을 발휘합니다. 에이전트 워크로드에 최적화되어 단순한 응답을 넘어 행동 수행이 가능하며, 즉흥적이고 일반적인 대화 및 에이전트 경험에 적합한 반사 수준의 모델입니다.",
  "NousResearch/Nous-Hermes-2-Mixtral-8x7B-DPO.description": "Nous Hermes 2 - Mixtral 8x7B-DPO (46.7B)는 복잡한 계산을 위한 고정밀 지시 모델입니다.",
  "OmniConsistency.description": "OmniConsistency는 대규모 Diffusion Transformer(DiT)와 스타일이 적용된 쌍 데이터셋을 도입하여 이미지-투-이미지 작업에서 스타일 일관성과 일반화를 향상시키며, 스타일 저하를 방지합니다.",
  "Phi-3-medium-128k-instruct.description": "RAG 또는 few-shot 프롬프트를 위한 더 큰 컨텍스트 윈도우를 갖춘 동일한 Phi-3-medium 모델입니다.",
  "Phi-3-medium-4k-instruct.description": "14B 파라미터를 가진 모델로, Phi-3-mini보다 더 높은 품질을 제공하며, 고품질 및 추론 중심 데이터에 중점을 둡니다.",
  "Phi-3-mini-128k-instruct.description": "RAG 또는 few-shot 프롬프트를 위한 더 큰 컨텍스트 윈도우를 갖춘 동일한 Phi-3-mini 모델입니다.",
  "Phi-3-mini-4k-instruct.description": "Phi-3 시리즈 중 가장 작은 모델로, 품질과 낮은 지연 시간에 최적화되어 있습니다.",
  "Phi-3-small-128k-instruct.description": "RAG 또는 few-shot 프롬프트를 위한 더 큰 컨텍스트 윈도우를 갖춘 동일한 Phi-3-small 모델입니다.",
  "Phi-3-small-8k-instruct.description": "7B 파라미터를 가진 모델로, Phi-3-mini보다 더 높은 품질을 제공하며, 고품질 및 추론 중심 데이터에 중점을 둡니다.",
  "Phi-3.5-mini-instruct.description": "Phi-3-mini 모델의 업데이트 버전입니다.",
  "Phi-3.5-vision-instrust.description": "Phi-3-vision 모델의 업데이트 버전입니다.",
  "Pro/Qwen/Qwen2-7B-Instruct.description": "Qwen2-7B-Instruct는 Qwen2 시리즈의 70억 매개변수 기반 지시 조정 LLM입니다. Transformer 아키텍처를 기반으로 SwiGLU, attention QKV bias, grouped-query attention을 사용하며, 대용량 입력을 처리할 수 있습니다. 언어 이해, 생성, 다국어 작업, 코딩, 수학, 추론 등 다양한 분야에서 강력한 성능을 발휘하며, 대부분의 오픈 모델을 능가하고 상용 모델과 경쟁합니다. 여러 벤치마크에서 Qwen1.5-7B-Chat을 능가합니다.",
  "Pro/Qwen/Qwen2.5-7B-Instruct.description": "Qwen2.5-7B-Instruct는 알리바바 클라우드의 최신 LLM 시리즈 중 하나입니다. 70억 매개변수 모델로 코딩과 수학에서 눈에 띄는 성능 향상을 보이며, 29개 이상의 언어를 지원합니다. 지시 따르기, 구조화된 데이터 이해, 구조화된 출력(특히 JSON) 생성 능력이 향상되었습니다.",
  "Pro/Qwen/Qwen2.5-Coder-7B-Instruct.description": "Qwen2.5-Coder-7B-Instruct는 알리바바 클라우드의 최신 코드 특화 LLM입니다. Qwen2.5를 기반으로 5.5조 토큰으로 학습되었으며, 코드 생성, 추론, 수정 능력을 크게 향상시켰습니다. 수학 및 일반적인 능력도 유지하며, 코딩 에이전트를 위한 강력한 기반을 제공합니다.",
  "Pro/Qwen/Qwen2.5-VL-7B-Instruct.description": "Qwen2.5-VL은 Qwen 시리즈의 새로운 비전-언어 모델로, 강력한 시각적 이해 능력을 갖추고 있습니다. 이미지 내 텍스트, 차트, 레이아웃을 분석하고, 긴 영상과 이벤트를 이해하며, 추론 및 도구 사용, 다양한 형식의 객체 정렬, 구조화된 출력 등을 지원합니다. 동적 해상도 및 프레임 속도 학습을 통해 영상 이해를 개선하고, 비전 인코더 효율성을 높였습니다.",
  "Pro/THUDM/GLM-4.1V-9B-Thinking.description": "GLM-4.1V-9B-Thinking은 Zhipu AI와 칭화대 KEG 연구실이 공동 개발한 오픈소스 VLM으로, 복잡한 멀티모달 인지를 위해 설계되었습니다. GLM-4-9B-0414를 기반으로 체인 오브 쏘트 추론과 강화 학습(RL)을 추가하여 교차 모달 추론과 안정성을 크게 향상시켰습니다.",
  "Pro/THUDM/glm-4-9b-chat.description": "GLM-4-9B-Chat은 Zhipu AI의 오픈소스 GLM-4 모델입니다. 의미 이해, 수학, 추론, 코드, 지식 등 다양한 분야에서 강력한 성능을 보입니다. 다중 턴 대화 외에도 웹 검색, 코드 실행, 사용자 정의 도구 호출, 장문 추론을 지원합니다. 중국어, 영어, 일본어, 한국어, 독일어 등 26개 언어를 지원하며, AlignBench-v2, MT-Bench, MMLU, C-Eval 등에서 우수한 성능을 보이고, 최대 128K 컨텍스트를 지원하여 학술 및 비즈니스 용도에 적합합니다.",
  "Pro/deepseek-ai/DeepSeek-R1-Distill-Qwen-7B.description": "DeepSeek-R1-Distill-Qwen-7B는 Qwen2.5-Math-7B에서 디스틸링되었으며, 80만 개의 정제된 DeepSeek-R1 샘플로 파인튜닝되었습니다. MATH-500에서 92.8%, AIME 2024에서 55.5%, CodeForces에서 7B 모델 기준 1189점을 기록하며 강력한 성능을 보입니다.",
  "Pro/deepseek-ai/DeepSeek-R1.description": "DeepSeek-R1은 반복을 줄이고 가독성을 높이기 위해 강화 학습(RL)을 적용한 추론 모델입니다. RL 이전에는 cold-start 데이터를 사용하여 추론 능력을 더욱 향상시켰으며, 수학, 코드, 추론 작업에서 OpenAI-o1과 유사한 성능을 보입니다. 정교한 학습을 통해 전반적인 성능을 개선했습니다.",
  "Pro/deepseek-ai/DeepSeek-V3.1-Terminus.description": "DeepSeek-V3.1-Terminus는 하이브리드 에이전트 LLM으로 포지셔닝된 V3.1 모델의 업데이트 버전입니다. 사용자 피드백을 반영하여 안정성, 언어 일관성, 중문/영문 혼합 및 비정상 문자 문제를 개선했습니다. 사고 모드와 비사고 모드를 통합하고, 채팅 템플릿을 통해 유연한 전환이 가능합니다. 또한 코드 에이전트와 검색 에이전트의 성능을 향상시켜 도구 사용과 다단계 작업의 신뢰성을 높였습니다.",
  "Pro/deepseek-ai/DeepSeek-V3.2-Exp.description": "DeepSeek-V3.2-Exp는 차세대 아키텍처로의 전환을 위한 실험적 V3.2 릴리스입니다. V3.1-Terminus 위에 DeepSeek Sparse Attention(DSA)을 추가하여 장문 컨텍스트 학습 및 추론 효율을 개선했으며, 도구 사용, 장문 문서 이해, 다단계 추론에 최적화되었습니다. 대규모 컨텍스트 예산에서 높은 추론 효율을 탐색하는 데 이상적입니다.",
  "Pro/deepseek-ai/DeepSeek-V3.description": "DeepSeek-V3는 6710억 매개변수의 MoE 모델로, MLA와 DeepSeekMoE를 사용하며 손실 없는 부하 분산을 통해 효율적인 추론과 학습을 실현합니다. 14.8조 고품질 토큰으로 사전 학습되었고, SFT 및 RL로 추가 튜닝되어 다른 오픈 모델을 능가하며 상용 모델에 근접한 성능을 보입니다.",
  "Pro/moonshotai/Kimi-K2-Instruct-0905.description": "Kimi K2-Instruct-0905는 최신이자 가장 강력한 Kimi K2 모델입니다. 총 1조, 활성 320억 매개변수를 가진 최상급 MoE 모델로, 에이전트 기반 코딩 지능이 강화되어 벤치마크 및 실제 에이전트 작업에서 큰 성능 향상을 보입니다. 프론트엔드 코드의 미적 품질과 사용성도 개선되었습니다.",
  "Pro/moonshotai/Kimi-K2-Thinking.description": "Kimi K2 Thinking Turbo는 추론 속도와 처리량을 최적화한 Turbo 버전으로, K2 Thinking의 다단계 추론 및 도구 사용 능력을 유지합니다. 약 1조 매개변수를 가진 MoE 모델로, 기본 256K 컨텍스트를 지원하며, 대규모 도구 호출이 필요한 실시간 및 동시성 높은 환경에 적합합니다.",
  "Pro/zai-org/glm-4.7.description": "GLM-4.7은 Zhipu의 차세대 플래그십 모델로, 총 파라미터 수 355B, 활성 파라미터 수 32B를 갖추고 있으며, 일반 대화, 추론, 에이전트 능력 전반에서 대폭 향상되었습니다. Interleaved Thinking(교차 사고)을 강화하고, Preserved Thinking(보존 사고) 및 Turn-level Thinking(턴 단위 사고)을 도입하였습니다.",
  "QwQ-32B-Preview.description": "Qwen QwQ는 추론 능력 향상을 목표로 한 실험적 연구 모델입니다.",
  "Qwen/QVQ-72B-Preview.description": "QVQ-72B-Preview는 복잡한 장면 이해와 시각 수학 문제 해결에 강점을 가진 Qwen의 시각 추론 연구 모델입니다.",
  "Qwen/QwQ-32B-Preview.description": "Qwen QwQ는 AI 추론 능력 향상을 목표로 한 실험적 연구 모델입니다.",
  "Qwen/QwQ-32B.description": "QwQ는 Qwen 계열의 추론 특화 모델입니다. 일반적인 지시 조정 모델과 비교해 사고 및 추론 능력이 추가되어, 특히 어려운 문제에서 다운스트림 성능을 크게 향상시킵니다. QwQ-32B는 DeepSeek-R1 및 o1-mini와 경쟁할 수 있는 중형 추론 모델로, RoPE, SwiGLU, RMSNorm, attention QKV bias를 사용하며, 64개 레이어와 40개의 Q attention 헤드(8개 KV in GQA)를 갖추고 있습니다.",
  "Qwen/Qwen-Image-Edit-2509.description": "Qwen-Image-Edit-2509는 Qwen 팀의 Qwen-Image 최신 편집 버전입니다. 200억 매개변수의 Qwen-Image 모델을 기반으로, 강력한 텍스트 렌더링 기능을 이미지 편집으로 확장하여 정밀한 텍스트 편집을 지원합니다. Qwen2.5-VL을 통한 의미 제어와 VAE 인코더를 통한 외형 제어를 결합한 이중 제어 아키텍처를 사용하여 의미 및 외형 수준의 편집이 가능합니다. 로컬 편집(추가/제거/수정)뿐 아니라 IP 생성, 스타일 전환 등 고차원 의미 편집도 지원하며, 의미를 보존합니다. 여러 벤치마크에서 SOTA 성능을 달성했습니다.",
  "Qwen/Qwen-Image.description": "Qwen-Image는 Qwen 팀이 개발한 200억 매개변수 기반 이미지 생성 기초 모델입니다. 복잡한 텍스트 렌더링과 정밀한 이미지 편집에서 큰 성능 향상을 이루었으며, 특히 고해상도 중국어/영어 텍스트 처리에 강점을 보입니다. 다중 행 및 단락 레이아웃을 지원하면서도 타이포그래피 일관성을 유지합니다. 텍스트 렌더링 외에도 사실적 스타일부터 애니메이션까지 다양한 스타일을 지원하며, 스타일 전환, 객체 추가/제거, 디테일 향상, 텍스트 편집, 포즈 제어 등 고급 편집 기능도 제공합니다. 시각 창작의 종합적 기반 모델을 목표로 합니다.",
  "Qwen/Qwen2-72B-Instruct.description": "Qwen 2 Instruct (72B)는 기업용 작업을 위한 정밀한 지시 따르기를 제공합니다.",
  "Qwen/Qwen2-7B-Instruct.description": "Qwen2-7B-Instruct는 Qwen2 시리즈의 70억 매개변수 지시 조정 모델로, Transformer, SwiGLU, QKV bias, grouped-query attention을 사용합니다. 대용량 입력을 처리할 수 있으며, 언어 이해, 생성, 다국어, 코딩, 수학, 추론 벤치마크에서 강력한 성능을 보이며, 대부분의 오픈 모델을 능가하고 Qwen1.5-7B-Chat보다 우수한 평가를 받았습니다.",
  "Qwen/Qwen2-VL-72B-Instruct.description": "Qwen2-VL은 최신 Qwen-VL 모델로, MathVista, DocVQA, RealWorldQA, MTVQA 등 시각 벤치마크에서 SOTA 성능을 달성했습니다. 20분 이상의 영상을 이해하여 영상 QA, 대화, 콘텐츠 생성이 가능하며, 복잡한 추론과 의사결정도 지원합니다. 기기 및 로봇과 통합되어 시각 기반 행동을 수행할 수 있습니다. 영어와 중국어 외에도 대부분의 유럽 언어, 일본어, 한국어, 아랍어, 베트남어 등 다양한 언어의 이미지 내 텍스트를 읽을 수 있습니다.",
  "Qwen/Qwen2.5-14B-Instruct.description": "Qwen2.5-14B-Instruct는 Alibaba Cloud의 최신 대형 언어 모델(LLM) 시리즈의 일부입니다. 140억 매개변수 모델은 코딩 및 수학 성능에서 두드러진 향상을 보이며, 29개 이상의 언어를 지원하고, 지시 따르기, 구조화된 데이터 이해 및 구조화된 출력(특히 JSON) 생성 능력을 개선합니다.",
  "Qwen/Qwen2.5-32B-Instruct.description": "Qwen2.5-32B-Instruct는 Alibaba Cloud의 최신 대형 언어 모델(LLM) 시리즈의 일부입니다. 320억 매개변수 모델은 코딩 및 수학 성능에서 두드러진 향상을 보이며, 29개 이상의 언어를 지원하고, 지시 따르기, 구조화된 데이터 이해 및 구조화된 출력(특히 JSON) 생성 능력을 개선합니다.",
  "Qwen/Qwen2.5-72B-Instruct-128K.description": "Qwen2.5-72B-Instruct는 Alibaba Cloud의 최신 대형 언어 모델(LLM) 시리즈의 일부입니다. 720억 매개변수 모델은 코딩 및 수학 성능을 향상시키고, 최대 128K 입력과 8K 이상의 출력을 지원하며, 29개 이상의 언어를 제공하고, 지시 따르기 및 구조화된 출력(특히 JSON) 생성 능력을 개선합니다.",
  "Qwen/Qwen2.5-72B-Instruct-Turbo.description": "Qwen2.5는 지시 기반 작업에 최적화된 새로운 대형 언어 모델(LLM) 계열입니다.",
  "Qwen/Qwen2.5-72B-Instruct.description": "Qwen2.5-72B-Instruct는 Alibaba Cloud의 최신 대형 언어 모델(LLM) 시리즈의 일부입니다. 720억 매개변수 모델은 코딩 및 수학 성능에서 두드러진 향상을 보이며, 29개 이상의 언어를 지원하고, 지시 따르기, 구조화된 데이터 이해 및 구조화된 출력(특히 JSON) 생성 능력을 개선합니다.",
  "Qwen/Qwen2.5-7B-Instruct-Turbo.description": "Qwen2.5는 지시 기반 작업에 최적화된 새로운 대형 언어 모델(LLM) 계열입니다.",
  "Qwen/Qwen2.5-7B-Instruct.description": "Qwen2.5-7B-Instruct는 Alibaba Cloud의 최신 대형 언어 모델(LLM) 시리즈의 일부입니다. 70억 매개변수 모델은 코딩 및 수학 성능에서 두드러진 향상을 보이며, 29개 이상의 언어를 지원하고, 지시 따르기, 구조화된 데이터 이해 및 구조화된 출력(특히 JSON) 생성 능력을 개선합니다.",
  "Qwen/Qwen2.5-Coder-32B-Instruct.description": "Qwen2.5 Coder 32B Instruct는 Alibaba Cloud의 최신 코드 특화 대형 언어 모델입니다. Qwen2.5를 기반으로 5.5조 토큰으로 학습되었으며, 코드 생성, 추론 및 수정 능력을 크게 향상시키면서 수학 및 일반적인 성능도 유지하여 코딩 에이전트의 강력한 기반을 제공합니다.",
  "Qwen/Qwen2.5-Coder-7B-Instruct.description": "Qwen2.5-Coder-7B-Instruct는 Alibaba Cloud의 최신 코드 특화 대형 언어 모델입니다. Qwen2.5를 기반으로 5.5조 토큰으로 학습되었으며, 코드 생성, 추론 및 수정 능력을 크게 향상시키면서 수학 및 일반적인 성능도 유지하여 코딩 에이전트의 견고한 기반을 제공합니다.",
  "Qwen/Qwen2.5-VL-32B-Instruct.description": "Qwen2.5-VL-32B-Instruct는 Qwen 팀이 개발한 멀티모달 모델입니다. 일반적인 객체 인식은 물론 텍스트, 차트, 아이콘, 그래픽, 레이아웃을 분석할 수 있습니다. 시각적 에이전트로서 도구를 동적으로 제어할 수 있으며, 컴퓨터 및 스마트폰 사용도 포함됩니다. 객체를 정밀하게 위치 지정하고, 송장 및 표와 같은 구조화된 출력을 생성할 수 있습니다. Qwen2-VL과 비교해 수학 및 문제 해결 능력이 향상되었으며, 사용자 선호에 더 부합하는 응답을 제공합니다.",
  "Qwen/Qwen2.5-VL-72B-Instruct.description": "Qwen2.5-VL은 Qwen2.5 시리즈의 비전-언어 모델로, 다음과 같은 주요 업그레이드를 포함합니다: 객체, 텍스트, 차트, 레이아웃에 대한 강력한 시각적 이해; 도구를 동적으로 사용하는 시각적 에이전트로서의 추론; 1시간 이상의 비디오 이해 및 주요 이벤트 포착; 박스 또는 포인트를 통한 정밀한 객체 위치 지정; 송장 및 표와 같은 스캔된 데이터에 대한 구조화된 출력 생성.",
  "Qwen/Qwen3-14B.description": "Qwen3는 차세대 Tongyi Qwen 모델로, 추론, 일반 능력, 에이전트 기능, 다국어 성능에서 큰 향상을 이루었으며, 사고 모드 전환을 지원합니다.",
  "Qwen/Qwen3-235B-A22B-Instruct-2507.description": "Qwen3-235B-A22B-Instruct-2507은 Qwen3의 플래그십 MoE 모델로, 총 2350억 매개변수 중 220억이 활성화됩니다. 사고 모드가 비활성화된 버전으로, 지시 따르기, 논리적 추론, 텍스트 이해, 수학, 과학, 코딩, 도구 사용 능력을 향상시키는 데 중점을 두었습니다. 또한 다국어 롱테일 지식을 확장하고, 주관적인 개방형 작업에서 사용자 선호에 더 잘 맞도록 조정되었습니다.",
  "Qwen/Qwen3-235B-A22B-Thinking-2507.description": "Qwen3-235B-A22B-Thinking-2507은 복잡한 고난도 추론에 중점을 둔 Qwen3 모델입니다. MoE 아키텍처를 사용하며, 총 2350억 매개변수 중 토큰당 약 220억이 활성화되어 효율성을 높입니다. 사고 전용 모델로서 논리, 수학, 과학, 코딩, 학술 벤치마크에서 뛰어난 성능을 보이며, 지시 따르기, 도구 사용, 텍스트 생성 능력도 향상되었습니다. 256K 컨텍스트를 기본 지원하여 심층 추론 및 장문 문서 처리에 적합합니다.",
  "Qwen/Qwen3-235B-A22B.description": "Qwen3는 차세대 Tongyi Qwen 모델로, 추론, 일반 능력, 에이전트 기능, 다국어 성능에서 큰 향상을 이루었으며, 사고 모드 전환을 지원합니다.",
  "Qwen/Qwen3-30B-A3B-Instruct-2507.description": "Qwen3-30B-A3B-Instruct-2507은 Qwen3-30B-A3B의 사고 비활성화 버전입니다. 총 305억 매개변수 중 33억이 활성화되는 MoE 모델로, 지시 따르기, 논리적 추론, 텍스트 이해, 수학, 과학, 코딩, 도구 사용 능력을 크게 향상시켰습니다. 다국어 롱테일 지식을 확장하고, 주관적인 개방형 작업에서 사용자 선호에 더 잘 맞도록 조정되었습니다. 256K 컨텍스트를 지원하며, 사고 모드가 비활성화되어 `<think></think>` 태그를 출력하지 않습니다.",
  "Qwen/Qwen3-30B-A3B-Thinking-2507.description": "Qwen3-30B-A3B-Thinking-2507은 Qwen3 시리즈의 최신 사고 모델입니다. 총 305억 매개변수 중 33억이 활성화되는 MoE 모델로, 복잡한 작업에 중점을 두고 설계되었습니다. 논리, 수학, 과학, 코딩, 학술 벤치마크에서 뛰어난 성능을 보이며, 지시 따르기, 도구 사용, 텍스트 생성, 선호 정렬 능력도 향상되었습니다. 256K 컨텍스트를 기본 지원하며, 최대 100만 토큰까지 확장 가능합니다. 사고 모드에 최적화되어 단계별 추론과 강력한 에이전트 기능을 제공합니다.",
  "Qwen/Qwen3-30B-A3B.description": "Qwen3는 차세대 Tongyi Qwen 모델로, 추론, 일반 능력, 에이전트 기능, 다국어 성능에서 큰 향상을 이루었으며, 사고 모드 전환을 지원합니다.",
  "Qwen/Qwen3-32B.description": "Qwen3는 차세대 Tongyi Qwen 모델로, 추론, 일반 능력, 에이전트 기능, 다국어 성능에서 큰 향상을 이루었으며, 사고 모드 전환을 지원합니다.",
  "Qwen/Qwen3-8B.description": "Qwen3는 차세대 Tongyi Qwen 모델로, 추론, 일반 능력, 에이전트 기능, 다국어 성능에서 큰 향상을 이루었으며, 사고 모드 전환을 지원합니다.",
  "Qwen/Qwen3-Coder-30B-A3B-Instruct.description": "Qwen3-Coder-30B-A3B-Instruct는 Qwen 팀이 개발한 Qwen3 코드 모델입니다. 고성능과 효율성을 위해 최적화되었으며, 코드 기능을 강화합니다. 에이전트 기반 코딩, 자동 브라우저 조작, 도구 사용에서 뛰어난 성능을 보이며, 256K 컨텍스트를 기본 지원하고 최대 100만 토큰까지 확장 가능합니다. Qwen Code 및 CLINE과 같은 플랫폼에서 함수 호출 형식을 통해 에이전트 기반 코딩을 지원합니다.",
  "Qwen/Qwen3-Coder-480B-A35B-Instruct.description": "Qwen3-Coder-480B-A35B-Instruct는 Alibaba의 가장 강력한 에이전트 기반 코드 모델입니다. 총 4800억 매개변수 중 350억이 활성화되는 MoE 모델로, 효율성과 성능의 균형을 이룹니다. 256K 컨텍스트를 기본 지원하며, YaRN을 통해 최대 100만 토큰까지 확장 가능하여 대규모 코드베이스 처리에 적합합니다. 에이전트 기반 코딩 워크플로우를 위해 설계되었으며, 도구 및 환경과 상호작용하여 복잡한 프로그래밍 작업을 해결할 수 있습니다. Claude Sonnet 4와 같은 선도 모델과 비교해도 손색없는 성능을 보입니다.",
  "Qwen/Qwen3-Next-80B-A3B-Instruct.description": "Qwen3-Next-80B-A3B-Instruct는 차세대 Qwen3-Next 아키텍처를 기반으로 한 모델로, 훈련 및 추론 효율성을 극대화한 차세대 베이스 모델입니다. Gated DeltaNet과 Gated Attention을 결합한 하이브리드 어텐션, 고희소성 MoE, 훈련 안정성 최적화를 통해 80B 전체 파라미터 중 약 3B만을 추론 시 활성화하여 연산 비용을 줄이고, 32K 이상의 컨텍스트에서 Qwen3-32B 대비 10배 이상의 처리량을 제공합니다. 이 버전은 일반적인 지시 따르기 작업에 최적화되어 있으며, '사고 모드'는 포함되어 있지 않습니다. 일부 벤치마크에서는 Qwen3-235B에 필적하는 성능을 보이며, 초장문 컨텍스트 작업에서 강력한 우위를 보입니다.",
  "Qwen/Qwen3-Next-80B-A3B-Thinking.description": "Qwen3-Next-80B-A3B-Thinking은 복잡한 추론을 위한 차세대 베이스 모델입니다. Gated DeltaNet과 Gated Attention을 결합한 하이브리드 어텐션과 고희소성 MoE를 활용하여 훈련 및 추론 효율성을 극대화하였습니다. 총 80B 파라미터 중 약 3B만을 추론 시 활성화하여 연산 비용을 절감하고, 32K 이상의 컨텍스트에서 Qwen3-32B 대비 10배 이상의 처리량을 제공합니다. 이 '사고' 버전은 증명, 코드 생성, 논리 분석, 계획 수립 등 다단계 작업에 최적화되어 있으며, 구조화된 사고 과정을 출력합니다. Qwen3-32B-Thinking보다 뛰어난 성능을 보이며, 여러 벤치마크에서 Gemini-2.5-Flash-Thinking을 능가합니다.",
  "Qwen/Qwen3-Omni-30B-A3B-Captioner.description": "Qwen3-Omni-30B-A3B-Captioner는 고품질, 정밀하고 정확한 이미지 캡션 생성을 위해 설계된 Qwen3 시리즈의 비전-언어 모델(VLM)입니다. 30B 파라미터의 MoE 아키텍처를 기반으로 이미지에 대한 깊은 이해를 바탕으로 유창한 설명을 생성하며, 세부 묘사, 장면 이해, 객체 인식, 관계 추론에서 뛰어난 성능을 발휘합니다.",
  "Qwen/Qwen3-Omni-30B-A3B-Instruct.description": "Qwen3-Omni-30B-A3B-Instruct는 30B 전체 파라미터 중 3B만을 활성화하는 MoE 구조의 Qwen3 시리즈 모델로, 낮은 추론 비용으로도 강력한 성능을 제공합니다. 고품질의 다국어 멀티소스 데이터를 기반으로 학습되었으며, 텍스트, 이미지, 오디오, 비디오 등 모든 모달 입력을 지원하고, 모달 간 이해 및 생성이 가능합니다.",
  "Qwen/Qwen3-Omni-30B-A3B-Thinking.description": "Qwen3-Omni-30B-A3B-Thinking은 Qwen3-Omni의 핵심 '사고' 컴포넌트로, 텍스트, 오디오, 이미지, 비디오 등 다양한 모달 입력을 처리하며 복잡한 사고 과정을 수행합니다. 입력을 통합된 표현으로 변환하여 깊이 있는 모달 간 이해를 가능하게 하며, 30B 전체 파라미터 중 3B만을 활성화하는 MoE 구조로 강력한 추론 능력과 연산 효율성을 균형 있게 제공합니다.",
  "Qwen/Qwen3-VL-235B-A22B-Instruct.description": "Qwen3-VL-235B-A22B-Instruct는 MoE 기반의 대규모 지시 튜닝된 Qwen3-VL 모델로, 뛰어난 멀티모달 이해 및 생성 능력을 제공합니다. 기본적으로 256K 컨텍스트를 지원하며, 고동시성 멀티모달 서비스에 적합합니다.",
  "Qwen/Qwen3-VL-235B-A22B-Thinking.description": "Qwen3-VL-235B-A22B-Thinking은 Qwen3-VL의 플래그십 사고 버전으로, 복잡한 멀티모달 추론, 장문 컨텍스트 추론, 엔터프라이즈 환경에서의 에이전트 상호작용에 최적화되어 있습니다.",
  "Qwen/Qwen3-VL-30B-A3B-Instruct.description": "Qwen3-VL-30B-A3B-Instruct는 강력한 비전-언어 이해 및 생성을 제공하는 지시 튜닝된 Qwen3-VL 모델입니다. 기본적으로 256K 컨텍스트를 지원하며, 멀티모달 채팅 및 이미지 기반 생성에 적합합니다.",
  "Qwen/Qwen3-VL-30B-A3B-Thinking.description": "Qwen3-VL-30B-A3B-Thinking은 멀티모달 추론, 이미지-코드 변환, 복잡한 시각적 이해에 최적화된 추론 강화 버전입니다. 256K 컨텍스트를 지원하며, 향상된 사고 체인 능력을 갖추고 있습니다.",
  "Qwen/Qwen3-VL-32B-Instruct.description": "Qwen3-VL-32B-Instruct는 Qwen 팀이 개발한 비전-언어 모델로, 여러 VL 벤치마크에서 SOTA 성능을 기록하고 있습니다. 메가픽셀 해상도의 이미지를 지원하며, 강력한 시각적 이해, 다국어 OCR, 정밀한 시각적 정렬, 시각적 대화를 제공합니다. 복잡한 멀티모달 작업을 처리할 수 있으며, 도구 호출 및 접두어 완성도 지원합니다.",
  "Qwen/Qwen3-VL-32B-Thinking.description": "Qwen3-VL-32B-Thinking은 복잡한 시각적 추론에 최적화된 모델입니다. 내장된 사고 모드를 통해 답변 전 중간 추론 단계를 생성하여 다단계 논리, 계획, 복잡한 추론 능력을 향상시킵니다. 메가픽셀 이미지, 강력한 시각적 이해, 다국어 OCR, 정밀한 정렬, 시각적 대화, 도구 호출, 접두어 완성을 지원합니다.",
  "Qwen/Qwen3-VL-8B-Instruct.description": "Qwen3-VL-8B-Instruct는 Qwen3-8B-Instruct를 기반으로 대규모 이미지-텍스트 데이터를 학습한 비전-언어 모델입니다. 일반적인 시각적 이해, 시각 중심 대화, 이미지 내 다국어 텍스트 인식에 뛰어나며, 시각적 QA, 캡셔닝, 멀티모달 지시 따르기, 도구 사용에 적합합니다.",
  "Qwen/Qwen3-VL-8B-Thinking.description": "Qwen3-VL-8B-Thinking은 Qwen3의 시각적 사고 버전으로, 복잡한 다단계 추론에 최적화되어 있습니다. 답변 전 사고 체인을 생성하여 정확도를 높이며, 심층 시각적 QA 및 정밀한 이미지 분석에 이상적입니다.",
  "Qwen2-72B-Instruct.description": "Qwen2는 최신 Qwen 시리즈로, 128K 컨텍스트 윈도우를 지원합니다. 현재 최고의 오픈 모델들과 비교해도, Qwen2-72B는 자연어 이해, 지식, 코드, 수학, 다국어 능력에서 선도적인 성능을 보입니다.",
  "Qwen2-7B-Instruct.description": "Qwen2는 최신 Qwen 시리즈로, 동급 및 더 큰 오픈 모델들을 능가합니다. Qwen2 7B는 여러 벤치마크에서 특히 코드 및 중국어 이해에서 뛰어난 성능을 보입니다.",
  "Qwen2-VL-72B.description": "Qwen2-VL-72B는 강력한 비전-언어 모델로, 멀티모달 이미지-텍스트 처리를 지원하며, 이미지 내용을 정확히 인식하고 관련 설명이나 답변을 생성합니다.",
  "Qwen2.5-14B-Instruct.description": "Qwen2.5-14B-Instruct는 14B 파라미터를 가진 LLM으로, 중국어 및 다국어 환경에 최적화되어 있으며, 지능형 Q&A 및 콘텐츠 생성을 지원합니다.",
  "Qwen2.5-32B-Instruct.description": "Qwen2.5-32B-Instruct는 32B 파라미터를 가진 LLM으로, 중국어 및 다국어 환경에 최적화되어 있으며, 지능형 Q&A 및 콘텐츠 생성을 지원합니다.",
  "Qwen2.5-72B-Instruct.description": "중국어 및 영어를 위한 LLM으로, 언어, 코딩, 수학, 추론에 최적화되어 있습니다.",
  "Qwen2.5-7B-Instruct.description": "Qwen2.5-7B-Instruct는 7B 파라미터를 가진 LLM으로, 함수 호출 및 외부 시스템과의 원활한 통합을 지원하여 유연성과 확장성을 크게 향상시킵니다. 중국어 및 다국어 환경에 최적화되어 있으며, 지능형 Q&A 및 콘텐츠 생성을 지원합니다.",
  "Qwen2.5-Coder-14B-Instruct.description": "Qwen2.5-Coder-14B-Instruct는 대규모 사전학습된 코딩 지시 모델로, 강력한 코드 이해 및 생성 능력을 갖추고 있습니다. 다양한 프로그래밍 작업을 효율적으로 처리하며, 스마트 코딩, 자동 스크립트 생성, 프로그래밍 Q&A에 이상적입니다.",
  "Qwen2.5-Coder-32B-Instruct.description": "주요 프로그래밍 언어 전반에 걸쳐 코드 생성, 추론, 버그 수정에 최적화된 고급 LLM입니다.",
  "Qwen3-235B-A22B-Instruct-2507-FP8.description": "Qwen3 235B A22B Instruct 2507은 대규모 추론을 효율적으로 수행할 수 있도록 MoE를 활용하여 고급 추론 및 지시 따르기에 최적화된 모델입니다.",
  "Qwen3-235B.description": "Qwen3-235B-A22B는 MoE 모델로, 사고 모드와 비사고 모드를 자유롭게 전환할 수 있는 하이브리드 추론 모드를 도입하였습니다. 119개 언어 및 방언에 대한 이해와 추론을 지원하며, 강력한 도구 호출 기능을 갖추고 있습니다. DeepSeek R1, OpenAI o1, o3-mini, Grok 3, Google Gemini 2.5 Pro 등 주요 모델들과 일반 능력, 코드 및 수학, 다국어 능력, 지식 추론 벤치마크에서 경쟁합니다.",
  "Qwen3-32B.description": "Qwen3-32B는 사고 모드와 비사고 모드를 전환할 수 있는 하이브리드 추론 모드를 도입한 밀집 모델입니다. 아키텍처 개선, 데이터 확장, 훈련 품질 향상을 통해 Qwen2.5-72B와 동등한 성능을 발휘합니다.",
  "SenseChat-128K.description": "128K 컨텍스트를 지원하는 Base V4 모델로, 장문 이해 및 생성에 강점을 가집니다.",
  "SenseChat-32K.description": "32K 컨텍스트를 지원하는 Base V4 모델로, 다양한 상황에 유연하게 대응합니다.",
  "SenseChat-5-1202.description": "V5.5 기반 최신 버전으로, 중영어 기초, 대화, STEM 지식, 인문학 지식, 글쓰기, 수학/논리, 길이 제어 등에서 큰 성능 향상을 이뤘습니다.",
  "SenseChat-5-Cantonese.description": "홍콩식 대화 습관, 속어, 지역 지식에 최적화된 모델로, 광둥어 이해에서 GPT-4를 능가하며, 지식, 추론, 수학, 코딩에서는 GPT-4 Turbo와 대등한 성능을 보입니다.",
  "SenseChat-5-beta.description": "일부 성능은 SenseChat-5-1202를 초과합니다.",
  "SenseChat-5.description": "128K 컨텍스트를 지원하는 최신 V5.5 모델로, 수학적 추론, 영어 대화, 지시 따르기, 장문 이해에서 큰 성능 향상을 이루었으며 GPT-4o와 유사한 수준입니다.",
  "SenseChat-Character-Pro.description": "32K 컨텍스트를 지원하는 고급 캐릭터 대화 모델로, 향상된 성능과 중영어 지원을 제공합니다.",
  "SenseChat-Character.description": "8K 컨텍스트를 지원하는 표준 캐릭터 대화 모델로, 빠른 응답 속도를 자랑합니다.",
  "SenseChat-Turbo-1202.description": "경량화된 최신 모델로, 전체 모델 성능의 90% 이상을 유지하면서 추론 비용을 크게 절감합니다.",
  "SenseChat-Turbo.description": "빠른 질의응답 및 모델 파인튜닝 시나리오에 적합합니다.",
  "SenseChat-Vision.description": "다중 이미지 입력을 지원하는 최신 V5.5 모델로, 속성 인식, 공간 관계, 동작/이벤트 감지, 장면 이해, 감정 인식, 상식 추론, 텍스트 이해/생성 등 핵심 기능이 전반적으로 향상되었습니다.",
  "SenseChat.description": "4K 컨텍스트를 지원하는 Base V4 모델로, 전반적인 성능이 우수합니다.",
  "SenseNova-V6-5-Pro.description": "멀티모달, 언어, 추론 데이터의 전면적인 업데이트와 학습 전략 최적화를 통해, 새로운 모델은 멀티모달 추론과 일반화된 지시 따르기 능력을 크게 향상시켰습니다. 최대 128K 컨텍스트 윈도우를 지원하며, OCR 및 문화 관광 IP 인식 작업에서 뛰어난 성능을 발휘합니다.",
  "SenseNova-V6-5-Turbo.description": "멀티모달, 언어, 추론 데이터의 전면적인 업데이트와 학습 전략 최적화를 통해, 새로운 모델은 멀티모달 추론과 일반화된 지시 따르기 능력을 크게 향상시켰습니다. 최대 128K 컨텍스트 윈도우를 지원하며, OCR 및 문화 관광 IP 인식 작업에서 뛰어난 성능을 발휘합니다.",
  "SenseNova-V6-Pro.description": "이미지, 텍스트, 비디오를 자연스럽게 통합하여 기존의 멀티모달 경계를 허물며, OpenCompass 및 SuperCLUE에서 최고 순위를 기록했습니다.",
  "SenseNova-V6-Reasoner.description": "시각과 언어의 심층 추론을 결합하여 느린 사고와 전체 사고 흐름(chain-of-thought)을 지원합니다.",
  "SenseNova-V6-Turbo.description": "이미지, 텍스트, 비디오를 자연스럽게 통합하여 기존의 멀티모달 경계를 허물며, 핵심 멀티모달 및 언어 능력 전반에서 선도적인 성능을 보이며 다양한 평가에서 상위권에 랭크되었습니다.",
  "Skylark2-lite-8k.description": "Skylark 2세대 모델. Skylark2-lite는 정확도 요구가 낮고 실시간 반응이 필요한 비용 민감형 시나리오에 적합하며, 8K 컨텍스트 윈도우를 지원합니다.",
  "Skylark2-pro-32k.description": "Skylark 2세대 모델. Skylark2-pro는 전문 카피라이팅, 소설 집필, 고품질 번역 등 복잡한 텍스트 생성에 높은 정확도를 제공하며, 32K 컨텍스트 윈도우를 지원합니다.",
  "Skylark2-pro-4k.description": "Skylark 2세대 모델. Skylark2-pro는 전문 카피라이팅, 소설 집필, 고품질 번역 등 복잡한 텍스트 생성에 높은 정확도를 제공하며, 4K 컨텍스트 윈도우를 지원합니다.",
  "Skylark2-pro-character-4k.description": "Skylark 2세대 모델. Skylark2-pro-character는 역할극 및 대화에 특화되어 있으며, 개성 있는 페르소나 스타일과 자연스러운 대화를 구현하여 챗봇, 가상 비서, 고객 서비스에 적합합니다. 빠른 응답 속도를 제공합니다.",
  "Skylark2-pro-turbo-8k.description": "Skylark 2세대 모델. Skylark2-pro-turbo-8k는 8K 컨텍스트 윈도우를 지원하며, 더 빠른 추론 속도와 낮은 비용을 제공합니다.",
  "THUDM/GLM-4-32B-0414.description": "GLM-4-32B-0414는 32B 파라미터를 가진 차세대 오픈 GLM 모델로, OpenAI GPT 및 DeepSeek V3/R1 시리즈와 유사한 성능을 보입니다.",
  "THUDM/GLM-4-9B-0414.description": "GLM-4-9B-0414는 GLM-4-32B의 기술을 계승하면서도 경량화된 배포가 가능한 9B GLM 모델입니다. 코드 생성, 웹 디자인, SVG 생성, 검색 기반 글쓰기 등에서 우수한 성능을 발휘합니다.",
  "THUDM/GLM-4.1V-9B-Thinking.description": "GLM-4.1V-9B-Thinking은 Zhipu AI와 칭화대 KEG 연구실이 공동 개발한 오픈소스 VLM으로, 복잡한 멀티모달 인지를 위해 설계되었습니다. GLM-4-9B-0414를 기반으로 사고 흐름(chain-of-thought) 추론과 강화학습(RL)을 추가하여 크로스모달 추론과 안정성을 크게 향상시켰습니다.",
  "THUDM/GLM-Z1-32B-0414.description": "GLM-Z1-32B-0414는 GLM-4-32B-0414를 기반으로 수학, 코드, 논리 분야에 대한 추가 학습과 강화학습을 통해 수학 능력과 복잡한 문제 해결 능력을 대폭 향상시킨 심층 추론 모델입니다.",
  "THUDM/GLM-Z1-9B-0414.description": "GLM-Z1-9B-0414는 9B 파라미터를 가진 소형 GLM 모델로, 오픈소스의 강점을 유지하면서도 뛰어난 성능을 제공합니다. 수학 추론과 일반 작업에서 강력한 성능을 보이며, 동급 오픈 모델 중 선두를 차지합니다.",
  "THUDM/GLM-Z1-Rumination-32B-0414.description": "GLM-Z1-Rumination-32B-0414는 OpenAI Deep Research와 비교되는 반추(rumination) 능력을 갖춘 심층 추론 모델입니다. 일반적인 심층 사고 모델과 달리 더 긴 숙고 과정을 통해 보다 개방적이고 복잡한 문제를 해결합니다.",
  "THUDM/glm-4-9b-chat.description": "GLM-4-9B-Chat은 Zhipu AI의 오픈소스 GLM-4 모델로, 의미 이해, 수학, 추론, 코드, 지식 등 다양한 분야에서 강력한 성능을 보입니다. 다중 턴 대화 외에도 웹 검색, 코드 실행, 사용자 정의 도구 호출, 장문 추론을 지원하며, 중국어, 영어, 일본어, 한국어, 독일어 등 26개 언어를 지원합니다. AlignBench-v2, MT-Bench, MMLU, C-Eval 등에서 우수한 성과를 보이며, 학술 및 비즈니스 용도로 최대 128K 컨텍스트를 지원합니다.",
  "Tongyi-Zhiwen/QwenLong-L1-32B.description": "QwenLong-L1-32B는 RL을 통해 학습된 최초의 장문 추론 모델(LRM)로, 장문 텍스트 추론에 최적화되어 있습니다. 점진적 컨텍스트 확장 RL을 통해 짧은 문맥에서 긴 문맥으로 안정적으로 전이되며, 7개의 장문 문서 QA 벤치마크에서 OpenAI-o3-mini 및 Qwen3-235B-A22B를 능가하고 Claude-3.7-Sonnet-Thinking과 대등한 성능을 보입니다. 수학, 논리, 다중 단계 추론에서 특히 강력합니다.",
  "Yi-34B-Chat.description": "Yi-1.5-34B는 시리즈의 강력한 일반 언어 능력을 유지하면서도 500B 고품질 토큰에 대한 점진적 학습을 통해 수학 논리 및 코딩 능력을 크게 향상시켰습니다.",
  "abab5.5-chat.description": "복잡한 작업 처리와 효율적인 텍스트 생성을 통해 생산성 중심의 시나리오에 적합하게 설계되었습니다.",
  "abab5.5s-chat.description": "중국어 페르소나 대화에 최적화되어 다양한 응용 분야에서 고품질 중국어 대화를 제공합니다.",
  "abab6.5g-chat.description": "다국어 페르소나 대화에 적합하며, 영어를 포함한 다양한 언어로 고품질 대화 생성을 지원합니다.",
  "abab6.5s-chat.description": "텍스트 생성 및 대화 시스템을 포함한 다양한 자연어 처리 작업에 적합합니다.",
  "abab6.5t-chat.description": "중국어 페르소나 대화에 최적화되어 있으며, 중국어 표현 습관에 맞는 유창한 대화를 제공합니다.",
  "accounts/fireworks/models/deepseek-r1.description": "DeepSeek-R1은 강화 학습과 콜드 스타트 데이터를 활용해 최적화된 최첨단 LLM으로, 뛰어난 추론, 수학, 코딩 성능을 제공합니다.",
  "accounts/fireworks/models/deepseek-v3.description": "DeepSeek에서 개발한 강력한 전문가 혼합(MoE) 언어 모델로, 총 671B 파라미터 중 토큰당 37B가 활성화됩니다.",
  "accounts/fireworks/models/llama-v3-70b-instruct.description": "Meta는 8B 및 70B 크기의 사전 학습 및 지시 조정 텍스트 생성 모델을 포함한 Meta Llama 3 LLM 시리즈를 개발 및 공개했습니다. Llama 3 지시 조정 모델은 대화형 사용에 최적화되어 있으며, 업계 표준 벤치마크에서 기존의 많은 오픈 챗 모델을 능가합니다.",
  "accounts/fireworks/models/llama-v3-8b-instruct-hf.description": "Meta Llama 3 지시 조정 모델은 대화형 사용에 최적화되어 있으며, 업계 표준 벤치마크에서 기존의 많은 오픈 챗 모델을 능가합니다. Llama 3 8B Instruct (HF 버전)는 Llama 3 8B Instruct의 원본 FP16 버전으로, 공식 Hugging Face 구현과 동일한 결과를 기대할 수 있습니다.",
  "accounts/fireworks/models/llama-v3-8b-instruct.description": "Meta는 8B 및 70B 크기의 사전 학습 및 지시 조정 텍스트 생성 모델을 포함한 Meta Llama 3 LLM 시리즈를 개발 및 공개했습니다. Llama 3 지시 조정 모델은 대화형 사용에 최적화되어 있으며, 업계 표준 벤치마크에서 기존의 많은 오픈 챗 모델을 능가합니다.",
  "accounts/fireworks/models/llama-v3p1-405b-instruct.description": "Meta Llama 3.1은 8B, 70B, 405B 크기의 사전 학습 및 지시 조정 생성 모델로 구성된 다국어 LLM 제품군입니다. 지시 조정 텍스트 모델은 다국어 대화에 최적화되어 있으며, 업계 표준 벤치마크에서 기존의 오픈 및 클로즈드 챗 모델을 능가합니다. 405B는 Llama 3.1 제품군 중 가장 강력한 모델로, 참조 구현과 거의 일치하는 FP8 추론을 사용합니다.",
  "accounts/fireworks/models/llama-v3p1-70b-instruct.description": "Meta Llama 3.1은 8B, 70B, 405B 크기의 사전 학습 및 지시 조정 생성 모델로 구성된 다국어 LLM 제품군입니다. 지시 조정 텍스트 모델은 다국어 대화에 최적화되어 있으며, 업계 표준 벤치마크에서 기존의 오픈 및 클로즈드 챗 모델을 능가합니다.",
  "accounts/fireworks/models/llama-v3p1-8b-instruct.description": "Meta Llama 3.1은 8B, 70B, 405B 크기의 사전 학습 및 지시 조정 생성 모델로 구성된 다국어 LLM 제품군입니다. 지시 조정 텍스트 모델은 다국어 대화에 최적화되어 있으며, 업계 표준 벤치마크에서 기존의 오픈 및 클로즈드 챗 모델을 능가합니다.",
  "accounts/fireworks/models/llama-v3p2-11b-vision-instruct.description": "Meta에서 개발한 11B 파라미터의 지시 조정 비전 추론 모델로, 시각 인식, 이미지 추론, 캡션 생성, 이미지 기반 Q&A에 최적화되어 있습니다. 차트 및 그래프와 같은 시각 데이터를 이해하며, 이미지 세부 정보를 텍스트로 생성하여 비전과 언어를 연결합니다.",
  "accounts/fireworks/models/llama-v3p2-3b-instruct.description": "Llama 3.2 3B Instruct는 Meta에서 개발한 경량 다국어 모델로, 실행 효율성이 뛰어나고 대형 모델 대비 지연 시간과 비용 면에서 큰 이점을 제공합니다. 일반적인 사용 사례로는 쿼리/프롬프트 재작성 및 글쓰기 지원이 있습니다.",
  "accounts/fireworks/models/llama-v3p2-90b-vision-instruct.description": "Meta에서 개발한 90B 파라미터의 지시 조정 비전 추론 모델로, 시각 인식, 이미지 추론, 캡션 생성, 이미지 기반 Q&A에 최적화되어 있습니다. 차트 및 그래프와 같은 시각 데이터를 이해하며, 이미지 세부 정보를 텍스트로 생성하여 비전과 언어를 연결합니다. 참고: 이 모델은 현재 서버리스 모델로 실험적으로 제공되며, 프로덕션 사용 시 Fireworks가 예고 없이 배포를 중단할 수 있습니다.",
  "accounts/fireworks/models/llama-v3p3-70b-instruct.description": "Llama 3.3 70B Instruct는 Llama 3.1 70B의 12월 업데이트 버전으로, 도구 사용, 다국어 텍스트 지원, 수학 및 코딩 성능이 2024년 7월 릴리스보다 향상되었습니다. 추론, 수학, 지시 따르기에서 업계 최고 수준의 성능을 제공하며, 3.1 405B와 유사한 성능을 더 빠르고 저렴하게 제공합니다.",
  "accounts/fireworks/models/mistral-small-24b-instruct-2501.description": "24B 파라미터를 가진 모델로, 대형 모델에 필적하는 최첨단 성능을 제공합니다.",
  "accounts/fireworks/models/mixtral-8x22b-instruct.description": "Mixtral MoE 8x22B Instruct v0.1은 Mixtral MoE 8x22B v0.1의 지시 조정 버전으로, 채팅 완료 API가 활성화되어 있습니다.",
  "accounts/fireworks/models/mixtral-8x7b-instruct.description": "Mixtral MoE 8x7B Instruct는 Mixtral MoE 8x7B의 지시 조정 버전으로, 채팅 완료 API가 활성화되어 있습니다.",
  "accounts/fireworks/models/mythomax-l2-13b.description": "MythoMix의 개선된 변형으로, MythoLogic-L2와 Huginn을 고도로 실험적인 텐서 병합 기법으로 결합한 모델입니다. 독특한 특성 덕분에 스토리텔링과 롤플레이에 탁월합니다.",
  "accounts/fireworks/models/phi-3-vision-128k-instruct.description": "Phi-3-Vision-128K-Instruct는 합성 데이터와 선별된 공개 웹 데이터셋을 기반으로 구축된 경량 최첨단 멀티모달 모델로, 고품질 추론 중심의 텍스트 및 비전 데이터를 중점적으로 처리합니다. Phi-3 제품군에 속하며, 128K 토큰 길이의 멀티모달 버전을 지원합니다. 정확한 지시 따르기와 강력한 안전성을 보장하기 위해 감독 학습 및 직접 선호 최적화를 포함한 철저한 개선 과정을 거쳤습니다.",
  "accounts/fireworks/models/qwen-qwq-32b-preview.description": "Qwen QwQ 모델은 AI 추론의 발전에 중점을 두며, 오픈 모델도 폐쇄형 최첨단 모델에 필적할 수 있음을 보여줍니다. QwQ-32B-Preview는 실험적 릴리스로, GPQA, AIME, MATH-500, LiveCodeBench에서 o1과 동등하거나 GPT-4o 및 Claude 3.5 Sonnet을 능가하는 추론 및 분석 성능을 보입니다. 참고: 이 모델은 현재 서버리스 모델로 실험적으로 제공되며, 프로덕션 사용 시 Fireworks가 예고 없이 배포를 중단할 수 있습니다.",
  "accounts/fireworks/models/qwen2-vl-72b-instruct.description": "72B Qwen-VL 모델은 Alibaba의 최신 버전으로, 거의 1년에 걸친 혁신을 반영합니다.",
  "accounts/fireworks/models/qwen2p5-72b-instruct.description": "Qwen2.5는 Qwen 팀과 Alibaba Cloud가 개발한 디코더 전용 LLM 시리즈로, 0.5B, 1.5B, 3B, 7B, 14B, 32B, 72B 크기를 제공하며, 기본 및 지시 조정 버전이 모두 포함됩니다.",
  "accounts/fireworks/models/qwen2p5-coder-32b-instruct.description": "Qwen2.5-Coder는 코드 전용으로 설계된 최신 Qwen LLM입니다 (이전 명칭: CodeQwen). 참고: 이 모델은 현재 서버리스 모델로 실험적으로 제공되며, 프로덕션 사용 시 Fireworks가 예고 없이 배포를 중단할 수 있습니다.",
  "accounts/yi-01-ai/models/yi-large.description": "Yi-Large는 LMSYS 리더보드에서 GPT-4, Gemini 1.5 Pro, Claude 3 Opus 바로 아래에 위치한 최고 수준의 LLM입니다. 특히 스페인어, 중국어, 일본어, 독일어, 프랑스어 등 다국어 처리 능력이 뛰어납니다. 또한 OpenAI와 동일한 API 스키마를 사용하여 개발자 친화적인 통합이 가능합니다.",
  "ai21-jamba-1.5-large.description": "398B 파라미터(활성 94B)를 가진 다국어 모델로, 256K 컨텍스트 윈도우, 함수 호출, 구조화된 출력, 근거 기반 생성을 지원합니다.",
  "ai21-jamba-1.5-mini.description": "52B 파라미터(활성 12B)를 가진 다국어 모델로, 256K 컨텍스트 윈도우, 함수 호출, 구조화된 출력, 근거 기반 생성을 지원합니다.",
  "ai21-labs/AI21-Jamba-1.5-Large.description": "398B 파라미터(활성 94B)를 가진 다국어 모델로, 256K 컨텍스트 윈도우, 함수 호출, 구조화된 출력, 근거 기반 생성을 지원합니다.",
  "ai21-labs/AI21-Jamba-1.5-Mini.description": "52B 파라미터(활성 12B)를 가진 다국어 모델로, 256K 컨텍스트 윈도우, 함수 호출, 구조화된 출력, 근거 기반 생성을 지원합니다.",
  "alibaba/qwen-3-14b.description": "Qwen3는 Qwen 시리즈의 최신 세대로, 밀집 및 MoE 모델을 모두 포함한 포괄적인 제품군을 제공합니다. 광범위한 학습을 기반으로 추론, 지시 따르기, 에이전트 기능, 다국어 지원에서 획기적인 성능을 보여줍니다.",
  "alibaba/qwen-3-235b.description": "Qwen3는 Qwen 시리즈의 최신 세대로, 밀집 및 MoE 모델을 모두 포함한 포괄적인 제품군을 제공합니다. 광범위한 학습을 기반으로 추론, 지시 따르기, 에이전트 기능, 다국어 지원에서 획기적인 성능을 보여줍니다.",
  "alibaba/qwen-3-30b.description": "Qwen3는 Qwen 시리즈의 최신 세대로, 밀집 및 MoE 모델을 모두 포함한 포괄적인 제품군을 제공합니다. 광범위한 학습을 기반으로 추론, 지시 따르기, 에이전트 기능, 다국어 지원에서 획기적인 성능을 보여줍니다.",
  "alibaba/qwen-3-32b.description": "Qwen3는 Qwen 시리즈의 최신 세대로, 밀집 및 MoE 모델을 모두 포함한 포괄적인 제품군을 제공합니다. 광범위한 학습을 기반으로 추론, 지시 따르기, 에이전트 기능, 다국어 지원에서 획기적인 성능을 보여줍니다.",
  "alibaba/qwen3-coder.description": "Qwen3-Coder-480B-A35B-Instruct는 Qwen의 가장 에이전트 지향적인 코드 모델로, 에이전트 기반 코딩, 브라우저 활용, 기타 핵심 코딩 작업에서 뛰어난 성능을 발휘하며 Claude Sonnet 수준의 결과를 보여줍니다.",
  "amazon/nova-lite.description": "이미지, 비디오, 텍스트 입력을 초고속으로 처리하는 매우 저비용의 멀티모달 모델입니다.",
  "amazon/nova-micro.description": "초저지연과 매우 낮은 비용으로 제공되는 텍스트 전용 모델입니다.",
  "amazon/nova-pro.description": "정확도, 속도, 비용의 균형이 뛰어난 고성능 멀티모달 모델로, 다양한 작업에 적합합니다.",
  "amazon/titan-embed-text-v2.description": "Amazon Titan Text Embeddings V2는 경량화되고 효율적인 다국어 임베딩 모델로, 1024, 512 및 256 차원을 지원합니다.",
  "anthropic.claude-3-5-sonnet-20240620-v1:0.description": "Claude 3.5 Sonnet은 업계 표준을 끌어올린 모델로, 경쟁 모델과 Claude 3 Opus를 광범위한 평가에서 능가하면서도 중간 수준의 속도와 비용을 유지합니다.",
  "anthropic.claude-3-5-sonnet-20241022-v2:0.description": "Claude 3.5 Sonnet은 업계 표준을 끌어올린 모델로, 경쟁 모델과 Claude 3 Opus를 광범위한 평가에서 능가하면서도 중간 수준의 속도와 비용을 유지합니다.",
  "anthropic.claude-3-haiku-20240307-v1:0.description": "Claude 3 Haiku는 Anthropic의 가장 빠르고 컴팩트한 모델로, 간단한 질문에 거의 즉각적인 응답을 제공합니다. 사람과 유사한 AI 경험을 가능하게 하며, 200K 컨텍스트 윈도우에서 이미지 입력을 지원합니다.",
  "anthropic.claude-3-opus-20240229-v1:0.description": "Claude 3 Opus는 Anthropic의 가장 강력한 AI 모델로, 매우 복잡한 작업에서 최첨단 성능을 발휘합니다. 개방형 프롬프트와 새로운 시나리오를 유창하고 사람처럼 이해하며, 200K 컨텍스트 윈도우에서 이미지 입력을 지원합니다.",
  "anthropic.claude-3-sonnet-20240229-v1:0.description": "Claude 3 Sonnet은 기업용 작업을 위해 지능과 속도의 균형을 맞춘 모델로, 낮은 비용으로 높은 가치를 제공합니다. 대규모 AI 배포에 적합하며, 200K 컨텍스트 윈도우에서 이미지 입력을 지원합니다.",
  "anthropic.claude-instant-v1.description": "일상적인 대화, 텍스트 분석, 요약, 문서 질의응답에 적합한 빠르고 경제적인 모델입니다.",
  "anthropic.claude-v2.description": "복잡한 대화, 창의적 생성, 세부 지침 이행 등 다양한 작업에서 뛰어난 성능을 발휘하는 고성능 모델입니다.",
  "anthropic.claude-v2:1.description": "Claude 2의 업그레이드 버전으로, 컨텍스트 윈도우가 두 배로 확장되었으며, 장문 문서 및 RAG 작업에서 신뢰성, 환각률, 근거 기반 정확도가 향상되었습니다.",
  "anthropic/claude-3-haiku.description": "Claude 3 Haiku는 Anthropic의 가장 빠른 모델로, 긴 프롬프트를 사용하는 기업용 작업에 적합합니다. 분기 보고서, 계약서, 법률 문서 등 대형 문서를 빠르게 분석하며, 동급 모델 대비 절반의 비용으로 운영됩니다.",
  "anthropic/claude-3-opus.description": "Claude 3 Opus는 Anthropic의 가장 지능적인 모델로, 매우 복잡한 작업에서 시장 선도 성능을 발휘하며, 개방형 프롬프트와 새로운 시나리오를 유창하고 사람처럼 이해합니다.",
  "anthropic/claude-3.5-haiku.description": "Claude 3.5 Haiku는 향상된 속도, 코딩 정확도, 도구 활용 능력을 갖춘 모델로, 빠른 응답과 도구 상호작용이 요구되는 시나리오에 적합합니다.",
  "anthropic/claude-3.5-sonnet.description": "Claude 3.5 Sonnet은 Sonnet 계열의 빠르고 효율적인 모델로, 향상된 코딩 및 추론 성능을 제공합니다. 일부 버전은 Sonnet 3.7 이상으로 점진적으로 대체됩니다.",
  "anthropic/claude-3.7-sonnet.description": "Claude 3.7 Sonnet은 향상된 추론 및 코딩 능력을 갖춘 업그레이드된 Sonnet 모델로, 기업 수준의 복잡한 작업에 적합합니다.",
  "anthropic/claude-haiku-4.5.description": "Claude Haiku 4.5는 Anthropic의 고성능 초고속 모델로, 매우 낮은 지연 시간과 높은 정확도를 동시에 제공합니다.",
  "anthropic/claude-opus-4.1.description": "Opus 4.1은 프로그래밍, 복잡한 추론, 장기 작업에 최적화된 Anthropic의 고급 모델입니다.",
  "anthropic/claude-opus-4.5.description": "Claude Opus 4.5는 Anthropic의 플래그십 모델로, 최고 수준의 지능과 확장 가능한 성능을 결합하여 복잡하고 고품질의 추론 작업에 적합합니다.",
  "anthropic/claude-opus-4.description": "Opus 4는 복잡한 작업과 기업용 애플리케이션을 위해 설계된 Anthropic의 플래그십 모델입니다.",
  "anthropic/claude-sonnet-4.5.description": "Claude Sonnet 4.5는 복잡한 추론과 코딩에 최적화된 Anthropic의 최신 하이브리드 추론 모델입니다.",
  "anthropic/claude-sonnet-4.description": "Claude Sonnet 4는 사고 기반과 비사고 기반 기능을 혼합한 하이브리드 추론 모델입니다.",
  "ascend-tribe/pangu-pro-moe.description": "Pangu-Pro-MoE 72B-A16B는 총 72B 파라미터 중 16B가 활성화되는 희소 LLM으로, 그룹화된 MoE(MoGE) 아키텍처를 기반으로 합니다. 전문가를 그룹으로 선택하고 각 그룹당 동일한 수의 전문가를 활성화하여 부하를 균형 있게 분산시키고 Ascend에서의 배포 효율을 향상시킵니다.",
  "aya.description": "Aya 23은 Cohere의 다국어 모델로, 23개 언어를 지원하여 다양한 사용 사례에 활용할 수 있습니다.",
  "aya:35b.description": "Aya 23은 Cohere의 다국어 모델로, 23개 언어를 지원하여 다양한 사용 사례에 활용할 수 있습니다.",
  "azure-DeepSeek-R1-0528.description": "Microsoft가 배포한 DeepSeek R1은 DeepSeek-R1-0528로 업그레이드되었습니다. 이 업데이트는 연산량과 사후 학습 알고리즘을 최적화하여 추론 깊이와 성능을 크게 향상시켰습니다. 수학, 코딩, 일반 논리 벤치마크에서 강력한 성능을 발휘하며, O3 및 Gemini 2.5 Pro와 유사한 수준에 도달합니다.",
  "baichuan-m2-32b.description": "Baichuan M2 32B는 Baichuan Intelligence의 MoE 모델로, 강력한 추론 능력을 갖추고 있습니다.",
  "baichuan/baichuan2-13b-chat.description": "Baichuan-13B는 Baichuan이 개발한 오픈소스 상업용 13B 파라미터 LLM으로, 중국어 및 영어의 권위 있는 벤치마크에서 동급 최고 성능을 달성했습니다.",
  "baidu/ERNIE-4.5-300B-A47B.description": "ERNIE-4.5-300B-A47B는 Baidu의 MoE LLM으로, 총 300B 파라미터 중 토큰당 47B가 활성화됩니다. 뛰어난 성능과 연산 효율의 균형을 이루며, 이해, 생성, 추론, 프로그래밍에 강점을 보입니다. 텍스트-비전 공동 학습을 포함한 멀티모달 이질적 MoE 사전학습 방식을 사용하여 전반적인 능력을 향상시켰습니다.",
  "baidu/ernie-5.0-thinking-preview.description": "ERNIE 5.0 Thinking Preview는 Baidu의 차세대 네이티브 멀티모달 ERNIE 모델로, 멀티모달 이해, 지시 이행, 창작, 사실 기반 질의응답, 도구 호출에 강점을 보입니다.",
  "black-forest-labs/flux-1.1-pro.description": "FLUX 1.1 Pro는 향상된 속도와 이미지 품질, 프롬프트 이행 능력을 갖춘 FLUX Pro의 개선 버전입니다.",
  "black-forest-labs/flux-dev.description": "FLUX Dev는 비상업적 사용을 위한 FLUX의 개발 버전입니다.",
  "black-forest-labs/flux-pro.description": "FLUX Pro는 고품질 이미지 출력을 위한 전문가용 FLUX 모델입니다.",
  "black-forest-labs/flux-schnell.description": "FLUX Schnell은 속도에 최적화된 빠른 이미지 생성 모델입니다.",
  "c4ai-aya-expanse-32b.description": "Aya Expanse는 32B 규모의 고성능 다국어 모델로, 지시 튜닝, 데이터 중재, 선호도 학습, 모델 병합을 통해 단일 언어 모델과 경쟁합니다. 23개 언어를 지원합니다.",
  "c4ai-aya-expanse-8b.description": "Aya Expanse는 8B 규모의 고성능 다국어 모델로, 지시 튜닝, 데이터 중재, 선호도 학습, 모델 병합을 통해 단일 언어 모델과 경쟁합니다. 23개 언어를 지원합니다.",
  "c4ai-aya-vision-32b.description": "Aya Vision은 언어, 텍스트, 비전 벤치마크에서 강력한 성능을 보이는 최첨단 멀티모달 모델입니다. 23개 언어를 지원하며, 이 32B 버전은 최고 수준의 다국어 성능에 중점을 둡니다.",
  "c4ai-aya-vision-8b.description": "Aya Vision은 언어, 텍스트, 비전 벤치마크에서 강력한 성능을 보이는 최첨단 멀티모달 모델입니다. 이 8B 버전은 낮은 지연 시간과 강력한 성능에 중점을 둡니다.",
  "charglm-3.description": "CharGLM-3는 롤플레이와 감정적 교감을 위해 설계된 모델로, 초장기 다중 턴 기억과 개인화된 대화를 지원합니다.",
  "charglm-4.description": "CharGLM-4는 롤플레이와 감정적 교감을 위해 설계된 모델로, 초장기 다중 턴 기억과 개인화된 대화를 지원합니다.",
  "chatgpt-4o-latest.description": "ChatGPT-4o는 실시간으로 업데이트되는 동적 모델로, 고객 지원, 교육, 기술 지원과 같은 대규모 활용 사례를 위한 강력한 이해 및 생성 능력을 결합합니다.",
  "claude-2.0.description": "Claude 2는 업계 최고 수준의 200K 토큰 컨텍스트, 환각 감소, 시스템 프롬프트, 새로운 테스트 기능인 도구 호출을 포함한 주요 엔터프라이즈 기능 향상을 제공합니다.",
  "claude-2.1.description": "Claude 2는 업계 최고 수준의 200K 토큰 컨텍스트, 환각 감소, 시스템 프롬프트, 새로운 테스트 기능인 도구 호출을 포함한 주요 엔터프라이즈 기능 향상을 제공합니다.",
  "claude-3-5-haiku-20241022.description": "Claude 3.5 Haiku는 Anthropic의 차세대 모델 중 가장 빠른 모델로, 다양한 기술에서 향상된 성능을 보이며 이전 플래그십 모델인 Claude 3 Opus를 여러 벤치마크에서 능가합니다.",
  "claude-3-5-haiku-latest.description": "Claude 3.5 Haiku는 가벼운 작업에 빠른 응답을 제공하는 모델입니다.",
  "claude-3-7-sonnet-20250219.description": "Claude Sonnet 3.7은 Anthropic의 가장 지능적인 모델로, 시장 최초의 하이브리드 추론 모델입니다. 즉각적인 응답부터 심화 사고까지 세밀한 제어가 가능하며, 다양한 상황에 유연하게 대응합니다.",
  "claude-3-7-sonnet-latest.description": "Claude 3.7 Sonnet은 Anthropic의 최신이자 가장 강력한 모델로, 고난도 작업에서 뛰어난 성능, 지능, 유창성, 이해력을 자랑합니다.",
  "claude-3-haiku-20240307.description": "Claude 3 Haiku는 Anthropic의 가장 빠르고 컴팩트한 모델로, 빠르고 정확한 성능으로 즉각적인 응답을 위해 설계되었습니다.",
  "claude-3-opus-20240229.description": "Claude 3 Opus는 Anthropic의 가장 강력한 모델로, 고난도 작업에서 뛰어난 성능, 지능, 유창성, 이해력을 자랑합니다.",
  "claude-3-sonnet-20240229.description": "Claude 3 Sonnet은 엔터프라이즈 워크로드를 위한 지능과 속도의 균형을 제공하며, 낮은 비용으로 높은 효용성과 안정적인 대규모 배포를 지원합니다.",
  "claude-haiku-4-5-20251001.description": "Claude Haiku 4.5는 Anthropic의 가장 빠르고 지능적인 Haiku 모델로, 번개 같은 속도와 심화 사고 능력을 갖추고 있습니다.",
  "claude-opus-4-1-20250805-thinking.description": "Claude Opus 4.1 Thinking은 자신의 추론 과정을 드러낼 수 있는 고급 변형 모델입니다.",
  "claude-opus-4-1-20250805.description": "Claude Opus 4.1은 Anthropic의 최신이자 가장 강력한 모델로, 고난도 작업에서 뛰어난 성능, 지능, 유창성, 이해력을 자랑합니다.",
  "claude-opus-4-20250514.description": "Claude Opus 4는 Anthropic의 가장 강력한 모델로, 고난도 작업에서 탁월한 성능, 지능, 유창성, 이해력을 발휘합니다.",
  "claude-opus-4-5-20251101.description": "Claude Opus 4.5는 Anthropic의 플래그십 모델로, 탁월한 지능과 확장 가능한 성능을 결합하여 최고 품질의 응답과 추론이 필요한 복잡한 작업에 이상적입니다.",
  "claude-sonnet-4-20250514-thinking.description": "Claude Sonnet 4 Thinking은 즉각적인 응답 또는 단계별 사고 과정을 시각적으로 보여주는 확장된 사고를 생성할 수 있습니다.",
  "claude-sonnet-4-20250514.description": "Claude Sonnet 4는 현재까지 Anthropic에서 가장 지능적인 모델로, API 사용자에게 세밀한 제어를 제공하며 즉각적인 응답 또는 단계별 사고를 지원합니다.",
  "claude-sonnet-4-5-20250929.description": "Claude Sonnet 4.5는 Anthropic이 지금까지 개발한 가장 지능적인 모델입니다.",
  "codegeex-4.description": "CodeGeeX-4는 다국어 Q&A 및 코드 자동 완성을 지원하여 개발자의 생산성을 높이는 강력한 AI 코딩 도우미입니다.",
  "codegeex4-all-9b.description": "CodeGeeX4-ALL-9B는 코드 자동 완성 및 생성, 코드 인터프리터, 웹 검색, 함수 호출, 저장소 수준의 코드 Q&A를 지원하는 다국어 코드 생성 모델로, 다양한 소프트웨어 개발 시나리오를 포괄합니다. 10B 미만 파라미터 중 최고 수준의 코드 모델입니다.",
  "codegemma.description": "CodeGemma는 다양한 프로그래밍 작업을 위한 경량 모델로, 빠른 반복과 통합을 가능하게 합니다.",
  "codegemma:2b.description": "CodeGemma는 다양한 프로그래밍 작업을 위한 경량 모델로, 빠른 반복과 통합을 가능하게 합니다.",
  "codellama.description": "Code Llama는 코드 생성 및 토론에 중점을 둔 대형 언어 모델로, 개발자 워크플로우를 위한 폭넓은 언어 지원을 제공합니다.",
  "codellama/CodeLlama-34b-Instruct-hf.description": "Code Llama는 코드 생성 및 토론에 중점을 둔 대형 언어 모델로, 개발자 워크플로우를 위한 폭넓은 언어 지원을 제공합니다.",
  "codellama:13b.description": "Code Llama는 코드 생성 및 토론에 중점을 둔 대형 언어 모델로, 개발자 워크플로우를 위한 폭넓은 언어 지원을 제공합니다.",
  "codellama:34b.description": "Code Llama는 코드 생성 및 토론에 중점을 둔 대형 언어 모델로, 개발자 워크플로우를 위한 폭넓은 언어 지원을 제공합니다.",
  "codellama:70b.description": "Code Llama는 코드 생성 및 토론에 중점을 둔 대형 언어 모델로, 개발자 워크플로우를 위한 폭넓은 언어 지원을 제공합니다.",
  "codeqwen.description": "CodeQwen1.5는 방대한 코드 데이터를 기반으로 학습된 대형 언어 모델로, 복잡한 프로그래밍 작업을 위해 설계되었습니다.",
  "codestral-latest.description": "Codestral은 가장 진보된 코딩 모델로, v2(2025년 1월)는 FIM, 코드 수정, 테스트 생성과 같은 저지연 고빈도 작업을 목표로 합니다.",
  "codestral.description": "Codestral은 Mistral AI의 첫 번째 코드 모델로, 강력한 코드 생성 지원을 제공합니다.",
  "codex-mini-latest.description": "codex-mini-latest는 Codex CLI용으로 미세 조정된 o4-mini 모델입니다. API 직접 사용 시 gpt-4.1을 시작점으로 권장합니다.",
  "cogito-2.1:671b.description": "Cogito v2.1 671B는 상업적 사용이 가능한 미국 오픈소스 LLM으로, 최고 수준의 모델과 견줄 수 있는 성능, 높은 토큰 추론 효율성, 128k 긴 컨텍스트, 전반적인 강력한 기능을 갖추고 있습니다.",
  "cogview-4.description": "CogView-4는 중국어 문자를 생성할 수 있는 Zhipu의 첫 오픈소스 텍스트-투-이미지 모델입니다. 의미 이해, 이미지 품질, 중영문 텍스트 렌더링이 향상되었으며, 길이 제한 없는 이중 언어 프롬프트를 지원하고, 지정된 범위 내에서 해상도에 맞는 이미지 생성을 지원합니다.",
  "cohere-command-r-plus.description": "Command R+는 엔터프라이즈 워크로드를 위해 구축된 고급 RAG 최적화 모델입니다.",
  "cohere-command-r.description": "Command R은 RAG 및 도구 사용을 위해 설계된 확장 가능한 생성 모델로, 프로덕션 수준의 AI를 가능하게 합니다.",
  "cohere/Cohere-command-r-plus.description": "Command R+는 엔터프라이즈 워크로드를 위해 구축된 고급 RAG 최적화 모델입니다.",
  "cohere/Cohere-command-r.description": "Command R은 RAG 및 도구 사용을 위해 설계된 확장 가능한 생성 모델로, 프로덕션 수준의 AI를 가능하게 합니다.",
  "cohere/command-a.description": "Command A는 Cohere의 가장 강력한 모델로, 도구 사용, 에이전트, RAG, 다국어 활용 사례에서 뛰어난 성능을 발휘합니다. 256K 컨텍스트 길이를 지원하며, 단 2개의 GPU로 실행 가능하고 Command R+ 08-2024 대비 150% 높은 처리량을 제공합니다.",
  "cohere/command-r-plus.description": "Command R+는 채팅 및 장문 컨텍스트에 최적화된 Cohere의 최신 LLM으로, 기업이 프로토타입을 넘어 실제 프로덕션으로 나아갈 수 있도록 뛰어난 성능을 목표로 합니다.",
  "cohere/command-r.description": "Command R은 채팅 및 장문 컨텍스트 작업에 최적화된 모델로, 높은 성능과 정확성의 균형을 이루며 기업이 프로토타입을 넘어 프로덕션으로 진입할 수 있도록 설계되었습니다.",
  "cohere/embed-v4.0.description": "텍스트, 이미지 또는 혼합 콘텐츠를 임베딩으로 분류하거나 변환하는 모델입니다.",
  "comfyui/flux-dev.description": "FLUX.1 Dev는 고품질의 텍스트-이미지 생성 모델로, 10~50단계 내에서 프리미엄 창작 및 예술적 결과물에 적합합니다.",
  "comfyui/flux-kontext-dev.description": "FLUX.1 Kontext-dev는 텍스트 기반 편집을 지원하는 이미지 편집 모델로, 국소 편집 및 스타일 전환 기능을 포함합니다.",
  "comfyui/flux-krea-dev.description": "FLUX.1 Krea-dev는 Krea와 공동 개발한 안전성이 강화된 텍스트-이미지 생성 모델로, 내장된 안전 필터를 제공합니다.",
  "comfyui/flux-schnell.description": "FLUX.1 Schnell은 1~4단계 내에서 고품질 이미지를 초고속으로 생성하는 텍스트-이미지 모델로, 실시간 사용 및 빠른 프로토타이핑에 이상적입니다.",
  "comfyui/stable-diffusion-15.description": "Stable Diffusion 1.5는 512x512 해상도의 클래식 텍스트-이미지 생성 모델로, 빠른 프로토타이핑 및 창의적 실험에 적합합니다.",
  "comfyui/stable-diffusion-35-inclclip.description": "Stable Diffusion 3.5는 내장된 CLIP/T5 인코더를 포함하여 외부 인코더 파일이 필요 없는 모델로, sd3.5_medium_incl_clips와 같은 저자원 모델에 적합합니다.",
  "comfyui/stable-diffusion-35.description": "Stable Diffusion 3.5는 차세대 텍스트-이미지 생성 모델로, Large 및 Medium 버전이 있으며 외부 CLIP 인코더 파일이 필요합니다. 뛰어난 이미지 품질과 프롬프트 반응성을 제공합니다.",
  "comfyui/stable-diffusion-custom-refiner.description": "사용자 정의 SDXL 이미지-이미지 모델입니다. 모델 파일명은 custom_sd_lobe.safetensors를 사용하고, VAE가 있다면 custom_sd_vae_lobe.safetensors를 사용하세요. 모델 파일은 Comfy의 지정된 폴더에 배치해야 합니다.",
  "comfyui/stable-diffusion-custom.description": "사용자 정의 SD 텍스트-이미지 생성 모델입니다. 모델 파일명은 custom_sd_lobe.safetensors를 사용하고, VAE가 있다면 custom_sd_vae_lobe.safetensors를 사용하세요. 모델 파일은 Comfy의 지정된 폴더에 배치해야 합니다.",
  "comfyui/stable-diffusion-refiner.description": "SDXL 이미지-이미지 모델로, 입력 이미지를 고품질로 변환하며 스타일 전환, 복원, 창의적 변형을 지원합니다.",
  "comfyui/stable-diffusion-xl.description": "SDXL은 1024x1024 고해상도 생성을 지원하는 텍스트-이미지 모델로, 향상된 이미지 품질과 세부 묘사를 제공합니다.",
  "command-a-03-2025.description": "Command A는 지금까지 가장 강력한 모델로, 도구 사용, 에이전트, RAG, 다국어 시나리오에서 뛰어난 성능을 발휘합니다. 256K 컨텍스트 윈도우를 지원하며, 단 2개의 GPU로 실행 가능하고 Command R+ 08-2024 대비 150% 높은 처리량을 제공합니다.",
  "command-light-nightly.description": "주요 릴리스 간의 간격을 줄이기 위해, 매일 업데이트되는 Command 빌드를 제공합니다. command-light 시리즈의 경우 이를 command-light-nightly라고 하며, 가장 최신이자 실험적인(그리고 불안정할 수 있는) 버전입니다. 정기적으로 예고 없이 업데이트되므로, 프로덕션 환경에서는 사용을 권장하지 않습니다.",
  "command-light.description": "거의 동일한 성능을 유지하면서도 더 빠른 속도를 제공하는 소형 Command 변형 모델입니다.",
  "command-nightly.description": "주요 릴리스 간의 간격을 줄이기 위해, 매일 업데이트되는 Command 빌드를 제공합니다. Command 시리즈의 경우 이를 command-nightly라고 하며, 가장 최신이자 실험적인(그리고 불안정할 수 있는) 버전입니다. 정기적으로 예고 없이 업데이트되므로, 프로덕션 환경에서는 사용을 권장하지 않습니다.",
  "command-r-03-2024.description": "Command R은 이전 모델보다 더 높은 품질과 신뢰성, 더 긴 컨텍스트 윈도우를 제공하는 지시문 기반 채팅 모델입니다. 코드 생성, RAG, 도구 사용, 에이전트 등 복잡한 워크플로우를 지원합니다.",
  "command-r-08-2024.description": "command-r-08-2024는 2024년 8월에 출시된 Command R 모델의 업데이트 버전입니다.",
  "command-r-plus-04-2024.description": "command-r-plus는 command-r-plus-04-2024의 별칭으로, API에서 command-r-plus를 사용하면 해당 모델을 가리킵니다.",
  "command-r-plus-08-2024.description": "Command R+는 이전 모델보다 더 높은 품질과 신뢰성, 더 긴 컨텍스트 윈도우를 제공하는 지시문 기반 채팅 모델입니다. 복잡한 RAG 워크플로우와 다단계 도구 사용에 최적화되어 있습니다.",
  "command-r-plus.description": "Command R+는 실제 기업 환경과 복잡한 애플리케이션을 위한 고성능 LLM입니다.",
  "command-r.description": "Command R은 채팅 및 장문 컨텍스트 작업에 최적화된 LLM으로, 동적인 상호작용과 지식 관리에 이상적입니다.",
  "command-r7b-12-2024.description": "command-r7b-12-2024는 2024년 12월에 출시된 소형이면서 효율적인 업데이트 모델입니다. 복잡한 다단계 추론이 필요한 RAG, 도구 사용, 에이전트 작업에 뛰어납니다.",
  "command.description": "기본 생성 모델보다 더 높은 품질과 신뢰성을 제공하며, 더 긴 컨텍스트 윈도우를 지원하는 지시문 기반 채팅 모델입니다.",
  "computer-use-preview.description": "computer-use-preview는 '컴퓨터 사용 도구'에 특화된 모델로, 컴퓨터 관련 작업을 이해하고 실행하도록 훈련되었습니다.",
  "dall-e-2.description": "1세대보다 4배 높은 해상도와 더 사실적이고 정확한 이미지 생성을 지원하는 2세대 DALL·E 모델입니다.",
  "dall-e-3.description": "2023년 11월에 출시된 최신 DALL·E 모델로, 더 사실적이고 정밀한 이미지 생성을 지원합니다.",
  "databricks/dbrx-instruct.description": "DBRX Instruct는 다양한 산업 분야에서 신뢰도 높은 지시문 처리를 제공합니다.",
  "deepseek-ai/DeepSeek-OCR.description": "DeepSeek-OCR은 DeepSeek AI에서 개발한 비전-언어 모델로, OCR 및 '문맥 광학 압축'에 중점을 둡니다. 이미지에서 문맥을 압축하고 문서를 효율적으로 처리하여 구조화된 텍스트(예: Markdown)로 변환합니다. 이미지 내 텍스트를 정확하게 인식하여 문서 디지털화, 텍스트 추출, 구조화 처리에 적합합니다.",
  "deepseek-ai/DeepSeek-R1-0528-Qwen3-8B.description": "DeepSeek-R1-0528-Qwen3-8B는 DeepSeek-R1-0528의 체인 오브 싱킹을 Qwen3 8B Base에 증류한 모델입니다. AIME 2024에서 Qwen3 8B보다 10% 높은 성능을 기록하며, Qwen3-235B-thinking과 동급의 성능을 보여줍니다. 수학 추론, 프로그래밍, 일반 논리 벤치마크에서 뛰어나며, Qwen3-8B 아키텍처를 공유하면서 DeepSeek-R1-0528 토크나이저를 사용합니다.",
  "deepseek-ai/DeepSeek-R1-0528.description": "DeepSeek R1은 추가 연산 자원과 사후 학습 알고리즘 최적화를 활용하여 추론 능력을 강화합니다. 수학, 프로그래밍, 일반 논리 벤치마크에서 강력한 성능을 발휘하며, o3 및 Gemini 2.5 Pro와 같은 선도 모델에 근접합니다.",
  "deepseek-ai/DeepSeek-R1-Distill-Llama-70B.description": "DeepSeek-R1 증류 모델은 RL 및 콜드 스타트 데이터를 활용하여 추론 능력을 향상시키고, 새로운 오픈 모델 멀티태스크 벤치마크를 설정합니다.",
  "deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B.description": "DeepSeek-R1 증류 모델은 RL 및 콜드 스타트 데이터를 활용하여 추론 능력을 향상시키고, 새로운 오픈 모델 멀티태스크 벤치마크를 설정합니다.",
  "deepseek-ai/DeepSeek-R1-Distill-Qwen-14B.description": "DeepSeek-R1 증류 모델은 RL 및 콜드 스타트 데이터를 활용하여 추론 능력을 향상시키고, 새로운 오픈 모델 멀티태스크 벤치마크를 설정합니다.",
  "deepseek-ai/DeepSeek-R1-Distill-Qwen-32B.description": "DeepSeek-R1-Distill-Qwen-32B는 Qwen2.5-32B에서 증류되었으며, 80만 개의 DeepSeek-R1 정제 샘플로 미세 조정되었습니다. 수학, 프로그래밍, 추론에서 뛰어난 성능을 보이며, AIME 2024, MATH-500(정확도 94.3%), GPQA Diamond에서 우수한 결과를 기록합니다.",
  "deepseek-ai/DeepSeek-R1-Distill-Qwen-7B.description": "DeepSeek-R1-Distill-Qwen-7B는 Qwen2.5-Math-7B에서 증류되었으며, 80만 개의 DeepSeek-R1 정제 샘플로 미세 조정되었습니다. MATH-500에서 92.8%, AIME 2024에서 55.5%, CodeForces에서 1189점을 기록하며 7B 모델 중 뛰어난 성능을 보입니다.",
  "deepseek-ai/DeepSeek-R1.description": "DeepSeek-R1은 RL 및 콜드 스타트 데이터를 활용하여 추론 능력을 향상시키며, 새로운 오픈 모델 멀티태스크 벤치마크를 설정하고 OpenAI-o1-mini를 능가합니다.",
  "deepseek-ai/DeepSeek-V2.5.description": "DeepSeek-V2.5는 DeepSeek-V2-Chat과 DeepSeek-Coder-V2-Instruct를 업그레이드하여 일반 및 코딩 능력을 통합합니다. 글쓰기 및 지시문 이행 능력을 향상시켜 선호도 정렬을 개선하며, AlpacaEval 2.0, ArenaHard, AlignBench, MT-Bench에서 큰 성능 향상을 보입니다.",
  "deepseek-ai/DeepSeek-V3.1-Terminus.description": "DeepSeek-V3.1-Terminus는 하이브리드 에이전트 LLM으로 포지셔닝된 V3.1 모델의 업데이트 버전입니다. 사용자 피드백 문제를 해결하고 안정성, 언어 일관성, 중문/영문 혼합 및 비정상 문자 출력을 개선합니다. 사고 및 비사고 모드를 통합하고 채팅 템플릿을 통해 유연하게 전환할 수 있으며, Code Agent 및 Search Agent 성능도 향상되어 도구 사용 및 다단계 작업에서 더 높은 신뢰성을 제공합니다.",
  "deepseek-ai/DeepSeek-V3.1.description": "DeepSeek V3.1은 하이브리드 추론 아키텍처를 사용하며, 사고 모드와 비사고 모드를 모두 지원합니다.",
  "deepseek-ai/DeepSeek-V3.2-Exp.description": "DeepSeek-V3.2-Exp는 차세대 아키텍처로의 전환을 위한 실험적 V3.2 릴리스입니다. V3.1-Terminus 위에 DeepSeek Sparse Attention(DSA)을 추가하여 긴 문맥 학습 및 추론 효율성을 향상시켰으며, 도구 사용, 장문 문서 이해, 다단계 추론에 최적화되어 있습니다. 대규모 문맥 처리 예산 하에서 고차원 추론 효율성을 탐색하기에 이상적입니다.",
  "deepseek-ai/DeepSeek-V3.description": "DeepSeek-V3는 MLA와 DeepSeekMoE를 기반으로 손실 없는 부하 분산을 구현한 671B 파라미터의 MoE 모델입니다. 14.8T 고품질 토큰으로 사전 학습되었으며 SFT와 RL을 통해 미세 조정되어, 다른 오픈 모델을 능가하고 주요 폐쇄형 모델에 근접한 성능을 보입니다.",
  "deepseek-ai/deepseek-llm-67b-chat.description": "DeepSeek LLM Chat (67B)은 심층 언어 이해와 상호작용을 제공하는 혁신적인 모델입니다.",
  "deepseek-ai/deepseek-r1.description": "최신 기술을 반영한 고효율 LLM으로, 추론, 수학, 프로그래밍에 강점을 보입니다.",
  "deepseek-ai/deepseek-v3.1-terminus.description": "DeepSeek V3.1은 복잡한 추론과 사고의 흐름(chain-of-thought)에 강한 차세대 추론 모델로, 심층 분석 작업에 적합합니다.",
  "deepseek-ai/deepseek-v3.1.description": "DeepSeek V3.1은 복잡한 추론과 사고의 흐름(chain-of-thought)에 강한 차세대 추론 모델로, 심층 분석 작업에 적합합니다.",
  "deepseek-ai/deepseek-vl2.description": "DeepSeek-VL2는 DeepSeekMoE-27B 기반의 MoE 비전-언어 모델로, 희소 활성화를 통해 4.5B 활성 파라미터만으로도 뛰어난 성능을 발휘합니다. 시각적 질의응답, OCR, 문서/표/차트 이해, 시각적 정렬에 탁월합니다.",
  "deepseek-chat.description": "DeepSeek V3.2는 일상적인 질의응답 및 에이전트 작업을 위해 추론 능력과 출력 길이의 균형을 맞춘 모델입니다. 공개 벤치마크에서 GPT-5 수준에 도달했으며, 도구 사용에 사고 과정을 통합한 최초의 모델로, 오픈소스 에이전트 평가에서 선도적인 성과를 보입니다.",
  "deepseek-coder-33B-instruct.description": "DeepSeek Coder 33B는 2T 토큰(코드 87%, 중/영문 텍스트 13%)으로 학습된 코드 언어 모델입니다. 16K 문맥 창과 중간 채우기(fit-in-the-middle) 작업을 도입하여 프로젝트 수준의 코드 완성과 코드 조각 보완을 지원합니다.",
  "deepseek-coder-v2.description": "DeepSeek Coder V2는 오픈소스 MoE 코드 모델로, GPT-4 Turbo에 필적하는 뛰어난 코딩 성능을 자랑합니다.",
  "deepseek-coder-v2:236b.description": "DeepSeek Coder V2는 오픈소스 MoE 코드 모델로, GPT-4 Turbo에 필적하는 뛰어난 코딩 성능을 자랑합니다.",
  "deepseek-ocr.description": "DeepSeek-OCR은 DeepSeek AI가 개발한 비전-언어 모델로, OCR과 '문맥 기반 광학 압축'에 중점을 둡니다. 이미지에서 문맥 정보를 압축하고 문서를 효율적으로 처리하여 Markdown과 같은 구조화된 텍스트 형식으로 변환합니다. 이미지 내 텍스트를 정확하게 인식하여 문서 디지털화, 텍스트 추출, 구조화 처리에 적합합니다.",
  "deepseek-r1-0528.description": "2025년 5월 28일에 공개된 685B 전체 모델입니다. DeepSeek-R1은 사후 학습에서 대규모 강화 학습을 활용하여 소량의 라벨 데이터로도 추론 능력을 크게 향상시켰으며, 수학, 코딩, 자연어 추론에서 뛰어난 성능을 보입니다.",
  "deepseek-r1-250528.description": "DeepSeek R1 250528은 고난도 수학 및 논리 작업을 위한 DeepSeek-R1 전체 추론 모델입니다.",
  "deepseek-r1-70b-fast-online.description": "DeepSeek R1 70B의 빠른 버전으로, 실시간 웹 검색을 지원하며 성능을 유지하면서 더 빠른 응답을 제공합니다.",
  "deepseek-r1-70b-online.description": "DeepSeek R1 70B 표준 버전으로, 실시간 웹 검색을 지원하며 최신 대화 및 텍스트 작업에 적합합니다.",
  "deepseek-r1-distill-llama-70b.description": "DeepSeek R1 Distill Llama 70B는 R1 추론을 Llama 생태계와 결합한 모델입니다.",
  "deepseek-r1-distill-llama-8b.description": "DeepSeek-R1-Distill-Llama-8B는 DeepSeek R1의 출력을 기반으로 Llama-3.1-8B에서 증류된 모델입니다.",
  "deepseek-r1-distill-llama.description": "deepseek-r1-distill-llama는 DeepSeek-R1을 Llama에 증류한 모델입니다.",
  "deepseek-r1-distill-qianfan-70b.description": "DeepSeek R1 Distill Qianfan 70B는 Qianfan-70B를 기반으로 한 R1 증류 모델로, 높은 가치의 성능을 제공합니다.",
  "deepseek-r1-distill-qianfan-8b.description": "DeepSeek R1 Distill Qianfan 8B는 Qianfan-8B를 기반으로 한 R1 증류 모델로, 중소형 애플리케이션에 적합합니다.",
  "deepseek-r1-distill-qianfan-llama-70b.description": "DeepSeek R1 Distill Qianfan Llama 70B는 Llama-70B를 기반으로 한 R1 증류 모델입니다.",
  "deepseek-r1-distill-qwen-1.5b.description": "DeepSeek R1 Distill Qwen 1.5B는 매우 저자원 환경을 위한 초경량 증류 모델입니다.",
  "deepseek-r1-distill-qwen-14b.description": "DeepSeek R1 Distill Qwen 14B는 다양한 시나리오에 배포 가능한 중형 증류 모델입니다.",
  "deepseek-r1-distill-qwen-32b.description": "DeepSeek R1 Distill Qwen 32B는 Qwen-32B를 기반으로 한 R1 증류 모델로, 성능과 비용의 균형을 이룹니다.",
  "deepseek-r1-distill-qwen-7b.description": "DeepSeek R1 Distill Qwen 7B는 엣지 및 프라이빗 기업 환경을 위한 경량 증류 모델입니다.",
  "deepseek-r1-distill-qwen.description": "deepseek-r1-distill-qwen은 DeepSeek-R1을 Qwen에 증류한 모델입니다.",
  "deepseek-r1-fast-online.description": "DeepSeek R1의 빠른 전체 버전으로, 실시간 웹 검색을 지원하며 671B 규모의 성능과 빠른 응답을 결합합니다.",
  "deepseek-r1-online.description": "DeepSeek R1 전체 버전은 671B 파라미터와 실시간 웹 검색을 지원하여 더 강력한 이해 및 생성 능력을 제공합니다.",
  "deepseek-r1.description": "DeepSeek-R1은 강화 학습 이전에 콜드 스타트 데이터를 사용하며, 수학, 코딩, 추론 작업에서 OpenAI-o1과 유사한 성능을 보입니다.",
  "deepseek-reasoner.description": "DeepSeek V3.2 Thinking은 출력 전에 사고 과정을 생성하여 정확도를 높이는 심층 추론 모델입니다. 주요 대회에서 상위권 성적을 기록하며, Gemini-3.0-Pro에 필적하는 추론 능력을 보입니다.",
  "deepseek-v2.description": "DeepSeek V2는 비용 효율적인 처리를 위한 고효율 MoE 모델입니다.",
  "deepseek-v2:236b.description": "DeepSeek V2 236B는 코드 생성에 강점을 가진 DeepSeek의 코드 특화 모델입니다.",
  "deepseek-v3-0324.description": "DeepSeek-V3-0324는 671B 파라미터의 MoE 모델로, 프로그래밍 및 기술적 역량, 문맥 이해, 장문 처리에서 뛰어난 성능을 보입니다.",
  "deepseek-v3.1-terminus.description": "DeepSeek-V3.1-Terminus는 터미널 장치에 최적화된 DeepSeek의 LLM으로, 터미널 환경에 맞춰 설계되었습니다.",
  "deepseek-v3.1-think-250821.description": "DeepSeek V3.1 Think 250821은 Terminus 버전에 대응하는 심층 사고 모델로, 고성능 추론을 위해 구축되었습니다.",
  "deepseek-v3.1.description": "DeepSeek-V3.1은 DeepSeek의 새로운 하이브리드 추론 모델로, 사고 모드와 비사고 모드를 모두 지원하며, DeepSeek-R1-0528보다 더 높은 사고 효율을 제공합니다. 사후 학습 최적화를 통해 에이전트 도구 사용 및 작업 수행 능력이 크게 향상되었습니다. 128k 컨텍스트 윈도우와 최대 64k 출력 토큰을 지원합니다.",
  "deepseek-v3.1:671b.description": "DeepSeek V3.1은 복잡한 추론과 연쇄 사고 능력이 향상된 차세대 추론 모델로, 심층 분석이 필요한 작업에 적합합니다.",
  "deepseek-v3.2-exp.description": "deepseek-v3.2-exp는 희소 어텐션(sparse attention)을 도입하여 긴 텍스트에 대한 학습 및 추론 효율을 개선하였으며, deepseek-v3.1보다 저렴한 가격으로 제공됩니다.",
  "deepseek-v3.2-think.description": "DeepSeek V3.2 Think는 장기 연쇄 추론 능력이 강화된 완전 심층 사고 모델입니다.",
  "deepseek-v3.2.description": "DeepSeek-V3.2는 DeepSeek가 출시한 최초의 도구 사용에 사고를 통합한 하이브리드 추론 모델로, 효율적인 아키텍처로 연산 자원을 절약하고, 대규모 강화 학습으로 능력을 향상시키며, 대규모 합성 작업 데이터를 통해 일반화 성능을 강화합니다. 이 세 가지 요소의 결합으로 GPT-5-High에 필적하는 성능을 제공하며, 출력 길이를 대폭 줄여 계산 비용과 사용자 대기 시간을 현저히 감소시켰습니다.",
  "deepseek-v3.description": "DeepSeek-V3는 총 671B 파라미터 중 토큰당 37B가 활성화되는 강력한 MoE 모델입니다.",
  "deepseek-vl2-small.description": "DeepSeek VL2 Small은 자원이 제한되거나 동시 접속이 많은 환경을 위한 경량 멀티모달 버전입니다.",
  "deepseek-vl2.description": "DeepSeek VL2는 이미지-텍스트 이해와 정밀한 시각적 질의응답에 특화된 멀티모달 모델입니다.",
  "deepseek/deepseek-chat-v3-0324.description": "DeepSeek V3는 685B 파라미터를 가진 MoE 모델로, DeepSeek의 대표 챗봇 시리즈의 최신 버전입니다.\n\n[DeepSeek V3](/deepseek/deepseek-chat-v3)를 기반으로 다양한 작업에서 뛰어난 성능을 발휘합니다.",
  "deepseek/deepseek-chat-v3-0324:free.description": "DeepSeek V3는 685B 파라미터를 가진 MoE 모델로, DeepSeek의 대표 챗봇 시리즈의 최신 버전입니다.\n\n[DeepSeek V3](/deepseek/deepseek-chat-v3)를 기반으로 다양한 작업에서 뛰어난 성능을 발휘합니다.",
  "deepseek/deepseek-chat-v3.1.description": "DeepSeek-V3.1은 DeepSeek의 장문 컨텍스트 하이브리드 추론 모델로, 사고/비사고 모드 전환과 도구 통합을 지원합니다.",
  "deepseek/deepseek-chat.description": "DeepSeek-V3는 복잡한 작업과 도구 통합을 위한 DeepSeek의 고성능 하이브리드 추론 모델입니다.",
  "deepseek/deepseek-r1-0528.description": "DeepSeek R1 0528은 공개 사용성과 심층 추론에 중점을 둔 업데이트 버전입니다.",
  "deepseek/deepseek-r1-0528:free.description": "DeepSeek-R1은 최소한의 라벨링 데이터로도 추론 능력을 크게 향상시키며, 최종 답변 전에 사고 과정을 출력하여 정확도를 높입니다.",
  "deepseek/deepseek-r1-distill-llama-70b.description": "DeepSeek R1 Distill Llama 70B는 Llama 3.3 70B를 기반으로 DeepSeek R1의 출력으로 파인튜닝된 디스틸 LLM으로, 대형 최첨단 모델과 경쟁할 수 있는 성능을 제공합니다.",
  "deepseek/deepseek-r1-distill-llama-8b.description": "DeepSeek R1 Distill Llama 8B는 Llama-3.1-8B-Instruct를 기반으로 DeepSeek R1의 출력으로 학습된 디스틸 LLM입니다.",
  "deepseek/deepseek-r1-distill-qwen-14b.description": "DeepSeek R1 Distill Qwen 14B는 Qwen 2.5 14B를 기반으로 DeepSeek R1의 출력으로 학습된 디스틸 LLM입니다. OpenAI o1-mini를 여러 벤치마크에서 능가하며, 밀집 모델 중 최고 성능을 기록합니다. 주요 벤치마크:\nAIME 2024 pass@1: 69.7\nMATH-500 pass@1: 93.9\nCodeForces Rating: 1481\nDeepSeek R1 출력으로 파인튜닝하여 대형 모델과 경쟁 가능한 성능을 제공합니다.",
  "deepseek/deepseek-r1-distill-qwen-32b.description": "DeepSeek R1 Distill Qwen 32B는 Qwen 2.5 32B를 기반으로 DeepSeek R1의 출력으로 학습된 디스틸 LLM입니다. OpenAI o1-mini를 여러 벤치마크에서 능가하며, 밀집 모델 중 최고 성능을 기록합니다. 주요 벤치마크:\nAIME 2024 pass@1: 72.6\nMATH-500 pass@1: 94.3\nCodeForces Rating: 1691\nDeepSeek R1 출력으로 파인튜닝하여 대형 모델과 경쟁 가능한 성능을 제공합니다.",
  "deepseek/deepseek-r1.description": "DeepSeek R1은 DeepSeek-R1-0528로 업데이트되었습니다. 더 많은 연산 자원과 사후 학습 알고리즘 최적화를 통해 추론 깊이와 능력이 크게 향상되었습니다. 수학, 프로그래밍, 일반 논리 벤치마크에서 뛰어난 성능을 보이며, o3 및 Gemini 2.5 Pro와 같은 선도 모델에 근접합니다.",
  "deepseek/deepseek-r1/community.description": "DeepSeek R1은 DeepSeek 팀이 공개한 최신 오픈소스 모델로, 수학, 코딩, 추론 작업에서 매우 강력한 성능을 발휘하며, OpenAI o1과 견줄 수 있습니다.",
  "deepseek/deepseek-r1:free.description": "DeepSeek-R1은 최소한의 라벨링 데이터로도 추론 능력을 크게 향상시키며, 최종 답변 전에 사고 과정을 출력하여 정확도를 높입니다.",
  "deepseek/deepseek-reasoner.description": "DeepSeek-V3 Thinking (reasoner)은 DeepSeek의 실험적 추론 모델로, 고난도 복잡 추론 작업에 적합합니다.",
  "deepseek/deepseek-v3.1-base.description": "DeepSeek V3.1 Base는 DeepSeek V3 모델의 개선 버전입니다.",
  "deepseek/deepseek-v3.description": "추론 능력이 향상된 고속 범용 LLM입니다.",
  "deepseek/deepseek-v3/community.description": "DeepSeek-V3는 이전 모델 대비 추론 속도에서 획기적인 발전을 이루었습니다. 오픈소스 모델 중 1위를 기록하며, 최고 수준의 폐쇄형 모델과 경쟁합니다. DeepSeek-V3는 DeepSeek-V2에서 검증된 Multi-Head Latent Attention (MLA)과 DeepSeekMoE 아키텍처를 채택하였으며, 부하 균형을 위한 무손실 보조 전략과 다중 토큰 예측 학습 목표를 도입하여 성능을 강화했습니다.",
  "deepseek_r1.description": "DeepSeek-R1은 반복성과 가독성 문제를 해결하기 위해 강화 학습 기반으로 설계된 추론 모델입니다. RL 이전에는 cold-start 데이터를 활용하여 추론 성능을 더욱 향상시킵니다. 수학, 코딩, 추론 작업에서 OpenAI-o1과 대등한 성능을 보이며, 정교한 학습 설계로 전반적인 결과를 개선합니다.",
  "deepseek_r1_distill_llama_70b.description": "DeepSeek-R1-Distill-Llama-70B는 Llama-3.3-70B-Instruct에서 디스틸된 모델로, DeepSeek-R1 시리즈의 일부입니다. DeepSeek-R1이 생성한 샘플로 파인튜닝되어 수학, 코딩, 추론에서 뛰어난 성능을 발휘합니다.",
  "deepseek_r1_distill_qwen_14b.description": "DeepSeek-R1-Distill-Qwen-14B는 Qwen2.5-14B에서 디스틸되었으며, DeepSeek-R1이 생성한 80만 개의 정제된 샘플로 파인튜닝되어 강력한 추론 능력을 제공합니다.",
  "deepseek_r1_distill_qwen_32b.description": "DeepSeek-R1-Distill-Qwen-32B는 Qwen2.5-32B에서 디스틸되었으며, DeepSeek-R1이 생성한 80만 개의 정제된 샘플로 파인튜닝되어 수학, 코딩, 추론에서 탁월한 성능을 발휘합니다.",
  "devstral-2:123b.description": "Devstral 2 123B는 코드베이스 탐색, 다중 파일 편집, 소프트웨어 엔지니어링 에이전트 지원에 탁월한 도구 활용 능력을 갖춘 모델입니다.",
  "doubao-1.5-lite-32k.description": "Doubao-1.5-lite는 초고속 응답을 제공하는 경량 모델로, 최고 수준의 품질과 지연 시간을 자랑합니다.",
  "doubao-1.5-pro-256k.description": "Doubao-1.5-pro-256k는 Doubao-1.5-Pro의 전면 업그레이드 버전으로, 전체 성능이 10% 향상되었습니다. 256k 컨텍스트 윈도우와 최대 12k 출력 토큰을 지원하며, 더 넓은 활용 사례에 적합한 고성능과 가성비를 제공합니다.",
  "doubao-1.5-pro-32k.description": "Doubao-1.5-pro는 지식, 코딩, 추론 전반에서 뛰어난 성능을 보이는 차세대 플래그십 모델입니다.",
  "doubao-1.5-thinking-pro-m.description": "Doubao-1.5는 수학, 코딩, 과학적 추론, 창의적 글쓰기 등 일반 작업에서 뛰어난 성능을 보이는 심층 추론 모델입니다. m 버전은 멀티모달 심층 추론을 기본으로 포함하며, AIME 2024, Codeforces, GPQA 등 주요 벤치마크에서 최고 수준의 결과를 달성하거나 근접합니다. 128k 컨텍스트 윈도우와 16k 출력 토큰을 지원합니다.",
  "doubao-1.5-thinking-pro.description": "Doubao-1.5는 수학, 코딩, 과학적 추론, 창의적 글쓰기 등 일반 작업에서 뛰어난 성능을 보이는 심층 추론 모델입니다. AIME 2024, Codeforces, GPQA 등 주요 벤치마크에서 최고 수준의 결과를 달성하거나 근접하며, 128k 컨텍스트 윈도우와 16k 출력 토큰을 지원합니다.",
  "doubao-1.5-thinking-vision-pro.description": "더 강력한 멀티모달 이해 및 추론 능력을 갖춘 새로운 시각 심층 추론 모델로, 59개 공개 벤치마크 중 37개에서 SOTA 성과를 달성했습니다.",
  "doubao-1.5-ui-tars.description": "Doubao-1.5-UI-TARS는 GUI 중심의 네이티브 에이전트 모델로, 인간과 유사한 인지, 추론, 행동을 통해 인터페이스와 자연스럽게 상호작용합니다.",
  "doubao-1.5-vision-lite.description": "Doubao-1.5-vision-lite는 모든 해상도 및 극단적인 종횡비의 이미지를 지원하는 업그레이드된 멀티모달 모델로, 시각적 추론, 문서 인식, 세부 이해, 지시 따르기 능력을 향상시킵니다. 128k 컨텍스트 윈도우와 최대 16k 출력 토큰을 지원합니다.",
  "doubao-1.5-vision-pro-32k.description": "Doubao-1.5-vision-pro는 모든 해상도 및 극단적인 종횡비의 이미지를 지원하는 업그레이드된 멀티모달 모델로, 시각적 추론, 문서 인식, 세부 이해, 지시 따르기 능력을 향상시킵니다.",
  "doubao-1.5-vision-pro.description": "Doubao-1.5-vision-pro는 모든 해상도 및 극단적인 종횡비의 이미지를 지원하는 업그레이드된 멀티모달 모델로, 시각적 추론, 문서 인식, 세부 이해, 지시 따르기 능력을 향상시킵니다.",
  "doubao-lite-128k.description": "초고속 응답과 뛰어난 가성비를 제공하며, 다양한 상황에서 유연한 선택이 가능합니다. 128k 컨텍스트 윈도우를 지원하며 추론 및 파인튜닝이 가능합니다.",
  "doubao-lite-32k.description": "초고속 응답과 뛰어난 가성비를 제공하며, 다양한 상황에서 유연한 선택이 가능합니다. 32k 컨텍스트 윈도우를 지원하며 추론 및 파인튜닝이 가능합니다.",
  "doubao-lite-4k.description": "초고속 응답과 뛰어난 가성비를 제공하며, 다양한 상황에서 유연한 선택이 가능합니다. 4k 컨텍스트 윈도우를 지원하며 추론 및 파인튜닝이 가능합니다.",
  "doubao-pro-256k.description": "복잡한 작업을 위한 최고 성능의 플래그십 모델로, 참조 기반 질의응답, 요약, 창작, 텍스트 분류, 롤플레이 등에서 강력한 성과를 보입니다. 256k 컨텍스트 윈도우를 지원하며 추론 및 파인튜닝이 가능합니다.",
  "doubao-pro-32k.description": "복잡한 작업을 위한 최고 성능의 플래그십 모델로, 참조 기반 질의응답, 요약, 창작, 텍스트 분류, 롤플레이 등에서 강력한 성과를 보입니다. 32k 컨텍스트 윈도우를 지원하며 추론 및 파인튜닝이 가능합니다.",
  "doubao-seed-1.6-flash.description": "Doubao-Seed-1.6-flash는 TPOT 10ms 수준의 초고속 멀티모달 심층 추론 모델입니다. 텍스트와 시각 입력을 모두 지원하며, 텍스트 이해는 이전 lite 모델을 능가하고, 시각 성능은 경쟁 pro 모델과 동등합니다. 256k 컨텍스트 윈도우와 최대 16k 출력 토큰을 지원합니다.",
  "doubao-seed-1.6-lite.description": "Doubao-Seed-1.6-lite는 추론 강도를 조절할 수 있는 새로운 멀티모달 심층 추론 모델로, 일반 작업에 적합한 가성비 높은 선택지를 제공합니다. 최대 256k 컨텍스트 윈도우를 지원합니다.",
  "doubao-seed-1.6-thinking.description": "Doubao-Seed-1.6-thinking은 Doubao-1.5-thinking-pro보다 코딩, 수학, 논리 추론의 핵심 능력을 더욱 강화하고 시각 이해 기능을 추가한 모델입니다. 256k 컨텍스트 윈도우와 최대 16k 출력 토큰을 지원합니다.",
  "doubao-seed-1.6-vision.description": "Doubao-Seed-1.6-vision은 교육, 이미지 리뷰, 검사/보안, AI 검색 질의응답 등에서 강력한 멀티모달 이해 및 추론을 제공하는 시각 심층 추론 모델입니다. 256k 컨텍스트 윈도우와 최대 64k 출력 토큰을 지원합니다.",
  "doubao-seed-1.6.description": "Doubao-Seed-1.6은 자동, 사고, 비사고 모드를 지원하는 새로운 멀티모달 심층 추론 모델입니다. 비사고 모드에서는 Doubao-1.5-pro/250115보다 현저히 뛰어난 성능을 보입니다. 256k 컨텍스트 윈도우와 최대 16k 출력 토큰을 지원합니다.",
  "doubao-seed-1.8.description": "Doubao-Seed-1.8은 더 강력한 멀티모달 이해력과 에이전트 능력을 갖추고 있으며, 텍스트/이미지/비디오 입력과 컨텍스트 캐시를 지원하여 복잡한 작업에서 뛰어난 성능을 발휘합니다.",
  "doubao-seed-code.description": "Doubao-Seed-Code는 에이전트 기반 코딩에 최적화된 모델로, 멀티모달 입력(텍스트/이미지/비디오)과 256k 컨텍스트 윈도우를 지원하며, Anthropic API와 호환됩니다. 코딩, 시각 이해, 에이전트 워크플로우에 적합합니다.",
  "doubao-seededit-3-0-i2i-250628.description": "ByteDance Seed의 Doubao 이미지 모델은 텍스트 및 이미지 입력을 지원하며, 고품질 이미지 생성과 세밀한 제어가 가능합니다. 텍스트 기반 이미지 편집을 지원하며, 출력 크기는 긴 변 기준 512~1536 사이입니다.",
  "doubao-seedream-3-0-t2i-250415.description": "Seedream 3.0은 ByteDance Seed의 이미지 생성 모델로, 텍스트 및 이미지 입력을 지원하며, 고품질 이미지 생성을 세밀하게 제어할 수 있습니다. 텍스트 프롬프트로부터 이미지를 생성합니다.",
  "doubao-seedream-4-0-250828.description": "Seedream 4.0은 ByteDance Seed의 이미지 생성 모델로, 텍스트 및 이미지 입력을 지원하며, 고품질 이미지 생성을 세밀하게 제어할 수 있습니다. 텍스트 프롬프트로부터 이미지를 생성합니다.",
  "doubao-vision-lite-32k.description": "Doubao-vision은 Doubao의 멀티모달 모델로, 강력한 이미지 이해 및 추론 능력과 정확한 지시 따르기 기능을 갖추고 있습니다. 이미지-텍스트 추출 및 이미지 기반 추론 작업에서 뛰어난 성능을 발휘하며, 더 복잡하고 다양한 시각 질의응답 시나리오를 가능하게 합니다.",
  "doubao-vision-pro-32k.description": "Doubao-vision은 Doubao의 멀티모달 모델로, 강력한 이미지 이해 및 추론 능력과 정확한 지시 따르기 기능을 갖추고 있습니다. 이미지-텍스트 추출 및 이미지 기반 추론 작업에서 뛰어난 성능을 발휘하며, 더 복잡하고 다양한 시각 질의응답 시나리오를 가능하게 합니다.",
  "emohaa.description": "Emohaa는 전문 상담 능력을 갖춘 정신 건강 모델로, 사용자가 감정 문제를 이해하도록 돕습니다.",
  "ernie-4.5-0.3b.description": "ERNIE 4.5 0.3B는 로컬 및 맞춤형 배포를 위한 오픈소스 경량 모델입니다.",
  "ernie-4.5-21b-a3b.description": "ERNIE 4.5 21B A3B는 이해력과 생성 능력이 뛰어난 오픈소스 대규모 파라미터 모델입니다.",
  "ernie-4.5-300b-a47b.description": "ERNIE 4.5 300B A47B는 Baidu ERNIE의 초대형 MoE 모델로, 탁월한 추론 능력을 자랑합니다.",
  "ernie-4.5-8k-preview.description": "ERNIE 4.5 8K Preview는 ERNIE 4.5의 평가를 위한 8K 컨텍스트 프리뷰 모델입니다.",
  "ernie-4.5-turbo-128k-preview.description": "ERNIE 4.5 Turbo 128K Preview는 릴리스 수준의 기능을 갖춘 모델로, 통합 및 카나리아 테스트에 적합합니다.",
  "ernie-4.5-turbo-128k.description": "ERNIE 4.5 Turbo 128K는 검색 보강 및 도구 호출 기능을 갖춘 고성능 범용 모델로, QA, 코딩, 에이전트 시나리오에 적합합니다.",
  "ernie-4.5-turbo-32k.description": "ERNIE 4.5 Turbo 32K는 QA, 지식 기반 검색, 다중 턴 대화를 위한 중간 길이 컨텍스트 버전입니다.",
  "ernie-4.5-turbo-latest.description": "최신 ERNIE 4.5 Turbo는 전반적인 성능이 최적화되어 주력 프로덕션 모델로 이상적입니다.",
  "ernie-4.5-turbo-vl-32k-preview.description": "ERNIE 4.5 Turbo VL 32K Preview는 장문 컨텍스트 비전 능력 평가를 위한 32K 멀티모달 프리뷰 모델입니다.",
  "ernie-4.5-turbo-vl-32k.description": "ERNIE 4.5 Turbo VL 32K는 장문 문서와 이미지 이해를 결합한 중장기 멀티모달 버전입니다.",
  "ernie-4.5-turbo-vl-latest.description": "ERNIE 4.5 Turbo VL Latest는 이미지-텍스트 이해 및 추론 능력이 향상된 최신 멀티모달 버전입니다.",
  "ernie-4.5-turbo-vl-preview.description": "ERNIE 4.5 Turbo VL Preview는 이미지-텍스트 이해 및 생성을 위한 멀티모달 프리뷰 모델로, 시각적 QA 및 콘텐츠 이해에 적합합니다.",
  "ernie-4.5-turbo-vl.description": "ERNIE 4.5 Turbo VL은 프로덕션 환경에서 이미지-텍스트 이해 및 인식을 위한 성숙한 멀티모달 모델입니다.",
  "ernie-4.5-vl-28b-a3b.description": "ERNIE 4.5 VL 28B A3B는 이미지-텍스트 이해 및 추론을 위한 오픈소스 멀티모달 모델입니다.",
  "ernie-5.0-thinking-latest.description": "Wenxin 5.0 Thinking은 텍스트, 이미지, 오디오, 비디오를 통합 모델링하는 네이티브 풀모달 플래그십 모델로, 복잡한 QA, 창작, 에이전트 시나리오에 대한 전반적인 기능 향상을 제공합니다.",
  "ernie-5.0-thinking-preview.description": "Wenxin 5.0 Thinking Preview는 텍스트, 이미지, 오디오, 비디오를 통합 모델링하는 네이티브 풀모달 플래그십 모델로, 복잡한 QA, 창작, 에이전트 시나리오에 대한 전반적인 기능 향상을 제공합니다.",
  "ernie-char-8k.description": "ERNIE Character 8K는 IP 캐릭터 구축 및 장기 동반자형 대화를 위한 페르소나 대화 모델입니다.",
  "ernie-char-fiction-8k-preview.description": "ERNIE Character Fiction 8K Preview는 캐릭터 및 플롯 창작 기능 평가를 위한 프리뷰 모델입니다.",
  "ernie-char-fiction-8k.description": "ERNIE Character Fiction 8K는 장편 소설 및 플롯 창작에 적합한 페르소나 모델입니다.",
  "ernie-irag-edit.description": "ERNIE iRAG Edit는 지우기, 다시 그리기, 변형 생성 등을 지원하는 이미지 편집 모델입니다.",
  "ernie-lite-8k.description": "ERNIE Lite 8K는 비용 민감한 일상 QA 및 콘텐츠 생성을 위한 경량 범용 모델입니다.",
  "ernie-lite-pro-128k.description": "ERNIE Lite Pro 128K는 지연 시간 및 비용에 민감한 시나리오를 위한 경량 고성능 모델입니다.",
  "ernie-novel-8k.description": "ERNIE Novel 8K는 다중 캐릭터 내러티브를 포함한 장편 소설 및 IP 플롯 생성을 위해 설계되었습니다.",
  "ernie-speed-128k.description": "ERNIE Speed 128K는 I/O 비용이 없는 모델로, 장문 이해 및 대규모 테스트에 적합합니다.",
  "ernie-speed-8k.description": "ERNIE Speed 8K는 일상 대화 및 간단한 텍스트 작업을 위한 무료 고속 모델입니다.",
  "ernie-speed-pro-128k.description": "ERNIE Speed Pro 128K는 대규모 온라인 서비스 및 엔터프라이즈 앱을 위한 고동시성 고가치 모델입니다.",
  "ernie-tiny-8k.description": "ERNIE Tiny 8K는 간단한 QA, 분류, 저비용 추론을 위한 초경량 모델입니다.",
  "ernie-x1-turbo-32k.description": "ERNIE X1 Turbo 32K는 복잡한 추론 및 다중 턴 대화를 위한 32K 컨텍스트의 고속 사고 모델입니다.",
  "ernie-x1.1-preview.description": "ERNIE X1.1 Preview는 평가 및 테스트를 위한 사고 모델 프리뷰입니다.",
  "gemini-flash-latest.description": "Gemini Flash 최신 버전",
  "gemini-flash-lite-latest.description": "Gemini Flash-Lite 최신 버전",
  "gemini-pro-latest.description": "Gemini Pro 최신 버전",
  "meta/Llama-3.2-90B-Vision-Instruct.description": "시각 이해 에이전트 애플리케이션을 위한 고급 이미지 추론 기능.",
  "meta/Llama-3.3-70B-Instruct.description": "Llama 3.3은 가장 진보된 다국어 오픈소스 Llama 모델로, 매우 낮은 비용으로 405B에 근접한 성능을 제공합니다. Transformer 기반이며, 유용성과 안전성을 위해 SFT 및 RLHF로 개선되었습니다. 명령어 튜닝 버전은 다국어 채팅에 최적화되어 있으며, 산업 벤치마크에서 많은 오픈 및 클로즈드 채팅 모델을 능가합니다. 지식 기준일: 2023년 12월.",
  "meta/Meta-Llama-3-70B-Instruct.description": "추론, 코딩, 다양한 언어 작업에 뛰어난 성능을 보이는 강력한 70B 파라미터 모델.",
  "meta/Meta-Llama-3-8B-Instruct.description": "채팅 및 텍스트 생성에 최적화된 다재다능한 8B 파라미터 모델.",
  "meta/Meta-Llama-3.1-405B-Instruct.description": "다국어 채팅에 최적화된 Llama 3.1 명령어 튜닝 텍스트 모델로, 오픈 및 클로즈드 채팅 모델 중 업계 표준 벤치마크에서 우수한 성능을 발휘합니다.",
  "meta/Meta-Llama-3.1-70B-Instruct.description": "다국어 채팅에 최적화된 Llama 3.1 명령어 튜닝 텍스트 모델로, 오픈 및 클로즈드 채팅 모델 중 업계 표준 벤치마크에서 우수한 성능을 발휘합니다.",
  "meta/Meta-Llama-3.1-8B-Instruct.description": "다국어 채팅에 최적화된 Llama 3.1 명령어 튜닝 텍스트 모델로, 오픈 및 클로즈드 채팅 모델 중 업계 표준 벤치마크에서 우수한 성능을 발휘합니다.",
  "meta/llama-3-70b.description": "Meta가 명령어 수행을 위해 미세 조정한 70B 오픈소스 모델로, Groq의 LPU 하드웨어에서 빠르고 효율적인 추론을 제공합니다.",
  "meta/llama-3-8b.description": "Meta가 명령어 수행을 위해 미세 조정한 8B 오픈소스 모델로, Groq의 LPU 하드웨어에서 빠르고 효율적인 추론을 제공합니다.",
  "meta/llama-3.1-405b-instruct.description": "챗봇, 코딩, 도메인 작업을 위한 합성 데이터 생성, 지식 증류, 추론을 지원하는 고급 LLM.",
  "meta/llama-3.1-70b-instruct.description": "우수한 문맥 이해, 추론, 텍스트 생성을 통해 복잡한 대화를 처리하도록 설계됨.",
  "meta/llama-3.1-70b.description": "128K 문맥, 다국어 지원, 향상된 추론 기능을 갖춘 최신 Meta Llama 3 70B Instruct.",
  "meta/llama-3.1-8b-instruct.description": "강력한 언어 이해, 추론, 텍스트 생성 기능을 갖춘 최첨단 모델.",
  "meta/llama-3.1-8b.description": "Llama 3.1 8B는 128K 문맥 창을 지원하며, 실시간 채팅 및 데이터 분석에 이상적이며, 대형 모델 대비 비용 효율성이 뛰어납니다. Groq의 LPU 하드웨어에서 빠르고 효율적인 추론을 제공합니다.",
  "meta/llama-3.2-11b-vision-instruct.description": "이미지로부터 고품질 추론을 수행하는 최첨단 비전-언어 모델.",
  "meta/llama-3.2-11b.description": "시각 인식, 이미지 추론, 캡션 생성, 일반 이미지 QA에 최적화된 명령어 튜닝 이미지 추론 모델 (텍스트+이미지 입력, 텍스트 출력).",
  "meta/llama-3.2-1b-instruct.description": "강력한 이해력, 추론력, 텍스트 생성 능력을 갖춘 최첨단 소형 언어 모델.",
  "meta/llama-3.2-1b.description": "다국어 로컬 검색, 요약, 재작성과 같은 온디바이스 사용 사례를 위한 텍스트 전용 모델.",
  "meta/llama-3.2-3b-instruct.description": "강력한 이해력, 추론력, 텍스트 생성 능력을 갖춘 최첨단 소형 언어 모델.",
  "meta/llama-3.2-3b.description": "다국어 로컬 검색, 요약, 재작성과 같은 온디바이스 사용 사례를 위해 미세 조정된 텍스트 전용 모델.",
  "meta/llama-3.2-90b-vision-instruct.description": "이미지로부터 고품질 추론을 수행하는 최첨단 비전-언어 모델.",
  "meta/llama-3.2-90b.description": "시각 인식, 이미지 추론, 캡션 생성, 일반 이미지 QA에 최적화된 명령어 튜닝 이미지 추론 모델 (텍스트+이미지 입력, 텍스트 출력).",
  "meta/llama-3.3-70b-instruct.description": "추론, 수학, 상식, 함수 호출에 강한 고급 LLM.",
  "meta/llama-3.3-70b.description": "성능과 효율성의 완벽한 균형. 콘텐츠 제작, 엔터프라이즈 앱, 연구를 위한 고성능 대화형 AI로 설계되었으며, 요약, 분류, 감정 분석, 코드 생성에 강력한 언어 이해력을 제공합니다.",
  "meta/llama-4-maverick.description": "Llama 4 시리즈는 텍스트 및 멀티모달 경험을 지원하는 네이티브 멀티모달 AI 모델 세트로, MoE를 활용하여 탁월한 텍스트 및 이미지 이해를 제공합니다. Llama 4 Maverick은 128명의 전문가를 갖춘 17B 모델로, DeepInfra에서 제공됩니다.",
  "meta/llama-4-scout.description": "Llama 4 시리즈는 텍스트 및 멀티모달 경험을 지원하는 네이티브 멀티모달 AI 모델 세트로, MoE를 활용하여 탁월한 텍스트 및 이미지 이해를 제공합니다. Llama 4 Scout은 16명의 전문가를 갖춘 17B 모델로, DeepInfra에서 제공됩니다.",
  "microsoft/Phi-3-medium-128k-instruct.description": "RAG 또는 few-shot 프롬프트를 위한 더 큰 문맥 창을 갖춘 동일한 Phi-3-medium 모델.",
  "microsoft/Phi-3-medium-4k-instruct.description": "Phi-3-mini보다 높은 품질을 제공하는 14B 파라미터 모델로, 고품질 및 추론 중심 데이터에 중점을 둠.",
  "microsoft/Phi-3-mini-128k-instruct.description": "RAG 또는 few-shot 프롬프트를 위한 더 큰 문맥 창을 갖춘 동일한 Phi-3-mini 모델.",
  "microsoft/Phi-3-mini-4k-instruct.description": "가장 작은 Phi-3 시리즈 모델로, 품질과 낮은 지연 시간에 최적화됨.",
  "microsoft/Phi-3-small-128k-instruct.description": "RAG 또는 few-shot 프롬프트를 위한 더 큰 문맥 창을 갖춘 동일한 Phi-3-small 모델.",
  "microsoft/Phi-3-small-8k-instruct.description": "Phi-3-mini보다 높은 품질을 제공하는 7B 파라미터 모델로, 고품질 및 추론 중심 데이터에 중점을 둠.",
  "microsoft/Phi-3.5-mini-instruct.description": "Phi-3-mini 모델의 업데이트 버전.",
  "microsoft/Phi-3.5-vision-instruct.description": "Phi-3-vision 모델의 업데이트 버전.",
  "microsoft/WizardLM-2-8x22B.description": "WizardLM 2는 Microsoft AI의 언어 모델로, 복잡한 대화, 다국어 작업, 추론, 어시스턴트에 뛰어납니다.",
  "microsoft/wizardlm-2-8x22b.description": "WizardLM-2 8x22B는 Microsoft AI의 가장 진보된 Wizard 모델로, 매우 경쟁력 있는 성능을 제공합니다.",
  "minicpm-v.description": "MiniCPM-V는 OpenBMB의 차세대 멀티모달 모델로, 광범위한 사용 사례에 대해 뛰어난 OCR 및 멀티모달 이해력을 제공합니다.",
  "minimax/minimax-m2.description": "MiniMax-M2는 다양한 엔지니어링 시나리오에서 코딩 및 에이전트 작업에 뛰어난 고가치 모델입니다.",
  "minimaxai/minimax-m2.description": "MiniMax-M2는 컴팩트하고 빠르며 비용 효율적인 MoE 모델(총 230B, 활성 10B)로, 다중 파일 편집, 코드 실행-수정 루프, 테스트 검증, 복잡한 툴체인에서 뛰어난 성능을 발휘하며 강력한 일반 지능을 유지합니다.",
  "ministral-3b-latest.description": "Ministral 3B는 Mistral의 최고급 엣지 모델입니다.",
  "ministral-8b-latest.description": "Ministral 8B는 Mistral의 매우 비용 효율적인 엣지 모델입니다.",
  "mistral-ai/Mistral-Large-2411.description": "대규모 추론 또는 특수화가 필요한 복잡한 작업을 위한 Mistral의 플래그십 모델 (합성 텍스트 생성, 코드 생성, RAG 또는 에이전트 등).",
  "mistral-ai/Mistral-Nemo.description": "Mistral Nemo는 크기에 비해 최첨단 추론, 세계 지식, 코딩 성능을 제공하는 최첨단 LLM입니다.",
  "mistral-ai/mistral-small-2503.description": "Mistral Small은 고효율 및 낮은 지연 시간이 필요한 모든 언어 기반 작업에 적합합니다.",
  "mistral-large-instruct.description": "Mistral-Large-Instruct-2407은 123B 파라미터를 갖춘 고급 밀집 LLM으로, 최첨단 추론, 지식, 코딩 기능을 제공합니다.",
  "mistral-large-latest.description": "Mistral Large는 다국어 작업, 복잡한 추론, 코드 생성에 강력한 플래그십 모델로, 고급 애플리케이션에 이상적입니다.",
  "mistral-large.description": "Mixtral Large는 Mistral의 플래그십 모델로, 코드 생성, 수학, 추론을 128K 문맥 창과 결합합니다.",
  "mistral-medium-latest.description": "Mistral Medium 3는 8배 낮은 비용으로 최첨단 성능을 제공하며, 엔터프라이즈 배포를 간소화합니다.",
  "mistral-nemo-instruct.description": "Mistral-Nemo-Instruct-2407은 Mistral-Nemo-Base-2407의 명령어 튜닝 버전입니다.",
  "mistral-nemo.description": "Mistral Nemo는 Mistral AI와 NVIDIA가 공동 개발한 고효율 12B 모델입니다.",
  "mistral-small-latest.description": "Mistral Small은 번역, 요약, 감정 분석에 적합한 비용 효율적이고 빠르며 신뢰할 수 있는 옵션입니다.",
  "mistral-small.description": "Mistral Small은 고효율 및 낮은 지연 시간이 필요한 모든 언어 기반 작업에 적합합니다.",
  "mistral.description": "Mistral은 다양한 언어 작업에 적합한 Mistral AI의 7B 모델입니다.",
  "morph/morph-v3-large.description": "Morph는 최첨단 모델(예: Claude 또는 GPT-4o)이 제안한 코드 변경 사항을 기존 파일에 빠르게 적용할 수 있도록 특화된 모델입니다. 초당 2500개 이상의 토큰 처리 속도를 자랑하며, AI 코딩 워크플로우의 마지막 단계로 16K 입력/출력 토큰을 지원합니다.",
  "nousresearch/hermes-2-pro-llama-3-8b.description": "Hermes 2 Pro Llama 3 8B는 Nous Hermes 2의 최신 버전으로, 내부에서 개발한 최신 데이터셋을 기반으로 업데이트되었습니다.",
  "nvidia/Llama-3.1-Nemotron-70B-Instruct-HF.description": "Llama 3.1 Nemotron 70B는 NVIDIA가 사용자 응답의 유용성을 향상시키기 위해 맞춤 제작한 LLM입니다. Arena Hard, AlpacaEval 2 LC, GPT-4-Turbo MT-Bench에서 모두 1위를 기록하며, 2024년 10월 1일 기준 자동 정렬 벤치마크에서 최고의 성능을 보입니다. 이 모델은 Llama-3.1-70B-Instruct를 기반으로 RLHF(REINFORCE), Llama-3.1-Nemotron-70B-Reward, HelpSteer2-Preference 프롬프트를 활용해 학습되었습니다.",
  "nvidia/llama-3.1-nemotron-51b-instruct.description": "탁월한 정확도와 효율성을 제공하는 독창적인 언어 모델입니다.",
  "nvidia/llama-3.1-nemotron-70b-instruct.description": "Llama-3.1-Nemotron-70B-Instruct는 LLM 응답의 유용성을 높이기 위해 NVIDIA가 맞춤 설계한 모델입니다.",
  "o1-mini.description": "o1-preview보다 작고 빠르며, 비용이 80% 저렴합니다. 코드 생성 및 짧은 문맥 작업에 강점을 보입니다.",
  "o1-preview.description": "수학 및 과학을 포함한 고급 추론과 복잡한 문제 해결에 중점을 둔 모델입니다. 깊은 문맥 이해와 자율 워크플로우가 필요한 애플리케이션에 적합합니다.",
  "o1-pro.description": "o1 시리즈는 강화 학습을 통해 응답 전에 사고하고 복잡한 추론을 처리하도록 훈련되었습니다. o1-pro는 더 많은 연산을 사용하여 더 깊이 사고하고 일관되게 높은 품질의 응답을 제공합니다.",
  "o1.description": "o1은 OpenAI의 새로운 추론 모델로, 텍스트+이미지 입력과 텍스트 출력을 지원하며, 폭넓은 지식이 필요한 복잡한 작업에 적합합니다. 200K 문맥 창과 2023년 10월 지식 기준을 갖추고 있습니다.",
  "o3-2025-04-16.description": "o3는 OpenAI의 새로운 추론 모델로, 텍스트+이미지 입력과 텍스트 출력을 지원하며, 폭넓은 지식이 필요한 복잡한 작업에 적합합니다.",
  "o3-deep-research.description": "o3-deep-research는 복잡한 다단계 작업을 위한 가장 진보된 심층 연구 모델입니다. 웹 검색과 MCP 커넥터를 통한 데이터 접근이 가능합니다.",
  "o3-mini.description": "o3-mini는 최신 소형 추론 모델로, o1-mini와 동일한 비용과 지연 시간 내에서 더 높은 지능을 제공합니다.",
  "o3-pro-2025-06-10.description": "o3 Pro는 OpenAI의 새로운 추론 모델로, 텍스트+이미지 입력과 텍스트 출력을 지원하며, 폭넓은 지식이 필요한 복잡한 작업에 적합합니다.",
  "o3-pro.description": "o3-pro는 더 많은 연산을 사용하여 더 깊이 사고하고 일관되게 더 나은 응답을 제공합니다. Responses API를 통해서만 이용 가능합니다.",
  "o3.description": "o3는 수학, 과학, 프로그래밍, 시각적 추론에서 새로운 기준을 제시하는 강력한 범용 모델입니다. 기술 문서 작성과 지시 따르기에 뛰어나며, 텍스트, 코드, 이미지를 분석하여 다단계 문제를 해결할 수 있습니다.",
  "o4-mini-2025-04-16.description": "o4-mini는 OpenAI의 추론 모델로, 텍스트+이미지 입력과 텍스트 출력을 지원하며, 폭넓은 지식이 필요한 복잡한 작업에 적합하고 200K 문맥 창을 갖추고 있습니다.",
  "o4-mini-deep-research.description": "o4-mini-deep-research는 빠르고 경제적인 심층 연구 모델로, 복잡한 다단계 연구를 지원합니다. 웹 검색과 MCP 커넥터를 통한 데이터 접근이 가능합니다.",
  "o4-mini.description": "o4-mini는 최신 소형 o 시리즈 모델로, 빠르고 효과적인 추론을 위해 최적화되었으며, 코딩 및 비전 작업에서 높은 효율성을 보입니다.",
  "open-codestral-mamba.description": "Codestral Mamba는 코드 생성에 중점을 둔 Mamba 2 언어 모델로, 고급 코딩 및 추론 작업을 지원합니다.",
  "open-mistral-7b.description": "Mistral 7B는 작지만 성능이 뛰어난 모델로, 배치 처리 및 분류, 텍스트 생성과 같은 단순 작업에 강하며, 안정적인 추론 능력을 갖추고 있습니다.",
  "open-mistral-nemo.description": "Mistral Nemo는 Nvidia와 공동 개발한 12B 모델로, 강력한 추론 및 코딩 성능과 쉬운 통합을 제공합니다.",
  "open-mixtral-8x22b.description": "Mixtral 8x22B는 복잡한 작업을 위한 대형 MoE 모델로, 강력한 추론 능력과 높은 처리량을 제공합니다.",
  "open-mixtral-8x7b.description": "Mixtral 8x7B는 추론 속도를 높이기 위한 희소 MoE 모델로, 다국어 및 코드 생성 작업에 적합합니다.",
  "openai/gpt-3.5-turbo-instruct.description": "GPT-3 시대 모델과 유사한 기능을 제공하며, 채팅이 아닌 기존 완성형 엔드포인트와 호환됩니다.",
  "openai/gpt-3.5-turbo.description": "OpenAI의 가장 강력하고 비용 효율적인 GPT-3.5 모델로, 채팅에 최적화되어 있지만 기존 완성형 작업에도 강점을 보입니다.",
  "openai/gpt-4-turbo.description": "OpenAI의 gpt-4-turbo는 폭넓은 일반 지식과 도메인 전문성을 갖추고 있으며, 복잡한 자연어 지시를 따르고 어려운 문제를 정확하게 해결합니다. 지식 기준은 2023년 4월이며, 128K 문맥 창을 지원합니다.",
  "openai/gpt-4.1-mini.description": "GPT-4.1 Mini는 중간 문맥 작업에 대해 낮은 지연 시간과 뛰어난 가성비를 제공합니다.",
  "openai/gpt-4.1-nano.description": "GPT-4.1 Nano는 초저비용, 저지연 옵션으로, 짧은 대화나 분류 작업에 적합합니다.",
  "openai/gpt-4.1.description": "GPT-4.1 시리즈는 더 큰 문맥 창과 향상된 엔지니어링 및 추론 능력을 제공합니다.",
  "openai/gpt-4o-mini.description": "GPT-4o-mini는 저지연 멀티모달 사용을 위한 빠르고 소형의 GPT-4o 변형입니다.",
  "openai/gpt-4o.description": "GPT-4o 시리즈는 OpenAI의 Omni 모델로, 텍스트+이미지 입력과 텍스트 출력을 지원합니다.",
  "openai/gpt-5-chat.description": "GPT-5 Chat은 대화에 최적화된 GPT-5 변형으로, 낮은 지연 시간으로 더 나은 상호작용을 제공합니다.",
  "openai/gpt-5-codex.description": "GPT-5-Codex는 코딩 및 대규모 코드 워크플로우에 최적화된 GPT-5 변형입니다.",
  "openai/gpt-5-mini.description": "GPT-5 Mini는 저지연, 저비용 시나리오를 위한 소형 GPT-5 변형입니다.",
  "openai/gpt-5-nano.description": "GPT-5 Nano는 비용과 지연 시간 제약이 엄격한 시나리오를 위한 초소형 변형입니다.",
  "openai/gpt-5-pro.description": "GPT-5 Pro는 OpenAI의 대표 모델로, 뛰어난 추론, 코드 생성, 엔터프라이즈급 기능을 제공하며, 테스트 시 라우팅 및 강화된 안전 정책을 지원합니다.",
  "openai/gpt-5.1-chat.description": "GPT-5.1 Chat은 GPT-5.1 시리즈의 경량 모델로, 낮은 지연 시간의 대화에 최적화되었으며, 강력한 추론 및 지시 실행 능력을 유지합니다.",
  "openai/gpt-5.1-codex-mini.description": "GPT-5.1-Codex-Mini는 GPT-5.1-Codex의 소형, 고속 버전으로, 지연 시간과 비용에 민감한 코딩 시나리오에 적합합니다.",
  "openai/gpt-5.1-codex.description": "GPT-5.1-Codex는 소프트웨어 엔지니어링 및 코딩 워크플로우에 최적화된 GPT-5.1 변형으로, 대규모 리팩터링, 복잡한 디버깅, 장기 자율 코딩 작업에 적합합니다.",
  "openai/gpt-5.1.description": "GPT-5.1은 GPT-5 시리즈의 최신 대표 모델로, 일반 추론, 지시 따르기, 대화 자연스러움에서 GPT-5 대비 큰 향상을 이루었으며, 다양한 작업에 적합합니다.",
  "openai/gpt-5.description": "GPT-5는 OpenAI의 고성능 모델로, 다양한 생산 및 연구 작업에 적합합니다.",
  "openai/gpt-oss-120b.description": "강력하고 제어 가능한 추론 능력을 갖춘 범용 LLM입니다.",
  "openai/gpt-oss-20b.description": "지연 시간과 자원 제약 환경(로컬 및 엣지 배포 포함)에 최적화된 소형 오픈 가중치 언어 모델입니다.",
  "openai/o1-mini.description": "o1-mini는 코딩, 수학, 과학을 위한 빠르고 비용 효율적인 추론 모델입니다. 128K 문맥 창과 2023년 10월 지식 기준을 갖추고 있습니다.",
  "openai/o1-preview.description": "o1은 복잡한 작업에 적합한 OpenAI의 새로운 추론 모델로, 128K 문맥 창과 2023년 10월 지식 기준을 갖추고 있습니다.",
  "openai/o1.description": "OpenAI o1은 깊은 사고가 필요한 복잡한 문제를 해결하기 위해 설계된 대표 추론 모델로, 강력한 추론 능력과 높은 정확도를 제공합니다.",
  "openai/o3-mini-high.description": "o3-mini (고급 추론)는 o1-mini와 동일한 비용과 지연 시간 내에서 더 높은 지능을 제공합니다.",
  "openai/o3-mini.description": "o3-mini는 OpenAI의 최신 소형 추론 모델로, o1-mini와 동일한 비용과 지연 시간 내에서 더 높은 지능을 제공합니다.",
  "openai/o3.description": "OpenAI o3는 가장 강력한 추론 모델로, 코딩, 수학, 과학, 시각 인식에서 새로운 SOTA를 설정합니다. 복잡하고 다면적인 질문에 뛰어나며, 이미지, 차트, 도표 분석에 특히 강합니다.",
  "openai/o4-mini-high.description": "o4-mini 고급 추론 등급은 빠르고 효율적인 추론을 위해 최적화되었으며, 강력한 코딩 및 비전 성능을 제공합니다.",
  "openai/o4-mini.description": "OpenAI o4-mini는 저지연 시나리오를 위한 소형, 효율적인 추론 모델입니다.",
  "openai/text-embedding-3-large.description": "OpenAI의 가장 강력한 임베딩 모델로, 영어 및 비영어 작업 모두에 적합합니다.",
  "openai/text-embedding-3-small.description": "OpenAI의 향상된 고성능 ada 임베딩 모델 변형입니다.",
  "openai/text-embedding-ada-002.description": "OpenAI의 레거시 텍스트 임베딩 모델입니다.",
  "qwen/qwen3-14b:free.description": "Qwen3-14B는 복잡한 추론과 효율적인 대화를 위해 설계된 148억 매개변수의 밀집형 인과 LLM입니다. 수학, 코딩, 논리를 위한 사고 모드와 일반 대화를 위한 비사고 모드 간 전환이 가능합니다. 100개 이상의 언어와 방언에 걸쳐 지시 따르기, 에이전트 도구 사용, 창의적 글쓰기에 최적화되어 있습니다. 기본적으로 32K 컨텍스트를 처리하며 YaRN을 통해 131K까지 확장됩니다.",
  "qwen/qwen3-235b-a22b-2507.description": "Qwen3-235B-A22B-Instruct-2507은 Qwen3 시리즈의 Instruct 변형으로, 다국어 지시 수행과 장문 컨텍스트 시나리오 간의 균형을 이룹니다.",
  "qwen/qwen3-235b-a22b-thinking-2507.description": "Qwen3-235B-A22B-Thinking-2507은 복잡한 수학 및 추론 작업에 강화된 Qwen3의 사고 중심 변형입니다.",
  "qwen/qwen3-235b-a22b.description": "Qwen3-235B-A22B는 Qwen의 235B 매개변수 MoE 모델로, 한 번의 추론에 22B가 활성화됩니다. 복잡한 추론, 수학, 코드를 위한 사고 모드와 효율적인 대화를 위한 비사고 모드 간 전환이 가능합니다. 강력한 추론 능력, 100개 이상의 언어/방언 지원, 고급 지시 따르기 및 에이전트 도구 사용을 제공합니다. 기본적으로 32K 컨텍스트를 처리하며 YaRN을 통해 131K까지 확장됩니다.",
  "qwen/qwen3-235b-a22b:free.description": "Qwen3-235B-A22B는 Qwen의 235B 매개변수 MoE 모델로, 한 번의 추론에 22B가 활성화됩니다. 복잡한 추론, 수학, 코드를 위한 사고 모드와 효율적인 대화를 위한 비사고 모드 간 전환이 가능합니다. 강력한 추론 능력, 100개 이상의 언어/방언 지원, 고급 지시 따르기 및 에이전트 도구 사용을 제공합니다. 기본적으로 32K 컨텍스트를 처리하며 YaRN을 통해 131K까지 확장됩니다.",
  "qwen/qwen3-30b-a3b.description": "Qwen3는 밀집형 및 MoE 아키텍처를 갖춘 최신 Qwen LLM 세대로, 추론, 다국어 지원, 고급 에이전트 작업에서 뛰어난 성능을 발휘합니다. 복잡한 추론을 위한 사고 모드와 효율적인 대화를 위한 비사고 모드 간 전환 기능을 통해 다재다능하고 고품질의 성능을 보장합니다.\n\nQwen3는 QwQ 및 Qwen2.5와 같은 이전 모델을 크게 능가하며, 수학, 코딩, 상식 추론, 창의적 글쓰기, 대화형 채팅에서 탁월한 성능을 제공합니다. Qwen3-30B-A3B 변형은 305억 매개변수(3.3B 활성), 48개 레이어, 128명의 전문가(작업당 8명 활성)를 갖추고 있으며, YaRN을 통해 최대 131K 컨텍스트를 지원하여 오픈 모델의 새로운 기준을 제시합니다.",
  "qwen/qwen3-30b-a3b:free.description": "Qwen3는 밀집형 및 MoE 아키텍처를 갖춘 최신 Qwen LLM 세대로, 추론, 다국어 지원, 고급 에이전트 작업에서 뛰어난 성능을 발휘합니다. 복잡한 추론을 위한 사고 모드와 효율적인 대화를 위한 비사고 모드 간 전환 기능을 통해 다재다능하고 고품질의 성능을 보장합니다.\n\nQwen3는 QwQ 및 Qwen2.5와 같은 이전 모델을 크게 능가하며, 수학, 코딩, 상식 추론, 창의적 글쓰기, 대화형 채팅에서 탁월한 성능을 제공합니다. Qwen3-30B-A3B 변형은 305억 매개변수(3.3B 활성), 48개 레이어, 128명의 전문가(작업당 8명 활성)를 갖추고 있으며, YaRN을 통해 최대 131K 컨텍스트를 지원하여 오픈 모델의 새로운 기준을 제시합니다.",
  "qwen/qwen3-32b.description": "Qwen3-32B는 복잡한 추론과 효율적인 대화를 위해 최적화된 328억 매개변수의 밀집형 인과 LLM입니다. 수학, 코딩, 논리를 위한 사고 모드와 빠른 일반 대화를 위한 비사고 모드 간 전환이 가능합니다. 100개 이상의 언어와 방언에 걸쳐 지시 따르기, 에이전트 도구 사용, 창의적 글쓰기에 강점을 보입니다. 기본적으로 32K 컨텍스트를 처리하며 YaRN을 통해 131K까지 확장됩니다.",
  "qwen/qwen3-32b:free.description": "Qwen3-32B는 복잡한 추론과 효율적인 대화를 위해 최적화된 328억 매개변수의 밀집형 인과 LLM입니다. 수학, 코딩, 논리를 위한 사고 모드와 빠른 일반 대화를 위한 비사고 모드 간 전환이 가능합니다. 100개 이상의 언어와 방언에 걸쳐 지시 따르기, 에이전트 도구 사용, 창의적 글쓰기에 강점을 보입니다. 기본적으로 32K 컨텍스트를 처리하며 YaRN을 통해 131K까지 확장됩니다.",
  "qwen/qwen3-8b:free.description": "Qwen3-8B는 추론 중심 작업과 효율적인 대화를 위해 설계된 82억 매개변수의 밀집형 인과 LLM입니다. 수학, 코딩, 논리를 위한 사고 모드와 일반 대화를 위한 비사고 모드 간 전환이 가능합니다. 100개 이상의 언어와 방언에 걸쳐 지시 따르기, 에이전트 통합, 창의적 글쓰기에 최적화되어 있습니다. 기본적으로 32K 컨텍스트를 지원하며 YaRN을 통해 131K까지 확장됩니다.",
  "qwen/qwen3-coder-plus.description": "Qwen3-Coder-Plus는 복잡한 도구 사용과 장시간 세션에 최적화된 Qwen 시리즈의 코딩 에이전트 모델입니다.",
  "qwen/qwen3-coder.description": "Qwen3-Coder는 장문 코드 이해 및 생성에 강점을 가진 Qwen3 코드 생성 모델군입니다.",
  "qwen/qwen3-max-preview.description": "Qwen3 Max (프리뷰)는 고급 추론 및 도구 통합을 위한 Max 변형입니다.",
  "qwen/qwen3-max.description": "Qwen3 Max는 Qwen3 시리즈의 고급 추론 모델로, 다국어 추론 및 도구 통합에 최적화되어 있습니다.",
  "qwen/qwen3-vl-plus.description": "Qwen3 VL-Plus는 향상된 멀티모달 추론 및 비디오 처리 기능을 갖춘 비전 강화형 Qwen3 변형입니다.",
  "qwen2.5-14b-instruct-1m.description": "Qwen2.5 오픈소스 72B 모델입니다.",
  "qwen2.5-14b-instruct.description": "Qwen2.5 오픈소스 14B 모델입니다.",
  "qwen2.5-32b-instruct.description": "Qwen2.5 오픈소스 32B 모델입니다.",
  "qwen2.5-72b-instruct.description": "Qwen2.5 오픈소스 72B 모델입니다.",
  "qwen2.5-7b-instruct.description": "Qwen2.5 7B Instruct는 다중 시나리오 대화 및 생성을 위한 성숙한 오픈소스 지시 모델입니다.",
  "qwen2.5-coder-1.5b-instruct.description": "오픈소스 Qwen 코드 모델입니다.",
  "qwen2.5-coder-14b-instruct.description": "오픈소스 Qwen 코드 모델입니다.",
  "qwen2.5-coder-32b-instruct.description": "오픈소스 Qwen 코드 모델입니다.",
  "qwen2.5-coder-7b-instruct.description": "오픈소스 Qwen 코드 모델입니다.",
  "qwen2.5-coder-instruct.description": "Qwen2.5-Coder는 Qwen 계열의 최신 코드 중심 LLM입니다 (이전 명칭: CodeQwen).",
  "qwen2.5-instruct.description": "Qwen2.5는 0.5B에서 72B까지의 기본 및 지시 조정 모델을 포함한 최신 Qwen LLM 시리즈입니다.",
  "qwen2.5-math-1.5b-instruct.description": "Qwen-Math는 강력한 수학 문제 해결 능력을 제공합니다.",
  "qwen2.5-math-72b-instruct.description": "Qwen-Math는 강력한 수학 문제 해결 능력을 제공합니다.",
  "qwen2.5-math-7b-instruct.description": "Qwen-Math는 강력한 수학 문제 해결 능력을 제공합니다.",
  "qwen2.5-omni-7b.description": "Qwen-Omni 모델은 멀티모달 입력(비디오, 오디오, 이미지, 텍스트)을 지원하며 오디오 및 텍스트 출력을 제공합니다.",
  "qwen2.5-vl-32b-instruct.description": "Qwen2.5 VL 32B Instruct는 프라이빗 배포 및 다중 시나리오 사용에 적합한 오픈소스 멀티모달 모델입니다.",
  "qwen2.5-vl-72b-instruct.description": "지시 따르기, 수학, 문제 해결, 코딩이 향상되었으며, 일반 객체 인식이 강화되었습니다. 다양한 형식에서 정밀한 시각 요소 위치 지정, 최대 10분 길이의 비디오 이해, 이벤트 타이밍, 시간 순서 및 속도 이해, OS 또는 모바일 제어가 가능한 에이전트 지원, 핵심 정보 추출 및 JSON 출력 기능을 갖추고 있습니다. 이 모델은 시리즈 중 가장 강력한 72B 버전입니다.",
  "qwen2.5-vl-7b-instruct.description": "Qwen2.5 VL 7B Instruct는 배포 비용과 인식 능력 간의 균형을 고려한 경량 멀티모달 모델입니다.",
  "qwen2.5-vl-instruct.description": "Qwen2.5-VL은 Qwen 계열의 최신 비전-언어 모델입니다.",
  "qwen2.5.description": "Qwen2.5는 다양한 사용 사례에서 강력한 성능을 발휘하는 Alibaba의 차세대 대형 언어 모델입니다.",
  "qwen2.5:0.5b.description": "Qwen2.5는 다양한 사용 사례에서 강력한 성능을 발휘하는 Alibaba의 차세대 대형 언어 모델입니다.",
  "qwen2.5:1.5b.description": "Qwen2.5는 다양한 사용 사례에서 강력한 성능을 발휘하는 Alibaba의 차세대 대형 언어 모델입니다.",
  "qwen2.5:72b.description": "Qwen2.5는 다양한 사용 사례에서 강력한 성능을 발휘하는 Alibaba의 차세대 대형 언어 모델입니다.",
  "qwen2.description": "Qwen2는 다양한 사용 사례에서 강력한 성능을 발휘하는 Alibaba의 차세대 대형 언어 모델입니다.",
  "qwen2:0.5b.description": "Qwen2는 다양한 사용 사례에서 강력한 성능을 발휘하는 Alibaba의 차세대 대형 언어 모델입니다.",
  "qwen2:1.5b.description": "Qwen2는 다양한 사용 사례에서 강력한 성능을 발휘하는 Alibaba의 차세대 대형 언어 모델입니다.",
  "qwen2:72b.description": "Qwen2는 다양한 사용 사례에서 강력한 성능을 발휘하는 Alibaba의 차세대 대형 언어 모델입니다.",
  "qwen3-0.6b.description": "Qwen3 0.6B는 단순한 추론과 매우 제한된 환경을 위한 입문용 모델입니다.",
  "qwen3-1.7b.description": "Qwen3 1.7B는 엣지 및 디바이스 배포를 위한 초경량 모델입니다.",
  "qwen3-14b.description": "Qwen3 14B는 다국어 질의응답 및 텍스트 생성을 위한 중간 규모 모델입니다.",
  "qwen3-8b.description": "Qwen3 8B는 고동시 처리에 적합한 유연한 배포가 가능한 경량 모델입니다.",
  "qwen3-coder-30b-a3b-instruct.description": "오픈소스 Qwen 코드 모델입니다. 최신 qwen3-coder-30b-a3b-instruct는 Qwen3 기반으로, 자율 프로그래밍을 위한 강력한 코딩 에이전트 기능, 도구 활용, 환경 상호작용을 제공하며, 우수한 코드 성능과 견고한 범용 능력을 갖추고 있습니다.",
  "qwen3-coder-480b-a35b-instruct.description": "Qwen3 Coder 480B A35B Instruct는 다국어 프로그래밍과 복잡한 코드 이해를 위한 플래그십 코드 모델입니다.",
  "qwen3-coder-flash.description": "Qwen 코드 모델입니다. 최신 Qwen3-Coder 시리즈는 Qwen3 기반으로, 자율 프로그래밍을 위한 강력한 코딩 에이전트 기능, 도구 활용, 환경 상호작용을 제공하며, 우수한 코드 성능과 견고한 범용 능력을 갖추고 있습니다.",
  "qwen3-coder-plus.description": "Qwen 코드 모델입니다. 최신 Qwen3-Coder 시리즈는 Qwen3 기반으로, 자율 프로그래밍을 위한 강력한 코딩 에이전트 기능, 도구 활용, 환경 상호작용을 제공하며, 우수한 코드 성능과 견고한 범용 능력을 갖추고 있습니다.",
  "qwen3-coder:480b.description": "Alibaba의 고성능 장문 컨텍스트 모델로, 에이전트 및 코딩 작업에 적합합니다.",
  "qwen3-max-preview.description": "복잡하고 다단계 작업에 최적화된 Qwen 모델의 프리뷰 버전입니다. 사고 기능을 지원합니다.",
  "qwen3-max.description": "Qwen3 Max 모델은 2.5 시리즈 대비 전반적인 능력, 중영어 이해, 복잡한 지시 수행, 주관적 개방형 작업, 다국어 처리, 도구 활용 등에서 큰 향상을 보이며, 환각 현상도 줄였습니다. 최신 qwen3-max는 qwen3-max-preview보다 에이전트 프로그래밍과 도구 활용이 향상되었습니다. 이 릴리스는 분야별 SOTA 수준에 도달하며, 더 복잡한 에이전트 요구를 충족합니다.",
  "qwen3-next-80b-a3b-instruct.description": "차세대 Qwen3 오픈소스 모델로, 이전 버전(Qwen3-235B-A22B-Instruct-2507) 대비 중국어 이해, 논리적 추론, 텍스트 생성 능력이 향상되었습니다.",
  "qwen3-next-80b-a3b-thinking.description": "Qwen3 Next 80B A3B Thinking은 복잡한 작업을 위한 플래그십 추론 모델입니다.",
  "qwen3-omni-flash.description": "Qwen-Omni는 텍스트, 이미지, 오디오, 비디오 등 다양한 입력을 받아 텍스트 또는 음성으로 출력합니다. 다양한 자연스러운 음성 스타일을 제공하며, 다국어 및 방언 음성을 지원하고, 글쓰기, 시각 인식, 음성 비서 등 다양한 활용 사례에 적합합니다.",
  "qwen3-vl-235b-a22b-instruct.description": "Qwen3 VL 235B A22B Instruct는 고난도 이해 및 생성 작업을 위한 플래그십 멀티모달 모델입니다.",
  "qwen3-vl-235b-a22b-thinking.description": "Qwen3 VL 235B A22B Thinking은 복잡한 멀티모달 추론 및 계획을 위한 플래그십 사고 버전입니다.",
  "qwen3-vl-30b-a3b-instruct.description": "Qwen3 VL 30B A3B Instruct는 정확성과 추론 성능의 균형을 갖춘 대형 멀티모달 모델입니다.",
  "qwen3-vl-30b-a3b-thinking.description": "Qwen3 VL 30B A3B Thinking은 복잡한 멀티모달 작업을 위한 심층 사고 버전입니다.",
  "qwen3-vl-32b-instruct.description": "Qwen3 VL 32B Instruct는 고품질 이미지-텍스트 질의응답 및 생성에 최적화된 멀티모달 지시 조정 모델입니다.",
  "qwen3-vl-32b-thinking.description": "Qwen3 VL 32B Thinking은 복잡한 추론과 장기 연쇄 분석을 위한 심층 사고 멀티모달 버전입니다.",
  "qwen3-vl-8b-instruct.description": "Qwen3 VL 8B Instruct는 일상적인 시각 질의응답 및 앱 통합에 적합한 경량 멀티모달 모델입니다.",
  "qwen3-vl-8b-thinking.description": "Qwen3 VL 8B Thinking은 정밀한 시각 추론을 위한 멀티모달 연쇄 사고 모델입니다.",
  "qwen3-vl-flash.description": "Qwen3 VL Flash는 지연 민감 또는 대량 요청에 적합한 경량 고속 추론 버전입니다.",
  "qwen3-vl-plus.description": "Qwen VL은 시각 이해 기능을 갖춘 텍스트 생성 모델입니다. OCR 수행은 물론, 제품 사진에서 속성 추출이나 이미지 기반 문제 해결 등 요약 및 추론도 가능합니다.",
  "qwen3.description": "Qwen3는 Alibaba의 차세대 대형 언어 모델로, 다양한 활용 사례에서 강력한 성능을 발휘합니다.",
  "qwq-32b-preview.description": "QwQ는 향상된 추론 능력에 중점을 둔 Qwen의 실험적 연구 모델입니다.",
  "qwq-32b.description": "QwQ는 Qwen 계열의 추론 모델입니다. 일반적인 지시 조정 모델과 비교해 사고 및 추론 능력이 뛰어나며, 특히 복잡한 문제에서 다운스트림 성능을 크게 향상시킵니다. QwQ-32B는 DeepSeek-R1 및 o1-mini와 경쟁할 수 있는 중형 추론 모델입니다.",
  "qwq-plus.description": "Qwen2.5 기반으로 학습된 QwQ 추론 모델은 RL을 통해 추론 능력을 크게 향상시켰습니다. 수학/코드(AIME 24/25, LiveCodeBench) 및 일부 일반 벤치마크(IFEval, LiveBench)에서 DeepSeek-R1 수준의 성능을 달성합니다.",
  "qwq.description": "QwQ는 Qwen 계열의 추론 모델입니다. 일반적인 지시 조정 모델과 비교해 사고 및 추론 능력이 뛰어나며, 특히 어려운 문제에서 다운스트림 성능을 크게 향상시킵니다. QwQ-32B는 DeepSeek-R1 및 o1-mini와 경쟁할 수 있는 중형 추론 모델입니다.",
  "qwq_32b.description": "Qwen 계열의 중형 추론 모델입니다. 일반적인 지시 조정 모델과 비교해 QwQ의 사고 및 추론 능력은 특히 어려운 문제에서 다운스트림 성능을 크게 향상시킵니다.",
  "r1-1776.description": "R1-1776은 DeepSeek R1의 후속 학습 버전으로, 검열되지 않고 편향 없는 사실 정보를 제공합니다.",
  "solar-mini-ja.description": "Solar Mini (Ja)는 Solar Mini의 일본어 특화 버전으로, 영어와 한국어에서도 효율적이고 강력한 성능을 유지합니다.",
  "solar-mini.description": "Solar Mini는 GPT-3.5를 능가하는 성능을 가진 소형 LLM으로, 영어와 한국어를 지원하는 강력한 다국어 기능을 갖추고 있으며, 효율적인 경량 솔루션을 제공합니다.",
  "solar-pro.description": "Solar Pro는 Upstage의 고지능 LLM으로, 단일 GPU에서 지시 수행에 최적화되어 있으며, IFEval 점수 80 이상을 기록합니다. 현재는 영어를 지원하며, 2024년 11월 전체 릴리스 시 더 많은 언어와 긴 컨텍스트를 지원할 예정입니다.",
  "sonar-deep-research.description": "Deep Research는 전문가 수준의 종합적인 리서치를 수행하고 이를 이해하기 쉽고 실행 가능한 보고서로 정리합니다.",
  "sonar-pro.description": "복잡한 질의와 후속 질문을 위한 검색 기반 고급 검색 제품입니다.",
  "sonar-reasoning-pro.description": "복잡한 질의와 후속 질문을 위한 검색 기반 고급 검색 제품입니다.",
  "sonar-reasoning.description": "복잡한 질의와 후속 질문을 위한 검색 기반 고급 검색 제품입니다.",
  "sonar.description": "Sonar Pro보다 빠르고 저렴한 경량 검색 기반 제품입니다.",
  "spark-x.description": "X1.5 업데이트: (1) `thinking` 필드로 제어되는 동적 사고 모드 추가; (2) 64K 입력 및 64K 출력의 확장된 컨텍스트 길이; (3) FunctionCall 지원.",
  "stable-diffusion-3-medium.description": "Stability AI의 최신 텍스트-이미지 모델입니다. 이미지 품질, 텍스트 이해, 스타일 다양성이 크게 향상되었으며, 복잡한 자연어 프롬프트를 더 정확하게 해석하고 정밀하고 다양한 이미지를 생성합니다.",
  "stable-diffusion-3.5-large-turbo.description": "stable-diffusion-3.5-large-turbo는 stable-diffusion-3.5-large에 적대적 확산 증류(ADD)를 적용하여 속도를 향상시킨 버전입니다.",
  "stable-diffusion-3.5-large.description": "stable-diffusion-3.5-large는 800M 파라미터의 MMDiT 텍스트-이미지 모델로, 우수한 품질과 프롬프트 정렬을 제공하며, 1메가픽셀 이미지를 지원하고 소비자 하드웨어에서 효율적으로 실행됩니다.",
  "stable-diffusion-v1.5.description": "stable-diffusion-v1.5는 v1.2 체크포인트에서 초기화되어 \"laion-aesthetics v2 5+\" 데이터셋으로 595k 스텝 파인튜닝되었으며, 텍스트 조건화를 10% 줄여 classifier-free guidance 샘플링을 개선했습니다.",
  "stable-diffusion-xl-base-1.0.description": "Stability AI의 오픈소스 텍스트-이미지 모델로, 업계 최고 수준의 창의적 이미지 생성을 제공합니다. 지시 이해력이 뛰어나며, 정밀한 생성을 위한 역 프롬프트 정의도 지원합니다.",
  "stable-diffusion-xl.description": "stable-diffusion-xl은 v1.5 대비 큰 개선을 이루었으며, 최고 수준의 오픈 텍스트-이미지 결과와 견줄 만합니다. 개선 사항에는 3배 더 큰 UNet 백본, 이미지 품질 향상을 위한 리파인먼트 모듈, 더 효율적인 학습 기법이 포함됩니다.",
  "step-1-128k.description": "일반적인 시나리오에서 성능과 비용의 균형을 제공합니다.",
  "step-1-256k.description": "장문 문서 분석에 적합한 초장문 컨텍스트 처리 지원.",
  "step-1-32k.description": "다양한 시나리오에 적합한 중간 길이 대화 지원.",
  "step-1-8k.description": "경량 작업에 적합한 소형 모델입니다.",
  "step-1-flash.description": "실시간 채팅에 적합한 고속 모델입니다.",
  "step-1.5v-mini.description": "강력한 비디오 이해 능력을 갖춘 모델입니다.",
  "step-1o-turbo-vision.description": "1o보다 수학 및 코딩 성능이 뛰어난 이미지 이해 모델로, 더 작고 빠른 출력 속도를 자랑합니다.",
  "step-1o-vision-32k.description": "Step-1V 시리즈보다 향상된 시각 성능을 제공하는 강력한 이미지 이해 모델입니다.",
  "step-1v-32k.description": "풍부한 멀티모달 상호작용을 위한 시각 입력을 지원합니다.",
  "step-1v-8k.description": "기본 이미지-텍스트 작업을 위한 소형 비전 모델입니다.",
  "step-1x-edit.description": "이 모델은 이미지 편집에 중점을 두며, 사용자 제공 이미지와 텍스트를 기반으로 이미지를 수정 및 향상시킵니다. 텍스트 설명 및 예시 이미지 등 다양한 입력 형식을 지원하며, 사용자 의도에 맞는 편집을 생성합니다.",
  "step-1x-medium.description": "이 모델은 텍스트 프롬프트 입력을 기반으로 강력한 이미지 생성을 제공합니다. 중국어를 기본적으로 지원하여 중국어 설명을 더 잘 이해하고 의미를 시각적 특징으로 변환하여 더 정확한 생성을 수행합니다. 고해상도, 고품질 이미지를 생성하며 일정 수준의 스타일 전환도 지원합니다.",
  "vercel/v0-1.5-md.description": "v0의 모델에 접근하여 최신 지식과 프레임워크별 추론을 바탕으로 현대적인 웹 앱을 생성, 수정, 최적화할 수 있습니다.",
  "volcengine/doubao-seed-code.description": "Doubao-Seed-Code는 바이트댄스 화산 엔진의 LLM으로, 에이전트 프로그래밍에 최적화되어 있으며, 256K 컨텍스트 지원과 함께 프로그래밍 및 에이전트 벤치마크에서 뛰어난 성능을 발휘합니다.",
  "wan2.2-t2i-flash.description": "Wanxiang 2.2 Speed는 창의성, 안정성, 사실감이 향상된 최신 모델로, 빠른 생성 속도와 높은 가치를 제공합니다.",
  "wan2.2-t2i-plus.description": "Wanxiang 2.2 Pro는 창의성, 안정성, 사실감이 향상된 최신 모델로, 더욱 풍부한 디테일을 생성합니다.",
  "wanx-v1.description": "기본 텍스트-투-이미지 모델로, Tongyi Wanxiang 1.0 General에 해당합니다.",
  "wanx2.0-t2i-turbo.description": "텍스처가 풍부한 인물화에 강하며, 속도는 중간 수준이고 비용은 낮습니다. Tongyi Wanxiang 2.0 Speed에 해당합니다.",
  "wanx2.1-t2i-plus.description": "이미지 디테일이 더욱 풍부해진 완전 업그레이드 버전으로, 속도는 다소 느립니다. Tongyi Wanxiang 2.1 Pro에 해당합니다.",
  "wanx2.1-t2i-turbo.description": "빠른 생성 속도와 뛰어난 전반적 품질, 높은 가치를 제공하는 완전 업그레이드 버전입니다. Tongyi Wanxiang 2.1 Speed에 해당합니다.",
  "whisper-1.description": "다국어 음성 인식, 음성 번역, 언어 식별을 지원하는 범용 음성 인식 모델입니다.",
  "wizardlm2.description": "WizardLM 2는 Microsoft AI의 언어 모델로, 복잡한 대화, 다국어 작업, 추론, 어시스턴트 기능에 뛰어납니다.",
  "wizardlm2:8x22b.description": "WizardLM 2는 Microsoft AI의 언어 모델로, 복잡한 대화, 다국어 작업, 추론, 어시스턴트 기능에 뛰어납니다.",
  "x-ai/grok-4-fast-non-reasoning.description": "Grok 4 Fast (비추론형)는 xAI의 고처리량, 저비용 멀티모달 모델로, 2M 컨텍스트 윈도우를 지원하며, 지연 시간과 비용에 민감하지만 모델 내 추론이 필요 없는 시나리오에 적합합니다. 추론이 필요한 경우 API의 reasoning 파라미터를 통해 활성화할 수 있습니다. 프롬프트와 응답은 xAI 또는 OpenRouter가 향후 모델 개선을 위해 사용할 수 있습니다.",
  "x-ai/grok-4-fast.description": "Grok 4 Fast는 xAI의 고처리량, 저비용 모델로, 2M 컨텍스트 윈도우를 지원하며, 동시성 높은 환경과 장문 컨텍스트에 이상적입니다.",
  "x-ai/grok-4.1-fast-non-reasoning.description": "Grok 4 Fast (비추론형)는 xAI의 고처리량, 저비용 멀티모달 모델로, 2M 컨텍스트 윈도우를 지원하며, 지연 시간과 비용에 민감하지만 모델 내 추론이 필요 없는 시나리오에 적합합니다. 추론이 필요한 경우 API의 reasoning 파라미터를 통해 활성화할 수 있습니다. 프롬프트와 응답은 xAI 또는 OpenRouter가 향후 모델 개선을 위해 사용할 수 있습니다.",
  "x-ai/grok-4.1-fast.description": "Grok 4 Fast는 xAI의 고처리량, 저비용 모델로, 2M 컨텍스트 윈도우를 지원하며, 동시성 높은 환경과 장문 컨텍스트에 이상적입니다.",
  "x-ai/grok-4.description": "Grok 4는 xAI의 대표 추론 모델로, 강력한 추론 능력과 멀티모달 기능을 갖추고 있습니다.",
  "x-ai/grok-code-fast-1.description": "Grok Code Fast 1은 xAI의 빠른 코드 모델로, 가독성이 높고 엔지니어 친화적인 출력을 제공합니다.",
  "xai/grok-2-vision.description": "Grok 2 Vision은 시각적 작업에 뛰어나며, 시각 수학 추론(MathVista)과 문서 QA(DocVQA)에서 최고 성능을 발휘합니다. 문서, 차트, 그래프, 스크린샷, 사진을 처리할 수 있습니다.",
  "xai/grok-2.description": "Grok 2는 최첨단 추론, 강력한 대화, 코딩 성능을 갖춘 프런티어 모델로, LMSYS에서 Claude 3.5 Sonnet 및 GPT-4 Turbo보다 높은 순위를 기록했습니다.",
  "xai/grok-3-fast.description": "xAI의 대표 모델로, 데이터 추출, 코딩, 요약 등 기업용 사례에 뛰어나며, 금융, 의료, 법률, 과학 분야에 대한 깊은 전문 지식을 갖추고 있습니다. 빠른 변형은 더 빠른 응답을 위해 고속 인프라에서 실행되며, 토큰당 비용은 더 높습니다.",
  "xai/grok-3-mini-fast.description": "xAI의 경량 모델로, 응답 전에 사고하며, 복잡한 도메인 지식 없이 단순하거나 논리 기반 작업에 적합합니다. 원시 추론 경로를 제공합니다. 빠른 변형은 더 빠른 응답을 위해 고속 인프라에서 실행되며, 토큰당 비용은 더 높습니다.",
  "xai/grok-3-mini.description": "xAI의 경량 모델로, 응답 전에 사고하며, 복잡한 도메인 지식 없이 단순하거나 논리 기반 작업에 적합합니다. 원시 추론 경로를 제공합니다.",
  "xai/grok-3.description": "xAI의 대표 모델로, 데이터 추출, 코딩, 요약 등 기업용 사례에 뛰어나며, 금융, 의료, 법률, 과학 분야에 대한 깊은 전문 지식을 갖추고 있습니다.",
  "xai/grok-4.description": "xAI의 최신 대표 모델로, 자연어, 수학, 추론에서 탁월한 성능을 발휘하는 만능형 모델입니다.",
  "yi-large-fc.description": "yi-large 기반에 도구 호출 기능이 강화되어, 에이전트 및 워크플로우 시나리오에 적합합니다.",
  "yi-large-preview.description": "초기 버전이며, 최신 버전인 yi-large 사용을 권장합니다.",
  "yi-large-rag.description": "yi-large 기반의 고급 서비스로, 검색과 생성을 결합하여 실시간 웹 검색을 통한 정확한 답변을 제공합니다.",
  "yi-large-turbo.description": "우수한 성능과 가성비를 제공하며, 품질, 속도, 비용 간의 균형이 뛰어나게 조정된 모델입니다.",
  "yi-large.description": "100B 파라미터의 새로운 모델로, 강력한 질의응답 및 텍스트 생성 능력을 갖추고 있습니다.",
  "yi-lightning-lite.description": "경량 버전이며, yi-lightning 사용을 권장합니다.",
  "yi-lightning.description": "최신 고성능 모델로, 빠른 추론과 고품질 출력을 제공합니다.",
  "yi-medium-200k.description": "200K 길이의 장문 컨텍스트를 지원하여, 깊이 있는 장문 이해 및 생성을 가능하게 합니다.",
  "yi-medium.description": "중간 크기의 모델로, 명령어 수행에 최적화되어 있으며, 성능과 가성비의 균형이 뛰어납니다.",
  "yi-spark.description": "수학 및 코딩 능력이 강화된 컴팩트하고 빠른 모델입니다.",
  "yi-vision-v2.description": "복잡한 작업을 위한 비전 모델로, 다중 이미지 이해 및 분석 능력이 뛰어납니다.",
  "yi-vision.description": "복잡한 작업을 위한 비전 모델로, 강력한 이미지 이해 및 분석 능력을 갖추고 있습니다.",
  "z-ai/glm-4.5-air.description": "GLM 4.5 Air는 비용에 민감한 시나리오를 위한 경량 모델로, 강력한 추론 능력을 유지합니다.",
  "z-ai/glm-4.5.description": "GLM 4.5는 Z.AI의 대표 모델로, 하이브리드 추론이 가능하며, 엔지니어링 및 장문 컨텍스트 작업에 최적화되어 있습니다.",
  "z-ai/glm-4.6.description": "GLM 4.6은 Z.AI의 대표 모델로, 확장된 컨텍스트 길이와 향상된 코딩 기능을 제공합니다.",
  "zai-glm-4.6.description": "코딩 및 추론 작업에서 뛰어난 성능을 발휘하며, 스트리밍 및 도구 호출을 지원하고, 에이전트 기반 코딩 및 복잡한 추론에 적합합니다.",
  "zai-org/GLM-4.5-Air.description": "GLM-4.5-Air는 Mixture-of-Experts 아키텍처를 사용하는 에이전트 애플리케이션용 기본 모델입니다. 도구 사용, 웹 브라우징, 소프트웨어 엔지니어링, 프론트엔드 코딩에 최적화되어 있으며, Claude Code 및 Roo Code와 같은 코드 에이전트와 통합됩니다. 복잡한 추론과 일상적인 시나리오 모두를 처리할 수 있는 하이브리드 추론을 사용합니다.",
  "zai-org/GLM-4.5.description": "GLM-4.5는 Mixture-of-Experts 아키텍처를 사용하는 에이전트 애플리케이션용 기본 모델입니다. 도구 사용, 웹 브라우징, 소프트웨어 엔지니어링, 프론트엔드 코딩에 깊이 최적화되어 있으며, Claude Code 및 Roo Code와 같은 코드 에이전트와 통합됩니다. 복잡한 추론과 일상적인 시나리오 모두를 처리할 수 있는 하이브리드 추론을 사용합니다.",
  "zai-org/GLM-4.5V.description": "GLM-4.5V는 GLM-4.5-Air 기반의 최신 VLM으로, 106B 총 파라미터(12B 활성)를 갖춘 MoE 아키텍처를 사용하여 낮은 비용으로 강력한 성능을 제공합니다. GLM-4.1V-Thinking 경로를 따르며, 3D-RoPE를 추가하여 3D 공간 추론을 향상시켰습니다. 사전학습, SFT, RL을 통해 최적화되었으며, 이미지, 비디오, 장문 문서를 처리할 수 있습니다. 41개 공개 멀티모달 벤치마크에서 오픈 모델 중 최고 순위를 기록했습니다. Thinking 모드 전환 기능을 통해 속도와 깊이를 조절할 수 있습니다.",
  "zai-org/GLM-4.6.description": "GLM-4.5와 비교해 GLM-4.6은 컨텍스트 길이를 128K에서 200K로 확장하여 더 복잡한 에이전트 작업을 처리할 수 있습니다. 코드 벤치마크에서 더 높은 점수를 기록하며, Claude Code, Cline, Roo Code, Kilo Code 등 실제 애플리케이션에서 더 강력한 성능을 보입니다. 추론 능력이 향상되었고, 추론 중 도구 사용이 가능하여 전반적인 역량이 강화되었습니다. 에이전트 프레임워크와의 통합이 개선되었으며, 도구/검색 에이전트 성능이 향상되고, 더 자연스러운 문체와 역할극 표현을 제공합니다.",
  "zai/glm-4.5-air.description": "GLM-4.5 및 GLM-4.5-Air는 에이전트 애플리케이션을 위한 최신 대표 모델로, 모두 MoE를 사용합니다. GLM-4.5는 총 355B 파라미터(32B 활성), GLM-4.5-Air는 더 슬림한 106B 총 파라미터(12B 활성)를 갖추고 있습니다.",
  "zai/glm-4.5.description": "GLM-4.5 시리즈는 에이전트를 위해 설계되었습니다. 대표 모델인 GLM-4.5는 355B 총 파라미터(32B 활성)를 갖추고 있으며, 추론, 코딩, 에이전트 기능을 결합한 하이브리드 추론 시스템으로 이중 작동 모드를 제공합니다.",
  "zai/glm-4.5v.description": "GLM-4.5V는 GLM-4.5-Air를 기반으로 하며, 검증된 GLM-4.1V-Thinking 기술을 계승하고, 106B 파라미터의 강력한 MoE 아키텍처로 확장되었습니다.",
  "zenmux/auto.description": "ZenMux 자동 라우팅은 요청에 따라 지원되는 옵션 중 최고의 성능과 가성비를 갖춘 모델을 선택합니다."
}
