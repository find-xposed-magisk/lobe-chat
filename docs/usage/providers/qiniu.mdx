---
title: Using Qiniu Cloud's Large Language Model API Key in LobeHub
description: >-
  Learn how to configure and use Qiniu Cloud's large language models in LobeHub
  to enable powerful natural language understanding and generation.
tags:
  - API key
  - Web UI
  - Qiniu
  - Qiniu Cloud
  - Qiniu AI
  - DeepSeek
---

# Using Qiniu Cloud's Large Language Model in LobeHub

<Image alt={'Using Qiniu Cloud LLM in LobeHub'} cover src={'/blog/assets48b5c19e20fb870c7bdd34bd3aefbb21.webp'} />

[Qiniu Cloud](https://www.qiniu.com), a well-established cloud service provider, offers cost-effective and reliable real-time and batch AI inference services that are easy to use.

This guide will walk you through how to use Qiniu Cloud's large language models in LobeHub:

<Steps>
  ### Step 1: [Obtain Your AI Model API Key](https://developer.qiniu.com/aitokenapi/12884/how-to-get-api-key)

  - Method 1: Get it via the Console

    1. [Register a Qiniu account](https://s.qiniu.com/umqq6n?ref=developer.qiniu.com\&s_path=%2Faitokenapi%2F12884%2Fhow-to-get-api-key)
    2. [Go to the Console to retrieve your API Key](https://portal.qiniu.com/ai-inference/api-key)
       <Image alt={'Retrieve API Key'} inStep src={'https://static.sufy.com/lobehub/438758098-119239c1-8552-420a-9906-de2eab739fc6.png'} />

  - Method 2: Get it via the Mini Program
    1. Open the Qiniu Mini Program
    2. Log in quickly with your account
    3. Tap on "My" in the bottom navigation bar
    4. Tap on "My Console"
    5. Navigate to "AI Inference"
    6. View and copy your API key

  ### Step 2: Configure Qiniu Cloud LLM Service in LobeHub

  - Open the Settings panel in LobeHub
  - Under the "AI Providers" section, find the "Qiniu Cloud" configuration

  <Image alt={'Enter API Key'} inStep src={'https://static.sufy.com/lobehub/439049319-6ae44f36-bf48-492a-a6aa-7be72f4a29d8.png'} />

  - Enable Qiniu Cloud and paste in your API key
  - Choose a Qiniu Cloud large language model for your AI assistant to start chatting

  <Image alt={'Select Qiniu Cloud LLM and start chatting'} inStep src={'https://static.sufy.com/lobehub/439048945-c608eb9e-6ee1-4611-9df7-2075e95d069b.png'} />

  <Callout type={'warning'}>
    You may incur charges from the API service provider during usage. Please refer to [Qiniu Cloud's pricing policy](https://developer.qiniu.com/aitokenapi/12898/ai-token-api-pricing) for details.
  </Callout>
</Steps>

That's it! You're now ready to use Qiniu Cloud's large language models in LobeHub for intelligent conversations.
